{
 "1": {
  "name": "LONG_DESCRIPTION",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "cerberus/setup.py",
  "lineno": "11",
  "column": "0",
  "slicing": "[\"LONG_DESCRIPTION = open('README.rst').read()\\n\", '    long_description=LONG_DESCRIPTION,\\n']",
  "context": "alidation tool for \"\n    \"Python dictionaries.\"\n)\nLONG_DESCRIPTION = open('README.rst').read()\nVERSION = '2.0.dev0'\n\nsetup_requires = (\n    [\"pyt"
 },
 "2": {
  "name": "extensions",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/docs/conf.py",
  "lineno": "40",
  "column": "0",
  "slicing": "['extensions = [\\n']",
  "context": "phinx (named 'sphinx.ext.*') or your custom ones.\nextensions = [\n    'alabaster',\n    'sphinx.ext.autodoc',\n    'sp"
 },
 "3": {
  "name": "templates_path",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/docs/conf.py",
  "lineno": "50",
  "column": "0",
  "slicing": "[\"templates_path = ['_templates']\\n\"]",
  "context": "ntain templates here, relative to this directory.\ntemplates_path = ['_templates']\n\n# The suffix of source filenames.\nsource_suffix ="
 },
 "4": {
  "name": "version",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/docs/conf.py",
  "lineno": "72",
  "column": "0",
  "slicing": "['module_spec = importlib.util.spec_from_file_location(\\n', '_module = importlib.util.module_from_spec(module_spec)\\n', 'module_spec.loader.exec_module(_module)\\n', \"release = __import__('cerberus').__version__\\n\", \"version = release.split('-dev')[0]\\n\"]",
  "context": "('cerberus').__version__\n# The short X.Y version.\nversion = release.split('-dev')[0]\n\n# Settings for `sphinxcontrib.issuetracker`\nissue"
 },
 "5": {
  "name": "exclude_patterns",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/docs/conf.py",
  "lineno": "90",
  "column": "0",
  "slicing": "[\"exclude_patterns = ['_build', 'includes']\\n\"]",
  "context": "ectories to ignore when looking for source files.\nexclude_patterns = ['_build', 'includes']\n\n# The reST default role (used for this markup: `t"
 },
 "6": {
  "name": "html_theme_options",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/docs/conf.py",
  "lineno": "122",
  "column": "0",
  "slicing": "['html_theme_options = {\\n']",
  "context": "vailable for each theme, see the\n# documentation.\nhtml_theme_options = {\n    'logo': 'cerberus.png',\n    'logo_name': True,"
 },
 "7": {
  "name": "html_theme_path",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/docs/conf.py",
  "lineno": "137",
  "column": "0",
  "slicing": "['module_spec = importlib.util.spec_from_file_location(\\n', '_module = importlib.util.module_from_spec(module_spec)\\n', 'module_spec.loader.exec_module(_module)\\n', \"release = __import__('cerberus').__version__\\n\", \"version = release.split('-dev')[0]\\n\", 'html_theme_path = [alabaster.get_path()]\\n']",
  "context": "n custom themes here, relative to this directory.\nhtml_theme_path = [alabaster.get_path()]\n\n# The name for this set of Sphinx documents.  If "
 },
 "8": {
  "name": "html_static_path",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/docs/conf.py",
  "lineno": "160",
  "column": "0",
  "slicing": "[\"html_static_path = ['_static']\\n\"]",
  "context": "lt.css\" will overwrite the builtin \"default.css\".\nhtml_static_path = ['_static']\n\n# If not '', a 'Last updated on:' timestamp is in"
 },
 "9": {
  "name": "html_sidebars",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/docs/conf.py",
  "lineno": "171",
  "column": "0",
  "slicing": "['html_sidebars = {\\n']",
  "context": "templates, maps document names to template names.\nhtml_sidebars = {\n    '**': [\n        'about.html',\n        'sidebar"
 },
 "10": {
  "name": "latex_elements",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/docs/conf.py",
  "lineno": "218",
  "column": "0",
  "slicing": "['latex_elements = {\\n']",
  "context": "------------------------------------------------\n\nlatex_elements = {\n    # The paper size ('letterpaper' or 'a4paper')."
 },
 "11": {
  "name": "latex_documents",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/docs/conf.py",
  "lineno": "229",
  "column": "0",
  "slicing": "['latex_documents = [\\n']",
  "context": "me, title, author, documentclass [howto/manual]).\nlatex_documents = [\n    ('index', 'Cerberus.tex', u'Cerberus Documenta"
 },
 "12": {
  "name": "man_pages",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/docs/conf.py",
  "lineno": "258",
  "column": "0",
  "slicing": "[\"man_pages = [('index', 'cerberus', u'Cerberus Documentation', [u'Nicola Iarocci'], 1)]\\n\"]",
  "context": "ile, name, description, authors, manual section).\nman_pages = [('index', 'cerberus', u'Cerberus Documentation', [u'Nicola Iarocci'], 1)]\n\n# If true, show URL addresses after external link"
 },
 "13": {
  "name": "texinfo_documents",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/docs/conf.py",
  "lineno": "269",
  "column": "0",
  "slicing": "['texinfo_documents = [\\n']",
  "context": "author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (\n        'index',\n        'Cerberus',\n       "
 },
 "14": {
  "name": "intersphinx_mapping",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/docs/conf.py",
  "lineno": "293",
  "column": "0",
  "slicing": "[\"intersphinx_mapping = {'py': ('https://docs.python.org/3', None)}\\n\"]",
  "context": "ension -----------------------------------------\n\nintersphinx_mapping = {'py': ('https://docs.python.org/3', None)}\n\n\n# -- Options for doclinks extension ------------"
 },
 "15": {
  "name": "linkcheck_ignore",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/docs/conf.py",
  "lineno": "298",
  "column": "0",
  "slicing": "[\"linkcheck_ignore = ['https://groups.google.com/forum/#!forum/.*']\\n\"]",
  "context": "ion --------------------------------------------\n\nlinkcheck_ignore = ['https://groups.google.com/forum/#!forum/.*']\nlinkcheck_anchors = True\n\n# -- Options for doctest"
 },
 "16": {
  "name": "linkcheck_anchors",
  "type": "bool",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/docs/conf.py",
  "lineno": "299",
  "column": "0",
  "slicing": "['linkcheck_anchors = True\\n']",
  "context": " = ['https://groups.google.com/forum/#!forum/.*']\nlinkcheck_anchors = True\n\n# -- Options for doctest extension --------------"
 },
 "17": {
  "name": "extlinks",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/docs/conf.py",
  "lineno": "312",
  "column": "0",
  "slicing": "[\"extlinks = {'issue': ('https://github.com/pyeve/cerberus/issues/%s', '#')}\\n\"]",
  "context": "ion --------------------------------------------\n\nextlinks = {'issue': ('https://github.com/pyeve/cerberus/issues/%s', '#')}\n"
 },
 "18": {
  "name": "errors_module",
  "type": "load_module_members",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/docs/includes/generate.py",
  "lineno": "22",
  "column": "0",
  "slicing": "['INCLUDES_DIR = Path(__file__).parent.resolve()\\n', \"CERBERUS_DIR = INCLUDES_DIR.parent.parent / 'cerberus'\\n\", 'def load_module_members(name, path):\\n', '    module_spec = importlib.util.spec_from_file_location(name, path)\\n', '    _module = importlib.util.module_from_spec(module_spec)\\n', '    module_spec.loader.exec_module(_module)\\n', '    return vars(_module)\\n', \"errors_module = load_module_members('errors', CERBERUS_DIR / 'errors.py')\\n\", \"error_type = errors_module['ErrorDefinition']\\n\", 'error_definitions = []\\n', 'for name, member in errors_module.items():\\n', '    if not isinstance(member, error_type):\\n', '    error_definition = SimpleNamespace(code=member.code, rule=member.rule)\\n', '    error_definition.name = name\\n', '    error_definitions.append(error_definition)\\n', \"error_definitions.sort(key=attrgetter('code'))\\n\", \"with (INCLUDES_DIR / 'error-codes.rst').open('wt') as f:\\n\", '        file=f,\\n', '    for error_definition in error_definitions:\\n', '   * - {error_definition.code}\\n', '     - {hex(error_definition.code)}\\n', '     - {error_definition.name}\\n', '     - {error_definition.rule}\"\"\".lstrip(\\n', '            file=f,\\n', \"validator_module = load_module_members('validator', CERBERUS_DIR / 'validator.py')\\n\", \"validator = validator_module['Validator']()\\n\", '    validator.rules, width=68\\n', \"with (INCLUDES_DIR / 'schema-validation-schema.rst').open('wt') as f:\\n\", \"        '.. code-block:: python\\\\n\\\\n', indent(schema_validation_schema, '    '), file=f\\n\"]",
  "context": "r.exec_module(_module)\n    return vars(_module)\n\n\nerrors_module = load_module_members('errors', CERBERUS_DIR / 'errors.py')\nerror_type = errors_module['ErrorDefinition']\nerro"
 },
 "19": {
  "name": "error_type",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/docs/includes/generate.py",
  "lineno": "23",
  "column": "0",
  "slicing": "['INCLUDES_DIR = Path(__file__).parent.resolve()\\n', \"CERBERUS_DIR = INCLUDES_DIR.parent.parent / 'cerberus'\\n\", 'def load_module_members(name, path):\\n', '    module_spec = importlib.util.spec_from_file_location(name, path)\\n', '    _module = importlib.util.module_from_spec(module_spec)\\n', '    module_spec.loader.exec_module(_module)\\n', '    return vars(_module)\\n', \"errors_module = load_module_members('errors', CERBERUS_DIR / 'errors.py')\\n\", \"error_type = errors_module['ErrorDefinition']\\n\", 'error_definitions = []\\n', 'for name, member in errors_module.items():\\n', '    if not isinstance(member, error_type):\\n', '    error_definition = SimpleNamespace(code=member.code, rule=member.rule)\\n', '    error_definition.name = name\\n', '    error_definitions.append(error_definition)\\n', \"error_definitions.sort(key=attrgetter('code'))\\n\", \"with (INCLUDES_DIR / 'error-codes.rst').open('wt') as f:\\n\", '        file=f,\\n', '    for error_definition in error_definitions:\\n', '   * - {error_definition.code}\\n', '     - {hex(error_definition.code)}\\n', '     - {error_definition.name}\\n', '     - {error_definition.rule}\"\"\".lstrip(\\n', '            file=f,\\n', \"validator_module = load_module_members('validator', CERBERUS_DIR / 'validator.py')\\n\", \"validator = validator_module['Validator']()\\n\", '    validator.rules, width=68\\n', \"with (INCLUDES_DIR / 'schema-validation-schema.rst').open('wt') as f:\\n\", \"        '.. code-block:: python\\\\n\\\\n', indent(schema_validation_schema, '    '), file=f\\n\"]",
  "context": "ule_members('errors', CERBERUS_DIR / 'errors.py')\nerror_type = errors_module['ErrorDefinition']\nerror_definitions = []\nfor name, member in errors_"
 },
 "20": {
  "name": "error_definitions",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/docs/includes/generate.py",
  "lineno": "24",
  "column": "0",
  "slicing": "['error_definitions = []\\n', '    error_definitions.append(error_definition)\\n', \"error_definitions.sort(key=attrgetter('code'))\\n\", '    for error_definition in error_definitions:\\n', '   * - {error_definition.code}\\n', '     - {hex(error_definition.code)}\\n', '     - {error_definition.name}\\n', '     - {error_definition.rule}\"\"\".lstrip(\\n']",
  "context": "y')\nerror_type = errors_module['ErrorDefinition']\nerror_definitions = []\nfor name, member in errors_module.items():\n    if "
 },
 "21": {
  "name": "error_definition",
  "type": "types.SimpleNamespace",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/docs/includes/generate.py",
  "lineno": "28",
  "column": "4",
  "slicing": "['INCLUDES_DIR = Path(__file__).parent.resolve()\\n', \"CERBERUS_DIR = INCLUDES_DIR.parent.parent / 'cerberus'\\n\", 'def load_module_members(name, path):\\n', '    module_spec = importlib.util.spec_from_file_location(name, path)\\n', '    _module = importlib.util.module_from_spec(module_spec)\\n', '    module_spec.loader.exec_module(_module)\\n', '    return vars(_module)\\n', \"errors_module = load_module_members('errors', CERBERUS_DIR / 'errors.py')\\n\", \"error_type = errors_module['ErrorDefinition']\\n\", 'error_definitions = []\\n', 'for name, member in errors_module.items():\\n', '    if not isinstance(member, error_type):\\n', '    error_definition = SimpleNamespace(code=member.code, rule=member.rule)\\n', '    error_definition.name = name\\n', '    error_definitions.append(error_definition)\\n', \"error_definitions.sort(key=attrgetter('code'))\\n\", \"with (INCLUDES_DIR / 'error-codes.rst').open('wt') as f:\\n\", '        file=f,\\n', '    for error_definition in error_definitions:\\n', '   * - {error_definition.code}\\n', '     - {hex(error_definition.code)}\\n', '     - {error_definition.name}\\n', '     - {error_definition.rule}\"\"\".lstrip(\\n', '            file=f,\\n', \"validator_module = load_module_members('validator', CERBERUS_DIR / 'validator.py')\\n\", \"validator = validator_module['Validator']()\\n\", '    validator.rules, width=68\\n', \"with (INCLUDES_DIR / 'schema-validation-schema.rst').open('wt') as f:\\n\", \"        '.. code-block:: python\\\\n\\\\n', indent(schema_validation_schema, '    '), file=f\\n\"]",
  "context": "nstance(member, error_type):\n        continue\n    error_definition = SimpleNamespace(code=member.code, rule=member.rule)\n    error_definition.name = name\n    error_definit"
 },
 "22": {
  "name": "validator_module",
  "type": "load_module_members",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/docs/includes/generate.py",
  "lineno": "62",
  "column": "0",
  "slicing": "['INCLUDES_DIR = Path(__file__).parent.resolve()\\n', \"CERBERUS_DIR = INCLUDES_DIR.parent.parent / 'cerberus'\\n\", 'def load_module_members(name, path):\\n', '    module_spec = importlib.util.spec_from_file_location(name, path)\\n', '    _module = importlib.util.module_from_spec(module_spec)\\n', '    module_spec.loader.exec_module(_module)\\n', '    return vars(_module)\\n', \"errors_module = load_module_members('errors', CERBERUS_DIR / 'errors.py')\\n\", \"error_type = errors_module['ErrorDefinition']\\n\", 'error_definitions = []\\n', 'for name, member in errors_module.items():\\n', '    if not isinstance(member, error_type):\\n', '    error_definition = SimpleNamespace(code=member.code, rule=member.rule)\\n', '    error_definition.name = name\\n', '    error_definitions.append(error_definition)\\n', \"error_definitions.sort(key=attrgetter('code'))\\n\", \"with (INCLUDES_DIR / 'error-codes.rst').open('wt') as f:\\n\", '        file=f,\\n', '    for error_definition in error_definitions:\\n', '   * - {error_definition.code}\\n', '     - {hex(error_definition.code)}\\n', '     - {error_definition.name}\\n', '     - {error_definition.rule}\"\"\".lstrip(\\n', '            file=f,\\n', \"validator_module = load_module_members('validator', CERBERUS_DIR / 'validator.py')\\n\", \"validator = validator_module['Validator']()\\n\", '    validator.rules, width=68\\n', \"with (INCLUDES_DIR / 'schema-validation-schema.rst').open('wt') as f:\\n\", \"        '.. code-block:: python\\\\n\\\\n', indent(schema_validation_schema, '    '), file=f\\n\"]",
  "context": "print('Generated table with ErrorDefinitions.')\n\n\nvalidator_module = load_module_members('validator', CERBERUS_DIR / 'validator.py')\nvalidator = validator_module['Validator']()\nschema"
 },
 "23": {
  "name": "validator",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/docs/includes/generate.py",
  "lineno": "63",
  "column": "0",
  "slicing": "['INCLUDES_DIR = Path(__file__).parent.resolve()\\n', \"CERBERUS_DIR = INCLUDES_DIR.parent.parent / 'cerberus'\\n\", 'def load_module_members(name, path):\\n', '    module_spec = importlib.util.spec_from_file_location(name, path)\\n', '    _module = importlib.util.module_from_spec(module_spec)\\n', '    module_spec.loader.exec_module(_module)\\n', '    return vars(_module)\\n', \"errors_module = load_module_members('errors', CERBERUS_DIR / 'errors.py')\\n\", \"error_type = errors_module['ErrorDefinition']\\n\", 'error_definitions = []\\n', 'for name, member in errors_module.items():\\n', '    if not isinstance(member, error_type):\\n', '    error_definition = SimpleNamespace(code=member.code, rule=member.rule)\\n', '    error_definition.name = name\\n', '    error_definitions.append(error_definition)\\n', \"error_definitions.sort(key=attrgetter('code'))\\n\", \"with (INCLUDES_DIR / 'error-codes.rst').open('wt') as f:\\n\", '        file=f,\\n', '    for error_definition in error_definitions:\\n', '   * - {error_definition.code}\\n', '     - {hex(error_definition.code)}\\n', '     - {error_definition.name}\\n', '     - {error_definition.rule}\"\"\".lstrip(\\n', '            file=f,\\n', \"validator_module = load_module_members('validator', CERBERUS_DIR / 'validator.py')\\n\", \"validator = validator_module['Validator']()\\n\", '    validator.rules, width=68\\n', \"with (INCLUDES_DIR / 'schema-validation-schema.rst').open('wt') as f:\\n\", \"        '.. code-block:: python\\\\n\\\\n', indent(schema_validation_schema, '    '), file=f\\n\"]",
  "context": "mbers('validator', CERBERUS_DIR / 'validator.py')\nvalidator = validator_module['Validator']()\nschema_validation_schema = pformat(\n    validator."
 },
 "24": {
  "name": "schema_validation_schema",
  "type": "pprint.pformat",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/docs/includes/generate.py",
  "lineno": "64",
  "column": "0",
  "slicing": "['INCLUDES_DIR = Path(__file__).parent.resolve()\\n', \"CERBERUS_DIR = INCLUDES_DIR.parent.parent / 'cerberus'\\n\", 'def load_module_members(name, path):\\n', '    module_spec = importlib.util.spec_from_file_location(name, path)\\n', '    _module = importlib.util.module_from_spec(module_spec)\\n', '    module_spec.loader.exec_module(_module)\\n', '    return vars(_module)\\n', \"errors_module = load_module_members('errors', CERBERUS_DIR / 'errors.py')\\n\", \"error_type = errors_module['ErrorDefinition']\\n\", 'error_definitions = []\\n', 'for name, member in errors_module.items():\\n', '    if not isinstance(member, error_type):\\n', '    error_definition = SimpleNamespace(code=member.code, rule=member.rule)\\n', '    error_definition.name = name\\n', '    error_definitions.append(error_definition)\\n', \"error_definitions.sort(key=attrgetter('code'))\\n\", \"with (INCLUDES_DIR / 'error-codes.rst').open('wt') as f:\\n\", '        file=f,\\n', '    for error_definition in error_definitions:\\n', '   * - {error_definition.code}\\n', '     - {hex(error_definition.code)}\\n', '     - {error_definition.name}\\n', '     - {error_definition.rule}\"\"\".lstrip(\\n', '            file=f,\\n', \"validator_module = load_module_members('validator', CERBERUS_DIR / 'validator.py')\\n\", \"validator = validator_module['Validator']()\\n\", 'schema_validation_schema = pformat(\\n', '    validator.rules, width=68\\n', \"with (INCLUDES_DIR / 'schema-validation-schema.rst').open('wt') as f:\\n\", \"        '.. code-block:: python\\\\n\\\\n', indent(schema_validation_schema, '    '), file=f\\n\"]",
  "context": ".py')\nvalidator = validator_module['Validator']()\nschema_validation_schema = pformat(\n    validator.rules, width=68\n)  # width seems w/o"
 },
 "25": {
  "name": "_hash",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/schema.py",
  "lineno": "89",
  "column": "8",
  "slicing": "['        _hash = (\\n', '        if _hash in self.target_validator._valid_schemas:\\n', '            self.target_validator._valid_schemas.add(_hash)\\n', '        if _hash in self.target_validator._valid_schemas:\\n', '            self.target_validator._valid_schemas.add(_hash)\\n', '            if _hash in self.target_validator._valid_schemas:\\n', '                self.target_validator._valid_schemas.add(_hash)\\n', '        if _hash not in self.validator._valid_schemas:\\n', '            self.validator._valid_schemas.add(_hash)\\n']",
  "context": "else:\n                value = definition\n\n        _hash = (\n            schema_hash({'turing': value}),\n      "
 },
 "26": {
  "name": "value",
  "type": "definition",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/schema.py",
  "lineno": "87",
  "column": "16",
  "slicing": "['    types_mapping = UnconcernedValidator.types_mapping.copy()\\n', '    types_mapping.update(\\n', '            validator = self._get_child_validator(\\n', '            if not validator(value, normalize=False):\\n', '                self._error(validator._errors)\\n', '            if not all(isinstance(x, Hashable) for x in value):\\n', '                path = self.document_path + (field,)\\n', \"                self._error(path, 'All dependencies must be a hashable type.')\\n\", '            field, {i: rules_set for i, rules_set in enumerate(value)}\\n', '            definition = self.target_validator.rules_set_registry.get(value)\\n', '            if definition is None:\\n', '                value = definition\\n', '        _hash = (\\n', \"            schema_hash({'turing': value}),\\n\", '        if _hash in self.target_validator._valid_schemas:\\n', '        validator = self._get_child_validator(\\n', '        validator(value, normalize=False)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', '            self.target_validator._valid_schemas.add(_hash)\\n', '        if isinstance(value, str):\\n', '            if value in self.known_schema_refs:\\n', '            self.known_schema_refs.add(value)\\n', '            definition = self.target_validator.schema_registry.get(value)\\n', '            if definition is None:\\n', '                path = self.document_path + (field,)\\n', '                self._error(path, \"Schema definition \\'{}\\' not found.\".format(value))\\n', '            definition = value\\n', '        _hash = (\\n', '            schema_hash(definition),\\n', '        if _hash in self.target_validator._valid_schemas:\\n', '        validator = self._get_child_validator(\\n', '        validator(self._expand_rules_set_refs(definition), normalize=False)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', '            self.target_validator._valid_schemas.add(_hash)\\n', '        if value not in self.target_validator.types_mapping:\\n', \"            self._error(field, 'Unsupported type name: {}'.format(value))\\n\", '        result = {}\\n', '        for k, v in schema.items():\\n', '            if isinstance(v, str):\\n', '                result[k] = self.target_validator.rules_set_registry.get(v)\\n', '                result[k] = v\\n', '        return result\\n', '        if not isinstance(value, Sequence):\\n', '        validator = self._get_child_validator(\\n', '        for constraints in value:\\n', '            _hash = (\\n', \"                schema_hash({'turing': constraints}),\\n\", '            if _hash in self.target_validator._valid_schemas:\\n', '            validator(constraints, normalize=False)\\n', '            if validator._errors:\\n', '                self._error(validator._errors)\\n', '                self.target_validator._valid_schemas.add(_hash)\\n', '        if not isinstance(validator, UnconcernedValidator):\\n', '        self.validator = validator\\n', '            target_validator=validator,\\n', '            schema = validator.schema_registry.get(schema, schema)\\n', '        if not isinstance(schema, abc.Mapping):\\n', '            raise SchemaError(errors.SCHEMA_TYPE.format(schema))\\n', '            schema = normalize_schema(schema)\\n', '        self.validate(schema)\\n', '        self._repr = (\"{}\", schema)\\n', '        self.schema = schema\\n', '        value = normalize_rulesset(value)\\n', '        self.validate({key: value})\\n', '        self.schema[key] = value\\n', '        if not isinstance(schema, abc.Mapping):\\n', '        new_schema = ChainMap(schema, self.schema)\\n', '        self.validate(new_schema)\\n', '        self.schema = new_schema\\n', '        if schema is None:\\n', '            schema = self.schema\\n', '        _hash = (schema_hash(schema), schema_hash(self.validator.types_mapping))\\n', '        if _hash not in self.validator._valid_schemas:\\n', '            self._validate(schema)\\n', '            self.validator._valid_schemas.add(_hash)\\n', '        if isinstance(schema, str):\\n', '            schema = self.validator.schema_registry.get(schema, schema)\\n', '        if schema is None:\\n', '            k: self.validator.rules_set_registry.get(v, v)\\n', '            for k, v in schema.items()\\n', '            if isinstance(v, str)\\n', '        if not self.schema_validator(ChainMap(resolved, schema), normalize=False):\\n']",
  "context": "         return\n            else:\n                value = definition\n\n        _hash = (\n            schema_hash({'turin"
 },
 "27": {
  "name": "value",
  "type": "dict",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/schema.py",
  "lineno": "107",
  "column": "40",
  "slicing": "['    def _check_with_schema(self, field, value):\\n']",
  "context": "d(_hash)\n\n    def _check_with_schema(self, field, value):\n        if isinstance(value, str):\n            if "
 },
 "28": {
  "name": "_hash",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/schema.py",
  "lineno": "120",
  "column": "8",
  "slicing": "['        _hash = (\\n', '        if _hash in self.target_validator._valid_schemas:\\n', '            self.target_validator._valid_schemas.add(_hash)\\n', '            if _hash in self.target_validator._valid_schemas:\\n', '                self.target_validator._valid_schemas.add(_hash)\\n', '        if _hash not in self.validator._valid_schemas:\\n', '            self.validator._valid_schemas.add(_hash)\\n']",
  "context": "    else:\n            definition = value\n\n        _hash = (\n            schema_hash(definition),\n            s"
 },
 "29": {
  "name": "definition",
  "type": "value",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/schema.py",
  "lineno": "118",
  "column": "12",
  "slicing": "['    types_mapping = UnconcernedValidator.types_mapping.copy()\\n', '    types_mapping.update(\\n', '            validator = self._get_child_validator(\\n', '            if not validator(value, normalize=False):\\n', '                self._error(validator._errors)\\n', '            if not all(isinstance(x, Hashable) for x in value):\\n', '                path = self.document_path + (field,)\\n', \"                self._error(path, 'All dependencies must be a hashable type.')\\n\", '            field, {i: rules_set for i, rules_set in enumerate(value)}\\n', '            definition = self.target_validator.rules_set_registry.get(value)\\n', '            if definition is None:\\n', '                value = definition\\n', '        _hash = (\\n', \"            schema_hash({'turing': value}),\\n\", '        if _hash in self.target_validator._valid_schemas:\\n', '        validator = self._get_child_validator(\\n', '        validator(value, normalize=False)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', '            self.target_validator._valid_schemas.add(_hash)\\n', '        if isinstance(value, str):\\n', '            if value in self.known_schema_refs:\\n', '            self.known_schema_refs.add(value)\\n', '            definition = self.target_validator.schema_registry.get(value)\\n', '            if definition is None:\\n', '                path = self.document_path + (field,)\\n', '                self._error(path, \"Schema definition \\'{}\\' not found.\".format(value))\\n', '            definition = value\\n', '        _hash = (\\n', '            schema_hash(definition),\\n', '        if _hash in self.target_validator._valid_schemas:\\n', '        validator = self._get_child_validator(\\n', '        validator(self._expand_rules_set_refs(definition), normalize=False)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', '            self.target_validator._valid_schemas.add(_hash)\\n', '        if value not in self.target_validator.types_mapping:\\n', \"            self._error(field, 'Unsupported type name: {}'.format(value))\\n\", '        result = {}\\n', '        for k, v in schema.items():\\n', '            if isinstance(v, str):\\n', '                result[k] = self.target_validator.rules_set_registry.get(v)\\n', '                result[k] = v\\n', '        return result\\n', '        if not isinstance(value, Sequence):\\n', '        validator = self._get_child_validator(\\n', '        for constraints in value:\\n', '            _hash = (\\n', \"                schema_hash({'turing': constraints}),\\n\", '            if _hash in self.target_validator._valid_schemas:\\n', '            validator(constraints, normalize=False)\\n', '            if validator._errors:\\n', '                self._error(validator._errors)\\n', '                self.target_validator._valid_schemas.add(_hash)\\n', '        if not isinstance(validator, UnconcernedValidator):\\n', '        self.validator = validator\\n', '            target_validator=validator,\\n', '            schema = validator.schema_registry.get(schema, schema)\\n', '        if not isinstance(schema, abc.Mapping):\\n', '            raise SchemaError(errors.SCHEMA_TYPE.format(schema))\\n', '            schema = normalize_schema(schema)\\n', '        self.validate(schema)\\n', '        self._repr = (\"{}\", schema)\\n', '        self.schema = schema\\n', '        value = normalize_rulesset(value)\\n', '        self.validate({key: value})\\n', '        self.schema[key] = value\\n', '        if not isinstance(schema, abc.Mapping):\\n', '        new_schema = ChainMap(schema, self.schema)\\n', '        self.validate(new_schema)\\n', '        self.schema = new_schema\\n', '        if schema is None:\\n', '            schema = self.schema\\n', '        _hash = (schema_hash(schema), schema_hash(self.validator.types_mapping))\\n', '        if _hash not in self.validator._valid_schemas:\\n', '            self._validate(schema)\\n', '            self.validator._valid_schemas.add(_hash)\\n', '        if isinstance(schema, str):\\n', '            schema = self.validator.schema_registry.get(schema, schema)\\n', '        if schema is None:\\n', '            k: self.validator.rules_set_registry.get(v, v)\\n', '            for k, v in schema.items()\\n', '            if isinstance(v, str)\\n', '        if not self.schema_validator(ChainMap(resolved, schema), normalize=False):\\n']",
  "context": " found.\".format(value))\n        else:\n            definition = value\n\n        _hash = (\n            schema_hash(definit"
 },
 "30": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/schema.py",
  "lineno": "140",
  "column": "37",
  "slicing": "['    def _expand_rules_set_refs(self, schema):\\n']",
  "context": "mat(value))\n\n    def _expand_rules_set_refs(self, schema):\n        result = {}\n        for k, v in schema.ite"
 },
 "31": {
  "name": "result",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/schema.py",
  "lineno": "141",
  "column": "8",
  "slicing": "['        result = {}\\n', '                result[k] = self.target_validator.rules_set_registry.get(v)\\n', '                result[k] = v\\n', '        return result\\n']",
  "context": "def _expand_rules_set_refs(self, schema):\n        result = {}\n        for k, v in schema.items():\n            if"
 },
 "32": {
  "name": "_hash",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/schema.py",
  "lineno": "162",
  "column": "12",
  "slicing": "['            _hash = (\\n', '            if _hash in self.target_validator._valid_schemas:\\n', '                self.target_validator._valid_schemas.add(_hash)\\n', '        if _hash not in self.validator._valid_schemas:\\n', '            self.validator._valid_schemas.add(_hash)\\n']",
  "context": " )\n\n        for constraints in value:\n            _hash = (\n                schema_hash({'turing': constraints"
 },
 "33": {
  "name": "schema",
  "type": "cerberus.base.normalize_schema",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/schema.py",
  "lineno": "208",
  "column": "12",
  "slicing": "['    types_mapping = UnconcernedValidator.types_mapping.copy()\\n', '    types_mapping.update(\\n', '            validator = self._get_child_validator(\\n', '            if not validator(value, normalize=False):\\n', '                self._error(validator._errors)\\n', '            if not all(isinstance(x, Hashable) for x in value):\\n', '                path = self.document_path + (field,)\\n', \"                self._error(path, 'All dependencies must be a hashable type.')\\n\", '            field, {i: rules_set for i, rules_set in enumerate(value)}\\n', '            definition = self.target_validator.rules_set_registry.get(value)\\n', '            if definition is None:\\n', '                value = definition\\n', '        _hash = (\\n', \"            schema_hash({'turing': value}),\\n\", '        if _hash in self.target_validator._valid_schemas:\\n', '        validator = self._get_child_validator(\\n', '        validator(value, normalize=False)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', '            self.target_validator._valid_schemas.add(_hash)\\n', '        if isinstance(value, str):\\n', '            if value in self.known_schema_refs:\\n', '            self.known_schema_refs.add(value)\\n', '            definition = self.target_validator.schema_registry.get(value)\\n', '            if definition is None:\\n', '                path = self.document_path + (field,)\\n', '                self._error(path, \"Schema definition \\'{}\\' not found.\".format(value))\\n', '            definition = value\\n', '        _hash = (\\n', '            schema_hash(definition),\\n', '        if _hash in self.target_validator._valid_schemas:\\n', '        validator = self._get_child_validator(\\n', '        validator(self._expand_rules_set_refs(definition), normalize=False)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', '            self.target_validator._valid_schemas.add(_hash)\\n', '        if value not in self.target_validator.types_mapping:\\n', \"            self._error(field, 'Unsupported type name: {}'.format(value))\\n\", '        result = {}\\n', '        for k, v in schema.items():\\n', '            if isinstance(v, str):\\n', '                result[k] = self.target_validator.rules_set_registry.get(v)\\n', '                result[k] = v\\n', '        return result\\n', '        if not isinstance(value, Sequence):\\n', '        validator = self._get_child_validator(\\n', '        for constraints in value:\\n', '            _hash = (\\n', \"                schema_hash({'turing': constraints}),\\n\", '            if _hash in self.target_validator._valid_schemas:\\n', '            validator(constraints, normalize=False)\\n', '            if validator._errors:\\n', '                self._error(validator._errors)\\n', '                self.target_validator._valid_schemas.add(_hash)\\n', '        if not isinstance(validator, UnconcernedValidator):\\n', '        self.validator = validator\\n', '            target_validator=validator,\\n', '            schema = validator.schema_registry.get(schema, schema)\\n', '        if not isinstance(schema, abc.Mapping):\\n', '            raise SchemaError(errors.SCHEMA_TYPE.format(schema))\\n', '            schema = normalize_schema(schema)\\n', '        self.validate(schema)\\n', '        self._repr = (\"{}\", schema)\\n', '        self.schema = schema\\n', '        value = normalize_rulesset(value)\\n', '        self.validate({key: value})\\n', '        self.schema[key] = value\\n', '        if not isinstance(schema, abc.Mapping):\\n', '        new_schema = ChainMap(schema, self.schema)\\n', '        self.validate(new_schema)\\n', '        self.schema = new_schema\\n', '        if schema is None:\\n', '            schema = self.schema\\n', '        _hash = (schema_hash(schema), schema_hash(self.validator.types_mapping))\\n', '        if _hash not in self.validator._valid_schemas:\\n', '            self._validate(schema)\\n', '            self.validator._valid_schemas.add(_hash)\\n', '        if isinstance(schema, str):\\n', '            schema = self.validator.schema_registry.get(schema, schema)\\n', '        if schema is None:\\n', '            k: self.validator.rules_set_registry.get(v, v)\\n', '            for k, v in schema.items()\\n', '            if isinstance(v, str)\\n', '        if not self.schema_validator(ChainMap(resolved, schema), normalize=False):\\n']",
  "context": "MA_TYPE.format(schema))\n        else:\n            schema = normalize_schema(schema)\n\n        self.validate(schema)\n        self._repr "
 },
 "34": {
  "name": "value",
  "type": "cerberus.base.normalize_rulesset",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/schema.py",
  "lineno": "231",
  "column": "8",
  "slicing": "['    types_mapping = UnconcernedValidator.types_mapping.copy()\\n', '    types_mapping.update(\\n', '            validator = self._get_child_validator(\\n', '            if not validator(value, normalize=False):\\n', '                self._error(validator._errors)\\n', '            if not all(isinstance(x, Hashable) for x in value):\\n', '                path = self.document_path + (field,)\\n', \"                self._error(path, 'All dependencies must be a hashable type.')\\n\", '            field, {i: rules_set for i, rules_set in enumerate(value)}\\n', '            definition = self.target_validator.rules_set_registry.get(value)\\n', '            if definition is None:\\n', '                value = definition\\n', '        _hash = (\\n', \"            schema_hash({'turing': value}),\\n\", '        if _hash in self.target_validator._valid_schemas:\\n', '        validator = self._get_child_validator(\\n', '        validator(value, normalize=False)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', '            self.target_validator._valid_schemas.add(_hash)\\n', '        if isinstance(value, str):\\n', '            if value in self.known_schema_refs:\\n', '            self.known_schema_refs.add(value)\\n', '            definition = self.target_validator.schema_registry.get(value)\\n', '            if definition is None:\\n', '                path = self.document_path + (field,)\\n', '                self._error(path, \"Schema definition \\'{}\\' not found.\".format(value))\\n', '            definition = value\\n', '        _hash = (\\n', '            schema_hash(definition),\\n', '        if _hash in self.target_validator._valid_schemas:\\n', '        validator = self._get_child_validator(\\n', '        validator(self._expand_rules_set_refs(definition), normalize=False)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', '            self.target_validator._valid_schemas.add(_hash)\\n', '        if value not in self.target_validator.types_mapping:\\n', \"            self._error(field, 'Unsupported type name: {}'.format(value))\\n\", '        result = {}\\n', '        for k, v in schema.items():\\n', '            if isinstance(v, str):\\n', '                result[k] = self.target_validator.rules_set_registry.get(v)\\n', '                result[k] = v\\n', '        return result\\n', '        if not isinstance(value, Sequence):\\n', '        validator = self._get_child_validator(\\n', '        for constraints in value:\\n', '            _hash = (\\n', \"                schema_hash({'turing': constraints}),\\n\", '            if _hash in self.target_validator._valid_schemas:\\n', '            validator(constraints, normalize=False)\\n', '            if validator._errors:\\n', '                self._error(validator._errors)\\n', '                self.target_validator._valid_schemas.add(_hash)\\n', '        if not isinstance(validator, UnconcernedValidator):\\n', '        self.validator = validator\\n', '            target_validator=validator,\\n', '            schema = validator.schema_registry.get(schema, schema)\\n', '        if not isinstance(schema, abc.Mapping):\\n', '            raise SchemaError(errors.SCHEMA_TYPE.format(schema))\\n', '            schema = normalize_schema(schema)\\n', '        self.validate(schema)\\n', '        self._repr = (\"{}\", schema)\\n', '        self.schema = schema\\n', '        value = normalize_rulesset(value)\\n', '        self.validate({key: value})\\n', '        self.schema[key] = value\\n', '        if not isinstance(schema, abc.Mapping):\\n', '        new_schema = ChainMap(schema, self.schema)\\n', '        self.validate(new_schema)\\n', '        self.schema = new_schema\\n', '        if schema is None:\\n', '            schema = self.schema\\n', '        _hash = (schema_hash(schema), schema_hash(self.validator.types_mapping))\\n', '        if _hash not in self.validator._valid_schemas:\\n', '            self._validate(schema)\\n', '            self.validator._valid_schemas.add(_hash)\\n', '        if isinstance(schema, str):\\n', '            schema = self.validator.schema_registry.get(schema, schema)\\n', '        if schema is None:\\n', '            k: self.validator.rules_set_registry.get(v, v)\\n', '            for k, v in schema.items()\\n', '            if isinstance(v, str)\\n', '        if not self.schema_validator(ChainMap(resolved, schema), normalize=False):\\n']",
  "context": ")\n\n    def __setitem__(self, key, value):\n        value = normalize_rulesset(value)\n        self.validate({key: value})\n        self.s"
 },
 "35": {
  "name": "new_schema",
  "type": "collections.ChainMap",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/schema.py",
  "lineno": "245",
  "column": "8",
  "slicing": "['    types_mapping = UnconcernedValidator.types_mapping.copy()\\n', '    types_mapping.update(\\n', '            validator = self._get_child_validator(\\n', '            if not validator(value, normalize=False):\\n', '                self._error(validator._errors)\\n', '            if not all(isinstance(x, Hashable) for x in value):\\n', '                path = self.document_path + (field,)\\n', \"                self._error(path, 'All dependencies must be a hashable type.')\\n\", '            field, {i: rules_set for i, rules_set in enumerate(value)}\\n', '            definition = self.target_validator.rules_set_registry.get(value)\\n', '            if definition is None:\\n', '                value = definition\\n', '        _hash = (\\n', \"            schema_hash({'turing': value}),\\n\", '        if _hash in self.target_validator._valid_schemas:\\n', '        validator = self._get_child_validator(\\n', '        validator(value, normalize=False)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', '            self.target_validator._valid_schemas.add(_hash)\\n', '        if isinstance(value, str):\\n', '            if value in self.known_schema_refs:\\n', '            self.known_schema_refs.add(value)\\n', '            definition = self.target_validator.schema_registry.get(value)\\n', '            if definition is None:\\n', '                path = self.document_path + (field,)\\n', '                self._error(path, \"Schema definition \\'{}\\' not found.\".format(value))\\n', '            definition = value\\n', '        _hash = (\\n', '            schema_hash(definition),\\n', '        if _hash in self.target_validator._valid_schemas:\\n', '        validator = self._get_child_validator(\\n', '        validator(self._expand_rules_set_refs(definition), normalize=False)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', '            self.target_validator._valid_schemas.add(_hash)\\n', '        if value not in self.target_validator.types_mapping:\\n', \"            self._error(field, 'Unsupported type name: {}'.format(value))\\n\", '        result = {}\\n', '        for k, v in schema.items():\\n', '            if isinstance(v, str):\\n', '                result[k] = self.target_validator.rules_set_registry.get(v)\\n', '                result[k] = v\\n', '        return result\\n', '        if not isinstance(value, Sequence):\\n', '        validator = self._get_child_validator(\\n', '        for constraints in value:\\n', '            _hash = (\\n', \"                schema_hash({'turing': constraints}),\\n\", '            if _hash in self.target_validator._valid_schemas:\\n', '            validator(constraints, normalize=False)\\n', '            if validator._errors:\\n', '                self._error(validator._errors)\\n', '                self.target_validator._valid_schemas.add(_hash)\\n', '        if not isinstance(validator, UnconcernedValidator):\\n', '        self.validator = validator\\n', '            target_validator=validator,\\n', '            schema = validator.schema_registry.get(schema, schema)\\n', '        if not isinstance(schema, abc.Mapping):\\n', '            raise SchemaError(errors.SCHEMA_TYPE.format(schema))\\n', '            schema = normalize_schema(schema)\\n', '        self.validate(schema)\\n', '        self._repr = (\"{}\", schema)\\n', '        self.schema = schema\\n', '        value = normalize_rulesset(value)\\n', '        self.validate({key: value})\\n', '        self.schema[key] = value\\n', '        if not isinstance(schema, abc.Mapping):\\n', '        new_schema = ChainMap(schema, self.schema)\\n', '        self.validate(new_schema)\\n', '        self.schema = new_schema\\n', '        if schema is None:\\n', '            schema = self.schema\\n', '        _hash = (schema_hash(schema), schema_hash(self.validator.types_mapping))\\n', '        if _hash not in self.validator._valid_schemas:\\n', '            self._validate(schema)\\n', '            self.validator._valid_schemas.add(_hash)\\n', '        if isinstance(schema, str):\\n', '            schema = self.validator.schema_registry.get(schema, schema)\\n', '        if schema is None:\\n', '            k: self.validator.rules_set_registry.get(v, v)\\n', '            for k, v in schema.items()\\n', '            if isinstance(v, str)\\n', '        if not self.schema_validator(ChainMap(resolved, schema), normalize=False):\\n']",
  "context": "eError(\"Value must be of Mapping Type.\")\n\n        new_schema = ChainMap(schema, self.schema)\n        self.validate(new_schema)\n        self.sch"
 },
 "36": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/schema.py",
  "lineno": "258",
  "column": "12",
  "slicing": "['    types_mapping = UnconcernedValidator.types_mapping.copy()\\n', '    types_mapping.update(\\n', '            validator = self._get_child_validator(\\n', '            if not validator(value, normalize=False):\\n', '                self._error(validator._errors)\\n', '            if not all(isinstance(x, Hashable) for x in value):\\n', '                path = self.document_path + (field,)\\n', \"                self._error(path, 'All dependencies must be a hashable type.')\\n\", '            field, {i: rules_set for i, rules_set in enumerate(value)}\\n', '            definition = self.target_validator.rules_set_registry.get(value)\\n', '            if definition is None:\\n', '                value = definition\\n', '        _hash = (\\n', \"            schema_hash({'turing': value}),\\n\", '        if _hash in self.target_validator._valid_schemas:\\n', '        validator = self._get_child_validator(\\n', '        validator(value, normalize=False)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', '            self.target_validator._valid_schemas.add(_hash)\\n', '        if isinstance(value, str):\\n', '            if value in self.known_schema_refs:\\n', '            self.known_schema_refs.add(value)\\n', '            definition = self.target_validator.schema_registry.get(value)\\n', '            if definition is None:\\n', '                path = self.document_path + (field,)\\n', '                self._error(path, \"Schema definition \\'{}\\' not found.\".format(value))\\n', '            definition = value\\n', '        _hash = (\\n', '            schema_hash(definition),\\n', '        if _hash in self.target_validator._valid_schemas:\\n', '        validator = self._get_child_validator(\\n', '        validator(self._expand_rules_set_refs(definition), normalize=False)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', '            self.target_validator._valid_schemas.add(_hash)\\n', '        if value not in self.target_validator.types_mapping:\\n', \"            self._error(field, 'Unsupported type name: {}'.format(value))\\n\", '        result = {}\\n', '        for k, v in schema.items():\\n', '            if isinstance(v, str):\\n', '                result[k] = self.target_validator.rules_set_registry.get(v)\\n', '                result[k] = v\\n', '        return result\\n', '        if not isinstance(value, Sequence):\\n', '        validator = self._get_child_validator(\\n', '        for constraints in value:\\n', '            _hash = (\\n', \"                schema_hash({'turing': constraints}),\\n\", '            if _hash in self.target_validator._valid_schemas:\\n', '            validator(constraints, normalize=False)\\n', '            if validator._errors:\\n', '                self._error(validator._errors)\\n', '                self.target_validator._valid_schemas.add(_hash)\\n', '        if not isinstance(validator, UnconcernedValidator):\\n', '        self.validator = validator\\n', '            target_validator=validator,\\n', '            schema = validator.schema_registry.get(schema, schema)\\n', '        if not isinstance(schema, abc.Mapping):\\n', '            raise SchemaError(errors.SCHEMA_TYPE.format(schema))\\n', '            schema = normalize_schema(schema)\\n', '        self.validate(schema)\\n', '        self._repr = (\"{}\", schema)\\n', '        self.schema = schema\\n', '        value = normalize_rulesset(value)\\n', '        self.validate({key: value})\\n', '        self.schema[key] = value\\n', '        if not isinstance(schema, abc.Mapping):\\n', '        new_schema = ChainMap(schema, self.schema)\\n', '        self.validate(new_schema)\\n', '        self.schema = new_schema\\n', '        if schema is None:\\n', '            schema = self.schema\\n', '        _hash = (schema_hash(schema), schema_hash(self.validator.types_mapping))\\n', '        if _hash not in self.validator._valid_schemas:\\n', '            self._validate(schema)\\n', '            self.validator._valid_schemas.add(_hash)\\n', '        if isinstance(schema, str):\\n', '            schema = self.validator.schema_registry.get(schema, schema)\\n', '        if schema is None:\\n', '            k: self.validator.rules_set_registry.get(v, v)\\n', '            for k, v in schema.items()\\n', '            if isinstance(v, str)\\n', '        if not self.schema_validator(ChainMap(resolved, schema), normalize=False):\\n']",
  "context": "ema=None):\n        if schema is None:\n            schema = self.schema\n        _hash = (schema_hash(schema), schema_hash("
 },
 "37": {
  "name": "_hash",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/schema.py",
  "lineno": "259",
  "column": "8",
  "slicing": "['    types_mapping = UnconcernedValidator.types_mapping.copy()\\n', '    types_mapping.update(\\n', '            validator = self._get_child_validator(\\n', '            if not validator(value, normalize=False):\\n', '                self._error(validator._errors)\\n', '            if not all(isinstance(x, Hashable) for x in value):\\n', '                path = self.document_path + (field,)\\n', \"                self._error(path, 'All dependencies must be a hashable type.')\\n\", '            field, {i: rules_set for i, rules_set in enumerate(value)}\\n', '            definition = self.target_validator.rules_set_registry.get(value)\\n', '            if definition is None:\\n', '                value = definition\\n', '        _hash = (\\n', \"            schema_hash({'turing': value}),\\n\", '        if _hash in self.target_validator._valid_schemas:\\n', '        validator = self._get_child_validator(\\n', '        validator(value, normalize=False)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', '            self.target_validator._valid_schemas.add(_hash)\\n', '        if isinstance(value, str):\\n', '            if value in self.known_schema_refs:\\n', '            self.known_schema_refs.add(value)\\n', '            definition = self.target_validator.schema_registry.get(value)\\n', '            if definition is None:\\n', '                path = self.document_path + (field,)\\n', '                self._error(path, \"Schema definition \\'{}\\' not found.\".format(value))\\n', '            definition = value\\n', '        _hash = (\\n', '            schema_hash(definition),\\n', '        if _hash in self.target_validator._valid_schemas:\\n', '        validator = self._get_child_validator(\\n', '        validator(self._expand_rules_set_refs(definition), normalize=False)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', '            self.target_validator._valid_schemas.add(_hash)\\n', '        if value not in self.target_validator.types_mapping:\\n', \"            self._error(field, 'Unsupported type name: {}'.format(value))\\n\", '        result = {}\\n', '        for k, v in schema.items():\\n', '            if isinstance(v, str):\\n', '                result[k] = self.target_validator.rules_set_registry.get(v)\\n', '                result[k] = v\\n', '        return result\\n', '        if not isinstance(value, Sequence):\\n', '        validator = self._get_child_validator(\\n', '        for constraints in value:\\n', '            _hash = (\\n', \"                schema_hash({'turing': constraints}),\\n\", '            if _hash in self.target_validator._valid_schemas:\\n', '            validator(constraints, normalize=False)\\n', '            if validator._errors:\\n', '                self._error(validator._errors)\\n', '                self.target_validator._valid_schemas.add(_hash)\\n', '        if not isinstance(validator, UnconcernedValidator):\\n', '        self.validator = validator\\n', '            target_validator=validator,\\n', '            schema = validator.schema_registry.get(schema, schema)\\n', '        if not isinstance(schema, abc.Mapping):\\n', '            raise SchemaError(errors.SCHEMA_TYPE.format(schema))\\n', '            schema = normalize_schema(schema)\\n', '        self.validate(schema)\\n', '        self._repr = (\"{}\", schema)\\n', '        self.schema = schema\\n', '        value = normalize_rulesset(value)\\n', '        self.validate({key: value})\\n', '        self.schema[key] = value\\n', '        if not isinstance(schema, abc.Mapping):\\n', '        new_schema = ChainMap(schema, self.schema)\\n', '        self.validate(new_schema)\\n', '        self.schema = new_schema\\n', '        if schema is None:\\n', '            schema = self.schema\\n', '        _hash = (schema_hash(schema), schema_hash(self.validator.types_mapping))\\n', '        if _hash not in self.validator._valid_schemas:\\n', '            self._validate(schema)\\n', '            self.validator._valid_schemas.add(_hash)\\n', '        if isinstance(schema, str):\\n', '            schema = self.validator.schema_registry.get(schema, schema)\\n', '        if schema is None:\\n', '            k: self.validator.rules_set_registry.get(v, v)\\n', '            for k, v in schema.items()\\n', '            if isinstance(v, str)\\n', '        if not self.schema_validator(ChainMap(resolved, schema), normalize=False):\\n']",
  "context": "is None:\n            schema = self.schema\n        _hash = (schema_hash(schema), schema_hash(self.validator.types_mapping))\n        if _hash not in self.validator._valid_sche"
 },
 "38": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/schema.py",
  "lineno": "264",
  "column": "24",
  "slicing": "['    def _validate(self, schema):\\n']",
  "context": "valid_schemas.add(_hash)\n\n    def _validate(self, schema):\n        \"\"\" Validates a schema that defines rules "
 },
 "39": {
  "name": "resolved",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/schema.py",
  "lineno": "276",
  "column": "8",
  "slicing": "['        resolved = {\\n', '        if not self.schema_validator(ChainMap(resolved, schema), normalize=False):\\n']",
  "context": "raise SchemaError(errors.SCHEMA_MISSING)\n\n        resolved = {\n            k: self.validator.rules_set_registry.g"
 },
 "40": {
  "name": "__all__",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/schema.py",
  "lineno": "286",
  "column": "0",
  "slicing": "['    types_mapping = UnconcernedValidator.types_mapping.copy()\\n', '    types_mapping.update(\\n', '            validator = self._get_child_validator(\\n', '            if not validator(value, normalize=False):\\n', '                self._error(validator._errors)\\n', '            if not all(isinstance(x, Hashable) for x in value):\\n', '                path = self.document_path + (field,)\\n', \"                self._error(path, 'All dependencies must be a hashable type.')\\n\", '            field, {i: rules_set for i, rules_set in enumerate(value)}\\n', '            definition = self.target_validator.rules_set_registry.get(value)\\n', '            if definition is None:\\n', '                value = definition\\n', '        _hash = (\\n', \"            schema_hash({'turing': value}),\\n\", '        if _hash in self.target_validator._valid_schemas:\\n', '        validator = self._get_child_validator(\\n', '        validator(value, normalize=False)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', '            self.target_validator._valid_schemas.add(_hash)\\n', '        if isinstance(value, str):\\n', '            if value in self.known_schema_refs:\\n', '            self.known_schema_refs.add(value)\\n', '            definition = self.target_validator.schema_registry.get(value)\\n', '            if definition is None:\\n', '                path = self.document_path + (field,)\\n', '                self._error(path, \"Schema definition \\'{}\\' not found.\".format(value))\\n', '            definition = value\\n', '        _hash = (\\n', '            schema_hash(definition),\\n', '        if _hash in self.target_validator._valid_schemas:\\n', '        validator = self._get_child_validator(\\n', '        validator(self._expand_rules_set_refs(definition), normalize=False)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', '            self.target_validator._valid_schemas.add(_hash)\\n', '        if value not in self.target_validator.types_mapping:\\n', \"            self._error(field, 'Unsupported type name: {}'.format(value))\\n\", '        result = {}\\n', '        for k, v in schema.items():\\n', '            if isinstance(v, str):\\n', '                result[k] = self.target_validator.rules_set_registry.get(v)\\n', '                result[k] = v\\n', '        return result\\n', '        if not isinstance(value, Sequence):\\n', '        validator = self._get_child_validator(\\n', '        for constraints in value:\\n', '            _hash = (\\n', \"                schema_hash({'turing': constraints}),\\n\", '            if _hash in self.target_validator._valid_schemas:\\n', '            validator(constraints, normalize=False)\\n', '            if validator._errors:\\n', '                self._error(validator._errors)\\n', '                self.target_validator._valid_schemas.add(_hash)\\n', '        if not isinstance(validator, UnconcernedValidator):\\n', '        self.validator = validator\\n', '            target_validator=validator,\\n', '            schema = validator.schema_registry.get(schema, schema)\\n', '        if not isinstance(schema, abc.Mapping):\\n', '            raise SchemaError(errors.SCHEMA_TYPE.format(schema))\\n', '            schema = normalize_schema(schema)\\n', '        self.validate(schema)\\n', '        self._repr = (\"{}\", schema)\\n', '        self.schema = schema\\n', '        value = normalize_rulesset(value)\\n', '        self.validate({key: value})\\n', '        self.schema[key] = value\\n', '        if not isinstance(schema, abc.Mapping):\\n', '        new_schema = ChainMap(schema, self.schema)\\n', '        self.validate(new_schema)\\n', '        self.schema = new_schema\\n', '        if schema is None:\\n', '            schema = self.schema\\n', '        _hash = (schema_hash(schema), schema_hash(self.validator.types_mapping))\\n', '        if _hash not in self.validator._valid_schemas:\\n', '            self._validate(schema)\\n', '            self.validator._valid_schemas.add(_hash)\\n', '        if isinstance(schema, str):\\n', '            schema = self.validator.schema_registry.get(schema, schema)\\n', '        if schema is None:\\n', '        resolved = {\\n', '            k: self.validator.rules_set_registry.get(v, v)\\n', '            for k, v in schema.items()\\n', '            if isinstance(v, str)\\n', '        if not self.schema_validator(ChainMap(resolved, schema), normalize=False):\\n', '__all__ = (RulesSetRegistry.__name__, SchemaRegistry.__name__)\\n']",
  "context": "raise SchemaError(self.schema_validator.errors)\n\n\n__all__ = (RulesSetRegistry.__name__, SchemaRegistry.__name__)\n"
 },
 "41": {
  "name": "x",
  "type": "(None,None,None,None,None)",
  "class": "imported",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/utils.py",
  "lineno": "5",
  "column": "21",
  "slicing": "['def compare_paths_lt(x, y):\\n']",
  "context": "le, Mapping, Sequence, Set\n\n\ndef compare_paths_lt(x, y):\n    min_length = min(len(x), len(y))\n\n    if x[:mi"
 },
 "42": {
  "name": "min_length",
  "type": "min",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/utils.py",
  "lineno": "6",
  "column": "4",
  "slicing": "['    min_length = min(len(x), len(y))\\n', '    if x[:min_length] == y[:min_length]:\\n', '        return len(x) == min_length\\n', '    for i in range(min_length):\\n', '        a, b = x[i], y[i]\\n', '            if isinstance(a, _type):\\n', '                if isinstance(b, _type):\\n', '        if a == b:\\n', '        elif a < b:\\n', '    return t[:i] + t[i + 1 :]\\n', '                    value[i] = mapping_to_frozenset(item)\\n']",
  "context": ", Sequence, Set\n\n\ndef compare_paths_lt(x, y):\n    min_length = min(len(x), len(y))\n\n    if x[:min_length] == y[:min_length]:\n        "
 },
 "43": {
  "name": "a",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/utils.py",
  "lineno": "12",
  "column": "8",
  "slicing": "['        a, b = x[i], y[i]\\n', '            if isinstance(a, _type):\\n', '        if a == b:\\n', '        elif a < b:\\n']",
  "context": "n_length\n\n    for i in range(min_length):\n        a, b = x[i], y[i]\n\n        for _type in (int, str, tuple):\n         "
 },
 "44": {
  "name": "b",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/utils.py",
  "lineno": "12",
  "column": "11",
  "slicing": "['        a, b = x[i], y[i]\\n', '                if isinstance(b, _type):\\n', '        if a == b:\\n', '        elif a < b:\\n']",
  "context": "ength\n\n    for i in range(min_length):\n        a, b = x[i], y[i]\n\n        for _type in (int, str, tuple):\n         "
 },
 "45": {
  "name": "i",
  "type": "int",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/utils.py",
  "lineno": "31",
  "column": "28",
  "slicing": "['def drop_item_from_tuple(t, i):\\n']",
  "context": " raise RuntimeError\n\n\ndef drop_item_from_tuple(t, i):\n    return t[:i] + t[i + 1 :]\n\n\ndef mapping_to_fro"
 },
 "46": {
  "name": "schema",
  "type": "typing.Mapping",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/utils.py",
  "lineno": "35",
  "column": "25",
  "slicing": "['def mapping_to_frozenset(schema: Mapping) -> frozenset:\\n', '    return hash(mapping_to_frozenset(schema))\\n']",
  "context": "urn t[:i] + t[i + 1 :]\n\n\ndef mapping_to_frozenset(schema: Mapping) -> frozenset:\n    \"\"\" Be aware that this treats any sequence typ"
 },
 "47": {
  "name": "schema_copy",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/utils.py",
  "lineno": "40",
  "column": "4",
  "slicing": "['    schema_copy = {}  # type: Dict[Hashable, Hashable]\\n', '            schema_copy[key] = mapping_to_frozenset(value)\\n', '            schema_copy[key] = tuple(value)\\n', '            schema_copy[key] = frozenset(value)\\n', '            schema_copy[key] = value\\n', '    return frozenset(schema_copy.items())\\n']",
  "context": "al regardless the\n        container type. \"\"\"\n    schema_copy = {}  # type: Dict[Hashable, Hashable]\n    for key, value in schema.items():\n        if i"
 },
 "48": {
  "name": "value",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/utils.py",
  "lineno": "45",
  "column": "12",
  "slicing": "['    min_length = min(len(x), len(y))\\n', '    if x[:min_length] == y[:min_length]:\\n', '        return len(x) == min_length\\n', '    for i in range(min_length):\\n', '        a, b = x[i], y[i]\\n', '        for _type in (int, str, tuple):\\n', '            if isinstance(a, _type):\\n', '                if isinstance(b, _type):\\n', '        if a == b:\\n', '        elif a < b:\\n', '    return t[:i] + t[i + 1 :]\\n', '    schema_copy = {}  # type: Dict[Hashable, Hashable]\\n', '    for key, value in schema.items():\\n', '        if isinstance(value, abc.Mapping):\\n', '            schema_copy[key] = mapping_to_frozenset(value)\\n', '        elif isinstance(value, Sequence):\\n', '            value = list(value)\\n', '            for i, item in enumerate(value):\\n', '                if isinstance(item, abc.Mapping):\\n', '                    value[i] = mapping_to_frozenset(item)\\n', '            schema_copy[key] = tuple(value)\\n', '        elif isinstance(value, Set):\\n', '            schema_copy[key] = frozenset(value)\\n', '        elif isinstance(value, Hashable):\\n', '            schema_copy[key] = value\\n', '    return frozenset(schema_copy.items())\\n', '    if isinstance(value, str):\\n', '        return \\'\"%s\"\\' % value\\n', '        return value\\n']",
  "context": "    elif isinstance(value, Sequence):\n            value = list(value)\n            for i, item in enumerate(value):\n     "
 },
 "49": {
  "name": "schema",
  "type": "typing.Mapping",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/utils.py",
  "lineno": "78",
  "column": "16",
  "slicing": "['def schema_hash(schema: Mapping) -> int:\\n']",
  "context": "is a readonly class property.')\n\n\ndef schema_hash(schema: Mapping) -> int:\n    return hash(mapping_to_frozenset(schema))\n"
 },
 "50": {
  "name": "FieldName",
  "type": "typing.Hashable",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/typing.py",
  "lineno": "19",
  "column": "0",
  "slicing": "['FieldName = Hashable\\n', 'Document = Mapping[FieldName, Any]\\n', 'DocumentPath = Tuple[FieldName, ...]\\n', 'RulesSet = Mapping[str, Any]\\n', 'SchemaDict = Mapping[FieldName, RulesSet]\\n', \"Schema = Union['ValidatedSchema', SchemaDict]\\n\", 'AllowUnknown = Union[bool, RulesSet]\\n', \"RegistryItem = TypeVar('RegistryItem', RulesSet, Schema)\\n\", 'RegistryItems = Union[Mapping[str, RegistryItem]]\\n']",
  "context": "rus.schema import ValidatedSchema  # noqa: F401\n\n\nFieldName = Hashable\nDocument = Mapping[FieldName, Any]\nDocumentPath = "
 },
 "51": {
  "name": "Document",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/typing.py",
  "lineno": "20",
  "column": "0",
  "slicing": "['FieldName = Hashable\\n', 'Document = Mapping[FieldName, Any]\\n', 'DocumentPath = Tuple[FieldName, ...]\\n', 'RulesSet = Mapping[str, Any]\\n', 'SchemaDict = Mapping[FieldName, RulesSet]\\n', \"Schema = Union['ValidatedSchema', SchemaDict]\\n\", 'AllowUnknown = Union[bool, RulesSet]\\n', \"RegistryItem = TypeVar('RegistryItem', RulesSet, Schema)\\n\", 'RegistryItems = Union[Mapping[str, RegistryItem]]\\n']",
  "context": "idatedSchema  # noqa: F401\n\n\nFieldName = Hashable\nDocument = Mapping[FieldName, Any]\nDocumentPath = Tuple[FieldName, ...]\nErrorHandlerC"
 },
 "52": {
  "name": "DocumentPath",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/typing.py",
  "lineno": "21",
  "column": "0",
  "slicing": "['FieldName = Hashable\\n', 'Document = Mapping[FieldName, Any]\\n', 'DocumentPath = Tuple[FieldName, ...]\\n', 'RulesSet = Mapping[str, Any]\\n', 'SchemaDict = Mapping[FieldName, RulesSet]\\n', \"Schema = Union['ValidatedSchema', SchemaDict]\\n\", 'AllowUnknown = Union[bool, RulesSet]\\n', \"RegistryItem = TypeVar('RegistryItem', RulesSet, Schema)\\n\", 'RegistryItems = Union[Mapping[str, RegistryItem]]\\n']",
  "context": "ame = Hashable\nDocument = Mapping[FieldName, Any]\nDocumentPath = Tuple[FieldName, ...]\nErrorHandlerConfig = Union[\n    'BaseErrorHandler'"
 },
 "53": {
  "name": "ErrorHandlerConfig",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/typing.py",
  "lineno": "22",
  "column": "0",
  "slicing": "['FieldName = Hashable\\n', 'Document = Mapping[FieldName, Any]\\n', 'DocumentPath = Tuple[FieldName, ...]\\n', 'ErrorHandlerConfig = Union[\\n', 'RulesSet = Mapping[str, Any]\\n', 'SchemaDict = Mapping[FieldName, RulesSet]\\n', \"Schema = Union['ValidatedSchema', SchemaDict]\\n\", 'AllowUnknown = Union[bool, RulesSet]\\n', \"RegistryItem = TypeVar('RegistryItem', RulesSet, Schema)\\n\", 'RegistryItems = Union[Mapping[str, RegistryItem]]\\n']",
  "context": "ldName, Any]\nDocumentPath = Tuple[FieldName, ...]\nErrorHandlerConfig = Union[\n    'BaseErrorHandler',\n    Type['BaseErrorHandler"
 },
 "54": {
  "name": "NoneType",
  "type": "type",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/typing.py",
  "lineno": "27",
  "column": "0",
  "slicing": "['FieldName = Hashable\\n', 'Document = Mapping[FieldName, Any]\\n', 'DocumentPath = Tuple[FieldName, ...]\\n', 'NoneType = type(None)\\n', 'RulesSet = Mapping[str, Any]\\n', 'SchemaDict = Mapping[FieldName, RulesSet]\\n', \"Schema = Union['ValidatedSchema', SchemaDict]\\n\", 'AllowUnknown = Union[bool, RulesSet]\\n', \"RegistryItem = TypeVar('RegistryItem', RulesSet, Schema)\\n\", 'RegistryItems = Union[Mapping[str, RegistryItem]]\\n']",
  "context": "e[Type['BaseErrorHandler'], Mapping[str, Any]],\n]\nNoneType = type(None)\nRulesSet = Mapping[str, Any]\nSchemaDict = Mapping["
 },
 "55": {
  "name": "RulesSet",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/typing.py",
  "lineno": "28",
  "column": "0",
  "slicing": "['FieldName = Hashable\\n', 'Document = Mapping[FieldName, Any]\\n', 'DocumentPath = Tuple[FieldName, ...]\\n', 'RulesSet = Mapping[str, Any]\\n', 'SchemaDict = Mapping[FieldName, RulesSet]\\n', \"Schema = Union['ValidatedSchema', SchemaDict]\\n\", 'AllowUnknown = Union[bool, RulesSet]\\n', \"RegistryItem = TypeVar('RegistryItem', RulesSet, Schema)\\n\", 'RegistryItems = Union[Mapping[str, RegistryItem]]\\n']",
  "context": "er'], Mapping[str, Any]],\n]\nNoneType = type(None)\nRulesSet = Mapping[str, Any]\nSchemaDict = Mapping[FieldName, RulesSet]\nSchema ="
 },
 "56": {
  "name": "SchemaDict",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/typing.py",
  "lineno": "29",
  "column": "0",
  "slicing": "['FieldName = Hashable\\n', 'Document = Mapping[FieldName, Any]\\n', 'DocumentPath = Tuple[FieldName, ...]\\n', 'RulesSet = Mapping[str, Any]\\n', 'SchemaDict = Mapping[FieldName, RulesSet]\\n', \"Schema = Union['ValidatedSchema', SchemaDict]\\n\", 'AllowUnknown = Union[bool, RulesSet]\\n', \"RegistryItem = TypeVar('RegistryItem', RulesSet, Schema)\\n\", 'RegistryItems = Union[Mapping[str, RegistryItem]]\\n']",
  "context": "oneType = type(None)\nRulesSet = Mapping[str, Any]\nSchemaDict = Mapping[FieldName, RulesSet]\nSchema = Union['ValidatedSchema', SchemaDict]\nAllo"
 },
 "57": {
  "name": "Schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/typing.py",
  "lineno": "30",
  "column": "0",
  "slicing": "['FieldName = Hashable\\n', 'Document = Mapping[FieldName, Any]\\n', 'DocumentPath = Tuple[FieldName, ...]\\n', 'RulesSet = Mapping[str, Any]\\n', 'SchemaDict = Mapping[FieldName, RulesSet]\\n', \"Schema = Union['ValidatedSchema', SchemaDict]\\n\", 'AllowUnknown = Union[bool, RulesSet]\\n', \"RegistryItem = TypeVar('RegistryItem', RulesSet, Schema)\\n\", 'RegistryItems = Union[Mapping[str, RegistryItem]]\\n']",
  "context": "r, Any]\nSchemaDict = Mapping[FieldName, RulesSet]\nSchema = Union['ValidatedSchema', SchemaDict]\nAllowUnknown = Union[bool, RulesSet]\nRegistryItem "
 },
 "58": {
  "name": "AllowUnknown",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/typing.py",
  "lineno": "31",
  "column": "0",
  "slicing": "['FieldName = Hashable\\n', 'Document = Mapping[FieldName, Any]\\n', 'DocumentPath = Tuple[FieldName, ...]\\n', 'RulesSet = Mapping[str, Any]\\n', 'SchemaDict = Mapping[FieldName, RulesSet]\\n', \"Schema = Union['ValidatedSchema', SchemaDict]\\n\", 'AllowUnknown = Union[bool, RulesSet]\\n', \"RegistryItem = TypeVar('RegistryItem', RulesSet, Schema)\\n\", 'RegistryItems = Union[Mapping[str, RegistryItem]]\\n']",
  "context": "et]\nSchema = Union['ValidatedSchema', SchemaDict]\nAllowUnknown = Union[bool, RulesSet]\nRegistryItem = TypeVar('RegistryItem', RulesSet, S"
 },
 "59": {
  "name": "RegistryItem",
  "type": "typing.TypeVar",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/typing.py",
  "lineno": "32",
  "column": "0",
  "slicing": "['FieldName = Hashable\\n', 'Document = Mapping[FieldName, Any]\\n', 'DocumentPath = Tuple[FieldName, ...]\\n', 'RulesSet = Mapping[str, Any]\\n', 'SchemaDict = Mapping[FieldName, RulesSet]\\n', \"Schema = Union['ValidatedSchema', SchemaDict]\\n\", 'AllowUnknown = Union[bool, RulesSet]\\n', \"RegistryItem = TypeVar('RegistryItem', RulesSet, Schema)\\n\", 'RegistryItems = Union[Mapping[str, RegistryItem]]\\n']",
  "context": " SchemaDict]\nAllowUnknown = Union[bool, RulesSet]\nRegistryItem = TypeVar('RegistryItem', RulesSet, Schema)\nRegistryItems = Union[Mapping[str, RegistryItem]]\n"
 },
 "60": {
  "name": "RegistryItems",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/typing.py",
  "lineno": "33",
  "column": "0",
  "slicing": "['FieldName = Hashable\\n', 'Document = Mapping[FieldName, Any]\\n', 'DocumentPath = Tuple[FieldName, ...]\\n', 'RulesSet = Mapping[str, Any]\\n', 'SchemaDict = Mapping[FieldName, RulesSet]\\n', \"Schema = Union['ValidatedSchema', SchemaDict]\\n\", 'AllowUnknown = Union[bool, RulesSet]\\n', \"RegistryItem = TypeVar('RegistryItem', RulesSet, Schema)\\n\", 'RegistryItems = Union[Mapping[str, RegistryItem]]\\n']",
  "context": "yItem = TypeVar('RegistryItem', RulesSet, Schema)\nRegistryItems = Union[Mapping[str, RegistryItem]]\nTypesMapping = Dict[str, \"TypeDefinition\"]\n"
 },
 "61": {
  "name": "TypesMapping",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/typing.py",
  "lineno": "34",
  "column": "0",
  "slicing": "['FieldName = Hashable\\n', 'Document = Mapping[FieldName, Any]\\n', 'DocumentPath = Tuple[FieldName, ...]\\n', 'RulesSet = Mapping[str, Any]\\n', 'SchemaDict = Mapping[FieldName, RulesSet]\\n', \"Schema = Union['ValidatedSchema', SchemaDict]\\n\", 'AllowUnknown = Union[bool, RulesSet]\\n', \"RegistryItem = TypeVar('RegistryItem', RulesSet, Schema)\\n\", 'RegistryItems = Union[Mapping[str, RegistryItem]]\\n', 'TypesMapping = Dict[str, \"TypeDefinition\"]\\n']",
  "context": "RegistryItems = Union[Mapping[str, RegistryItem]]\nTypesMapping = Dict[str, \"TypeDefinition\"]\n"
 },
 "62": {
  "name": "name",
  "type": "str",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/__init__.py",
  "lineno": "32",
  "column": "4",
  "slicing": "['    name: str,\\n']",
  "context": "ersion__ = \"unknown\"\n\n\ndef validator_factory(\n    name: str,\n    bases: Union[type, Tuple[type], None] = None,\n"
 },
 "63": {
  "name": "bases",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/__init__.py",
  "lineno": "33",
  "column": "4",
  "slicing": "['    bases: Union[type, Tuple[type], None] = None,\\n']",
  "context": "nown\"\n\n\ndef validator_factory(\n    name: str,\n    bases: Union[type, Tuple[type], None] = None,\n    namespace: Optional[Dict] = None,\n    validate"
 },
 "64": {
  "name": "namespace",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/__init__.py",
  "lineno": "34",
  "column": "4",
  "slicing": "['    namespace: Optional[Dict] = None,\\n']",
  "context": "bases: Union[type, Tuple[type], None] = None,\n    namespace: Optional[Dict] = None,\n    validated_schema: bool = True,\n) -> type:\n    "
 },
 "65": {
  "name": "validated_schema",
  "type": "bool",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/__init__.py",
  "lineno": "35",
  "column": "4",
  "slicing": "['    validated_schema: bool = True,\\n']",
  "context": "= None,\n    namespace: Optional[Dict] = None,\n    validated_schema: bool = True,\n) -> type:\n    \"\"\" Dynamically create a :class:`~c"
 },
 "66": {
  "name": "namespace",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/__init__.py",
  "lineno": "52",
  "column": "8",
  "slicing": "['        namespace = {}\\n', \"    if len(docstrings) > 1 and '__doc__' not in namespace:\\n\", \"        namespace.update({'__doc__': '\\\\n'.join(docstrings)})\\n\", '    return type(name, computed_bases, namespace)\\n']",
  "context": "ernedValidator\n\n    if namespace is None:\n        namespace = {}\n\n    if bases is None:\n        computed_bases = (v"
 },
 "67": {
  "name": "computed_bases",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/__init__.py",
  "lineno": "55",
  "column": "8",
  "slicing": "['    validator_class = Validator if validated_schema else UnconcernedValidator\\n', '        namespace = {}\\n', '        computed_bases = (validator_class,)\\n', '    elif isinstance(bases, tuple) and validator_class not in bases:\\n', '        computed_bases = bases + (validator_class,)  # type: ignore\\n', '        computed_bases = (bases, validator_class)  # type: ignore\\n', '    docstrings = [x.__doc__ for x in computed_bases if x.__doc__]\\n', \"    if len(docstrings) > 1 and '__doc__' not in namespace:\\n\", \"        namespace.update({'__doc__': '\\\\n'.join(docstrings)})\\n\", '    return type(name, computed_bases, namespace)\\n']",
  "context": "    namespace = {}\n\n    if bases is None:\n        computed_bases = (validator_class,)\n    elif isinstance(bases, tuple) and validator_cl"
 },
 "68": {
  "name": "docstrings",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/__init__.py",
  "lineno": "61",
  "column": "4",
  "slicing": "['    validator_class = Validator if validated_schema else UnconcernedValidator\\n', '        namespace = {}\\n', '        computed_bases = (validator_class,)\\n', '    elif isinstance(bases, tuple) and validator_class not in bases:\\n', '        computed_bases = bases + (validator_class,)  # type: ignore\\n', '        computed_bases = (bases, validator_class)  # type: ignore\\n', '    docstrings = [x.__doc__ for x in computed_bases if x.__doc__]\\n', \"    if len(docstrings) > 1 and '__doc__' not in namespace:\\n\", \"        namespace.update({'__doc__': '\\\\n'.join(docstrings)})\\n\", '    return type(name, computed_bases, namespace)\\n']",
  "context": "s = (bases, validator_class)  # type: ignore\n\n    docstrings = [x.__doc__ for x in computed_bases if x.__doc__]\n    if len(docstrings) > 1 and '__doc__' not in na"
 },
 "69": {
  "name": "computed_bases",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/__init__.py",
  "lineno": "59",
  "column": "8",
  "slicing": "['    validator_class = Validator if validated_schema else UnconcernedValidator\\n', '        namespace = {}\\n', '        computed_bases = (validator_class,)\\n', '    elif isinstance(bases, tuple) and validator_class not in bases:\\n', '        computed_bases = bases + (validator_class,)  # type: ignore\\n', '        computed_bases = (bases, validator_class)  # type: ignore\\n', '    docstrings = [x.__doc__ for x in computed_bases if x.__doc__]\\n', \"    if len(docstrings) > 1 and '__doc__' not in namespace:\\n\", \"        namespace.update({'__doc__': '\\\\n'.join(docstrings)})\\n\", '    return type(name, computed_bases, namespace)\\n']",
  "context": "lidator_class,)  # type: ignore\n    else:\n        computed_bases = (bases, validator_class)  # type: ignore\n\n    docstrings = [x.__doc__ for x in computed_bas"
 },
 "70": {
  "name": "__all__",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/__init__.py",
  "lineno": "68",
  "column": "0",
  "slicing": "['__all__ = [\\n']",
  "context": "   return type(name, computed_bases, namespace)\n\n\n__all__ = [\n    DocumentError.__name__,\n    SchemaError.__name"
 },
 "71": {
  "name": "__slots__",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "36",
  "column": "4",
  "slicing": "[\"    __slots__ = ('code', 'rule')\\n\"]",
  "context": "e namespace, e.g. ``errors.CUSTOM``.\n    \"\"\"\n\n    __slots__ = ('code', 'rule')\n\n    def __init__(self, code: int, rule: Optional["
 },
 "72": {
  "name": "code",
  "type": "int",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "38",
  "column": "23",
  "slicing": "['    def __init__(self, code: int, rule: Optional[str]) -> None:\\n']",
  "context": "lots__ = ('code', 'rule')\n\n    def __init__(self, code: int, rule: Optional[str]) -> None:\n        self.code = code\n        self.rule = rule\n"
 },
 "73": {
  "name": "rule",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "38",
  "column": "34",
  "slicing": "['    def __init__(self, code: int, rule: Optional[str]) -> None:\\n']",
  "context": "code', 'rule')\n\n    def __init__(self, code: int, rule: Optional[str]) -> None:\n        self.code = code\n        self.rule = rule\n"
 },
 "74": {
  "name": "CUSTOM",
  "type": "ErrorDefinition",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "44",
  "column": "0",
  "slicing": "['CUSTOM = ErrorDefinition(0x00, None)\\n']",
  "context": "f.code = code\n        self.rule = rule\n\n\n# custom\nCUSTOM = ErrorDefinition(0x00, None)\n\n# existence\nDOCUMENT_MISSING = ErrorDefinition(0x"
 },
 "75": {
  "name": "DOCUMENT_MISSING",
  "type": "ErrorDefinition",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "47",
  "column": "0",
  "slicing": "['DOCUMENT_MISSING = ErrorDefinition(0x01, None)  # issues/141\\n']",
  "context": "CUSTOM = ErrorDefinition(0x00, None)\n\n# existence\nDOCUMENT_MISSING = ErrorDefinition(0x01, None)  # issues/141\nDOCUMENT_MISSING = \"document is missing\"  # type: "
 },
 "76": {
  "name": "REQUIRED_FIELD",
  "type": "ErrorDefinition",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "49",
  "column": "0",
  "slicing": "[\"REQUIRED_FIELD = ErrorDefinition(0x02, 'required')\\n\"]",
  "context": "T_MISSING = \"document is missing\"  # type: ignore\nREQUIRED_FIELD = ErrorDefinition(0x02, 'required')\nUNKNOWN_FIELD = ErrorDefinition(0x03, None)\nDEPEND"
 },
 "77": {
  "name": "UNKNOWN_FIELD",
  "type": "ErrorDefinition",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "50",
  "column": "0",
  "slicing": "['UNKNOWN_FIELD = ErrorDefinition(0x03, None)\\n']",
  "context": "EQUIRED_FIELD = ErrorDefinition(0x02, 'required')\nUNKNOWN_FIELD = ErrorDefinition(0x03, None)\nDEPENDENCIES_FIELD = ErrorDefinition(0x04, 'depend"
 },
 "78": {
  "name": "DEPENDENCIES_FIELD",
  "type": "ErrorDefinition",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "51",
  "column": "0",
  "slicing": "[\"DEPENDENCIES_FIELD = ErrorDefinition(0x04, 'dependencies')\\n\"]",
  "context": "red')\nUNKNOWN_FIELD = ErrorDefinition(0x03, None)\nDEPENDENCIES_FIELD = ErrorDefinition(0x04, 'dependencies')\nDEPENDENCIES_FIELD_VALUE = ErrorDefinition(0x05, '"
 },
 "79": {
  "name": "DEPENDENCIES_FIELD_VALUE",
  "type": "ErrorDefinition",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "52",
  "column": "0",
  "slicing": "[\"DEPENDENCIES_FIELD_VALUE = ErrorDefinition(0x05, 'dependencies')\\n\"]",
  "context": "IES_FIELD = ErrorDefinition(0x04, 'dependencies')\nDEPENDENCIES_FIELD_VALUE = ErrorDefinition(0x05, 'dependencies')\nEXCLUDES_FIELD = ErrorDefinition(0x06, 'excludes')"
 },
 "80": {
  "name": "EXCLUDES_FIELD",
  "type": "ErrorDefinition",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "53",
  "column": "0",
  "slicing": "[\"EXCLUDES_FIELD = ErrorDefinition(0x06, 'excludes')\\n\"]",
  "context": "ELD_VALUE = ErrorDefinition(0x05, 'dependencies')\nEXCLUDES_FIELD = ErrorDefinition(0x06, 'excludes')\n\n# shape\nDOCUMENT_FORMAT = ErrorDefinition(0x21, N"
 },
 "81": {
  "name": "DOCUMENT_FORMAT",
  "type": "ErrorDefinition",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "56",
  "column": "0",
  "slicing": "['DOCUMENT_FORMAT = ErrorDefinition(0x21, None)  # issues/141\\n']",
  "context": "IELD = ErrorDefinition(0x06, 'excludes')\n\n# shape\nDOCUMENT_FORMAT = ErrorDefinition(0x21, None)  # issues/141\nDOCUMENT_FORMAT = \"'{0}' is not a document, must b"
 },
 "82": {
  "name": "EMPTY",
  "type": "ErrorDefinition",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "58",
  "column": "0",
  "slicing": "[\"EMPTY = ErrorDefinition(0x22, 'empty')\\n\"]",
  "context": "s not a document, must be a dict\"  # type: ignore\nEMPTY = ErrorDefinition(0x22, 'empty')\nNULLABLE = ErrorDefinition(0x23, 'nullable')\nTYPE "
 },
 "83": {
  "name": "NULLABLE",
  "type": "ErrorDefinition",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "59",
  "column": "0",
  "slicing": "[\"NULLABLE = ErrorDefinition(0x23, 'nullable')\\n\"]",
  "context": "pe: ignore\nEMPTY = ErrorDefinition(0x22, 'empty')\nNULLABLE = ErrorDefinition(0x23, 'nullable')\nTYPE = ErrorDefinition(0x24, 'type')\nITEMS_LENGTH "
 },
 "84": {
  "name": "TYPE",
  "type": "ErrorDefinition",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "60",
  "column": "0",
  "slicing": "[\"TYPE = ErrorDefinition(0x24, 'type')\\n\"]",
  "context": "ty')\nNULLABLE = ErrorDefinition(0x23, 'nullable')\nTYPE = ErrorDefinition(0x24, 'type')\nITEMS_LENGTH = ErrorDefinition(0x26, 'items')\nMIN_"
 },
 "85": {
  "name": "ITEMS_LENGTH",
  "type": "ErrorDefinition",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "61",
  "column": "0",
  "slicing": "[\"ITEMS_LENGTH = ErrorDefinition(0x26, 'items')\\n\"]",
  "context": " 'nullable')\nTYPE = ErrorDefinition(0x24, 'type')\nITEMS_LENGTH = ErrorDefinition(0x26, 'items')\nMIN_LENGTH = ErrorDefinition(0x27, 'minlength')\nMA"
 },
 "86": {
  "name": "MIN_LENGTH",
  "type": "ErrorDefinition",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "62",
  "column": "0",
  "slicing": "[\"MIN_LENGTH = ErrorDefinition(0x27, 'minlength')\\n\"]",
  "context": "e')\nITEMS_LENGTH = ErrorDefinition(0x26, 'items')\nMIN_LENGTH = ErrorDefinition(0x27, 'minlength')\nMAX_LENGTH = ErrorDefinition(0x28, 'maxlength')\n\n#"
 },
 "87": {
  "name": "MAX_LENGTH",
  "type": "ErrorDefinition",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "63",
  "column": "0",
  "slicing": "[\"MAX_LENGTH = ErrorDefinition(0x28, 'maxlength')\\n\"]",
  "context": ")\nMIN_LENGTH = ErrorDefinition(0x27, 'minlength')\nMAX_LENGTH = ErrorDefinition(0x28, 'maxlength')\n\n# color\nREGEX_MISMATCH = ErrorDefinition(0x41, 'r"
 },
 "88": {
  "name": "REGEX_MISMATCH",
  "type": "ErrorDefinition",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "66",
  "column": "0",
  "slicing": "[\"REGEX_MISMATCH = ErrorDefinition(0x41, 'regex')\\n\"]",
  "context": "GTH = ErrorDefinition(0x28, 'maxlength')\n\n# color\nREGEX_MISMATCH = ErrorDefinition(0x41, 'regex')\nMIN_VALUE = ErrorDefinition(0x42, 'min')\nMAX_VALUE"
 },
 "89": {
  "name": "MIN_VALUE",
  "type": "ErrorDefinition",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "67",
  "column": "0",
  "slicing": "[\"MIN_VALUE = ErrorDefinition(0x42, 'min')\\n\"]",
  "context": "r\nREGEX_MISMATCH = ErrorDefinition(0x41, 'regex')\nMIN_VALUE = ErrorDefinition(0x42, 'min')\nMAX_VALUE = ErrorDefinition(0x43, 'max')\nUNALLOWED"
 },
 "90": {
  "name": "MAX_VALUE",
  "type": "ErrorDefinition",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "68",
  "column": "0",
  "slicing": "[\"MAX_VALUE = ErrorDefinition(0x43, 'max')\\n\"]",
  "context": "'regex')\nMIN_VALUE = ErrorDefinition(0x42, 'min')\nMAX_VALUE = ErrorDefinition(0x43, 'max')\nUNALLOWED_VALUE = ErrorDefinition(0x44, 'allowed')"
 },
 "91": {
  "name": "UNALLOWED_VALUE",
  "type": "ErrorDefinition",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "69",
  "column": "0",
  "slicing": "[\"UNALLOWED_VALUE = ErrorDefinition(0x44, 'allowed')\\n\"]",
  "context": ", 'min')\nMAX_VALUE = ErrorDefinition(0x43, 'max')\nUNALLOWED_VALUE = ErrorDefinition(0x44, 'allowed')\nUNALLOWED_VALUES = ErrorDefinition(0x45, 'allowed'"
 },
 "92": {
  "name": "UNALLOWED_VALUES",
  "type": "ErrorDefinition",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "70",
  "column": "0",
  "slicing": "[\"UNALLOWED_VALUES = ErrorDefinition(0x45, 'allowed')\\n\"]",
  "context": "NALLOWED_VALUE = ErrorDefinition(0x44, 'allowed')\nUNALLOWED_VALUES = ErrorDefinition(0x45, 'allowed')\nFORBIDDEN_VALUE = ErrorDefinition(0x46, 'forbidden"
 },
 "93": {
  "name": "FORBIDDEN_VALUE",
  "type": "ErrorDefinition",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "71",
  "column": "0",
  "slicing": "[\"FORBIDDEN_VALUE = ErrorDefinition(0x46, 'forbidden')\\n\"]",
  "context": "ALLOWED_VALUES = ErrorDefinition(0x45, 'allowed')\nFORBIDDEN_VALUE = ErrorDefinition(0x46, 'forbidden')\nFORBIDDEN_VALUES = ErrorDefinition(0x47, 'forbidde"
 },
 "94": {
  "name": "FORBIDDEN_VALUES",
  "type": "ErrorDefinition",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "72",
  "column": "0",
  "slicing": "[\"FORBIDDEN_VALUES = ErrorDefinition(0x47, 'forbidden')\\n\"]",
  "context": "BIDDEN_VALUE = ErrorDefinition(0x46, 'forbidden')\nFORBIDDEN_VALUES = ErrorDefinition(0x47, 'forbidden')\nMISSING_MEMBERS = ErrorDefinition(0x48, 'contains'"
 },
 "95": {
  "name": "MISSING_MEMBERS",
  "type": "ErrorDefinition",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "73",
  "column": "0",
  "slicing": "[\"MISSING_MEMBERS = ErrorDefinition(0x48, 'contains')\\n\"]",
  "context": "IDDEN_VALUES = ErrorDefinition(0x47, 'forbidden')\nMISSING_MEMBERS = ErrorDefinition(0x48, 'contains')\n\n# other\nNORMALIZATION = ErrorDefinition(0x60, Non"
 },
 "96": {
  "name": "NORMALIZATION",
  "type": "ErrorDefinition",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "76",
  "column": "0",
  "slicing": "['NORMALIZATION = ErrorDefinition(0x60, None)\\n', '        return bool(self.code & NORMALIZATION.code)\\n']",
  "context": "BERS = ErrorDefinition(0x48, 'contains')\n\n# other\nNORMALIZATION = ErrorDefinition(0x60, None)\nCOERCION_FAILED = ErrorDefinition(0x61, 'coerce')\n"
 },
 "97": {
  "name": "COERCION_FAILED",
  "type": "ErrorDefinition",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "77",
  "column": "0",
  "slicing": "[\"COERCION_FAILED = ErrorDefinition(0x61, 'coerce')\\n\"]",
  "context": "other\nNORMALIZATION = ErrorDefinition(0x60, None)\nCOERCION_FAILED = ErrorDefinition(0x61, 'coerce')\nRENAMING_FAILED = ErrorDefinition(0x62, 'rename_ha"
 },
 "98": {
  "name": "RENAMING_FAILED",
  "type": "ErrorDefinition",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "78",
  "column": "0",
  "slicing": "[\"RENAMING_FAILED = ErrorDefinition(0x62, 'rename_handler')\\n\"]",
  "context": "COERCION_FAILED = ErrorDefinition(0x61, 'coerce')\nRENAMING_FAILED = ErrorDefinition(0x62, 'rename_handler')\nREADONLY_FIELD = ErrorDefinition(0x63, 'readonly')"
 },
 "99": {
  "name": "READONLY_FIELD",
  "type": "ErrorDefinition",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "79",
  "column": "0",
  "slicing": "[\"READONLY_FIELD = ErrorDefinition(0x63, 'readonly')\\n\"]",
  "context": "_FAILED = ErrorDefinition(0x62, 'rename_handler')\nREADONLY_FIELD = ErrorDefinition(0x63, 'readonly')\nSETTING_DEFAULT_FAILED = ErrorDefinition(0x64, 'de"
 },
 "100": {
  "name": "SETTING_DEFAULT_FAILED",
  "type": "ErrorDefinition",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "80",
  "column": "0",
  "slicing": "[\"SETTING_DEFAULT_FAILED = ErrorDefinition(0x64, 'default_setter')\\n\"]",
  "context": "EADONLY_FIELD = ErrorDefinition(0x63, 'readonly')\nSETTING_DEFAULT_FAILED = ErrorDefinition(0x64, 'default_setter')\n\n# groups\nERROR_GROUP = ErrorDefinition(0x80, None"
 },
 "101": {
  "name": "ERROR_GROUP",
  "type": "ErrorDefinition",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "83",
  "column": "0",
  "slicing": "['ERROR_GROUP = ErrorDefinition(0x80, None)\\n', '        return bool(self.code & ERROR_GROUP.code)\\n', '        return bool(self.code & LOGICAL.code - ERROR_GROUP.code)\\n']",
  "context": "ErrorDefinition(0x64, 'default_setter')\n\n# groups\nERROR_GROUP = ErrorDefinition(0x80, None)\nSCHEMA = ErrorDefinition(0x81, 'schema')\nITEMSRULE"
 },
 "102": {
  "name": "SCHEMA",
  "type": "ErrorDefinition",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "84",
  "column": "0",
  "slicing": "[\"SCHEMA = ErrorDefinition(0x81, 'schema')\\n\"]",
  "context": " groups\nERROR_GROUP = ErrorDefinition(0x80, None)\nSCHEMA = ErrorDefinition(0x81, 'schema')\nITEMSRULES = ErrorDefinition(0x82, 'itemsrules')\nK"
 },
 "103": {
  "name": "ITEMSRULES",
  "type": "ErrorDefinition",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "85",
  "column": "0",
  "slicing": "[\"ITEMSRULES = ErrorDefinition(0x82, 'itemsrules')\\n\"]",
  "context": "0, None)\nSCHEMA = ErrorDefinition(0x81, 'schema')\nITEMSRULES = ErrorDefinition(0x82, 'itemsrules')\nKEYSRULES = ErrorDefinition(0x83, 'keysrules')\nVAL"
 },
 "104": {
  "name": "KEYSRULES",
  "type": "ErrorDefinition",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "86",
  "column": "0",
  "slicing": "[\"KEYSRULES = ErrorDefinition(0x83, 'keysrules')\\n\"]",
  "context": "\nITEMSRULES = ErrorDefinition(0x82, 'itemsrules')\nKEYSRULES = ErrorDefinition(0x83, 'keysrules')\nVALUESRULES = ErrorDefinition(0x84, 'valuesrules')"
 },
 "105": {
  "name": "VALUESRULES",
  "type": "ErrorDefinition",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "87",
  "column": "0",
  "slicing": "[\"VALUESRULES = ErrorDefinition(0x84, 'valuesrules')\\n\"]",
  "context": "')\nKEYSRULES = ErrorDefinition(0x83, 'keysrules')\nVALUESRULES = ErrorDefinition(0x84, 'valuesrules')\nITEMS = ErrorDefinition(0x8F, 'items')\n\nLOGICAL = "
 },
 "106": {
  "name": "ITEMS",
  "type": "ErrorDefinition",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "88",
  "column": "0",
  "slicing": "[\"ITEMS = ErrorDefinition(0x8F, 'items')\\n\"]",
  "context": "ALUESRULES = ErrorDefinition(0x84, 'valuesrules')\nITEMS = ErrorDefinition(0x8F, 'items')\n\nLOGICAL = ErrorDefinition(0x90, None)\nNONEOF = Er"
 },
 "107": {
  "name": "LOGICAL",
  "type": "ErrorDefinition",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "90",
  "column": "0",
  "slicing": "['LOGICAL = ErrorDefinition(0x90, None)\\n', '        return bool(self.code & LOGICAL.code - ERROR_GROUP.code)\\n']",
  "context": "esrules')\nITEMS = ErrorDefinition(0x8F, 'items')\n\nLOGICAL = ErrorDefinition(0x90, None)\nNONEOF = ErrorDefinition(0x91, 'noneof')\nONEOF = E"
 },
 "108": {
  "name": "NONEOF",
  "type": "ErrorDefinition",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "91",
  "column": "0",
  "slicing": "[\"NONEOF = ErrorDefinition(0x91, 'noneof')\\n\"]",
  "context": ", 'items')\n\nLOGICAL = ErrorDefinition(0x90, None)\nNONEOF = ErrorDefinition(0x91, 'noneof')\nONEOF = ErrorDefinition(0x92, 'oneof')\nANYOF = Err"
 },
 "109": {
  "name": "ONEOF",
  "type": "ErrorDefinition",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "92",
  "column": "0",
  "slicing": "[\"ONEOF = ErrorDefinition(0x92, 'oneof')\\n\"]",
  "context": "0, None)\nNONEOF = ErrorDefinition(0x91, 'noneof')\nONEOF = ErrorDefinition(0x92, 'oneof')\nANYOF = ErrorDefinition(0x93, 'anyof')\nALLOF = Err"
 },
 "110": {
  "name": "ANYOF",
  "type": "ErrorDefinition",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "93",
  "column": "0",
  "slicing": "[\"ANYOF = ErrorDefinition(0x93, 'anyof')\\n\"]",
  "context": " 'noneof')\nONEOF = ErrorDefinition(0x92, 'oneof')\nANYOF = ErrorDefinition(0x93, 'anyof')\nALLOF = ErrorDefinition(0x94, 'allof')\n\n\n\"\"\" Schem"
 },
 "111": {
  "name": "ALLOF",
  "type": "ErrorDefinition",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "94",
  "column": "0",
  "slicing": "[\"ALLOF = ErrorDefinition(0x94, 'allof')\\n\"]",
  "context": ", 'oneof')\nANYOF = ErrorDefinition(0x93, 'anyof')\nALLOF = ErrorDefinition(0x94, 'allof')\n\n\n\"\"\" SchemaError messages \"\"\"\n\nMISSING_SCHEMA = \""
 },
 "112": {
  "name": "document_path",
  "type": "cerberus.typing.DocumentPath",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "111",
  "column": "8",
  "slicing": "['        document_path: DocumentPath,\\n']",
  "context": "ion. \"\"\"\n\n    def __init__(\n        self,\n        document_path: DocumentPath,\n        schema_path: DocumentPath,\n        code: i"
 },
 "113": {
  "name": "schema_path",
  "type": "cerberus.typing.DocumentPath",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "112",
  "column": "8",
  "slicing": "['        schema_path: DocumentPath,\\n']",
  "context": "elf,\n        document_path: DocumentPath,\n        schema_path: DocumentPath,\n        code: int,\n        rule: str,\n        cons"
 },
 "114": {
  "name": "code",
  "type": "int",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "113",
  "column": "8",
  "slicing": "['        code: int,\\n']",
  "context": "tPath,\n        schema_path: DocumentPath,\n        code: int,\n        rule: str,\n        constraint: Any,\n      "
 },
 "115": {
  "name": "rule",
  "type": "str",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "114",
  "column": "8",
  "slicing": "['        rule: str,\\n']",
  "context": "ma_path: DocumentPath,\n        code: int,\n        rule: str,\n        constraint: Any,\n        value: Any,\n     "
 },
 "116": {
  "name": "constraint",
  "type": "typing.Any",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "115",
  "column": "8",
  "slicing": "['        constraint: Any,\\n']",
  "context": "th,\n        code: int,\n        rule: str,\n        constraint: Any,\n        value: Any,\n        info: Any,\n    ) -> No"
 },
 "117": {
  "name": "value",
  "type": "typing.Any",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "116",
  "column": "8",
  "slicing": "['        value: Any,\\n']",
  "context": "      rule: str,\n        constraint: Any,\n        value: Any,\n        info: Any,\n    ) -> None:\n        self.doc"
 },
 "118": {
  "name": "info",
  "type": "typing.Any",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "117",
  "column": "8",
  "slicing": "['        info: Any,\\n']",
  "context": "     constraint: Any,\n        value: Any,\n        info: Any,\n    ) -> None:\n        self.document_path = docume"
 },
 "119": {
  "name": "result",
  "type": "collections.defaultdict",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "187",
  "column": "8",
  "slicing": "['        result = defaultdict(ErrorList)  # type: DefaultDict[int, ErrorList]\\n', '            result[i].append(error)\\n', '        return result\\n']",
  "context": ".is_logic_error:\n            return None\n\n        result = defaultdict(ErrorList)  # type: DefaultDict[int, ErrorList]\n        for error in self.child_errors:  # type: i"
 },
 "120": {
  "name": "i",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "189",
  "column": "12",
  "slicing": "['NORMALIZATION = ErrorDefinition(0x60, None)\\n', 'ERROR_GROUP = ErrorDefinition(0x80, None)\\n', 'LOGICAL = ErrorDefinition(0x90, None)\\n', '        result = defaultdict(ErrorList)  # type: DefaultDict[int, ErrorList]\\n', '        for error in self.child_errors:  # type: ignore\\n', '            i = error.schema_path[len(self.schema_path)]\\n', '            result[i].append(error)\\n', '        return result\\n', '        return bool(self.code & ERROR_GROUP.code)\\n', '        return bool(self.code & LOGICAL.code - ERROR_GROUP.code)\\n', '        return bool(self.code & NORMALIZATION.code)\\n', '        wanted_code = error_definition.code\\n', '        return any(x.code == wanted_code for x in self)\\n', '            for error in self.errors:\\n', '                if item.code == error.code:\\n', '                    return error\\n', '        error_path = self._path_of_(error)\\n', '        key = error_path[self.depth]\\n', '        if key not in self.descendants:\\n', '            self[key] = ErrorTreeNode(error_path, self)\\n', '        node = cast(ErrorTreeNode, self[key])\\n', '        if len(error_path) == self.depth + 1:\\n', '            node.errors.append(error)\\n', '            node.errors.sort()\\n', '            if error.is_group_error:\\n', '                for child_error in error.child_errors:  # type: ignore\\n', '                    self.tree_root.add(child_error)\\n', '            node.add(error)\\n', \"        return getattr(error, self.tree_type + '_path')\\n\", '    path = ()\\n', '        for error in errors:\\n', '            self.add(error)\\n', '        if not self._path_of_(error):\\n', '            self.errors.append(error)\\n', '            super().add(error)\\n', '        node = self.fetch_node_from(path)\\n', '        if node is None:\\n', '            return node.errors\\n', '        context = self\\n', '        for key in path:\\n', '            context = context.get(key, None)\\n', '            if context is None:\\n', '        return context\\n', '        for error in errors:\\n', '            self.add(error)\\n', '        pretty = deepcopy(self.tree)\\n', '        for field in pretty:\\n', '            self._purge_empty_dicts(pretty[field])\\n', '        return pretty\\n', '        error = deepcopy(error)\\n', '        self._rewrite_error_path(error)\\n', '        if error.is_logic_error:\\n', '            self._insert_logic_error(error)\\n', '        elif error.is_group_error:\\n', '            self._insert_group_error(error)\\n', '        elif error.code in self.messages:\\n', '                error.document_path, self._format_message(error.field, error)\\n', '        return self.messages[error.code].format(\\n', '            *error.info, constraint=error.constraint, field=field, value=error.value\\n', '        field = path[0]\\n', '        if len(path) == 1:\\n', '            if field in self.tree:\\n', '                subtree = self.tree[field].pop()\\n', '                self.tree[field] += [node, subtree]\\n', '                self.tree[field] = [node, {}]\\n', '        elif len(path) >= 1:\\n', '            if field not in self.tree:\\n', '                self.tree[field] = [{}]\\n', '            subtree = self.tree[field][-1]\\n', '            if subtree:\\n', '                new = self.__class__(tree=copy(subtree))\\n', '                new = self.__class__()\\n', '            new._insert_error(path[1:], node)\\n', '            subtree.update(new.tree)\\n', '        for child_error in error.child_errors:\\n', '            if child_error.is_logic_error:\\n', '                self._insert_logic_error(child_error)\\n', '            elif child_error.is_group_error:\\n', '                self._insert_group_error(child_error)\\n', '                    child_error.document_path,\\n', '                    self._format_message(child_error.field, child_error),\\n', '        field = error.field\\n', '        self._insert_error(error.document_path, self._format_message(field, error))\\n', '        for definition_errors in error.definitions_errors.values():\\n', '            for child_error in definition_errors:\\n', '                if child_error.is_logic_error:\\n', '                    self._insert_logic_error(child_error)\\n', '                elif child_error.is_group_error:\\n', '                    self._insert_group_error(child_error)\\n', '                        child_error.document_path,\\n', '                        self._format_message(field, child_error),\\n', '        subtree = error_list[-1]\\n', '            for key in subtree:\\n', '                self._purge_empty_dicts(subtree[key])\\n', '        if error.is_logic_error:\\n', '            self._rewrite_logic_error_path(error, offset)\\n', '        elif error.is_group_error:\\n', '            self._rewrite_group_error_path(error, offset)\\n', '        child_start = len(error.document_path) - offset\\n', '        for child_error in error.child_errors:\\n', '            relative_path = child_error.document_path[child_start:]\\n', '            child_error.document_path = error.document_path + relative_path\\n', '            self._rewrite_error_path(child_error, offset)\\n', '        child_start = len(error.document_path) - offset\\n', '        for i, definition_errors in error.definitions_errors.items():\\n', '            if not definition_errors:\\n', \"            nodename = '%s definition %s' % (error.rule, i)\\n\", '            path = error.document_path + (nodename,)\\n', '            for child_error in definition_errors:\\n', '                rel_path = child_error.document_path[child_start:]\\n', '                child_error.document_path = path + rel_path\\n', '                self._rewrite_error_path(child_error, offset + 1)\\n']",
  "context": "in self.child_errors:  # type: ignore\n            i = error.schema_path[len(self.schema_path)]\n            result[i].append(error)\n        return"
 },
 "121": {
  "name": "__slots__",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "233",
  "column": "4",
  "slicing": "[\"    __slots__ = ('descendants', 'errors', 'parent_node', 'path', 'tree_root')\\n\"]",
  "context": " self)\n\n\nclass ErrorTreeNode(MutableMapping):\n    __slots__ = ('descendants', 'errors', 'parent_node', 'path', 'tree_root')\n\n    def __init__(self, path: DocumentPath, parent"
 },
 "122": {
  "name": "path",
  "type": "cerberus.typing.DocumentPath",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "235",
  "column": "23",
  "slicing": "[\"    def __init__(self, path: DocumentPath, parent_node: 'ErrorTreeNode') -> None:\\n\"]",
  "context": "de', 'path', 'tree_root')\n\n    def __init__(self, path: DocumentPath, parent_node: 'ErrorTreeNode') -> None:\n        self.parent_node = parent_node  # type: Op"
 },
 "123": {
  "name": "parent_node",
  "type": "ErrorTreeNode",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "235",
  "column": "43",
  "slicing": "[\"    def __init__(self, path: DocumentPath, parent_node: 'ErrorTreeNode') -> None:\\n\"]",
  "context": "oot')\n\n    def __init__(self, path: DocumentPath, parent_node: 'ErrorTreeNode') -> None:\n        self.parent_node = parent_node  # type: Op"
 },
 "124": {
  "name": "item",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "255",
  "column": "14",
  "slicing": "['        self, item: Union[ErrorDefinition, FieldName]\\n']",
  "context": "(self.errors)\n\n    def __getitem__(\n        self, item: Union[ErrorDefinition, FieldName]\n    ) -> Union[Optional[ValidationError], Optional"
 },
 "125": {
  "name": "key",
  "type": "cerberus.typing.FieldName",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "271",
  "column": "26",
  "slicing": "['    def __setitem__(self, key: FieldName, value: \"ErrorTreeNode\") -> None:\\n']",
  "context": " return self.__str__()\n\n    def __setitem__(self, key: FieldName, value: \"ErrorTreeNode\") -> None:\n        self.descendants[key] = value\n\n    def __s"
 },
 "126": {
  "name": "error",
  "type": "ValidationError",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "285",
  "column": "18",
  "slicing": "['    def add(self, error: ValidationError) -> None:\\n']",
  "context": "eturn self.tree_root.tree_type\n\n    def add(self, error: ValidationError) -> None:\n        error_path = self._path_of_(error)\n\n      "
 },
 "127": {
  "name": "key",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "288",
  "column": "8",
  "slicing": "['NORMALIZATION = ErrorDefinition(0x60, None)\\n', 'ERROR_GROUP = ErrorDefinition(0x80, None)\\n', 'LOGICAL = ErrorDefinition(0x90, None)\\n', '        result = defaultdict(ErrorList)  # type: DefaultDict[int, ErrorList]\\n', '        for error in self.child_errors:  # type: ignore\\n', '            i = error.schema_path[len(self.schema_path)]\\n', '            result[i].append(error)\\n', '        return result\\n', '        return bool(self.code & ERROR_GROUP.code)\\n', '        return bool(self.code & LOGICAL.code - ERROR_GROUP.code)\\n', '        return bool(self.code & NORMALIZATION.code)\\n', '        wanted_code = error_definition.code\\n', '        return any(x.code == wanted_code for x in self)\\n', '            for error in self.errors:\\n', '                if item.code == error.code:\\n', '                    return error\\n', '        error_path = self._path_of_(error)\\n', '        key = error_path[self.depth]\\n', '        if key not in self.descendants:\\n', '            self[key] = ErrorTreeNode(error_path, self)\\n', '        node = cast(ErrorTreeNode, self[key])\\n', '        if len(error_path) == self.depth + 1:\\n', '            node.errors.append(error)\\n', '            node.errors.sort()\\n', '            if error.is_group_error:\\n', '                for child_error in error.child_errors:  # type: ignore\\n', '                    self.tree_root.add(child_error)\\n', '            node.add(error)\\n', \"        return getattr(error, self.tree_type + '_path')\\n\", '    path = ()\\n', '        for error in errors:\\n', '            self.add(error)\\n', '        if not self._path_of_(error):\\n', '            self.errors.append(error)\\n', '            super().add(error)\\n', '        node = self.fetch_node_from(path)\\n', '        if node is None:\\n', '            return node.errors\\n', '        context = self\\n', '        for key in path:\\n', '            context = context.get(key, None)\\n', '            if context is None:\\n', '        return context\\n', '        for error in errors:\\n', '            self.add(error)\\n', '        pretty = deepcopy(self.tree)\\n', '        for field in pretty:\\n', '            self._purge_empty_dicts(pretty[field])\\n', '        return pretty\\n', '        error = deepcopy(error)\\n', '        self._rewrite_error_path(error)\\n', '        if error.is_logic_error:\\n', '            self._insert_logic_error(error)\\n', '        elif error.is_group_error:\\n', '            self._insert_group_error(error)\\n', '        elif error.code in self.messages:\\n', '                error.document_path, self._format_message(error.field, error)\\n', '        return self.messages[error.code].format(\\n', '            *error.info, constraint=error.constraint, field=field, value=error.value\\n', '        field = path[0]\\n', '        if len(path) == 1:\\n', '            if field in self.tree:\\n', '                subtree = self.tree[field].pop()\\n', '                self.tree[field] += [node, subtree]\\n', '                self.tree[field] = [node, {}]\\n', '        elif len(path) >= 1:\\n', '            if field not in self.tree:\\n', '                self.tree[field] = [{}]\\n', '            subtree = self.tree[field][-1]\\n', '            if subtree:\\n', '                new = self.__class__(tree=copy(subtree))\\n', '                new = self.__class__()\\n', '            new._insert_error(path[1:], node)\\n', '            subtree.update(new.tree)\\n', '        for child_error in error.child_errors:\\n', '            if child_error.is_logic_error:\\n', '                self._insert_logic_error(child_error)\\n', '            elif child_error.is_group_error:\\n', '                self._insert_group_error(child_error)\\n', '                    child_error.document_path,\\n', '                    self._format_message(child_error.field, child_error),\\n', '        field = error.field\\n', '        self._insert_error(error.document_path, self._format_message(field, error))\\n', '        for definition_errors in error.definitions_errors.values():\\n', '            for child_error in definition_errors:\\n', '                if child_error.is_logic_error:\\n', '                    self._insert_logic_error(child_error)\\n', '                elif child_error.is_group_error:\\n', '                    self._insert_group_error(child_error)\\n', '                        child_error.document_path,\\n', '                        self._format_message(field, child_error),\\n', '        subtree = error_list[-1]\\n', '            for key in subtree:\\n', '                self._purge_empty_dicts(subtree[key])\\n', '        if error.is_logic_error:\\n', '            self._rewrite_logic_error_path(error, offset)\\n', '        elif error.is_group_error:\\n', '            self._rewrite_group_error_path(error, offset)\\n', '        child_start = len(error.document_path) - offset\\n', '        for child_error in error.child_errors:\\n', '            relative_path = child_error.document_path[child_start:]\\n', '            child_error.document_path = error.document_path + relative_path\\n', '            self._rewrite_error_path(child_error, offset)\\n', '        child_start = len(error.document_path) - offset\\n', '        for i, definition_errors in error.definitions_errors.items():\\n', '            if not definition_errors:\\n', \"            nodename = '%s definition %s' % (error.rule, i)\\n\", '            path = error.document_path + (nodename,)\\n', '            for child_error in definition_errors:\\n', '                rel_path = child_error.document_path[child_start:]\\n', '                child_error.document_path = path + rel_path\\n', '                self._rewrite_error_path(child_error, offset + 1)\\n']",
  "context": "      error_path = self._path_of_(error)\n\n        key = error_path[self.depth]\n        if key not in self.descendants:\n          "
 },
 "128": {
  "name": "node",
  "type": "typing.cast",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "292",
  "column": "8",
  "slicing": "['NORMALIZATION = ErrorDefinition(0x60, None)\\n', 'ERROR_GROUP = ErrorDefinition(0x80, None)\\n', 'LOGICAL = ErrorDefinition(0x90, None)\\n', '        result = defaultdict(ErrorList)  # type: DefaultDict[int, ErrorList]\\n', '        for error in self.child_errors:  # type: ignore\\n', '            i = error.schema_path[len(self.schema_path)]\\n', '            result[i].append(error)\\n', '        return result\\n', '        return bool(self.code & ERROR_GROUP.code)\\n', '        return bool(self.code & LOGICAL.code - ERROR_GROUP.code)\\n', '        return bool(self.code & NORMALIZATION.code)\\n', '        wanted_code = error_definition.code\\n', '        return any(x.code == wanted_code for x in self)\\n', '            for error in self.errors:\\n', '                if item.code == error.code:\\n', '                    return error\\n', '        error_path = self._path_of_(error)\\n', '        key = error_path[self.depth]\\n', '        if key not in self.descendants:\\n', '            self[key] = ErrorTreeNode(error_path, self)\\n', '        node = cast(ErrorTreeNode, self[key])\\n', '        if len(error_path) == self.depth + 1:\\n', '            node.errors.append(error)\\n', '            node.errors.sort()\\n', '            if error.is_group_error:\\n', '                for child_error in error.child_errors:  # type: ignore\\n', '                    self.tree_root.add(child_error)\\n', '            node.add(error)\\n', \"        return getattr(error, self.tree_type + '_path')\\n\", '    path = ()\\n', '        for error in errors:\\n', '            self.add(error)\\n', '        if not self._path_of_(error):\\n', '            self.errors.append(error)\\n', '            super().add(error)\\n', '        node = self.fetch_node_from(path)\\n', '        if node is None:\\n', '            return node.errors\\n', '        context = self\\n', '        for key in path:\\n', '            context = context.get(key, None)\\n', '            if context is None:\\n', '        return context\\n', '        for error in errors:\\n', '            self.add(error)\\n', '        pretty = deepcopy(self.tree)\\n', '        for field in pretty:\\n', '            self._purge_empty_dicts(pretty[field])\\n', '        return pretty\\n', '        error = deepcopy(error)\\n', '        self._rewrite_error_path(error)\\n', '        if error.is_logic_error:\\n', '            self._insert_logic_error(error)\\n', '        elif error.is_group_error:\\n', '            self._insert_group_error(error)\\n', '        elif error.code in self.messages:\\n', '                error.document_path, self._format_message(error.field, error)\\n', '        return self.messages[error.code].format(\\n', '            *error.info, constraint=error.constraint, field=field, value=error.value\\n', '        field = path[0]\\n', '        if len(path) == 1:\\n', '            if field in self.tree:\\n', '                subtree = self.tree[field].pop()\\n', '                self.tree[field] += [node, subtree]\\n', '                self.tree[field] = [node, {}]\\n', '        elif len(path) >= 1:\\n', '            if field not in self.tree:\\n', '                self.tree[field] = [{}]\\n', '            subtree = self.tree[field][-1]\\n', '            if subtree:\\n', '                new = self.__class__(tree=copy(subtree))\\n', '                new = self.__class__()\\n', '            new._insert_error(path[1:], node)\\n', '            subtree.update(new.tree)\\n', '        for child_error in error.child_errors:\\n', '            if child_error.is_logic_error:\\n', '                self._insert_logic_error(child_error)\\n', '            elif child_error.is_group_error:\\n', '                self._insert_group_error(child_error)\\n', '                    child_error.document_path,\\n', '                    self._format_message(child_error.field, child_error),\\n', '        field = error.field\\n', '        self._insert_error(error.document_path, self._format_message(field, error))\\n', '        for definition_errors in error.definitions_errors.values():\\n', '            for child_error in definition_errors:\\n', '                if child_error.is_logic_error:\\n', '                    self._insert_logic_error(child_error)\\n', '                elif child_error.is_group_error:\\n', '                    self._insert_group_error(child_error)\\n', '                        child_error.document_path,\\n', '                        self._format_message(field, child_error),\\n', '        subtree = error_list[-1]\\n', '            for key in subtree:\\n', '                self._purge_empty_dicts(subtree[key])\\n', '        if error.is_logic_error:\\n', '            self._rewrite_logic_error_path(error, offset)\\n', '        elif error.is_group_error:\\n', '            self._rewrite_group_error_path(error, offset)\\n', '        child_start = len(error.document_path) - offset\\n', '        for child_error in error.child_errors:\\n', '            relative_path = child_error.document_path[child_start:]\\n', '            child_error.document_path = error.document_path + relative_path\\n', '            self._rewrite_error_path(child_error, offset)\\n', '        child_start = len(error.document_path) - offset\\n', '        for i, definition_errors in error.definitions_errors.items():\\n', '            if not definition_errors:\\n', \"            nodename = '%s definition %s' % (error.rule, i)\\n\", '            path = error.document_path + (nodename,)\\n', '            for child_error in definition_errors:\\n', '                rel_path = child_error.document_path[child_start:]\\n', '                child_error.document_path = path + rel_path\\n', '                self._rewrite_error_path(child_error, offset + 1)\\n']",
  "context": "f[key] = ErrorTreeNode(error_path, self)\n\n        node = cast(ErrorTreeNode, self[key])\n\n        if len(error_path) == self.depth + 1:\n   "
 },
 "129": {
  "name": "parent",
  "type": "None",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "312",
  "column": "4",
  "slicing": "['    parent = None\\n']",
  "context": "s.errors.SchemaErrorTree`. \"\"\"\n\n    depth = 0\n    parent = None\n    path = ()\n\n    def __init__(self, errors: Iter"
 },
 "130": {
  "name": "path",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "313",
  "column": "4",
  "slicing": "['NORMALIZATION = ErrorDefinition(0x60, None)\\n', 'ERROR_GROUP = ErrorDefinition(0x80, None)\\n', 'LOGICAL = ErrorDefinition(0x90, None)\\n', '        result = defaultdict(ErrorList)  # type: DefaultDict[int, ErrorList]\\n', '        for error in self.child_errors:  # type: ignore\\n', '            i = error.schema_path[len(self.schema_path)]\\n', '            result[i].append(error)\\n', '        return result\\n', '        return bool(self.code & ERROR_GROUP.code)\\n', '        return bool(self.code & LOGICAL.code - ERROR_GROUP.code)\\n', '        return bool(self.code & NORMALIZATION.code)\\n', '        wanted_code = error_definition.code\\n', '        return any(x.code == wanted_code for x in self)\\n', '            for error in self.errors:\\n', '                if item.code == error.code:\\n', '                    return error\\n', '        error_path = self._path_of_(error)\\n', '        key = error_path[self.depth]\\n', '        if key not in self.descendants:\\n', '            self[key] = ErrorTreeNode(error_path, self)\\n', '        node = cast(ErrorTreeNode, self[key])\\n', '        if len(error_path) == self.depth + 1:\\n', '            node.errors.append(error)\\n', '            node.errors.sort()\\n', '            if error.is_group_error:\\n', '                for child_error in error.child_errors:  # type: ignore\\n', '                    self.tree_root.add(child_error)\\n', '            node.add(error)\\n', \"        return getattr(error, self.tree_type + '_path')\\n\", '    path = ()\\n', '        for error in errors:\\n', '            self.add(error)\\n', '        if not self._path_of_(error):\\n', '            self.errors.append(error)\\n', '            super().add(error)\\n', '        node = self.fetch_node_from(path)\\n', '        if node is None:\\n', '            return node.errors\\n', '        context = self\\n', '        for key in path:\\n', '            context = context.get(key, None)\\n', '            if context is None:\\n', '        return context\\n', '        for error in errors:\\n', '            self.add(error)\\n', '        pretty = deepcopy(self.tree)\\n', '        for field in pretty:\\n', '            self._purge_empty_dicts(pretty[field])\\n', '        return pretty\\n', '        error = deepcopy(error)\\n', '        self._rewrite_error_path(error)\\n', '        if error.is_logic_error:\\n', '            self._insert_logic_error(error)\\n', '        elif error.is_group_error:\\n', '            self._insert_group_error(error)\\n', '        elif error.code in self.messages:\\n', '                error.document_path, self._format_message(error.field, error)\\n', '        return self.messages[error.code].format(\\n', '            *error.info, constraint=error.constraint, field=field, value=error.value\\n', '        field = path[0]\\n', '        if len(path) == 1:\\n', '            if field in self.tree:\\n', '                subtree = self.tree[field].pop()\\n', '                self.tree[field] += [node, subtree]\\n', '                self.tree[field] = [node, {}]\\n', '        elif len(path) >= 1:\\n', '            if field not in self.tree:\\n', '                self.tree[field] = [{}]\\n', '            subtree = self.tree[field][-1]\\n', '            if subtree:\\n', '                new = self.__class__(tree=copy(subtree))\\n', '                new = self.__class__()\\n', '            new._insert_error(path[1:], node)\\n', '            subtree.update(new.tree)\\n', '        for child_error in error.child_errors:\\n', '            if child_error.is_logic_error:\\n', '                self._insert_logic_error(child_error)\\n', '            elif child_error.is_group_error:\\n', '                self._insert_group_error(child_error)\\n', '                    child_error.document_path,\\n', '                    self._format_message(child_error.field, child_error),\\n', '        field = error.field\\n', '        self._insert_error(error.document_path, self._format_message(field, error))\\n', '        for definition_errors in error.definitions_errors.values():\\n', '            for child_error in definition_errors:\\n', '                if child_error.is_logic_error:\\n', '                    self._insert_logic_error(child_error)\\n', '                elif child_error.is_group_error:\\n', '                    self._insert_group_error(child_error)\\n', '                        child_error.document_path,\\n', '                        self._format_message(field, child_error),\\n', '        subtree = error_list[-1]\\n', '            for key in subtree:\\n', '                self._purge_empty_dicts(subtree[key])\\n', '        if error.is_logic_error:\\n', '            self._rewrite_logic_error_path(error, offset)\\n', '        elif error.is_group_error:\\n', '            self._rewrite_group_error_path(error, offset)\\n', '        child_start = len(error.document_path) - offset\\n', '        for child_error in error.child_errors:\\n', '            relative_path = child_error.document_path[child_start:]\\n', '            child_error.document_path = error.document_path + relative_path\\n', '            self._rewrite_error_path(child_error, offset)\\n', '        child_start = len(error.document_path) - offset\\n', '        for i, definition_errors in error.definitions_errors.items():\\n', '            if not definition_errors:\\n', \"            nodename = '%s definition %s' % (error.rule, i)\\n\", '            path = error.document_path + (nodename,)\\n', '            for child_error in definition_errors:\\n', '                rel_path = child_error.document_path[child_start:]\\n', '                child_error.document_path = path + rel_path\\n', '                self._rewrite_error_path(child_error, offset + 1)\\n']",
  "context": "orTree`. \"\"\"\n\n    depth = 0\n    parent = None\n    path = ()\n\n    def __init__(self, errors: Iterable[Validatio"
 },
 "131": {
  "name": "errors",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "315",
  "column": "23",
  "slicing": "['    def __init__(self, errors: Iterable[ValidationError] = ()) -> None:\\n']",
  "context": "rent = None\n    path = ()\n\n    def __init__(self, errors: Iterable[ValidationError] = ()) -> None:\n        self.tree_root = self\n        self.errors "
 },
 "132": {
  "name": "error",
  "type": "ValidationError",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "322",
  "column": "18",
  "slicing": "['    def add(self, error: ValidationError) -> None:\\n']",
  "context": "s:\n            self.add(error)\n\n    def add(self, error: ValidationError) -> None:\n        \"\"\" Add an error to the tree. \"\"\"\n        "
 },
 "133": {
  "name": "path",
  "type": "cerberus.typing.DocumentPath",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "330",
  "column": "32",
  "slicing": "['    def fetch_errors_from(self, path: DocumentPath) -> ErrorList:\\n']",
  "context": "per().add(error)\n\n    def fetch_errors_from(self, path: DocumentPath) -> ErrorList:\n        \"\"\" Returns all errors for a particular pa"
 },
 "134": {
  "name": "node",
  "type": "DocumentErrorTree",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "332",
  "column": "8",
  "slicing": "['NORMALIZATION = ErrorDefinition(0x60, None)\\n', 'ERROR_GROUP = ErrorDefinition(0x80, None)\\n', 'LOGICAL = ErrorDefinition(0x90, None)\\n', '        result = defaultdict(ErrorList)  # type: DefaultDict[int, ErrorList]\\n', '        for error in self.child_errors:  # type: ignore\\n', '            i = error.schema_path[len(self.schema_path)]\\n', '            result[i].append(error)\\n', '        return result\\n', '        return bool(self.code & ERROR_GROUP.code)\\n', '        return bool(self.code & LOGICAL.code - ERROR_GROUP.code)\\n', '        return bool(self.code & NORMALIZATION.code)\\n', '        wanted_code = error_definition.code\\n', '        return any(x.code == wanted_code for x in self)\\n', '            for error in self.errors:\\n', '                if item.code == error.code:\\n', '                    return error\\n', '        error_path = self._path_of_(error)\\n', '        key = error_path[self.depth]\\n', '        if key not in self.descendants:\\n', '            self[key] = ErrorTreeNode(error_path, self)\\n', '        node = cast(ErrorTreeNode, self[key])\\n', '        if len(error_path) == self.depth + 1:\\n', '            node.errors.append(error)\\n', '            node.errors.sort()\\n', '            if error.is_group_error:\\n', '                for child_error in error.child_errors:  # type: ignore\\n', '                    self.tree_root.add(child_error)\\n', '            node.add(error)\\n', \"        return getattr(error, self.tree_type + '_path')\\n\", '    path = ()\\n', '        for error in errors:\\n', '            self.add(error)\\n', '        if not self._path_of_(error):\\n', '            self.errors.append(error)\\n', '            super().add(error)\\n', '        node = self.fetch_node_from(path)\\n', '        if node is None:\\n', '            return node.errors\\n', '        context = self\\n', '        for key in path:\\n', '            context = context.get(key, None)\\n', '            if context is None:\\n', '        return context\\n', '        for error in errors:\\n', '            self.add(error)\\n', '        pretty = deepcopy(self.tree)\\n', '        for field in pretty:\\n', '            self._purge_empty_dicts(pretty[field])\\n', '        return pretty\\n', '        error = deepcopy(error)\\n', '        self._rewrite_error_path(error)\\n', '        if error.is_logic_error:\\n', '            self._insert_logic_error(error)\\n', '        elif error.is_group_error:\\n', '            self._insert_group_error(error)\\n', '        elif error.code in self.messages:\\n', '                error.document_path, self._format_message(error.field, error)\\n', '        return self.messages[error.code].format(\\n', '            *error.info, constraint=error.constraint, field=field, value=error.value\\n', '        field = path[0]\\n', '        if len(path) == 1:\\n', '            if field in self.tree:\\n', '                subtree = self.tree[field].pop()\\n', '                self.tree[field] += [node, subtree]\\n', '                self.tree[field] = [node, {}]\\n', '        elif len(path) >= 1:\\n', '            if field not in self.tree:\\n', '                self.tree[field] = [{}]\\n', '            subtree = self.tree[field][-1]\\n', '            if subtree:\\n', '                new = self.__class__(tree=copy(subtree))\\n', '                new = self.__class__()\\n', '            new._insert_error(path[1:], node)\\n', '            subtree.update(new.tree)\\n', '        for child_error in error.child_errors:\\n', '            if child_error.is_logic_error:\\n', '                self._insert_logic_error(child_error)\\n', '            elif child_error.is_group_error:\\n', '                self._insert_group_error(child_error)\\n', '                    child_error.document_path,\\n', '                    self._format_message(child_error.field, child_error),\\n', '        field = error.field\\n', '        self._insert_error(error.document_path, self._format_message(field, error))\\n', '        for definition_errors in error.definitions_errors.values():\\n', '            for child_error in definition_errors:\\n', '                if child_error.is_logic_error:\\n', '                    self._insert_logic_error(child_error)\\n', '                elif child_error.is_group_error:\\n', '                    self._insert_group_error(child_error)\\n', '                        child_error.document_path,\\n', '                        self._format_message(field, child_error),\\n', '        subtree = error_list[-1]\\n', '            for key in subtree:\\n', '                self._purge_empty_dicts(subtree[key])\\n', '        if error.is_logic_error:\\n', '            self._rewrite_logic_error_path(error, offset)\\n', '        elif error.is_group_error:\\n', '            self._rewrite_group_error_path(error, offset)\\n', '        child_start = len(error.document_path) - offset\\n', '        for child_error in error.child_errors:\\n', '            relative_path = child_error.document_path[child_start:]\\n', '            child_error.document_path = error.document_path + relative_path\\n', '            self._rewrite_error_path(child_error, offset)\\n', '        child_start = len(error.document_path) - offset\\n', '        for i, definition_errors in error.definitions_errors.items():\\n', '            if not definition_errors:\\n', \"            nodename = '%s definition %s' % (error.rule, i)\\n\", '            path = error.document_path + (nodename,)\\n', '            for child_error in definition_errors:\\n', '                rel_path = child_error.document_path[child_start:]\\n', '                child_error.document_path = path + rel_path\\n', '                self._rewrite_error_path(child_error, offset + 1)\\n']",
  "context": "rns all errors for a particular path. \"\"\"\n        node = self.fetch_node_from(path)\n        if node is None:\n            return ErrorL"
 },
 "135": {
  "name": "path",
  "type": "cerberus.typing.DocumentPath",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "338",
  "column": "30",
  "slicing": "['    def fetch_node_from(self, path: DocumentPath) -> ErrorTreeNode:\\n']",
  "context": "return node.errors\n\n    def fetch_node_from(self, path: DocumentPath) -> ErrorTreeNode:\n        \"\"\" Returns a node for a path. \"\"\"\n       "
 },
 "136": {
  "name": "context",
  "type": "self",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "340",
  "column": "8",
  "slicing": "['NORMALIZATION = ErrorDefinition(0x60, None)\\n', 'ERROR_GROUP = ErrorDefinition(0x80, None)\\n', 'LOGICAL = ErrorDefinition(0x90, None)\\n', '        result = defaultdict(ErrorList)  # type: DefaultDict[int, ErrorList]\\n', '        for error in self.child_errors:  # type: ignore\\n', '            i = error.schema_path[len(self.schema_path)]\\n', '            result[i].append(error)\\n', '        return result\\n', '        return bool(self.code & ERROR_GROUP.code)\\n', '        return bool(self.code & LOGICAL.code - ERROR_GROUP.code)\\n', '        return bool(self.code & NORMALIZATION.code)\\n', '        wanted_code = error_definition.code\\n', '        return any(x.code == wanted_code for x in self)\\n', '            for error in self.errors:\\n', '                if item.code == error.code:\\n', '                    return error\\n', '        error_path = self._path_of_(error)\\n', '        key = error_path[self.depth]\\n', '        if key not in self.descendants:\\n', '            self[key] = ErrorTreeNode(error_path, self)\\n', '        node = cast(ErrorTreeNode, self[key])\\n', '        if len(error_path) == self.depth + 1:\\n', '            node.errors.append(error)\\n', '            node.errors.sort()\\n', '            if error.is_group_error:\\n', '                for child_error in error.child_errors:  # type: ignore\\n', '                    self.tree_root.add(child_error)\\n', '            node.add(error)\\n', \"        return getattr(error, self.tree_type + '_path')\\n\", '    path = ()\\n', '        for error in errors:\\n', '            self.add(error)\\n', '        if not self._path_of_(error):\\n', '            self.errors.append(error)\\n', '            super().add(error)\\n', '        node = self.fetch_node_from(path)\\n', '        if node is None:\\n', '            return node.errors\\n', '        context = self\\n', '        for key in path:\\n', '            context = context.get(key, None)\\n', '            if context is None:\\n', '        return context\\n', '        for error in errors:\\n', '            self.add(error)\\n', '        pretty = deepcopy(self.tree)\\n', '        for field in pretty:\\n', '            self._purge_empty_dicts(pretty[field])\\n', '        return pretty\\n', '        error = deepcopy(error)\\n', '        self._rewrite_error_path(error)\\n', '        if error.is_logic_error:\\n', '            self._insert_logic_error(error)\\n', '        elif error.is_group_error:\\n', '            self._insert_group_error(error)\\n', '        elif error.code in self.messages:\\n', '                error.document_path, self._format_message(error.field, error)\\n', '        return self.messages[error.code].format(\\n', '            *error.info, constraint=error.constraint, field=field, value=error.value\\n', '        field = path[0]\\n', '        if len(path) == 1:\\n', '            if field in self.tree:\\n', '                subtree = self.tree[field].pop()\\n', '                self.tree[field] += [node, subtree]\\n', '                self.tree[field] = [node, {}]\\n', '        elif len(path) >= 1:\\n', '            if field not in self.tree:\\n', '                self.tree[field] = [{}]\\n', '            subtree = self.tree[field][-1]\\n', '            if subtree:\\n', '                new = self.__class__(tree=copy(subtree))\\n', '                new = self.__class__()\\n', '            new._insert_error(path[1:], node)\\n', '            subtree.update(new.tree)\\n', '        for child_error in error.child_errors:\\n', '            if child_error.is_logic_error:\\n', '                self._insert_logic_error(child_error)\\n', '            elif child_error.is_group_error:\\n', '                self._insert_group_error(child_error)\\n', '                    child_error.document_path,\\n', '                    self._format_message(child_error.field, child_error),\\n', '        field = error.field\\n', '        self._insert_error(error.document_path, self._format_message(field, error))\\n', '        for definition_errors in error.definitions_errors.values():\\n', '            for child_error in definition_errors:\\n', '                if child_error.is_logic_error:\\n', '                    self._insert_logic_error(child_error)\\n', '                elif child_error.is_group_error:\\n', '                    self._insert_group_error(child_error)\\n', '                        child_error.document_path,\\n', '                        self._format_message(field, child_error),\\n', '        subtree = error_list[-1]\\n', '            for key in subtree:\\n', '                self._purge_empty_dicts(subtree[key])\\n', '        if error.is_logic_error:\\n', '            self._rewrite_logic_error_path(error, offset)\\n', '        elif error.is_group_error:\\n', '            self._rewrite_group_error_path(error, offset)\\n', '        child_start = len(error.document_path) - offset\\n', '        for child_error in error.child_errors:\\n', '            relative_path = child_error.document_path[child_start:]\\n', '            child_error.document_path = error.document_path + relative_path\\n', '            self._rewrite_error_path(child_error, offset)\\n', '        child_start = len(error.document_path) - offset\\n', '        for i, definition_errors in error.definitions_errors.items():\\n', '            if not definition_errors:\\n', \"            nodename = '%s definition %s' % (error.rule, i)\\n\", '            path = error.document_path + (nodename,)\\n', '            for child_error in definition_errors:\\n', '                rel_path = child_error.document_path[child_start:]\\n', '                child_error.document_path = path + rel_path\\n', '                self._rewrite_error_path(child_error, offset + 1)\\n']",
  "context": "       \"\"\" Returns a node for a path. \"\"\"\n        context = self\n        for key in path:\n            context = con"
 },
 "137": {
  "name": "errors",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "370",
  "column": "23",
  "slicing": "['    def __call__(self, errors: Iterable[ValidationError]) -> Any:\\n']",
  "context": " pass\n\n    @abstractmethod\n    def __call__(self, errors: Iterable[ValidationError]) -> Any:\n        \"\"\" Returns errors in a handler-specific f"
 },
 "138": {
  "name": "error",
  "type": "ValidationError",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "379",
  "column": "18",
  "slicing": "['    def add(self, error: ValidationError) -> None:\\n']",
  "context": "entedError\n\n    @abstractmethod\n    def add(self, error: ValidationError) -> None:\n        \"\"\" Add an error to the errors' container "
 },
 "139": {
  "name": "error",
  "type": "ValidationError",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "386",
  "column": "19",
  "slicing": "['    def emit(self, error: ValidationError) -> None:\\n']",
  "context": "add.\n        \"\"\"\n        pass\n\n    def emit(self, error: ValidationError) -> None:\n        \"\"\" Optionally emits an error in the handl"
 },
 "140": {
  "name": "validator",
  "type": "cerberus.validator.Validator",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "394",
  "column": "18",
  "slicing": "['    def end(self, validator: \"UnconcernedValidator\") -> None:\\n']",
  "context": "emit.\n        \"\"\"\n        pass\n\n    def end(self, validator: \"UnconcernedValidator\") -> None:\n        \"\"\" Gets called when a validation ends.\n\n "
 },
 "141": {
  "name": "errors",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "401",
  "column": "21",
  "slicing": "['    def extend(self, errors: Iterable[ValidationError]) -> None:\\n']",
  "context": "r.\n        \"\"\"\n        pass\n\n    def extend(self, errors: Iterable[ValidationError]) -> None:\n        \"\"\" Adds all errors to the handler's conta"
 },
 "142": {
  "name": "add",
  "type": "__call__",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "418",
  "column": "4",
  "slicing": "['NORMALIZATION = ErrorDefinition(0x60, None)\\n', 'ERROR_GROUP = ErrorDefinition(0x80, None)\\n', 'LOGICAL = ErrorDefinition(0x90, None)\\n', '        result = defaultdict(ErrorList)  # type: DefaultDict[int, ErrorList]\\n', '        for error in self.child_errors:  # type: ignore\\n', '            i = error.schema_path[len(self.schema_path)]\\n', '            result[i].append(error)\\n', '        return result\\n', '        return bool(self.code & ERROR_GROUP.code)\\n', '        return bool(self.code & LOGICAL.code - ERROR_GROUP.code)\\n', '        return bool(self.code & NORMALIZATION.code)\\n', '        wanted_code = error_definition.code\\n', '        return any(x.code == wanted_code for x in self)\\n', '            for error in self.errors:\\n', '                if item.code == error.code:\\n', '                    return error\\n', '        error_path = self._path_of_(error)\\n', '        key = error_path[self.depth]\\n', '        if key not in self.descendants:\\n', '            self[key] = ErrorTreeNode(error_path, self)\\n', '        node = cast(ErrorTreeNode, self[key])\\n', '        if len(error_path) == self.depth + 1:\\n', '            node.errors.append(error)\\n', '            node.errors.sort()\\n', '            if error.is_group_error:\\n', '                for child_error in error.child_errors:  # type: ignore\\n', '                    self.tree_root.add(child_error)\\n', '            node.add(error)\\n', \"        return getattr(error, self.tree_type + '_path')\\n\", '    path = ()\\n', '        for error in errors:\\n', '            self.add(error)\\n', '        if not self._path_of_(error):\\n', '            self.errors.append(error)\\n', '            super().add(error)\\n', '        node = self.fetch_node_from(path)\\n', '        if node is None:\\n', '            return node.errors\\n', '        context = self\\n', '        for key in path:\\n', '            context = context.get(key, None)\\n', '            if context is None:\\n', '        return context\\n', '        for error in errors:\\n', '            self.add(error)\\n', '    add = __call__\\n', '        pretty = deepcopy(self.tree)\\n', '        for field in pretty:\\n', '            self._purge_empty_dicts(pretty[field])\\n', '        return pretty\\n', '        error = deepcopy(error)\\n', '        self._rewrite_error_path(error)\\n', '        if error.is_logic_error:\\n', '            self._insert_logic_error(error)\\n', '        elif error.is_group_error:\\n', '            self._insert_group_error(error)\\n', '        elif error.code in self.messages:\\n', '                error.document_path, self._format_message(error.field, error)\\n', '        return self.messages[error.code].format(\\n', '            *error.info, constraint=error.constraint, field=field, value=error.value\\n', '        field = path[0]\\n', '        if len(path) == 1:\\n', '            if field in self.tree:\\n', '                subtree = self.tree[field].pop()\\n', '                self.tree[field] += [node, subtree]\\n', '                self.tree[field] = [node, {}]\\n', '        elif len(path) >= 1:\\n', '            if field not in self.tree:\\n', '                self.tree[field] = [{}]\\n', '            subtree = self.tree[field][-1]\\n', '            if subtree:\\n', '                new = self.__class__(tree=copy(subtree))\\n', '                new = self.__class__()\\n', '            new._insert_error(path[1:], node)\\n', '            subtree.update(new.tree)\\n', '        for child_error in error.child_errors:\\n', '            if child_error.is_logic_error:\\n', '                self._insert_logic_error(child_error)\\n', '            elif child_error.is_group_error:\\n', '                self._insert_group_error(child_error)\\n', '                    child_error.document_path,\\n', '                    self._format_message(child_error.field, child_error),\\n', '        field = error.field\\n', '        self._insert_error(error.document_path, self._format_message(field, error))\\n', '        for definition_errors in error.definitions_errors.values():\\n', '            for child_error in definition_errors:\\n', '                if child_error.is_logic_error:\\n', '                    self._insert_logic_error(child_error)\\n', '                elif child_error.is_group_error:\\n', '                    self._insert_group_error(child_error)\\n', '                        child_error.document_path,\\n', '                        self._format_message(field, child_error),\\n', '        subtree = error_list[-1]\\n', '            for key in subtree:\\n', '                self._purge_empty_dicts(subtree[key])\\n', '        if error.is_logic_error:\\n', '            self._rewrite_logic_error_path(error, offset)\\n', '        elif error.is_group_error:\\n', '            self._rewrite_group_error_path(error, offset)\\n', '        child_start = len(error.document_path) - offset\\n', '        for child_error in error.child_errors:\\n', '            relative_path = child_error.document_path[child_start:]\\n', '            child_error.document_path = error.document_path + relative_path\\n', '            self._rewrite_error_path(child_error, offset)\\n', '        child_start = len(error.document_path) - offset\\n', '        for i, definition_errors in error.definitions_errors.items():\\n', '            if not definition_errors:\\n', \"            nodename = '%s definition %s' % (error.rule, i)\\n\", '            path = error.document_path + (nodename,)\\n', '            for child_error in definition_errors:\\n', '                rel_path = child_error.document_path[child_start:]\\n', '                child_error.document_path = path + rel_path\\n', '                self._rewrite_error_path(child_error, offset + 1)\\n']",
  "context": "timeError('This is not supposed to happen.')\n\n    add = __call__\n\n\nclass BasicErrorHandler(BaseErrorHandler):\n    \""
 },
 "143": {
  "name": "messages",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "427",
  "column": "4",
  "slicing": "['    messages = {\\n', '    messages[0x03] = \"unknown rule\"\\n']",
  "context": "on of that\n        tree is returned.\n    \"\"\"\n\n    messages = {\n        0x00: \"{0}\",\n        0x01: \"document is mi"
 },
 "144": {
  "name": "tree",
  "type": "typing.Dict",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "465",
  "column": "23",
  "slicing": "['    def __init__(self, tree: Dict = None) -> None:\\n']",
  "context": "ns don't validate\",\n    }\n\n    def __init__(self, tree: Dict = None) -> None:\n        self.tree = {} if tree is None else tree\n\n"
 },
 "145": {
  "name": "pretty",
  "type": "copy.deepcopy",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "478",
  "column": "8",
  "slicing": "['NORMALIZATION = ErrorDefinition(0x60, None)\\n', 'ERROR_GROUP = ErrorDefinition(0x80, None)\\n', 'LOGICAL = ErrorDefinition(0x90, None)\\n', '        result = defaultdict(ErrorList)  # type: DefaultDict[int, ErrorList]\\n', '        for error in self.child_errors:  # type: ignore\\n', '            i = error.schema_path[len(self.schema_path)]\\n', '            result[i].append(error)\\n', '        return result\\n', '        return bool(self.code & ERROR_GROUP.code)\\n', '        return bool(self.code & LOGICAL.code - ERROR_GROUP.code)\\n', '        return bool(self.code & NORMALIZATION.code)\\n', '        wanted_code = error_definition.code\\n', '        return any(x.code == wanted_code for x in self)\\n', '            for error in self.errors:\\n', '                if item.code == error.code:\\n', '                    return error\\n', '        error_path = self._path_of_(error)\\n', '        key = error_path[self.depth]\\n', '        if key not in self.descendants:\\n', '            self[key] = ErrorTreeNode(error_path, self)\\n', '        node = cast(ErrorTreeNode, self[key])\\n', '        if len(error_path) == self.depth + 1:\\n', '            node.errors.append(error)\\n', '            node.errors.sort()\\n', '            if error.is_group_error:\\n', '                for child_error in error.child_errors:  # type: ignore\\n', '                    self.tree_root.add(child_error)\\n', '            node.add(error)\\n', \"        return getattr(error, self.tree_type + '_path')\\n\", '    path = ()\\n', '        for error in errors:\\n', '            self.add(error)\\n', '        if not self._path_of_(error):\\n', '            self.errors.append(error)\\n', '            super().add(error)\\n', '        node = self.fetch_node_from(path)\\n', '        if node is None:\\n', '            return node.errors\\n', '        context = self\\n', '        for key in path:\\n', '            context = context.get(key, None)\\n', '            if context is None:\\n', '        return context\\n', '        for error in errors:\\n', '            self.add(error)\\n', '        pretty = deepcopy(self.tree)\\n', '        for field in pretty:\\n', '            self._purge_empty_dicts(pretty[field])\\n', '        return pretty\\n', '        error = deepcopy(error)\\n', '        self._rewrite_error_path(error)\\n', '        if error.is_logic_error:\\n', '            self._insert_logic_error(error)\\n', '        elif error.is_group_error:\\n', '            self._insert_group_error(error)\\n', '        elif error.code in self.messages:\\n', '                error.document_path, self._format_message(error.field, error)\\n', '        return self.messages[error.code].format(\\n', '            *error.info, constraint=error.constraint, field=field, value=error.value\\n', '        field = path[0]\\n', '        if len(path) == 1:\\n', '            if field in self.tree:\\n', '                subtree = self.tree[field].pop()\\n', '                self.tree[field] += [node, subtree]\\n', '                self.tree[field] = [node, {}]\\n', '        elif len(path) >= 1:\\n', '            if field not in self.tree:\\n', '                self.tree[field] = [{}]\\n', '            subtree = self.tree[field][-1]\\n', '            if subtree:\\n', '                new = self.__class__(tree=copy(subtree))\\n', '                new = self.__class__()\\n', '            new._insert_error(path[1:], node)\\n', '            subtree.update(new.tree)\\n', '        for child_error in error.child_errors:\\n', '            if child_error.is_logic_error:\\n', '                self._insert_logic_error(child_error)\\n', '            elif child_error.is_group_error:\\n', '                self._insert_group_error(child_error)\\n', '                    child_error.document_path,\\n', '                    self._format_message(child_error.field, child_error),\\n', '        field = error.field\\n', '        self._insert_error(error.document_path, self._format_message(field, error))\\n', '        for definition_errors in error.definitions_errors.values():\\n', '            for child_error in definition_errors:\\n', '                if child_error.is_logic_error:\\n', '                    self._insert_logic_error(child_error)\\n', '                elif child_error.is_group_error:\\n', '                    self._insert_group_error(child_error)\\n', '                        child_error.document_path,\\n', '                        self._format_message(field, child_error),\\n', '        subtree = error_list[-1]\\n', '            for key in subtree:\\n', '                self._purge_empty_dicts(subtree[key])\\n', '        if error.is_logic_error:\\n', '            self._rewrite_logic_error_path(error, offset)\\n', '        elif error.is_group_error:\\n', '            self._rewrite_group_error_path(error, offset)\\n', '        child_start = len(error.document_path) - offset\\n', '        for child_error in error.child_errors:\\n', '            relative_path = child_error.document_path[child_start:]\\n', '            child_error.document_path = error.document_path + relative_path\\n', '            self._rewrite_error_path(child_error, offset)\\n', '        child_start = len(error.document_path) - offset\\n', '        for i, definition_errors in error.definitions_errors.items():\\n', '            if not definition_errors:\\n', \"            nodename = '%s definition %s' % (error.rule, i)\\n\", '            path = error.document_path + (nodename,)\\n', '            for child_error in definition_errors:\\n', '                rel_path = child_error.document_path[child_start:]\\n', '                child_error.document_path = path + rel_path\\n', '                self._rewrite_error_path(child_error, offset + 1)\\n']",
  "context": "operty\n    def pretty_tree(self) -> Dict:\n        pretty = deepcopy(self.tree)\n        for field in pretty:\n            self._pur"
 },
 "146": {
  "name": "error",
  "type": "copy.deepcopy",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "486",
  "column": "8",
  "slicing": "['NORMALIZATION = ErrorDefinition(0x60, None)\\n', 'ERROR_GROUP = ErrorDefinition(0x80, None)\\n', 'LOGICAL = ErrorDefinition(0x90, None)\\n', '        result = defaultdict(ErrorList)  # type: DefaultDict[int, ErrorList]\\n', '        for error in self.child_errors:  # type: ignore\\n', '            i = error.schema_path[len(self.schema_path)]\\n', '            result[i].append(error)\\n', '        return result\\n', '        return bool(self.code & ERROR_GROUP.code)\\n', '        return bool(self.code & LOGICAL.code - ERROR_GROUP.code)\\n', '        return bool(self.code & NORMALIZATION.code)\\n', '        wanted_code = error_definition.code\\n', '        return any(x.code == wanted_code for x in self)\\n', '            for error in self.errors:\\n', '                if item.code == error.code:\\n', '                    return error\\n', '        error_path = self._path_of_(error)\\n', '        key = error_path[self.depth]\\n', '        if key not in self.descendants:\\n', '            self[key] = ErrorTreeNode(error_path, self)\\n', '        node = cast(ErrorTreeNode, self[key])\\n', '        if len(error_path) == self.depth + 1:\\n', '            node.errors.append(error)\\n', '            node.errors.sort()\\n', '            if error.is_group_error:\\n', '                for child_error in error.child_errors:  # type: ignore\\n', '                    self.tree_root.add(child_error)\\n', '            node.add(error)\\n', \"        return getattr(error, self.tree_type + '_path')\\n\", '    path = ()\\n', '        for error in errors:\\n', '            self.add(error)\\n', '        if not self._path_of_(error):\\n', '            self.errors.append(error)\\n', '            super().add(error)\\n', '        node = self.fetch_node_from(path)\\n', '        if node is None:\\n', '            return node.errors\\n', '        context = self\\n', '        for key in path:\\n', '            context = context.get(key, None)\\n', '            if context is None:\\n', '        return context\\n', '        for error in errors:\\n', '            self.add(error)\\n', '        pretty = deepcopy(self.tree)\\n', '        for field in pretty:\\n', '            self._purge_empty_dicts(pretty[field])\\n', '        return pretty\\n', '        error = deepcopy(error)\\n', '        self._rewrite_error_path(error)\\n', '        if error.is_logic_error:\\n', '            self._insert_logic_error(error)\\n', '        elif error.is_group_error:\\n', '            self._insert_group_error(error)\\n', '        elif error.code in self.messages:\\n', '                error.document_path, self._format_message(error.field, error)\\n', '        return self.messages[error.code].format(\\n', '            *error.info, constraint=error.constraint, field=field, value=error.value\\n', '        field = path[0]\\n', '        if len(path) == 1:\\n', '            if field in self.tree:\\n', '                subtree = self.tree[field].pop()\\n', '                self.tree[field] += [node, subtree]\\n', '                self.tree[field] = [node, {}]\\n', '        elif len(path) >= 1:\\n', '            if field not in self.tree:\\n', '                self.tree[field] = [{}]\\n', '            subtree = self.tree[field][-1]\\n', '            if subtree:\\n', '                new = self.__class__(tree=copy(subtree))\\n', '                new = self.__class__()\\n', '            new._insert_error(path[1:], node)\\n', '            subtree.update(new.tree)\\n', '        for child_error in error.child_errors:\\n', '            if child_error.is_logic_error:\\n', '                self._insert_logic_error(child_error)\\n', '            elif child_error.is_group_error:\\n', '                self._insert_group_error(child_error)\\n', '                    child_error.document_path,\\n', '                    self._format_message(child_error.field, child_error),\\n', '        field = error.field\\n', '        self._insert_error(error.document_path, self._format_message(field, error))\\n', '        for definition_errors in error.definitions_errors.values():\\n', '            for child_error in definition_errors:\\n', '                if child_error.is_logic_error:\\n', '                    self._insert_logic_error(child_error)\\n', '                elif child_error.is_group_error:\\n', '                    self._insert_group_error(child_error)\\n', '                        child_error.document_path,\\n', '                        self._format_message(field, child_error),\\n', '        subtree = error_list[-1]\\n', '            for key in subtree:\\n', '                self._purge_empty_dicts(subtree[key])\\n', '        if error.is_logic_error:\\n', '            self._rewrite_logic_error_path(error, offset)\\n', '        elif error.is_group_error:\\n', '            self._rewrite_group_error_path(error, offset)\\n', '        child_start = len(error.document_path) - offset\\n', '        for child_error in error.child_errors:\\n', '            relative_path = child_error.document_path[child_start:]\\n', '            child_error.document_path = error.document_path + relative_path\\n', '            self._rewrite_error_path(child_error, offset)\\n', '        child_start = len(error.document_path) - offset\\n', '        for i, definition_errors in error.definitions_errors.items():\\n', '            if not definition_errors:\\n', \"            nodename = '%s definition %s' % (error.rule, i)\\n\", '            path = error.document_path + (nodename,)\\n', '            for child_error in definition_errors:\\n', '                rel_path = child_error.document_path[child_start:]\\n', '                child_error.document_path = path + rel_path\\n', '                self._rewrite_error_path(child_error, offset + 1)\\n']",
  "context": "   # error paths specific to the handler.\n        error = deepcopy(error)\n\n        self._rewrite_error_path(error)\n\n        "
 },
 "147": {
  "name": "field",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "518",
  "column": "8",
  "slicing": "['NORMALIZATION = ErrorDefinition(0x60, None)\\n', 'ERROR_GROUP = ErrorDefinition(0x80, None)\\n', 'LOGICAL = ErrorDefinition(0x90, None)\\n', '        result = defaultdict(ErrorList)  # type: DefaultDict[int, ErrorList]\\n', '        for error in self.child_errors:  # type: ignore\\n', '            i = error.schema_path[len(self.schema_path)]\\n', '            result[i].append(error)\\n', '        return result\\n', '        return bool(self.code & ERROR_GROUP.code)\\n', '        return bool(self.code & LOGICAL.code - ERROR_GROUP.code)\\n', '        return bool(self.code & NORMALIZATION.code)\\n', '        wanted_code = error_definition.code\\n', '        return any(x.code == wanted_code for x in self)\\n', '            for error in self.errors:\\n', '                if item.code == error.code:\\n', '                    return error\\n', '        error_path = self._path_of_(error)\\n', '        key = error_path[self.depth]\\n', '        if key not in self.descendants:\\n', '            self[key] = ErrorTreeNode(error_path, self)\\n', '        node = cast(ErrorTreeNode, self[key])\\n', '        if len(error_path) == self.depth + 1:\\n', '            node.errors.append(error)\\n', '            node.errors.sort()\\n', '            if error.is_group_error:\\n', '                for child_error in error.child_errors:  # type: ignore\\n', '                    self.tree_root.add(child_error)\\n', '            node.add(error)\\n', \"        return getattr(error, self.tree_type + '_path')\\n\", '    path = ()\\n', '        for error in errors:\\n', '            self.add(error)\\n', '        if not self._path_of_(error):\\n', '            self.errors.append(error)\\n', '            super().add(error)\\n', '        node = self.fetch_node_from(path)\\n', '        if node is None:\\n', '            return node.errors\\n', '        context = self\\n', '        for key in path:\\n', '            context = context.get(key, None)\\n', '            if context is None:\\n', '        return context\\n', '        for error in errors:\\n', '            self.add(error)\\n', '        pretty = deepcopy(self.tree)\\n', '        for field in pretty:\\n', '            self._purge_empty_dicts(pretty[field])\\n', '        return pretty\\n', '        error = deepcopy(error)\\n', '        self._rewrite_error_path(error)\\n', '        if error.is_logic_error:\\n', '            self._insert_logic_error(error)\\n', '        elif error.is_group_error:\\n', '            self._insert_group_error(error)\\n', '        elif error.code in self.messages:\\n', '                error.document_path, self._format_message(error.field, error)\\n', '        return self.messages[error.code].format(\\n', '            *error.info, constraint=error.constraint, field=field, value=error.value\\n', '        field = path[0]\\n', '        if len(path) == 1:\\n', '            if field in self.tree:\\n', '                subtree = self.tree[field].pop()\\n', '                self.tree[field] += [node, subtree]\\n', '                self.tree[field] = [node, {}]\\n', '        elif len(path) >= 1:\\n', '            if field not in self.tree:\\n', '                self.tree[field] = [{}]\\n', '            subtree = self.tree[field][-1]\\n', '            if subtree:\\n', '                new = self.__class__(tree=copy(subtree))\\n', '                new = self.__class__()\\n', '            new._insert_error(path[1:], node)\\n', '            subtree.update(new.tree)\\n', '        for child_error in error.child_errors:\\n', '            if child_error.is_logic_error:\\n', '                self._insert_logic_error(child_error)\\n', '            elif child_error.is_group_error:\\n', '                self._insert_group_error(child_error)\\n', '                    child_error.document_path,\\n', '                    self._format_message(child_error.field, child_error),\\n', '        field = error.field\\n', '        self._insert_error(error.document_path, self._format_message(field, error))\\n', '        for definition_errors in error.definitions_errors.values():\\n', '            for child_error in definition_errors:\\n', '                if child_error.is_logic_error:\\n', '                    self._insert_logic_error(child_error)\\n', '                elif child_error.is_group_error:\\n', '                    self._insert_group_error(child_error)\\n', '                        child_error.document_path,\\n', '                        self._format_message(field, child_error),\\n', '        subtree = error_list[-1]\\n', '            for key in subtree:\\n', '                self._purge_empty_dicts(subtree[key])\\n', '        if error.is_logic_error:\\n', '            self._rewrite_logic_error_path(error, offset)\\n', '        elif error.is_group_error:\\n', '            self._rewrite_group_error_path(error, offset)\\n', '        child_start = len(error.document_path) - offset\\n', '        for child_error in error.child_errors:\\n', '            relative_path = child_error.document_path[child_start:]\\n', '            child_error.document_path = error.document_path + relative_path\\n', '            self._rewrite_error_path(child_error, offset)\\n', '        child_start = len(error.document_path) - offset\\n', '        for i, definition_errors in error.definitions_errors.items():\\n', '            if not definition_errors:\\n', \"            nodename = '%s definition %s' % (error.rule, i)\\n\", '            path = error.document_path + (nodename,)\\n', '            for child_error in definition_errors:\\n', '                rel_path = child_error.document_path[child_start:]\\n', '                child_error.document_path = path + rel_path\\n', '                self._rewrite_error_path(child_error, offset + 1)\\n']",
  "context": "e node: String or dictionary.\n        \"\"\"\n        field = path[0]\n        if len(path) == 1:\n            if field in"
 },
 "148": {
  "name": "subtree",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "528",
  "column": "12",
  "slicing": "['NORMALIZATION = ErrorDefinition(0x60, None)\\n', 'ERROR_GROUP = ErrorDefinition(0x80, None)\\n', 'LOGICAL = ErrorDefinition(0x90, None)\\n', '        result = defaultdict(ErrorList)  # type: DefaultDict[int, ErrorList]\\n', '        for error in self.child_errors:  # type: ignore\\n', '            i = error.schema_path[len(self.schema_path)]\\n', '            result[i].append(error)\\n', '        return result\\n', '        return bool(self.code & ERROR_GROUP.code)\\n', '        return bool(self.code & LOGICAL.code - ERROR_GROUP.code)\\n', '        return bool(self.code & NORMALIZATION.code)\\n', '        wanted_code = error_definition.code\\n', '        return any(x.code == wanted_code for x in self)\\n', '            for error in self.errors:\\n', '                if item.code == error.code:\\n', '                    return error\\n', '        error_path = self._path_of_(error)\\n', '        key = error_path[self.depth]\\n', '        if key not in self.descendants:\\n', '            self[key] = ErrorTreeNode(error_path, self)\\n', '        node = cast(ErrorTreeNode, self[key])\\n', '        if len(error_path) == self.depth + 1:\\n', '            node.errors.append(error)\\n', '            node.errors.sort()\\n', '            if error.is_group_error:\\n', '                for child_error in error.child_errors:  # type: ignore\\n', '                    self.tree_root.add(child_error)\\n', '            node.add(error)\\n', \"        return getattr(error, self.tree_type + '_path')\\n\", '    path = ()\\n', '        for error in errors:\\n', '            self.add(error)\\n', '        if not self._path_of_(error):\\n', '            self.errors.append(error)\\n', '            super().add(error)\\n', '        node = self.fetch_node_from(path)\\n', '        if node is None:\\n', '            return node.errors\\n', '        context = self\\n', '        for key in path:\\n', '            context = context.get(key, None)\\n', '            if context is None:\\n', '        return context\\n', '        for error in errors:\\n', '            self.add(error)\\n', '        pretty = deepcopy(self.tree)\\n', '        for field in pretty:\\n', '            self._purge_empty_dicts(pretty[field])\\n', '        return pretty\\n', '        error = deepcopy(error)\\n', '        self._rewrite_error_path(error)\\n', '        if error.is_logic_error:\\n', '            self._insert_logic_error(error)\\n', '        elif error.is_group_error:\\n', '            self._insert_group_error(error)\\n', '        elif error.code in self.messages:\\n', '                error.document_path, self._format_message(error.field, error)\\n', '        return self.messages[error.code].format(\\n', '            *error.info, constraint=error.constraint, field=field, value=error.value\\n', '        field = path[0]\\n', '        if len(path) == 1:\\n', '            if field in self.tree:\\n', '                subtree = self.tree[field].pop()\\n', '                self.tree[field] += [node, subtree]\\n', '                self.tree[field] = [node, {}]\\n', '        elif len(path) >= 1:\\n', '            if field not in self.tree:\\n', '                self.tree[field] = [{}]\\n', '            subtree = self.tree[field][-1]\\n', '            if subtree:\\n', '                new = self.__class__(tree=copy(subtree))\\n', '                new = self.__class__()\\n', '            new._insert_error(path[1:], node)\\n', '            subtree.update(new.tree)\\n', '        for child_error in error.child_errors:\\n', '            if child_error.is_logic_error:\\n', '                self._insert_logic_error(child_error)\\n', '            elif child_error.is_group_error:\\n', '                self._insert_group_error(child_error)\\n', '                    child_error.document_path,\\n', '                    self._format_message(child_error.field, child_error),\\n', '        field = error.field\\n', '        self._insert_error(error.document_path, self._format_message(field, error))\\n', '        for definition_errors in error.definitions_errors.values():\\n', '            for child_error in definition_errors:\\n', '                if child_error.is_logic_error:\\n', '                    self._insert_logic_error(child_error)\\n', '                elif child_error.is_group_error:\\n', '                    self._insert_group_error(child_error)\\n', '                        child_error.document_path,\\n', '                        self._format_message(field, child_error),\\n', '        subtree = error_list[-1]\\n', '            for key in subtree:\\n', '                self._purge_empty_dicts(subtree[key])\\n', '        if error.is_logic_error:\\n', '            self._rewrite_logic_error_path(error, offset)\\n', '        elif error.is_group_error:\\n', '            self._rewrite_group_error_path(error, offset)\\n', '        child_start = len(error.document_path) - offset\\n', '        for child_error in error.child_errors:\\n', '            relative_path = child_error.document_path[child_start:]\\n', '            child_error.document_path = error.document_path + relative_path\\n', '            self._rewrite_error_path(child_error, offset)\\n', '        child_start = len(error.document_path) - offset\\n', '        for i, definition_errors in error.definitions_errors.items():\\n', '            if not definition_errors:\\n', \"            nodename = '%s definition %s' % (error.rule, i)\\n\", '            path = error.document_path + (nodename,)\\n', '            for child_error in definition_errors:\\n', '                rel_path = child_error.document_path[child_start:]\\n', '                child_error.document_path = path + rel_path\\n', '                self._rewrite_error_path(child_error, offset + 1)\\n']",
  "context": "              self.tree[field] = [{}]\n            subtree = self.tree[field][-1]\n\n            if subtree:\n                new = sel"
 },
 "149": {
  "name": "subtree",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "566",
  "column": "8",
  "slicing": "['NORMALIZATION = ErrorDefinition(0x60, None)\\n', 'ERROR_GROUP = ErrorDefinition(0x80, None)\\n', 'LOGICAL = ErrorDefinition(0x90, None)\\n', '        result = defaultdict(ErrorList)  # type: DefaultDict[int, ErrorList]\\n', '        for error in self.child_errors:  # type: ignore\\n', '            i = error.schema_path[len(self.schema_path)]\\n', '            result[i].append(error)\\n', '        return result\\n', '        return bool(self.code & ERROR_GROUP.code)\\n', '        return bool(self.code & LOGICAL.code - ERROR_GROUP.code)\\n', '        return bool(self.code & NORMALIZATION.code)\\n', '        wanted_code = error_definition.code\\n', '        return any(x.code == wanted_code for x in self)\\n', '            for error in self.errors:\\n', '                if item.code == error.code:\\n', '                    return error\\n', '        error_path = self._path_of_(error)\\n', '        key = error_path[self.depth]\\n', '        if key not in self.descendants:\\n', '            self[key] = ErrorTreeNode(error_path, self)\\n', '        node = cast(ErrorTreeNode, self[key])\\n', '        if len(error_path) == self.depth + 1:\\n', '            node.errors.append(error)\\n', '            node.errors.sort()\\n', '            if error.is_group_error:\\n', '                for child_error in error.child_errors:  # type: ignore\\n', '                    self.tree_root.add(child_error)\\n', '            node.add(error)\\n', \"        return getattr(error, self.tree_type + '_path')\\n\", '    path = ()\\n', '        for error in errors:\\n', '            self.add(error)\\n', '        if not self._path_of_(error):\\n', '            self.errors.append(error)\\n', '            super().add(error)\\n', '        node = self.fetch_node_from(path)\\n', '        if node is None:\\n', '            return node.errors\\n', '        context = self\\n', '        for key in path:\\n', '            context = context.get(key, None)\\n', '            if context is None:\\n', '        return context\\n', '        for error in errors:\\n', '            self.add(error)\\n', '        pretty = deepcopy(self.tree)\\n', '        for field in pretty:\\n', '            self._purge_empty_dicts(pretty[field])\\n', '        return pretty\\n', '        error = deepcopy(error)\\n', '        self._rewrite_error_path(error)\\n', '        if error.is_logic_error:\\n', '            self._insert_logic_error(error)\\n', '        elif error.is_group_error:\\n', '            self._insert_group_error(error)\\n', '        elif error.code in self.messages:\\n', '                error.document_path, self._format_message(error.field, error)\\n', '        return self.messages[error.code].format(\\n', '            *error.info, constraint=error.constraint, field=field, value=error.value\\n', '        field = path[0]\\n', '        if len(path) == 1:\\n', '            if field in self.tree:\\n', '                subtree = self.tree[field].pop()\\n', '                self.tree[field] += [node, subtree]\\n', '                self.tree[field] = [node, {}]\\n', '        elif len(path) >= 1:\\n', '            if field not in self.tree:\\n', '                self.tree[field] = [{}]\\n', '            subtree = self.tree[field][-1]\\n', '            if subtree:\\n', '                new = self.__class__(tree=copy(subtree))\\n', '                new = self.__class__()\\n', '            new._insert_error(path[1:], node)\\n', '            subtree.update(new.tree)\\n', '        for child_error in error.child_errors:\\n', '            if child_error.is_logic_error:\\n', '                self._insert_logic_error(child_error)\\n', '            elif child_error.is_group_error:\\n', '                self._insert_group_error(child_error)\\n', '                    child_error.document_path,\\n', '                    self._format_message(child_error.field, child_error),\\n', '        field = error.field\\n', '        self._insert_error(error.document_path, self._format_message(field, error))\\n', '        for definition_errors in error.definitions_errors.values():\\n', '            for child_error in definition_errors:\\n', '                if child_error.is_logic_error:\\n', '                    self._insert_logic_error(child_error)\\n', '                elif child_error.is_group_error:\\n', '                    self._insert_group_error(child_error)\\n', '                        child_error.document_path,\\n', '                        self._format_message(field, child_error),\\n', '        subtree = error_list[-1]\\n', '            for key in subtree:\\n', '                self._purge_empty_dicts(subtree[key])\\n', '        if error.is_logic_error:\\n', '            self._rewrite_logic_error_path(error, offset)\\n', '        elif error.is_group_error:\\n', '            self._rewrite_group_error_path(error, offset)\\n', '        child_start = len(error.document_path) - offset\\n', '        for child_error in error.child_errors:\\n', '            relative_path = child_error.document_path[child_start:]\\n', '            child_error.document_path = error.document_path + relative_path\\n', '            self._rewrite_error_path(child_error, offset)\\n', '        child_start = len(error.document_path) - offset\\n', '        for i, definition_errors in error.definitions_errors.items():\\n', '            if not definition_errors:\\n', \"            nodename = '%s definition %s' % (error.rule, i)\\n\", '            path = error.document_path + (nodename,)\\n', '            for child_error in definition_errors:\\n', '                rel_path = child_error.document_path[child_start:]\\n', '                child_error.document_path = path + rel_path\\n', '                self._rewrite_error_path(child_error, offset + 1)\\n']",
  "context": "def _purge_empty_dicts(self, error_list):\n        subtree = error_list[-1]\n        if not error_list[-1]:\n            error_l"
 },
 "150": {
  "name": "child_start",
  "type": "int",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "583",
  "column": "8",
  "slicing": "['NORMALIZATION = ErrorDefinition(0x60, None)\\n', 'ERROR_GROUP = ErrorDefinition(0x80, None)\\n', 'LOGICAL = ErrorDefinition(0x90, None)\\n', '        result = defaultdict(ErrorList)  # type: DefaultDict[int, ErrorList]\\n', '        for error in self.child_errors:  # type: ignore\\n', '            i = error.schema_path[len(self.schema_path)]\\n', '            result[i].append(error)\\n', '        return result\\n', '        return bool(self.code & ERROR_GROUP.code)\\n', '        return bool(self.code & LOGICAL.code - ERROR_GROUP.code)\\n', '        return bool(self.code & NORMALIZATION.code)\\n', '        wanted_code = error_definition.code\\n', '        return any(x.code == wanted_code for x in self)\\n', '            for error in self.errors:\\n', '                if item.code == error.code:\\n', '                    return error\\n', '        error_path = self._path_of_(error)\\n', '        key = error_path[self.depth]\\n', '        if key not in self.descendants:\\n', '            self[key] = ErrorTreeNode(error_path, self)\\n', '        node = cast(ErrorTreeNode, self[key])\\n', '        if len(error_path) == self.depth + 1:\\n', '            node.errors.append(error)\\n', '            node.errors.sort()\\n', '            if error.is_group_error:\\n', '                for child_error in error.child_errors:  # type: ignore\\n', '                    self.tree_root.add(child_error)\\n', '            node.add(error)\\n', \"        return getattr(error, self.tree_type + '_path')\\n\", '    path = ()\\n', '        for error in errors:\\n', '            self.add(error)\\n', '        if not self._path_of_(error):\\n', '            self.errors.append(error)\\n', '            super().add(error)\\n', '        node = self.fetch_node_from(path)\\n', '        if node is None:\\n', '            return node.errors\\n', '        context = self\\n', '        for key in path:\\n', '            context = context.get(key, None)\\n', '            if context is None:\\n', '        return context\\n', '        for error in errors:\\n', '            self.add(error)\\n', '        pretty = deepcopy(self.tree)\\n', '        for field in pretty:\\n', '            self._purge_empty_dicts(pretty[field])\\n', '        return pretty\\n', '        error = deepcopy(error)\\n', '        self._rewrite_error_path(error)\\n', '        if error.is_logic_error:\\n', '            self._insert_logic_error(error)\\n', '        elif error.is_group_error:\\n', '            self._insert_group_error(error)\\n', '        elif error.code in self.messages:\\n', '                error.document_path, self._format_message(error.field, error)\\n', '        return self.messages[error.code].format(\\n', '            *error.info, constraint=error.constraint, field=field, value=error.value\\n', '        field = path[0]\\n', '        if len(path) == 1:\\n', '            if field in self.tree:\\n', '                subtree = self.tree[field].pop()\\n', '                self.tree[field] += [node, subtree]\\n', '                self.tree[field] = [node, {}]\\n', '        elif len(path) >= 1:\\n', '            if field not in self.tree:\\n', '                self.tree[field] = [{}]\\n', '            subtree = self.tree[field][-1]\\n', '            if subtree:\\n', '                new = self.__class__(tree=copy(subtree))\\n', '                new = self.__class__()\\n', '            new._insert_error(path[1:], node)\\n', '            subtree.update(new.tree)\\n', '        for child_error in error.child_errors:\\n', '            if child_error.is_logic_error:\\n', '                self._insert_logic_error(child_error)\\n', '            elif child_error.is_group_error:\\n', '                self._insert_group_error(child_error)\\n', '                    child_error.document_path,\\n', '                    self._format_message(child_error.field, child_error),\\n', '        field = error.field\\n', '        self._insert_error(error.document_path, self._format_message(field, error))\\n', '        for definition_errors in error.definitions_errors.values():\\n', '            for child_error in definition_errors:\\n', '                if child_error.is_logic_error:\\n', '                    self._insert_logic_error(child_error)\\n', '                elif child_error.is_group_error:\\n', '                    self._insert_group_error(child_error)\\n', '                        child_error.document_path,\\n', '                        self._format_message(field, child_error),\\n', '        subtree = error_list[-1]\\n', '            for key in subtree:\\n', '                self._purge_empty_dicts(subtree[key])\\n', '        if error.is_logic_error:\\n', '            self._rewrite_logic_error_path(error, offset)\\n', '        elif error.is_group_error:\\n', '            self._rewrite_group_error_path(error, offset)\\n', '        child_start = len(error.document_path) - offset\\n', '        for child_error in error.child_errors:\\n', '            relative_path = child_error.document_path[child_start:]\\n', '            child_error.document_path = error.document_path + relative_path\\n', '            self._rewrite_error_path(child_error, offset)\\n', '        child_start = len(error.document_path) - offset\\n', '        for i, definition_errors in error.definitions_errors.items():\\n', '            if not definition_errors:\\n', \"            nodename = '%s definition %s' % (error.rule, i)\\n\", '            path = error.document_path + (nodename,)\\n', '            for child_error in definition_errors:\\n', '                rel_path = child_error.document_path[child_start:]\\n', '                child_error.document_path = path + rel_path\\n', '                self._rewrite_error_path(child_error, offset + 1)\\n']",
  "context": "_group_error_path(self, error, offset=0):\n        child_start = len(error.document_path) - offset\n\n        for child_error in error.child_errors:\n  "
 },
 "151": {
  "name": "relative_path",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "586",
  "column": "12",
  "slicing": "['NORMALIZATION = ErrorDefinition(0x60, None)\\n', 'ERROR_GROUP = ErrorDefinition(0x80, None)\\n', 'LOGICAL = ErrorDefinition(0x90, None)\\n', '        result = defaultdict(ErrorList)  # type: DefaultDict[int, ErrorList]\\n', '        for error in self.child_errors:  # type: ignore\\n', '            i = error.schema_path[len(self.schema_path)]\\n', '            result[i].append(error)\\n', '        return result\\n', '        return bool(self.code & ERROR_GROUP.code)\\n', '        return bool(self.code & LOGICAL.code - ERROR_GROUP.code)\\n', '        return bool(self.code & NORMALIZATION.code)\\n', '        wanted_code = error_definition.code\\n', '        return any(x.code == wanted_code for x in self)\\n', '            for error in self.errors:\\n', '                if item.code == error.code:\\n', '                    return error\\n', '        error_path = self._path_of_(error)\\n', '        key = error_path[self.depth]\\n', '        if key not in self.descendants:\\n', '            self[key] = ErrorTreeNode(error_path, self)\\n', '        node = cast(ErrorTreeNode, self[key])\\n', '        if len(error_path) == self.depth + 1:\\n', '            node.errors.append(error)\\n', '            node.errors.sort()\\n', '            if error.is_group_error:\\n', '                for child_error in error.child_errors:  # type: ignore\\n', '                    self.tree_root.add(child_error)\\n', '            node.add(error)\\n', \"        return getattr(error, self.tree_type + '_path')\\n\", '    path = ()\\n', '        for error in errors:\\n', '            self.add(error)\\n', '        if not self._path_of_(error):\\n', '            self.errors.append(error)\\n', '            super().add(error)\\n', '        node = self.fetch_node_from(path)\\n', '        if node is None:\\n', '            return node.errors\\n', '        context = self\\n', '        for key in path:\\n', '            context = context.get(key, None)\\n', '            if context is None:\\n', '        return context\\n', '        for error in errors:\\n', '            self.add(error)\\n', '        pretty = deepcopy(self.tree)\\n', '        for field in pretty:\\n', '            self._purge_empty_dicts(pretty[field])\\n', '        return pretty\\n', '        error = deepcopy(error)\\n', '        self._rewrite_error_path(error)\\n', '        if error.is_logic_error:\\n', '            self._insert_logic_error(error)\\n', '        elif error.is_group_error:\\n', '            self._insert_group_error(error)\\n', '        elif error.code in self.messages:\\n', '                error.document_path, self._format_message(error.field, error)\\n', '        return self.messages[error.code].format(\\n', '            *error.info, constraint=error.constraint, field=field, value=error.value\\n', '        field = path[0]\\n', '        if len(path) == 1:\\n', '            if field in self.tree:\\n', '                subtree = self.tree[field].pop()\\n', '                self.tree[field] += [node, subtree]\\n', '                self.tree[field] = [node, {}]\\n', '        elif len(path) >= 1:\\n', '            if field not in self.tree:\\n', '                self.tree[field] = [{}]\\n', '            subtree = self.tree[field][-1]\\n', '            if subtree:\\n', '                new = self.__class__(tree=copy(subtree))\\n', '                new = self.__class__()\\n', '            new._insert_error(path[1:], node)\\n', '            subtree.update(new.tree)\\n', '        for child_error in error.child_errors:\\n', '            if child_error.is_logic_error:\\n', '                self._insert_logic_error(child_error)\\n', '            elif child_error.is_group_error:\\n', '                self._insert_group_error(child_error)\\n', '                    child_error.document_path,\\n', '                    self._format_message(child_error.field, child_error),\\n', '        field = error.field\\n', '        self._insert_error(error.document_path, self._format_message(field, error))\\n', '        for definition_errors in error.definitions_errors.values():\\n', '            for child_error in definition_errors:\\n', '                if child_error.is_logic_error:\\n', '                    self._insert_logic_error(child_error)\\n', '                elif child_error.is_group_error:\\n', '                    self._insert_group_error(child_error)\\n', '                        child_error.document_path,\\n', '                        self._format_message(field, child_error),\\n', '        subtree = error_list[-1]\\n', '            for key in subtree:\\n', '                self._purge_empty_dicts(subtree[key])\\n', '        if error.is_logic_error:\\n', '            self._rewrite_logic_error_path(error, offset)\\n', '        elif error.is_group_error:\\n', '            self._rewrite_group_error_path(error, offset)\\n', '        child_start = len(error.document_path) - offset\\n', '        for child_error in error.child_errors:\\n', '            relative_path = child_error.document_path[child_start:]\\n', '            child_error.document_path = error.document_path + relative_path\\n', '            self._rewrite_error_path(child_error, offset)\\n', '        child_start = len(error.document_path) - offset\\n', '        for i, definition_errors in error.definitions_errors.items():\\n', '            if not definition_errors:\\n', \"            nodename = '%s definition %s' % (error.rule, i)\\n\", '            path = error.document_path + (nodename,)\\n', '            for child_error in definition_errors:\\n', '                rel_path = child_error.document_path[child_start:]\\n', '                child_error.document_path = path + rel_path\\n', '                self._rewrite_error_path(child_error, offset + 1)\\n']",
  "context": "or child_error in error.child_errors:\n            relative_path = child_error.document_path[child_start:]\n            child_error.document_path = error.docu"
 },
 "152": {
  "name": "child_start",
  "type": "int",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "592",
  "column": "8",
  "slicing": "['NORMALIZATION = ErrorDefinition(0x60, None)\\n', 'ERROR_GROUP = ErrorDefinition(0x80, None)\\n', 'LOGICAL = ErrorDefinition(0x90, None)\\n', '        result = defaultdict(ErrorList)  # type: DefaultDict[int, ErrorList]\\n', '        for error in self.child_errors:  # type: ignore\\n', '            i = error.schema_path[len(self.schema_path)]\\n', '            result[i].append(error)\\n', '        return result\\n', '        return bool(self.code & ERROR_GROUP.code)\\n', '        return bool(self.code & LOGICAL.code - ERROR_GROUP.code)\\n', '        return bool(self.code & NORMALIZATION.code)\\n', '        wanted_code = error_definition.code\\n', '        return any(x.code == wanted_code for x in self)\\n', '            for error in self.errors:\\n', '                if item.code == error.code:\\n', '                    return error\\n', '        error_path = self._path_of_(error)\\n', '        key = error_path[self.depth]\\n', '        if key not in self.descendants:\\n', '            self[key] = ErrorTreeNode(error_path, self)\\n', '        node = cast(ErrorTreeNode, self[key])\\n', '        if len(error_path) == self.depth + 1:\\n', '            node.errors.append(error)\\n', '            node.errors.sort()\\n', '            if error.is_group_error:\\n', '                for child_error in error.child_errors:  # type: ignore\\n', '                    self.tree_root.add(child_error)\\n', '            node.add(error)\\n', \"        return getattr(error, self.tree_type + '_path')\\n\", '    path = ()\\n', '        for error in errors:\\n', '            self.add(error)\\n', '        if not self._path_of_(error):\\n', '            self.errors.append(error)\\n', '            super().add(error)\\n', '        node = self.fetch_node_from(path)\\n', '        if node is None:\\n', '            return node.errors\\n', '        context = self\\n', '        for key in path:\\n', '            context = context.get(key, None)\\n', '            if context is None:\\n', '        return context\\n', '        for error in errors:\\n', '            self.add(error)\\n', '        pretty = deepcopy(self.tree)\\n', '        for field in pretty:\\n', '            self._purge_empty_dicts(pretty[field])\\n', '        return pretty\\n', '        error = deepcopy(error)\\n', '        self._rewrite_error_path(error)\\n', '        if error.is_logic_error:\\n', '            self._insert_logic_error(error)\\n', '        elif error.is_group_error:\\n', '            self._insert_group_error(error)\\n', '        elif error.code in self.messages:\\n', '                error.document_path, self._format_message(error.field, error)\\n', '        return self.messages[error.code].format(\\n', '            *error.info, constraint=error.constraint, field=field, value=error.value\\n', '        field = path[0]\\n', '        if len(path) == 1:\\n', '            if field in self.tree:\\n', '                subtree = self.tree[field].pop()\\n', '                self.tree[field] += [node, subtree]\\n', '                self.tree[field] = [node, {}]\\n', '        elif len(path) >= 1:\\n', '            if field not in self.tree:\\n', '                self.tree[field] = [{}]\\n', '            subtree = self.tree[field][-1]\\n', '            if subtree:\\n', '                new = self.__class__(tree=copy(subtree))\\n', '                new = self.__class__()\\n', '            new._insert_error(path[1:], node)\\n', '            subtree.update(new.tree)\\n', '        for child_error in error.child_errors:\\n', '            if child_error.is_logic_error:\\n', '                self._insert_logic_error(child_error)\\n', '            elif child_error.is_group_error:\\n', '                self._insert_group_error(child_error)\\n', '                    child_error.document_path,\\n', '                    self._format_message(child_error.field, child_error),\\n', '        field = error.field\\n', '        self._insert_error(error.document_path, self._format_message(field, error))\\n', '        for definition_errors in error.definitions_errors.values():\\n', '            for child_error in definition_errors:\\n', '                if child_error.is_logic_error:\\n', '                    self._insert_logic_error(child_error)\\n', '                elif child_error.is_group_error:\\n', '                    self._insert_group_error(child_error)\\n', '                        child_error.document_path,\\n', '                        self._format_message(field, child_error),\\n', '        subtree = error_list[-1]\\n', '            for key in subtree:\\n', '                self._purge_empty_dicts(subtree[key])\\n', '        if error.is_logic_error:\\n', '            self._rewrite_logic_error_path(error, offset)\\n', '        elif error.is_group_error:\\n', '            self._rewrite_group_error_path(error, offset)\\n', '        child_start = len(error.document_path) - offset\\n', '        for child_error in error.child_errors:\\n', '            relative_path = child_error.document_path[child_start:]\\n', '            child_error.document_path = error.document_path + relative_path\\n', '            self._rewrite_error_path(child_error, offset)\\n', '        child_start = len(error.document_path) - offset\\n', '        for i, definition_errors in error.definitions_errors.items():\\n', '            if not definition_errors:\\n', \"            nodename = '%s definition %s' % (error.rule, i)\\n\", '            path = error.document_path + (nodename,)\\n', '            for child_error in definition_errors:\\n', '                rel_path = child_error.document_path[child_start:]\\n', '                child_error.document_path = path + rel_path\\n', '                self._rewrite_error_path(child_error, offset + 1)\\n']",
  "context": "_logic_error_path(self, error, offset=0):\n        child_start = len(error.document_path) - offset\n\n        for i, definition_errors in error.definit"
 },
 "153": {
  "name": "rel_path",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "602",
  "column": "16",
  "slicing": "['NORMALIZATION = ErrorDefinition(0x60, None)\\n', 'ERROR_GROUP = ErrorDefinition(0x80, None)\\n', 'LOGICAL = ErrorDefinition(0x90, None)\\n', '        result = defaultdict(ErrorList)  # type: DefaultDict[int, ErrorList]\\n', '        for error in self.child_errors:  # type: ignore\\n', '            i = error.schema_path[len(self.schema_path)]\\n', '            result[i].append(error)\\n', '        return result\\n', '        return bool(self.code & ERROR_GROUP.code)\\n', '        return bool(self.code & LOGICAL.code - ERROR_GROUP.code)\\n', '        return bool(self.code & NORMALIZATION.code)\\n', '        wanted_code = error_definition.code\\n', '        return any(x.code == wanted_code for x in self)\\n', '            for error in self.errors:\\n', '                if item.code == error.code:\\n', '                    return error\\n', '        error_path = self._path_of_(error)\\n', '        key = error_path[self.depth]\\n', '        if key not in self.descendants:\\n', '            self[key] = ErrorTreeNode(error_path, self)\\n', '        node = cast(ErrorTreeNode, self[key])\\n', '        if len(error_path) == self.depth + 1:\\n', '            node.errors.append(error)\\n', '            node.errors.sort()\\n', '            if error.is_group_error:\\n', '                for child_error in error.child_errors:  # type: ignore\\n', '                    self.tree_root.add(child_error)\\n', '            node.add(error)\\n', \"        return getattr(error, self.tree_type + '_path')\\n\", '    path = ()\\n', '        for error in errors:\\n', '            self.add(error)\\n', '        if not self._path_of_(error):\\n', '            self.errors.append(error)\\n', '            super().add(error)\\n', '        node = self.fetch_node_from(path)\\n', '        if node is None:\\n', '            return node.errors\\n', '        context = self\\n', '        for key in path:\\n', '            context = context.get(key, None)\\n', '            if context is None:\\n', '        return context\\n', '        for error in errors:\\n', '            self.add(error)\\n', '        pretty = deepcopy(self.tree)\\n', '        for field in pretty:\\n', '            self._purge_empty_dicts(pretty[field])\\n', '        return pretty\\n', '        error = deepcopy(error)\\n', '        self._rewrite_error_path(error)\\n', '        if error.is_logic_error:\\n', '            self._insert_logic_error(error)\\n', '        elif error.is_group_error:\\n', '            self._insert_group_error(error)\\n', '        elif error.code in self.messages:\\n', '                error.document_path, self._format_message(error.field, error)\\n', '        return self.messages[error.code].format(\\n', '            *error.info, constraint=error.constraint, field=field, value=error.value\\n', '        field = path[0]\\n', '        if len(path) == 1:\\n', '            if field in self.tree:\\n', '                subtree = self.tree[field].pop()\\n', '                self.tree[field] += [node, subtree]\\n', '                self.tree[field] = [node, {}]\\n', '        elif len(path) >= 1:\\n', '            if field not in self.tree:\\n', '                self.tree[field] = [{}]\\n', '            subtree = self.tree[field][-1]\\n', '            if subtree:\\n', '                new = self.__class__(tree=copy(subtree))\\n', '                new = self.__class__()\\n', '            new._insert_error(path[1:], node)\\n', '            subtree.update(new.tree)\\n', '        for child_error in error.child_errors:\\n', '            if child_error.is_logic_error:\\n', '                self._insert_logic_error(child_error)\\n', '            elif child_error.is_group_error:\\n', '                self._insert_group_error(child_error)\\n', '                    child_error.document_path,\\n', '                    self._format_message(child_error.field, child_error),\\n', '        field = error.field\\n', '        self._insert_error(error.document_path, self._format_message(field, error))\\n', '        for definition_errors in error.definitions_errors.values():\\n', '            for child_error in definition_errors:\\n', '                if child_error.is_logic_error:\\n', '                    self._insert_logic_error(child_error)\\n', '                elif child_error.is_group_error:\\n', '                    self._insert_group_error(child_error)\\n', '                        child_error.document_path,\\n', '                        self._format_message(field, child_error),\\n', '        subtree = error_list[-1]\\n', '            for key in subtree:\\n', '                self._purge_empty_dicts(subtree[key])\\n', '        if error.is_logic_error:\\n', '            self._rewrite_logic_error_path(error, offset)\\n', '        elif error.is_group_error:\\n', '            self._rewrite_group_error_path(error, offset)\\n', '        child_start = len(error.document_path) - offset\\n', '        for child_error in error.child_errors:\\n', '            relative_path = child_error.document_path[child_start:]\\n', '            child_error.document_path = error.document_path + relative_path\\n', '            self._rewrite_error_path(child_error, offset)\\n', '        child_start = len(error.document_path) - offset\\n', '        for i, definition_errors in error.definitions_errors.items():\\n', '            if not definition_errors:\\n', \"            nodename = '%s definition %s' % (error.rule, i)\\n\", '            path = error.document_path + (nodename,)\\n', '            for child_error in definition_errors:\\n', '                rel_path = child_error.document_path[child_start:]\\n', '                child_error.document_path = path + rel_path\\n', '                self._rewrite_error_path(child_error, offset + 1)\\n']",
  "context": "child_error in definition_errors:\n                rel_path = child_error.document_path[child_start:]\n                child_error.document_path = path +"
 },
 "154": {
  "name": "toy_error_handler",
  "type": "ToyErrorHandler",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "45",
  "column": "0",
  "slicing": "['toy_error_handler = errors.ToyErrorHandler()\\n', \"                    'error_handler': toy_error_handler,\\n\"]",
  "context": "e's arguments are validated against this schema:\"\ntoy_error_handler = errors.ToyErrorHandler()\n\n\n_ellipsis = typing.Tuple[int, ...].__args__[-1]\n"
 },
 "155": {
  "name": "_ellipsis",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "48",
  "column": "0",
  "slicing": "['_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', '                if args[-1] is _ellipsis:\\n']",
  "context": ":\"\ntoy_error_handler = errors.ToyErrorHandler()\n\n\n_ellipsis = typing.Tuple[int, ...].__args__[-1]\n\n\ndef dummy_for_rule_validation(rule_constraints: "
 },
 "156": {
  "name": "rule_constraints",
  "type": "str",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "51",
  "column": "30",
  "slicing": "['def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f.__doc__ = rule_constraints\\n']",
  "context": "...].__args__[-1]\n\n\ndef dummy_for_rule_validation(rule_constraints: str) -> Callable:\n    def dummy(self, constraint, field, value):\n   "
 },
 "157": {
  "name": "f",
  "type": "dummy",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "59",
  "column": "4",
  "slicing": "['    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n']",
  "context": " in its '\n            'docstring.'\n        )\n\n    f = dummy\n    f.__doc__ = rule_constraints\n    return f\n\n\n# "
 },
 "158": {
  "name": "_normalized_rulesset_cache",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "79",
  "column": "0",
  "slicing": "['_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    _normalized_rulesset_cache[_hash] = rules\\n']",
  "context": "       contains errors. \"\"\"\n\n\n# Schema mangling\n\n\n_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\n\n\ndef normalize_rulesset(rules: RulesSet) -> Rules"
 },
 "159": {
  "name": "rules",
  "type": "cerberus.typing.RulesSet",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "82",
  "column": "23",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "ict[int, Dict[str, Any]]\n\n\ndef normalize_rulesset(rules: RulesSet) -> RulesSet:\n    \"\"\" Transforms a set of rules into a canonical"
 },
 "160": {
  "name": "_hash",
  "type": "cerberus.utils.schema_hash",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "87",
  "column": "4",
  "slicing": "['    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    _normalized_rulesset_cache[_hash] = rules\\n']",
  "context": "ce(rules, abc.Mapping):\n        return rules\n\n    _hash = schema_hash(rules)\n    if _hash in _normalized_rulesset_cache:\n      "
 },
 "161": {
  "name": "rules",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "91",
  "column": "4",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "    return _normalized_rulesset_cache[_hash]\n\n    rules = dict(rules)\n\n    rules_with_whitespace = [x for x in rules if "
 },
 "162": {
  "name": "rules_with_whitespace",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "93",
  "column": "4",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "lesset_cache[_hash]\n\n    rules = dict(rules)\n\n    rules_with_whitespace = [x for x in rules if \" \" in x]\n    if rules_with_whitespace:\n        for rule in "
 },
 "163": {
  "name": "constraint",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "102",
  "column": "8",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "ndencies\"],)\n\n    if \"excludes\" in rules:\n        constraint = rules[\"excludes\"]\n        if isinstance(constraint, str) or not isin"
 },
 "164": {
  "name": "constraint",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "107",
  "column": "8",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": " = (constraint,)\n\n    if \"type\" in rules:\n        constraint = rules[\"type\"]\n        if not (isinstance(constraint, Iterable) a"
 },
 "165": {
  "name": "schema",
  "type": "cerberus.typing.Schema",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "119",
  "column": "21",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "] = rules\n    return rules\n\n\ndef normalize_schema(schema: Schema) -> Schema:\n    \"\"\" Transforms a schema into a canonical form."
 },
 "166": {
  "name": "rules",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "124",
  "column": "33",
  "slicing": "['def _expand_generic_type_aliases(rules: Dict[str, Any]) -> None:\\n']",
  "context": "chema.items()}\n\n\ndef _expand_generic_type_aliases(rules: Dict[str, Any]) -> None:\n    compound_types = []\n    plain_types = []\n    i"
 },
 "167": {
  "name": "compound_types",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "125",
  "column": "4",
  "slicing": "['    compound_types = []\\n', '                compound_types.append(\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '                    compound_types.append(\\n', '                    compound_types.append(\\n', '    if compound_types or is_nullable:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n']",
  "context": "_type_aliases(rules: Dict[str, Any]) -> None:\n    compound_types = []\n    plain_types = []\n    is_nullable = False\n\n    "
 },
 "168": {
  "name": "plain_types",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "126",
  "column": "4",
  "slicing": "['    plain_types = []\\n', '                plain_types.append(origin)\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        rules[\"type\"] = tuple(plain_types)\\n']",
  "context": "t[str, Any]) -> None:\n    compound_types = []\n    plain_types = []\n    is_nullable = False\n\n    for constraint in _fl"
 },
 "169": {
  "name": "is_nullable",
  "type": "bool",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "127",
  "column": "4",
  "slicing": "['    is_nullable = False\\n', '    if compound_types or is_nullable:\\n', '        if is_nullable:\\n']",
  "context": "\n    compound_types = []\n    plain_types = []\n    is_nullable = False\n\n    for constraint in _flatten_Union_and_Optional"
 },
 "170": {
  "name": "origin",
  "type": "cerberus.platform.get_type_origin",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "133",
  "column": "12",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "instance(constraint, _GenericAlias):\n\n            origin = get_type_origin(constraint)\n            args = get_type_args(constraint)\n\n    "
 },
 "171": {
  "name": "args",
  "type": "cerberus.platform.get_type_args",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "134",
  "column": "12",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": " origin = get_type_origin(constraint)\n            args = get_type_args(constraint)\n\n            # mappings, e.g. Mapping[int, str]\n  "
 },
 "172": {
  "name": "is_nullable",
  "type": "bool",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "171",
  "column": "12",
  "slicing": "['            is_nullable = True\\n', '    if compound_types or is_nullable:\\n', '        if is_nullable:\\n']",
  "context": "nstraint is NoneType:  # type: ignore\n            is_nullable = True\n\n        elif isinstance(constraint, ForwardRef):\n"
 },
 "173": {
  "name": "rules",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "205",
  "column": "30",
  "slicing": "['def _expand_composed_of_rules(rules: Dict[str, Any]) -> None:\\n']",
  "context": " yield constraint\n\n\ndef _expand_composed_of_rules(rules: Dict[str, Any]) -> None:\n    \"\"\" Expands of-rules that have another rule ag"
 },
 "174": {
  "name": "composed_rules",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "207",
  "column": "4",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "another rule agglutinated in a rules set. \"\"\"\n    composed_rules = [\n        x for x in rules if x.startswith(('allof_'"
 },
 "175": {
  "name": "rules",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "221",
  "column": "35",
  "slicing": "['def _normalize_contained_rulessets(rules: Dict[str, Any]) -> None:\\n']",
  "context": "es.pop(rule)\n\n\ndef _normalize_contained_rulessets(rules: Dict[str, Any]) -> None:\n    if isinstance(rules.get(\"schema\"), abc.Mapping"
 },
 "176": {
  "name": "definitions",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "246",
  "column": "14",
  "slicing": "['        self, definitions: Union[RegistryItems, Iterable[Tuple[str, RegistryItem]]] = ()\\n']",
  "context": "nitions.\n    \"\"\"\n\n    def __init__(\n        self, definitions: Union[RegistryItems, Iterable[Tuple[str, RegistryItem]]] = ()\n    ):\n        self._storage = {}  # type: Dict[st"
 },
 "177": {
  "name": "name",
  "type": "str",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "251",
  "column": "18",
  "slicing": "['    def add(self, name: str, definition: RegistryItem) -> None:\\n']",
  "context": "      self.extend(definitions)\n\n    def add(self, name: str, definition: RegistryItem) -> None:\n        \"\"\" Register a definition to the registry."
 },
 "178": {
  "name": "definition",
  "type": "cerberus.typing.RegistryItem",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "251",
  "column": "29",
  "slicing": "['    def add(self, name: str, definition: RegistryItem) -> None:\\n']",
  "context": "extend(definitions)\n\n    def add(self, name: str, definition: RegistryItem) -> None:\n        \"\"\" Register a definition to the registry."
 },
 "179": {
  "name": "definitions",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "275",
  "column": "14",
  "slicing": "['        self, definitions: Union[RegistryItems, Iterable[Tuple[str, RegistryItem]]]\\n']",
  "context": "f._storage.clear()\n\n    def extend(\n        self, definitions: Union[RegistryItems, Iterable[Tuple[str, RegistryItem]]]\n    ) -> None:\n        \"\"\" Add several definitions"
 },
 "180": {
  "name": "name",
  "type": "str",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "286",
  "column": "14",
  "slicing": "['        self, name: str, default: Optional[RegistryItem] = None\\n']",
  "context": "add(name, definition)\n\n    def get(\n        self, name: str, default: Optional[RegistryItem] = None\n    ) -> Optional[RegistryItem]:\n        \"\"\" Retri"
 },
 "181": {
  "name": "default",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "286",
  "column": "25",
  "slicing": "['        self, name: str, default: Optional[RegistryItem] = None\\n']",
  "context": "efinition)\n\n    def get(\n        self, name: str, default: Optional[RegistryItem] = None\n    ) -> Optional[RegistryItem]:\n        \"\"\" Retri"
 },
 "182": {
  "name": "_normalize_value",
  "type": "staticmethod",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "304",
  "column": "4",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', '    _normalize_value = staticmethod(normalize_schema)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "name, None)\n\n\nclass SchemaRegistry(Registry):\n    _normalize_value = staticmethod(normalize_schema)\n\n\nclass RulesSetRegistry(Registry):\n    _normalize"
 },
 "183": {
  "name": "_normalize_value",
  "type": "staticmethod",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "308",
  "column": "4",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', '    _normalize_value = staticmethod(normalize_rulesset)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "e_schema)\n\n\nclass RulesSetRegistry(Registry):\n    _normalize_value = staticmethod(normalize_rulesset)\n\n\nschema_registry, rules_set_registry = SchemaRegi"
 },
 "184": {
  "name": "schema_registry",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "311",
  "column": "0",
  "slicing": "['schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '    @schema_registry.setter\\n']",
  "context": "malize_value = staticmethod(normalize_rulesset)\n\n\nschema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\n\n\n# Defining types\n\n\nTypeDefinition = NamedTuple(\n"
 },
 "185": {
  "name": "rules_set_registry",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "311",
  "column": "17",
  "slicing": "['schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '    @rules_set_registry.setter\\n']",
  "context": "aticmethod(normalize_rulesset)\n\n\nschema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\n\n\n# Defining types\n\n\nTypeDefinition = NamedTuple(\n"
 },
 "186": {
  "name": "TypeDefinition",
  "type": "typing.NamedTuple",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "317",
  "column": "0",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "gistry(), RulesSetRegistry()\n\n\n# Defining types\n\n\nTypeDefinition = NamedTuple(\n    'TypeDefinition',\n    (\n        ('name', str),"
 },
 "187": {
  "name": "mcls",
  "type": "ValidatorMeta",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "342",
  "column": "16",
  "slicing": "['    def __new__(mcls, name, bases, namespace):\\n']",
  "context": "Metaclass for all validators \"\"\"\n\n    def __new__(mcls, name, bases, namespace):\n        if '__doc__' not in namespace:\n           "
 },
 "188": {
  "name": "cls",
  "type": "ValidatorMeta",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "347",
  "column": "17",
  "slicing": "['    def __init__(cls, name, bases, namespace):\\n']",
  "context": "_(mcls, name, bases, namespace)\n\n    def __init__(cls, name, bases, namespace):\n        def attributes_with_prefix(prefix):\n      "
 },
 "189": {
  "name": "validation_rules",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "357",
  "column": "8",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "super().__init__(name, bases, namespace)\n\n        validation_rules = {\n            attribute: cls.__get_rule_schema('_val"
 },
 "190": {
  "name": "x",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "363",
  "column": "8",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": " in attributes_with_prefix('check_with'))\n        x = validation_rules['check_with']['oneof']\n        x[1]['itemsrules']['oneof'][1]['allowed'] "
 },
 "191": {
  "name": "normalization_rules",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "369",
  "column": "43",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": " True\n\n        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\n        for attribute in attributes_with_prefix('n"
 },
 "192": {
  "name": "x",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "381",
  "column": "12",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "rule in ('coerce', 'rename_handler'):\n            x = normalization_rules[rule]['oneof']\n            x[1]['itemsrules']['oneof'][1]['allowe"
 },
 "193": {
  "name": "mcls",
  "type": "ValidatorMeta",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "391",
  "column": "26",
  "slicing": "['    def __get_rule_schema(mcls, method_name):\\n']",
  "context": " cls.validation_rules)\n\n    def __get_rule_schema(mcls, method_name):\n        docstring = getattr(mcls, method_name).__d"
 },
 "194": {
  "name": "result",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "394",
  "column": "12",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "__doc__\n        if docstring is None:\n            result = {}\n        else:\n            if RULE_SCHEMA_SEPARATOR"
 },
 "195": {
  "name": "docstring",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "397",
  "column": "16",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "LE_SCHEMA_SEPARATOR in docstring:\n                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\n            try:\n                result = literal_"
 },
 "196": {
  "name": "result",
  "type": "ast.literal_eval",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "399",
  "column": "16",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "MA_SEPARATOR)[1]\n            try:\n                result = literal_eval(docstring.strip())\n            except Exception:\n                resu"
 },
 "197": {
  "name": "result",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "401",
  "column": "16",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "())\n            except Exception:\n                result = {}\n\n        if not result and method_name != '_valida"
 },
 "198": {
  "name": "mandatory_validations",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "450",
  "column": "4",
  "slicing": "[\"    mandatory_validations = ('nullable',)  # type: ClassVar[Tuple[str, ...]]\\n\"]",
  "context": "~cerberus.errors.BasicErrorHandler`.\n    \"\"\"\n\n    mandatory_validations = ('nullable',)  # type: ClassVar[Tuple[str, ...]]\n    \"\"\" Rules that are evaluated on any field, reg"
 },
 "199": {
  "name": "priority_validations",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "453",
  "column": "4",
  "slicing": "['    priority_validations = (\\n']",
  "context": "ther defined in\n        the schema or not.\"\"\"\n    priority_validations = (\n        'nullable',\n        'readonly',\n        't"
 },
 "200": {
  "name": "types_mapping",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "460",
  "column": "4",
  "slicing": "['    types_mapping = {\\n', '    types_mapping.update(\\n']",
  "context": "processed in that order before any other. \"\"\"\n    types_mapping = {\n        'boolean': TypeDefinition('boolean', (bool"
 },
 "201": {
  "name": "_valid_schemas",
  "type": "set",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "485",
  "column": "4",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    _valid_schemas = set()  # type: ClassVar[Set[Tuple[int, int]]]\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "  for x in abc.__all__  # type: ignore\n    )\n\n    _valid_schemas = set()  # type: ClassVar[Set[Tuple[int, int]]]\n    \"\"\" A :class:`set` of hashes derived from vali"
 },
 "202": {
  "name": "checkers",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "490",
  "column": "4",
  "slicing": "['    checkers = ()  # type: ClassVar[Tuple[str, ...]]\\n']",
  "context": " by the metaclass, here type hints are given:\n    checkers = ()  # type: ClassVar[Tuple[str, ...]]\n    coercers = ()  # type: ClassVar[Tuple[str, ..."
 },
 "203": {
  "name": "coercers",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "491",
  "column": "4",
  "slicing": "['    coercers = ()  # type: ClassVar[Tuple[str, ...]]\\n']",
  "context": "ckers = ()  # type: ClassVar[Tuple[str, ...]]\n    coercers = ()  # type: ClassVar[Tuple[str, ...]]\n    default_setters = ()  # type: ClassVar[Tuple[s"
 },
 "204": {
  "name": "default_setters",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "492",
  "column": "4",
  "slicing": "['    default_setters = ()  # type: ClassVar[Tuple[str, ...]]\\n']",
  "context": "rcers = ()  # type: ClassVar[Tuple[str, ...]]\n    default_setters = ()  # type: ClassVar[Tuple[str, ...]]\n    normalization_rules = {}  # type: ClassVar[Sch"
 },
 "205": {
  "name": "normalization_rules",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "493",
  "column": "4",
  "slicing": "['    normalization_rules = {}  # type: ClassVar[Schema]\\n']",
  "context": "tters = ()  # type: ClassVar[Tuple[str, ...]]\n    normalization_rules = {}  # type: ClassVar[Schema]\n    rules = {}  # type: ClassVar[Dict[str, RulesSe"
 },
 "206": {
  "name": "rules",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "494",
  "column": "4",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "lization_rules = {}  # type: ClassVar[Schema]\n    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\n    validation_rules = {}  # type: ClassVar[Schema"
 },
 "207": {
  "name": "validation_rules",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "495",
  "column": "4",
  "slicing": "['    validation_rules = {}  # type: ClassVar[Schema]\\n']",
  "context": "s = {}  # type: ClassVar[Dict[str, RulesSet]]\n    validation_rules = {}  # type: ClassVar[Schema]\n\n    def __init__(\n        self,\n        schema: S"
 },
 "208": {
  "name": "schema",
  "type": "cerberus.typing.Schema",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "499",
  "column": "8",
  "slicing": "['        schema: Schema = None,\\n']",
  "context": "[Schema]\n\n    def __init__(\n        self,\n        schema: Schema = None,\n        *,\n        allow_unknown: AllowUnknown = F"
 },
 "209": {
  "name": "config",
  "type": "cerberus.typing.ErrorHandlerConfig",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "565",
  "column": "29",
  "slicing": "['    def __init_error_handler(config: ErrorHandlerConfig) -> errors.BaseErrorHandler:\\n']",
  "context": ")\n\n    @staticmethod\n    def __init_error_handler(config: ErrorHandlerConfig) -> errors.BaseErrorHandler:\n        if isinstance(config, errors.BaseErrorHand"
 },
 "210": {
  "name": "error_handler",
  "type": "config",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "570",
  "column": "12",
  "slicing": "['            error_handler, eh_config = config\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n']",
  "context": "        if isinstance(config, tuple):\n            error_handler, eh_config = config\n\n        else:\n            error_handler, eh_confi"
 },
 "211": {
  "name": "eh_config",
  "type": "config",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "570",
  "column": "27",
  "slicing": "['            error_handler, eh_config = config\\n', '            return error_handler(**eh_config)\\n']",
  "context": "stance(config, tuple):\n            error_handler, eh_config = config\n\n        else:\n            error_handler, eh_confi"
 },
 "212": {
  "name": "error_handler",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "573",
  "column": "12",
  "slicing": "['            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n']",
  "context": "er, eh_config = config\n\n        else:\n            error_handler, eh_config = config, {}\n\n        if isinstance(error_handler, type) and is"
 },
 "213": {
  "name": "eh_config",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "573",
  "column": "27",
  "slicing": "['            error_handler, eh_config = config, {}\\n', '            return error_handler(**eh_config)\\n']",
  "context": " config\n\n        else:\n            error_handler, eh_config = config, {}\n\n        if isinstance(error_handler, type) and is"
 },
 "214": {
  "name": "cls",
  "type": "cerberus.base.UnconcernedValidator",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "584",
  "column": "21",
  "slicing": "['    def clear_caches(cls):\\n']",
  "context": "uration.')\n\n    @classmethod\n    def clear_caches(cls):\n        \"\"\" Purge the cache of known valid schemas"
 },
 "215": {
  "name": "field",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "634",
  "column": "12",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "args[1])\n        elif len(args) >= 2:\n            field = args[0]\n            code = args[1].code\n            rule ="
 },
 "216": {
  "name": "info",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "637",
  "column": "12",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": ".code\n            rule = args[1].rule\n            info = args[2:]\n\n            document_path = self.document_path + "
 },
 "217": {
  "name": "schema_path",
  "type": "()",
  "class": "imported",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "641",
  "column": "12",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "path = self.document_path + (field,)\n\n            schema_path = self.schema_path\n            if code != errors.UNKNOWN_FIELD.code a"
 },
 "218": {
  "name": "schema_path",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "643",
  "column": "16",
  "slicing": "['                schema_path += (field, rule)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n']",
  "context": "_FIELD.code and rule is not None:\n                schema_path += (field, rule)\n\n            if not rule:\n                constrai"
 },
 "219": {
  "name": "constraint",
  "type": "None",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "646",
  "column": "16",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": ", rule)\n\n            if not rule:\n                constraint = None\n            else:\n                field_definition"
 },
 "220": {
  "name": "constraint",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "656",
  "column": "20",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "_all__\"\n                else:\n                    constraint = field_definitions[rule]\n\n            value = self.document.get(field)\n\n   "
 },
 "221": {
  "name": "document_crumb",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "667",
  "column": "8",
  "slicing": "['        document_crumb: Union[FieldName, Iterable[FieldName], None] = None,\\n']",
  "context": "  def _get_child_validator(\n        self,\n        document_crumb: Union[FieldName, Iterable[FieldName], None] = None,\n        schema_crumb: Union[FieldName, Iterable[Fi"
 },
 "222": {
  "name": "schema_crumb",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "668",
  "column": "8",
  "slicing": "['        schema_crumb: Union[FieldName, Iterable[FieldName], None] = None,\\n']",
  "context": "dName, Iterable[FieldName], None] = None,\n        schema_crumb: Union[FieldName, Iterable[FieldName], None] = None,\n        **kwargs: Any\n    ) -> 'UnconcernedValidat"
 },
 "223": {
  "name": "child_config",
  "type": "collections.ChainMap",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "680",
  "column": "8",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "arguments for initialization.\n        \"\"\"\n        child_config = ChainMap(kwargs, self._config)\n        if not self.is_child:\n            child_co"
 },
 "224": {
  "name": "document_crumb",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "697",
  "column": "16",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "sinstance(document_crumb, tuple):\n                document_crumb = (document_crumb,)\n            child_validator.document_path = self.d"
 },
 "225": {
  "name": "schema_crumb",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "704",
  "column": "16",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": " isinstance(schema_crumb, tuple):\n                schema_crumb = (schema_crumb,)\n            child_validator.schema_path = self.sch"
 },
 "226": {
  "name": "rule",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "709",
  "column": "41",
  "slicing": "['    def __get_rule_handler(self, domain, rule):\\n']",
  "context": "lidator\n\n    def __get_rule_handler(self, domain, rule):\n        methodname = '_{0}_{1}'.format(domain, rul"
 },
 "227": {
  "name": "result",
  "type": "getattr",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "711",
  "column": "8",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "}'.format(domain, rule.replace(' ', '_'))\n        result = getattr(self, methodname, None)\n        if result is None:\n            raise Runti"
 },
 "228": {
  "name": "dp_items",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "722",
  "column": "8",
  "slicing": "['        dp_items: Iterable[int],\\n']",
  "context": " self,\n        _errors: errors.ErrorList,\n        dp_items: Iterable[int],\n        sp_items: Iterable[int],\n    ) -> None:\n  "
 },
 "229": {
  "name": "sp_items",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "723",
  "column": "8",
  "slicing": "['        sp_items: Iterable[int],\\n']",
  "context": "rorList,\n        dp_items: Iterable[int],\n        sp_items: Iterable[int],\n    ) -> None:\n        \"\"\" Removes nodes by index "
 },
 "230": {
  "name": "dp_basedepth",
  "type": "len",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "733",
  "column": "8",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": " but for :attr:`schema_path`.\n        \"\"\"\n        dp_basedepth = len(self.document_path)\n        sp_basedepth = len(self.schema_path)\n     "
 },
 "231": {
  "name": "sp_basedepth",
  "type": "len",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "734",
  "column": "8",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "   dp_basedepth = len(self.document_path)\n        sp_basedepth = len(self.schema_path)\n        for error in _errors:\n            for i in"
 },
 "232": {
  "name": "path",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "763",
  "column": "12",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": " \"\"\"\n        if path.startswith('^'):\n            path = path[1:]\n            context = self.document if path.starts"
 },
 "233": {
  "name": "schema",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "783",
  "column": "30",
  "slicing": "['    def _resolve_schema(self, schema):\\n']",
  "context": "       return None\n\n    def _resolve_schema(self, schema):\n        if isinstance(schema, Mapping):\n          "
 },
 "234": {
  "name": "value",
  "type": "cerberus.typing.AllowUnknown",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "803",
  "column": "28",
  "slicing": "['    def allow_unknown(self, value: AllowUnknown) -> None:\\n']",
  "context": "@allow_unknown.setter\n    def allow_unknown(self, value: AllowUnknown) -> None:\n        if isinstance(value, Mapping):\n           "
 },
 "235": {
  "name": "value",
  "type": "bool",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "824",
  "column": "33",
  "slicing": "['    def ignore_none_values(self, value: bool) -> None:\\n']",
  "context": "ne_values.setter\n    def ignore_none_values(self, value: bool) -> None:\n        self._config['ignore_none_values'] = value"
 },
 "236": {
  "name": "value",
  "type": "bool",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "840",
  "column": "29",
  "slicing": "['    def _is_normalized(self, value: bool) -> None:\\n']",
  "context": "is_normalized.setter\n    def _is_normalized(self, value: bool) -> None:\n        self._config['_is_normalized'] = value\n\n  "
 },
 "237": {
  "name": "value",
  "type": "bool",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "851",
  "column": "28",
  "slicing": "['    def purge_unknown(self, value: bool) -> None:\\n']",
  "context": "@purge_unknown.setter\n    def purge_unknown(self, value: bool) -> None:\n        self._config['purge_unknown'] = value\n\n   "
 },
 "238": {
  "name": "value",
  "type": "bool",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "862",
  "column": "29",
  "slicing": "['    def purge_readonly(self, value: bool) -> None:\\n']",
  "context": "urge_readonly.setter\n    def purge_readonly(self, value: bool) -> None:\n        self._config['purge_readonly'] = value\n\n  "
 },
 "239": {
  "name": "value",
  "type": "bool",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "872",
  "column": "26",
  "slicing": "['    def require_all(self, value: bool) -> None:\\n']",
  "context": "    @require_all.setter\n    def require_all(self, value: bool) -> None:\n        self._config['require_all'] = value\n\n    @"
 },
 "240": {
  "name": "registry",
  "type": "cerberus.base.RulesSetRegistry",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "900",
  "column": "33",
  "slicing": "['    def rules_set_registry(self, registry: RulesSetRegistry) -> None:\\n']",
  "context": "_registry.setter\n    def rules_set_registry(self, registry: RulesSetRegistry) -> None:\n        self._config['rules_set_registry'] = regis"
 },
 "241": {
  "name": "registry",
  "type": "cerberus.base.SchemaRegistry",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "932",
  "column": "30",
  "slicing": "['    def schema_registry(self, registry: SchemaRegistry) -> None:\\n']",
  "context": "ema_registry.setter\n    def schema_registry(self, registry: SchemaRegistry) -> None:\n        self._config['schema_registry'] = registry"
 },
 "242": {
  "name": "cls",
  "type": "cerberus.base.UnconcernedValidator",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "938",
  "column": "14",
  "slicing": "['    def types(cls) -> Tuple[str, ...]:\\n']",
  "context": "PI docs\n    @readonly_classproperty\n    def types(cls) -> Tuple[str, ...]:\n        \"\"\" The constraints that can be used for t"
 },
 "243": {
  "name": "document",
  "type": "dict",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "945",
  "column": "32",
  "slicing": "['    def __init_processing(self, document, schema=None):\\n']",
  "context": "ument processing\n\n    def __init_processing(self, document, schema=None):\n        self._errors = errors.ErrorList()\n        "
 },
 "244": {
  "name": "document",
  "type": "cerberus.typing.Document",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "984",
  "column": "8",
  "slicing": "['        document: Document,\\n']",
  "context": "lizing\n\n    def normalized(\n        self,\n        document: Document,\n        schema: Optional[Schema] = None,\n        a"
 },
 "245": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "985",
  "column": "8",
  "slicing": "['        schema: Optional[Schema] = None,\\n']",
  "context": "        self,\n        document: Document,\n        schema: Optional[Schema] = None,\n        always_return_document: bool = False,\n    "
 },
 "246": {
  "name": "always_return_document",
  "type": "bool",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "986",
  "column": "8",
  "slicing": "['        always_return_document: bool = False,\\n']",
  "context": "\n        schema: Optional[Schema] = None,\n        always_return_document: bool = False,\n    ) -> Optional[Document]:\n        \"\"\"\n        R"
 },
 "247": {
  "name": "mapping",
  "type": "dict",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1009",
  "column": "34",
  "slicing": "['    def __normalize_mapping(self, mapping, schema):\\n']",
  "context": " self.document\n\n    def __normalize_mapping(self, mapping, schema):\n        mapping = mapping.copy()\n\n        if isins"
 },
 "248": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1014",
  "column": "8",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "    schema = self._resolve_schema(schema)\n        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\n\n        self.__normalize_rename_fields(mapping, s"
 },
 "249": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1031",
  "column": "41",
  "slicing": "['    def _normalize_coerce(self, mapping, schema):\\n']",
  "context": "mapping\n\n    def _normalize_coerce(self, mapping, schema):\n        \"\"\" {'oneof': [\n                {'type': '"
 },
 "250": {
  "name": "error",
  "type": "ErrorDefinition",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1040",
  "column": "8",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "'type': 'string'}\n                ]} \"\"\"\n\n        error = errors.COERCION_FAILED\n        for field in mapping:\n            if field"
 },
 "251": {
  "name": "error",
  "type": "ErrorDefinition",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1062",
  "column": "68",
  "slicing": "['    def __normalize_coerce(self, processor, field, value, nullable, error):\\n']",
  "context": "e_coerce(self, processor, field, value, nullable, error):\n        if isinstance(processor, str):\n           "
 },
 "252": {
  "name": "result",
  "type": "value",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1067",
  "column": "12",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "elif isinstance(processor, Iterable):\n            result = value\n            for p in processor:\n                re"
 },
 "253": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1088",
  "column": "46",
  "slicing": "['    def __normalize_containers(self, mapping, schema):\\n']",
  "context": "ue\n\n    def __normalize_containers(self, mapping, schema):\n        for field in mapping:\n            rules = "
 },
 "254": {
  "name": "rules",
  "type": "set",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1090",
  "column": "12",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "chema):\n        for field in mapping:\n            rules = set(schema.get(field, ()))\n\n            if isinstance(mapping[field], Mapping"
 },
 "255": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1116",
  "column": "8",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "es(self, field, mapping, property_rules):\n        schema = {k: property_rules for k in mapping[field]}\n        document = {k: k for k in mapping[field]}\n"
 },
 "256": {
  "name": "document",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1117",
  "column": "8",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": ": property_rules for k in mapping[field]}\n        document = {k: k for k in mapping[field]}\n        validator = self._get_child_validator(\n   "
 },
 "257": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1140",
  "column": "8",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "rules(self, field, mapping, value_rules):\n        schema = {k: value_rules for k in mapping[field]}\n        validator = self._get_child_validator(\n   "
 },
 "258": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1151",
  "column": "61",
  "slicing": "['    def __normalize_mapping_per_schema(self, field, mapping, schema):\\n']",
  "context": "ormalize_mapping_per_schema(self, field, mapping, schema):\n        rules = schema.get(field, {})\n        if n"
 },
 "259": {
  "name": "value_type",
  "type": "type",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1163",
  "column": "8",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "elf.require_all),\n        )  # noqa: E501\n        value_type = type(mapping[field])\n        result_value = validator.normalized(mappin"
 },
 "260": {
  "name": "rules",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1170",
  "column": "8",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "_per_items(self, field, mapping, schema):\n        rules, values = schema[field]['items'], mapping[field]\n        if len(rules) != len(values):\n            "
 },
 "261": {
  "name": "values",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1170",
  "column": "15",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "ems(self, field, mapping, schema):\n        rules, values = schema[field]['items'], mapping[field]\n        if len(rules) != len(values):\n            "
 },
 "262": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1173",
  "column": "8",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "rules) != len(values):\n            return\n        schema = {k: v for k, v in enumerate(rules)}\n        document = {k: v for k, v in enumerate(val"
 },
 "263": {
  "name": "document",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1174",
  "column": "8",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "ema = {k: v for k, v in enumerate(rules)}\n        document = {k: v for k, v in enumerate(values)}\n        validator = self._get_child_validator(\n   "
 },
 "264": {
  "name": "value_type",
  "type": "type",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1178",
  "column": "8",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "(field, 'items'), schema=schema\n        )\n        value_type = type(mapping[field])\n        result = validator.normalized(document, al"
 },
 "265": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1185",
  "column": "66",
  "slicing": "['    def __normalize_sequence_per_itemsrules(self, field, mapping, schema):\\n']",
  "context": "ize_sequence_per_itemsrules(self, field, mapping, schema):\n        constraint = schema[field]['itemsrules']\n "
 },
 "266": {
  "name": "constraint",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1186",
  "column": "8",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "itemsrules(self, field, mapping, schema):\n        constraint = schema[field]['itemsrules']\n        schema = {k: constraint for k in range(len"
 },
 "267": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1187",
  "column": "8",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": " constraint = schema[field]['itemsrules']\n        schema = {k: constraint for k in range(len(mapping[field]))}\n        document = {k: v for k, v in enumerate(map"
 },
 "268": {
  "name": "document",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1188",
  "column": "8",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "aint for k in range(len(mapping[field]))}\n        document = {k: v for k, v in enumerate(mapping[field])}\n        validator = self._get_child_validator(\n   "
 },
 "269": {
  "name": "value_type",
  "type": "type",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1192",
  "column": "8",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "d, 'itemsrules'), schema=schema\n        )\n        value_type = type(mapping[field])\n        result = validator.normalized(document, al"
 },
 "270": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1200",
  "column": "44",
  "slicing": "['    def __normalize_purge_readonly(mapping, schema):\\n']",
  "context": "ethod\n    def __normalize_purge_readonly(mapping, schema):\n        for field in [x for x in mapping if schema"
 },
 "271": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1206",
  "column": "42",
  "slicing": "['    def _normalize_purge_unknown(mapping, schema):\\n']",
  "context": "cmethod\n    def _normalize_purge_unknown(mapping, schema):\n        \"\"\" {'type': 'boolean'} \"\"\"\n        for fi"
 },
 "272": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1212",
  "column": "49",
  "slicing": "['    def __normalize_rename_fields(self, mapping, schema):\\n']",
  "context": "\n    def __normalize_rename_fields(self, mapping, schema):\n        for field in tuple(mapping):\n            i"
 },
 "273": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1226",
  "column": "41",
  "slicing": "['    def _normalize_rename(self, mapping, schema, field):\\n']",
  "context": "mapping\n\n    def _normalize_rename(self, mapping, schema, field):\n        \"\"\" {'type': 'Hashable'} \"\"\"\n        if 'r"
 },
 "274": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1232",
  "column": "49",
  "slicing": "['    def _normalize_rename_handler(self, mapping, schema, field):\\n']",
  "context": "\n    def _normalize_rename_handler(self, mapping, schema, field):\n        \"\"\" {'oneof': [\n                {'type': '"
 },
 "275": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1249",
  "column": "50",
  "slicing": "['    def __validate_readonly_fields(self, mapping, schema):\\n']",
  "context": "    def __validate_readonly_fields(self, mapping, schema):\n        for field in (\n            x\n            f"
 },
 "276": {
  "name": "empty_fields",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1258",
  "column": "8",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "ze_default_fields(self, mapping, schema):\n        empty_fields = [\n            x\n            for x in schema\n        "
 },
 "277": {
  "name": "known_fields_states",
  "type": "set",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1271",
  "column": "8",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "ormalize_default(mapping, schema, field)\n\n        known_fields_states = set()\n        fields_with_default_setter = [\n           "
 },
 "278": {
  "name": "fields_with_default_setter",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1272",
  "column": "8",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "eld)\n\n        known_fields_states = set()\n        fields_with_default_setter = [\n            x for x in empty_fields if 'default_se"
 },
 "279": {
  "name": "fields_processing_state",
  "type": "hash",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1286",
  "column": "12",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "rors.SETTING_DEFAULT_FAILED, str(e))\n\n            fields_processing_state = hash(tuple(fields_with_default_setter))\n            if fields_processing_state in known_fi"
 },
 "280": {
  "name": "setter",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1308",
  "column": "12",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "if 'default_setter' in schema[field]:\n            setter = schema[field]['default_setter']\n            if isinstance(setter, str):\n          "
 },
 "281": {
  "name": "document",
  "type": "cerberus.typing.Document",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1317",
  "column": "8",
  "slicing": "['        document: Document,\\n']",
  "context": "lidating\n\n    def validate(\n        self,\n        document: Document,\n        schema: Optional[Schema] = None,\n        u"
 },
 "282": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1318",
  "column": "8",
  "slicing": "['        schema: Optional[Schema] = None,\\n']",
  "context": "        self,\n        document: Document,\n        schema: Optional[Schema] = None,\n        update: bool = False,\n        normalize: b"
 },
 "283": {
  "name": "update",
  "type": "bool",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1319",
  "column": "8",
  "slicing": "['        update: bool = False,\\n']",
  "context": "\n        schema: Optional[Schema] = None,\n        update: bool = False,\n        normalize: bool = True,\n    ) -> bool:\n   "
 },
 "284": {
  "name": "normalize",
  "type": "bool",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1320",
  "column": "8",
  "slicing": "['        normalize: bool = True,\\n']",
  "context": "ma] = None,\n        update: bool = False,\n        normalize: bool = True,\n    ) -> bool:\n        \"\"\"\n        Normalizes and "
 },
 "285": {
  "name": "__call__",
  "type": "validate",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1357",
  "column": "4",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '    __call__ = validate\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "ort()\n\n        return not bool(self._errors)\n\n    __call__ = validate\n\n    def validated(\n        self,\n        document"
 },
 "286": {
  "name": "document",
  "type": "cerberus.typing.Document",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1361",
  "column": "8",
  "slicing": "['        document: Document,\\n']",
  "context": "alidate\n\n    def validated(\n        self,\n        document: Document,\n        schema: Optional[Schema] = None,\n        u"
 },
 "287": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1362",
  "column": "8",
  "slicing": "['        schema: Optional[Schema] = None,\\n']",
  "context": "        self,\n        document: Document,\n        schema: Optional[Schema] = None,\n        update: bool = False,\n        normalize: b"
 },
 "288": {
  "name": "update",
  "type": "bool",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1363",
  "column": "8",
  "slicing": "['        update: bool = False,\\n']",
  "context": "\n        schema: Optional[Schema] = None,\n        update: bool = False,\n        normalize: bool = True,\n        always_ret"
 },
 "289": {
  "name": "normalize",
  "type": "bool",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1364",
  "column": "8",
  "slicing": "['        normalize: bool = True,\\n']",
  "context": "ma] = None,\n        update: bool = False,\n        normalize: bool = True,\n        always_return_document: bool = False,\n    "
 },
 "290": {
  "name": "always_return_document",
  "type": "bool",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1365",
  "column": "8",
  "slicing": "['        always_return_document: bool = False,\\n']",
  "context": " = False,\n        normalize: bool = True,\n        always_return_document: bool = False,\n    ) -> Optional[Document]:\n        \"\"\"\n        W"
 },
 "291": {
  "name": "value",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1381",
  "column": "12",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "ield):\n        if self.allow_unknown:\n            value = self.document[field]\n            if isinstance(self.allow_unknown, (Map"
 },
 "292": {
  "name": "value",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1398",
  "column": "8",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "ns = self._resolve_rules_set(definitions)\n        value = self.document[field]\n\n        rules_queue = [\n            x\n           "
 },
 "293": {
  "name": "rules_queue",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1400",
  "column": "8",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "ns)\n        value = self.document[field]\n\n        rules_queue = [\n            x\n            for x in self.priority_v"
 },
 "294": {
  "name": "_validate_allow_unknown",
  "type": "dummy_for_rule_validation",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1425",
  "column": "4",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '    _validate_allow_unknown = dummy_for_rule_validation(\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": " below this line\n    # sorted alphabetically\n\n    _validate_allow_unknown = dummy_for_rule_validation(\n        \"\"\" {'oneof': [{'type': 'boolean'},\n      "
 },
 "295": {
  "name": "unallowed",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1434",
  "column": "12",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "able) and not isinstance(value, str):\n            unallowed = tuple(x for x in value if x not in allowed_values)\n            if unallowed:\n                self._er"
 },
 "296": {
  "name": "expected_values",
  "type": "set",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1467",
  "column": "12",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "      expected_values, str\n        ):\n            expected_values = set((expected_values,))\n        else:\n            expected_values = set(ex"
 },
 "297": {
  "name": "expected_values",
  "type": "set",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1469",
  "column": "12",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "set((expected_values,))\n        else:\n            expected_values = set(expected_values)\n\n        missing_values = expected_values - set(va"
 },
 "298": {
  "name": "dependencies",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1479",
  "column": "12",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "    if isinstance(dependencies, str):\n            dependencies = (dependencies,)\n\n        if isinstance(dependencies, Sequence):\n  "
 },
 "299": {
  "name": "error_info",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1496",
  "column": "8",
  "slicing": "['        error_info = {}\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n']",
  "context": "       validated_dependencies_counter = 0\n        error_info = {}\n        for dependency_name, dependency_values in "
 },
 "300": {
  "name": "dependency_values",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1501",
  "column": "16",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "ndency_values, str\n            ):\n                dependency_values = [dependency_values]\n\n            wanted_field, wanted_field_value = se"
 },
 "301": {
  "name": "excluded_fields",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1539",
  "column": "12",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "excluded_fields, Container\n        ):\n            excluded_fields = (excluded_fields,)\n\n        # Mark the currently evaluated field as n"
 },
 "302": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1577",
  "column": "12",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "en(items), len(values))\n        else:\n            schema = {i: definition for i, definition in enumerate(items)}\n\n            validator = self._get_child_validator"
 },
 "303": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1598",
  "column": "8",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "nce(value, Sequence):\n            return\n\n        schema = {i: rulesset for i in range(len(value))}\n        validator = self._get_child_validator(\n   "
 },
 "304": {
  "name": "_errors",
  "type": "ErrorList",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1617",
  "column": "8",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "e operator. \"\"\"\n        valid_counter = 0\n        _errors = errors.ErrorList()\n\n        for i, definition in enumerate(definition"
 },
 "305": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1620",
  "column": "12",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "definition in enumerate(definitions):\n            schema = {field: definition.copy()}\n            for rule in ('allow_unknown', 'type'):"
 },
 "306": {
  "name": "_errors",
  "type": "ErrorList",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1640",
  "column": "16",
  "slicing": "[\"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n']",
  "context": "equence', 'logical': 'anyof'} \"\"\"\n        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\n        if valids < 1:\n            self._error(fie"
 },
 "307": {
  "name": "_errors",
  "type": "ErrorList",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1646",
  "column": "16",
  "slicing": "[\"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n']",
  "context": "equence', 'logical': 'allof'} \"\"\"\n        valids, _errors = self.__validate_logical('allof', definitions, field, value)\n        if valids < len(definitions):\n            "
 },
 "308": {
  "name": "_errors",
  "type": "ErrorList",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1652",
  "column": "16",
  "slicing": "[\"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n']",
  "context": "quence', 'logical': 'noneof'} \"\"\"\n        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\n        if valids > 0:\n            self._error(fie"
 },
 "309": {
  "name": "_errors",
  "type": "ErrorList",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1658",
  "column": "16",
  "slicing": "[\"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n']",
  "context": "equence', 'logical': 'oneof'} \"\"\"\n        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\n        if valids != 1:\n            self._error(fi"
 },
 "310": {
  "name": "_validate_meta",
  "type": "dummy_for_rule_validation",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1683",
  "column": "4",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', \"    _validate_meta = dummy_for_rule_validation('')\\n\", '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "_error(field, errors.MAX_LENGTH, len(value))\n\n    _validate_meta = dummy_for_rule_validation('')\n\n    def _validate_minlength(self, min_length, fie"
 },
 "311": {
  "name": "has_error",
  "type": "bool",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1732",
  "column": "12",
  "slicing": "['            has_error = (\\n', '            if self._is_normalized and has_error:\\n']",
  "context": "\n            # if an error was filed.\n            has_error = (\n                errors.READONLY_FIELD\n            "
 },
 "312": {
  "name": "_validate_required",
  "type": "dummy_for_rule_validation",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1751",
  "column": "4",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '    _validate_required = dummy_for_rule_validation(\"\"\" {\\'type\\': \\'boolean\\'} \"\"\")\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "   self._error(field, errors.REGEX_MISMATCH)\n\n    _validate_required = dummy_for_rule_validation(\"\"\" {'type': 'boolean'} \"\"\")\n\n    _validate_require_all = dummy_for_rule_valida"
 },
 "313": {
  "name": "_validate_require_all",
  "type": "dummy_for_rule_validation",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1753",
  "column": "4",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '    _validate_require_all = dummy_for_rule_validation(\"\"\" {\\'type\\': \\'boolean\\'} \"\"\")\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "rule_validation(\"\"\" {'type': 'boolean'} \"\"\")\n\n    _validate_require_all = dummy_for_rule_validation(\"\"\" {'type': 'boolean'} \"\"\")\n\n    def __validate_required_fields(self, document"
 },
 "314": {
  "name": "required",
  "type": "set",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1760",
  "column": "8",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "The document being validated.\n        \"\"\"\n        required = set(\n            field\n            for field, definitio"
 },
 "315": {
  "name": "fields",
  "type": "set",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1778",
  "column": "12",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "     if self._unrequired_by_excludes:\n            fields = set(field for field in document if document.get(field) is not None)\n            if self._unrequired_by_excludes.isdisj"
 },
 "316": {
  "name": "type_definition",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1815",
  "column": "16",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "       if isinstance(_type, str):\n                type_definition = self.types_mapping[_type]\n                if isinstance(value, type_definiti"
 },
 "317": {
  "name": "schema_crumb",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1831",
  "column": "12",
  "slicing": "['RULE_SCHEMA_SEPARATOR = \"The rule\\'s arguments are validated against this schema:\"\\n', 'toy_error_handler = errors.ToyErrorHandler()\\n', '_ellipsis = typing.Tuple[int, ...].__args__[-1]\\n', 'def dummy_for_rule_validation(rule_constraints: str) -> Callable:\\n', '    f = dummy\\n', '    f.__doc__ = rule_constraints\\n', '    return f\\n', '_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\\n', 'def normalize_rulesset(rules: RulesSet) -> RulesSet:\\n', '    _hash = schema_hash(rules)\\n', '    if _hash in _normalized_rulesset_cache:\\n', '        return _normalized_rulesset_cache[_hash]\\n', '    rules = dict(rules)\\n', '    rules_with_whitespace = [x for x in rules if \" \" in x]\\n', '    if rules_with_whitespace:\\n', '        for rule in rules_with_whitespace:\\n', '            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\\n', '    if isinstance(rules.get(\"dependencies\"), str):\\n', '        rules[\"dependencies\"] = (rules[\"dependencies\"],)\\n', '    if \"excludes\" in rules:\\n', '        constraint = rules[\"excludes\"]\\n', '        if isinstance(constraint, str) or not isinstance(constraint, Container):\\n', '            rules[\"excludes\"] = (constraint,)\\n', '    if \"type\" in rules:\\n', '        constraint = rules[\"type\"]\\n', '        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\\n', '            rules[\"type\"] = (constraint,)\\n', '        _expand_generic_type_aliases(rules)\\n', '    _expand_composed_of_rules(rules)\\n', '    _normalize_contained_rulessets(rules)\\n', '    _normalized_rulesset_cache[_hash] = rules\\n', '    return rules\\n', 'def normalize_schema(schema: Schema) -> Schema:\\n', '    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\\n', '    compound_types = []\\n', '    plain_types = []\\n', '    is_nullable = False\\n', '    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\\n', '        if isinstance(constraint, _GenericAlias):\\n', '            origin = get_type_origin(constraint)\\n', '            args = get_type_args(constraint)\\n', '            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\\n', '                compound_types.append(\\n', '                        \"type\": origin,\\n', '                        \"keysrules\": {\"type\": args[0]},\\n', '                        \"valuesrules\": {\"type\": args[1]},\\n', '                issubclass(origin, (abc.MutableSequence, abc.Set))\\n', '                and not constraint.__parameters__\\n', '                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\\n', '            elif issubclass(origin, tuple) and args:\\n', '                if args[-1] is _ellipsis:\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\\n', '                    compound_types.append(\\n', '                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\\n', '                plain_types.append(origin)\\n', '        elif constraint is NoneType:  # type: ignore\\n', '            is_nullable = True\\n', '        elif isinstance(constraint, ForwardRef):\\n', '            plain_types.append(constraint.__forward_arg__)\\n', '            plain_types.append(constraint)\\n', '    if compound_types or is_nullable:\\n', '        if \"anyof\" in rules:\\n', '        if plain_types:\\n', '            compound_types.append({\"type\": tuple(plain_types)})\\n', '        if is_nullable:\\n', '            compound_types.append({\"nullable\": True})\\n', '        rules[\"anyof\"] = tuple(compound_types)\\n', '        rules[\"type\"] = tuple(plain_types)\\n', '    for constraint in type_constraints:\\n', '        if get_type_origin(constraint) is typing.Union:\\n', '            yield from _flatten_Union_and_Optional(get_type_args(constraint))\\n', '            yield constraint\\n', '    composed_rules = [\\n', \"        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\\n\", '    if not composed_rules:\\n', '    for composed_rule in composed_rules:\\n', \"        of_rule, rule = composed_rule.split('_', 1)\\n\", '        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\\n', '    for rule in composed_rules:\\n', '        rules.pop(rule)\\n', '    if isinstance(rules.get(\"schema\"), abc.Mapping):\\n', \"        rules['schema'] = normalize_schema(rules['schema'])\\n\", '    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\\n', '        if rule in rules:\\n', '            rules[rule] = normalize_rulesset(rules[rule])\\n', \"    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\\n\", '        if not isinstance(rules.get(rule), Sequence):\\n', '        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\\n', '        for name, definition in dict(definitions).items():\\n', '            self.add(name, definition)\\n', '        return self._storage.get(name, default)\\n', '        for name in names:\\n', '            self._storage.pop(name, None)\\n', 'schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\\n', 'TypeDefinition = NamedTuple(\\n', '        return super().__new__(mcls, name, bases, namespace)\\n', '        def attributes_with_prefix(prefix):\\n', '                x[len(prefix) + 2 :]\\n', '                for x in dir(cls)\\n', \"                if x.startswith('_' + prefix + '_')\\n\", '        super().__init__(name, bases, namespace)\\n', '        validation_rules = {\\n', \"            for attribute in attributes_with_prefix('validate')\\n\", \"        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\\n\", \"        x = validation_rules['check_with']['oneof']\\n\", \"        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\\n\", \"        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\\n\", \"            validation_rules[rule]['required'] = True\\n\", '        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\\n', \"        for attribute in attributes_with_prefix('normalize'):\\n\", \"            if attribute.startswith('coerce_'):\\n\", \"                cls.coercers += (attribute[len('coerce_') :],)\\n\", \"            elif attribute.startswith('default_setter_'):\\n\", \"                cls.default_setters += (attribute[len('default_setter_') :],)\\n\", '                normalization_rules[attribute] = cls.__get_rule_schema(\\n', \"                    '_normalize_' + attribute\\n\", \"        for rule in ('coerce', 'rename_handler'):\\n\", \"            x = normalization_rules[rule]['oneof']\\n\", \"            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\\n\", \"        normalization_rules['default_setter']['oneof'][1][\\n\", '        cls.normalization_rules = normalize_schema(normalization_rules)\\n', '        cls.validation_rules = normalize_schema(validation_rules)\\n', '        docstring = getattr(mcls, method_name).__doc__\\n', '        if docstring is None:\\n', '            result = {}\\n', '            if RULE_SCHEMA_SEPARATOR in docstring:\\n', '                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\\n', '                result = literal_eval(docstring.strip())\\n', '                result = {}\\n', \"        if not result and method_name != '_validate_meta':\\n\", '        return result\\n', '    types_mapping = {\\n', \"        'boolean': TypeDefinition('boolean', (bool,), ()),\\n\", \"        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\\n\", \"        'bytes': TypeDefinition('bytes', (bytes,), ()),\\n\", \"        'complex': TypeDefinition('complex', (complex,), ()),\\n\", \"        'date': TypeDefinition('date', (date,), (datetime,)),\\n\", \"        'datetime': TypeDefinition('datetime', (datetime,), ()),\\n\", \"        'dict': TypeDefinition('dict', (Mapping,), ()),\\n\", \"        'float': TypeDefinition('float', (float,), ()),\\n\", \"        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\\n\", \"        'integer': TypeDefinition('integer', (int,), (bool,)),\\n\", \"        'list': TypeDefinition('list', (list,), ()),\\n\", \"        'number': TypeDefinition('number', (int, float), (bool,)),\\n\", \"        'set': TypeDefinition('set', (set,), ()),\\n\", \"        'string': TypeDefinition('string', (str,), ()),\\n\", \"        'tuple': TypeDefinition('tuple', (tuple,), ()),\\n\", \"        'type': TypeDefinition('type', (type,), ()),\\n\", '    types_mapping.update(\\n', '        (x, TypeDefinition(x, (getattr(abc, x),), ()))\\n', '        for x in abc.__all__  # type: ignore\\n', '    normalization_rules = {}  # type: ClassVar[Schema]\\n', '    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\\n', '    validation_rules = {}  # type: ClassVar[Schema]\\n', '        rules_set_registry: RulesSetRegistry = rules_set_registry,\\n', '        schema_registry: SchemaRegistry = schema_registry,\\n', '                \"rules_set_registry\": rules_set_registry,\\n', '                \"schema_registry\": schema_registry,\\n', '        self.schema = schema\\n', '            error_handler, eh_config = config\\n', '            error_handler, eh_config = config, {}\\n', '        if isinstance(error_handler, type) and issubclass(\\n', '            error_handler, errors.BaseErrorHandler\\n', '            return error_handler(**eh_config)\\n', '        if len(args) == 1:\\n', '            self._errors.extend(args[0])\\n', '            for error in args[0]:\\n', '                self.document_error_tree.add(error)\\n', '                self.schema_error_tree.add(error)\\n', '                self.error_handler.emit(error)\\n', '        elif len(args) == 2 and isinstance(args[1], str):\\n', '            self._error(args[0], errors.CUSTOM, args[1])\\n', '        elif len(args) >= 2:\\n', '            field = args[0]\\n', '            code = args[1].code\\n', '            rule = args[1].rule\\n', '            info = args[2:]\\n', '            document_path = self.document_path + (field,)\\n', '            schema_path = self.schema_path\\n', '            if code != errors.UNKNOWN_FIELD.code and rule is not None:\\n', '                schema_path += (field, rule)\\n', '            if not rule:\\n', '                constraint = None\\n', '                field_definitions = self._resolve_rules_set(self.schema[field])\\n', \"                if rule == 'nullable':\\n\", '                    constraint = field_definitions.get(rule, False)\\n', \"                elif rule == 'required':\\n\", '                    constraint = field_definitions.get(rule, self.require_all)\\n', '                    if rule not in field_definitions:\\n', '                        schema_path = \"__require_all__\"\\n', '                    constraint = field_definitions[rule]\\n', '            value = self.document.get(field)\\n', '                document_path, schema_path, code, rule, constraint, value, info\\n', '        child_config = ChainMap(kwargs, self._config)\\n', '            child_config = child_config.new_child(\\n', \"                    'error_handler': toy_error_handler,\\n\", '        child_validator = self.__class__(**child_config)\\n', '            child_validator.document_path = self.document_path\\n', '                document_crumb = (document_crumb,)\\n', '            child_validator.document_path = self.document_path + document_crumb\\n', '            child_validator.schema_path = self.schema_path\\n', '                schema_crumb = (schema_crumb,)\\n', '            child_validator.schema_path = self.schema_path + schema_crumb\\n', '        return child_validator\\n', \"        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\\n\", '        result = getattr(self, methodname, None)\\n', '        if result is None:\\n', '                \"domain.\".format(rule, domain)\\n', '        return result\\n', '        dp_basedepth = len(self.document_path)\\n', '        sp_basedepth = len(self.schema_path)\\n', '        for error in _errors:\\n', '            for i in sorted(dp_items, reverse=True):\\n', '                error.document_path = drop_item_from_tuple(\\n', '                    error.document_path, dp_basedepth + i\\n', '            for i in sorted(sp_items, reverse=True):\\n', '                error.schema_path = drop_item_from_tuple(\\n', '                    error.schema_path, sp_basedepth + i\\n', '            if error.child_errors:\\n', '                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\\n', '            path = path[1:]\\n', \"            context = self.document if path.startswith('^') else self.root_document\\n\", '            context = self.document\\n', \"        parts = path.split('.')\\n\", '        for part in parts:\\n', '            if part not in context:\\n', '            context = context.get(part, {})\\n', '        return parts[-1], context\\n', '        if isinstance(schema, Mapping):\\n', '            return schema\\n', '        elif isinstance(schema, str):\\n', '            return self.schema_registry.get(schema)\\n', '        if isinstance(value, Mapping):\\n', \"            self._config['allow_unknown'] = normalize_rulesset(value)\\n\", '        elif isinstance(value, bool):\\n', \"            self._config['allow_unknown'] = value\\n\", \"        self._config['ignore_none_values'] = value\\n\", \"        self._config['_is_normalized'] = value\\n\", \"        self._config['purge_unknown'] = value\\n\", \"        self._config['purge_readonly'] = value\\n\", \"        self._config['require_all'] = value\\n\", '    @rules_set_registry.setter\\n', '    @schema.setter\\n', '        if schema is None:\\n', '            self._schema = schema\\n', '            self._schema = normalize_schema(schema)\\n', '    @schema_registry.setter\\n', '        if schema is not None:\\n', '            self.schema = schema\\n', '        if rules:\\n', '            for rule in (x for x in rules if x in self._remaining_rules):\\n', '                self._remaining_rules.remove(rule)\\n', '        self.__init_processing(document, schema)\\n', '        mapping = mapping.copy()\\n', '        if isinstance(schema, str):\\n', '            schema = self._resolve_schema(schema)\\n', '        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\\n', '        self.__normalize_rename_fields(mapping, schema)\\n', '            self._normalize_purge_unknown(mapping, schema)\\n', '            self.__normalize_purge_readonly(mapping, schema)\\n', '        self.__validate_readonly_fields(mapping, schema)\\n', '        self.__normalize_default_fields(mapping, schema)\\n', '        self._normalize_coerce(mapping, schema)\\n', '        self.__normalize_containers(mapping, schema)\\n', '        return mapping\\n', '        error = errors.COERCION_FAILED\\n', '        for field in mapping:\\n', \"            if field in schema and 'coerce' in schema[field]:\\n\", '                mapping[field] = self.__normalize_coerce(\\n', \"                    schema[field]['coerce'],\\n\", '                    field,\\n', '                    mapping[field],\\n', \"                    schema[field].get('nullable', False),\\n\", '                    error,\\n', '                mapping[field] = self.__normalize_coerce(\\n', '                    field,\\n', '                    mapping[field],\\n', '                    error,\\n', \"            processor = self.__get_rule_handler('normalize_coerce', processor)\\n\", '        elif isinstance(processor, Iterable):\\n', '            result = value\\n', '            for p in processor:\\n', '                result = self.__normalize_coerce(p, field, result, nullable, error)\\n', '                        self.document_path + (field,)\\n', '            return result\\n', '            return processor(value)\\n', '            if not (nullable and value is None):\\n', '                self._error(field, error, str(e))\\n', '            return value\\n', '        for field in mapping:\\n', '            rules = set(schema.get(field, ()))\\n', '            if isinstance(mapping[field], Mapping):\\n', \"                if 'keysrules' in rules:\\n\", \"                        field, mapping, schema[field]['keysrules']\\n\", \"                if 'valuesrules' in rules:\\n\", \"                        field, mapping, schema[field]['valuesrules']\\n\", \"                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\\n\", '                    self.__normalize_mapping_per_schema(field, mapping, schema)\\n', '            elif isinstance(mapping[field], str):\\n', '            elif isinstance(mapping[field], Sequence):\\n', \"                if 'itemsrules' in rules:\\n\", '                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\\n', \"                elif 'items' in rules:\\n\", '                    self.__normalize_sequence_per_items(field, mapping, schema)\\n', '        schema = {k: property_rules for k in mapping[field]}\\n', '        document = {k: k for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\\n\", '        result = validator.normalized(document, always_return_document=True)\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '            self._error(validator._errors)\\n', '        for _in, out in ((k, v) for k, v in result.items() if k != v):\\n', '            if out in mapping[field]:\\n', \"                        path='.'.join(str(x) for x in self.document_path + (field,)),\\n\", '                        key=_in,\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                mapping[field][out] = mapping[field][_in]\\n', '                del mapping[field][_in]\\n', '        schema = {k: value_rules for k in mapping[field]}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\\n\", '        mapping[field] = validator.normalized(\\n', '            mapping[field], always_return_document=True\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', '        rules = schema.get(field, {})\\n', '        if not rules and isinstance(self.allow_unknown, Mapping):\\n', '            rules = self.allow_unknown\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", \"            schema=rules.get('schema', {}),\\n\", \"            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\\n\", \"            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\\n\", \"            require_all=rules.get('require_all', self.require_all),\\n\", '        value_type = type(mapping[field])\\n', '        result_value = validator.normalized(mapping[field], always_return_document=True)\\n', '        mapping[field] = value_type(result_value)\\n', '        if validator._errors:\\n', '            self._error(validator._errors)\\n', \"        rules, values = schema[field]['items'], mapping[field]\\n\", '        if len(rules) != len(values):\\n', '        schema = {k: v for k, v in enumerate(rules)}\\n', '        document = {k: v for k, v in enumerate(values)}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        constraint = schema[field]['itemsrules']\\n\", '        schema = {k: constraint for k in range(len(mapping[field]))}\\n', '        document = {k: v for k, v in enumerate(mapping[field])}\\n', '        validator = self._get_child_validator(\\n', \"            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\\n\", '        value_type = type(mapping[field])\\n', '        result = validator.normalized(document, always_return_document=True)\\n', '        mapping[field] = value_type(result.values())\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(validator._errors)\\n', \"        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\\n\", '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in [x for x in mapping if x not in schema]:\\n', '            mapping.pop(field)\\n', '        return mapping\\n', '        for field in tuple(mapping):\\n', '            if field in schema:\\n', '                self._normalize_rename(mapping, schema, field)\\n', '                self._normalize_rename_handler(mapping, schema, field)\\n', '                    mapping, {field: self.allow_unknown}, field\\n', '        return mapping\\n', \"        if 'rename' in schema[field]:\\n\", \"            mapping[schema[field]['rename']] = mapping[field]\\n\", '            del mapping[field]\\n', \"        if 'rename_handler' not in schema[field]:\\n\", '        new_name = self.__normalize_coerce(\\n', \"            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\\n\", '        if new_name != field:\\n', '            mapping[new_name] = mapping[field]\\n', '            del mapping[field]\\n', '        for field in (\\n', '            x\\n', '            for x in schema\\n', \"            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\\n\", \"            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\\n\", '        empty_fields = [\\n', '            x\\n', '            for x in schema\\n', '            if x not in mapping\\n', '                mapping[x] is None  # noqa: W503\\n', \"                and not schema[x].get('nullable', False)\\n\", \"        for field in (x for x in empty_fields if 'default' in schema[x]):\\n\", '            self._normalize_default(mapping, schema, field)\\n', '        known_fields_states = set()\\n', '        fields_with_default_setter = [\\n', \"            x for x in empty_fields if 'default_setter' in schema[x]\\n\", '        while fields_with_default_setter:\\n', '            field = fields_with_default_setter.pop(0)\\n', '                self._normalize_default_setter(mapping, schema, field)\\n', '                fields_with_default_setter.append(field)\\n', '                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\\n', '            fields_processing_state = hash(tuple(fields_with_default_setter))\\n', '            if fields_processing_state in known_fields_states:\\n', '                for field in fields_with_default_setter:\\n', '                        field,\\n', '                known_fields_states.add(fields_processing_state)\\n', \"        mapping[field] = schema[field]['default']\\n\", \"        if 'default_setter' in schema[field]:\\n\", \"            setter = schema[field]['default_setter']\\n\", '            if isinstance(setter, str):\\n', \"                setter = self.__get_rule_handler('normalize_default_setter', setter)\\n\", '            mapping[field] = setter(mapping)\\n', '        self.__init_processing(document, schema)\\n', '        for field in self.document:  # type: ignore\\n', '            definitions = self.schema.get(field)  # type: ignore\\n', '            if definitions is not None:\\n', '                self.__validate_definitions(definitions, field)\\n', '                self.__validate_unknown_fields(field)\\n', '            document=document, schema=schema, update=update, normalize=normalize\\n', '            value = self.document[field]\\n', \"                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\\n\", '                validator = self._get_child_validator(\\n', '                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\\n', '                if not validator({field: value}, normalize=False):\\n', '                    self._error(validator._errors)\\n', '            self._error(field, errors.UNKNOWN_FIELD)\\n', '        definitions = self._resolve_rules_set(definitions)\\n', '        value = self.document[field]\\n', '        rules_queue = [\\n', '            x\\n', '            for x in self.priority_validations\\n', '            if x in definitions or x in self.mandatory_validations\\n', '        rules_queue.extend(\\n', '            x for x in self.mandatory_validations if x not in rules_queue\\n', '        rules_queue.extend(\\n', '            x\\n', '            for x in definitions\\n', '            if x not in rules_queue\\n', '            and x not in self.normalization_rules\\n', \"            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\\n\", '        self._remaining_rules = rules_queue\\n', '            rule = self._remaining_rules.pop(0)\\n', \"            rule_handler = self.__get_rule_handler('validate', rule)\\n\", '            rule_handler(definitions.get(rule, None), field, value)\\n', '        if isinstance(value, Iterable) and not isinstance(value, str):\\n', '            unallowed = tuple(x for x in value if x not in allowed_values)\\n', '            if unallowed:\\n', '                self._error(field, errors.UNALLOWED_VALUES, unallowed)\\n', '            if value not in allowed_values:\\n', '                self._error(field, errors.UNALLOWED_VALUE, value)\\n', \"            value_checker = self.__get_rule_handler('check_with', checks)\\n\", '            value_checker(field, value)\\n', '            for v in checks:\\n', '                self._validate_check_with(v, field, value)\\n', '            checks(field, value, self._error)\\n', '        if not isinstance(value, Container):\\n', '            expected_values = set((expected_values,))\\n', '            expected_values = set(expected_values)\\n', '        missing_values = expected_values - set(value)\\n', '        if missing_values:\\n', '            self._error(field, errors.MISSING_MEMBERS, missing_values)\\n', '            dependencies = (dependencies,)\\n', '        if isinstance(dependencies, Sequence):\\n', '            self.__validate_dependencies_sequence(dependencies, field)\\n', '        elif isinstance(dependencies, Mapping):\\n', '            self.__validate_dependencies_mapping(dependencies, field)\\n', \"                self.schema_path + (field, 'dependencies')\\n\", '        validated_dependencies_counter = 0\\n', '        error_info = {}\\n', '        for dependency_name, dependency_values in dependencies.items():\\n', '            if not isinstance(dependency_values, Sequence) or isinstance(\\n', '                dependency_values, str\\n', '                dependency_values = [dependency_values]\\n', '            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\\n', '            if wanted_field_value in dependency_values:\\n', '                validated_dependencies_counter += 1\\n', '                error_info.update({dependency_name: wanted_field_value})\\n', '        if validated_dependencies_counter != len(dependencies):\\n', '            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\\n', '        for dependency in dependencies:\\n', '            if self._lookup_field(dependency)[0] is None:\\n', '                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\\n', '        if isinstance(value, Sized) and len(value) == 0:\\n', '                self._error(field, errors.EMPTY)\\n', '            excluded_fields = (excluded_fields,)\\n', \"        if self.schema[field].get('required', self.require_all):\\n\", '            self._unrequired_by_excludes.add(field)\\n', '        for excluded_field in excluded_fields:\\n', '            if excluded_field in self.schema and self.schema[field].get(\\n', '                self._unrequired_by_excludes.add(excluded_field)\\n', '        if any(excluded_field in self.document for excluded_field in excluded_fields):\\n', \"            exclusion_str = ', '.join(\\n\", '                \"\\'{0}\\'\".format(field) for field in excluded_fields\\n', '            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\\n', '        if isinstance(value, str):\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        elif isinstance(value, Iterable):\\n', '            forbidden = set(value) & set(forbidden_values)\\n', '            if forbidden:\\n', '                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\\n', '            if value in forbidden_values:\\n', '                self._error(field, errors.FORBIDDEN_VALUE, value)\\n', '        if len(items) != len(values):\\n', '            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\\n', '            schema = {i: definition for i, definition in enumerate(items)}\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'items'),  # noqa: E501\\n\", '                schema=schema,\\n', '            if not validator(\\n', '                {i: value for i, value in enumerate(values)},\\n', '                self._error(field, errors.ITEMS, validator._errors)\\n', '        if not isinstance(value, Sequence):\\n', '        schema = {i: rulesset for i in range(len(value))}\\n', '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'itemsrules'),\\n\", '            schema=schema,\\n', '        validator(\\n', '            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\\n', '        if validator._errors:\\n', '            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '            self._error(field, errors.ITEMSRULES, validator._errors)\\n', '        valid_counter = 0\\n', '        _errors = errors.ErrorList()\\n', '        for i, definition in enumerate(definitions):\\n', '            schema = {field: definition.copy()}\\n', \"            for rule in ('allow_unknown', 'type'):\\n\", '                if rule not in definition and rule in self.schema[field]:\\n', '                    schema[field][rule] = self.schema[field][rule]\\n', \"            if 'allow_unknown' not in definition:\\n\", \"                schema[field]['allow_unknown'] = self.allow_unknown\\n\", '            validator = self._get_child_validator(\\n', '                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\\n', '            if validator(self.document, update=self.update, normalize=False):\\n', '                valid_counter += 1\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\\n', '                _errors.extend(validator._errors)\\n', '        return valid_counter, _errors\\n', \"        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\\n\", '        if valids < 1:\\n', '            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('allof', definitions, field, value)\\n\", '        if valids < len(definitions):\\n', '            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\\n\", '        if valids > 0:\\n', '            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\\n', \"        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\\n\", '        if valids != 1:\\n', '            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\\n', '            if value > max_value:\\n', '                self._error(field, errors.MAX_VALUE)\\n', '            if value < min_value:\\n', '                self._error(field, errors.MIN_VALUE)\\n', '        if isinstance(value, Iterable) and len(value) > max_length:\\n', '            self._error(field, errors.MAX_LENGTH, len(value))\\n', '        if isinstance(value, Iterable) and len(value) < min_length:\\n', '            self._error(field, errors.MIN_LENGTH, len(value))\\n', '        if value is None:\\n', '                self._error(field, errors.NULLABLE)\\n', '        if isinstance(value, Mapping):\\n', '            validator = self._get_child_validator(\\n', '                document_crumb=field,\\n', \"                schema_crumb=(field, 'keysrules'),\\n\", '                schema={k: schema for k in value.keys()},\\n', '            if not validator({k: k for k in value.keys()}, normalize=False):\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\\n', '                self._error(field, errors.KEYSRULES, validator._errors)\\n', '                self._error(field, errors.READONLY_FIELD)\\n', '            has_error = (\\n', '                    self.document_path + (field,)\\n', '            if self._is_normalized and has_error:\\n', '        if not isinstance(value, str):\\n', \"            pattern += '$'\\n\", '        re_obj = re.compile(pattern)\\n', '        if not re_obj.match(value):\\n', '            self._error(field, errors.REGEX_MISMATCH)\\n', '        required = set(\\n', '            field\\n', '            for field, definition in self.schema.items()\\n', \"            if self._resolve_rules_set(definition).get('required', self.require_all)\\n\", '        required -= self._unrequired_by_excludes\\n', '        missing = required - set(\\n', '            field\\n', '            for field in document\\n', '            if document.get(field) is not None or not self.ignore_none_values\\n', '        for field in missing:\\n', '            self._error(field, errors.REQUIRED_FIELD)\\n', '            fields = set(field for field in document if document.get(field) is not None)\\n', '            if self._unrequired_by_excludes.isdisjoint(fields):\\n', '                for field in self._unrequired_by_excludes - fields:\\n', '                    self._error(field, errors.REQUIRED_FIELD)\\n', '        if not isinstance(value, Mapping):\\n', '        schema = self._resolve_schema(schema)\\n', \"        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\\n\", \"        require_all = self.schema[field].get('require_all', self.require_all)\\n\", '        validator = self._get_child_validator(\\n', '            document_crumb=field,\\n', \"            schema_crumb=(field, 'schema'),\\n\", '            schema=schema,\\n', '            allow_unknown=allow_unknown,\\n', '            require_all=require_all,\\n', '        if not validator(value, update=self.update, normalize=False):\\n', '            self._error(field, errors.SCHEMA, validator._errors)\\n', '        for _type in data_type:\\n', '            if isinstance(_type, str):\\n', '                type_definition = self.types_mapping[_type]\\n', '                if isinstance(value, type_definition.included_types) and not isinstance(\\n', '                    value, type_definition.excluded_types\\n', '                if isinstance(value, _type):\\n', '        self._error(field, errors.TYPE)\\n', '        if isinstance(value, Mapping):\\n', \"            schema_crumb = (field, 'valuesrules')\\n\", '                document_crumb=field,\\n', '                schema_crumb=schema_crumb,\\n', '                schema={k: schema for k in value},\\n', '            validator(value, update=self.update, normalize=False)\\n', '            if validator._errors:\\n', '                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\\n', '                self._error(field, errors.VALUESRULES, validator._errors)\\n']",
  "context": "       if isinstance(value, Mapping):\n            schema_crumb = (field, 'valuesrules')\n            validator = self._get_child_validator("
 },
 "318": {
  "name": "__all__",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/platform.py",
  "lineno": "44",
  "column": "0",
  "slicing": "['__all__ = (\\n']",
  "context": "rom typing import get_origin as get_type_origin\n\n\n__all__ = (\n    \"ForwardRef\",\n    \"_GenericAlias\",\n    get_typ"
 },
 "319": {
  "name": "value",
  "type": "cerberus.base.normalize_rulesset",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/validator.py",
  "lineno": "28",
  "column": "12",
  "slicing": "['            value = normalize_rulesset(value)\\n', \"            ValidatedSchema(self, {'allow_unknown': value})\\n\", \"        self._config['allow_unknown'] = value\\n\"]",
  "context": "nce(value, (bool, ValidatedSchema))):\n            value = normalize_rulesset(value)\n            ValidatedSchema(self, {'allow_unknown'"
 },
 "320": {
  "name": "schema_1",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/benchmarks/test_overall_performance.py",
  "lineno": "48",
  "column": "0",
  "slicing": "['schema_1 = {\\n', '    return TestValidator(schema_1, purge_unknown=True)\\n']",
  "context": "       error(field, \"Requires a smaller list.\")\n\n\nschema_1 = {\n    \"field_1\": {\n        \"type\": \"dict\",\n        \""
 },
 "321": {
  "name": "types_mapping",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/benchmarks/test_overall_performance.py",
  "lineno": "98",
  "column": "8",
  "slicing": "['        types_mapping = {\\n']",
  "context": "_1():\n    class TestValidator(Validator):\n        types_mapping = {\n            **Validator.types_mapping,\n           "
 },
 "322": {
  "name": "init_validator",
  "type": "typing.Callable",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/benchmarks/test_overall_performance.py",
  "lineno": "112",
  "column": "23",
  "slicing": "['def validate_documents(init_validator: Callable, documents: List[dict]) -> None:\\n']",
  "context": "(f)\n    return documents\n\n\ndef validate_documents(init_validator: Callable, documents: List[dict]) -> None:\n    doc_count = failed_count = 0\n    error_paths: "
 },
 "323": {
  "name": "documents",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/benchmarks/test_overall_performance.py",
  "lineno": "112",
  "column": "49",
  "slicing": "['def validate_documents(init_validator: Callable, documents: List[dict]) -> None:\\n']",
  "context": "\ndef validate_documents(init_validator: Callable, documents: List[dict]) -> None:\n    doc_count = failed_count = 0\n    error_paths: "
 },
 "324": {
  "name": "error_paths",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/benchmarks/test_overall_performance.py",
  "lineno": "114",
  "column": "4",
  "slicing": "['    error_paths: CounterType[tuple] = Counter()\\n', '                error_paths[error.schema_path] += 1\\n', '        f\"{failed_count} out of {doc_count} documents failed with \"\\n', '    for path, count in error_paths.most_common(3):\\n', '        print(f\"{count}: {path}\")\\n']",
  "context": "t]) -> None:\n    doc_count = failed_count = 0\n    error_paths: CounterType[tuple] = Counter()\n    validator = init_validator()\n\n    def count_er"
 },
 "325": {
  "name": "validator",
  "type": "init_validator",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/benchmarks/test_overall_performance.py",
  "lineno": "115",
  "column": "4",
  "slicing": "['schema_1 = {\\n', '    return TestValidator(schema_1, purge_unknown=True)\\n', '    with (DOCUMENTS_PATH / \"overall_documents_1.json\").open() as f:\\n', '        documents = json.load(f)\\n', '    return documents\\n', '    validator = init_validator()\\n', '    for document in documents:\\n', '        if validator.validated(document) is None:\\n', '            count_errors(validator._errors)\\n', '        json.dump([generate_sample_document_1() for _ in range(10_000)], f)\\n']",
  "context": "  error_paths: CounterType[tuple] = Counter()\n    validator = init_validator()\n\n    def count_errors(errors):\n        if errors i"
 },
 "326": {
  "name": "result",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/benchmarks/test_overall_performance.py",
  "lineno": "151",
  "column": "4",
  "slicing": "['    result = {}\\n', '            result[f\"field_{i}\"] = globals()[f\"generate_document_1_field_{i}\"]()\\n', '    return result\\n', '        result[\"field_12\"] = 0\\n', '        result[\"field_14\"] = None\\n', '        result[\"field_15\"] = None\\n', '    return result\\n', '        result[\"field_22\"] = None\\n', '    if \"field_22\" in result and not randrange(100):\\n', '        result[\"field_23\"] = None\\n', '    return result\\n', '        result[\"field_31\"] = [randrange(2) for _ in range(randrange(20))]\\n', '        result[\"field_31\"] = None\\n', '        result[\"field_32\"] = [\\n', '        result[\"3_unknown\"] = [0] * (randrange(10) + 1)\\n', '    return result\\n']",
  "context": "#\n\n\ndef generate_sample_document_1() -> dict:\n    result = {}\n    for i in (1, 2, 3, 4, 5):\n        if randrange"
 },
 "327": {
  "name": "result",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/benchmarks/test_overall_performance.py",
  "lineno": "159",
  "column": "4",
  "slicing": "['    result: Dict[str, Optional[int]] = {\"field_11\": randrange(100), \"field_13\": 0}\\n', '        result[\"field_12\"] = 0\\n', '        result[\"field_14\"] = None\\n', '        result[\"field_15\"] = None\\n', '    return result\\n', '        result[\"field_22\"] = None\\n', '    if \"field_22\" in result and not randrange(100):\\n', '        result[\"field_23\"] = None\\n', '    return result\\n', '        result[\"field_31\"] = [randrange(2) for _ in range(randrange(20))]\\n', '        result[\"field_31\"] = None\\n', '        result[\"field_32\"] = [\\n', '        result[\"3_unknown\"] = [0] * (randrange(10) + 1)\\n', '    return result\\n']",
  "context": "\n\n\ndef generate_document_1_field_1() -> dict:\n    result: Dict[str, Optional[int]] = {\"field_11\": randrange(100), \"field_13\": 0}\n    if randrange(100):\n        result[\"field_12\"] "
 },
 "328": {
  "name": "result",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/benchmarks/test_overall_performance.py",
  "lineno": "171",
  "column": "4",
  "slicing": "['    result: Dict[str, Union[int, str, None]] = {\"field_21\": x + str(randrange(100)) + x}\\n', '        result[\"field_22\"] = None\\n', '    if \"field_22\" in result and not randrange(100):\\n', '        result[\"field_23\"] = None\\n', '    return result\\n', '        result[\"field_31\"] = [randrange(2) for _ in range(randrange(20))]\\n', '        result[\"field_31\"] = None\\n', '        result[\"field_32\"] = [\\n', '        result[\"3_unknown\"] = [0] * (randrange(10) + 1)\\n', '    return result\\n']",
  "context": "ct:\n    x = \"*\" if not randrange(50) else \" \"\n    result: Dict[str, Union[int, str, None]] = {\"field_21\": x + str(randrange(100)) + x}\n\n    if randrange(100):\n        result[\"field_22\"]"
 },
 "329": {
  "name": "result",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/benchmarks/test_overall_performance.py",
  "lineno": "182",
  "column": "4",
  "slicing": "['    result: Dict[str, Optional[list]] = {}\\n', '        result[\"field_31\"] = [randrange(2) for _ in range(randrange(20))]\\n', '        result[\"field_31\"] = None\\n', '        result[\"field_32\"] = [\\n', '        result[\"3_unknown\"] = [0] * (randrange(10) + 1)\\n', '    return result\\n']",
  "context": "\n\n\ndef generate_document_1_field_3() -> dict:\n    result: Dict[str, Optional[list]] = {}\n    if randrange(100):\n        result[\"field_31\"] "
 },
 "330": {
  "name": "v",
  "type": "cerberus.Validator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_zzz_validated_schema_cache.py",
  "lineno": "5",
  "column": "4",
  "slicing": "[\"    v = Validator({'foozifix': {'coerce': int}})\\n\", '    cache_size = len(v._valid_schemas)\\n', '    assert len(v._valid_schemas) == cache_size\\n', '    assert len(v._valid_schemas) == cache_size\\n', '    assert cache_size <= max_cache_size, (\\n', '        \"variable `max_cache_size` according to the added schemas.\" % cache_size\\n']",
  "context": "alidator\n\n\ndef test_validated_schema_cache():\n    v = Validator({'foozifix': {'coerce': int}})\n    cache_size = len(v._valid_schemas)\n\n    v = Va"
 },
 "331": {
  "name": "cache_size",
  "type": "len",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_zzz_validated_schema_cache.py",
  "lineno": "6",
  "column": "4",
  "slicing": "[\"    v = Validator({'foozifix': {'coerce': int}})\\n\", '    cache_size = len(v._valid_schemas)\\n', '    assert len(v._valid_schemas) == cache_size\\n', '    assert len(v._valid_schemas) == cache_size\\n', '    assert cache_size <= max_cache_size, (\\n', '        \"variable `max_cache_size` according to the added schemas.\" % cache_size\\n']",
  "context": " v = Validator({'foozifix': {'coerce': int}})\n    cache_size = len(v._valid_schemas)\n\n    v = Validator({'foozifix': {'type': 'integer'"
 },
 "332": {
  "name": "v",
  "type": "cerberus.Validator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_zzz_validated_schema_cache.py",
  "lineno": "8",
  "column": "4",
  "slicing": "[\"    v = Validator({'foozifix': {'coerce': int}})\\n\", '    cache_size = len(v._valid_schemas)\\n', \"    v = Validator({'foozifix': {'type': 'integer'}})\\n\", '    assert len(v._valid_schemas) == cache_size\\n', '    assert len(v._valid_schemas) == cache_size\\n', '    assert cache_size <= max_cache_size, (\\n', '        \"variable `max_cache_size` according to the added schemas.\" % cache_size\\n']",
  "context": "nt}})\n    cache_size = len(v._valid_schemas)\n\n    v = Validator({'foozifix': {'type': 'integer'}})\n    cache_size += 1\n    assert len(v._valid_schema"
 },
 "333": {
  "name": "cache_size",
  "type": "int",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/tests/test_zzz_validated_schema_cache.py",
  "lineno": "9",
  "column": "4",
  "slicing": "['    cache_size += 1\\n', '    assert len(v._valid_schemas) == cache_size\\n', '    assert len(v._valid_schemas) == cache_size\\n', '    assert cache_size <= max_cache_size, (\\n', '        \"variable `max_cache_size` according to the added schemas.\" % cache_size\\n']",
  "context": " Validator({'foozifix': {'type': 'integer'}})\n    cache_size += 1\n    assert len(v._valid_schemas) == cache_size\n\n  "
 },
 "334": {
  "name": "v",
  "type": "cerberus.Validator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_zzz_validated_schema_cache.py",
  "lineno": "12",
  "column": "4",
  "slicing": "[\"    v = Validator({'foozifix': {'coerce': int}})\\n\", '    cache_size = len(v._valid_schemas)\\n', \"    v = Validator({'foozifix': {'type': 'integer'}})\\n\", '    cache_size += 1\\n', '    assert len(v._valid_schemas) == cache_size\\n', \"    v = Validator({'foozifix': {'coerce': int}})\\n\", '    assert len(v._valid_schemas) == cache_size\\n', '    assert cache_size <= max_cache_size, (\\n', '        \"variable `max_cache_size` according to the added schemas.\" % cache_size\\n']",
  "context": "  assert len(v._valid_schemas) == cache_size\n\n    v = Validator({'foozifix': {'coerce': int}})\n    assert len(v._valid_schemas) == cache_size\n\n  "
 },
 "335": {
  "name": "validator",
  "type": "cerberus.Validator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_schema.py",
  "lineno": "16",
  "column": "4",
  "slicing": "['    validator = Validator()\\n', '        validator({}, schema=None)\\n', '        validator.schema = schema\\n', '        validator.schema = schema\\n', \"        validator.schema = {'foo': {'unknown': 'rule'}}\\n\", \"        validator.schema = {'foo': {'type': 'unknown'}}\\n\", \"        validator.schema = {field: 'this should really be a dict'}\\n\", '    assert validator.schema == {\\n', '    assert_success(document={\"field\": \"Aladdin Sane\"}, validator=validator)\\n', '    assert \"default_setter\" in validator.schema[\"field\"]\\n', '    assert validator.schema[\"field\"][rule][\"type\"] == (\"string\",)\\n']",
  "context": "or, assert_success\n\n\ndef test_empty_schema():\n    validator = Validator()\n    with raises(SchemaError, match=errors.MISSING_"
 },
 "336": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_schema.py",
  "lineno": "30",
  "column": "4",
  "slicing": "['    validator = Validator()\\n', '        validator({}, schema=None)\\n', '    schema = \"this string should really be dict\"\\n', '    msg = errors.SCHEMA_TYPE.format(schema)\\n', '    with raises(SchemaError, match=msg):\\n', '        validator.schema = schema\\n', \"    field = 'foo'\\n\", \"    schema = {field: {'schema': {'bar': {'type': 'strong'}}}}\\n\", '        validator.schema = schema\\n', '    msg = \"{\\'foo\\': [{\\'unknown\\': [\\'unknown rule\\']}]}\"\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {'foo': {'unknown': 'rule'}}\\n\", '    msg = str(\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {'foo': {'type': 'unknown'}}\\n\", \"    field = 'name'\\n\", '    msg = str({field: [\"must be one of these types: (\\'Mapping\\',)\"]})\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {field: 'this should really be a dict'}\\n\", \"    schema = {'foo': {'anyof': {'type': 'string'}}}\\n\", '    assert_schema_error({}, schema)\\n', \"    schema = {0: {'anyof': [{'coerce': lambda x: x}]}}\\n\", '    assert_schema_error({}, schema)\\n', '    schema = {\\n', \"    assert_schema_error({'doc': 'this is my document'}, schema)\\n\", '    schema = {\\n', \"    assert_schema_error({'doc': 'this is my document'}, schema)\\n\", \"    v = Validator({'foo': {'type': 'string'}})\\n\", '    assert repr(v.schema) == \"{\\'foo\\': {\\'type\\': (\\'string\\',)}}\"\\n', \"    schema = {'detroit': {'itemsrules': {'anyof_regex': ['^Aladdin', 'Sane$']}}}\\n\", '    v = Validator(schema)\\n', \"    assert v.schema['detroit']['itemsrules'] == {\\n\", '    assert validator.schema == {\\n', '    assert_success(document={\"field\": \"Aladdin Sane\"}, validator=validator)\\n', '    assert \"default_setter\" in validator.schema[\"field\"]\\n', '    assert validator.schema[\"field\"][rule][\"type\"] == (\"string\",)\\n']",
  "context": "hema_type_field(validator):\n    field = 'foo'\n    schema = {field: {'schema': {'bar': {'type': 'strong'}}}}\n    with raises(SchemaError):\n        validator.sc"
 },
 "337": {
  "name": "msg",
  "type": "str",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_schema.py",
  "lineno": "42",
  "column": "4",
  "slicing": "['    validator = Validator()\\n', '        validator({}, schema=None)\\n', '    schema = \"this string should really be dict\"\\n', '    msg = errors.SCHEMA_TYPE.format(schema)\\n', '    with raises(SchemaError, match=msg):\\n', '        validator.schema = schema\\n', \"    field = 'foo'\\n\", \"    schema = {field: {'schema': {'bar': {'type': 'strong'}}}}\\n\", '        validator.schema = schema\\n', '    msg = \"{\\'foo\\': [{\\'unknown\\': [\\'unknown rule\\']}]}\"\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {'foo': {'unknown': 'rule'}}\\n\", '    msg = str(\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {'foo': {'type': 'unknown'}}\\n\", \"    field = 'name'\\n\", '    msg = str({field: [\"must be one of these types: (\\'Mapping\\',)\"]})\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {field: 'this should really be a dict'}\\n\", \"    schema = {'foo': {'anyof': {'type': 'string'}}}\\n\", '    assert_schema_error({}, schema)\\n', \"    schema = {0: {'anyof': [{'coerce': lambda x: x}]}}\\n\", '    assert_schema_error({}, schema)\\n', '    schema = {\\n', \"    assert_schema_error({'doc': 'this is my document'}, schema)\\n\", '    schema = {\\n', \"    assert_schema_error({'doc': 'this is my document'}, schema)\\n\", \"    v = Validator({'foo': {'type': 'string'}})\\n\", '    assert repr(v.schema) == \"{\\'foo\\': {\\'type\\': (\\'string\\',)}}\"\\n', \"    schema = {'detroit': {'itemsrules': {'anyof_regex': ['^Aladdin', 'Sane$']}}}\\n\", '    v = Validator(schema)\\n', \"    assert v.schema['detroit']['itemsrules'] == {\\n\", '    assert validator.schema == {\\n', '    assert_success(document={\"field\": \"Aladdin Sane\"}, validator=validator)\\n', '    assert \"default_setter\" in validator.schema[\"field\"]\\n', '    assert validator.schema[\"field\"][rule][\"type\"] == (\"string\",)\\n']",
  "context": " 'rule'}}\n\n\ndef test_unknown_type(validator):\n    msg = str(\n        {\n            'foo': [\n                {\n "
 },
 "338": {
  "name": "msg",
  "type": "str",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_schema.py",
  "lineno": "73",
  "column": "4",
  "slicing": "['    validator = Validator()\\n', '        validator({}, schema=None)\\n', '    schema = \"this string should really be dict\"\\n', '    msg = errors.SCHEMA_TYPE.format(schema)\\n', '    with raises(SchemaError, match=msg):\\n', '        validator.schema = schema\\n', \"    field = 'foo'\\n\", \"    schema = {field: {'schema': {'bar': {'type': 'strong'}}}}\\n\", '        validator.schema = schema\\n', '    msg = \"{\\'foo\\': [{\\'unknown\\': [\\'unknown rule\\']}]}\"\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {'foo': {'unknown': 'rule'}}\\n\", '    msg = str(\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {'foo': {'type': 'unknown'}}\\n\", \"    field = 'name'\\n\", '    msg = str({field: [\"must be one of these types: (\\'Mapping\\',)\"]})\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {field: 'this should really be a dict'}\\n\", \"    schema = {'foo': {'anyof': {'type': 'string'}}}\\n\", '    assert_schema_error({}, schema)\\n', \"    schema = {0: {'anyof': [{'coerce': lambda x: x}]}}\\n\", '    assert_schema_error({}, schema)\\n', '    schema = {\\n', \"    assert_schema_error({'doc': 'this is my document'}, schema)\\n\", '    schema = {\\n', \"    assert_schema_error({'doc': 'this is my document'}, schema)\\n\", \"    v = Validator({'foo': {'type': 'string'}})\\n\", '    assert repr(v.schema) == \"{\\'foo\\': {\\'type\\': (\\'string\\',)}}\"\\n', \"    schema = {'detroit': {'itemsrules': {'anyof_regex': ['^Aladdin', 'Sane$']}}}\\n\", '    v = Validator(schema)\\n', \"    assert v.schema['detroit']['itemsrules'] == {\\n\", '    assert validator.schema == {\\n', '    assert_success(document={\"field\": \"Aladdin Sane\"}, validator=validator)\\n', '    assert \"default_setter\" in validator.schema[\"field\"]\\n', '    assert validator.schema[\"field\"][rule][\"type\"] == (\"string\",)\\n']",
  "context": "ema_definition(validator):\n    field = 'name'\n    msg = str({field: [\"must be one of these types: ('Mapping',)\"]})\n    with raises(SchemaError, match=re.escape(msg))"
 },
 "339": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_schema.py",
  "lineno": "79",
  "column": "4",
  "slicing": "['    validator = Validator()\\n', '        validator({}, schema=None)\\n', '    schema = \"this string should really be dict\"\\n', '    msg = errors.SCHEMA_TYPE.format(schema)\\n', '    with raises(SchemaError, match=msg):\\n', '        validator.schema = schema\\n', \"    field = 'foo'\\n\", \"    schema = {field: {'schema': {'bar': {'type': 'strong'}}}}\\n\", '        validator.schema = schema\\n', '    msg = \"{\\'foo\\': [{\\'unknown\\': [\\'unknown rule\\']}]}\"\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {'foo': {'unknown': 'rule'}}\\n\", '    msg = str(\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {'foo': {'type': 'unknown'}}\\n\", \"    field = 'name'\\n\", '    msg = str({field: [\"must be one of these types: (\\'Mapping\\',)\"]})\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {field: 'this should really be a dict'}\\n\", \"    schema = {'foo': {'anyof': {'type': 'string'}}}\\n\", '    assert_schema_error({}, schema)\\n', \"    schema = {0: {'anyof': [{'coerce': lambda x: x}]}}\\n\", '    assert_schema_error({}, schema)\\n', '    schema = {\\n', \"    assert_schema_error({'doc': 'this is my document'}, schema)\\n\", '    schema = {\\n', \"    assert_schema_error({'doc': 'this is my document'}, schema)\\n\", \"    v = Validator({'foo': {'type': 'string'}})\\n\", '    assert repr(v.schema) == \"{\\'foo\\': {\\'type\\': (\\'string\\',)}}\"\\n', \"    schema = {'detroit': {'itemsrules': {'anyof_regex': ['^Aladdin', 'Sane$']}}}\\n\", '    v = Validator(schema)\\n', \"    assert v.schema['detroit']['itemsrules'] == {\\n\", '    assert validator.schema == {\\n', '    assert_success(document={\"field\": \"Aladdin Sane\"}, validator=validator)\\n', '    assert \"default_setter\" in validator.schema[\"field\"]\\n', '    assert validator.schema[\"field\"][rule][\"type\"] == (\"string\",)\\n']",
  "context": "really be a dict'}\n\n\ndef test_bad_of_rules():\n    schema = {'foo': {'anyof': {'type': 'string'}}}\n    assert_schema_error({}, schema)\n\n\ndef test_nor"
 },
 "340": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_schema.py",
  "lineno": "84",
  "column": "4",
  "slicing": "['    validator = Validator()\\n', '        validator({}, schema=None)\\n', '    schema = \"this string should really be dict\"\\n', '    msg = errors.SCHEMA_TYPE.format(schema)\\n', '    with raises(SchemaError, match=msg):\\n', '        validator.schema = schema\\n', \"    field = 'foo'\\n\", \"    schema = {field: {'schema': {'bar': {'type': 'strong'}}}}\\n\", '        validator.schema = schema\\n', '    msg = \"{\\'foo\\': [{\\'unknown\\': [\\'unknown rule\\']}]}\"\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {'foo': {'unknown': 'rule'}}\\n\", '    msg = str(\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {'foo': {'type': 'unknown'}}\\n\", \"    field = 'name'\\n\", '    msg = str({field: [\"must be one of these types: (\\'Mapping\\',)\"]})\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {field: 'this should really be a dict'}\\n\", \"    schema = {'foo': {'anyof': {'type': 'string'}}}\\n\", '    assert_schema_error({}, schema)\\n', \"    schema = {0: {'anyof': [{'coerce': lambda x: x}]}}\\n\", '    assert_schema_error({}, schema)\\n', '    schema = {\\n', \"    assert_schema_error({'doc': 'this is my document'}, schema)\\n\", '    schema = {\\n', \"    assert_schema_error({'doc': 'this is my document'}, schema)\\n\", \"    v = Validator({'foo': {'type': 'string'}})\\n\", '    assert repr(v.schema) == \"{\\'foo\\': {\\'type\\': (\\'string\\',)}}\"\\n', \"    schema = {'detroit': {'itemsrules': {'anyof_regex': ['^Aladdin', 'Sane$']}}}\\n\", '    v = Validator(schema)\\n', \"    assert v.schema['detroit']['itemsrules'] == {\\n\", '    assert validator.schema == {\\n', '    assert_success(document={\"field\": \"Aladdin Sane\"}, validator=validator)\\n', '    assert \"default_setter\" in validator.schema[\"field\"]\\n', '    assert validator.schema[\"field\"][rule][\"type\"] == (\"string\",)\\n']",
  "context": "ormalization_rules_are_invalid_in_of_rules():\n    schema = {0: {'anyof': [{'coerce': lambda x: x}]}}\n    assert_schema_error({}, schema)\n\n\ndef test_any"
 },
 "341": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_schema.py",
  "lineno": "91",
  "column": "4",
  "slicing": "['    validator = Validator()\\n', '        validator({}, schema=None)\\n', '    schema = \"this string should really be dict\"\\n', '    msg = errors.SCHEMA_TYPE.format(schema)\\n', '    with raises(SchemaError, match=msg):\\n', '        validator.schema = schema\\n', \"    field = 'foo'\\n\", \"    schema = {field: {'schema': {'bar': {'type': 'strong'}}}}\\n\", '        validator.schema = schema\\n', '    msg = \"{\\'foo\\': [{\\'unknown\\': [\\'unknown rule\\']}]}\"\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {'foo': {'unknown': 'rule'}}\\n\", '    msg = str(\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {'foo': {'type': 'unknown'}}\\n\", \"    field = 'name'\\n\", '    msg = str({field: [\"must be one of these types: (\\'Mapping\\',)\"]})\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {field: 'this should really be a dict'}\\n\", \"    schema = {'foo': {'anyof': {'type': 'string'}}}\\n\", '    assert_schema_error({}, schema)\\n', \"    schema = {0: {'anyof': [{'coerce': lambda x: x}]}}\\n\", '    assert_schema_error({}, schema)\\n', '    schema = {\\n', \"    assert_schema_error({'doc': 'this is my document'}, schema)\\n\", '    schema = {\\n', \"    assert_schema_error({'doc': 'this is my document'}, schema)\\n\", \"    v = Validator({'foo': {'type': 'string'}})\\n\", '    assert repr(v.schema) == \"{\\'foo\\': {\\'type\\': (\\'string\\',)}}\"\\n', \"    schema = {'detroit': {'itemsrules': {'anyof_regex': ['^Aladdin', 'Sane$']}}}\\n\", '    v = Validator(schema)\\n', \"    assert v.schema['detroit']['itemsrules'] == {\\n\", '    assert validator.schema == {\\n', '    assert_success(document={\"field\": \"Aladdin Sane\"}, validator=validator)\\n', '    assert \"default_setter\" in validator.schema[\"field\"]\\n', '    assert validator.schema[\"field\"][rule][\"type\"] == (\"string\",)\\n']",
  "context": "llof' constraints are checked\n    # correctly\n    schema = {\n        'doc': {'type': 'dict', 'anyof': [{'schema"
 },
 "342": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_schema.py",
  "lineno": "96",
  "column": "4",
  "slicing": "['    validator = Validator()\\n', '        validator({}, schema=None)\\n', '    schema = \"this string should really be dict\"\\n', '    msg = errors.SCHEMA_TYPE.format(schema)\\n', '    with raises(SchemaError, match=msg):\\n', '        validator.schema = schema\\n', \"    field = 'foo'\\n\", \"    schema = {field: {'schema': {'bar': {'type': 'strong'}}}}\\n\", '        validator.schema = schema\\n', '    msg = \"{\\'foo\\': [{\\'unknown\\': [\\'unknown rule\\']}]}\"\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {'foo': {'unknown': 'rule'}}\\n\", '    msg = str(\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {'foo': {'type': 'unknown'}}\\n\", \"    field = 'name'\\n\", '    msg = str({field: [\"must be one of these types: (\\'Mapping\\',)\"]})\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {field: 'this should really be a dict'}\\n\", \"    schema = {'foo': {'anyof': {'type': 'string'}}}\\n\", '    assert_schema_error({}, schema)\\n', \"    schema = {0: {'anyof': [{'coerce': lambda x: x}]}}\\n\", '    assert_schema_error({}, schema)\\n', '    schema = {\\n', \"    assert_schema_error({'doc': 'this is my document'}, schema)\\n\", '    schema = {\\n', \"    assert_schema_error({'doc': 'this is my document'}, schema)\\n\", \"    v = Validator({'foo': {'type': 'string'}})\\n\", '    assert repr(v.schema) == \"{\\'foo\\': {\\'type\\': (\\'string\\',)}}\"\\n', \"    schema = {'detroit': {'itemsrules': {'anyof_regex': ['^Aladdin', 'Sane$']}}}\\n\", '    v = Validator(schema)\\n', \"    assert v.schema['detroit']['itemsrules'] == {\\n\", '    assert validator.schema == {\\n', '    assert_success(document={\"field\": \"Aladdin Sane\"}, validator=validator)\\n', '    assert \"default_setter\" in validator.schema[\"field\"]\\n', '    assert validator.schema[\"field\"][rule][\"type\"] == (\"string\",)\\n']",
  "context": "rror({'doc': 'this is my document'}, schema)\n\n    schema = {\n        'doc': {'type': 'dict', 'allof': [{'schema"
 },
 "343": {
  "name": "v",
  "type": "cerberus.Validator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_schema.py",
  "lineno": "103",
  "column": "4",
  "slicing": "['    validator = Validator()\\n', '        validator({}, schema=None)\\n', '    schema = \"this string should really be dict\"\\n', '    msg = errors.SCHEMA_TYPE.format(schema)\\n', '    with raises(SchemaError, match=msg):\\n', '        validator.schema = schema\\n', \"    field = 'foo'\\n\", \"    schema = {field: {'schema': {'bar': {'type': 'strong'}}}}\\n\", '        validator.schema = schema\\n', '    msg = \"{\\'foo\\': [{\\'unknown\\': [\\'unknown rule\\']}]}\"\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {'foo': {'unknown': 'rule'}}\\n\", '    msg = str(\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {'foo': {'type': 'unknown'}}\\n\", \"    field = 'name'\\n\", '    msg = str({field: [\"must be one of these types: (\\'Mapping\\',)\"]})\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {field: 'this should really be a dict'}\\n\", \"    schema = {'foo': {'anyof': {'type': 'string'}}}\\n\", '    assert_schema_error({}, schema)\\n', \"    schema = {0: {'anyof': [{'coerce': lambda x: x}]}}\\n\", '    assert_schema_error({}, schema)\\n', '    schema = {\\n', \"    assert_schema_error({'doc': 'this is my document'}, schema)\\n\", '    schema = {\\n', \"    assert_schema_error({'doc': 'this is my document'}, schema)\\n\", \"    v = Validator({'foo': {'type': 'string'}})\\n\", '    assert repr(v.schema) == \"{\\'foo\\': {\\'type\\': (\\'string\\',)}}\"\\n', \"    schema = {'detroit': {'itemsrules': {'anyof_regex': ['^Aladdin', 'Sane$']}}}\\n\", '    v = Validator(schema)\\n', \"    assert v.schema['detroit']['itemsrules'] == {\\n\", '    assert validator.schema == {\\n', '    assert_success(document={\"field\": \"Aladdin Sane\"}, validator=validator)\\n', '    assert \"default_setter\" in validator.schema[\"field\"]\\n', '    assert validator.schema[\"field\"][rule][\"type\"] == (\"string\",)\\n']",
  "context": " is my document'}, schema)\n\n\ndef test_repr():\n    v = Validator({'foo': {'type': 'string'}})\n    assert repr(v.schema) == \"{'foo': {'type': ('s"
 },
 "344": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_schema.py",
  "lineno": "108",
  "column": "4",
  "slicing": "['    validator = Validator()\\n', '        validator({}, schema=None)\\n', '    schema = \"this string should really be dict\"\\n', '    msg = errors.SCHEMA_TYPE.format(schema)\\n', '    with raises(SchemaError, match=msg):\\n', '        validator.schema = schema\\n', \"    field = 'foo'\\n\", \"    schema = {field: {'schema': {'bar': {'type': 'strong'}}}}\\n\", '        validator.schema = schema\\n', '    msg = \"{\\'foo\\': [{\\'unknown\\': [\\'unknown rule\\']}]}\"\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {'foo': {'unknown': 'rule'}}\\n\", '    msg = str(\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {'foo': {'type': 'unknown'}}\\n\", \"    field = 'name'\\n\", '    msg = str({field: [\"must be one of these types: (\\'Mapping\\',)\"]})\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {field: 'this should really be a dict'}\\n\", \"    schema = {'foo': {'anyof': {'type': 'string'}}}\\n\", '    assert_schema_error({}, schema)\\n', \"    schema = {0: {'anyof': [{'coerce': lambda x: x}]}}\\n\", '    assert_schema_error({}, schema)\\n', '    schema = {\\n', \"    assert_schema_error({'doc': 'this is my document'}, schema)\\n\", '    schema = {\\n', \"    assert_schema_error({'doc': 'this is my document'}, schema)\\n\", \"    v = Validator({'foo': {'type': 'string'}})\\n\", '    assert repr(v.schema) == \"{\\'foo\\': {\\'type\\': (\\'string\\',)}}\"\\n', \"    schema = {'detroit': {'itemsrules': {'anyof_regex': ['^Aladdin', 'Sane$']}}}\\n\", '    v = Validator(schema)\\n', \"    assert v.schema['detroit']['itemsrules'] == {\\n\", '    assert validator.schema == {\\n', '    assert_success(document={\"field\": \"Aladdin Sane\"}, validator=validator)\\n', '    assert \"default_setter\" in validator.schema[\"field\"]\\n', '    assert validator.schema[\"field\"][rule][\"type\"] == (\"string\",)\\n']",
  "context": ")}}\"\n\n\ndef test_expansion_in_nested_schema():\n    schema = {'detroit': {'itemsrules': {'anyof_regex': ['^Aladdin', 'Sane$']}}}\n    v = Validator(schema)\n    assert v.schema['det"
 },
 "345": {
  "name": "v",
  "type": "cerberus.Validator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_schema.py",
  "lineno": "109",
  "column": "4",
  "slicing": "['    validator = Validator()\\n', '        validator({}, schema=None)\\n', '    schema = \"this string should really be dict\"\\n', '    msg = errors.SCHEMA_TYPE.format(schema)\\n', '    with raises(SchemaError, match=msg):\\n', '        validator.schema = schema\\n', \"    field = 'foo'\\n\", \"    schema = {field: {'schema': {'bar': {'type': 'strong'}}}}\\n\", '        validator.schema = schema\\n', '    msg = \"{\\'foo\\': [{\\'unknown\\': [\\'unknown rule\\']}]}\"\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {'foo': {'unknown': 'rule'}}\\n\", '    msg = str(\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {'foo': {'type': 'unknown'}}\\n\", \"    field = 'name'\\n\", '    msg = str({field: [\"must be one of these types: (\\'Mapping\\',)\"]})\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {field: 'this should really be a dict'}\\n\", \"    schema = {'foo': {'anyof': {'type': 'string'}}}\\n\", '    assert_schema_error({}, schema)\\n', \"    schema = {0: {'anyof': [{'coerce': lambda x: x}]}}\\n\", '    assert_schema_error({}, schema)\\n', '    schema = {\\n', \"    assert_schema_error({'doc': 'this is my document'}, schema)\\n\", '    schema = {\\n', \"    assert_schema_error({'doc': 'this is my document'}, schema)\\n\", \"    v = Validator({'foo': {'type': 'string'}})\\n\", '    assert repr(v.schema) == \"{\\'foo\\': {\\'type\\': (\\'string\\',)}}\"\\n', \"    schema = {'detroit': {'itemsrules': {'anyof_regex': ['^Aladdin', 'Sane$']}}}\\n\", '    v = Validator(schema)\\n', \"    assert v.schema['detroit']['itemsrules'] == {\\n\", '    assert validator.schema == {\\n', '    assert_success(document={\"field\": \"Aladdin Sane\"}, validator=validator)\\n', '    assert \"default_setter\" in validator.schema[\"field\"]\\n', '    assert validator.schema[\"field\"][rule][\"type\"] == (\"string\",)\\n']",
  "context": "es': {'anyof_regex': ['^Aladdin', 'Sane$']}}}\n    v = Validator(schema)\n    assert v.schema['detroit']['itemsrules'] == {\n"
 },
 "346": {
  "name": "validator",
  "type": "cerberus.Validator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_schema.py",
  "lineno": "122",
  "column": "4",
  "slicing": "['    validator = Validator()\\n', '        validator({}, schema=None)\\n', '    schema = \"this string should really be dict\"\\n', '    msg = errors.SCHEMA_TYPE.format(schema)\\n', '    with raises(SchemaError, match=msg):\\n', '        validator.schema = schema\\n', \"    field = 'foo'\\n\", \"    schema = {field: {'schema': {'bar': {'type': 'strong'}}}}\\n\", '        validator.schema = schema\\n', '    msg = \"{\\'foo\\': [{\\'unknown\\': [\\'unknown rule\\']}]}\"\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {'foo': {'unknown': 'rule'}}\\n\", '    msg = str(\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {'foo': {'type': 'unknown'}}\\n\", \"    field = 'name'\\n\", '    msg = str({field: [\"must be one of these types: (\\'Mapping\\',)\"]})\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {field: 'this should really be a dict'}\\n\", \"    schema = {'foo': {'anyof': {'type': 'string'}}}\\n\", '    assert_schema_error({}, schema)\\n', \"    schema = {0: {'anyof': [{'coerce': lambda x: x}]}}\\n\", '    assert_schema_error({}, schema)\\n', '    schema = {\\n', \"    assert_schema_error({'doc': 'this is my document'}, schema)\\n\", '    schema = {\\n', \"    assert_schema_error({'doc': 'this is my document'}, schema)\\n\", \"    v = Validator({'foo': {'type': 'string'}})\\n\", '    assert repr(v.schema) == \"{\\'foo\\': {\\'type\\': (\\'string\\',)}}\"\\n', \"    schema = {'detroit': {'itemsrules': {'anyof_regex': ['^Aladdin', 'Sane$']}}}\\n\", '    v = Validator(schema)\\n', \"    assert v.schema['detroit']['itemsrules'] == {\\n\", \"    validator = Validator({'field': {'anyof_check_with': [foo, bar]}})\\n\", '    assert validator.schema == {\\n', '    assert_success(document={\"field\": \"Aladdin Sane\"}, validator=validator)\\n', '    assert \"default_setter\" in validator.schema[\"field\"]\\n', '    assert validator.schema[\"field\"][rule][\"type\"] == (\"string\",)\\n']",
  "context": "  def bar(field, value, error):\n        pass\n\n    validator = Validator({'field': {'anyof_check_with': [foo, bar]}})\n\n    assert validator.schema == {\n        'field':"
 },
 "347": {
  "name": "validator",
  "type": "cerberus.UnconcernedValidator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_schema.py",
  "lineno": "130",
  "column": "4",
  "slicing": "['    validator = Validator()\\n', '        validator({}, schema=None)\\n', '    schema = \"this string should really be dict\"\\n', '    msg = errors.SCHEMA_TYPE.format(schema)\\n', '    with raises(SchemaError, match=msg):\\n', '        validator.schema = schema\\n', \"    field = 'foo'\\n\", \"    schema = {field: {'schema': {'bar': {'type': 'strong'}}}}\\n\", '        validator.schema = schema\\n', '    msg = \"{\\'foo\\': [{\\'unknown\\': [\\'unknown rule\\']}]}\"\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {'foo': {'unknown': 'rule'}}\\n\", '    msg = str(\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {'foo': {'type': 'unknown'}}\\n\", \"    field = 'name'\\n\", '    msg = str({field: [\"must be one of these types: (\\'Mapping\\',)\"]})\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {field: 'this should really be a dict'}\\n\", \"    schema = {'foo': {'anyof': {'type': 'string'}}}\\n\", '    assert_schema_error({}, schema)\\n', \"    schema = {0: {'anyof': [{'coerce': lambda x: x}]}}\\n\", '    assert_schema_error({}, schema)\\n', '    schema = {\\n', \"    assert_schema_error({'doc': 'this is my document'}, schema)\\n\", '    schema = {\\n', \"    assert_schema_error({'doc': 'this is my document'}, schema)\\n\", \"    v = Validator({'foo': {'type': 'string'}})\\n\", '    assert repr(v.schema) == \"{\\'foo\\': {\\'type\\': (\\'string\\',)}}\"\\n', \"    schema = {'detroit': {'itemsrules': {'anyof_regex': ['^Aladdin', 'Sane$']}}}\\n\", '    v = Validator(schema)\\n', \"    assert v.schema['detroit']['itemsrules'] == {\\n\", \"    validator = Validator({'field': {'anyof_check_with': [foo, bar]}})\\n\", '    assert validator.schema == {\\n', '    validator = UnconcernedValidator(\\n', '    assert_success(document={\"field\": \"Aladdin Sane\"}, validator=validator)\\n', '    assert \"default_setter\" in validator.schema[\"field\"]\\n', '    assert validator.schema[\"field\"][rule][\"type\"] == (\"string\",)\\n']",
  "context": "def test_expansion_with_unvalidated_schema():\n    validator = UnconcernedValidator(\n        {\"field\": {'allof_regex': ['^Aladdin .*', "
 },
 "348": {
  "name": "validator",
  "type": "cerberus.Validator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_schema.py",
  "lineno": "137",
  "column": "4",
  "slicing": "['    validator = Validator()\\n', '        validator({}, schema=None)\\n', '    schema = \"this string should really be dict\"\\n', '    msg = errors.SCHEMA_TYPE.format(schema)\\n', '    with raises(SchemaError, match=msg):\\n', '        validator.schema = schema\\n', \"    field = 'foo'\\n\", \"    schema = {field: {'schema': {'bar': {'type': 'strong'}}}}\\n\", '        validator.schema = schema\\n', '    msg = \"{\\'foo\\': [{\\'unknown\\': [\\'unknown rule\\']}]}\"\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {'foo': {'unknown': 'rule'}}\\n\", '    msg = str(\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {'foo': {'type': 'unknown'}}\\n\", \"    field = 'name'\\n\", '    msg = str({field: [\"must be one of these types: (\\'Mapping\\',)\"]})\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {field: 'this should really be a dict'}\\n\", \"    schema = {'foo': {'anyof': {'type': 'string'}}}\\n\", '    assert_schema_error({}, schema)\\n', \"    schema = {0: {'anyof': [{'coerce': lambda x: x}]}}\\n\", '    assert_schema_error({}, schema)\\n', '    schema = {\\n', \"    assert_schema_error({'doc': 'this is my document'}, schema)\\n\", '    schema = {\\n', \"    assert_schema_error({'doc': 'this is my document'}, schema)\\n\", \"    v = Validator({'foo': {'type': 'string'}})\\n\", '    assert repr(v.schema) == \"{\\'foo\\': {\\'type\\': (\\'string\\',)}}\"\\n', \"    schema = {'detroit': {'itemsrules': {'anyof_regex': ['^Aladdin', 'Sane$']}}}\\n\", '    v = Validator(schema)\\n', \"    assert v.schema['detroit']['itemsrules'] == {\\n\", \"    validator = Validator({'field': {'anyof_check_with': [foo, bar]}})\\n\", '    assert validator.schema == {\\n', '    validator = UnconcernedValidator(\\n', '    assert_success(document={\"field\": \"Aladdin Sane\"}, validator=validator)\\n', '    validator = Validator(\\n', '    assert \"default_setter\" in validator.schema[\"field\"]\\n', '    assert validator.schema[\"field\"][rule][\"type\"] == (\"string\",)\\n']",
  "context": "r)\n\n\ndef test_rulename_space_is_normalized():\n    validator = Validator(\n        schema={\"field\": {\"default setter\": lambda"
 },
 "349": {
  "name": "validator",
  "type": "cerberus.Validator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_schema.py",
  "lineno": "150",
  "column": "4",
  "slicing": "['    validator = Validator()\\n', '        validator({}, schema=None)\\n', '    schema = \"this string should really be dict\"\\n', '    msg = errors.SCHEMA_TYPE.format(schema)\\n', '    with raises(SchemaError, match=msg):\\n', '        validator.schema = schema\\n', \"    field = 'foo'\\n\", \"    schema = {field: {'schema': {'bar': {'type': 'strong'}}}}\\n\", '        validator.schema = schema\\n', '    msg = \"{\\'foo\\': [{\\'unknown\\': [\\'unknown rule\\']}]}\"\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {'foo': {'unknown': 'rule'}}\\n\", '    msg = str(\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {'foo': {'type': 'unknown'}}\\n\", \"    field = 'name'\\n\", '    msg = str({field: [\"must be one of these types: (\\'Mapping\\',)\"]})\\n', '    with raises(SchemaError, match=re.escape(msg)):\\n', \"        validator.schema = {field: 'this should really be a dict'}\\n\", \"    schema = {'foo': {'anyof': {'type': 'string'}}}\\n\", '    assert_schema_error({}, schema)\\n', \"    schema = {0: {'anyof': [{'coerce': lambda x: x}]}}\\n\", '    assert_schema_error({}, schema)\\n', '    schema = {\\n', \"    assert_schema_error({'doc': 'this is my document'}, schema)\\n\", '    schema = {\\n', \"    assert_schema_error({'doc': 'this is my document'}, schema)\\n\", \"    v = Validator({'foo': {'type': 'string'}})\\n\", '    assert repr(v.schema) == \"{\\'foo\\': {\\'type\\': (\\'string\\',)}}\"\\n', \"    schema = {'detroit': {'itemsrules': {'anyof_regex': ['^Aladdin', 'Sane$']}}}\\n\", '    v = Validator(schema)\\n', \"    assert v.schema['detroit']['itemsrules'] == {\\n\", \"    validator = Validator({'field': {'anyof_check_with': [foo, bar]}})\\n\", '    assert validator.schema == {\\n', '    validator = UnconcernedValidator(\\n', '    assert_success(document={\"field\": \"Aladdin Sane\"}, validator=validator)\\n', '    validator = Validator(\\n', '    assert \"default_setter\" in validator.schema[\"field\"]\\n', '    validator = Validator(\\n', '    assert validator.schema[\"field\"][rule][\"type\"] == (\"string\",)\\n']",
  "context": "egistry.add(\n        \"schema_ref\", {},\n    )\n\n    validator = Validator(\n        schema={\"field\": {rule: {\"type\": \"string\"}"
 },
 "350": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_registries.py",
  "lineno": "12",
  "column": "4",
  "slicing": "[\"    schema = {'a': {'schema': 'foo'}, 'b': {'schema': 'foo'}}\\n\", '    assert_success(document, schema)\\n', \"    assert_success({'soi': 'hello'}, schema)\\n\", \"    assert_success({'soi': {'id': 'hello'}}, schema)\\n\", '    assert_schema_error(document, schema)\\n', '    assert_success(document, schema)\\n']",
  "context": "istry.add('foo', {'bar': {'type': 'string'}})\n    schema = {'a': {'schema': 'foo'}, 'b': {'schema': 'foo'}}\n    document = {'a': {'bar': 'a'}, 'b': {'bar': 'b"
 },
 "351": {
  "name": "document",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_registries.py",
  "lineno": "13",
  "column": "4",
  "slicing": "[\"    document = {'a': {'bar': 'a'}, 'b': {'bar': 'b'}}\\n\", '    assert_success(document, schema)\\n', \"    assert_success(document, 'peng')\\n\", '    assert_schema_error(document, schema)\\n', '    assert_success(document, schema)\\n']",
  "context": "': {'schema': 'foo'}, 'b': {'schema': 'foo'}}\n    document = {'a': {'bar': 'a'}, 'b': {'bar': 'b'}}\n    assert_success(document, schema)\n\n\ndef test_to"
 },
 "352": {
  "name": "document",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_registries.py",
  "lineno": "19",
  "column": "4",
  "slicing": "[\"    document = {'foo': 42}\\n\", \"    assert_success(document, 'peng')\\n\", '    assert_schema_error(document, schema)\\n', '    assert_success(document, schema)\\n']",
  "context": "try.add('peng', {'foo': {'type': 'integer'}})\n    document = {'foo': 42}\n    assert_success(document, 'peng')\n\n\ndef test_ru"
 },
 "353": {
  "name": "v",
  "type": "cerberus.Validator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_registries.py",
  "lineno": "31",
  "column": "4",
  "slicing": "[\"    schema = {'a': {'schema': 'foo'}, 'b': {'schema': 'foo'}}\\n\", \"    document = {'a': {'bar': 'a'}, 'b': {'bar': 'b'}}\\n\", '    assert_success(document, schema)\\n', \"    document = {'foo': 42}\\n\", \"    assert_success(document, 'peng')\\n\", \"    v = Validator(allow_unknown='foo')\\n\", '    assert_success({0: 1}, {}, v)\\n', \"    assert_fail({0: 'one'}, {}, v)\\n\", '    assert_success({0: {1: {2: {}}}}, {}, v)\\n', \"    assert_success({'soi': 'hello'}, schema)\\n\", \"    assert_success({'soi': {'id': 'hello'}}, schema)\\n\", '    assert_schema_error(document, schema)\\n', '    assert_success(document, schema)\\n']",
  "context": "s_set_registry.add('foo', {'type': 'number'})\n    v = Validator(allow_unknown='foo')\n    assert_success({0: 1}, {}, v)\n    assert_fail("
 },
 "354": {
  "name": "v",
  "type": "cerberus.Validator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_registries.py",
  "lineno": "38",
  "column": "4",
  "slicing": "[\"    schema = {'a': {'schema': 'foo'}, 'b': {'schema': 'foo'}}\\n\", \"    document = {'a': {'bar': 'a'}, 'b': {'bar': 'b'}}\\n\", '    assert_success(document, schema)\\n', \"    document = {'foo': 42}\\n\", \"    assert_success(document, 'peng')\\n\", \"    v = Validator(allow_unknown='foo')\\n\", '    assert_success({0: 1}, {}, v)\\n', \"    assert_fail({0: 'one'}, {}, v)\\n\", \"    v = Validator(allow_unknown='self')\\n\", '    assert_success({0: {1: {2: {}}}}, {}, v)\\n', \"    assert_success({'soi': 'hello'}, schema)\\n\", \"    assert_success({'soi': {'id': 'hello'}}, schema)\\n\", '    assert_schema_error(document, schema)\\n', '    assert_success(document, schema)\\n']",
  "context": "', {'type': 'dict', 'allow_unknown': 'self'})\n    v = Validator(allow_unknown='self')\n    assert_success({0: {1: {2: {}}}}, {}, v)\n\n\ndef"
 },
 "355": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_registries.py",
  "lineno": "53",
  "column": "4",
  "slicing": "[\"    schema = {'soi': 'string_or_integer'}\\n\", \"    assert_success({'soi': 'hello'}, schema)\\n\", \"    assert_success({'soi': {'id': 'hello'}}, schema)\\n\", '    assert_schema_error(document, schema)\\n', '    assert_success(document, schema)\\n']",
  "context": "eger', {'anyof_type': ['string', 'integer']})\n    schema = {'soi': 'string_or_integer'}\n    assert_success({'soi': 'hello'}, schema)\n\n\ndef"
 },
 "356": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_registries.py",
  "lineno": "59",
  "column": "4",
  "slicing": "[\"    schema = {'soi': {'schema': 'soi_id'}}\\n\", \"    assert_success({'soi': {'id': 'hello'}}, schema)\\n\", '    assert_schema_error(document, schema)\\n', '    assert_success(document, schema)\\n']",
  "context": "'id': {'anyof_type': ['string', 'integer']}})\n    schema = {'soi': {'schema': 'soi_id'}}\n    assert_success({'soi': {'id': 'hello'}}, schem"
 },
 "357": {
  "name": "document",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_registries.py",
  "lineno": "74",
  "column": "4",
  "slicing": "[\"    document = {'a_dict': {'foo': 1}}\\n\", '    assert_schema_error(document, schema)\\n', '    assert_success(document, schema)\\n']",
  "context": "oo'})\n\n\ndef test_rules_set_with_dict_field():\n    document = {'a_dict': {'foo': 1}}\n    schema = {'a_dict': {'type': 'dict', 'schema':"
 },
 "358": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_registries.py",
  "lineno": "75",
  "column": "4",
  "slicing": "[\"    schema = {'a_dict': {'type': 'dict', 'schema': {'foo': 'rule'}}}\\n\", '    assert_schema_error(document, schema)\\n', '    assert_success(document, schema)\\n']",
  "context": "ield():\n    document = {'a_dict': {'foo': 1}}\n    schema = {'a_dict': {'type': 'dict', 'schema': {'foo': 'rule'}}}\n\n    # the schema's not yet added to the valid one"
 },
 "359": {
  "name": "lesser",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_utils.py",
  "lineno": "5",
  "column": "4",
  "slicing": "[\"    lesser = ('a_dict', 'keysrules')\\n\", '    assert compare_paths_lt(lesser, greater)\\n', '    assert compare_paths_lt(lesser, greater)\\n']",
  "context": " compare_paths_lt\n\n\ndef test_compare_paths():\n    lesser = ('a_dict', 'keysrules')\n    greater = ('a_dict', 'valuesrules')\n    assert"
 },
 "360": {
  "name": "greater",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_utils.py",
  "lineno": "6",
  "column": "4",
  "slicing": "[\"    greater = ('a_dict', 'valuesrules')\\n\", '    assert compare_paths_lt(lesser, greater)\\n', '    assert compare_paths_lt(lesser, greater)\\n']",
  "context": "paths():\n    lesser = ('a_dict', 'keysrules')\n    greater = ('a_dict', 'valuesrules')\n    assert compare_paths_lt(lesser, greater)\n\n    "
 },
 "361": {
  "name": "lesser",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_utils.py",
  "lineno": "9",
  "column": "4",
  "slicing": "[\"    lesser += ('type',)\\n\", '    assert compare_paths_lt(lesser, greater)\\n']",
  "context": "    assert compare_paths_lt(lesser, greater)\n\n    lesser += ('type',)\n    greater += ('regex',)\n    assert compare_paths"
 },
 "362": {
  "name": "greater",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_utils.py",
  "lineno": "10",
  "column": "4",
  "slicing": "[\"    greater += ('regex',)\\n\", '    assert compare_paths_lt(lesser, greater)\\n']",
  "context": "_lt(lesser, greater)\n\n    lesser += ('type',)\n    greater += ('regex',)\n    assert compare_paths_lt(lesser, greater)\n"
 },
 "363": {
  "name": "value",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_items.py",
  "lineno": "7",
  "column": "4",
  "slicing": "[\"    value = ['a string', 'not an integer']\\n\", '        document={field: value},\\n']",
  "context": "ms(validator):\n    field = 'a_list_of_values'\n    value = ['a string', 'not an integer']\n    assert_fail(\n        document={field: value},\n"
 },
 "364": {
  "name": "message",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_excludes.py",
  "lineno": "39",
  "column": "4",
  "slicing": "['    message = errors.BasicErrorHandler.messages[errors.EXCLUDES_FIELD.code]\\n', '        \\'that_field\\': [message.format(\"\\'this_field\\'\", field=\"that_field\")],\\n', '            message.format(\"\\'that_field\\', \\'bazo_field\\'\", field=\"this_field\")\\n']",
  "context": "        },\n        validator=validator,\n    )\n    message = errors.BasicErrorHandler.messages[errors.EXCLUDES_FIELD.code]\n    assert validator.errors == {\n        'that_fie"
 },
 "365": {
  "name": "max_value",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_max_min.py",
  "lineno": "13",
  "column": "4",
  "slicing": "[\"    max_value = schema[field]['max']\\n\", '    value = max_value + increment\\n', \"        {field: value}, error=(field, (field, 'max'), errors.MAX_VALUE, max_value)\\n\", \"        {field: value}, error=(field, (field, 'min'), errors.MIN_VALUE, min_value)\\n\"]",
  "context": "1)]\n)\ndef test_max(schema, field, increment):\n    max_value = schema[field]['max']\n    value = max_value + increment\n    assert_fail("
 },
 "366": {
  "name": "min_value",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_max_min.py",
  "lineno": "24",
  "column": "4",
  "slicing": "[\"    max_value = schema[field]['max']\\n\", '    value = max_value + increment\\n', \"        {field: value}, error=(field, (field, 'max'), errors.MAX_VALUE, max_value)\\n\", \"    min_value = schema[field]['min']\\n\", '    value = min_value - decrement\\n', \"        {field: value}, error=(field, (field, 'min'), errors.MIN_VALUE, min_value)\\n\"]",
  "context": "1)]\n)\ndef test_min(schema, field, decrement):\n    min_value = schema[field]['min']\n    value = min_value - decrement\n    assert_fail("
 },
 "367": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_max_min.py",
  "lineno": "32",
  "column": "4",
  "slicing": "[\"    max_value = schema[field]['max']\\n\", '    value = max_value + increment\\n', \"        {field: value}, error=(field, (field, 'max'), errors.MAX_VALUE, max_value)\\n\", \"    min_value = schema[field]['min']\\n\", '    value = min_value - decrement\\n', \"        {field: value}, error=(field, (field, 'min'), errors.MIN_VALUE, min_value)\\n\", \"    schema = {'date': {'min': date(1900, 1, 1), 'max': date(1999, 12, 31)}}\\n\", \"    assert_success({'date': date(1945, 5, 8)}, schema)\\n\", \"    assert_fail({'date': date(1871, 5, 10)}, schema)\\n\"]",
  "context": "ue)\n    )\n\n\ndef test_min_and_max_with_date():\n    schema = {'date': {'min': date(1900, 1, 1), 'max': date(1999, 12, 31)}}\n    assert_success({'date': date(1945, 5, 8)}, sch"
 },
 "368": {
  "name": "mapping_schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_itemsrules.py",
  "lineno": "11",
  "column": "4",
  "slicing": "['    mapping_schema = {\\n', \"    itemsrules = {'type': ('dict',), 'schema': mapping_schema}\\n\", \"        schema={field: {'type': 'list', 'itemsrules': itemsrules}},\\n\", \"        error=(field, (field, 'itemsrules'), errors.ITEMSRULES, itemsrules),\\n\", \"            ((field, 0), (field, 'itemsrules', 'schema'), errors.SCHEMA, mapping_schema)\\n\", \"        error=(field, (field, 'itemsrules'), errors.ITEMSRULES, itemsrules),\\n\"]",
  "context": "ema(validator):\n    field = 'a_list_of_dicts'\n    mapping_schema = {\n        'sku': {'type': ('string',)},\n        'pri"
 },
 "369": {
  "name": "itemsrules",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_itemsrules.py",
  "lineno": "15",
  "column": "4",
  "slicing": "['    mapping_schema = {\\n', \"    itemsrules = {'type': ('dict',), 'schema': mapping_schema}\\n\", \"        schema={field: {'type': 'list', 'itemsrules': itemsrules}},\\n\", \"        error=(field, (field, 'itemsrules'), errors.ITEMSRULES, itemsrules),\\n\", \"            ((field, 0), (field, 'itemsrules', 'schema'), errors.SCHEMA, mapping_schema)\\n\", \"        error=(field, (field, 'itemsrules'), errors.ITEMSRULES, itemsrules),\\n\"]",
  "context": "type': ('integer',), 'required': True},\n    }\n    itemsrules = {'type': ('dict',), 'schema': mapping_schema}\n\n    assert_fail(\n        schema={field: {'type': "
 },
 "370": {
  "name": "document",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_empty.py",
  "lineno": "10",
  "column": "4",
  "slicing": "[\"    field = 'test'\\n\", '    document = {field: value}\\n', '    assert_success(schema={field: {}}, document=document)\\n', '    assert_success(schema={field: {\"empty\": True}}, document=document)\\n', '        schema={field: {\"empty\": False}},\\n', '        document=document,\\n', \"        error=(field, (field, 'empty'), errors.EMPTY, False),\\n\"]",
  "context": "]))\ndef test_empty(value):\n    field = 'test'\n    document = {field: value}\n\n    assert_success(schema={field: {}}, document=d"
 },
 "371": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_of.py",
  "lineno": "23",
  "column": "4",
  "slicing": "[\"    schema = {'field': {'type': 'integer', 'anyof': [{'min': 0}, {'min': 10}]}}\\n\", '        schema=schema,\\n', \"    assert_fail(document={'field': 5.5}, schema=schema)\\n\", \"    assert_fail(document={'field': '5.5'}, schema=schema)\\n\", '    assert_success(schema=schema, document=document)\\n', '    assert_success(document=document, schema=schema, validator=validator)\\n', '    assert_fail(document=document, schema=schema, validator=validator)\\n', '    assert_success(document=document, schema=schema, validator=validator)\\n', '        schema,\\n', '        schema=schema,\\n', \"        error=('test', ('test', 'oneof'), errors.ONEOF, schema['test']['oneof']),\\n\", \"    assert_success(document={'test': {'known': 's', 'unknown': 'asd'}}, schema=schema)\\n\"]",
  "context": "ent=document,\n    )\n\n\ndef test_anyof_fails():\n    schema = {'field': {'type': 'integer', 'anyof': [{'min': 0}, {'min': 10}]}}\n    assert_fail(\n        document={'field': -1},\n "
 },
 "372": {
  "name": "valid_parts",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_of.py",
  "lineno": "94",
  "column": "4",
  "slicing": "[\"    schema = {'field': {'type': 'integer', 'anyof': [{'min': 0}, {'min': 10}]}}\\n\", '        schema=schema,\\n', \"    assert_fail(document={'field': 5.5}, schema=schema)\\n\", \"    assert_fail(document={'field': '5.5'}, schema=schema)\\n\", '    assert_success(schema=schema, document=document)\\n', '    valid_parts = (\\n', \"    valid_item = {'type': ('dict', 'string'), 'anyof': valid_parts}\\n\", \"    schema = {'parts': {'type': 'list', 'itemsrules': valid_item}}\\n\", '    assert_success(document=document, schema=schema, validator=validator)\\n', '    assert_fail(document=document, schema=schema, validator=validator)\\n', '    assert_success(document=document, schema=schema, validator=validator)\\n', '        schema,\\n', \"        error=('parts', ('parts', 'itemsrules'), errors.ITEMSRULES, valid_item),\\n\", \"            (('parts', 3), ('parts', 'itemsrules', 'anyof'), errors.ANYOF, valid_parts),\\n\", '        valid_parts,\\n', '        schema=schema,\\n', \"        error=('test', ('test', 'oneof'), errors.ONEOF, schema['test']['oneof']),\\n\", \"    assert_success(document={'test': {'known': 's', 'unknown': 'asd'}}, schema=schema)\\n\"]",
  "context": "est that a list of schemas can be specified.\n\n    valid_parts = (\n        {\n            'schema': {\n                "
 },
 "373": {
  "name": "valid_item",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_of.py",
  "lineno": "103",
  "column": "4",
  "slicing": "[\"    schema = {'field': {'type': 'integer', 'anyof': [{'min': 0}, {'min': 10}]}}\\n\", '        schema=schema,\\n', \"    assert_fail(document={'field': 5.5}, schema=schema)\\n\", \"    assert_fail(document={'field': '5.5'}, schema=schema)\\n\", '    assert_success(schema=schema, document=document)\\n', '    valid_parts = (\\n', \"    valid_item = {'type': ('dict', 'string'), 'anyof': valid_parts}\\n\", \"    schema = {'parts': {'type': 'list', 'itemsrules': valid_item}}\\n\", '    assert_success(document=document, schema=schema, validator=validator)\\n', '    assert_fail(document=document, schema=schema, validator=validator)\\n', '    assert_success(document=document, schema=schema, validator=validator)\\n', '        schema,\\n', \"        error=('parts', ('parts', 'itemsrules'), errors.ITEMSRULES, valid_item),\\n\", \"            (('parts', 3), ('parts', 'itemsrules', 'anyof'), errors.ANYOF, valid_parts),\\n\", '        valid_parts,\\n', '        schema=schema,\\n', \"        error=('test', ('test', 'oneof'), errors.ONEOF, schema['test']['oneof']),\\n\", \"    assert_success(document={'test': {'known': 's', 'unknown': 'asd'}}, schema=schema)\\n\"]",
  "context": ": (str,)}, 'count': {'type': (int,)}}},\n    )\n    valid_item = {'type': ('dict', 'string'), 'anyof': valid_parts}\n    schema = {'parts': {'type': 'list', 'itemsrule"
 },
 "374": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_of.py",
  "lineno": "104",
  "column": "4",
  "slicing": "[\"    schema = {'field': {'type': 'integer', 'anyof': [{'min': 0}, {'min': 10}]}}\\n\", '        schema=schema,\\n', \"    assert_fail(document={'field': 5.5}, schema=schema)\\n\", \"    assert_fail(document={'field': '5.5'}, schema=schema)\\n\", '    assert_success(schema=schema, document=document)\\n', '    valid_parts = (\\n', \"    valid_item = {'type': ('dict', 'string'), 'anyof': valid_parts}\\n\", \"    schema = {'parts': {'type': 'list', 'itemsrules': valid_item}}\\n\", '    assert_success(document=document, schema=schema, validator=validator)\\n', '    assert_fail(document=document, schema=schema, validator=validator)\\n', '    assert_success(document=document, schema=schema, validator=validator)\\n', '        schema,\\n', \"        error=('parts', ('parts', 'itemsrules'), errors.ITEMSRULES, valid_item),\\n\", \"            (('parts', 3), ('parts', 'itemsrules', 'anyof'), errors.ANYOF, valid_parts),\\n\", '        valid_parts,\\n', '        schema=schema,\\n', \"        error=('test', ('test', 'oneof'), errors.ONEOF, schema['test']['oneof']),\\n\", \"    assert_success(document={'test': {'known': 's', 'unknown': 'asd'}}, schema=schema)\\n\"]",
  "context": "e': ('dict', 'string'), 'anyof': valid_parts}\n    schema = {'parts': {'type': 'list', 'itemsrules': valid_item}}\n    document = {\n        'parts': [\n            {'"
 },
 "375": {
  "name": "document",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_of.py",
  "lineno": "105",
  "column": "4",
  "slicing": "['    document = {\\n', '    assert_success(document=document, schema=schema, validator=validator)\\n', '    document[\\'parts\\'].append({\\'product name\\': \"Monitors\", \\'count\\': 18})\\n', '    assert_fail(document=document, schema=schema, validator=validator)\\n', \"    document['parts'].pop()\\n\", '    assert_success(document=document, schema=schema, validator=validator)\\n', '    document[\\'parts\\'].append({\\'product name\\': \"Monitors\", \\'count\\': 18})\\n', \"    document['parts'].append(10)\\n\", '        document,\\n', '        document=document,\\n', '        document=document,\\n', '        document=document,\\n', '        document=document,\\n', \"        schema={'field': {'anyof_type': ['string', 'integer']}}, document=document\\n\", '        document=document,\\n', '        document=document,\\n']",
  "context": ": {'type': 'list', 'itemsrules': valid_item}}\n    document = {\n        'parts': [\n            {'model number': 'M"
 },
 "376": {
  "name": "_errors",
  "type": "cerberus.tests.assert_fail",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_of.py",
  "lineno": "127",
  "column": "4",
  "slicing": "[\"    schema = {'field': {'type': 'integer', 'anyof': [{'min': 0}, {'min': 10}]}}\\n\", '        schema=schema,\\n', \"    assert_fail(document={'field': 5.5}, schema=schema)\\n\", \"    assert_fail(document={'field': '5.5'}, schema=schema)\\n\", '    assert_success(schema=schema, document=document)\\n', '    valid_parts = (\\n', \"    valid_item = {'type': ('dict', 'string'), 'anyof': valid_parts}\\n\", \"    schema = {'parts': {'type': 'list', 'itemsrules': valid_item}}\\n\", '    document = {\\n', '    assert_success(document=document, schema=schema, validator=validator)\\n', '    document[\\'parts\\'].append({\\'product name\\': \"Monitors\", \\'count\\': 18})\\n', '    assert_fail(document=document, schema=schema, validator=validator)\\n', \"    document['parts'].pop()\\n\", '    assert_success(document=document, schema=schema, validator=validator)\\n', '    document[\\'parts\\'].append({\\'product name\\': \"Monitors\", \\'count\\': 18})\\n', \"    document['parts'].append(10)\\n\", '    _errors = assert_fail(\\n', '        document,\\n', '        schema,\\n', \"        error=('parts', ('parts', 'itemsrules'), errors.ITEMSRULES, valid_item),\\n\", \"            (('parts', 3), ('parts', 'itemsrules', 'anyof'), errors.ANYOF, valid_parts),\\n\", '        _errors,\\n', '        valid_parts,\\n', '    _errors = validator.errors\\n', \"    assert 'parts' in _errors\\n\", \"    assert 3 in _errors['parts'][-1]\\n\", '    assert _errors[\\'parts\\'][-1][3][0] == \"no definitions validate\"\\n', \"    scope = _errors['parts'][-1][3][-1]\\n\", \"    assert 'anyof definition 0' in scope\\n\", \"    assert 'anyof definition 1' in scope\\n\", '    assert scope[\\'anyof definition 0\\'] == [{\"product name\": [\"unknown field\"]}]\\n', '    assert scope[\\'anyof definition 1\\'] == [{\"product name\": [\"unknown field\"]}]\\n', '    assert _errors[\\'parts\\'][-1][4] == [\"must be one of these types: (\\'dict\\', \\'string\\')\"]\\n', '        document=document,\\n', '        document=document,\\n', '        document=document,\\n', '        document=document,\\n', \"        schema={'field': {'anyof_type': ['string', 'integer']}}, document=document\\n\", '        document=document,\\n', '        document=document,\\n', '        schema=schema,\\n', \"        error=('test', ('test', 'oneof'), errors.ONEOF, schema['test']['oneof']),\\n\", \"    assert_success(document={'test': {'known': 's', 'unknown': 'asd'}}, schema=schema)\\n\"]",
  "context": ")\n    # and invalid. numbers are not allowed.\n    _errors = assert_fail(\n        document,\n        schema,\n        validato"
 },
 "377": {
  "name": "scope",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_of.py",
  "lineno": "155",
  "column": "4",
  "slicing": "[\"    schema = {'field': {'type': 'integer', 'anyof': [{'min': 0}, {'min': 10}]}}\\n\", '        schema=schema,\\n', \"    assert_fail(document={'field': 5.5}, schema=schema)\\n\", \"    assert_fail(document={'field': '5.5'}, schema=schema)\\n\", '    assert_success(schema=schema, document=document)\\n', '    valid_parts = (\\n', \"    valid_item = {'type': ('dict', 'string'), 'anyof': valid_parts}\\n\", \"    schema = {'parts': {'type': 'list', 'itemsrules': valid_item}}\\n\", '    document = {\\n', '    assert_success(document=document, schema=schema, validator=validator)\\n', '    document[\\'parts\\'].append({\\'product name\\': \"Monitors\", \\'count\\': 18})\\n', '    assert_fail(document=document, schema=schema, validator=validator)\\n', \"    document['parts'].pop()\\n\", '    assert_success(document=document, schema=schema, validator=validator)\\n', '    document[\\'parts\\'].append({\\'product name\\': \"Monitors\", \\'count\\': 18})\\n', \"    document['parts'].append(10)\\n\", '    _errors = assert_fail(\\n', '        document,\\n', '        schema,\\n', \"        error=('parts', ('parts', 'itemsrules'), errors.ITEMSRULES, valid_item),\\n\", \"            (('parts', 3), ('parts', 'itemsrules', 'anyof'), errors.ANYOF, valid_parts),\\n\", '        _errors,\\n', '        valid_parts,\\n', '    _errors = validator.errors\\n', \"    assert 'parts' in _errors\\n\", \"    assert 3 in _errors['parts'][-1]\\n\", '    assert _errors[\\'parts\\'][-1][3][0] == \"no definitions validate\"\\n', \"    scope = _errors['parts'][-1][3][-1]\\n\", \"    assert 'anyof definition 0' in scope\\n\", \"    assert 'anyof definition 1' in scope\\n\", '    assert scope[\\'anyof definition 0\\'] == [{\"product name\": [\"unknown field\"]}]\\n', '    assert scope[\\'anyof definition 1\\'] == [{\"product name\": [\"unknown field\"]}]\\n', '    assert _errors[\\'parts\\'][-1][4] == [\"must be one of these types: (\\'dict\\', \\'string\\')\"]\\n', '        document=document,\\n', '        document=document,\\n', '        document=document,\\n', '        document=document,\\n', \"        schema={'field': {'anyof_type': ['string', 'integer']}}, document=document\\n\", '        document=document,\\n', '        document=document,\\n', '        schema=schema,\\n', \"        error=('test', ('test', 'oneof'), errors.ONEOF, schema['test']['oneof']),\\n\", \"    assert_success(document={'test': {'known': 's', 'unknown': 'asd'}}, schema=schema)\\n\"]",
  "context": "arts'][-1][3][0] == \"no definitions validate\"\n    scope = _errors['parts'][-1][3][-1]\n    assert 'anyof definition 0' in scope\n    asser"
 },
 "378": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_of.py",
  "lineno": "346",
  "column": "4",
  "slicing": "['    schema = {\\n', '        schema=schema,\\n', \"        error=('test', ('test', 'oneof'), errors.ONEOF, schema['test']['oneof']),\\n\", \"    assert_success(document={'test': {'known': 's', 'unknown': 'asd'}}, schema=schema)\\n\"]",
  "context": " https://github.com/pyeve/cerberus/issues/251\n    schema = {\n        'test': {\n            'oneof': (\n         "
 },
 "379": {
  "name": "validator",
  "type": "cerberus.Validator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_coerce.py",
  "lineno": "32",
  "column": "4",
  "slicing": "['    drop_prefix = lambda x: x[2:]  # noqa: E731\\n', '    upper = lambda x: x.upper()  # noqa: E731\\n', \"        schema={'foo': {'coerce': [hex, drop_prefix, upper]}},\\n\", \"    validator = Validator({'amount': {'coerce': int}})\\n\", '    validator.validate(document)\\n', '    assert validator.document is not document\\n', '    assert not validator(document)\\n', \"    assert validator.document['things'] == document['things']\\n\", '        validator=validator,\\n', '    assert validator.validated(document, schema) is None\\n', '        validator.validated(document, schema, always_return_document=True) == document\\n']",
  "context": "rors\n\n\ndef test_coerce_does_not_input_data():\n    validator = Validator({'amount': {'coerce': int}})\n    document = {'amount': '1'}\n    validator.valid"
 },
 "380": {
  "name": "document",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_coerce.py",
  "lineno": "33",
  "column": "4",
  "slicing": "['    drop_prefix = lambda x: x[2:]  # noqa: E731\\n', '    upper = lambda x: x.upper()  # noqa: E731\\n', \"        schema={'foo': {'coerce': [hex, drop_prefix, upper]}},\\n\", \"    validator = Validator({'amount': {'coerce': int}})\\n\", \"    document = {'amount': '1'}\\n\", '    validator.validate(document)\\n', '    assert validator.document is not document\\n', \"    schema = {'things': {'type': 'list', 'items': [{'coerce': int}, {'coerce': str}]}}\\n\", \"    document = {'things': ['1', 2]}\\n\", \"    expected = {'things': [1, '2']}\\n\", '    assert_normalized(document, expected, schema)\\n', '    validator = Validator(schema)\\n', \"    document['things'].append(3)\\n\", '    assert not validator(document)\\n', \"    assert validator.document['things'] == document['things']\\n\", '        validator=validator,\\n', '    schema = {\\n', \"    document = {'data': ['q']}\\n\", '    assert validator.validated(document, schema) is None\\n', '        validator.validated(document, schema, always_return_document=True) == document\\n', \"    schema = {'amount': {'coerce': int}}\\n\", \"    _errors = assert_fail({'amount': 'not_a_number'}, schema)\\n\", '    _errors[0].info = ()  # ignore exception message here\\n', \"        _errors, 'amount', ('amount', 'coerce'), errors.COERCION_FAILED, int\\n\", \"    schema = {'things': {'type': 'list', 'items': [{'coerce': int}, {'coerce': str}]}}\\n\", \"    document = {'things': ['not_a_number', 2]}\\n\", '    _errors = assert_fail(document, schema)\\n', '    _errors[0].info = ()  # ignore exception message here\\n', '        _errors,\\n', \"    schema = {'name': {'coerce': str.lower}}\\n\", \"    _errors = assert_fail({'name': 1234}, schema)\\n\", '    _errors[0].info = ()  # ignore exception message here\\n', \"        _errors, 'name', ('name', 'coerce'), errors.COERCION_FAILED, str.lower\\n\", '    schema = {\\n', \"    document = {'things': ['1', 2]}\\n\", '    _errors = assert_fail(document, schema)\\n', '    _errors[0].info = ()  # ignore exception message here\\n', '        _errors,\\n']",
  "context": "ator = Validator({'amount': {'coerce': int}})\n    document = {'amount': '1'}\n    validator.validate(document)\n    assert valida"
 },
 "381": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_coerce.py",
  "lineno": "47",
  "column": "4",
  "slicing": "['    drop_prefix = lambda x: x[2:]  # noqa: E731\\n', '    upper = lambda x: x.upper()  # noqa: E731\\n', \"        schema={'foo': {'coerce': [hex, drop_prefix, upper]}},\\n\", \"    validator = Validator({'amount': {'coerce': int}})\\n\", \"    document = {'amount': '1'}\\n\", '    validator.validate(document)\\n', '    assert validator.document is not document\\n', \"    schema = {'things': {'type': 'list', 'items': [{'coerce': int}, {'coerce': str}]}}\\n\", \"    document = {'things': ['1', 2]}\\n\", \"    expected = {'things': [1, '2']}\\n\", '    assert_normalized(document, expected, schema)\\n', '    validator = Validator(schema)\\n', \"    document['things'].append(3)\\n\", '    assert not validator(document)\\n', \"    assert validator.document['things'] == document['things']\\n\", '        validator=validator,\\n', '    schema = {\\n', \"    document = {'data': ['q']}\\n\", '    assert validator.validated(document, schema) is None\\n', '        validator.validated(document, schema, always_return_document=True) == document\\n', \"    schema = {'amount': {'coerce': int}}\\n\", \"    _errors = assert_fail({'amount': 'not_a_number'}, schema)\\n\", '    _errors[0].info = ()  # ignore exception message here\\n', \"        _errors, 'amount', ('amount', 'coerce'), errors.COERCION_FAILED, int\\n\", \"    schema = {'things': {'type': 'list', 'items': [{'coerce': int}, {'coerce': str}]}}\\n\", \"    document = {'things': ['not_a_number', 2]}\\n\", '    _errors = assert_fail(document, schema)\\n', '    _errors[0].info = ()  # ignore exception message here\\n', '        _errors,\\n', \"    schema = {'name': {'coerce': str.lower}}\\n\", \"    _errors = assert_fail({'name': 1234}, schema)\\n\", '    _errors[0].info = ()  # ignore exception message here\\n', \"        _errors, 'name', ('name', 'coerce'), errors.COERCION_FAILED, str.lower\\n\", '    schema = {\\n', \"    document = {'things': ['1', 2]}\\n\", '    _errors = assert_fail(document, schema)\\n', '    _errors[0].info = ()  # ignore exception message here\\n', '        _errors,\\n']",
  "context": "ar': 0}},\n    )\n\n\ndef test_coerce_in_items():\n    schema = {'things': {'type': 'list', 'items': [{'coerce': int}, {'coerce': str}]}}\n    document = {'things': ['1', 2]}\n    expected ="
 },
 "382": {
  "name": "document",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_coerce.py",
  "lineno": "48",
  "column": "4",
  "slicing": "['    drop_prefix = lambda x: x[2:]  # noqa: E731\\n', '    upper = lambda x: x.upper()  # noqa: E731\\n', \"        schema={'foo': {'coerce': [hex, drop_prefix, upper]}},\\n\", \"    validator = Validator({'amount': {'coerce': int}})\\n\", \"    document = {'amount': '1'}\\n\", '    validator.validate(document)\\n', '    assert validator.document is not document\\n', \"    schema = {'things': {'type': 'list', 'items': [{'coerce': int}, {'coerce': str}]}}\\n\", \"    document = {'things': ['1', 2]}\\n\", \"    expected = {'things': [1, '2']}\\n\", '    assert_normalized(document, expected, schema)\\n', '    validator = Validator(schema)\\n', \"    document['things'].append(3)\\n\", '    assert not validator(document)\\n', \"    assert validator.document['things'] == document['things']\\n\", '        validator=validator,\\n', '    schema = {\\n', \"    document = {'data': ['q']}\\n\", '    assert validator.validated(document, schema) is None\\n', '        validator.validated(document, schema, always_return_document=True) == document\\n', \"    schema = {'amount': {'coerce': int}}\\n\", \"    _errors = assert_fail({'amount': 'not_a_number'}, schema)\\n\", '    _errors[0].info = ()  # ignore exception message here\\n', \"        _errors, 'amount', ('amount', 'coerce'), errors.COERCION_FAILED, int\\n\", \"    schema = {'things': {'type': 'list', 'items': [{'coerce': int}, {'coerce': str}]}}\\n\", \"    document = {'things': ['not_a_number', 2]}\\n\", '    _errors = assert_fail(document, schema)\\n', '    _errors[0].info = ()  # ignore exception message here\\n', '        _errors,\\n', \"    schema = {'name': {'coerce': str.lower}}\\n\", \"    _errors = assert_fail({'name': 1234}, schema)\\n\", '    _errors[0].info = ()  # ignore exception message here\\n', \"        _errors, 'name', ('name', 'coerce'), errors.COERCION_FAILED, str.lower\\n\", '    schema = {\\n', \"    document = {'things': ['1', 2]}\\n\", '    _errors = assert_fail(document, schema)\\n', '    _errors[0].info = ()  # ignore exception message here\\n', '        _errors,\\n']",
  "context": "'items': [{'coerce': int}, {'coerce': str}]}}\n    document = {'things': ['1', 2]}\n    expected = {'things': [1, '2']}\n    assert_nor"
 },
 "383": {
  "name": "expected",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_coerce.py",
  "lineno": "49",
  "column": "4",
  "slicing": "[\"    expected = {'things': [1, '2']}\\n\", '    assert_normalized(document, expected, schema)\\n']",
  "context": ": str}]}}\n    document = {'things': ['1', 2]}\n    expected = {'things': [1, '2']}\n    assert_normalized(document, expected, schema)\n"
 },
 "384": {
  "name": "validator",
  "type": "cerberus.Validator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_coerce.py",
  "lineno": "52",
  "column": "4",
  "slicing": "['    drop_prefix = lambda x: x[2:]  # noqa: E731\\n', '    upper = lambda x: x.upper()  # noqa: E731\\n', \"        schema={'foo': {'coerce': [hex, drop_prefix, upper]}},\\n\", \"    validator = Validator({'amount': {'coerce': int}})\\n\", \"    document = {'amount': '1'}\\n\", '    validator.validate(document)\\n', '    assert validator.document is not document\\n', \"    schema = {'things': {'type': 'list', 'items': [{'coerce': int}, {'coerce': str}]}}\\n\", \"    document = {'things': ['1', 2]}\\n\", \"    expected = {'things': [1, '2']}\\n\", '    assert_normalized(document, expected, schema)\\n', '    validator = Validator(schema)\\n', \"    document['things'].append(3)\\n\", '    assert not validator(document)\\n', \"    assert validator.document['things'] == document['things']\\n\", '        validator=validator,\\n', '    schema = {\\n', \"    document = {'data': ['q']}\\n\", '    assert validator.validated(document, schema) is None\\n', '        validator.validated(document, schema, always_return_document=True) == document\\n', \"    schema = {'amount': {'coerce': int}}\\n\", \"    _errors = assert_fail({'amount': 'not_a_number'}, schema)\\n\", '    _errors[0].info = ()  # ignore exception message here\\n', \"        _errors, 'amount', ('amount', 'coerce'), errors.COERCION_FAILED, int\\n\", \"    schema = {'things': {'type': 'list', 'items': [{'coerce': int}, {'coerce': str}]}}\\n\", \"    document = {'things': ['not_a_number', 2]}\\n\", '    _errors = assert_fail(document, schema)\\n', '    _errors[0].info = ()  # ignore exception message here\\n', '        _errors,\\n', \"    schema = {'name': {'coerce': str.lower}}\\n\", \"    _errors = assert_fail({'name': 1234}, schema)\\n\", '    _errors[0].info = ()  # ignore exception message here\\n', \"        _errors, 'name', ('name', 'coerce'), errors.COERCION_FAILED, str.lower\\n\", '    schema = {\\n', \"    document = {'things': ['1', 2]}\\n\", '    _errors = assert_fail(document, schema)\\n', '    _errors[0].info = ()  # ignore exception message here\\n', '        _errors,\\n']",
  "context": "ssert_normalized(document, expected, schema)\n\n    validator = Validator(schema)\n    document['things'].append(3)\n    assert not va"
 },
 "385": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_coerce.py",
  "lineno": "80",
  "column": "4",
  "slicing": "['    drop_prefix = lambda x: x[2:]  # noqa: E731\\n', '    upper = lambda x: x.upper()  # noqa: E731\\n', \"        schema={'foo': {'coerce': [hex, drop_prefix, upper]}},\\n\", \"    validator = Validator({'amount': {'coerce': int}})\\n\", \"    document = {'amount': '1'}\\n\", '    validator.validate(document)\\n', '    assert validator.document is not document\\n', \"    schema = {'things': {'type': 'list', 'items': [{'coerce': int}, {'coerce': str}]}}\\n\", \"    document = {'things': ['1', 2]}\\n\", \"    expected = {'things': [1, '2']}\\n\", '    assert_normalized(document, expected, schema)\\n', '    validator = Validator(schema)\\n', \"    document['things'].append(3)\\n\", '    assert not validator(document)\\n', \"    assert validator.document['things'] == document['things']\\n\", '        validator=validator,\\n', '    schema = {\\n', \"    document = {'data': ['q']}\\n\", '    assert validator.validated(document, schema) is None\\n', '        validator.validated(document, schema, always_return_document=True) == document\\n', \"    schema = {'amount': {'coerce': int}}\\n\", \"    _errors = assert_fail({'amount': 'not_a_number'}, schema)\\n\", '    _errors[0].info = ()  # ignore exception message here\\n', \"        _errors, 'amount', ('amount', 'coerce'), errors.COERCION_FAILED, int\\n\", \"    schema = {'things': {'type': 'list', 'items': [{'coerce': int}, {'coerce': str}]}}\\n\", \"    document = {'things': ['not_a_number', 2]}\\n\", '    _errors = assert_fail(document, schema)\\n', '    _errors[0].info = ()  # ignore exception message here\\n', '        _errors,\\n', \"    schema = {'name': {'coerce': str.lower}}\\n\", \"    _errors = assert_fail({'name': 1234}, schema)\\n\", '    _errors[0].info = ()  # ignore exception message here\\n', \"        _errors, 'name', ('name', 'coerce'), errors.COERCION_FAILED, str.lower\\n\", '    schema = {\\n', \"    document = {'things': ['1', 2]}\\n\", '    _errors = assert_fail(document, schema)\\n', '    _errors[0].info = ()  # ignore exception message here\\n', '        _errors,\\n']",
  "context": " https://github.com/pyeve/cerberus/issues/211\n    schema = {\n        'data': {'type': 'list', 'itemsrules': {'t"
 },
 "386": {
  "name": "document",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_coerce.py",
  "lineno": "83",
  "column": "4",
  "slicing": "['    drop_prefix = lambda x: x[2:]  # noqa: E731\\n', '    upper = lambda x: x.upper()  # noqa: E731\\n', \"        schema={'foo': {'coerce': [hex, drop_prefix, upper]}},\\n\", \"    validator = Validator({'amount': {'coerce': int}})\\n\", \"    document = {'amount': '1'}\\n\", '    validator.validate(document)\\n', '    assert validator.document is not document\\n', \"    schema = {'things': {'type': 'list', 'items': [{'coerce': int}, {'coerce': str}]}}\\n\", \"    document = {'things': ['1', 2]}\\n\", \"    expected = {'things': [1, '2']}\\n\", '    assert_normalized(document, expected, schema)\\n', '    validator = Validator(schema)\\n', \"    document['things'].append(3)\\n\", '    assert not validator(document)\\n', \"    assert validator.document['things'] == document['things']\\n\", '        validator=validator,\\n', '    schema = {\\n', \"    document = {'data': ['q']}\\n\", '    assert validator.validated(document, schema) is None\\n', '        validator.validated(document, schema, always_return_document=True) == document\\n', \"    schema = {'amount': {'coerce': int}}\\n\", \"    _errors = assert_fail({'amount': 'not_a_number'}, schema)\\n\", '    _errors[0].info = ()  # ignore exception message here\\n', \"        _errors, 'amount', ('amount', 'coerce'), errors.COERCION_FAILED, int\\n\", \"    schema = {'things': {'type': 'list', 'items': [{'coerce': int}, {'coerce': str}]}}\\n\", \"    document = {'things': ['not_a_number', 2]}\\n\", '    _errors = assert_fail(document, schema)\\n', '    _errors[0].info = ()  # ignore exception message here\\n', '        _errors,\\n', \"    schema = {'name': {'coerce': str.lower}}\\n\", \"    _errors = assert_fail({'name': 1234}, schema)\\n\", '    _errors[0].info = ()  # ignore exception message here\\n', \"        _errors, 'name', ('name', 'coerce'), errors.COERCION_FAILED, str.lower\\n\", '    schema = {\\n', \"    document = {'things': ['1', 2]}\\n\", '    _errors = assert_fail(document, schema)\\n', '    _errors[0].info = ()  # ignore exception message here\\n', '        _errors,\\n']",
  "context": "s': {'type': 'integer', 'coerce': int}}\n    }\n    document = {'data': ['q']}\n    assert validator.validated(document, schema) i"
 },
 "387": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_coerce.py",
  "lineno": "134",
  "column": "4",
  "slicing": "['    drop_prefix = lambda x: x[2:]  # noqa: E731\\n', '    upper = lambda x: x.upper()  # noqa: E731\\n', \"        schema={'foo': {'coerce': [hex, drop_prefix, upper]}},\\n\", \"    validator = Validator({'amount': {'coerce': int}})\\n\", \"    document = {'amount': '1'}\\n\", '    validator.validate(document)\\n', '    assert validator.document is not document\\n', \"    schema = {'things': {'type': 'list', 'items': [{'coerce': int}, {'coerce': str}]}}\\n\", \"    document = {'things': ['1', 2]}\\n\", \"    expected = {'things': [1, '2']}\\n\", '    assert_normalized(document, expected, schema)\\n', '    validator = Validator(schema)\\n', \"    document['things'].append(3)\\n\", '    assert not validator(document)\\n', \"    assert validator.document['things'] == document['things']\\n\", '        validator=validator,\\n', '    schema = {\\n', \"    document = {'data': ['q']}\\n\", '    assert validator.validated(document, schema) is None\\n', '        validator.validated(document, schema, always_return_document=True) == document\\n', \"    schema = {'amount': {'coerce': int}}\\n\", \"    _errors = assert_fail({'amount': 'not_a_number'}, schema)\\n\", '    _errors[0].info = ()  # ignore exception message here\\n', \"        _errors, 'amount', ('amount', 'coerce'), errors.COERCION_FAILED, int\\n\", \"    schema = {'things': {'type': 'list', 'items': [{'coerce': int}, {'coerce': str}]}}\\n\", \"    document = {'things': ['not_a_number', 2]}\\n\", '    _errors = assert_fail(document, schema)\\n', '    _errors[0].info = ()  # ignore exception message here\\n', '        _errors,\\n', \"    schema = {'name': {'coerce': str.lower}}\\n\", \"    _errors = assert_fail({'name': 1234}, schema)\\n\", '    _errors[0].info = ()  # ignore exception message here\\n', \"        _errors, 'name', ('name', 'coerce'), errors.COERCION_FAILED, str.lower\\n\", '    schema = {\\n', \"    document = {'things': ['1', 2]}\\n\", '    _errors = assert_fail(document, schema)\\n', '    _errors[0].info = ()  # ignore exception message here\\n', '        _errors,\\n']",
  "context": "    )\n\n\ndef test_coerce_catches_ValueError():\n    schema = {'amount': {'coerce': int}}\n    _errors = assert_fail({'amount': 'not_a_number"
 },
 "388": {
  "name": "_errors",
  "type": "cerberus.tests.assert_fail",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_coerce.py",
  "lineno": "135",
  "column": "4",
  "slicing": "['    drop_prefix = lambda x: x[2:]  # noqa: E731\\n', '    upper = lambda x: x.upper()  # noqa: E731\\n', \"        schema={'foo': {'coerce': [hex, drop_prefix, upper]}},\\n\", \"    validator = Validator({'amount': {'coerce': int}})\\n\", \"    document = {'amount': '1'}\\n\", '    validator.validate(document)\\n', '    assert validator.document is not document\\n', \"    schema = {'things': {'type': 'list', 'items': [{'coerce': int}, {'coerce': str}]}}\\n\", \"    document = {'things': ['1', 2]}\\n\", \"    expected = {'things': [1, '2']}\\n\", '    assert_normalized(document, expected, schema)\\n', '    validator = Validator(schema)\\n', \"    document['things'].append(3)\\n\", '    assert not validator(document)\\n', \"    assert validator.document['things'] == document['things']\\n\", '        validator=validator,\\n', '    schema = {\\n', \"    document = {'data': ['q']}\\n\", '    assert validator.validated(document, schema) is None\\n', '        validator.validated(document, schema, always_return_document=True) == document\\n', \"    schema = {'amount': {'coerce': int}}\\n\", \"    _errors = assert_fail({'amount': 'not_a_number'}, schema)\\n\", '    _errors[0].info = ()  # ignore exception message here\\n', \"        _errors, 'amount', ('amount', 'coerce'), errors.COERCION_FAILED, int\\n\", \"    schema = {'things': {'type': 'list', 'items': [{'coerce': int}, {'coerce': str}]}}\\n\", \"    document = {'things': ['not_a_number', 2]}\\n\", '    _errors = assert_fail(document, schema)\\n', '    _errors[0].info = ()  # ignore exception message here\\n', '        _errors,\\n', \"    schema = {'name': {'coerce': str.lower}}\\n\", \"    _errors = assert_fail({'name': 1234}, schema)\\n\", '    _errors[0].info = ()  # ignore exception message here\\n', \"        _errors, 'name', ('name', 'coerce'), errors.COERCION_FAILED, str.lower\\n\", '    schema = {\\n', \"    document = {'things': ['1', 2]}\\n\", '    _errors = assert_fail(document, schema)\\n', '    _errors[0].info = ()  # ignore exception message here\\n', '        _errors,\\n']",
  "context": "r():\n    schema = {'amount': {'coerce': int}}\n    _errors = assert_fail({'amount': 'not_a_number'}, schema)\n    _errors[0].info = ()  # ignore exception messa"
 },
 "389": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_coerce.py",
  "lineno": "143",
  "column": "4",
  "slicing": "['    drop_prefix = lambda x: x[2:]  # noqa: E731\\n', '    upper = lambda x: x.upper()  # noqa: E731\\n', \"        schema={'foo': {'coerce': [hex, drop_prefix, upper]}},\\n\", \"    validator = Validator({'amount': {'coerce': int}})\\n\", \"    document = {'amount': '1'}\\n\", '    validator.validate(document)\\n', '    assert validator.document is not document\\n', \"    schema = {'things': {'type': 'list', 'items': [{'coerce': int}, {'coerce': str}]}}\\n\", \"    document = {'things': ['1', 2]}\\n\", \"    expected = {'things': [1, '2']}\\n\", '    assert_normalized(document, expected, schema)\\n', '    validator = Validator(schema)\\n', \"    document['things'].append(3)\\n\", '    assert not validator(document)\\n', \"    assert validator.document['things'] == document['things']\\n\", '        validator=validator,\\n', '    schema = {\\n', \"    document = {'data': ['q']}\\n\", '    assert validator.validated(document, schema) is None\\n', '        validator.validated(document, schema, always_return_document=True) == document\\n', \"    schema = {'amount': {'coerce': int}}\\n\", \"    _errors = assert_fail({'amount': 'not_a_number'}, schema)\\n\", '    _errors[0].info = ()  # ignore exception message here\\n', \"        _errors, 'amount', ('amount', 'coerce'), errors.COERCION_FAILED, int\\n\", \"    schema = {'things': {'type': 'list', 'items': [{'coerce': int}, {'coerce': str}]}}\\n\", \"    document = {'things': ['not_a_number', 2]}\\n\", '    _errors = assert_fail(document, schema)\\n', '    _errors[0].info = ()  # ignore exception message here\\n', '        _errors,\\n', \"    schema = {'name': {'coerce': str.lower}}\\n\", \"    _errors = assert_fail({'name': 1234}, schema)\\n\", '    _errors[0].info = ()  # ignore exception message here\\n', \"        _errors, 'name', ('name', 'coerce'), errors.COERCION_FAILED, str.lower\\n\", '    schema = {\\n', \"    document = {'things': ['1', 2]}\\n\", '    _errors = assert_fail(document, schema)\\n', '    _errors[0].info = ()  # ignore exception message here\\n', '        _errors,\\n']",
  "context": "est_coerce_in_listitems_catches_ValueError():\n    schema = {'things': {'type': 'list', 'items': [{'coerce': int}, {'coerce': str}]}}\n    document = {'things': ['not_a_number', 2]}\n   "
 },
 "390": {
  "name": "document",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_coerce.py",
  "lineno": "144",
  "column": "4",
  "slicing": "['    drop_prefix = lambda x: x[2:]  # noqa: E731\\n', '    upper = lambda x: x.upper()  # noqa: E731\\n', \"        schema={'foo': {'coerce': [hex, drop_prefix, upper]}},\\n\", \"    validator = Validator({'amount': {'coerce': int}})\\n\", \"    document = {'amount': '1'}\\n\", '    validator.validate(document)\\n', '    assert validator.document is not document\\n', \"    schema = {'things': {'type': 'list', 'items': [{'coerce': int}, {'coerce': str}]}}\\n\", \"    document = {'things': ['1', 2]}\\n\", \"    expected = {'things': [1, '2']}\\n\", '    assert_normalized(document, expected, schema)\\n', '    validator = Validator(schema)\\n', \"    document['things'].append(3)\\n\", '    assert not validator(document)\\n', \"    assert validator.document['things'] == document['things']\\n\", '        validator=validator,\\n', '    schema = {\\n', \"    document = {'data': ['q']}\\n\", '    assert validator.validated(document, schema) is None\\n', '        validator.validated(document, schema, always_return_document=True) == document\\n', \"    schema = {'amount': {'coerce': int}}\\n\", \"    _errors = assert_fail({'amount': 'not_a_number'}, schema)\\n\", '    _errors[0].info = ()  # ignore exception message here\\n', \"        _errors, 'amount', ('amount', 'coerce'), errors.COERCION_FAILED, int\\n\", \"    schema = {'things': {'type': 'list', 'items': [{'coerce': int}, {'coerce': str}]}}\\n\", \"    document = {'things': ['not_a_number', 2]}\\n\", '    _errors = assert_fail(document, schema)\\n', '    _errors[0].info = ()  # ignore exception message here\\n', '        _errors,\\n', \"    schema = {'name': {'coerce': str.lower}}\\n\", \"    _errors = assert_fail({'name': 1234}, schema)\\n\", '    _errors[0].info = ()  # ignore exception message here\\n', \"        _errors, 'name', ('name', 'coerce'), errors.COERCION_FAILED, str.lower\\n\", '    schema = {\\n', \"    document = {'things': ['1', 2]}\\n\", '    _errors = assert_fail(document, schema)\\n', '    _errors[0].info = ()  # ignore exception message here\\n', '        _errors,\\n']",
  "context": "'items': [{'coerce': int}, {'coerce': str}]}}\n    document = {'things': ['not_a_number', 2]}\n    _errors = assert_fail(document, schema)\n    _e"
 },
 "391": {
  "name": "_errors",
  "type": "cerberus.tests.assert_fail",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_coerce.py",
  "lineno": "145",
  "column": "4",
  "slicing": "['    drop_prefix = lambda x: x[2:]  # noqa: E731\\n', '    upper = lambda x: x.upper()  # noqa: E731\\n', \"        schema={'foo': {'coerce': [hex, drop_prefix, upper]}},\\n\", \"    validator = Validator({'amount': {'coerce': int}})\\n\", \"    document = {'amount': '1'}\\n\", '    validator.validate(document)\\n', '    assert validator.document is not document\\n', \"    schema = {'things': {'type': 'list', 'items': [{'coerce': int}, {'coerce': str}]}}\\n\", \"    document = {'things': ['1', 2]}\\n\", \"    expected = {'things': [1, '2']}\\n\", '    assert_normalized(document, expected, schema)\\n', '    validator = Validator(schema)\\n', \"    document['things'].append(3)\\n\", '    assert not validator(document)\\n', \"    assert validator.document['things'] == document['things']\\n\", '        validator=validator,\\n', '    schema = {\\n', \"    document = {'data': ['q']}\\n\", '    assert validator.validated(document, schema) is None\\n', '        validator.validated(document, schema, always_return_document=True) == document\\n', \"    schema = {'amount': {'coerce': int}}\\n\", \"    _errors = assert_fail({'amount': 'not_a_number'}, schema)\\n\", '    _errors[0].info = ()  # ignore exception message here\\n', \"        _errors, 'amount', ('amount', 'coerce'), errors.COERCION_FAILED, int\\n\", \"    schema = {'things': {'type': 'list', 'items': [{'coerce': int}, {'coerce': str}]}}\\n\", \"    document = {'things': ['not_a_number', 2]}\\n\", '    _errors = assert_fail(document, schema)\\n', '    _errors[0].info = ()  # ignore exception message here\\n', '        _errors,\\n', \"    schema = {'name': {'coerce': str.lower}}\\n\", \"    _errors = assert_fail({'name': 1234}, schema)\\n\", '    _errors[0].info = ()  # ignore exception message here\\n', \"        _errors, 'name', ('name', 'coerce'), errors.COERCION_FAILED, str.lower\\n\", '    schema = {\\n', \"    document = {'things': ['1', 2]}\\n\", '    _errors = assert_fail(document, schema)\\n', '    _errors[0].info = ()  # ignore exception message here\\n', '        _errors,\\n']",
  "context": "   document = {'things': ['not_a_number', 2]}\n    _errors = assert_fail(document, schema)\n    _errors[0].info = ()  # ignore exception messa"
 },
 "392": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_coerce.py",
  "lineno": "157",
  "column": "4",
  "slicing": "['    drop_prefix = lambda x: x[2:]  # noqa: E731\\n', '    upper = lambda x: x.upper()  # noqa: E731\\n', \"        schema={'foo': {'coerce': [hex, drop_prefix, upper]}},\\n\", \"    validator = Validator({'amount': {'coerce': int}})\\n\", \"    document = {'amount': '1'}\\n\", '    validator.validate(document)\\n', '    assert validator.document is not document\\n', \"    schema = {'things': {'type': 'list', 'items': [{'coerce': int}, {'coerce': str}]}}\\n\", \"    document = {'things': ['1', 2]}\\n\", \"    expected = {'things': [1, '2']}\\n\", '    assert_normalized(document, expected, schema)\\n', '    validator = Validator(schema)\\n', \"    document['things'].append(3)\\n\", '    assert not validator(document)\\n', \"    assert validator.document['things'] == document['things']\\n\", '        validator=validator,\\n', '    schema = {\\n', \"    document = {'data': ['q']}\\n\", '    assert validator.validated(document, schema) is None\\n', '        validator.validated(document, schema, always_return_document=True) == document\\n', \"    schema = {'amount': {'coerce': int}}\\n\", \"    _errors = assert_fail({'amount': 'not_a_number'}, schema)\\n\", '    _errors[0].info = ()  # ignore exception message here\\n', \"        _errors, 'amount', ('amount', 'coerce'), errors.COERCION_FAILED, int\\n\", \"    schema = {'things': {'type': 'list', 'items': [{'coerce': int}, {'coerce': str}]}}\\n\", \"    document = {'things': ['not_a_number', 2]}\\n\", '    _errors = assert_fail(document, schema)\\n', '    _errors[0].info = ()  # ignore exception message here\\n', '        _errors,\\n', \"    schema = {'name': {'coerce': str.lower}}\\n\", \"    _errors = assert_fail({'name': 1234}, schema)\\n\", '    _errors[0].info = ()  # ignore exception message here\\n', \"        _errors, 'name', ('name', 'coerce'), errors.COERCION_FAILED, str.lower\\n\", '    schema = {\\n', \"    document = {'things': ['1', 2]}\\n\", '    _errors = assert_fail(document, schema)\\n', '    _errors[0].info = ()  # ignore exception message here\\n', '        _errors,\\n']",
  "context": "\n    )\n\n\ndef test_coerce_catches_TypeError():\n    schema = {'name': {'coerce': str.lower}}\n    _errors = assert_fail({'name': 1234}, schema)\n"
 },
 "393": {
  "name": "_errors",
  "type": "cerberus.tests.assert_fail",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_coerce.py",
  "lineno": "158",
  "column": "4",
  "slicing": "['    drop_prefix = lambda x: x[2:]  # noqa: E731\\n', '    upper = lambda x: x.upper()  # noqa: E731\\n', \"        schema={'foo': {'coerce': [hex, drop_prefix, upper]}},\\n\", \"    validator = Validator({'amount': {'coerce': int}})\\n\", \"    document = {'amount': '1'}\\n\", '    validator.validate(document)\\n', '    assert validator.document is not document\\n', \"    schema = {'things': {'type': 'list', 'items': [{'coerce': int}, {'coerce': str}]}}\\n\", \"    document = {'things': ['1', 2]}\\n\", \"    expected = {'things': [1, '2']}\\n\", '    assert_normalized(document, expected, schema)\\n', '    validator = Validator(schema)\\n', \"    document['things'].append(3)\\n\", '    assert not validator(document)\\n', \"    assert validator.document['things'] == document['things']\\n\", '        validator=validator,\\n', '    schema = {\\n', \"    document = {'data': ['q']}\\n\", '    assert validator.validated(document, schema) is None\\n', '        validator.validated(document, schema, always_return_document=True) == document\\n', \"    schema = {'amount': {'coerce': int}}\\n\", \"    _errors = assert_fail({'amount': 'not_a_number'}, schema)\\n\", '    _errors[0].info = ()  # ignore exception message here\\n', \"        _errors, 'amount', ('amount', 'coerce'), errors.COERCION_FAILED, int\\n\", \"    schema = {'things': {'type': 'list', 'items': [{'coerce': int}, {'coerce': str}]}}\\n\", \"    document = {'things': ['not_a_number', 2]}\\n\", '    _errors = assert_fail(document, schema)\\n', '    _errors[0].info = ()  # ignore exception message here\\n', '        _errors,\\n', \"    schema = {'name': {'coerce': str.lower}}\\n\", \"    _errors = assert_fail({'name': 1234}, schema)\\n\", '    _errors[0].info = ()  # ignore exception message here\\n', \"        _errors, 'name', ('name', 'coerce'), errors.COERCION_FAILED, str.lower\\n\", '    schema = {\\n', \"    document = {'things': ['1', 2]}\\n\", '    _errors = assert_fail(document, schema)\\n', '    _errors[0].info = ()  # ignore exception message here\\n', '        _errors,\\n']",
  "context": "\n    schema = {'name': {'coerce': str.lower}}\n    _errors = assert_fail({'name': 1234}, schema)\n    _errors[0].info = ()  # ignore exception messa"
 },
 "394": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_coerce.py",
  "lineno": "166",
  "column": "4",
  "slicing": "['    drop_prefix = lambda x: x[2:]  # noqa: E731\\n', '    upper = lambda x: x.upper()  # noqa: E731\\n', \"        schema={'foo': {'coerce': [hex, drop_prefix, upper]}},\\n\", \"    validator = Validator({'amount': {'coerce': int}})\\n\", \"    document = {'amount': '1'}\\n\", '    validator.validate(document)\\n', '    assert validator.document is not document\\n', \"    schema = {'things': {'type': 'list', 'items': [{'coerce': int}, {'coerce': str}]}}\\n\", \"    document = {'things': ['1', 2]}\\n\", \"    expected = {'things': [1, '2']}\\n\", '    assert_normalized(document, expected, schema)\\n', '    validator = Validator(schema)\\n', \"    document['things'].append(3)\\n\", '    assert not validator(document)\\n', \"    assert validator.document['things'] == document['things']\\n\", '        validator=validator,\\n', '    schema = {\\n', \"    document = {'data': ['q']}\\n\", '    assert validator.validated(document, schema) is None\\n', '        validator.validated(document, schema, always_return_document=True) == document\\n', \"    schema = {'amount': {'coerce': int}}\\n\", \"    _errors = assert_fail({'amount': 'not_a_number'}, schema)\\n\", '    _errors[0].info = ()  # ignore exception message here\\n', \"        _errors, 'amount', ('amount', 'coerce'), errors.COERCION_FAILED, int\\n\", \"    schema = {'things': {'type': 'list', 'items': [{'coerce': int}, {'coerce': str}]}}\\n\", \"    document = {'things': ['not_a_number', 2]}\\n\", '    _errors = assert_fail(document, schema)\\n', '    _errors[0].info = ()  # ignore exception message here\\n', '        _errors,\\n', \"    schema = {'name': {'coerce': str.lower}}\\n\", \"    _errors = assert_fail({'name': 1234}, schema)\\n\", '    _errors[0].info = ()  # ignore exception message here\\n', \"        _errors, 'name', ('name', 'coerce'), errors.COERCION_FAILED, str.lower\\n\", '    schema = {\\n', \"    document = {'things': ['1', 2]}\\n\", '    _errors = assert_fail(document, schema)\\n', '    _errors[0].info = ()  # ignore exception message here\\n', '        _errors,\\n']",
  "context": "test_coerce_in_listitems_catches_TypeError():\n    schema = {\n        'things': {'type': 'list', 'items': [{'coe"
 },
 "395": {
  "name": "document",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_coerce.py",
  "lineno": "169",
  "column": "4",
  "slicing": "['    drop_prefix = lambda x: x[2:]  # noqa: E731\\n', '    upper = lambda x: x.upper()  # noqa: E731\\n', \"        schema={'foo': {'coerce': [hex, drop_prefix, upper]}},\\n\", \"    validator = Validator({'amount': {'coerce': int}})\\n\", \"    document = {'amount': '1'}\\n\", '    validator.validate(document)\\n', '    assert validator.document is not document\\n', \"    schema = {'things': {'type': 'list', 'items': [{'coerce': int}, {'coerce': str}]}}\\n\", \"    document = {'things': ['1', 2]}\\n\", \"    expected = {'things': [1, '2']}\\n\", '    assert_normalized(document, expected, schema)\\n', '    validator = Validator(schema)\\n', \"    document['things'].append(3)\\n\", '    assert not validator(document)\\n', \"    assert validator.document['things'] == document['things']\\n\", '        validator=validator,\\n', '    schema = {\\n', \"    document = {'data': ['q']}\\n\", '    assert validator.validated(document, schema) is None\\n', '        validator.validated(document, schema, always_return_document=True) == document\\n', \"    schema = {'amount': {'coerce': int}}\\n\", \"    _errors = assert_fail({'amount': 'not_a_number'}, schema)\\n\", '    _errors[0].info = ()  # ignore exception message here\\n', \"        _errors, 'amount', ('amount', 'coerce'), errors.COERCION_FAILED, int\\n\", \"    schema = {'things': {'type': 'list', 'items': [{'coerce': int}, {'coerce': str}]}}\\n\", \"    document = {'things': ['not_a_number', 2]}\\n\", '    _errors = assert_fail(document, schema)\\n', '    _errors[0].info = ()  # ignore exception message here\\n', '        _errors,\\n', \"    schema = {'name': {'coerce': str.lower}}\\n\", \"    _errors = assert_fail({'name': 1234}, schema)\\n\", '    _errors[0].info = ()  # ignore exception message here\\n', \"        _errors, 'name', ('name', 'coerce'), errors.COERCION_FAILED, str.lower\\n\", '    schema = {\\n', \"    document = {'things': ['1', 2]}\\n\", '    _errors = assert_fail(document, schema)\\n', '    _errors[0].info = ()  # ignore exception message here\\n', '        _errors,\\n']",
  "context": "'coerce': int}, {'coerce': str.lower}]}\n    }\n    document = {'things': ['1', 2]}\n    _errors = assert_fail(document, schema)\n    _e"
 },
 "396": {
  "name": "_errors",
  "type": "cerberus.tests.assert_fail",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_coerce.py",
  "lineno": "170",
  "column": "4",
  "slicing": "['    drop_prefix = lambda x: x[2:]  # noqa: E731\\n', '    upper = lambda x: x.upper()  # noqa: E731\\n', \"        schema={'foo': {'coerce': [hex, drop_prefix, upper]}},\\n\", \"    validator = Validator({'amount': {'coerce': int}})\\n\", \"    document = {'amount': '1'}\\n\", '    validator.validate(document)\\n', '    assert validator.document is not document\\n', \"    schema = {'things': {'type': 'list', 'items': [{'coerce': int}, {'coerce': str}]}}\\n\", \"    document = {'things': ['1', 2]}\\n\", \"    expected = {'things': [1, '2']}\\n\", '    assert_normalized(document, expected, schema)\\n', '    validator = Validator(schema)\\n', \"    document['things'].append(3)\\n\", '    assert not validator(document)\\n', \"    assert validator.document['things'] == document['things']\\n\", '        validator=validator,\\n', '    schema = {\\n', \"    document = {'data': ['q']}\\n\", '    assert validator.validated(document, schema) is None\\n', '        validator.validated(document, schema, always_return_document=True) == document\\n', \"    schema = {'amount': {'coerce': int}}\\n\", \"    _errors = assert_fail({'amount': 'not_a_number'}, schema)\\n\", '    _errors[0].info = ()  # ignore exception message here\\n', \"        _errors, 'amount', ('amount', 'coerce'), errors.COERCION_FAILED, int\\n\", \"    schema = {'things': {'type': 'list', 'items': [{'coerce': int}, {'coerce': str}]}}\\n\", \"    document = {'things': ['not_a_number', 2]}\\n\", '    _errors = assert_fail(document, schema)\\n', '    _errors[0].info = ()  # ignore exception message here\\n', '        _errors,\\n', \"    schema = {'name': {'coerce': str.lower}}\\n\", \"    _errors = assert_fail({'name': 1234}, schema)\\n\", '    _errors[0].info = ()  # ignore exception message here\\n', \"        _errors, 'name', ('name', 'coerce'), errors.COERCION_FAILED, str.lower\\n\", '    schema = {\\n', \"    document = {'things': ['1', 2]}\\n\", '    _errors = assert_fail(document, schema)\\n', '    _errors[0].info = ()  # ignore exception message here\\n', '        _errors,\\n']",
  "context": "}]}\n    }\n    document = {'things': ['1', 2]}\n    _errors = assert_fail(document, schema)\n    _errors[0].info = ()  # ignore exception messa"
 },
 "397": {
  "name": "v",
  "type": "MyNormalizer",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_coerce.py",
  "lineno": "190",
  "column": "4",
  "slicing": "['    drop_prefix = lambda x: x[2:]  # noqa: E731\\n', '    upper = lambda x: x.upper()  # noqa: E731\\n', \"        schema={'foo': {'coerce': [hex, drop_prefix, upper]}},\\n\", \"    validator = Validator({'amount': {'coerce': int}})\\n\", \"    document = {'amount': '1'}\\n\", '    validator.validate(document)\\n', '    assert validator.document is not document\\n', \"    schema = {'things': {'type': 'list', 'items': [{'coerce': int}, {'coerce': str}]}}\\n\", \"    document = {'things': ['1', 2]}\\n\", \"    expected = {'things': [1, '2']}\\n\", '    assert_normalized(document, expected, schema)\\n', '    validator = Validator(schema)\\n', \"    document['things'].append(3)\\n\", '    assert not validator(document)\\n', \"    assert validator.document['things'] == document['things']\\n\", '        validator=validator,\\n', '    schema = {\\n', \"    document = {'data': ['q']}\\n\", '    assert validator.validated(document, schema) is None\\n', '        validator.validated(document, schema, always_return_document=True) == document\\n', \"    schema = {'amount': {'coerce': int}}\\n\", \"    _errors = assert_fail({'amount': 'not_a_number'}, schema)\\n\", '    _errors[0].info = ()  # ignore exception message here\\n', \"        _errors, 'amount', ('amount', 'coerce'), errors.COERCION_FAILED, int\\n\", \"    schema = {'things': {'type': 'list', 'items': [{'coerce': int}, {'coerce': str}]}}\\n\", \"    document = {'things': ['not_a_number', 2]}\\n\", '    _errors = assert_fail(document, schema)\\n', '    _errors[0].info = ()  # ignore exception message here\\n', '        _errors,\\n', \"    schema = {'name': {'coerce': str.lower}}\\n\", \"    _errors = assert_fail({'name': 1234}, schema)\\n\", '    _errors[0].info = ()  # ignore exception message here\\n', \"        _errors, 'name', ('name', 'coerce'), errors.COERCION_FAILED, str.lower\\n\", '    schema = {\\n', \"    document = {'things': ['1', 2]}\\n\", '    _errors = assert_fail(document, schema)\\n', '    _errors[0].info = ()  # ignore exception message here\\n', '        _errors,\\n', \"    v = MyNormalizer(2, {'foo': {'coerce': 'multiply'}})\\n\", \"    assert v.normalized({'foo': 2})['foo'] == 4\\n\", '    assert v.normalized({3: None}) == {9: None}\\n']",
  "context": ":\n            return value * self.multiplier\n\n    v = MyNormalizer(2, {'foo': {'coerce': 'multiply'}})\n    assert v.normalized({'foo': 2})['foo'] == 4\n\n "
 },
 "398": {
  "name": "v",
  "type": "MyNormalizer",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_coerce.py",
  "lineno": "193",
  "column": "4",
  "slicing": "['    drop_prefix = lambda x: x[2:]  # noqa: E731\\n', '    upper = lambda x: x.upper()  # noqa: E731\\n', \"        schema={'foo': {'coerce': [hex, drop_prefix, upper]}},\\n\", \"    validator = Validator({'amount': {'coerce': int}})\\n\", \"    document = {'amount': '1'}\\n\", '    validator.validate(document)\\n', '    assert validator.document is not document\\n', \"    schema = {'things': {'type': 'list', 'items': [{'coerce': int}, {'coerce': str}]}}\\n\", \"    document = {'things': ['1', 2]}\\n\", \"    expected = {'things': [1, '2']}\\n\", '    assert_normalized(document, expected, schema)\\n', '    validator = Validator(schema)\\n', \"    document['things'].append(3)\\n\", '    assert not validator(document)\\n', \"    assert validator.document['things'] == document['things']\\n\", '        validator=validator,\\n', '    schema = {\\n', \"    document = {'data': ['q']}\\n\", '    assert validator.validated(document, schema) is None\\n', '        validator.validated(document, schema, always_return_document=True) == document\\n', \"    schema = {'amount': {'coerce': int}}\\n\", \"    _errors = assert_fail({'amount': 'not_a_number'}, schema)\\n\", '    _errors[0].info = ()  # ignore exception message here\\n', \"        _errors, 'amount', ('amount', 'coerce'), errors.COERCION_FAILED, int\\n\", \"    schema = {'things': {'type': 'list', 'items': [{'coerce': int}, {'coerce': str}]}}\\n\", \"    document = {'things': ['not_a_number', 2]}\\n\", '    _errors = assert_fail(document, schema)\\n', '    _errors[0].info = ()  # ignore exception message here\\n', '        _errors,\\n', \"    schema = {'name': {'coerce': str.lower}}\\n\", \"    _errors = assert_fail({'name': 1234}, schema)\\n\", '    _errors[0].info = ()  # ignore exception message here\\n', \"        _errors, 'name', ('name', 'coerce'), errors.COERCION_FAILED, str.lower\\n\", '    schema = {\\n', \"    document = {'things': ['1', 2]}\\n\", '    _errors = assert_fail(document, schema)\\n', '    _errors[0].info = ()  # ignore exception message here\\n', '        _errors,\\n', \"    v = MyNormalizer(2, {'foo': {'coerce': 'multiply'}})\\n\", \"    assert v.normalized({'foo': 2})['foo'] == 4\\n\", \"    v = MyNormalizer(3, allow_unknown={'rename_handler': 'multiply'})\\n\", '    assert v.normalized({3: None}) == {9: None}\\n']",
  "context": " assert v.normalized({'foo': 2})['foo'] == 4\n\n    v = MyNormalizer(3, allow_unknown={'rename_handler': 'multiply'})\n    assert v.normalized({3: None}) == {9: None}\n"
 },
 "399": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_nullable.py",
  "lineno": "34",
  "column": "4",
  "slicing": "[\"    schema = {'foo': {'coerce': failing_coercion, 'nullable': True, 'type': 'integer'}}\\n\", \"    assert_normalized(document={'foo': None}, expected={'foo': None}, schema=schema)\\n\", \"    assert_fail(document={'foo': 2}, schema=schema, validator=validator)\\n\"]",
  "context": "\n        raise Exception(\"expected to fail\")\n\n    schema = {'foo': {'coerce': failing_coercion, 'nullable': True, 'type': 'integer'}}\n\n    assert_normalized(document={'foo': None}, exp"
 },
 "400": {
  "name": "min_length",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_length.py",
  "lineno": "10",
  "column": "4",
  "slicing": "[\"    field = 'a_list_length'\\n\", \"    min_length = schema[field]['minlength']\\n\", \"    max_length = schema[field]['maxlength']\\n\", '        {field: [1] * (min_length - 1)},\\n', '            field,\\n', \"            (field, 'minlength'),\\n\", '            min_length,\\n', '            (min_length - 1,),\\n', '    for i in range(min_length, max_length):\\n', '        assert_success({field: [1] * i})\\n', '        {field: [1] * (max_length + 1)},\\n', '            field,\\n', \"            (field, 'maxlength'),\\n\", '            max_length,\\n', '            (max_length + 1,),\\n', \"    field = 'a_string'\\n\", \"    max_length = schema[field]['maxlength']\\n\", '    value = \"\".join(choice(ascii_lowercase) for i in range(max_length + 1))\\n', '        document={field: value},\\n', '            field,\\n', \"            (field, 'maxlength'),\\n\", '            max_length,\\n', '            (len(value),),\\n', \"    field = 'a_bytestring'\\n\", \"    max_length = schema[field]['maxlength']\\n\", \"    value = b'\\\\x00' * (max_length + 1)\\n\", '        document={field: value},\\n', '            field,\\n', \"            (field, 'maxlength'),\\n\", '            max_length,\\n', '            (len(value),),\\n', \"    field = 'a_string'\\n\", \"    min_length = schema[field]['minlength']\\n\", '    value = \"\".join(choice(ascii_lowercase) for i in range(min_length - 1))\\n', '        document={field: value},\\n', '            field,\\n', \"            (field, 'minlength'),\\n\", '            min_length,\\n', '            (len(value),),\\n', \"    field = 'a_bytestring'\\n\", \"    min_length = schema[field]['minlength']\\n\", \"    value = b'\\\\x00' * (min_length - 1)\\n\", '        document={field: value},\\n', '            field,\\n', \"            (field, 'minlength'),\\n\", '            min_length,\\n', '            (len(value),),\\n']",
  "context": "ith_list(schema):\n    field = 'a_list_length'\n    min_length = schema[field]['minlength']\n    max_length = schema[field]['maxlength']\n\n    a"
 },
 "401": {
  "name": "max_length",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_length.py",
  "lineno": "11",
  "column": "4",
  "slicing": "[\"    field = 'a_list_length'\\n\", \"    min_length = schema[field]['minlength']\\n\", \"    max_length = schema[field]['maxlength']\\n\", '        {field: [1] * (min_length - 1)},\\n', '            field,\\n', \"            (field, 'minlength'),\\n\", '            min_length,\\n', '            (min_length - 1,),\\n', '    for i in range(min_length, max_length):\\n', '        assert_success({field: [1] * i})\\n', '        {field: [1] * (max_length + 1)},\\n', '            field,\\n', \"            (field, 'maxlength'),\\n\", '            max_length,\\n', '            (max_length + 1,),\\n', \"    field = 'a_string'\\n\", \"    max_length = schema[field]['maxlength']\\n\", '    value = \"\".join(choice(ascii_lowercase) for i in range(max_length + 1))\\n', '        document={field: value},\\n', '            field,\\n', \"            (field, 'maxlength'),\\n\", '            max_length,\\n', '            (len(value),),\\n', \"    field = 'a_bytestring'\\n\", \"    max_length = schema[field]['maxlength']\\n\", \"    value = b'\\\\x00' * (max_length + 1)\\n\", '        document={field: value},\\n', '            field,\\n', \"            (field, 'maxlength'),\\n\", '            max_length,\\n', '            (len(value),),\\n', \"    field = 'a_string'\\n\", \"    min_length = schema[field]['minlength']\\n\", '    value = \"\".join(choice(ascii_lowercase) for i in range(min_length - 1))\\n', '        document={field: value},\\n', '            field,\\n', \"            (field, 'minlength'),\\n\", '            min_length,\\n', '            (len(value),),\\n', \"    field = 'a_bytestring'\\n\", \"    min_length = schema[field]['minlength']\\n\", \"    value = b'\\\\x00' * (min_length - 1)\\n\", '        document={field: value},\\n', '            field,\\n', \"            (field, 'minlength'),\\n\", '            min_length,\\n', '            (len(value),),\\n']",
  "context": "'\n    min_length = schema[field]['minlength']\n    max_length = schema[field]['maxlength']\n\n    assert_fail(\n        {field: [1] * (min_lengt"
 },
 "402": {
  "name": "max_length",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_length.py",
  "lineno": "41",
  "column": "4",
  "slicing": "[\"    field = 'a_list_length'\\n\", \"    min_length = schema[field]['minlength']\\n\", \"    max_length = schema[field]['maxlength']\\n\", '        {field: [1] * (min_length - 1)},\\n', '            field,\\n', \"            (field, 'minlength'),\\n\", '            min_length,\\n', '            (min_length - 1,),\\n', '    for i in range(min_length, max_length):\\n', '        assert_success({field: [1] * i})\\n', '        {field: [1] * (max_length + 1)},\\n', '            field,\\n', \"            (field, 'maxlength'),\\n\", '            max_length,\\n', '            (max_length + 1,),\\n', \"    field = 'a_string'\\n\", \"    max_length = schema[field]['maxlength']\\n\", '    value = \"\".join(choice(ascii_lowercase) for i in range(max_length + 1))\\n', '        document={field: value},\\n', '            field,\\n', \"            (field, 'maxlength'),\\n\", '            max_length,\\n', '            (len(value),),\\n', \"    field = 'a_bytestring'\\n\", \"    max_length = schema[field]['maxlength']\\n\", \"    value = b'\\\\x00' * (max_length + 1)\\n\", '        document={field: value},\\n', '            field,\\n', \"            (field, 'maxlength'),\\n\", '            max_length,\\n', '            (len(value),),\\n', \"    field = 'a_string'\\n\", \"    min_length = schema[field]['minlength']\\n\", '    value = \"\".join(choice(ascii_lowercase) for i in range(min_length - 1))\\n', '        document={field: value},\\n', '            field,\\n', \"            (field, 'minlength'),\\n\", '            min_length,\\n', '            (len(value),),\\n', \"    field = 'a_bytestring'\\n\", \"    min_length = schema[field]['minlength']\\n\", \"    value = b'\\\\x00' * (min_length - 1)\\n\", '        document={field: value},\\n', '            field,\\n', \"            (field, 'minlength'),\\n\", '            min_length,\\n', '            (len(value),),\\n']",
  "context": "xlength_fails(schema):\n    field = 'a_string'\n    max_length = schema[field]['maxlength']\n    value = \"\".join(choice(ascii_lowercase) for i "
 },
 "403": {
  "name": "max_length",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_length.py",
  "lineno": "57",
  "column": "4",
  "slicing": "[\"    field = 'a_list_length'\\n\", \"    min_length = schema[field]['minlength']\\n\", \"    max_length = schema[field]['maxlength']\\n\", '        {field: [1] * (min_length - 1)},\\n', '            field,\\n', \"            (field, 'minlength'),\\n\", '            min_length,\\n', '            (min_length - 1,),\\n', '    for i in range(min_length, max_length):\\n', '        assert_success({field: [1] * i})\\n', '        {field: [1] * (max_length + 1)},\\n', '            field,\\n', \"            (field, 'maxlength'),\\n\", '            max_length,\\n', '            (max_length + 1,),\\n', \"    field = 'a_string'\\n\", \"    max_length = schema[field]['maxlength']\\n\", '    value = \"\".join(choice(ascii_lowercase) for i in range(max_length + 1))\\n', '        document={field: value},\\n', '            field,\\n', \"            (field, 'maxlength'),\\n\", '            max_length,\\n', '            (len(value),),\\n', \"    field = 'a_bytestring'\\n\", \"    max_length = schema[field]['maxlength']\\n\", \"    value = b'\\\\x00' * (max_length + 1)\\n\", '        document={field: value},\\n', '            field,\\n', \"            (field, 'maxlength'),\\n\", '            max_length,\\n', '            (len(value),),\\n', \"    field = 'a_string'\\n\", \"    min_length = schema[field]['minlength']\\n\", '    value = \"\".join(choice(ascii_lowercase) for i in range(min_length - 1))\\n', '        document={field: value},\\n', '            field,\\n', \"            (field, 'minlength'),\\n\", '            min_length,\\n', '            (len(value),),\\n', \"    field = 'a_bytestring'\\n\", \"    min_length = schema[field]['minlength']\\n\", \"    value = b'\\\\x00' * (min_length - 1)\\n\", '        document={field: value},\\n', '            field,\\n', \"            (field, 'minlength'),\\n\", '            min_length,\\n', '            (len(value),),\\n']",
  "context": "ing_fails(schema):\n    field = 'a_bytestring'\n    max_length = schema[field]['maxlength']\n    value = b'\\x00' * (max_length + 1)\n    assert_"
 },
 "404": {
  "name": "min_length",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_length.py",
  "lineno": "73",
  "column": "4",
  "slicing": "[\"    field = 'a_list_length'\\n\", \"    min_length = schema[field]['minlength']\\n\", \"    max_length = schema[field]['maxlength']\\n\", '        {field: [1] * (min_length - 1)},\\n', '            field,\\n', \"            (field, 'minlength'),\\n\", '            min_length,\\n', '            (min_length - 1,),\\n', '    for i in range(min_length, max_length):\\n', '        assert_success({field: [1] * i})\\n', '        {field: [1] * (max_length + 1)},\\n', '            field,\\n', \"            (field, 'maxlength'),\\n\", '            max_length,\\n', '            (max_length + 1,),\\n', \"    field = 'a_string'\\n\", \"    max_length = schema[field]['maxlength']\\n\", '    value = \"\".join(choice(ascii_lowercase) for i in range(max_length + 1))\\n', '        document={field: value},\\n', '            field,\\n', \"            (field, 'maxlength'),\\n\", '            max_length,\\n', '            (len(value),),\\n', \"    field = 'a_bytestring'\\n\", \"    max_length = schema[field]['maxlength']\\n\", \"    value = b'\\\\x00' * (max_length + 1)\\n\", '        document={field: value},\\n', '            field,\\n', \"            (field, 'maxlength'),\\n\", '            max_length,\\n', '            (len(value),),\\n', \"    field = 'a_string'\\n\", \"    min_length = schema[field]['minlength']\\n\", '    value = \"\".join(choice(ascii_lowercase) for i in range(min_length - 1))\\n', '        document={field: value},\\n', '            field,\\n', \"            (field, 'minlength'),\\n\", '            min_length,\\n', '            (len(value),),\\n', \"    field = 'a_bytestring'\\n\", \"    min_length = schema[field]['minlength']\\n\", \"    value = b'\\\\x00' * (min_length - 1)\\n\", '        document={field: value},\\n', '            field,\\n', \"            (field, 'minlength'),\\n\", '            min_length,\\n', '            (len(value),),\\n']",
  "context": "nlength_fails(schema):\n    field = 'a_string'\n    min_length = schema[field]['minlength']\n    value = \"\".join(choice(ascii_lowercase) for i "
 },
 "405": {
  "name": "min_length",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_length.py",
  "lineno": "89",
  "column": "4",
  "slicing": "[\"    field = 'a_list_length'\\n\", \"    min_length = schema[field]['minlength']\\n\", \"    max_length = schema[field]['maxlength']\\n\", '        {field: [1] * (min_length - 1)},\\n', '            field,\\n', \"            (field, 'minlength'),\\n\", '            min_length,\\n', '            (min_length - 1,),\\n', '    for i in range(min_length, max_length):\\n', '        assert_success({field: [1] * i})\\n', '        {field: [1] * (max_length + 1)},\\n', '            field,\\n', \"            (field, 'maxlength'),\\n\", '            max_length,\\n', '            (max_length + 1,),\\n', \"    field = 'a_string'\\n\", \"    max_length = schema[field]['maxlength']\\n\", '    value = \"\".join(choice(ascii_lowercase) for i in range(max_length + 1))\\n', '        document={field: value},\\n', '            field,\\n', \"            (field, 'maxlength'),\\n\", '            max_length,\\n', '            (len(value),),\\n', \"    field = 'a_bytestring'\\n\", \"    max_length = schema[field]['maxlength']\\n\", \"    value = b'\\\\x00' * (max_length + 1)\\n\", '        document={field: value},\\n', '            field,\\n', \"            (field, 'maxlength'),\\n\", '            max_length,\\n', '            (len(value),),\\n', \"    field = 'a_string'\\n\", \"    min_length = schema[field]['minlength']\\n\", '    value = \"\".join(choice(ascii_lowercase) for i in range(min_length - 1))\\n', '        document={field: value},\\n', '            field,\\n', \"            (field, 'minlength'),\\n\", '            min_length,\\n', '            (len(value),),\\n', \"    field = 'a_bytestring'\\n\", \"    min_length = schema[field]['minlength']\\n\", \"    value = b'\\\\x00' * (min_length - 1)\\n\", '        document={field: value},\\n', '            field,\\n', \"            (field, 'minlength'),\\n\", '            min_length,\\n', '            (len(value),),\\n']",
  "context": "ing_fails(schema):\n    field = 'a_bytestring'\n    min_length = schema[field]['minlength']\n    value = b'\\x00' * (min_length - 1)\n    assert_"
 },
 "406": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_length.py",
  "lineno": "104",
  "column": "4",
  "slicing": "[\"    schema = {'dict': {'minlength': 1}}\\n\", \"    assert_fail(document={'dict': {}}, schema=schema)\\n\", \"    assert_success(document={'dict': {'foo': 'bar'}}, schema=schema)\\n\"]",
  "context": "   ),\n    )\n\n\ndef test_minlength_with_dict():\n    schema = {'dict': {'minlength': 1}}\n    assert_fail(document={'dict': {}}, schema=sche"
 },
 "407": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_allow_unknown.py",
  "lineno": "6",
  "column": "4",
  "slicing": "['    schema = {\\n', '    assert_success(document=document, schema=schema)\\n', \"    schema['field']['allow_unknown'] = {'type': 'string'}\\n\", '    assert_fail(document=document, schema=schema)\\n', '    assert_normalized(document, expected, schema, validator)\\n', '    assert_normalized(document, expected, schema, validator)\\n']",
  "context": "success\n\n\ndef test_allow_unknown_in_schema():\n    schema = {\n        'field': {\n            'type': 'dict',\n   "
 },
 "408": {
  "name": "document",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_allow_unknown.py",
  "lineno": "13",
  "column": "4",
  "slicing": "[\"    document = {'field': {'nested': 'foo', 'arb1': 'bar', 'arb2': 42}}\\n\", '    assert_success(document=document, schema=schema)\\n', '    assert_fail(document=document, schema=schema)\\n', '    assert_normalized(document, expected, schema, validator)\\n', '    assert_normalized(document, expected, schema, validator)\\n']",
  "context": "nested': {'type': 'string'}},\n        }\n    }\n    document = {'field': {'nested': 'foo', 'arb1': 'bar', 'arb2': 42}}\n\n    assert_success(document=document, schema=sche"
 },
 "409": {
  "name": "validator",
  "type": "cerberus.Validator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_allow_unknown.py",
  "lineno": "22",
  "column": "4",
  "slicing": "['    schema = {\\n', \"    document = {'field': {'nested': 'foo', 'arb1': 'bar', 'arb2': 42}}\\n\", '    assert_success(document=document, schema=schema)\\n', \"    schema['field']['allow_unknown'] = {'type': 'string'}\\n\", '    assert_fail(document=document, schema=schema)\\n', '    validator = Validator(purge_unknown=True)\\n', '    assert_normalized(document, expected, schema, validator)\\n', '    assert_normalized(document, expected, schema, validator)\\n']",
  "context": "\ndef test_allow_unknown_with_purge_unknown():\n    validator = Validator(purge_unknown=True)\n    schema = {'foo': {'type': 'dict', 'allow_unkno"
 },
 "410": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_allow_unknown.py",
  "lineno": "23",
  "column": "4",
  "slicing": "[\"    schema = {'foo': {'type': 'dict', 'allow_unknown': True}}\\n\", '    assert_normalized(document, expected, schema, validator)\\n', '    assert_normalized(document, expected, schema, validator)\\n']",
  "context": "    validator = Validator(purge_unknown=True)\n    schema = {'foo': {'type': 'dict', 'allow_unknown': True}}\n    document = {'foo': {'bar': True}, 'bar': 'foo'"
 },
 "411": {
  "name": "document",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_allow_unknown.py",
  "lineno": "24",
  "column": "4",
  "slicing": "[\"    document = {'foo': {'bar': True}, 'bar': 'foo'}\\n\", '    assert_normalized(document, expected, schema, validator)\\n', '    assert_normalized(document, expected, schema, validator)\\n']",
  "context": "oo': {'type': 'dict', 'allow_unknown': True}}\n    document = {'foo': {'bar': True}, 'bar': 'foo'}\n    expected = {'foo': {'bar': True}}\n    assert_n"
 },
 "412": {
  "name": "expected",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_allow_unknown.py",
  "lineno": "25",
  "column": "4",
  "slicing": "[\"    expected = {'foo': {'bar': True}}\\n\", '    assert_normalized(document, expected, schema, validator)\\n', '    assert_normalized(document, expected, schema, validator)\\n']",
  "context": "cument = {'foo': {'bar': True}, 'bar': 'foo'}\n    expected = {'foo': {'bar': True}}\n    assert_normalized(document, expected, schema, "
 },
 "413": {
  "name": "validator",
  "type": "cerberus.Validator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_allow_unknown.py",
  "lineno": "30",
  "column": "4",
  "slicing": "['    schema = {\\n', \"    document = {'field': {'nested': 'foo', 'arb1': 'bar', 'arb2': 42}}\\n\", '    assert_success(document=document, schema=schema)\\n', \"    schema['field']['allow_unknown'] = {'type': 'string'}\\n\", '    assert_fail(document=document, schema=schema)\\n', '    validator = Validator(purge_unknown=True)\\n', \"    schema = {'foo': {'type': 'dict', 'allow_unknown': True}}\\n\", \"    document = {'foo': {'bar': True}, 'bar': 'foo'}\\n\", \"    expected = {'foo': {'bar': True}}\\n\", '    assert_normalized(document, expected, schema, validator)\\n', '    validator = Validator(purge_unknown=True)\\n', '    assert_normalized(document, expected, schema, validator)\\n']",
  "context": "low_unknown_with_purge_unknown_subdocument():\n    validator = Validator(purge_unknown=True)\n    schema = {\n        'foo': {\n            'type'"
 },
 "414": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_allow_unknown.py",
  "lineno": "31",
  "column": "4",
  "slicing": "['    schema = {\\n', '    assert_normalized(document, expected, schema, validator)\\n']",
  "context": "    validator = Validator(purge_unknown=True)\n    schema = {\n        'foo': {\n            'type': 'dict',\n     "
 },
 "415": {
  "name": "document",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_allow_unknown.py",
  "lineno": "38",
  "column": "4",
  "slicing": "[\"    document = {'foo': {'bar': 'baz', 'corge': False}, 'thud': 'xyzzy'}\\n\", '    assert_normalized(document, expected, schema, validator)\\n']",
  "context": "       'allow_unknown': True,\n        }\n    }\n    document = {'foo': {'bar': 'baz', 'corge': False}, 'thud': 'xyzzy'}\n    expected = {'foo': {'bar': 'baz', 'corge': Fal"
 },
 "416": {
  "name": "expected",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_allow_unknown.py",
  "lineno": "39",
  "column": "4",
  "slicing": "[\"    expected = {'foo': {'bar': 'baz', 'corge': False}}\\n\", '    assert_normalized(document, expected, schema, validator)\\n']",
  "context": "ar': 'baz', 'corge': False}, 'thud': 'xyzzy'}\n    expected = {'foo': {'bar': 'baz', 'corge': False}}\n    assert_normalized(document, expected, schema, "
 },
 "417": {
  "name": "v",
  "type": "cerberus.Validator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_allow_unknown.py",
  "lineno": "45",
  "column": "4",
  "slicing": "['    schema = {\\n', \"    document = {'field': {'nested': 'foo', 'arb1': 'bar', 'arb2': 42}}\\n\", '    assert_success(document=document, schema=schema)\\n', \"    schema['field']['allow_unknown'] = {'type': 'string'}\\n\", '    assert_fail(document=document, schema=schema)\\n', '    validator = Validator(purge_unknown=True)\\n', \"    schema = {'foo': {'type': 'dict', 'allow_unknown': True}}\\n\", \"    document = {'foo': {'bar': True}, 'bar': 'foo'}\\n\", \"    expected = {'foo': {'bar': True}}\\n\", '    assert_normalized(document, expected, schema, validator)\\n', '    validator = Validator(purge_unknown=True)\\n', '    schema = {\\n', \"    document = {'foo': {'bar': 'baz', 'corge': False}, 'thud': 'xyzzy'}\\n\", \"    expected = {'foo': {'bar': 'baz', 'corge': False}}\\n\", '    assert_normalized(document, expected, schema, validator)\\n', \"    v = Validator({'a': {'type': 'dict', 'allow_unknown': True}})\\n\", \"    v({'a': {}})\\n\"]",
  "context": " https://github.com/pyeve/cerberus/issues/302\n    v = Validator({'a': {'type': 'dict', 'allow_unknown': True}})\n    v({'a': {}})\n"
 },
 "418": {
  "name": "missing_actors",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_contains.py",
  "lineno": "27",
  "column": "4",
  "slicing": "[\"    missing_actors = validator.document_error_tree['actors'][\\n\", \"    assert any(x in missing_actors for x in ('Eric Idle', 'Terry Gilliam'))\\n\"]",
  "context": "S in validator.document_error_tree['actors']\n\n    missing_actors = validator.document_error_tree['actors'][\n        errors.MISSING_MEMBERS\n    ].info[0]\n    a"
 },
 "419": {
  "name": "cerberus",
  "type": "__import__",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_assorted.py",
  "lineno": "17",
  "column": "8",
  "slicing": "['        cerberus = __import__(\"cerberus\")\\n', '        reload(cerberus)\\n', '        assert cerberus.__version__ == \"1.2.3\"\\n', '        reload(cerberus)\\n', '        assert cerberus.__version__ == \"unknown\"\\n']",
  "context": "3\")\n\n    with monkeypatch.context() as m:\n        cerberus = __import__(\"cerberus\")\n        m.setattr(\"pkg_resources.get_distribution\""
 },
 "420": {
  "name": "cerberus",
  "type": "__import__",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_assorted.py",
  "lineno": "28",
  "column": "8",
  "slicing": "['    with monkeypatch.context() as m:\\n', '        cerberus = __import__(\"cerberus\")\\n', '        m.setattr(\"pkg_resources.get_distribution\", create_fake_distribution)\\n', '        reload(cerberus)\\n', '        assert cerberus.__version__ == \"1.2.3\"\\n', '    with monkeypatch.context() as m:\\n', '        cerberus = __import__(\"cerberus\")\\n', '        m.setattr(\"pkg_resources.get_distribution\", raise_distribution_not_found)\\n', '        reload(cerberus)\\n', '        assert cerberus.__version__ == \"unknown\"\\n']",
  "context": "n\")\n\n    with monkeypatch.context() as m:\n        cerberus = __import__(\"cerberus\")\n        m.setattr(\"pkg_resources.get_distribution\""
 },
 "421": {
  "name": "decimal_type",
  "type": "cerberus.TypeDefinition",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_assorted.py",
  "lineno": "62",
  "column": "4",
  "slicing": "['    with monkeypatch.context() as m:\\n', '        cerberus = __import__(\"cerberus\")\\n', '        m.setattr(\"pkg_resources.get_distribution\", create_fake_distribution)\\n', '        reload(cerberus)\\n', '        assert cerberus.__version__ == \"1.2.3\"\\n', '    with monkeypatch.context() as m:\\n', '        cerberus = __import__(\"cerberus\")\\n', '        m.setattr(\"pkg_resources.get_distribution\", raise_distribution_not_found)\\n', '        reload(cerberus)\\n', '        assert cerberus.__version__ == \"unknown\"\\n', '    decimal_type = TypeDefinition(\"decimal\", (Decimal,), ())\\n', '    validator.types_mapping[\"decimal\"] = decimal_type\\n', '        types_mapping[\"decimal\"] = decimal_type\\n']",
  "context": "est didn't fail\")\n\n\ndef test_dynamic_types():\n    decimal_type = TypeDefinition(\"decimal\", (Decimal,), ())\n    document = {\"measurement\": Decimal(0)}\n    sch"
 },
 "422": {
  "name": "document",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_assorted.py",
  "lineno": "63",
  "column": "4",
  "slicing": "['    with monkeypatch.context() as m:\\n', '        cerberus = __import__(\"cerberus\")\\n', '        m.setattr(\"pkg_resources.get_distribution\", create_fake_distribution)\\n', '        reload(cerberus)\\n', '        assert cerberus.__version__ == \"1.2.3\"\\n', '    with monkeypatch.context() as m:\\n', '        cerberus = __import__(\"cerberus\")\\n', '        m.setattr(\"pkg_resources.get_distribution\", raise_distribution_not_found)\\n', '        reload(cerberus)\\n', '        assert cerberus.__version__ == \"unknown\"\\n', '    document = {\"measurement\": Decimal(0)}\\n', '    assert_success(document, schema, validator)\\n', '    assert_success(document, schema, validator)\\n']",
  "context": "e = TypeDefinition(\"decimal\", (Decimal,), ())\n    document = {\"measurement\": Decimal(0)}\n    schema = {\"measurement\": {\"type\": \"decimal\"}}\n"
 },
 "423": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_assorted.py",
  "lineno": "64",
  "column": "4",
  "slicing": "['    schema = {\"measurement\": {\"type\": \"decimal\"}}\\n', '    assert_success(document, schema, validator)\\n', '    assert_success(document, schema, validator)\\n']",
  "context": "))\n    document = {\"measurement\": Decimal(0)}\n    schema = {\"measurement\": {\"type\": \"decimal\"}}\n\n    validator = Validator()\n    validator.types_m"
 },
 "424": {
  "name": "validator",
  "type": "cerberus.Validator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_assorted.py",
  "lineno": "66",
  "column": "4",
  "slicing": "['    with monkeypatch.context() as m:\\n', '        cerberus = __import__(\"cerberus\")\\n', '        m.setattr(\"pkg_resources.get_distribution\", create_fake_distribution)\\n', '        reload(cerberus)\\n', '        assert cerberus.__version__ == \"1.2.3\"\\n', '    with monkeypatch.context() as m:\\n', '        cerberus = __import__(\"cerberus\")\\n', '        m.setattr(\"pkg_resources.get_distribution\", raise_distribution_not_found)\\n', '        reload(cerberus)\\n', '        assert cerberus.__version__ == \"unknown\"\\n', '    document = {\"measurement\": Decimal(0)}\\n', '    validator = Validator()\\n', '    validator.types_mapping[\"decimal\"] = decimal_type\\n', '    assert_success(document, schema, validator)\\n', '    assert_success(document, schema, validator)\\n', '    assert validator._config[\"test\"]\\n', '    assert validator._config[\"test\"]\\n']",
  "context": "chema = {\"measurement\": {\"type\": \"decimal\"}}\n\n    validator = Validator()\n    validator.types_mapping[\"decimal\"] = decimal_t"
 },
 "425": {
  "name": "validator",
  "type": "MyValidator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_assorted.py",
  "lineno": "74",
  "column": "4",
  "slicing": "['    with monkeypatch.context() as m:\\n', '        cerberus = __import__(\"cerberus\")\\n', '        m.setattr(\"pkg_resources.get_distribution\", create_fake_distribution)\\n', '        reload(cerberus)\\n', '        assert cerberus.__version__ == \"1.2.3\"\\n', '    with monkeypatch.context() as m:\\n', '        cerberus = __import__(\"cerberus\")\\n', '        m.setattr(\"pkg_resources.get_distribution\", raise_distribution_not_found)\\n', '        reload(cerberus)\\n', '        assert cerberus.__version__ == \"unknown\"\\n', '    decimal_type = TypeDefinition(\"decimal\", (Decimal,), ())\\n', '    document = {\"measurement\": Decimal(0)}\\n', '    schema = {\"measurement\": {\"type\": \"decimal\"}}\\n', '    validator = Validator()\\n', '    validator.types_mapping[\"decimal\"] = decimal_type\\n', '    assert_success(document, schema, validator)\\n', '        types_mapping = Validator.types_mapping.copy()\\n', '        types_mapping[\"decimal\"] = decimal_type\\n', '    validator = MyValidator()\\n', '    assert_success(document, schema, validator)\\n', '    assert validator._config[\"test\"]\\n', '    assert validator._config[\"test\"]\\n']",
  "context": "     types_mapping[\"decimal\"] = decimal_type\n\n    validator = MyValidator()\n    assert_success(document, schema, validator)\n\n\n"
 },
 "426": {
  "name": "MyValidator",
  "type": "cerberus.validator_factory",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_assorted.py",
  "lineno": "92",
  "column": "4",
  "slicing": "['    with monkeypatch.context() as m:\\n', '        cerberus = __import__(\"cerberus\")\\n', '        m.setattr(\"pkg_resources.get_distribution\", create_fake_distribution)\\n', '        reload(cerberus)\\n', '        assert cerberus.__version__ == \"1.2.3\"\\n', '    with monkeypatch.context() as m:\\n', '        cerberus = __import__(\"cerberus\")\\n', '        m.setattr(\"pkg_resources.get_distribution\", raise_distribution_not_found)\\n', '        reload(cerberus)\\n', '        assert cerberus.__version__ == \"unknown\"\\n', '    decimal_type = TypeDefinition(\"decimal\", (Decimal,), ())\\n', '    document = {\"measurement\": Decimal(0)}\\n', '    schema = {\"measurement\": {\"type\": \"decimal\"}}\\n', '    validator = Validator()\\n', '    validator.types_mapping[\"decimal\"] = decimal_type\\n', '    assert_success(document, schema, validator)\\n', '        types_mapping = Validator.types_mapping.copy()\\n', '        types_mapping[\"decimal\"] = decimal_type\\n', '    validator = MyValidator()\\n', '    assert_success(document, schema, validator)\\n', '    MyValidator = validator_factory(\"MyValidator\", Mixin)\\n', '    validator = MyValidator()\\n', '    assert validator._config[\"test\"]\\n', '    validator = MyValidator()\\n', '    assert validator._config[\"test\"]\\n']",
  "context": "           super().__init__(*args, **kwargs)\n\n    MyValidator = validator_factory(\"MyValidator\", Mixin)\n    validator = MyValidator()\n    assert validator"
 },
 "427": {
  "name": "validator",
  "type": "MyValidator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_assorted.py",
  "lineno": "93",
  "column": "4",
  "slicing": "['    with monkeypatch.context() as m:\\n', '        cerberus = __import__(\"cerberus\")\\n', '        m.setattr(\"pkg_resources.get_distribution\", create_fake_distribution)\\n', '        reload(cerberus)\\n', '        assert cerberus.__version__ == \"1.2.3\"\\n', '    with monkeypatch.context() as m:\\n', '        cerberus = __import__(\"cerberus\")\\n', '        m.setattr(\"pkg_resources.get_distribution\", raise_distribution_not_found)\\n', '        reload(cerberus)\\n', '        assert cerberus.__version__ == \"unknown\"\\n', '    decimal_type = TypeDefinition(\"decimal\", (Decimal,), ())\\n', '    document = {\"measurement\": Decimal(0)}\\n', '    schema = {\"measurement\": {\"type\": \"decimal\"}}\\n', '    validator = Validator()\\n', '    validator.types_mapping[\"decimal\"] = decimal_type\\n', '    assert_success(document, schema, validator)\\n', '        types_mapping = Validator.types_mapping.copy()\\n', '        types_mapping[\"decimal\"] = decimal_type\\n', '    validator = MyValidator()\\n', '    assert_success(document, schema, validator)\\n', '    MyValidator = validator_factory(\"MyValidator\", Mixin)\\n', '    validator = MyValidator()\\n', '    assert validator._config[\"test\"]\\n', '    validator = MyValidator()\\n', '    assert validator._config[\"test\"]\\n']",
  "context": "tor = validator_factory(\"MyValidator\", Mixin)\n    validator = MyValidator()\n    assert validator._config[\"test\"]\n\n\ndef test_su"
 },
 "428": {
  "name": "validator",
  "type": "MyValidator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_assorted.py",
  "lineno": "103",
  "column": "4",
  "slicing": "['    with monkeypatch.context() as m:\\n', '        cerberus = __import__(\"cerberus\")\\n', '        m.setattr(\"pkg_resources.get_distribution\", create_fake_distribution)\\n', '        reload(cerberus)\\n', '        assert cerberus.__version__ == \"1.2.3\"\\n', '    with monkeypatch.context() as m:\\n', '        cerberus = __import__(\"cerberus\")\\n', '        m.setattr(\"pkg_resources.get_distribution\", raise_distribution_not_found)\\n', '        reload(cerberus)\\n', '        assert cerberus.__version__ == \"unknown\"\\n', '    decimal_type = TypeDefinition(\"decimal\", (Decimal,), ())\\n', '    document = {\"measurement\": Decimal(0)}\\n', '    schema = {\"measurement\": {\"type\": \"decimal\"}}\\n', '    validator = Validator()\\n', '    validator.types_mapping[\"decimal\"] = decimal_type\\n', '    assert_success(document, schema, validator)\\n', '        types_mapping = Validator.types_mapping.copy()\\n', '        types_mapping[\"decimal\"] = decimal_type\\n', '    validator = MyValidator()\\n', '    assert_success(document, schema, validator)\\n', '    MyValidator = validator_factory(\"MyValidator\", Mixin)\\n', '    validator = MyValidator()\\n', '    assert validator._config[\"test\"]\\n', '    validator = MyValidator()\\n', '    assert validator._config[\"test\"]\\n']",
  "context": "           super().__init__(*args, **kwargs)\n\n    validator = MyValidator()\n    assert validator._config[\"test\"]\n"
 },
 "429": {
  "name": "ValidationError",
  "type": "ValidationError",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/tests/test_errors.py",
  "lineno": "5",
  "column": "0",
  "slicing": "['ValidationError = errors.ValidationError\\n', \"    v = Validator(schema={'foo': {'type': 'string'}})\\n\", \"    v.document = {'foo': 42}\\n\", \"    v._error('foo', errors.TYPE, 'string')\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'type')\\n\", '    assert error.code == 0x24\\n', \"    assert error.rule == 'type'\\n\", \"    assert error.constraint == ('string',)\\n\", '    assert error.value == 42\\n', \"    assert error.info == ('string',)\\n\", '    assert not error.is_group_error\\n', '    assert not error.is_logic_error\\n', \"    v = Validator(schema={'foo': {'keysrules': {'type': 'integer'}}})\\n\", \"    v.document = {'foo': {'0': 'bar'}}\\n\", \"    v._error('foo', errors.KEYSRULES, ())\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'keysrules')\\n\", '    assert error.code == 0x83\\n', \"    assert error.rule == 'keysrules'\\n\", \"    assert error.constraint == {'type': ('integer',)}\\n\", \"    assert error.value == {'0': 'bar'}\\n\", '    assert error.info == ((),)\\n', '    assert error.is_group_error\\n', '    assert not error.is_logic_error\\n', '    valids = (\\n', \"    v = Validator(schema={'foo': {'oneof': valids}})\\n\", \"    v.document = {'foo': '0x100'}\\n\", \"    v._error('foo', errors.ONEOF, (), 0, 2)\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'oneof')\\n\", '    assert error.code == 0x92\\n', \"    assert error.rule == 'oneof'\\n\", '    assert error.constraint == valids\\n', \"    assert error.value == '0x100'\\n\", '    assert error.info == ((), 0, 2)\\n', '    assert error.is_group_error\\n', '    assert error.is_logic_error\\n', \"    schema = {'foo': {'schema': {'bar': {'type': 'string'}}}}\\n\", \"    document = {'foo': {'bar': 0}}\\n\", '    assert_fail(document, schema, validator=validator)\\n', '    d_error_tree = validator.document_error_tree\\n', '    s_error_tree = validator.schema_error_tree\\n', \"    assert 'foo' in d_error_tree\\n\", \"    assert len(d_error_tree['foo'].errors) == 1, d_error_tree['foo']\\n\", \"    assert d_error_tree['foo'].errors[0].code == errors.SCHEMA.code\\n\", \"    assert 'bar' in d_error_tree['foo']\\n\", \"    assert d_error_tree['foo']['bar'].errors[0].value == 0\\n\", \"    assert d_error_tree.fetch_errors_from(('foo', 'bar'))[0].value == 0\\n\", \"    assert 'foo' in s_error_tree\\n\", \"    assert 'schema' in s_error_tree['foo']\\n\", \"    assert 'bar' in s_error_tree['foo']['schema']\\n\", \"    assert 'type' in s_error_tree['foo']['schema']['bar']\\n\", \"    assert s_error_tree['foo']['schema']['bar']['type'].errors[0].value == 0\\n\", \"        s_error_tree.fetch_errors_from(('foo', 'schema', 'bar', 'type'))[0].value == 0\\n\", \"    schema = {'foo': {'anyof': [{'type': 'string'}, {'type': 'integer'}]}}\\n\", \"    document = {'foo': []}\\n\", '    assert_fail(document, schema, validator=validator)\\n', '    d_error_tree = validator.document_error_tree\\n', '    s_error_tree = validator.schema_error_tree\\n', \"    assert 'foo' in d_error_tree\\n\", \"    assert d_error_tree['foo'].errors[0].value == []\\n\", \"    assert 'foo' in s_error_tree\\n\", \"    assert 'anyof' in s_error_tree['foo']\\n\", \"    assert 0 in s_error_tree['foo']['anyof']\\n\", \"    assert 1 in s_error_tree['foo']['anyof']\\n\", \"    assert 'type' in s_error_tree['foo']['anyof'][0]\\n\", \"    assert s_error_tree['foo']['anyof'][0]['type'].errors[0].value == []\\n\", '    schema = {\\n', '    document = {\\n', '    assert_fail(document, schema, validator=validator)\\n', '    _det = validator.document_error_tree\\n', '    _set = validator.schema_error_tree\\n', '    assert len(_det.errors) == 0\\n', '    assert len(_set.errors) == 0\\n', \"    assert len(_det['a_dict'].errors) == 2\\n\", \"    assert len(_set['a_dict'].errors) == 0\\n\", \"    assert _det['a_dict'][0] is None\\n\", \"    assert len(_det['a_dict']['one'].errors) == 1\\n\", \"    assert len(_det['a_dict'][2].errors) == 1\\n\", \"    assert len(_det['a_dict']['three'].errors) == 2\\n\", \"    assert len(_set['a_dict']['keysrules'].errors) == 1\\n\", \"    assert len(_set['a_dict']['valuesrules'].errors) == 1\\n\", \"    assert len(_set['a_dict']['keysrules']['type'].errors) == 2\\n\", \"    assert len(_set['a_dict']['valuesrules']['regex'].errors) == 2\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['one'].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['keysrules']['type'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict'][2].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['valuesrules']['regex'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['three'].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['keysrules']['type'].errors[1] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['three'].errors[1] == _ref_err\\n\", \"    assert _set['a_dict']['valuesrules']['regex'].errors[1] == _ref_err\\n\", \"    assert len(_det['a_list'].errors) == 1\\n\", \"    assert len(_det['a_list'][0].errors) == 1\\n\", \"    assert _det['a_list'][1] is None\\n\", \"    assert len(_det['a_list'][2].errors) == 3\\n\", \"    assert len(_set['a_list'].errors) == 0\\n\", \"    assert len(_set['a_list']['itemsrules'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['type'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['oneof'][0]['regex'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['oneof'][1]['regex'].errors) == 1\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][0].errors[0] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['type'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[0] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[1] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'][0]['regex'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[2] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'][1]['regex'].errors[0] == _ref_err\\n\", \"    schema = {'foo': {'type': 'dict', 'schema': {'bar': {'type': 'number'}}}}\\n\", \"    document = {'foo': {'bar': 'zero'}}\\n\", '    validator = Validator(schema)\\n', '    validator(document)\\n', \"    assert 'foo' in validator.document_error_tree\\n\", \"    assert 'bar' in validator.document_error_tree['foo']\\n\", \"    assert 'foo' in validator.schema_error_tree\\n\", \"    assert 'schema' in validator.schema_error_tree['foo']\\n\", \"    assert errors.SCHEMA in validator.document_error_tree['foo'].errors\\n\", \"    assert errors.SCHEMA in validator.document_error_tree['foo']\\n\", \"    assert errors.TYPE in validator.document_error_tree['foo']['bar']\\n\", \"    assert errors.SCHEMA in validator.schema_error_tree['foo']['schema']\\n\", \"    assert errors.TYPE in validator.schema_error_tree['foo']['schema']['bar']['type']\\n\", \"        validator.document_error_tree['foo'][errors.SCHEMA].child_errors[0].code\\n\", '    handler = errors.BasicErrorHandler()\\n', '    _errors, ref = [], {}\\n', \"    _errors.append(ValidationError(['foo'], ['foo'], 0x63, 'readonly', True, None, ()))\\n\", \"    ref.update({'foo': [handler.messages[0x63]]})\\n\", '    assert handler(_errors) == ref\\n', \"    _errors.append(ValidationError(['bar'], ['foo'], 0x42, 'min', 1, 2, ()))\\n\", \"    ref.update({'bar': [handler.messages[0x42].format(constraint=1)]})\\n\", '    assert handler(_errors) == ref\\n', '    _errors.append(\\n', '        ValidationError(\\n', \"    ref.update({'zap': [{'foo': [handler.messages[0x24].format(constraint='string')]}]})\\n\", '    assert handler(_errors) == ref\\n', '    _errors.append(\\n', '        ValidationError(\\n', \"    ref['zap'][0]['foo'].append(handler.messages[0x41].format(constraint='^p[e]ng$'))\\n\", '    assert handler(_errors) == ref\\n', \"    schema = {'foo': {'oneof': ({'type': ('integer',)}, {'type': ('string',)})}}\\n\", \"    document = {'foo': 23.42}\\n\", \"    error = ('foo', ('foo', 'oneof'), errors.ONEOF, schema['foo']['oneof'], ())\\n\", \"        (error[0], error[1] + (0, 'type'), errors.TYPE, ('integer',)),\\n\", \"        (error[0], error[1] + (1, 'type'), errors.TYPE, ('string',)),\\n\", '        document, schema, validator=validator, error=error, child_errors=child_errors\\n', '    assert validator.errors == {\\n', '    validator.schema = {\\n', \"    validator({'test_list': ['test']})\\n\", '    assert validator.errors == {\\'test_list\\': [\"length of list should be 2, it is 1\"]}\\n']",
  "context": ", errors\nfrom cerberus.tests import assert_fail\n\n\nValidationError = errors.ValidationError\n\n\ndef test__error_1():\n    v = Validator(schema={'"
 },
 "430": {
  "name": "v",
  "type": "cerberus.Validator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_errors.py",
  "lineno": "9",
  "column": "4",
  "slicing": "[\"    v = Validator(schema={'foo': {'type': 'string'}})\\n\", \"    v.document = {'foo': 42}\\n\", \"    v._error('foo', errors.TYPE, 'string')\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'type')\\n\", '    assert error.code == 0x24\\n', \"    assert error.rule == 'type'\\n\", \"    assert error.constraint == ('string',)\\n\", '    assert error.value == 42\\n', \"    assert error.info == ('string',)\\n\", '    assert not error.is_group_error\\n', '    assert not error.is_logic_error\\n', \"    v = Validator(schema={'foo': {'keysrules': {'type': 'integer'}}})\\n\", \"    v.document = {'foo': {'0': 'bar'}}\\n\", \"    v._error('foo', errors.KEYSRULES, ())\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'keysrules')\\n\", '    assert error.code == 0x83\\n', \"    assert error.rule == 'keysrules'\\n\", \"    assert error.constraint == {'type': ('integer',)}\\n\", \"    assert error.value == {'0': 'bar'}\\n\", '    assert error.info == ((),)\\n', '    assert error.is_group_error\\n', '    assert not error.is_logic_error\\n', '    valids = (\\n', \"    v = Validator(schema={'foo': {'oneof': valids}})\\n\", \"    v.document = {'foo': '0x100'}\\n\", \"    v._error('foo', errors.ONEOF, (), 0, 2)\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'oneof')\\n\", '    assert error.code == 0x92\\n', \"    assert error.rule == 'oneof'\\n\", '    assert error.constraint == valids\\n', \"    assert error.value == '0x100'\\n\", '    assert error.info == ((), 0, 2)\\n', '    assert error.is_group_error\\n', '    assert error.is_logic_error\\n', \"        (error[0], error[1] + (0, 'type'), errors.TYPE, ('integer',)),\\n\", \"        (error[0], error[1] + (1, 'type'), errors.TYPE, ('string',)),\\n\", '        document, schema, validator=validator, error=error, child_errors=child_errors\\n']",
  "context": "errors.ValidationError\n\n\ndef test__error_1():\n    v = Validator(schema={'foo': {'type': 'string'}})\n    v.document = {'foo': 42}\n    v._error('foo', e"
 },
 "431": {
  "name": "error",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_errors.py",
  "lineno": "12",
  "column": "4",
  "slicing": "[\"    v = Validator(schema={'foo': {'type': 'string'}})\\n\", \"    v.document = {'foo': 42}\\n\", \"    v._error('foo', errors.TYPE, 'string')\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'type')\\n\", '    assert error.code == 0x24\\n', \"    assert error.rule == 'type'\\n\", \"    assert error.constraint == ('string',)\\n\", '    assert error.value == 42\\n', \"    assert error.info == ('string',)\\n\", '    assert not error.is_group_error\\n', '    assert not error.is_logic_error\\n', \"    v = Validator(schema={'foo': {'keysrules': {'type': 'integer'}}})\\n\", \"    v.document = {'foo': {'0': 'bar'}}\\n\", \"    v._error('foo', errors.KEYSRULES, ())\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'keysrules')\\n\", '    assert error.code == 0x83\\n', \"    assert error.rule == 'keysrules'\\n\", \"    assert error.constraint == {'type': ('integer',)}\\n\", \"    assert error.value == {'0': 'bar'}\\n\", '    assert error.info == ((),)\\n', '    assert error.is_group_error\\n', '    assert not error.is_logic_error\\n', '    valids = (\\n', \"    v = Validator(schema={'foo': {'oneof': valids}})\\n\", \"    v.document = {'foo': '0x100'}\\n\", \"    v._error('foo', errors.ONEOF, (), 0, 2)\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'oneof')\\n\", '    assert error.code == 0x92\\n', \"    assert error.rule == 'oneof'\\n\", '    assert error.constraint == valids\\n', \"    assert error.value == '0x100'\\n\", '    assert error.info == ((), 0, 2)\\n', '    assert error.is_group_error\\n', '    assert error.is_logic_error\\n', \"        (error[0], error[1] + (0, 'type'), errors.TYPE, ('integer',)),\\n\", \"        (error[0], error[1] + (1, 'type'), errors.TYPE, ('string',)),\\n\", '        document, schema, validator=validator, error=error, child_errors=child_errors\\n']",
  "context": "2}\n    v._error('foo', errors.TYPE, 'string')\n    error = v._errors[0]\n    assert error.document_path == ('foo',)\n    ass"
 },
 "432": {
  "name": "v",
  "type": "cerberus.Validator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_errors.py",
  "lineno": "25",
  "column": "4",
  "slicing": "[\"    v = Validator(schema={'foo': {'type': 'string'}})\\n\", \"    v.document = {'foo': 42}\\n\", \"    v._error('foo', errors.TYPE, 'string')\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'type')\\n\", '    assert error.code == 0x24\\n', \"    assert error.rule == 'type'\\n\", \"    assert error.constraint == ('string',)\\n\", '    assert error.value == 42\\n', \"    assert error.info == ('string',)\\n\", '    assert not error.is_group_error\\n', '    assert not error.is_logic_error\\n', \"    v = Validator(schema={'foo': {'keysrules': {'type': 'integer'}}})\\n\", \"    v.document = {'foo': {'0': 'bar'}}\\n\", \"    v._error('foo', errors.KEYSRULES, ())\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'keysrules')\\n\", '    assert error.code == 0x83\\n', \"    assert error.rule == 'keysrules'\\n\", \"    assert error.constraint == {'type': ('integer',)}\\n\", \"    assert error.value == {'0': 'bar'}\\n\", '    assert error.info == ((),)\\n', '    assert error.is_group_error\\n', '    assert not error.is_logic_error\\n', '    valids = (\\n', \"    v = Validator(schema={'foo': {'oneof': valids}})\\n\", \"    v.document = {'foo': '0x100'}\\n\", \"    v._error('foo', errors.ONEOF, (), 0, 2)\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'oneof')\\n\", '    assert error.code == 0x92\\n', \"    assert error.rule == 'oneof'\\n\", '    assert error.constraint == valids\\n', \"    assert error.value == '0x100'\\n\", '    assert error.info == ((), 0, 2)\\n', '    assert error.is_group_error\\n', '    assert error.is_logic_error\\n', \"        (error[0], error[1] + (0, 'type'), errors.TYPE, ('integer',)),\\n\", \"        (error[0], error[1] + (1, 'type'), errors.TYPE, ('string',)),\\n\", '        document, schema, validator=validator, error=error, child_errors=child_errors\\n']",
  "context": "t error.is_logic_error\n\n\ndef test__error_2():\n    v = Validator(schema={'foo': {'keysrules': {'type': 'integer'}}})\n    v.document = {'foo': {'0': 'bar'}}\n    v._erro"
 },
 "433": {
  "name": "error",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_errors.py",
  "lineno": "28",
  "column": "4",
  "slicing": "[\"    v = Validator(schema={'foo': {'type': 'string'}})\\n\", \"    v.document = {'foo': 42}\\n\", \"    v._error('foo', errors.TYPE, 'string')\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'type')\\n\", '    assert error.code == 0x24\\n', \"    assert error.rule == 'type'\\n\", \"    assert error.constraint == ('string',)\\n\", '    assert error.value == 42\\n', \"    assert error.info == ('string',)\\n\", '    assert not error.is_group_error\\n', '    assert not error.is_logic_error\\n', \"    v = Validator(schema={'foo': {'keysrules': {'type': 'integer'}}})\\n\", \"    v.document = {'foo': {'0': 'bar'}}\\n\", \"    v._error('foo', errors.KEYSRULES, ())\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'keysrules')\\n\", '    assert error.code == 0x83\\n', \"    assert error.rule == 'keysrules'\\n\", \"    assert error.constraint == {'type': ('integer',)}\\n\", \"    assert error.value == {'0': 'bar'}\\n\", '    assert error.info == ((),)\\n', '    assert error.is_group_error\\n', '    assert not error.is_logic_error\\n', '    valids = (\\n', \"    v = Validator(schema={'foo': {'oneof': valids}})\\n\", \"    v.document = {'foo': '0x100'}\\n\", \"    v._error('foo', errors.ONEOF, (), 0, 2)\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'oneof')\\n\", '    assert error.code == 0x92\\n', \"    assert error.rule == 'oneof'\\n\", '    assert error.constraint == valids\\n', \"    assert error.value == '0x100'\\n\", '    assert error.info == ((), 0, 2)\\n', '    assert error.is_group_error\\n', '    assert error.is_logic_error\\n', \"        (error[0], error[1] + (0, 'type'), errors.TYPE, ('integer',)),\\n\", \"        (error[0], error[1] + (1, 'type'), errors.TYPE, ('string',)),\\n\", '        document, schema, validator=validator, error=error, child_errors=child_errors\\n']",
  "context": "'}}\n    v._error('foo', errors.KEYSRULES, ())\n    error = v._errors[0]\n    assert error.document_path == ('foo',)\n    ass"
 },
 "434": {
  "name": "valids",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_errors.py",
  "lineno": "41",
  "column": "4",
  "slicing": "[\"    v = Validator(schema={'foo': {'type': 'string'}})\\n\", \"    v.document = {'foo': 42}\\n\", \"    v._error('foo', errors.TYPE, 'string')\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'type')\\n\", '    assert error.code == 0x24\\n', \"    assert error.rule == 'type'\\n\", \"    assert error.constraint == ('string',)\\n\", '    assert error.value == 42\\n', \"    assert error.info == ('string',)\\n\", '    assert not error.is_group_error\\n', '    assert not error.is_logic_error\\n', \"    v = Validator(schema={'foo': {'keysrules': {'type': 'integer'}}})\\n\", \"    v.document = {'foo': {'0': 'bar'}}\\n\", \"    v._error('foo', errors.KEYSRULES, ())\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'keysrules')\\n\", '    assert error.code == 0x83\\n', \"    assert error.rule == 'keysrules'\\n\", \"    assert error.constraint == {'type': ('integer',)}\\n\", \"    assert error.value == {'0': 'bar'}\\n\", '    assert error.info == ((),)\\n', '    assert error.is_group_error\\n', '    assert not error.is_logic_error\\n', '    valids = (\\n', \"    v = Validator(schema={'foo': {'oneof': valids}})\\n\", \"    v.document = {'foo': '0x100'}\\n\", \"    v._error('foo', errors.ONEOF, (), 0, 2)\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'oneof')\\n\", '    assert error.code == 0x92\\n', \"    assert error.rule == 'oneof'\\n\", '    assert error.constraint == valids\\n', \"    assert error.value == '0x100'\\n\", '    assert error.info == ((), 0, 2)\\n', '    assert error.is_group_error\\n', '    assert error.is_logic_error\\n', \"        (error[0], error[1] + (0, 'type'), errors.TYPE, ('integer',)),\\n\", \"        (error[0], error[1] + (1, 'type'), errors.TYPE, ('string',)),\\n\", '        document, schema, validator=validator, error=error, child_errors=child_errors\\n']",
  "context": "t error.is_logic_error\n\n\ndef test__error_3():\n    valids = (\n        {'type': ('string',), 'regex': '0x[0-9a-f]"
 },
 "435": {
  "name": "v",
  "type": "cerberus.Validator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_errors.py",
  "lineno": "45",
  "column": "4",
  "slicing": "[\"    v = Validator(schema={'foo': {'type': 'string'}})\\n\", \"    v.document = {'foo': 42}\\n\", \"    v._error('foo', errors.TYPE, 'string')\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'type')\\n\", '    assert error.code == 0x24\\n', \"    assert error.rule == 'type'\\n\", \"    assert error.constraint == ('string',)\\n\", '    assert error.value == 42\\n', \"    assert error.info == ('string',)\\n\", '    assert not error.is_group_error\\n', '    assert not error.is_logic_error\\n', \"    v = Validator(schema={'foo': {'keysrules': {'type': 'integer'}}})\\n\", \"    v.document = {'foo': {'0': 'bar'}}\\n\", \"    v._error('foo', errors.KEYSRULES, ())\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'keysrules')\\n\", '    assert error.code == 0x83\\n', \"    assert error.rule == 'keysrules'\\n\", \"    assert error.constraint == {'type': ('integer',)}\\n\", \"    assert error.value == {'0': 'bar'}\\n\", '    assert error.info == ((),)\\n', '    assert error.is_group_error\\n', '    assert not error.is_logic_error\\n', '    valids = (\\n', \"    v = Validator(schema={'foo': {'oneof': valids}})\\n\", \"    v.document = {'foo': '0x100'}\\n\", \"    v._error('foo', errors.ONEOF, (), 0, 2)\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'oneof')\\n\", '    assert error.code == 0x92\\n', \"    assert error.rule == 'oneof'\\n\", '    assert error.constraint == valids\\n', \"    assert error.value == '0x100'\\n\", '    assert error.info == ((), 0, 2)\\n', '    assert error.is_group_error\\n', '    assert error.is_logic_error\\n', \"        (error[0], error[1] + (0, 'type'), errors.TYPE, ('integer',)),\\n\", \"        (error[0], error[1] + (1, 'type'), errors.TYPE, ('string',)),\\n\", '        document, schema, validator=validator, error=error, child_errors=child_errors\\n']",
  "context": "': ('integer',), 'min': 0, 'max': 255},\n    )\n    v = Validator(schema={'foo': {'oneof': valids}})\n    v.document = {'foo': '0x100'}\n    v._error('fo"
 },
 "436": {
  "name": "error",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_errors.py",
  "lineno": "48",
  "column": "4",
  "slicing": "[\"    v = Validator(schema={'foo': {'type': 'string'}})\\n\", \"    v.document = {'foo': 42}\\n\", \"    v._error('foo', errors.TYPE, 'string')\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'type')\\n\", '    assert error.code == 0x24\\n', \"    assert error.rule == 'type'\\n\", \"    assert error.constraint == ('string',)\\n\", '    assert error.value == 42\\n', \"    assert error.info == ('string',)\\n\", '    assert not error.is_group_error\\n', '    assert not error.is_logic_error\\n', \"    v = Validator(schema={'foo': {'keysrules': {'type': 'integer'}}})\\n\", \"    v.document = {'foo': {'0': 'bar'}}\\n\", \"    v._error('foo', errors.KEYSRULES, ())\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'keysrules')\\n\", '    assert error.code == 0x83\\n', \"    assert error.rule == 'keysrules'\\n\", \"    assert error.constraint == {'type': ('integer',)}\\n\", \"    assert error.value == {'0': 'bar'}\\n\", '    assert error.info == ((),)\\n', '    assert error.is_group_error\\n', '    assert not error.is_logic_error\\n', '    valids = (\\n', \"    v = Validator(schema={'foo': {'oneof': valids}})\\n\", \"    v.document = {'foo': '0x100'}\\n\", \"    v._error('foo', errors.ONEOF, (), 0, 2)\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'oneof')\\n\", '    assert error.code == 0x92\\n', \"    assert error.rule == 'oneof'\\n\", '    assert error.constraint == valids\\n', \"    assert error.value == '0x100'\\n\", '    assert error.info == ((), 0, 2)\\n', '    assert error.is_group_error\\n', '    assert error.is_logic_error\\n', \"        (error[0], error[1] + (0, 'type'), errors.TYPE, ('integer',)),\\n\", \"        (error[0], error[1] + (1, 'type'), errors.TYPE, ('string',)),\\n\", '        document, schema, validator=validator, error=error, child_errors=child_errors\\n']",
  "context": "}\n    v._error('foo', errors.ONEOF, (), 0, 2)\n    error = v._errors[0]\n    assert error.document_path == ('foo',)\n    ass"
 },
 "437": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_errors.py",
  "lineno": "61",
  "column": "4",
  "slicing": "['ValidationError = errors.ValidationError\\n', \"    v = Validator(schema={'foo': {'type': 'string'}})\\n\", \"    v.document = {'foo': 42}\\n\", \"    v._error('foo', errors.TYPE, 'string')\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'type')\\n\", '    assert error.code == 0x24\\n', \"    assert error.rule == 'type'\\n\", \"    assert error.constraint == ('string',)\\n\", '    assert error.value == 42\\n', \"    assert error.info == ('string',)\\n\", '    assert not error.is_group_error\\n', '    assert not error.is_logic_error\\n', \"    v = Validator(schema={'foo': {'keysrules': {'type': 'integer'}}})\\n\", \"    v.document = {'foo': {'0': 'bar'}}\\n\", \"    v._error('foo', errors.KEYSRULES, ())\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'keysrules')\\n\", '    assert error.code == 0x83\\n', \"    assert error.rule == 'keysrules'\\n\", \"    assert error.constraint == {'type': ('integer',)}\\n\", \"    assert error.value == {'0': 'bar'}\\n\", '    assert error.info == ((),)\\n', '    assert error.is_group_error\\n', '    assert not error.is_logic_error\\n', '    valids = (\\n', \"    v = Validator(schema={'foo': {'oneof': valids}})\\n\", \"    v.document = {'foo': '0x100'}\\n\", \"    v._error('foo', errors.ONEOF, (), 0, 2)\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'oneof')\\n\", '    assert error.code == 0x92\\n', \"    assert error.rule == 'oneof'\\n\", '    assert error.constraint == valids\\n', \"    assert error.value == '0x100'\\n\", '    assert error.info == ((), 0, 2)\\n', '    assert error.is_group_error\\n', '    assert error.is_logic_error\\n', \"    schema = {'foo': {'schema': {'bar': {'type': 'string'}}}}\\n\", \"    document = {'foo': {'bar': 0}}\\n\", '    assert_fail(document, schema, validator=validator)\\n', '    d_error_tree = validator.document_error_tree\\n', '    s_error_tree = validator.schema_error_tree\\n', \"    assert 'foo' in d_error_tree\\n\", \"    assert len(d_error_tree['foo'].errors) == 1, d_error_tree['foo']\\n\", \"    assert d_error_tree['foo'].errors[0].code == errors.SCHEMA.code\\n\", \"    assert 'bar' in d_error_tree['foo']\\n\", \"    assert d_error_tree['foo']['bar'].errors[0].value == 0\\n\", \"    assert d_error_tree.fetch_errors_from(('foo', 'bar'))[0].value == 0\\n\", \"    assert 'foo' in s_error_tree\\n\", \"    assert 'schema' in s_error_tree['foo']\\n\", \"    assert 'bar' in s_error_tree['foo']['schema']\\n\", \"    assert 'type' in s_error_tree['foo']['schema']['bar']\\n\", \"    assert s_error_tree['foo']['schema']['bar']['type'].errors[0].value == 0\\n\", \"        s_error_tree.fetch_errors_from(('foo', 'schema', 'bar', 'type'))[0].value == 0\\n\", \"    schema = {'foo': {'anyof': [{'type': 'string'}, {'type': 'integer'}]}}\\n\", \"    document = {'foo': []}\\n\", '    assert_fail(document, schema, validator=validator)\\n', '    d_error_tree = validator.document_error_tree\\n', '    s_error_tree = validator.schema_error_tree\\n', \"    assert 'foo' in d_error_tree\\n\", \"    assert d_error_tree['foo'].errors[0].value == []\\n\", \"    assert 'foo' in s_error_tree\\n\", \"    assert 'anyof' in s_error_tree['foo']\\n\", \"    assert 0 in s_error_tree['foo']['anyof']\\n\", \"    assert 1 in s_error_tree['foo']['anyof']\\n\", \"    assert 'type' in s_error_tree['foo']['anyof'][0]\\n\", \"    assert s_error_tree['foo']['anyof'][0]['type'].errors[0].value == []\\n\", '    schema = {\\n', '    document = {\\n', '    assert_fail(document, schema, validator=validator)\\n', '    _det = validator.document_error_tree\\n', '    _set = validator.schema_error_tree\\n', '    assert len(_det.errors) == 0\\n', '    assert len(_set.errors) == 0\\n', \"    assert len(_det['a_dict'].errors) == 2\\n\", \"    assert len(_set['a_dict'].errors) == 0\\n\", \"    assert _det['a_dict'][0] is None\\n\", \"    assert len(_det['a_dict']['one'].errors) == 1\\n\", \"    assert len(_det['a_dict'][2].errors) == 1\\n\", \"    assert len(_det['a_dict']['three'].errors) == 2\\n\", \"    assert len(_set['a_dict']['keysrules'].errors) == 1\\n\", \"    assert len(_set['a_dict']['valuesrules'].errors) == 1\\n\", \"    assert len(_set['a_dict']['keysrules']['type'].errors) == 2\\n\", \"    assert len(_set['a_dict']['valuesrules']['regex'].errors) == 2\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['one'].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['keysrules']['type'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict'][2].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['valuesrules']['regex'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['three'].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['keysrules']['type'].errors[1] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['three'].errors[1] == _ref_err\\n\", \"    assert _set['a_dict']['valuesrules']['regex'].errors[1] == _ref_err\\n\", \"    assert len(_det['a_list'].errors) == 1\\n\", \"    assert len(_det['a_list'][0].errors) == 1\\n\", \"    assert _det['a_list'][1] is None\\n\", \"    assert len(_det['a_list'][2].errors) == 3\\n\", \"    assert len(_set['a_list'].errors) == 0\\n\", \"    assert len(_set['a_list']['itemsrules'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['type'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['oneof'][0]['regex'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['oneof'][1]['regex'].errors) == 1\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][0].errors[0] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['type'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[0] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[1] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'][0]['regex'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[2] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'][1]['regex'].errors[0] == _ref_err\\n\", \"    schema = {'foo': {'type': 'dict', 'schema': {'bar': {'type': 'number'}}}}\\n\", \"    document = {'foo': {'bar': 'zero'}}\\n\", '    validator = Validator(schema)\\n', '    validator(document)\\n', \"    assert 'foo' in validator.document_error_tree\\n\", \"    assert 'bar' in validator.document_error_tree['foo']\\n\", \"    assert 'foo' in validator.schema_error_tree\\n\", \"    assert 'schema' in validator.schema_error_tree['foo']\\n\", \"    assert errors.SCHEMA in validator.document_error_tree['foo'].errors\\n\", \"    assert errors.SCHEMA in validator.document_error_tree['foo']\\n\", \"    assert errors.TYPE in validator.document_error_tree['foo']['bar']\\n\", \"    assert errors.SCHEMA in validator.schema_error_tree['foo']['schema']\\n\", \"    assert errors.TYPE in validator.schema_error_tree['foo']['schema']['bar']['type']\\n\", \"        validator.document_error_tree['foo'][errors.SCHEMA].child_errors[0].code\\n\", '    handler = errors.BasicErrorHandler()\\n', '    _errors, ref = [], {}\\n', \"    _errors.append(ValidationError(['foo'], ['foo'], 0x63, 'readonly', True, None, ()))\\n\", \"    ref.update({'foo': [handler.messages[0x63]]})\\n\", '    assert handler(_errors) == ref\\n', \"    _errors.append(ValidationError(['bar'], ['foo'], 0x42, 'min', 1, 2, ()))\\n\", \"    ref.update({'bar': [handler.messages[0x42].format(constraint=1)]})\\n\", '    assert handler(_errors) == ref\\n', '    _errors.append(\\n', '        ValidationError(\\n', \"    ref.update({'zap': [{'foo': [handler.messages[0x24].format(constraint='string')]}]})\\n\", '    assert handler(_errors) == ref\\n', '    _errors.append(\\n', '        ValidationError(\\n', \"    ref['zap'][0]['foo'].append(handler.messages[0x41].format(constraint='^p[e]ng$'))\\n\", '    assert handler(_errors) == ref\\n', \"    schema = {'foo': {'oneof': ({'type': ('integer',)}, {'type': ('string',)})}}\\n\", \"    document = {'foo': 23.42}\\n\", \"    error = ('foo', ('foo', 'oneof'), errors.ONEOF, schema['foo']['oneof'], ())\\n\", \"        (error[0], error[1] + (0, 'type'), errors.TYPE, ('integer',)),\\n\", \"        (error[0], error[1] + (1, 'type'), errors.TYPE, ('string',)),\\n\", '        document, schema, validator=validator, error=error, child_errors=child_errors\\n', '    assert validator.errors == {\\n', '    validator.schema = {\\n', \"    validator({'test_list': ['test']})\\n\", '    assert validator.errors == {\\'test_list\\': [\"length of list should be 2, it is 1\"]}\\n']",
  "context": "ef test_error_tree_from_subschema(validator):\n    schema = {'foo': {'schema': {'bar': {'type': 'string'}}}}\n    document = {'foo': {'bar': 0}}\n    assert_fail"
 },
 "438": {
  "name": "document",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_errors.py",
  "lineno": "62",
  "column": "4",
  "slicing": "[\"    document = {'foo': {'bar': 0}}\\n\", '    assert_fail(document, schema, validator=validator)\\n', '    assert_fail(document, schema, validator=validator)\\n', '    assert_fail(document, schema, validator=validator)\\n', '    validator(document)\\n', '        document, schema, validator=validator, error=error, child_errors=child_errors\\n']",
  "context": "oo': {'schema': {'bar': {'type': 'string'}}}}\n    document = {'foo': {'bar': 0}}\n    assert_fail(document, schema, validator=valida"
 },
 "439": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_errors.py",
  "lineno": "86",
  "column": "4",
  "slicing": "['ValidationError = errors.ValidationError\\n', \"    v = Validator(schema={'foo': {'type': 'string'}})\\n\", \"    v.document = {'foo': 42}\\n\", \"    v._error('foo', errors.TYPE, 'string')\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'type')\\n\", '    assert error.code == 0x24\\n', \"    assert error.rule == 'type'\\n\", \"    assert error.constraint == ('string',)\\n\", '    assert error.value == 42\\n', \"    assert error.info == ('string',)\\n\", '    assert not error.is_group_error\\n', '    assert not error.is_logic_error\\n', \"    v = Validator(schema={'foo': {'keysrules': {'type': 'integer'}}})\\n\", \"    v.document = {'foo': {'0': 'bar'}}\\n\", \"    v._error('foo', errors.KEYSRULES, ())\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'keysrules')\\n\", '    assert error.code == 0x83\\n', \"    assert error.rule == 'keysrules'\\n\", \"    assert error.constraint == {'type': ('integer',)}\\n\", \"    assert error.value == {'0': 'bar'}\\n\", '    assert error.info == ((),)\\n', '    assert error.is_group_error\\n', '    assert not error.is_logic_error\\n', '    valids = (\\n', \"    v = Validator(schema={'foo': {'oneof': valids}})\\n\", \"    v.document = {'foo': '0x100'}\\n\", \"    v._error('foo', errors.ONEOF, (), 0, 2)\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'oneof')\\n\", '    assert error.code == 0x92\\n', \"    assert error.rule == 'oneof'\\n\", '    assert error.constraint == valids\\n', \"    assert error.value == '0x100'\\n\", '    assert error.info == ((), 0, 2)\\n', '    assert error.is_group_error\\n', '    assert error.is_logic_error\\n', \"    schema = {'foo': {'schema': {'bar': {'type': 'string'}}}}\\n\", \"    document = {'foo': {'bar': 0}}\\n\", '    assert_fail(document, schema, validator=validator)\\n', '    d_error_tree = validator.document_error_tree\\n', '    s_error_tree = validator.schema_error_tree\\n', \"    assert 'foo' in d_error_tree\\n\", \"    assert len(d_error_tree['foo'].errors) == 1, d_error_tree['foo']\\n\", \"    assert d_error_tree['foo'].errors[0].code == errors.SCHEMA.code\\n\", \"    assert 'bar' in d_error_tree['foo']\\n\", \"    assert d_error_tree['foo']['bar'].errors[0].value == 0\\n\", \"    assert d_error_tree.fetch_errors_from(('foo', 'bar'))[0].value == 0\\n\", \"    assert 'foo' in s_error_tree\\n\", \"    assert 'schema' in s_error_tree['foo']\\n\", \"    assert 'bar' in s_error_tree['foo']['schema']\\n\", \"    assert 'type' in s_error_tree['foo']['schema']['bar']\\n\", \"    assert s_error_tree['foo']['schema']['bar']['type'].errors[0].value == 0\\n\", \"        s_error_tree.fetch_errors_from(('foo', 'schema', 'bar', 'type'))[0].value == 0\\n\", \"    schema = {'foo': {'anyof': [{'type': 'string'}, {'type': 'integer'}]}}\\n\", \"    document = {'foo': []}\\n\", '    assert_fail(document, schema, validator=validator)\\n', '    d_error_tree = validator.document_error_tree\\n', '    s_error_tree = validator.schema_error_tree\\n', \"    assert 'foo' in d_error_tree\\n\", \"    assert d_error_tree['foo'].errors[0].value == []\\n\", \"    assert 'foo' in s_error_tree\\n\", \"    assert 'anyof' in s_error_tree['foo']\\n\", \"    assert 0 in s_error_tree['foo']['anyof']\\n\", \"    assert 1 in s_error_tree['foo']['anyof']\\n\", \"    assert 'type' in s_error_tree['foo']['anyof'][0]\\n\", \"    assert s_error_tree['foo']['anyof'][0]['type'].errors[0].value == []\\n\", '    schema = {\\n', '    document = {\\n', '    assert_fail(document, schema, validator=validator)\\n', '    _det = validator.document_error_tree\\n', '    _set = validator.schema_error_tree\\n', '    assert len(_det.errors) == 0\\n', '    assert len(_set.errors) == 0\\n', \"    assert len(_det['a_dict'].errors) == 2\\n\", \"    assert len(_set['a_dict'].errors) == 0\\n\", \"    assert _det['a_dict'][0] is None\\n\", \"    assert len(_det['a_dict']['one'].errors) == 1\\n\", \"    assert len(_det['a_dict'][2].errors) == 1\\n\", \"    assert len(_det['a_dict']['three'].errors) == 2\\n\", \"    assert len(_set['a_dict']['keysrules'].errors) == 1\\n\", \"    assert len(_set['a_dict']['valuesrules'].errors) == 1\\n\", \"    assert len(_set['a_dict']['keysrules']['type'].errors) == 2\\n\", \"    assert len(_set['a_dict']['valuesrules']['regex'].errors) == 2\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['one'].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['keysrules']['type'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict'][2].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['valuesrules']['regex'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['three'].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['keysrules']['type'].errors[1] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['three'].errors[1] == _ref_err\\n\", \"    assert _set['a_dict']['valuesrules']['regex'].errors[1] == _ref_err\\n\", \"    assert len(_det['a_list'].errors) == 1\\n\", \"    assert len(_det['a_list'][0].errors) == 1\\n\", \"    assert _det['a_list'][1] is None\\n\", \"    assert len(_det['a_list'][2].errors) == 3\\n\", \"    assert len(_set['a_list'].errors) == 0\\n\", \"    assert len(_set['a_list']['itemsrules'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['type'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['oneof'][0]['regex'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['oneof'][1]['regex'].errors) == 1\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][0].errors[0] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['type'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[0] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[1] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'][0]['regex'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[2] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'][1]['regex'].errors[0] == _ref_err\\n\", \"    schema = {'foo': {'type': 'dict', 'schema': {'bar': {'type': 'number'}}}}\\n\", \"    document = {'foo': {'bar': 'zero'}}\\n\", '    validator = Validator(schema)\\n', '    validator(document)\\n', \"    assert 'foo' in validator.document_error_tree\\n\", \"    assert 'bar' in validator.document_error_tree['foo']\\n\", \"    assert 'foo' in validator.schema_error_tree\\n\", \"    assert 'schema' in validator.schema_error_tree['foo']\\n\", \"    assert errors.SCHEMA in validator.document_error_tree['foo'].errors\\n\", \"    assert errors.SCHEMA in validator.document_error_tree['foo']\\n\", \"    assert errors.TYPE in validator.document_error_tree['foo']['bar']\\n\", \"    assert errors.SCHEMA in validator.schema_error_tree['foo']['schema']\\n\", \"    assert errors.TYPE in validator.schema_error_tree['foo']['schema']['bar']['type']\\n\", \"        validator.document_error_tree['foo'][errors.SCHEMA].child_errors[0].code\\n\", '    handler = errors.BasicErrorHandler()\\n', '    _errors, ref = [], {}\\n', \"    _errors.append(ValidationError(['foo'], ['foo'], 0x63, 'readonly', True, None, ()))\\n\", \"    ref.update({'foo': [handler.messages[0x63]]})\\n\", '    assert handler(_errors) == ref\\n', \"    _errors.append(ValidationError(['bar'], ['foo'], 0x42, 'min', 1, 2, ()))\\n\", \"    ref.update({'bar': [handler.messages[0x42].format(constraint=1)]})\\n\", '    assert handler(_errors) == ref\\n', '    _errors.append(\\n', '        ValidationError(\\n', \"    ref.update({'zap': [{'foo': [handler.messages[0x24].format(constraint='string')]}]})\\n\", '    assert handler(_errors) == ref\\n', '    _errors.append(\\n', '        ValidationError(\\n', \"    ref['zap'][0]['foo'].append(handler.messages[0x41].format(constraint='^p[e]ng$'))\\n\", '    assert handler(_errors) == ref\\n', \"    schema = {'foo': {'oneof': ({'type': ('integer',)}, {'type': ('string',)})}}\\n\", \"    document = {'foo': 23.42}\\n\", \"    error = ('foo', ('foo', 'oneof'), errors.ONEOF, schema['foo']['oneof'], ())\\n\", \"        (error[0], error[1] + (0, 'type'), errors.TYPE, ('integer',)),\\n\", \"        (error[0], error[1] + (1, 'type'), errors.TYPE, ('string',)),\\n\", '        document, schema, validator=validator, error=error, child_errors=child_errors\\n', '    assert validator.errors == {\\n', '    validator.schema = {\\n', \"    validator({'test_list': ['test']})\\n\", '    assert validator.errors == {\\'test_list\\': [\"length of list should be 2, it is 1\"]}\\n']",
  "context": "\n\n\ndef test_error_tree_from_anyof(validator):\n    schema = {'foo': {'anyof': [{'type': 'string'}, {'type': 'integer'}]}}\n    document = {'foo': []}\n    assert_fail(documen"
 },
 "440": {
  "name": "document",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_errors.py",
  "lineno": "87",
  "column": "4",
  "slicing": "[\"    document = {'foo': []}\\n\", '    assert_fail(document, schema, validator=validator)\\n', '    assert_fail(document, schema, validator=validator)\\n', '    validator(document)\\n', '        document, schema, validator=validator, error=error, child_errors=child_errors\\n']",
  "context": ": [{'type': 'string'}, {'type': 'integer'}]}}\n    document = {'foo': []}\n    assert_fail(document, schema, validator=valida"
 },
 "441": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_errors.py",
  "lineno": "102",
  "column": "4",
  "slicing": "['ValidationError = errors.ValidationError\\n', \"    v = Validator(schema={'foo': {'type': 'string'}})\\n\", \"    v.document = {'foo': 42}\\n\", \"    v._error('foo', errors.TYPE, 'string')\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'type')\\n\", '    assert error.code == 0x24\\n', \"    assert error.rule == 'type'\\n\", \"    assert error.constraint == ('string',)\\n\", '    assert error.value == 42\\n', \"    assert error.info == ('string',)\\n\", '    assert not error.is_group_error\\n', '    assert not error.is_logic_error\\n', \"    v = Validator(schema={'foo': {'keysrules': {'type': 'integer'}}})\\n\", \"    v.document = {'foo': {'0': 'bar'}}\\n\", \"    v._error('foo', errors.KEYSRULES, ())\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'keysrules')\\n\", '    assert error.code == 0x83\\n', \"    assert error.rule == 'keysrules'\\n\", \"    assert error.constraint == {'type': ('integer',)}\\n\", \"    assert error.value == {'0': 'bar'}\\n\", '    assert error.info == ((),)\\n', '    assert error.is_group_error\\n', '    assert not error.is_logic_error\\n', '    valids = (\\n', \"    v = Validator(schema={'foo': {'oneof': valids}})\\n\", \"    v.document = {'foo': '0x100'}\\n\", \"    v._error('foo', errors.ONEOF, (), 0, 2)\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'oneof')\\n\", '    assert error.code == 0x92\\n', \"    assert error.rule == 'oneof'\\n\", '    assert error.constraint == valids\\n', \"    assert error.value == '0x100'\\n\", '    assert error.info == ((), 0, 2)\\n', '    assert error.is_group_error\\n', '    assert error.is_logic_error\\n', \"    schema = {'foo': {'schema': {'bar': {'type': 'string'}}}}\\n\", \"    document = {'foo': {'bar': 0}}\\n\", '    assert_fail(document, schema, validator=validator)\\n', '    d_error_tree = validator.document_error_tree\\n', '    s_error_tree = validator.schema_error_tree\\n', \"    assert 'foo' in d_error_tree\\n\", \"    assert len(d_error_tree['foo'].errors) == 1, d_error_tree['foo']\\n\", \"    assert d_error_tree['foo'].errors[0].code == errors.SCHEMA.code\\n\", \"    assert 'bar' in d_error_tree['foo']\\n\", \"    assert d_error_tree['foo']['bar'].errors[0].value == 0\\n\", \"    assert d_error_tree.fetch_errors_from(('foo', 'bar'))[0].value == 0\\n\", \"    assert 'foo' in s_error_tree\\n\", \"    assert 'schema' in s_error_tree['foo']\\n\", \"    assert 'bar' in s_error_tree['foo']['schema']\\n\", \"    assert 'type' in s_error_tree['foo']['schema']['bar']\\n\", \"    assert s_error_tree['foo']['schema']['bar']['type'].errors[0].value == 0\\n\", \"        s_error_tree.fetch_errors_from(('foo', 'schema', 'bar', 'type'))[0].value == 0\\n\", \"    schema = {'foo': {'anyof': [{'type': 'string'}, {'type': 'integer'}]}}\\n\", \"    document = {'foo': []}\\n\", '    assert_fail(document, schema, validator=validator)\\n', '    d_error_tree = validator.document_error_tree\\n', '    s_error_tree = validator.schema_error_tree\\n', \"    assert 'foo' in d_error_tree\\n\", \"    assert d_error_tree['foo'].errors[0].value == []\\n\", \"    assert 'foo' in s_error_tree\\n\", \"    assert 'anyof' in s_error_tree['foo']\\n\", \"    assert 0 in s_error_tree['foo']['anyof']\\n\", \"    assert 1 in s_error_tree['foo']['anyof']\\n\", \"    assert 'type' in s_error_tree['foo']['anyof'][0]\\n\", \"    assert s_error_tree['foo']['anyof'][0]['type'].errors[0].value == []\\n\", '    schema = {\\n', '    document = {\\n', '    assert_fail(document, schema, validator=validator)\\n', '    _det = validator.document_error_tree\\n', '    _set = validator.schema_error_tree\\n', '    assert len(_det.errors) == 0\\n', '    assert len(_set.errors) == 0\\n', \"    assert len(_det['a_dict'].errors) == 2\\n\", \"    assert len(_set['a_dict'].errors) == 0\\n\", \"    assert _det['a_dict'][0] is None\\n\", \"    assert len(_det['a_dict']['one'].errors) == 1\\n\", \"    assert len(_det['a_dict'][2].errors) == 1\\n\", \"    assert len(_det['a_dict']['three'].errors) == 2\\n\", \"    assert len(_set['a_dict']['keysrules'].errors) == 1\\n\", \"    assert len(_set['a_dict']['valuesrules'].errors) == 1\\n\", \"    assert len(_set['a_dict']['keysrules']['type'].errors) == 2\\n\", \"    assert len(_set['a_dict']['valuesrules']['regex'].errors) == 2\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['one'].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['keysrules']['type'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict'][2].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['valuesrules']['regex'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['three'].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['keysrules']['type'].errors[1] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['three'].errors[1] == _ref_err\\n\", \"    assert _set['a_dict']['valuesrules']['regex'].errors[1] == _ref_err\\n\", \"    assert len(_det['a_list'].errors) == 1\\n\", \"    assert len(_det['a_list'][0].errors) == 1\\n\", \"    assert _det['a_list'][1] is None\\n\", \"    assert len(_det['a_list'][2].errors) == 3\\n\", \"    assert len(_set['a_list'].errors) == 0\\n\", \"    assert len(_set['a_list']['itemsrules'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['type'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['oneof'][0]['regex'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['oneof'][1]['regex'].errors) == 1\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][0].errors[0] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['type'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[0] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[1] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'][0]['regex'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[2] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'][1]['regex'].errors[0] == _ref_err\\n\", \"    schema = {'foo': {'type': 'dict', 'schema': {'bar': {'type': 'number'}}}}\\n\", \"    document = {'foo': {'bar': 'zero'}}\\n\", '    validator = Validator(schema)\\n', '    validator(document)\\n', \"    assert 'foo' in validator.document_error_tree\\n\", \"    assert 'bar' in validator.document_error_tree['foo']\\n\", \"    assert 'foo' in validator.schema_error_tree\\n\", \"    assert 'schema' in validator.schema_error_tree['foo']\\n\", \"    assert errors.SCHEMA in validator.document_error_tree['foo'].errors\\n\", \"    assert errors.SCHEMA in validator.document_error_tree['foo']\\n\", \"    assert errors.TYPE in validator.document_error_tree['foo']['bar']\\n\", \"    assert errors.SCHEMA in validator.schema_error_tree['foo']['schema']\\n\", \"    assert errors.TYPE in validator.schema_error_tree['foo']['schema']['bar']['type']\\n\", \"        validator.document_error_tree['foo'][errors.SCHEMA].child_errors[0].code\\n\", '    handler = errors.BasicErrorHandler()\\n', '    _errors, ref = [], {}\\n', \"    _errors.append(ValidationError(['foo'], ['foo'], 0x63, 'readonly', True, None, ()))\\n\", \"    ref.update({'foo': [handler.messages[0x63]]})\\n\", '    assert handler(_errors) == ref\\n', \"    _errors.append(ValidationError(['bar'], ['foo'], 0x42, 'min', 1, 2, ()))\\n\", \"    ref.update({'bar': [handler.messages[0x42].format(constraint=1)]})\\n\", '    assert handler(_errors) == ref\\n', '    _errors.append(\\n', '        ValidationError(\\n', \"    ref.update({'zap': [{'foo': [handler.messages[0x24].format(constraint='string')]}]})\\n\", '    assert handler(_errors) == ref\\n', '    _errors.append(\\n', '        ValidationError(\\n', \"    ref['zap'][0]['foo'].append(handler.messages[0x41].format(constraint='^p[e]ng$'))\\n\", '    assert handler(_errors) == ref\\n', \"    schema = {'foo': {'oneof': ({'type': ('integer',)}, {'type': ('string',)})}}\\n\", \"    document = {'foo': 23.42}\\n\", \"    error = ('foo', ('foo', 'oneof'), errors.ONEOF, schema['foo']['oneof'], ())\\n\", \"        (error[0], error[1] + (0, 'type'), errors.TYPE, ('integer',)),\\n\", \"        (error[0], error[1] + (1, 'type'), errors.TYPE, ('string',)),\\n\", '        document, schema, validator=validator, error=error, child_errors=child_errors\\n', '    assert validator.errors == {\\n', '    validator.schema = {\\n', \"    validator({'test_list': ['test']})\\n\", '    assert validator.errors == {\\'test_list\\': [\"length of list should be 2, it is 1\"]}\\n']",
  "context": " []\n\n\ndef test_nested_error_paths(validator):\n    schema = {\n        'a_dict': {\n            'keysrules': {'typ"
 },
 "442": {
  "name": "document",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_errors.py",
  "lineno": "111",
  "column": "4",
  "slicing": "['    document = {\\n', '    assert_fail(document, schema, validator=validator)\\n', '    validator(document)\\n', '        document, schema, validator=validator, error=error, child_errors=child_errors\\n']",
  "context": "gex': ['[a-z]*$', '[A-Z]*']}\n        },\n    }\n    document = {\n        'a_dict': {0: 'abc', 'one': 'abc', 2: 'aBc"
 },
 "443": {
  "name": "_ref_err",
  "type": "ValidationError",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_errors.py",
  "lineno": "137",
  "column": "4",
  "slicing": "['ValidationError = errors.ValidationError\\n', \"    v = Validator(schema={'foo': {'type': 'string'}})\\n\", \"    v.document = {'foo': 42}\\n\", \"    v._error('foo', errors.TYPE, 'string')\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'type')\\n\", '    assert error.code == 0x24\\n', \"    assert error.rule == 'type'\\n\", \"    assert error.constraint == ('string',)\\n\", '    assert error.value == 42\\n', \"    assert error.info == ('string',)\\n\", '    assert not error.is_group_error\\n', '    assert not error.is_logic_error\\n', \"    v = Validator(schema={'foo': {'keysrules': {'type': 'integer'}}})\\n\", \"    v.document = {'foo': {'0': 'bar'}}\\n\", \"    v._error('foo', errors.KEYSRULES, ())\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'keysrules')\\n\", '    assert error.code == 0x83\\n', \"    assert error.rule == 'keysrules'\\n\", \"    assert error.constraint == {'type': ('integer',)}\\n\", \"    assert error.value == {'0': 'bar'}\\n\", '    assert error.info == ((),)\\n', '    assert error.is_group_error\\n', '    assert not error.is_logic_error\\n', '    valids = (\\n', \"    v = Validator(schema={'foo': {'oneof': valids}})\\n\", \"    v.document = {'foo': '0x100'}\\n\", \"    v._error('foo', errors.ONEOF, (), 0, 2)\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'oneof')\\n\", '    assert error.code == 0x92\\n', \"    assert error.rule == 'oneof'\\n\", '    assert error.constraint == valids\\n', \"    assert error.value == '0x100'\\n\", '    assert error.info == ((), 0, 2)\\n', '    assert error.is_group_error\\n', '    assert error.is_logic_error\\n', \"    schema = {'foo': {'schema': {'bar': {'type': 'string'}}}}\\n\", \"    document = {'foo': {'bar': 0}}\\n\", '    assert_fail(document, schema, validator=validator)\\n', '    d_error_tree = validator.document_error_tree\\n', '    s_error_tree = validator.schema_error_tree\\n', \"    assert 'foo' in d_error_tree\\n\", \"    assert len(d_error_tree['foo'].errors) == 1, d_error_tree['foo']\\n\", \"    assert d_error_tree['foo'].errors[0].code == errors.SCHEMA.code\\n\", \"    assert 'bar' in d_error_tree['foo']\\n\", \"    assert d_error_tree['foo']['bar'].errors[0].value == 0\\n\", \"    assert d_error_tree.fetch_errors_from(('foo', 'bar'))[0].value == 0\\n\", \"    assert 'foo' in s_error_tree\\n\", \"    assert 'schema' in s_error_tree['foo']\\n\", \"    assert 'bar' in s_error_tree['foo']['schema']\\n\", \"    assert 'type' in s_error_tree['foo']['schema']['bar']\\n\", \"    assert s_error_tree['foo']['schema']['bar']['type'].errors[0].value == 0\\n\", \"        s_error_tree.fetch_errors_from(('foo', 'schema', 'bar', 'type'))[0].value == 0\\n\", \"    schema = {'foo': {'anyof': [{'type': 'string'}, {'type': 'integer'}]}}\\n\", \"    document = {'foo': []}\\n\", '    assert_fail(document, schema, validator=validator)\\n', '    d_error_tree = validator.document_error_tree\\n', '    s_error_tree = validator.schema_error_tree\\n', \"    assert 'foo' in d_error_tree\\n\", \"    assert d_error_tree['foo'].errors[0].value == []\\n\", \"    assert 'foo' in s_error_tree\\n\", \"    assert 'anyof' in s_error_tree['foo']\\n\", \"    assert 0 in s_error_tree['foo']['anyof']\\n\", \"    assert 1 in s_error_tree['foo']['anyof']\\n\", \"    assert 'type' in s_error_tree['foo']['anyof'][0]\\n\", \"    assert s_error_tree['foo']['anyof'][0]['type'].errors[0].value == []\\n\", '    schema = {\\n', '    document = {\\n', '    assert_fail(document, schema, validator=validator)\\n', '    _det = validator.document_error_tree\\n', '    _set = validator.schema_error_tree\\n', '    assert len(_det.errors) == 0\\n', '    assert len(_set.errors) == 0\\n', \"    assert len(_det['a_dict'].errors) == 2\\n\", \"    assert len(_set['a_dict'].errors) == 0\\n\", \"    assert _det['a_dict'][0] is None\\n\", \"    assert len(_det['a_dict']['one'].errors) == 1\\n\", \"    assert len(_det['a_dict'][2].errors) == 1\\n\", \"    assert len(_det['a_dict']['three'].errors) == 2\\n\", \"    assert len(_set['a_dict']['keysrules'].errors) == 1\\n\", \"    assert len(_set['a_dict']['valuesrules'].errors) == 1\\n\", \"    assert len(_set['a_dict']['keysrules']['type'].errors) == 2\\n\", \"    assert len(_set['a_dict']['valuesrules']['regex'].errors) == 2\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['one'].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['keysrules']['type'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict'][2].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['valuesrules']['regex'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['three'].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['keysrules']['type'].errors[1] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['three'].errors[1] == _ref_err\\n\", \"    assert _set['a_dict']['valuesrules']['regex'].errors[1] == _ref_err\\n\", \"    assert len(_det['a_list'].errors) == 1\\n\", \"    assert len(_det['a_list'][0].errors) == 1\\n\", \"    assert _det['a_list'][1] is None\\n\", \"    assert len(_det['a_list'][2].errors) == 3\\n\", \"    assert len(_set['a_list'].errors) == 0\\n\", \"    assert len(_set['a_list']['itemsrules'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['type'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['oneof'][0]['regex'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['oneof'][1]['regex'].errors) == 1\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][0].errors[0] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['type'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[0] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[1] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'][0]['regex'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[2] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'][1]['regex'].errors[0] == _ref_err\\n\", \"    schema = {'foo': {'type': 'dict', 'schema': {'bar': {'type': 'number'}}}}\\n\", \"    document = {'foo': {'bar': 'zero'}}\\n\", '    validator = Validator(schema)\\n', '    validator(document)\\n', \"    assert 'foo' in validator.document_error_tree\\n\", \"    assert 'bar' in validator.document_error_tree['foo']\\n\", \"    assert 'foo' in validator.schema_error_tree\\n\", \"    assert 'schema' in validator.schema_error_tree['foo']\\n\", \"    assert errors.SCHEMA in validator.document_error_tree['foo'].errors\\n\", \"    assert errors.SCHEMA in validator.document_error_tree['foo']\\n\", \"    assert errors.TYPE in validator.document_error_tree['foo']['bar']\\n\", \"    assert errors.SCHEMA in validator.schema_error_tree['foo']['schema']\\n\", \"    assert errors.TYPE in validator.schema_error_tree['foo']['schema']['bar']['type']\\n\", \"        validator.document_error_tree['foo'][errors.SCHEMA].child_errors[0].code\\n\", '    handler = errors.BasicErrorHandler()\\n', '    _errors, ref = [], {}\\n', \"    _errors.append(ValidationError(['foo'], ['foo'], 0x63, 'readonly', True, None, ()))\\n\", \"    ref.update({'foo': [handler.messages[0x63]]})\\n\", '    assert handler(_errors) == ref\\n', \"    _errors.append(ValidationError(['bar'], ['foo'], 0x42, 'min', 1, 2, ()))\\n\", \"    ref.update({'bar': [handler.messages[0x42].format(constraint=1)]})\\n\", '    assert handler(_errors) == ref\\n', '    _errors.append(\\n', '        ValidationError(\\n', \"    ref.update({'zap': [{'foo': [handler.messages[0x24].format(constraint='string')]}]})\\n\", '    assert handler(_errors) == ref\\n', '    _errors.append(\\n', '        ValidationError(\\n', \"    ref['zap'][0]['foo'].append(handler.messages[0x41].format(constraint='^p[e]ng$'))\\n\", '    assert handler(_errors) == ref\\n', \"    schema = {'foo': {'oneof': ({'type': ('integer',)}, {'type': ('string',)})}}\\n\", \"    document = {'foo': 23.42}\\n\", \"    error = ('foo', ('foo', 'oneof'), errors.ONEOF, schema['foo']['oneof'], ())\\n\", \"        (error[0], error[1] + (0, 'type'), errors.TYPE, ('integer',)),\\n\", \"        (error[0], error[1] + (1, 'type'), errors.TYPE, ('string',)),\\n\", '        document, schema, validator=validator, error=error, child_errors=child_errors\\n', '    assert validator.errors == {\\n', '    validator.schema = {\\n', \"    validator({'test_list': ['test']})\\n\", '    assert validator.errors == {\\'test_list\\': [\"length of list should be 2, it is 1\"]}\\n']",
  "context": "_dict']['valuesrules']['regex'].errors) == 2\n\n    _ref_err = ValidationError(\n        ('a_dict', 'one'),\n        ('a_dict', 'key"
 },
 "444": {
  "name": "_ref_err",
  "type": "ValidationError",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_errors.py",
  "lineno": "149",
  "column": "4",
  "slicing": "['ValidationError = errors.ValidationError\\n', \"    v = Validator(schema={'foo': {'type': 'string'}})\\n\", \"    v.document = {'foo': 42}\\n\", \"    v._error('foo', errors.TYPE, 'string')\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'type')\\n\", '    assert error.code == 0x24\\n', \"    assert error.rule == 'type'\\n\", \"    assert error.constraint == ('string',)\\n\", '    assert error.value == 42\\n', \"    assert error.info == ('string',)\\n\", '    assert not error.is_group_error\\n', '    assert not error.is_logic_error\\n', \"    v = Validator(schema={'foo': {'keysrules': {'type': 'integer'}}})\\n\", \"    v.document = {'foo': {'0': 'bar'}}\\n\", \"    v._error('foo', errors.KEYSRULES, ())\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'keysrules')\\n\", '    assert error.code == 0x83\\n', \"    assert error.rule == 'keysrules'\\n\", \"    assert error.constraint == {'type': ('integer',)}\\n\", \"    assert error.value == {'0': 'bar'}\\n\", '    assert error.info == ((),)\\n', '    assert error.is_group_error\\n', '    assert not error.is_logic_error\\n', '    valids = (\\n', \"    v = Validator(schema={'foo': {'oneof': valids}})\\n\", \"    v.document = {'foo': '0x100'}\\n\", \"    v._error('foo', errors.ONEOF, (), 0, 2)\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'oneof')\\n\", '    assert error.code == 0x92\\n', \"    assert error.rule == 'oneof'\\n\", '    assert error.constraint == valids\\n', \"    assert error.value == '0x100'\\n\", '    assert error.info == ((), 0, 2)\\n', '    assert error.is_group_error\\n', '    assert error.is_logic_error\\n', \"    schema = {'foo': {'schema': {'bar': {'type': 'string'}}}}\\n\", \"    document = {'foo': {'bar': 0}}\\n\", '    assert_fail(document, schema, validator=validator)\\n', '    d_error_tree = validator.document_error_tree\\n', '    s_error_tree = validator.schema_error_tree\\n', \"    assert 'foo' in d_error_tree\\n\", \"    assert len(d_error_tree['foo'].errors) == 1, d_error_tree['foo']\\n\", \"    assert d_error_tree['foo'].errors[0].code == errors.SCHEMA.code\\n\", \"    assert 'bar' in d_error_tree['foo']\\n\", \"    assert d_error_tree['foo']['bar'].errors[0].value == 0\\n\", \"    assert d_error_tree.fetch_errors_from(('foo', 'bar'))[0].value == 0\\n\", \"    assert 'foo' in s_error_tree\\n\", \"    assert 'schema' in s_error_tree['foo']\\n\", \"    assert 'bar' in s_error_tree['foo']['schema']\\n\", \"    assert 'type' in s_error_tree['foo']['schema']['bar']\\n\", \"    assert s_error_tree['foo']['schema']['bar']['type'].errors[0].value == 0\\n\", \"        s_error_tree.fetch_errors_from(('foo', 'schema', 'bar', 'type'))[0].value == 0\\n\", \"    schema = {'foo': {'anyof': [{'type': 'string'}, {'type': 'integer'}]}}\\n\", \"    document = {'foo': []}\\n\", '    assert_fail(document, schema, validator=validator)\\n', '    d_error_tree = validator.document_error_tree\\n', '    s_error_tree = validator.schema_error_tree\\n', \"    assert 'foo' in d_error_tree\\n\", \"    assert d_error_tree['foo'].errors[0].value == []\\n\", \"    assert 'foo' in s_error_tree\\n\", \"    assert 'anyof' in s_error_tree['foo']\\n\", \"    assert 0 in s_error_tree['foo']['anyof']\\n\", \"    assert 1 in s_error_tree['foo']['anyof']\\n\", \"    assert 'type' in s_error_tree['foo']['anyof'][0]\\n\", \"    assert s_error_tree['foo']['anyof'][0]['type'].errors[0].value == []\\n\", '    schema = {\\n', '    document = {\\n', '    assert_fail(document, schema, validator=validator)\\n', '    _det = validator.document_error_tree\\n', '    _set = validator.schema_error_tree\\n', '    assert len(_det.errors) == 0\\n', '    assert len(_set.errors) == 0\\n', \"    assert len(_det['a_dict'].errors) == 2\\n\", \"    assert len(_set['a_dict'].errors) == 0\\n\", \"    assert _det['a_dict'][0] is None\\n\", \"    assert len(_det['a_dict']['one'].errors) == 1\\n\", \"    assert len(_det['a_dict'][2].errors) == 1\\n\", \"    assert len(_det['a_dict']['three'].errors) == 2\\n\", \"    assert len(_set['a_dict']['keysrules'].errors) == 1\\n\", \"    assert len(_set['a_dict']['valuesrules'].errors) == 1\\n\", \"    assert len(_set['a_dict']['keysrules']['type'].errors) == 2\\n\", \"    assert len(_set['a_dict']['valuesrules']['regex'].errors) == 2\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['one'].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['keysrules']['type'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict'][2].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['valuesrules']['regex'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['three'].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['keysrules']['type'].errors[1] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['three'].errors[1] == _ref_err\\n\", \"    assert _set['a_dict']['valuesrules']['regex'].errors[1] == _ref_err\\n\", \"    assert len(_det['a_list'].errors) == 1\\n\", \"    assert len(_det['a_list'][0].errors) == 1\\n\", \"    assert _det['a_list'][1] is None\\n\", \"    assert len(_det['a_list'][2].errors) == 3\\n\", \"    assert len(_set['a_list'].errors) == 0\\n\", \"    assert len(_set['a_list']['itemsrules'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['type'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['oneof'][0]['regex'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['oneof'][1]['regex'].errors) == 1\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][0].errors[0] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['type'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[0] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[1] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'][0]['regex'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[2] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'][1]['regex'].errors[0] == _ref_err\\n\", \"    schema = {'foo': {'type': 'dict', 'schema': {'bar': {'type': 'number'}}}}\\n\", \"    document = {'foo': {'bar': 'zero'}}\\n\", '    validator = Validator(schema)\\n', '    validator(document)\\n', \"    assert 'foo' in validator.document_error_tree\\n\", \"    assert 'bar' in validator.document_error_tree['foo']\\n\", \"    assert 'foo' in validator.schema_error_tree\\n\", \"    assert 'schema' in validator.schema_error_tree['foo']\\n\", \"    assert errors.SCHEMA in validator.document_error_tree['foo'].errors\\n\", \"    assert errors.SCHEMA in validator.document_error_tree['foo']\\n\", \"    assert errors.TYPE in validator.document_error_tree['foo']['bar']\\n\", \"    assert errors.SCHEMA in validator.schema_error_tree['foo']['schema']\\n\", \"    assert errors.TYPE in validator.schema_error_tree['foo']['schema']['bar']['type']\\n\", \"        validator.document_error_tree['foo'][errors.SCHEMA].child_errors[0].code\\n\", '    handler = errors.BasicErrorHandler()\\n', '    _errors, ref = [], {}\\n', \"    _errors.append(ValidationError(['foo'], ['foo'], 0x63, 'readonly', True, None, ()))\\n\", \"    ref.update({'foo': [handler.messages[0x63]]})\\n\", '    assert handler(_errors) == ref\\n', \"    _errors.append(ValidationError(['bar'], ['foo'], 0x42, 'min', 1, 2, ()))\\n\", \"    ref.update({'bar': [handler.messages[0x42].format(constraint=1)]})\\n\", '    assert handler(_errors) == ref\\n', '    _errors.append(\\n', '        ValidationError(\\n', \"    ref.update({'zap': [{'foo': [handler.messages[0x24].format(constraint='string')]}]})\\n\", '    assert handler(_errors) == ref\\n', '    _errors.append(\\n', '        ValidationError(\\n', \"    ref['zap'][0]['foo'].append(handler.messages[0x41].format(constraint='^p[e]ng$'))\\n\", '    assert handler(_errors) == ref\\n', \"    schema = {'foo': {'oneof': ({'type': ('integer',)}, {'type': ('string',)})}}\\n\", \"    document = {'foo': 23.42}\\n\", \"    error = ('foo', ('foo', 'oneof'), errors.ONEOF, schema['foo']['oneof'], ())\\n\", \"        (error[0], error[1] + (0, 'type'), errors.TYPE, ('integer',)),\\n\", \"        (error[0], error[1] + (1, 'type'), errors.TYPE, ('string',)),\\n\", '        document, schema, validator=validator, error=error, child_errors=child_errors\\n', '    assert validator.errors == {\\n', '    validator.schema = {\\n', \"    validator({'test_list': ['test']})\\n\", '    assert validator.errors == {\\'test_list\\': [\"length of list should be 2, it is 1\"]}\\n']",
  "context": "]['keysrules']['type'].errors[0] == _ref_err\n\n    _ref_err = ValidationError(\n        ('a_dict', 2),\n        ('a_dict', 'valuesr"
 },
 "445": {
  "name": "_ref_err",
  "type": "ValidationError",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_errors.py",
  "lineno": "161",
  "column": "4",
  "slicing": "['ValidationError = errors.ValidationError\\n', \"    v = Validator(schema={'foo': {'type': 'string'}})\\n\", \"    v.document = {'foo': 42}\\n\", \"    v._error('foo', errors.TYPE, 'string')\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'type')\\n\", '    assert error.code == 0x24\\n', \"    assert error.rule == 'type'\\n\", \"    assert error.constraint == ('string',)\\n\", '    assert error.value == 42\\n', \"    assert error.info == ('string',)\\n\", '    assert not error.is_group_error\\n', '    assert not error.is_logic_error\\n', \"    v = Validator(schema={'foo': {'keysrules': {'type': 'integer'}}})\\n\", \"    v.document = {'foo': {'0': 'bar'}}\\n\", \"    v._error('foo', errors.KEYSRULES, ())\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'keysrules')\\n\", '    assert error.code == 0x83\\n', \"    assert error.rule == 'keysrules'\\n\", \"    assert error.constraint == {'type': ('integer',)}\\n\", \"    assert error.value == {'0': 'bar'}\\n\", '    assert error.info == ((),)\\n', '    assert error.is_group_error\\n', '    assert not error.is_logic_error\\n', '    valids = (\\n', \"    v = Validator(schema={'foo': {'oneof': valids}})\\n\", \"    v.document = {'foo': '0x100'}\\n\", \"    v._error('foo', errors.ONEOF, (), 0, 2)\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'oneof')\\n\", '    assert error.code == 0x92\\n', \"    assert error.rule == 'oneof'\\n\", '    assert error.constraint == valids\\n', \"    assert error.value == '0x100'\\n\", '    assert error.info == ((), 0, 2)\\n', '    assert error.is_group_error\\n', '    assert error.is_logic_error\\n', \"    schema = {'foo': {'schema': {'bar': {'type': 'string'}}}}\\n\", \"    document = {'foo': {'bar': 0}}\\n\", '    assert_fail(document, schema, validator=validator)\\n', '    d_error_tree = validator.document_error_tree\\n', '    s_error_tree = validator.schema_error_tree\\n', \"    assert 'foo' in d_error_tree\\n\", \"    assert len(d_error_tree['foo'].errors) == 1, d_error_tree['foo']\\n\", \"    assert d_error_tree['foo'].errors[0].code == errors.SCHEMA.code\\n\", \"    assert 'bar' in d_error_tree['foo']\\n\", \"    assert d_error_tree['foo']['bar'].errors[0].value == 0\\n\", \"    assert d_error_tree.fetch_errors_from(('foo', 'bar'))[0].value == 0\\n\", \"    assert 'foo' in s_error_tree\\n\", \"    assert 'schema' in s_error_tree['foo']\\n\", \"    assert 'bar' in s_error_tree['foo']['schema']\\n\", \"    assert 'type' in s_error_tree['foo']['schema']['bar']\\n\", \"    assert s_error_tree['foo']['schema']['bar']['type'].errors[0].value == 0\\n\", \"        s_error_tree.fetch_errors_from(('foo', 'schema', 'bar', 'type'))[0].value == 0\\n\", \"    schema = {'foo': {'anyof': [{'type': 'string'}, {'type': 'integer'}]}}\\n\", \"    document = {'foo': []}\\n\", '    assert_fail(document, schema, validator=validator)\\n', '    d_error_tree = validator.document_error_tree\\n', '    s_error_tree = validator.schema_error_tree\\n', \"    assert 'foo' in d_error_tree\\n\", \"    assert d_error_tree['foo'].errors[0].value == []\\n\", \"    assert 'foo' in s_error_tree\\n\", \"    assert 'anyof' in s_error_tree['foo']\\n\", \"    assert 0 in s_error_tree['foo']['anyof']\\n\", \"    assert 1 in s_error_tree['foo']['anyof']\\n\", \"    assert 'type' in s_error_tree['foo']['anyof'][0]\\n\", \"    assert s_error_tree['foo']['anyof'][0]['type'].errors[0].value == []\\n\", '    schema = {\\n', '    document = {\\n', '    assert_fail(document, schema, validator=validator)\\n', '    _det = validator.document_error_tree\\n', '    _set = validator.schema_error_tree\\n', '    assert len(_det.errors) == 0\\n', '    assert len(_set.errors) == 0\\n', \"    assert len(_det['a_dict'].errors) == 2\\n\", \"    assert len(_set['a_dict'].errors) == 0\\n\", \"    assert _det['a_dict'][0] is None\\n\", \"    assert len(_det['a_dict']['one'].errors) == 1\\n\", \"    assert len(_det['a_dict'][2].errors) == 1\\n\", \"    assert len(_det['a_dict']['three'].errors) == 2\\n\", \"    assert len(_set['a_dict']['keysrules'].errors) == 1\\n\", \"    assert len(_set['a_dict']['valuesrules'].errors) == 1\\n\", \"    assert len(_set['a_dict']['keysrules']['type'].errors) == 2\\n\", \"    assert len(_set['a_dict']['valuesrules']['regex'].errors) == 2\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['one'].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['keysrules']['type'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict'][2].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['valuesrules']['regex'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['three'].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['keysrules']['type'].errors[1] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['three'].errors[1] == _ref_err\\n\", \"    assert _set['a_dict']['valuesrules']['regex'].errors[1] == _ref_err\\n\", \"    assert len(_det['a_list'].errors) == 1\\n\", \"    assert len(_det['a_list'][0].errors) == 1\\n\", \"    assert _det['a_list'][1] is None\\n\", \"    assert len(_det['a_list'][2].errors) == 3\\n\", \"    assert len(_set['a_list'].errors) == 0\\n\", \"    assert len(_set['a_list']['itemsrules'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['type'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['oneof'][0]['regex'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['oneof'][1]['regex'].errors) == 1\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][0].errors[0] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['type'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[0] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[1] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'][0]['regex'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[2] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'][1]['regex'].errors[0] == _ref_err\\n\", \"    schema = {'foo': {'type': 'dict', 'schema': {'bar': {'type': 'number'}}}}\\n\", \"    document = {'foo': {'bar': 'zero'}}\\n\", '    validator = Validator(schema)\\n', '    validator(document)\\n', \"    assert 'foo' in validator.document_error_tree\\n\", \"    assert 'bar' in validator.document_error_tree['foo']\\n\", \"    assert 'foo' in validator.schema_error_tree\\n\", \"    assert 'schema' in validator.schema_error_tree['foo']\\n\", \"    assert errors.SCHEMA in validator.document_error_tree['foo'].errors\\n\", \"    assert errors.SCHEMA in validator.document_error_tree['foo']\\n\", \"    assert errors.TYPE in validator.document_error_tree['foo']['bar']\\n\", \"    assert errors.SCHEMA in validator.schema_error_tree['foo']['schema']\\n\", \"    assert errors.TYPE in validator.schema_error_tree['foo']['schema']['bar']['type']\\n\", \"        validator.document_error_tree['foo'][errors.SCHEMA].child_errors[0].code\\n\", '    handler = errors.BasicErrorHandler()\\n', '    _errors, ref = [], {}\\n', \"    _errors.append(ValidationError(['foo'], ['foo'], 0x63, 'readonly', True, None, ()))\\n\", \"    ref.update({'foo': [handler.messages[0x63]]})\\n\", '    assert handler(_errors) == ref\\n', \"    _errors.append(ValidationError(['bar'], ['foo'], 0x42, 'min', 1, 2, ()))\\n\", \"    ref.update({'bar': [handler.messages[0x42].format(constraint=1)]})\\n\", '    assert handler(_errors) == ref\\n', '    _errors.append(\\n', '        ValidationError(\\n', \"    ref.update({'zap': [{'foo': [handler.messages[0x24].format(constraint='string')]}]})\\n\", '    assert handler(_errors) == ref\\n', '    _errors.append(\\n', '        ValidationError(\\n', \"    ref['zap'][0]['foo'].append(handler.messages[0x41].format(constraint='^p[e]ng$'))\\n\", '    assert handler(_errors) == ref\\n', \"    schema = {'foo': {'oneof': ({'type': ('integer',)}, {'type': ('string',)})}}\\n\", \"    document = {'foo': 23.42}\\n\", \"    error = ('foo', ('foo', 'oneof'), errors.ONEOF, schema['foo']['oneof'], ())\\n\", \"        (error[0], error[1] + (0, 'type'), errors.TYPE, ('integer',)),\\n\", \"        (error[0], error[1] + (1, 'type'), errors.TYPE, ('string',)),\\n\", '        document, schema, validator=validator, error=error, child_errors=child_errors\\n', '    assert validator.errors == {\\n', '    validator.schema = {\\n', \"    validator({'test_list': ['test']})\\n\", '    assert validator.errors == {\\'test_list\\': [\"length of list should be 2, it is 1\"]}\\n']",
  "context": "valuesrules']['regex'].errors[0] == _ref_err\n\n    _ref_err = ValidationError(\n        ('a_dict', 'three'),\n        ('a_dict', 'k"
 },
 "446": {
  "name": "_ref_err",
  "type": "ValidationError",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_errors.py",
  "lineno": "173",
  "column": "4",
  "slicing": "['ValidationError = errors.ValidationError\\n', \"    v = Validator(schema={'foo': {'type': 'string'}})\\n\", \"    v.document = {'foo': 42}\\n\", \"    v._error('foo', errors.TYPE, 'string')\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'type')\\n\", '    assert error.code == 0x24\\n', \"    assert error.rule == 'type'\\n\", \"    assert error.constraint == ('string',)\\n\", '    assert error.value == 42\\n', \"    assert error.info == ('string',)\\n\", '    assert not error.is_group_error\\n', '    assert not error.is_logic_error\\n', \"    v = Validator(schema={'foo': {'keysrules': {'type': 'integer'}}})\\n\", \"    v.document = {'foo': {'0': 'bar'}}\\n\", \"    v._error('foo', errors.KEYSRULES, ())\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'keysrules')\\n\", '    assert error.code == 0x83\\n', \"    assert error.rule == 'keysrules'\\n\", \"    assert error.constraint == {'type': ('integer',)}\\n\", \"    assert error.value == {'0': 'bar'}\\n\", '    assert error.info == ((),)\\n', '    assert error.is_group_error\\n', '    assert not error.is_logic_error\\n', '    valids = (\\n', \"    v = Validator(schema={'foo': {'oneof': valids}})\\n\", \"    v.document = {'foo': '0x100'}\\n\", \"    v._error('foo', errors.ONEOF, (), 0, 2)\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'oneof')\\n\", '    assert error.code == 0x92\\n', \"    assert error.rule == 'oneof'\\n\", '    assert error.constraint == valids\\n', \"    assert error.value == '0x100'\\n\", '    assert error.info == ((), 0, 2)\\n', '    assert error.is_group_error\\n', '    assert error.is_logic_error\\n', \"    schema = {'foo': {'schema': {'bar': {'type': 'string'}}}}\\n\", \"    document = {'foo': {'bar': 0}}\\n\", '    assert_fail(document, schema, validator=validator)\\n', '    d_error_tree = validator.document_error_tree\\n', '    s_error_tree = validator.schema_error_tree\\n', \"    assert 'foo' in d_error_tree\\n\", \"    assert len(d_error_tree['foo'].errors) == 1, d_error_tree['foo']\\n\", \"    assert d_error_tree['foo'].errors[0].code == errors.SCHEMA.code\\n\", \"    assert 'bar' in d_error_tree['foo']\\n\", \"    assert d_error_tree['foo']['bar'].errors[0].value == 0\\n\", \"    assert d_error_tree.fetch_errors_from(('foo', 'bar'))[0].value == 0\\n\", \"    assert 'foo' in s_error_tree\\n\", \"    assert 'schema' in s_error_tree['foo']\\n\", \"    assert 'bar' in s_error_tree['foo']['schema']\\n\", \"    assert 'type' in s_error_tree['foo']['schema']['bar']\\n\", \"    assert s_error_tree['foo']['schema']['bar']['type'].errors[0].value == 0\\n\", \"        s_error_tree.fetch_errors_from(('foo', 'schema', 'bar', 'type'))[0].value == 0\\n\", \"    schema = {'foo': {'anyof': [{'type': 'string'}, {'type': 'integer'}]}}\\n\", \"    document = {'foo': []}\\n\", '    assert_fail(document, schema, validator=validator)\\n', '    d_error_tree = validator.document_error_tree\\n', '    s_error_tree = validator.schema_error_tree\\n', \"    assert 'foo' in d_error_tree\\n\", \"    assert d_error_tree['foo'].errors[0].value == []\\n\", \"    assert 'foo' in s_error_tree\\n\", \"    assert 'anyof' in s_error_tree['foo']\\n\", \"    assert 0 in s_error_tree['foo']['anyof']\\n\", \"    assert 1 in s_error_tree['foo']['anyof']\\n\", \"    assert 'type' in s_error_tree['foo']['anyof'][0]\\n\", \"    assert s_error_tree['foo']['anyof'][0]['type'].errors[0].value == []\\n\", '    schema = {\\n', '    document = {\\n', '    assert_fail(document, schema, validator=validator)\\n', '    _det = validator.document_error_tree\\n', '    _set = validator.schema_error_tree\\n', '    assert len(_det.errors) == 0\\n', '    assert len(_set.errors) == 0\\n', \"    assert len(_det['a_dict'].errors) == 2\\n\", \"    assert len(_set['a_dict'].errors) == 0\\n\", \"    assert _det['a_dict'][0] is None\\n\", \"    assert len(_det['a_dict']['one'].errors) == 1\\n\", \"    assert len(_det['a_dict'][2].errors) == 1\\n\", \"    assert len(_det['a_dict']['three'].errors) == 2\\n\", \"    assert len(_set['a_dict']['keysrules'].errors) == 1\\n\", \"    assert len(_set['a_dict']['valuesrules'].errors) == 1\\n\", \"    assert len(_set['a_dict']['keysrules']['type'].errors) == 2\\n\", \"    assert len(_set['a_dict']['valuesrules']['regex'].errors) == 2\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['one'].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['keysrules']['type'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict'][2].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['valuesrules']['regex'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['three'].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['keysrules']['type'].errors[1] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['three'].errors[1] == _ref_err\\n\", \"    assert _set['a_dict']['valuesrules']['regex'].errors[1] == _ref_err\\n\", \"    assert len(_det['a_list'].errors) == 1\\n\", \"    assert len(_det['a_list'][0].errors) == 1\\n\", \"    assert _det['a_list'][1] is None\\n\", \"    assert len(_det['a_list'][2].errors) == 3\\n\", \"    assert len(_set['a_list'].errors) == 0\\n\", \"    assert len(_set['a_list']['itemsrules'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['type'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['oneof'][0]['regex'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['oneof'][1]['regex'].errors) == 1\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][0].errors[0] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['type'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[0] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[1] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'][0]['regex'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[2] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'][1]['regex'].errors[0] == _ref_err\\n\", \"    schema = {'foo': {'type': 'dict', 'schema': {'bar': {'type': 'number'}}}}\\n\", \"    document = {'foo': {'bar': 'zero'}}\\n\", '    validator = Validator(schema)\\n', '    validator(document)\\n', \"    assert 'foo' in validator.document_error_tree\\n\", \"    assert 'bar' in validator.document_error_tree['foo']\\n\", \"    assert 'foo' in validator.schema_error_tree\\n\", \"    assert 'schema' in validator.schema_error_tree['foo']\\n\", \"    assert errors.SCHEMA in validator.document_error_tree['foo'].errors\\n\", \"    assert errors.SCHEMA in validator.document_error_tree['foo']\\n\", \"    assert errors.TYPE in validator.document_error_tree['foo']['bar']\\n\", \"    assert errors.SCHEMA in validator.schema_error_tree['foo']['schema']\\n\", \"    assert errors.TYPE in validator.schema_error_tree['foo']['schema']['bar']['type']\\n\", \"        validator.document_error_tree['foo'][errors.SCHEMA].child_errors[0].code\\n\", '    handler = errors.BasicErrorHandler()\\n', '    _errors, ref = [], {}\\n', \"    _errors.append(ValidationError(['foo'], ['foo'], 0x63, 'readonly', True, None, ()))\\n\", \"    ref.update({'foo': [handler.messages[0x63]]})\\n\", '    assert handler(_errors) == ref\\n', \"    _errors.append(ValidationError(['bar'], ['foo'], 0x42, 'min', 1, 2, ()))\\n\", \"    ref.update({'bar': [handler.messages[0x42].format(constraint=1)]})\\n\", '    assert handler(_errors) == ref\\n', '    _errors.append(\\n', '        ValidationError(\\n', \"    ref.update({'zap': [{'foo': [handler.messages[0x24].format(constraint='string')]}]})\\n\", '    assert handler(_errors) == ref\\n', '    _errors.append(\\n', '        ValidationError(\\n', \"    ref['zap'][0]['foo'].append(handler.messages[0x41].format(constraint='^p[e]ng$'))\\n\", '    assert handler(_errors) == ref\\n', \"    schema = {'foo': {'oneof': ({'type': ('integer',)}, {'type': ('string',)})}}\\n\", \"    document = {'foo': 23.42}\\n\", \"    error = ('foo', ('foo', 'oneof'), errors.ONEOF, schema['foo']['oneof'], ())\\n\", \"        (error[0], error[1] + (0, 'type'), errors.TYPE, ('integer',)),\\n\", \"        (error[0], error[1] + (1, 'type'), errors.TYPE, ('string',)),\\n\", '        document, schema, validator=validator, error=error, child_errors=child_errors\\n', '    assert validator.errors == {\\n', '    validator.schema = {\\n', \"    validator({'test_list': ['test']})\\n\", '    assert validator.errors == {\\'test_list\\': [\"length of list should be 2, it is 1\"]}\\n']",
  "context": "]['keysrules']['type'].errors[1] == _ref_err\n\n    _ref_err = ValidationError(\n        ('a_dict', 'three'),\n        ('a_dict', 'v"
 },
 "447": {
  "name": "_ref_err",
  "type": "ValidationError",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_errors.py",
  "lineno": "195",
  "column": "4",
  "slicing": "['ValidationError = errors.ValidationError\\n', \"    v = Validator(schema={'foo': {'type': 'string'}})\\n\", \"    v.document = {'foo': 42}\\n\", \"    v._error('foo', errors.TYPE, 'string')\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'type')\\n\", '    assert error.code == 0x24\\n', \"    assert error.rule == 'type'\\n\", \"    assert error.constraint == ('string',)\\n\", '    assert error.value == 42\\n', \"    assert error.info == ('string',)\\n\", '    assert not error.is_group_error\\n', '    assert not error.is_logic_error\\n', \"    v = Validator(schema={'foo': {'keysrules': {'type': 'integer'}}})\\n\", \"    v.document = {'foo': {'0': 'bar'}}\\n\", \"    v._error('foo', errors.KEYSRULES, ())\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'keysrules')\\n\", '    assert error.code == 0x83\\n', \"    assert error.rule == 'keysrules'\\n\", \"    assert error.constraint == {'type': ('integer',)}\\n\", \"    assert error.value == {'0': 'bar'}\\n\", '    assert error.info == ((),)\\n', '    assert error.is_group_error\\n', '    assert not error.is_logic_error\\n', '    valids = (\\n', \"    v = Validator(schema={'foo': {'oneof': valids}})\\n\", \"    v.document = {'foo': '0x100'}\\n\", \"    v._error('foo', errors.ONEOF, (), 0, 2)\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'oneof')\\n\", '    assert error.code == 0x92\\n', \"    assert error.rule == 'oneof'\\n\", '    assert error.constraint == valids\\n', \"    assert error.value == '0x100'\\n\", '    assert error.info == ((), 0, 2)\\n', '    assert error.is_group_error\\n', '    assert error.is_logic_error\\n', \"    schema = {'foo': {'schema': {'bar': {'type': 'string'}}}}\\n\", \"    document = {'foo': {'bar': 0}}\\n\", '    assert_fail(document, schema, validator=validator)\\n', '    d_error_tree = validator.document_error_tree\\n', '    s_error_tree = validator.schema_error_tree\\n', \"    assert 'foo' in d_error_tree\\n\", \"    assert len(d_error_tree['foo'].errors) == 1, d_error_tree['foo']\\n\", \"    assert d_error_tree['foo'].errors[0].code == errors.SCHEMA.code\\n\", \"    assert 'bar' in d_error_tree['foo']\\n\", \"    assert d_error_tree['foo']['bar'].errors[0].value == 0\\n\", \"    assert d_error_tree.fetch_errors_from(('foo', 'bar'))[0].value == 0\\n\", \"    assert 'foo' in s_error_tree\\n\", \"    assert 'schema' in s_error_tree['foo']\\n\", \"    assert 'bar' in s_error_tree['foo']['schema']\\n\", \"    assert 'type' in s_error_tree['foo']['schema']['bar']\\n\", \"    assert s_error_tree['foo']['schema']['bar']['type'].errors[0].value == 0\\n\", \"        s_error_tree.fetch_errors_from(('foo', 'schema', 'bar', 'type'))[0].value == 0\\n\", \"    schema = {'foo': {'anyof': [{'type': 'string'}, {'type': 'integer'}]}}\\n\", \"    document = {'foo': []}\\n\", '    assert_fail(document, schema, validator=validator)\\n', '    d_error_tree = validator.document_error_tree\\n', '    s_error_tree = validator.schema_error_tree\\n', \"    assert 'foo' in d_error_tree\\n\", \"    assert d_error_tree['foo'].errors[0].value == []\\n\", \"    assert 'foo' in s_error_tree\\n\", \"    assert 'anyof' in s_error_tree['foo']\\n\", \"    assert 0 in s_error_tree['foo']['anyof']\\n\", \"    assert 1 in s_error_tree['foo']['anyof']\\n\", \"    assert 'type' in s_error_tree['foo']['anyof'][0]\\n\", \"    assert s_error_tree['foo']['anyof'][0]['type'].errors[0].value == []\\n\", '    schema = {\\n', '    document = {\\n', '    assert_fail(document, schema, validator=validator)\\n', '    _det = validator.document_error_tree\\n', '    _set = validator.schema_error_tree\\n', '    assert len(_det.errors) == 0\\n', '    assert len(_set.errors) == 0\\n', \"    assert len(_det['a_dict'].errors) == 2\\n\", \"    assert len(_set['a_dict'].errors) == 0\\n\", \"    assert _det['a_dict'][0] is None\\n\", \"    assert len(_det['a_dict']['one'].errors) == 1\\n\", \"    assert len(_det['a_dict'][2].errors) == 1\\n\", \"    assert len(_det['a_dict']['three'].errors) == 2\\n\", \"    assert len(_set['a_dict']['keysrules'].errors) == 1\\n\", \"    assert len(_set['a_dict']['valuesrules'].errors) == 1\\n\", \"    assert len(_set['a_dict']['keysrules']['type'].errors) == 2\\n\", \"    assert len(_set['a_dict']['valuesrules']['regex'].errors) == 2\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['one'].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['keysrules']['type'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict'][2].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['valuesrules']['regex'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['three'].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['keysrules']['type'].errors[1] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['three'].errors[1] == _ref_err\\n\", \"    assert _set['a_dict']['valuesrules']['regex'].errors[1] == _ref_err\\n\", \"    assert len(_det['a_list'].errors) == 1\\n\", \"    assert len(_det['a_list'][0].errors) == 1\\n\", \"    assert _det['a_list'][1] is None\\n\", \"    assert len(_det['a_list'][2].errors) == 3\\n\", \"    assert len(_set['a_list'].errors) == 0\\n\", \"    assert len(_set['a_list']['itemsrules'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['type'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['oneof'][0]['regex'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['oneof'][1]['regex'].errors) == 1\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][0].errors[0] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['type'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[0] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[1] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'][0]['regex'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[2] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'][1]['regex'].errors[0] == _ref_err\\n\", \"    schema = {'foo': {'type': 'dict', 'schema': {'bar': {'type': 'number'}}}}\\n\", \"    document = {'foo': {'bar': 'zero'}}\\n\", '    validator = Validator(schema)\\n', '    validator(document)\\n', \"    assert 'foo' in validator.document_error_tree\\n\", \"    assert 'bar' in validator.document_error_tree['foo']\\n\", \"    assert 'foo' in validator.schema_error_tree\\n\", \"    assert 'schema' in validator.schema_error_tree['foo']\\n\", \"    assert errors.SCHEMA in validator.document_error_tree['foo'].errors\\n\", \"    assert errors.SCHEMA in validator.document_error_tree['foo']\\n\", \"    assert errors.TYPE in validator.document_error_tree['foo']['bar']\\n\", \"    assert errors.SCHEMA in validator.schema_error_tree['foo']['schema']\\n\", \"    assert errors.TYPE in validator.schema_error_tree['foo']['schema']['bar']['type']\\n\", \"        validator.document_error_tree['foo'][errors.SCHEMA].child_errors[0].code\\n\", '    handler = errors.BasicErrorHandler()\\n', '    _errors, ref = [], {}\\n', \"    _errors.append(ValidationError(['foo'], ['foo'], 0x63, 'readonly', True, None, ()))\\n\", \"    ref.update({'foo': [handler.messages[0x63]]})\\n\", '    assert handler(_errors) == ref\\n', \"    _errors.append(ValidationError(['bar'], ['foo'], 0x42, 'min', 1, 2, ()))\\n\", \"    ref.update({'bar': [handler.messages[0x42].format(constraint=1)]})\\n\", '    assert handler(_errors) == ref\\n', '    _errors.append(\\n', '        ValidationError(\\n', \"    ref.update({'zap': [{'foo': [handler.messages[0x24].format(constraint='string')]}]})\\n\", '    assert handler(_errors) == ref\\n', '    _errors.append(\\n', '        ValidationError(\\n', \"    ref['zap'][0]['foo'].append(handler.messages[0x41].format(constraint='^p[e]ng$'))\\n\", '    assert handler(_errors) == ref\\n', \"    schema = {'foo': {'oneof': ({'type': ('integer',)}, {'type': ('string',)})}}\\n\", \"    document = {'foo': 23.42}\\n\", \"    error = ('foo', ('foo', 'oneof'), errors.ONEOF, schema['foo']['oneof'], ())\\n\", \"        (error[0], error[1] + (0, 'type'), errors.TYPE, ('integer',)),\\n\", \"        (error[0], error[1] + (1, 'type'), errors.TYPE, ('string',)),\\n\", '        document, schema, validator=validator, error=error, child_errors=child_errors\\n', '    assert validator.errors == {\\n', '    validator.schema = {\\n', \"    validator({'test_list': ['test']})\\n\", '    assert validator.errors == {\\'test_list\\': [\"length of list should be 2, it is 1\"]}\\n']",
  "context": "emsrules']['oneof'][1]['regex'].errors) == 1\n\n    _ref_err = ValidationError(\n        ('a_list', 0),\n        ('a_list', 'itemsru"
 },
 "448": {
  "name": "_ref_err",
  "type": "ValidationError",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_errors.py",
  "lineno": "207",
  "column": "4",
  "slicing": "['ValidationError = errors.ValidationError\\n', \"    v = Validator(schema={'foo': {'type': 'string'}})\\n\", \"    v.document = {'foo': 42}\\n\", \"    v._error('foo', errors.TYPE, 'string')\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'type')\\n\", '    assert error.code == 0x24\\n', \"    assert error.rule == 'type'\\n\", \"    assert error.constraint == ('string',)\\n\", '    assert error.value == 42\\n', \"    assert error.info == ('string',)\\n\", '    assert not error.is_group_error\\n', '    assert not error.is_logic_error\\n', \"    v = Validator(schema={'foo': {'keysrules': {'type': 'integer'}}})\\n\", \"    v.document = {'foo': {'0': 'bar'}}\\n\", \"    v._error('foo', errors.KEYSRULES, ())\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'keysrules')\\n\", '    assert error.code == 0x83\\n', \"    assert error.rule == 'keysrules'\\n\", \"    assert error.constraint == {'type': ('integer',)}\\n\", \"    assert error.value == {'0': 'bar'}\\n\", '    assert error.info == ((),)\\n', '    assert error.is_group_error\\n', '    assert not error.is_logic_error\\n', '    valids = (\\n', \"    v = Validator(schema={'foo': {'oneof': valids}})\\n\", \"    v.document = {'foo': '0x100'}\\n\", \"    v._error('foo', errors.ONEOF, (), 0, 2)\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'oneof')\\n\", '    assert error.code == 0x92\\n', \"    assert error.rule == 'oneof'\\n\", '    assert error.constraint == valids\\n', \"    assert error.value == '0x100'\\n\", '    assert error.info == ((), 0, 2)\\n', '    assert error.is_group_error\\n', '    assert error.is_logic_error\\n', \"    schema = {'foo': {'schema': {'bar': {'type': 'string'}}}}\\n\", \"    document = {'foo': {'bar': 0}}\\n\", '    assert_fail(document, schema, validator=validator)\\n', '    d_error_tree = validator.document_error_tree\\n', '    s_error_tree = validator.schema_error_tree\\n', \"    assert 'foo' in d_error_tree\\n\", \"    assert len(d_error_tree['foo'].errors) == 1, d_error_tree['foo']\\n\", \"    assert d_error_tree['foo'].errors[0].code == errors.SCHEMA.code\\n\", \"    assert 'bar' in d_error_tree['foo']\\n\", \"    assert d_error_tree['foo']['bar'].errors[0].value == 0\\n\", \"    assert d_error_tree.fetch_errors_from(('foo', 'bar'))[0].value == 0\\n\", \"    assert 'foo' in s_error_tree\\n\", \"    assert 'schema' in s_error_tree['foo']\\n\", \"    assert 'bar' in s_error_tree['foo']['schema']\\n\", \"    assert 'type' in s_error_tree['foo']['schema']['bar']\\n\", \"    assert s_error_tree['foo']['schema']['bar']['type'].errors[0].value == 0\\n\", \"        s_error_tree.fetch_errors_from(('foo', 'schema', 'bar', 'type'))[0].value == 0\\n\", \"    schema = {'foo': {'anyof': [{'type': 'string'}, {'type': 'integer'}]}}\\n\", \"    document = {'foo': []}\\n\", '    assert_fail(document, schema, validator=validator)\\n', '    d_error_tree = validator.document_error_tree\\n', '    s_error_tree = validator.schema_error_tree\\n', \"    assert 'foo' in d_error_tree\\n\", \"    assert d_error_tree['foo'].errors[0].value == []\\n\", \"    assert 'foo' in s_error_tree\\n\", \"    assert 'anyof' in s_error_tree['foo']\\n\", \"    assert 0 in s_error_tree['foo']['anyof']\\n\", \"    assert 1 in s_error_tree['foo']['anyof']\\n\", \"    assert 'type' in s_error_tree['foo']['anyof'][0]\\n\", \"    assert s_error_tree['foo']['anyof'][0]['type'].errors[0].value == []\\n\", '    schema = {\\n', '    document = {\\n', '    assert_fail(document, schema, validator=validator)\\n', '    _det = validator.document_error_tree\\n', '    _set = validator.schema_error_tree\\n', '    assert len(_det.errors) == 0\\n', '    assert len(_set.errors) == 0\\n', \"    assert len(_det['a_dict'].errors) == 2\\n\", \"    assert len(_set['a_dict'].errors) == 0\\n\", \"    assert _det['a_dict'][0] is None\\n\", \"    assert len(_det['a_dict']['one'].errors) == 1\\n\", \"    assert len(_det['a_dict'][2].errors) == 1\\n\", \"    assert len(_det['a_dict']['three'].errors) == 2\\n\", \"    assert len(_set['a_dict']['keysrules'].errors) == 1\\n\", \"    assert len(_set['a_dict']['valuesrules'].errors) == 1\\n\", \"    assert len(_set['a_dict']['keysrules']['type'].errors) == 2\\n\", \"    assert len(_set['a_dict']['valuesrules']['regex'].errors) == 2\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['one'].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['keysrules']['type'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict'][2].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['valuesrules']['regex'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['three'].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['keysrules']['type'].errors[1] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['three'].errors[1] == _ref_err\\n\", \"    assert _set['a_dict']['valuesrules']['regex'].errors[1] == _ref_err\\n\", \"    assert len(_det['a_list'].errors) == 1\\n\", \"    assert len(_det['a_list'][0].errors) == 1\\n\", \"    assert _det['a_list'][1] is None\\n\", \"    assert len(_det['a_list'][2].errors) == 3\\n\", \"    assert len(_set['a_list'].errors) == 0\\n\", \"    assert len(_set['a_list']['itemsrules'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['type'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['oneof'][0]['regex'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['oneof'][1]['regex'].errors) == 1\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][0].errors[0] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['type'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[0] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[1] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'][0]['regex'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[2] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'][1]['regex'].errors[0] == _ref_err\\n\", \"    schema = {'foo': {'type': 'dict', 'schema': {'bar': {'type': 'number'}}}}\\n\", \"    document = {'foo': {'bar': 'zero'}}\\n\", '    validator = Validator(schema)\\n', '    validator(document)\\n', \"    assert 'foo' in validator.document_error_tree\\n\", \"    assert 'bar' in validator.document_error_tree['foo']\\n\", \"    assert 'foo' in validator.schema_error_tree\\n\", \"    assert 'schema' in validator.schema_error_tree['foo']\\n\", \"    assert errors.SCHEMA in validator.document_error_tree['foo'].errors\\n\", \"    assert errors.SCHEMA in validator.document_error_tree['foo']\\n\", \"    assert errors.TYPE in validator.document_error_tree['foo']['bar']\\n\", \"    assert errors.SCHEMA in validator.schema_error_tree['foo']['schema']\\n\", \"    assert errors.TYPE in validator.schema_error_tree['foo']['schema']['bar']['type']\\n\", \"        validator.document_error_tree['foo'][errors.SCHEMA].child_errors[0].code\\n\", '    handler = errors.BasicErrorHandler()\\n', '    _errors, ref = [], {}\\n', \"    _errors.append(ValidationError(['foo'], ['foo'], 0x63, 'readonly', True, None, ()))\\n\", \"    ref.update({'foo': [handler.messages[0x63]]})\\n\", '    assert handler(_errors) == ref\\n', \"    _errors.append(ValidationError(['bar'], ['foo'], 0x42, 'min', 1, 2, ()))\\n\", \"    ref.update({'bar': [handler.messages[0x42].format(constraint=1)]})\\n\", '    assert handler(_errors) == ref\\n', '    _errors.append(\\n', '        ValidationError(\\n', \"    ref.update({'zap': [{'foo': [handler.messages[0x24].format(constraint='string')]}]})\\n\", '    assert handler(_errors) == ref\\n', '    _errors.append(\\n', '        ValidationError(\\n', \"    ref['zap'][0]['foo'].append(handler.messages[0x41].format(constraint='^p[e]ng$'))\\n\", '    assert handler(_errors) == ref\\n', \"    schema = {'foo': {'oneof': ({'type': ('integer',)}, {'type': ('string',)})}}\\n\", \"    document = {'foo': 23.42}\\n\", \"    error = ('foo', ('foo', 'oneof'), errors.ONEOF, schema['foo']['oneof'], ())\\n\", \"        (error[0], error[1] + (0, 'type'), errors.TYPE, ('integer',)),\\n\", \"        (error[0], error[1] + (1, 'type'), errors.TYPE, ('string',)),\\n\", '        document, schema, validator=validator, error=error, child_errors=child_errors\\n', '    assert validator.errors == {\\n', '    validator.schema = {\\n', \"    validator({'test_list': ['test']})\\n\", '    assert validator.errors == {\\'test_list\\': [\"length of list should be 2, it is 1\"]}\\n']",
  "context": "['itemsrules']['type'].errors[0] == _ref_err\n\n    _ref_err = ValidationError(\n        ('a_list', 2),\n        ('a_list', 'itemsru"
 },
 "449": {
  "name": "_ref_err",
  "type": "ValidationError",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_errors.py",
  "lineno": "219",
  "column": "4",
  "slicing": "['ValidationError = errors.ValidationError\\n', \"    v = Validator(schema={'foo': {'type': 'string'}})\\n\", \"    v.document = {'foo': 42}\\n\", \"    v._error('foo', errors.TYPE, 'string')\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'type')\\n\", '    assert error.code == 0x24\\n', \"    assert error.rule == 'type'\\n\", \"    assert error.constraint == ('string',)\\n\", '    assert error.value == 42\\n', \"    assert error.info == ('string',)\\n\", '    assert not error.is_group_error\\n', '    assert not error.is_logic_error\\n', \"    v = Validator(schema={'foo': {'keysrules': {'type': 'integer'}}})\\n\", \"    v.document = {'foo': {'0': 'bar'}}\\n\", \"    v._error('foo', errors.KEYSRULES, ())\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'keysrules')\\n\", '    assert error.code == 0x83\\n', \"    assert error.rule == 'keysrules'\\n\", \"    assert error.constraint == {'type': ('integer',)}\\n\", \"    assert error.value == {'0': 'bar'}\\n\", '    assert error.info == ((),)\\n', '    assert error.is_group_error\\n', '    assert not error.is_logic_error\\n', '    valids = (\\n', \"    v = Validator(schema={'foo': {'oneof': valids}})\\n\", \"    v.document = {'foo': '0x100'}\\n\", \"    v._error('foo', errors.ONEOF, (), 0, 2)\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'oneof')\\n\", '    assert error.code == 0x92\\n', \"    assert error.rule == 'oneof'\\n\", '    assert error.constraint == valids\\n', \"    assert error.value == '0x100'\\n\", '    assert error.info == ((), 0, 2)\\n', '    assert error.is_group_error\\n', '    assert error.is_logic_error\\n', \"    schema = {'foo': {'schema': {'bar': {'type': 'string'}}}}\\n\", \"    document = {'foo': {'bar': 0}}\\n\", '    assert_fail(document, schema, validator=validator)\\n', '    d_error_tree = validator.document_error_tree\\n', '    s_error_tree = validator.schema_error_tree\\n', \"    assert 'foo' in d_error_tree\\n\", \"    assert len(d_error_tree['foo'].errors) == 1, d_error_tree['foo']\\n\", \"    assert d_error_tree['foo'].errors[0].code == errors.SCHEMA.code\\n\", \"    assert 'bar' in d_error_tree['foo']\\n\", \"    assert d_error_tree['foo']['bar'].errors[0].value == 0\\n\", \"    assert d_error_tree.fetch_errors_from(('foo', 'bar'))[0].value == 0\\n\", \"    assert 'foo' in s_error_tree\\n\", \"    assert 'schema' in s_error_tree['foo']\\n\", \"    assert 'bar' in s_error_tree['foo']['schema']\\n\", \"    assert 'type' in s_error_tree['foo']['schema']['bar']\\n\", \"    assert s_error_tree['foo']['schema']['bar']['type'].errors[0].value == 0\\n\", \"        s_error_tree.fetch_errors_from(('foo', 'schema', 'bar', 'type'))[0].value == 0\\n\", \"    schema = {'foo': {'anyof': [{'type': 'string'}, {'type': 'integer'}]}}\\n\", \"    document = {'foo': []}\\n\", '    assert_fail(document, schema, validator=validator)\\n', '    d_error_tree = validator.document_error_tree\\n', '    s_error_tree = validator.schema_error_tree\\n', \"    assert 'foo' in d_error_tree\\n\", \"    assert d_error_tree['foo'].errors[0].value == []\\n\", \"    assert 'foo' in s_error_tree\\n\", \"    assert 'anyof' in s_error_tree['foo']\\n\", \"    assert 0 in s_error_tree['foo']['anyof']\\n\", \"    assert 1 in s_error_tree['foo']['anyof']\\n\", \"    assert 'type' in s_error_tree['foo']['anyof'][0]\\n\", \"    assert s_error_tree['foo']['anyof'][0]['type'].errors[0].value == []\\n\", '    schema = {\\n', '    document = {\\n', '    assert_fail(document, schema, validator=validator)\\n', '    _det = validator.document_error_tree\\n', '    _set = validator.schema_error_tree\\n', '    assert len(_det.errors) == 0\\n', '    assert len(_set.errors) == 0\\n', \"    assert len(_det['a_dict'].errors) == 2\\n\", \"    assert len(_set['a_dict'].errors) == 0\\n\", \"    assert _det['a_dict'][0] is None\\n\", \"    assert len(_det['a_dict']['one'].errors) == 1\\n\", \"    assert len(_det['a_dict'][2].errors) == 1\\n\", \"    assert len(_det['a_dict']['three'].errors) == 2\\n\", \"    assert len(_set['a_dict']['keysrules'].errors) == 1\\n\", \"    assert len(_set['a_dict']['valuesrules'].errors) == 1\\n\", \"    assert len(_set['a_dict']['keysrules']['type'].errors) == 2\\n\", \"    assert len(_set['a_dict']['valuesrules']['regex'].errors) == 2\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['one'].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['keysrules']['type'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict'][2].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['valuesrules']['regex'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['three'].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['keysrules']['type'].errors[1] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['three'].errors[1] == _ref_err\\n\", \"    assert _set['a_dict']['valuesrules']['regex'].errors[1] == _ref_err\\n\", \"    assert len(_det['a_list'].errors) == 1\\n\", \"    assert len(_det['a_list'][0].errors) == 1\\n\", \"    assert _det['a_list'][1] is None\\n\", \"    assert len(_det['a_list'][2].errors) == 3\\n\", \"    assert len(_set['a_list'].errors) == 0\\n\", \"    assert len(_set['a_list']['itemsrules'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['type'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['oneof'][0]['regex'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['oneof'][1]['regex'].errors) == 1\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][0].errors[0] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['type'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[0] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[1] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'][0]['regex'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[2] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'][1]['regex'].errors[0] == _ref_err\\n\", \"    schema = {'foo': {'type': 'dict', 'schema': {'bar': {'type': 'number'}}}}\\n\", \"    document = {'foo': {'bar': 'zero'}}\\n\", '    validator = Validator(schema)\\n', '    validator(document)\\n', \"    assert 'foo' in validator.document_error_tree\\n\", \"    assert 'bar' in validator.document_error_tree['foo']\\n\", \"    assert 'foo' in validator.schema_error_tree\\n\", \"    assert 'schema' in validator.schema_error_tree['foo']\\n\", \"    assert errors.SCHEMA in validator.document_error_tree['foo'].errors\\n\", \"    assert errors.SCHEMA in validator.document_error_tree['foo']\\n\", \"    assert errors.TYPE in validator.document_error_tree['foo']['bar']\\n\", \"    assert errors.SCHEMA in validator.schema_error_tree['foo']['schema']\\n\", \"    assert errors.TYPE in validator.schema_error_tree['foo']['schema']['bar']['type']\\n\", \"        validator.document_error_tree['foo'][errors.SCHEMA].child_errors[0].code\\n\", '    handler = errors.BasicErrorHandler()\\n', '    _errors, ref = [], {}\\n', \"    _errors.append(ValidationError(['foo'], ['foo'], 0x63, 'readonly', True, None, ()))\\n\", \"    ref.update({'foo': [handler.messages[0x63]]})\\n\", '    assert handler(_errors) == ref\\n', \"    _errors.append(ValidationError(['bar'], ['foo'], 0x42, 'min', 1, 2, ()))\\n\", \"    ref.update({'bar': [handler.messages[0x42].format(constraint=1)]})\\n\", '    assert handler(_errors) == ref\\n', '    _errors.append(\\n', '        ValidationError(\\n', \"    ref.update({'zap': [{'foo': [handler.messages[0x24].format(constraint='string')]}]})\\n\", '    assert handler(_errors) == ref\\n', '    _errors.append(\\n', '        ValidationError(\\n', \"    ref['zap'][0]['foo'].append(handler.messages[0x41].format(constraint='^p[e]ng$'))\\n\", '    assert handler(_errors) == ref\\n', \"    schema = {'foo': {'oneof': ({'type': ('integer',)}, {'type': ('string',)})}}\\n\", \"    document = {'foo': 23.42}\\n\", \"    error = ('foo', ('foo', 'oneof'), errors.ONEOF, schema['foo']['oneof'], ())\\n\", \"        (error[0], error[1] + (0, 'type'), errors.TYPE, ('integer',)),\\n\", \"        (error[0], error[1] + (1, 'type'), errors.TYPE, ('string',)),\\n\", '        document, schema, validator=validator, error=error, child_errors=child_errors\\n', '    assert validator.errors == {\\n', '    validator.schema = {\\n', \"    validator({'test_list': ['test']})\\n\", '    assert validator.errors == {\\'test_list\\': [\"length of list should be 2, it is 1\"]}\\n']",
  "context": "'itemsrules']['oneof'].errors[0] == _ref_err\n\n    _ref_err = ValidationError(\n        ('a_list', 2),\n        ('a_list', 'itemsru"
 },
 "450": {
  "name": "_ref_err",
  "type": "ValidationError",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_errors.py",
  "lineno": "231",
  "column": "4",
  "slicing": "['ValidationError = errors.ValidationError\\n', \"    v = Validator(schema={'foo': {'type': 'string'}})\\n\", \"    v.document = {'foo': 42}\\n\", \"    v._error('foo', errors.TYPE, 'string')\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'type')\\n\", '    assert error.code == 0x24\\n', \"    assert error.rule == 'type'\\n\", \"    assert error.constraint == ('string',)\\n\", '    assert error.value == 42\\n', \"    assert error.info == ('string',)\\n\", '    assert not error.is_group_error\\n', '    assert not error.is_logic_error\\n', \"    v = Validator(schema={'foo': {'keysrules': {'type': 'integer'}}})\\n\", \"    v.document = {'foo': {'0': 'bar'}}\\n\", \"    v._error('foo', errors.KEYSRULES, ())\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'keysrules')\\n\", '    assert error.code == 0x83\\n', \"    assert error.rule == 'keysrules'\\n\", \"    assert error.constraint == {'type': ('integer',)}\\n\", \"    assert error.value == {'0': 'bar'}\\n\", '    assert error.info == ((),)\\n', '    assert error.is_group_error\\n', '    assert not error.is_logic_error\\n', '    valids = (\\n', \"    v = Validator(schema={'foo': {'oneof': valids}})\\n\", \"    v.document = {'foo': '0x100'}\\n\", \"    v._error('foo', errors.ONEOF, (), 0, 2)\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'oneof')\\n\", '    assert error.code == 0x92\\n', \"    assert error.rule == 'oneof'\\n\", '    assert error.constraint == valids\\n', \"    assert error.value == '0x100'\\n\", '    assert error.info == ((), 0, 2)\\n', '    assert error.is_group_error\\n', '    assert error.is_logic_error\\n', \"    schema = {'foo': {'schema': {'bar': {'type': 'string'}}}}\\n\", \"    document = {'foo': {'bar': 0}}\\n\", '    assert_fail(document, schema, validator=validator)\\n', '    d_error_tree = validator.document_error_tree\\n', '    s_error_tree = validator.schema_error_tree\\n', \"    assert 'foo' in d_error_tree\\n\", \"    assert len(d_error_tree['foo'].errors) == 1, d_error_tree['foo']\\n\", \"    assert d_error_tree['foo'].errors[0].code == errors.SCHEMA.code\\n\", \"    assert 'bar' in d_error_tree['foo']\\n\", \"    assert d_error_tree['foo']['bar'].errors[0].value == 0\\n\", \"    assert d_error_tree.fetch_errors_from(('foo', 'bar'))[0].value == 0\\n\", \"    assert 'foo' in s_error_tree\\n\", \"    assert 'schema' in s_error_tree['foo']\\n\", \"    assert 'bar' in s_error_tree['foo']['schema']\\n\", \"    assert 'type' in s_error_tree['foo']['schema']['bar']\\n\", \"    assert s_error_tree['foo']['schema']['bar']['type'].errors[0].value == 0\\n\", \"        s_error_tree.fetch_errors_from(('foo', 'schema', 'bar', 'type'))[0].value == 0\\n\", \"    schema = {'foo': {'anyof': [{'type': 'string'}, {'type': 'integer'}]}}\\n\", \"    document = {'foo': []}\\n\", '    assert_fail(document, schema, validator=validator)\\n', '    d_error_tree = validator.document_error_tree\\n', '    s_error_tree = validator.schema_error_tree\\n', \"    assert 'foo' in d_error_tree\\n\", \"    assert d_error_tree['foo'].errors[0].value == []\\n\", \"    assert 'foo' in s_error_tree\\n\", \"    assert 'anyof' in s_error_tree['foo']\\n\", \"    assert 0 in s_error_tree['foo']['anyof']\\n\", \"    assert 1 in s_error_tree['foo']['anyof']\\n\", \"    assert 'type' in s_error_tree['foo']['anyof'][0]\\n\", \"    assert s_error_tree['foo']['anyof'][0]['type'].errors[0].value == []\\n\", '    schema = {\\n', '    document = {\\n', '    assert_fail(document, schema, validator=validator)\\n', '    _det = validator.document_error_tree\\n', '    _set = validator.schema_error_tree\\n', '    assert len(_det.errors) == 0\\n', '    assert len(_set.errors) == 0\\n', \"    assert len(_det['a_dict'].errors) == 2\\n\", \"    assert len(_set['a_dict'].errors) == 0\\n\", \"    assert _det['a_dict'][0] is None\\n\", \"    assert len(_det['a_dict']['one'].errors) == 1\\n\", \"    assert len(_det['a_dict'][2].errors) == 1\\n\", \"    assert len(_det['a_dict']['three'].errors) == 2\\n\", \"    assert len(_set['a_dict']['keysrules'].errors) == 1\\n\", \"    assert len(_set['a_dict']['valuesrules'].errors) == 1\\n\", \"    assert len(_set['a_dict']['keysrules']['type'].errors) == 2\\n\", \"    assert len(_set['a_dict']['valuesrules']['regex'].errors) == 2\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['one'].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['keysrules']['type'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict'][2].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['valuesrules']['regex'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['three'].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['keysrules']['type'].errors[1] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['three'].errors[1] == _ref_err\\n\", \"    assert _set['a_dict']['valuesrules']['regex'].errors[1] == _ref_err\\n\", \"    assert len(_det['a_list'].errors) == 1\\n\", \"    assert len(_det['a_list'][0].errors) == 1\\n\", \"    assert _det['a_list'][1] is None\\n\", \"    assert len(_det['a_list'][2].errors) == 3\\n\", \"    assert len(_set['a_list'].errors) == 0\\n\", \"    assert len(_set['a_list']['itemsrules'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['type'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['oneof'][0]['regex'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['oneof'][1]['regex'].errors) == 1\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][0].errors[0] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['type'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[0] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[1] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'][0]['regex'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[2] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'][1]['regex'].errors[0] == _ref_err\\n\", \"    schema = {'foo': {'type': 'dict', 'schema': {'bar': {'type': 'number'}}}}\\n\", \"    document = {'foo': {'bar': 'zero'}}\\n\", '    validator = Validator(schema)\\n', '    validator(document)\\n', \"    assert 'foo' in validator.document_error_tree\\n\", \"    assert 'bar' in validator.document_error_tree['foo']\\n\", \"    assert 'foo' in validator.schema_error_tree\\n\", \"    assert 'schema' in validator.schema_error_tree['foo']\\n\", \"    assert errors.SCHEMA in validator.document_error_tree['foo'].errors\\n\", \"    assert errors.SCHEMA in validator.document_error_tree['foo']\\n\", \"    assert errors.TYPE in validator.document_error_tree['foo']['bar']\\n\", \"    assert errors.SCHEMA in validator.schema_error_tree['foo']['schema']\\n\", \"    assert errors.TYPE in validator.schema_error_tree['foo']['schema']['bar']['type']\\n\", \"        validator.document_error_tree['foo'][errors.SCHEMA].child_errors[0].code\\n\", '    handler = errors.BasicErrorHandler()\\n', '    _errors, ref = [], {}\\n', \"    _errors.append(ValidationError(['foo'], ['foo'], 0x63, 'readonly', True, None, ()))\\n\", \"    ref.update({'foo': [handler.messages[0x63]]})\\n\", '    assert handler(_errors) == ref\\n', \"    _errors.append(ValidationError(['bar'], ['foo'], 0x42, 'min', 1, 2, ()))\\n\", \"    ref.update({'bar': [handler.messages[0x42].format(constraint=1)]})\\n\", '    assert handler(_errors) == ref\\n', '    _errors.append(\\n', '        ValidationError(\\n', \"    ref.update({'zap': [{'foo': [handler.messages[0x24].format(constraint='string')]}]})\\n\", '    assert handler(_errors) == ref\\n', '    _errors.append(\\n', '        ValidationError(\\n', \"    ref['zap'][0]['foo'].append(handler.messages[0x41].format(constraint='^p[e]ng$'))\\n\", '    assert handler(_errors) == ref\\n', \"    schema = {'foo': {'oneof': ({'type': ('integer',)}, {'type': ('string',)})}}\\n\", \"    document = {'foo': 23.42}\\n\", \"    error = ('foo', ('foo', 'oneof'), errors.ONEOF, schema['foo']['oneof'], ())\\n\", \"        (error[0], error[1] + (0, 'type'), errors.TYPE, ('integer',)),\\n\", \"        (error[0], error[1] + (1, 'type'), errors.TYPE, ('string',)),\\n\", '        document, schema, validator=validator, error=error, child_errors=child_errors\\n', '    assert validator.errors == {\\n', '    validator.schema = {\\n', \"    validator({'test_list': ['test']})\\n\", '    assert validator.errors == {\\'test_list\\': [\"length of list should be 2, it is 1\"]}\\n']",
  "context": "]['oneof'][0]['regex'].errors[0] == _ref_err\n\n    _ref_err = ValidationError(\n        ('a_list', 2),\n        ('a_list', 'itemsru"
 },
 "451": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_errors.py",
  "lineno": "245",
  "column": "4",
  "slicing": "['ValidationError = errors.ValidationError\\n', \"    v = Validator(schema={'foo': {'type': 'string'}})\\n\", \"    v.document = {'foo': 42}\\n\", \"    v._error('foo', errors.TYPE, 'string')\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'type')\\n\", '    assert error.code == 0x24\\n', \"    assert error.rule == 'type'\\n\", \"    assert error.constraint == ('string',)\\n\", '    assert error.value == 42\\n', \"    assert error.info == ('string',)\\n\", '    assert not error.is_group_error\\n', '    assert not error.is_logic_error\\n', \"    v = Validator(schema={'foo': {'keysrules': {'type': 'integer'}}})\\n\", \"    v.document = {'foo': {'0': 'bar'}}\\n\", \"    v._error('foo', errors.KEYSRULES, ())\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'keysrules')\\n\", '    assert error.code == 0x83\\n', \"    assert error.rule == 'keysrules'\\n\", \"    assert error.constraint == {'type': ('integer',)}\\n\", \"    assert error.value == {'0': 'bar'}\\n\", '    assert error.info == ((),)\\n', '    assert error.is_group_error\\n', '    assert not error.is_logic_error\\n', '    valids = (\\n', \"    v = Validator(schema={'foo': {'oneof': valids}})\\n\", \"    v.document = {'foo': '0x100'}\\n\", \"    v._error('foo', errors.ONEOF, (), 0, 2)\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'oneof')\\n\", '    assert error.code == 0x92\\n', \"    assert error.rule == 'oneof'\\n\", '    assert error.constraint == valids\\n', \"    assert error.value == '0x100'\\n\", '    assert error.info == ((), 0, 2)\\n', '    assert error.is_group_error\\n', '    assert error.is_logic_error\\n', \"    schema = {'foo': {'schema': {'bar': {'type': 'string'}}}}\\n\", \"    document = {'foo': {'bar': 0}}\\n\", '    assert_fail(document, schema, validator=validator)\\n', '    d_error_tree = validator.document_error_tree\\n', '    s_error_tree = validator.schema_error_tree\\n', \"    assert 'foo' in d_error_tree\\n\", \"    assert len(d_error_tree['foo'].errors) == 1, d_error_tree['foo']\\n\", \"    assert d_error_tree['foo'].errors[0].code == errors.SCHEMA.code\\n\", \"    assert 'bar' in d_error_tree['foo']\\n\", \"    assert d_error_tree['foo']['bar'].errors[0].value == 0\\n\", \"    assert d_error_tree.fetch_errors_from(('foo', 'bar'))[0].value == 0\\n\", \"    assert 'foo' in s_error_tree\\n\", \"    assert 'schema' in s_error_tree['foo']\\n\", \"    assert 'bar' in s_error_tree['foo']['schema']\\n\", \"    assert 'type' in s_error_tree['foo']['schema']['bar']\\n\", \"    assert s_error_tree['foo']['schema']['bar']['type'].errors[0].value == 0\\n\", \"        s_error_tree.fetch_errors_from(('foo', 'schema', 'bar', 'type'))[0].value == 0\\n\", \"    schema = {'foo': {'anyof': [{'type': 'string'}, {'type': 'integer'}]}}\\n\", \"    document = {'foo': []}\\n\", '    assert_fail(document, schema, validator=validator)\\n', '    d_error_tree = validator.document_error_tree\\n', '    s_error_tree = validator.schema_error_tree\\n', \"    assert 'foo' in d_error_tree\\n\", \"    assert d_error_tree['foo'].errors[0].value == []\\n\", \"    assert 'foo' in s_error_tree\\n\", \"    assert 'anyof' in s_error_tree['foo']\\n\", \"    assert 0 in s_error_tree['foo']['anyof']\\n\", \"    assert 1 in s_error_tree['foo']['anyof']\\n\", \"    assert 'type' in s_error_tree['foo']['anyof'][0]\\n\", \"    assert s_error_tree['foo']['anyof'][0]['type'].errors[0].value == []\\n\", '    schema = {\\n', '    document = {\\n', '    assert_fail(document, schema, validator=validator)\\n', '    _det = validator.document_error_tree\\n', '    _set = validator.schema_error_tree\\n', '    assert len(_det.errors) == 0\\n', '    assert len(_set.errors) == 0\\n', \"    assert len(_det['a_dict'].errors) == 2\\n\", \"    assert len(_set['a_dict'].errors) == 0\\n\", \"    assert _det['a_dict'][0] is None\\n\", \"    assert len(_det['a_dict']['one'].errors) == 1\\n\", \"    assert len(_det['a_dict'][2].errors) == 1\\n\", \"    assert len(_det['a_dict']['three'].errors) == 2\\n\", \"    assert len(_set['a_dict']['keysrules'].errors) == 1\\n\", \"    assert len(_set['a_dict']['valuesrules'].errors) == 1\\n\", \"    assert len(_set['a_dict']['keysrules']['type'].errors) == 2\\n\", \"    assert len(_set['a_dict']['valuesrules']['regex'].errors) == 2\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['one'].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['keysrules']['type'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict'][2].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['valuesrules']['regex'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['three'].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['keysrules']['type'].errors[1] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['three'].errors[1] == _ref_err\\n\", \"    assert _set['a_dict']['valuesrules']['regex'].errors[1] == _ref_err\\n\", \"    assert len(_det['a_list'].errors) == 1\\n\", \"    assert len(_det['a_list'][0].errors) == 1\\n\", \"    assert _det['a_list'][1] is None\\n\", \"    assert len(_det['a_list'][2].errors) == 3\\n\", \"    assert len(_set['a_list'].errors) == 0\\n\", \"    assert len(_set['a_list']['itemsrules'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['type'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['oneof'][0]['regex'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['oneof'][1]['regex'].errors) == 1\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][0].errors[0] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['type'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[0] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[1] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'][0]['regex'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[2] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'][1]['regex'].errors[0] == _ref_err\\n\", \"    schema = {'foo': {'type': 'dict', 'schema': {'bar': {'type': 'number'}}}}\\n\", \"    document = {'foo': {'bar': 'zero'}}\\n\", '    validator = Validator(schema)\\n', '    validator(document)\\n', \"    assert 'foo' in validator.document_error_tree\\n\", \"    assert 'bar' in validator.document_error_tree['foo']\\n\", \"    assert 'foo' in validator.schema_error_tree\\n\", \"    assert 'schema' in validator.schema_error_tree['foo']\\n\", \"    assert errors.SCHEMA in validator.document_error_tree['foo'].errors\\n\", \"    assert errors.SCHEMA in validator.document_error_tree['foo']\\n\", \"    assert errors.TYPE in validator.document_error_tree['foo']['bar']\\n\", \"    assert errors.SCHEMA in validator.schema_error_tree['foo']['schema']\\n\", \"    assert errors.TYPE in validator.schema_error_tree['foo']['schema']['bar']['type']\\n\", \"        validator.document_error_tree['foo'][errors.SCHEMA].child_errors[0].code\\n\", '    handler = errors.BasicErrorHandler()\\n', '    _errors, ref = [], {}\\n', \"    _errors.append(ValidationError(['foo'], ['foo'], 0x63, 'readonly', True, None, ()))\\n\", \"    ref.update({'foo': [handler.messages[0x63]]})\\n\", '    assert handler(_errors) == ref\\n', \"    _errors.append(ValidationError(['bar'], ['foo'], 0x42, 'min', 1, 2, ()))\\n\", \"    ref.update({'bar': [handler.messages[0x42].format(constraint=1)]})\\n\", '    assert handler(_errors) == ref\\n', '    _errors.append(\\n', '        ValidationError(\\n', \"    ref.update({'zap': [{'foo': [handler.messages[0x24].format(constraint='string')]}]})\\n\", '    assert handler(_errors) == ref\\n', '    _errors.append(\\n', '        ValidationError(\\n', \"    ref['zap'][0]['foo'].append(handler.messages[0x41].format(constraint='^p[e]ng$'))\\n\", '    assert handler(_errors) == ref\\n', \"    schema = {'foo': {'oneof': ({'type': ('integer',)}, {'type': ('string',)})}}\\n\", \"    document = {'foo': 23.42}\\n\", \"    error = ('foo', ('foo', 'oneof'), errors.ONEOF, schema['foo']['oneof'], ())\\n\", \"        (error[0], error[1] + (0, 'type'), errors.TYPE, ('integer',)),\\n\", \"        (error[0], error[1] + (1, 'type'), errors.TYPE, ('string',)),\\n\", '        document, schema, validator=validator, error=error, child_errors=child_errors\\n', '    assert validator.errors == {\\n', '    validator.schema = {\\n', \"    validator({'test_list': ['test']})\\n\", '    assert validator.errors == {\\'test_list\\': [\"length of list should be 2, it is 1\"]}\\n']",
  "context": "].errors[0] == _ref_err\n\n\ndef test_queries():\n    schema = {'foo': {'type': 'dict', 'schema': {'bar': {'type': 'number'}}}}\n    document = {'foo': {'bar': 'zero'}}\n    valida"
 },
 "452": {
  "name": "document",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_errors.py",
  "lineno": "246",
  "column": "4",
  "slicing": "[\"    document = {'foo': {'bar': 'zero'}}\\n\", '    validator(document)\\n', '        document, schema, validator=validator, error=error, child_errors=child_errors\\n']",
  "context": "ict', 'schema': {'bar': {'type': 'number'}}}}\n    document = {'foo': {'bar': 'zero'}}\n    validator = Validator(schema)\n    validator(do"
 },
 "453": {
  "name": "validator",
  "type": "cerberus.Validator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_errors.py",
  "lineno": "247",
  "column": "4",
  "slicing": "['ValidationError = errors.ValidationError\\n', \"    v = Validator(schema={'foo': {'type': 'string'}})\\n\", \"    v.document = {'foo': 42}\\n\", \"    v._error('foo', errors.TYPE, 'string')\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'type')\\n\", '    assert error.code == 0x24\\n', \"    assert error.rule == 'type'\\n\", \"    assert error.constraint == ('string',)\\n\", '    assert error.value == 42\\n', \"    assert error.info == ('string',)\\n\", '    assert not error.is_group_error\\n', '    assert not error.is_logic_error\\n', \"    v = Validator(schema={'foo': {'keysrules': {'type': 'integer'}}})\\n\", \"    v.document = {'foo': {'0': 'bar'}}\\n\", \"    v._error('foo', errors.KEYSRULES, ())\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'keysrules')\\n\", '    assert error.code == 0x83\\n', \"    assert error.rule == 'keysrules'\\n\", \"    assert error.constraint == {'type': ('integer',)}\\n\", \"    assert error.value == {'0': 'bar'}\\n\", '    assert error.info == ((),)\\n', '    assert error.is_group_error\\n', '    assert not error.is_logic_error\\n', '    valids = (\\n', \"    v = Validator(schema={'foo': {'oneof': valids}})\\n\", \"    v.document = {'foo': '0x100'}\\n\", \"    v._error('foo', errors.ONEOF, (), 0, 2)\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'oneof')\\n\", '    assert error.code == 0x92\\n', \"    assert error.rule == 'oneof'\\n\", '    assert error.constraint == valids\\n', \"    assert error.value == '0x100'\\n\", '    assert error.info == ((), 0, 2)\\n', '    assert error.is_group_error\\n', '    assert error.is_logic_error\\n', \"    schema = {'foo': {'schema': {'bar': {'type': 'string'}}}}\\n\", \"    document = {'foo': {'bar': 0}}\\n\", '    assert_fail(document, schema, validator=validator)\\n', '    d_error_tree = validator.document_error_tree\\n', '    s_error_tree = validator.schema_error_tree\\n', \"    assert 'foo' in d_error_tree\\n\", \"    assert len(d_error_tree['foo'].errors) == 1, d_error_tree['foo']\\n\", \"    assert d_error_tree['foo'].errors[0].code == errors.SCHEMA.code\\n\", \"    assert 'bar' in d_error_tree['foo']\\n\", \"    assert d_error_tree['foo']['bar'].errors[0].value == 0\\n\", \"    assert d_error_tree.fetch_errors_from(('foo', 'bar'))[0].value == 0\\n\", \"    assert 'foo' in s_error_tree\\n\", \"    assert 'schema' in s_error_tree['foo']\\n\", \"    assert 'bar' in s_error_tree['foo']['schema']\\n\", \"    assert 'type' in s_error_tree['foo']['schema']['bar']\\n\", \"    assert s_error_tree['foo']['schema']['bar']['type'].errors[0].value == 0\\n\", \"        s_error_tree.fetch_errors_from(('foo', 'schema', 'bar', 'type'))[0].value == 0\\n\", \"    schema = {'foo': {'anyof': [{'type': 'string'}, {'type': 'integer'}]}}\\n\", \"    document = {'foo': []}\\n\", '    assert_fail(document, schema, validator=validator)\\n', '    d_error_tree = validator.document_error_tree\\n', '    s_error_tree = validator.schema_error_tree\\n', \"    assert 'foo' in d_error_tree\\n\", \"    assert d_error_tree['foo'].errors[0].value == []\\n\", \"    assert 'foo' in s_error_tree\\n\", \"    assert 'anyof' in s_error_tree['foo']\\n\", \"    assert 0 in s_error_tree['foo']['anyof']\\n\", \"    assert 1 in s_error_tree['foo']['anyof']\\n\", \"    assert 'type' in s_error_tree['foo']['anyof'][0]\\n\", \"    assert s_error_tree['foo']['anyof'][0]['type'].errors[0].value == []\\n\", '    schema = {\\n', '    document = {\\n', '    assert_fail(document, schema, validator=validator)\\n', '    _det = validator.document_error_tree\\n', '    _set = validator.schema_error_tree\\n', '    assert len(_det.errors) == 0\\n', '    assert len(_set.errors) == 0\\n', \"    assert len(_det['a_dict'].errors) == 2\\n\", \"    assert len(_set['a_dict'].errors) == 0\\n\", \"    assert _det['a_dict'][0] is None\\n\", \"    assert len(_det['a_dict']['one'].errors) == 1\\n\", \"    assert len(_det['a_dict'][2].errors) == 1\\n\", \"    assert len(_det['a_dict']['three'].errors) == 2\\n\", \"    assert len(_set['a_dict']['keysrules'].errors) == 1\\n\", \"    assert len(_set['a_dict']['valuesrules'].errors) == 1\\n\", \"    assert len(_set['a_dict']['keysrules']['type'].errors) == 2\\n\", \"    assert len(_set['a_dict']['valuesrules']['regex'].errors) == 2\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['one'].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['keysrules']['type'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict'][2].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['valuesrules']['regex'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['three'].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['keysrules']['type'].errors[1] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['three'].errors[1] == _ref_err\\n\", \"    assert _set['a_dict']['valuesrules']['regex'].errors[1] == _ref_err\\n\", \"    assert len(_det['a_list'].errors) == 1\\n\", \"    assert len(_det['a_list'][0].errors) == 1\\n\", \"    assert _det['a_list'][1] is None\\n\", \"    assert len(_det['a_list'][2].errors) == 3\\n\", \"    assert len(_set['a_list'].errors) == 0\\n\", \"    assert len(_set['a_list']['itemsrules'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['type'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['oneof'][0]['regex'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['oneof'][1]['regex'].errors) == 1\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][0].errors[0] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['type'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[0] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[1] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'][0]['regex'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[2] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'][1]['regex'].errors[0] == _ref_err\\n\", \"    schema = {'foo': {'type': 'dict', 'schema': {'bar': {'type': 'number'}}}}\\n\", \"    document = {'foo': {'bar': 'zero'}}\\n\", '    validator = Validator(schema)\\n', '    validator(document)\\n', \"    assert 'foo' in validator.document_error_tree\\n\", \"    assert 'bar' in validator.document_error_tree['foo']\\n\", \"    assert 'foo' in validator.schema_error_tree\\n\", \"    assert 'schema' in validator.schema_error_tree['foo']\\n\", \"    assert errors.SCHEMA in validator.document_error_tree['foo'].errors\\n\", \"    assert errors.SCHEMA in validator.document_error_tree['foo']\\n\", \"    assert errors.TYPE in validator.document_error_tree['foo']['bar']\\n\", \"    assert errors.SCHEMA in validator.schema_error_tree['foo']['schema']\\n\", \"    assert errors.TYPE in validator.schema_error_tree['foo']['schema']['bar']['type']\\n\", \"        validator.document_error_tree['foo'][errors.SCHEMA].child_errors[0].code\\n\", '    handler = errors.BasicErrorHandler()\\n', '    _errors, ref = [], {}\\n', \"    _errors.append(ValidationError(['foo'], ['foo'], 0x63, 'readonly', True, None, ()))\\n\", \"    ref.update({'foo': [handler.messages[0x63]]})\\n\", '    assert handler(_errors) == ref\\n', \"    _errors.append(ValidationError(['bar'], ['foo'], 0x42, 'min', 1, 2, ()))\\n\", \"    ref.update({'bar': [handler.messages[0x42].format(constraint=1)]})\\n\", '    assert handler(_errors) == ref\\n', '    _errors.append(\\n', '        ValidationError(\\n', \"    ref.update({'zap': [{'foo': [handler.messages[0x24].format(constraint='string')]}]})\\n\", '    assert handler(_errors) == ref\\n', '    _errors.append(\\n', '        ValidationError(\\n', \"    ref['zap'][0]['foo'].append(handler.messages[0x41].format(constraint='^p[e]ng$'))\\n\", '    assert handler(_errors) == ref\\n', \"    schema = {'foo': {'oneof': ({'type': ('integer',)}, {'type': ('string',)})}}\\n\", \"    document = {'foo': 23.42}\\n\", \"    error = ('foo', ('foo', 'oneof'), errors.ONEOF, schema['foo']['oneof'], ())\\n\", \"        (error[0], error[1] + (0, 'type'), errors.TYPE, ('integer',)),\\n\", \"        (error[0], error[1] + (1, 'type'), errors.TYPE, ('string',)),\\n\", '        document, schema, validator=validator, error=error, child_errors=child_errors\\n', '    assert validator.errors == {\\n', '    validator.schema = {\\n', \"    validator({'test_list': ['test']})\\n\", '    assert validator.errors == {\\'test_list\\': [\"length of list should be 2, it is 1\"]}\\n']",
  "context": "'}}}}\n    document = {'foo': {'bar': 'zero'}}\n    validator = Validator(schema)\n    validator(document)\n\n    assert 'foo' in valid"
 },
 "454": {
  "name": "handler",
  "type": "BasicErrorHandler",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/tests/test_errors.py",
  "lineno": "268",
  "column": "4",
  "slicing": "['ValidationError = errors.ValidationError\\n', \"    v = Validator(schema={'foo': {'type': 'string'}})\\n\", \"    v.document = {'foo': 42}\\n\", \"    v._error('foo', errors.TYPE, 'string')\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'type')\\n\", '    assert error.code == 0x24\\n', \"    assert error.rule == 'type'\\n\", \"    assert error.constraint == ('string',)\\n\", '    assert error.value == 42\\n', \"    assert error.info == ('string',)\\n\", '    assert not error.is_group_error\\n', '    assert not error.is_logic_error\\n', \"    v = Validator(schema={'foo': {'keysrules': {'type': 'integer'}}})\\n\", \"    v.document = {'foo': {'0': 'bar'}}\\n\", \"    v._error('foo', errors.KEYSRULES, ())\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'keysrules')\\n\", '    assert error.code == 0x83\\n', \"    assert error.rule == 'keysrules'\\n\", \"    assert error.constraint == {'type': ('integer',)}\\n\", \"    assert error.value == {'0': 'bar'}\\n\", '    assert error.info == ((),)\\n', '    assert error.is_group_error\\n', '    assert not error.is_logic_error\\n', '    valids = (\\n', \"    v = Validator(schema={'foo': {'oneof': valids}})\\n\", \"    v.document = {'foo': '0x100'}\\n\", \"    v._error('foo', errors.ONEOF, (), 0, 2)\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'oneof')\\n\", '    assert error.code == 0x92\\n', \"    assert error.rule == 'oneof'\\n\", '    assert error.constraint == valids\\n', \"    assert error.value == '0x100'\\n\", '    assert error.info == ((), 0, 2)\\n', '    assert error.is_group_error\\n', '    assert error.is_logic_error\\n', \"    schema = {'foo': {'schema': {'bar': {'type': 'string'}}}}\\n\", \"    document = {'foo': {'bar': 0}}\\n\", '    assert_fail(document, schema, validator=validator)\\n', '    d_error_tree = validator.document_error_tree\\n', '    s_error_tree = validator.schema_error_tree\\n', \"    assert 'foo' in d_error_tree\\n\", \"    assert len(d_error_tree['foo'].errors) == 1, d_error_tree['foo']\\n\", \"    assert d_error_tree['foo'].errors[0].code == errors.SCHEMA.code\\n\", \"    assert 'bar' in d_error_tree['foo']\\n\", \"    assert d_error_tree['foo']['bar'].errors[0].value == 0\\n\", \"    assert d_error_tree.fetch_errors_from(('foo', 'bar'))[0].value == 0\\n\", \"    assert 'foo' in s_error_tree\\n\", \"    assert 'schema' in s_error_tree['foo']\\n\", \"    assert 'bar' in s_error_tree['foo']['schema']\\n\", \"    assert 'type' in s_error_tree['foo']['schema']['bar']\\n\", \"    assert s_error_tree['foo']['schema']['bar']['type'].errors[0].value == 0\\n\", \"        s_error_tree.fetch_errors_from(('foo', 'schema', 'bar', 'type'))[0].value == 0\\n\", \"    schema = {'foo': {'anyof': [{'type': 'string'}, {'type': 'integer'}]}}\\n\", \"    document = {'foo': []}\\n\", '    assert_fail(document, schema, validator=validator)\\n', '    d_error_tree = validator.document_error_tree\\n', '    s_error_tree = validator.schema_error_tree\\n', \"    assert 'foo' in d_error_tree\\n\", \"    assert d_error_tree['foo'].errors[0].value == []\\n\", \"    assert 'foo' in s_error_tree\\n\", \"    assert 'anyof' in s_error_tree['foo']\\n\", \"    assert 0 in s_error_tree['foo']['anyof']\\n\", \"    assert 1 in s_error_tree['foo']['anyof']\\n\", \"    assert 'type' in s_error_tree['foo']['anyof'][0]\\n\", \"    assert s_error_tree['foo']['anyof'][0]['type'].errors[0].value == []\\n\", '    schema = {\\n', '    document = {\\n', '    assert_fail(document, schema, validator=validator)\\n', '    _det = validator.document_error_tree\\n', '    _set = validator.schema_error_tree\\n', '    assert len(_det.errors) == 0\\n', '    assert len(_set.errors) == 0\\n', \"    assert len(_det['a_dict'].errors) == 2\\n\", \"    assert len(_set['a_dict'].errors) == 0\\n\", \"    assert _det['a_dict'][0] is None\\n\", \"    assert len(_det['a_dict']['one'].errors) == 1\\n\", \"    assert len(_det['a_dict'][2].errors) == 1\\n\", \"    assert len(_det['a_dict']['three'].errors) == 2\\n\", \"    assert len(_set['a_dict']['keysrules'].errors) == 1\\n\", \"    assert len(_set['a_dict']['valuesrules'].errors) == 1\\n\", \"    assert len(_set['a_dict']['keysrules']['type'].errors) == 2\\n\", \"    assert len(_set['a_dict']['valuesrules']['regex'].errors) == 2\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['one'].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['keysrules']['type'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict'][2].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['valuesrules']['regex'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['three'].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['keysrules']['type'].errors[1] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['three'].errors[1] == _ref_err\\n\", \"    assert _set['a_dict']['valuesrules']['regex'].errors[1] == _ref_err\\n\", \"    assert len(_det['a_list'].errors) == 1\\n\", \"    assert len(_det['a_list'][0].errors) == 1\\n\", \"    assert _det['a_list'][1] is None\\n\", \"    assert len(_det['a_list'][2].errors) == 3\\n\", \"    assert len(_set['a_list'].errors) == 0\\n\", \"    assert len(_set['a_list']['itemsrules'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['type'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['oneof'][0]['regex'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['oneof'][1]['regex'].errors) == 1\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][0].errors[0] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['type'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[0] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[1] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'][0]['regex'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[2] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'][1]['regex'].errors[0] == _ref_err\\n\", \"    schema = {'foo': {'type': 'dict', 'schema': {'bar': {'type': 'number'}}}}\\n\", \"    document = {'foo': {'bar': 'zero'}}\\n\", '    validator = Validator(schema)\\n', '    validator(document)\\n', \"    assert 'foo' in validator.document_error_tree\\n\", \"    assert 'bar' in validator.document_error_tree['foo']\\n\", \"    assert 'foo' in validator.schema_error_tree\\n\", \"    assert 'schema' in validator.schema_error_tree['foo']\\n\", \"    assert errors.SCHEMA in validator.document_error_tree['foo'].errors\\n\", \"    assert errors.SCHEMA in validator.document_error_tree['foo']\\n\", \"    assert errors.TYPE in validator.document_error_tree['foo']['bar']\\n\", \"    assert errors.SCHEMA in validator.schema_error_tree['foo']['schema']\\n\", \"    assert errors.TYPE in validator.schema_error_tree['foo']['schema']['bar']['type']\\n\", \"        validator.document_error_tree['foo'][errors.SCHEMA].child_errors[0].code\\n\", '    handler = errors.BasicErrorHandler()\\n', '    _errors, ref = [], {}\\n', \"    _errors.append(ValidationError(['foo'], ['foo'], 0x63, 'readonly', True, None, ()))\\n\", \"    ref.update({'foo': [handler.messages[0x63]]})\\n\", '    assert handler(_errors) == ref\\n', \"    _errors.append(ValidationError(['bar'], ['foo'], 0x42, 'min', 1, 2, ()))\\n\", \"    ref.update({'bar': [handler.messages[0x42].format(constraint=1)]})\\n\", '    assert handler(_errors) == ref\\n', '    _errors.append(\\n', '        ValidationError(\\n', \"    ref.update({'zap': [{'foo': [handler.messages[0x24].format(constraint='string')]}]})\\n\", '    assert handler(_errors) == ref\\n', '    _errors.append(\\n', '        ValidationError(\\n', \"    ref['zap'][0]['foo'].append(handler.messages[0x41].format(constraint='^p[e]ng$'))\\n\", '    assert handler(_errors) == ref\\n', \"    schema = {'foo': {'oneof': ({'type': ('integer',)}, {'type': ('string',)})}}\\n\", \"    document = {'foo': 23.42}\\n\", \"    error = ('foo', ('foo', 'oneof'), errors.ONEOF, schema['foo']['oneof'], ())\\n\", \"        (error[0], error[1] + (0, 'type'), errors.TYPE, ('integer',)),\\n\", \"        (error[0], error[1] + (1, 'type'), errors.TYPE, ('string',)),\\n\", '        document, schema, validator=validator, error=error, child_errors=child_errors\\n', '    assert validator.errors == {\\n', '    validator.schema = {\\n', \"    validator({'test_list': ['test']})\\n\", '    assert validator.errors == {\\'test_list\\': [\"length of list should be 2, it is 1\"]}\\n']",
  "context": ".code\n    )\n\n\ndef test_basic_error_handler():\n    handler = errors.BasicErrorHandler()\n    _errors, ref = [], {}\n\n    _errors.append(Vali"
 },
 "455": {
  "name": "_errors",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_errors.py",
  "lineno": "269",
  "column": "4",
  "slicing": "['    _errors, ref = [], {}\\n', \"    _errors.append(ValidationError(['foo'], ['foo'], 0x63, 'readonly', True, None, ()))\\n\", '    assert handler(_errors) == ref\\n', \"    _errors.append(ValidationError(['bar'], ['foo'], 0x42, 'min', 1, 2, ()))\\n\", '    assert handler(_errors) == ref\\n', '    _errors.append(\\n', '    assert handler(_errors) == ref\\n', '    _errors.append(\\n', '    assert handler(_errors) == ref\\n']",
  "context": "r():\n    handler = errors.BasicErrorHandler()\n    _errors, ref = [], {}\n\n    _errors.append(ValidationError(['foo'], ['foo"
 },
 "456": {
  "name": "ref",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_errors.py",
  "lineno": "269",
  "column": "13",
  "slicing": "['    _errors, ref = [], {}\\n', \"    ref.update({'foo': [handler.messages[0x63]]})\\n\", '    assert handler(_errors) == ref\\n', \"    ref.update({'bar': [handler.messages[0x42].format(constraint=1)]})\\n\", '    assert handler(_errors) == ref\\n', \"    ref.update({'zap': [{'foo': [handler.messages[0x24].format(constraint='string')]}]})\\n\", '    assert handler(_errors) == ref\\n', \"    ref['zap'][0]['foo'].append(handler.messages[0x41].format(constraint='^p[e]ng$'))\\n\", '    assert handler(_errors) == ref\\n']",
  "context": "handler = errors.BasicErrorHandler()\n    _errors, ref = [], {}\n\n    _errors.append(ValidationError(['foo'], ['foo"
 },
 "457": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_errors.py",
  "lineno": "303",
  "column": "4",
  "slicing": "['ValidationError = errors.ValidationError\\n', \"    v = Validator(schema={'foo': {'type': 'string'}})\\n\", \"    v.document = {'foo': 42}\\n\", \"    v._error('foo', errors.TYPE, 'string')\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'type')\\n\", '    assert error.code == 0x24\\n', \"    assert error.rule == 'type'\\n\", \"    assert error.constraint == ('string',)\\n\", '    assert error.value == 42\\n', \"    assert error.info == ('string',)\\n\", '    assert not error.is_group_error\\n', '    assert not error.is_logic_error\\n', \"    v = Validator(schema={'foo': {'keysrules': {'type': 'integer'}}})\\n\", \"    v.document = {'foo': {'0': 'bar'}}\\n\", \"    v._error('foo', errors.KEYSRULES, ())\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'keysrules')\\n\", '    assert error.code == 0x83\\n', \"    assert error.rule == 'keysrules'\\n\", \"    assert error.constraint == {'type': ('integer',)}\\n\", \"    assert error.value == {'0': 'bar'}\\n\", '    assert error.info == ((),)\\n', '    assert error.is_group_error\\n', '    assert not error.is_logic_error\\n', '    valids = (\\n', \"    v = Validator(schema={'foo': {'oneof': valids}})\\n\", \"    v.document = {'foo': '0x100'}\\n\", \"    v._error('foo', errors.ONEOF, (), 0, 2)\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'oneof')\\n\", '    assert error.code == 0x92\\n', \"    assert error.rule == 'oneof'\\n\", '    assert error.constraint == valids\\n', \"    assert error.value == '0x100'\\n\", '    assert error.info == ((), 0, 2)\\n', '    assert error.is_group_error\\n', '    assert error.is_logic_error\\n', \"    schema = {'foo': {'schema': {'bar': {'type': 'string'}}}}\\n\", \"    document = {'foo': {'bar': 0}}\\n\", '    assert_fail(document, schema, validator=validator)\\n', '    d_error_tree = validator.document_error_tree\\n', '    s_error_tree = validator.schema_error_tree\\n', \"    assert 'foo' in d_error_tree\\n\", \"    assert len(d_error_tree['foo'].errors) == 1, d_error_tree['foo']\\n\", \"    assert d_error_tree['foo'].errors[0].code == errors.SCHEMA.code\\n\", \"    assert 'bar' in d_error_tree['foo']\\n\", \"    assert d_error_tree['foo']['bar'].errors[0].value == 0\\n\", \"    assert d_error_tree.fetch_errors_from(('foo', 'bar'))[0].value == 0\\n\", \"    assert 'foo' in s_error_tree\\n\", \"    assert 'schema' in s_error_tree['foo']\\n\", \"    assert 'bar' in s_error_tree['foo']['schema']\\n\", \"    assert 'type' in s_error_tree['foo']['schema']['bar']\\n\", \"    assert s_error_tree['foo']['schema']['bar']['type'].errors[0].value == 0\\n\", \"        s_error_tree.fetch_errors_from(('foo', 'schema', 'bar', 'type'))[0].value == 0\\n\", \"    schema = {'foo': {'anyof': [{'type': 'string'}, {'type': 'integer'}]}}\\n\", \"    document = {'foo': []}\\n\", '    assert_fail(document, schema, validator=validator)\\n', '    d_error_tree = validator.document_error_tree\\n', '    s_error_tree = validator.schema_error_tree\\n', \"    assert 'foo' in d_error_tree\\n\", \"    assert d_error_tree['foo'].errors[0].value == []\\n\", \"    assert 'foo' in s_error_tree\\n\", \"    assert 'anyof' in s_error_tree['foo']\\n\", \"    assert 0 in s_error_tree['foo']['anyof']\\n\", \"    assert 1 in s_error_tree['foo']['anyof']\\n\", \"    assert 'type' in s_error_tree['foo']['anyof'][0]\\n\", \"    assert s_error_tree['foo']['anyof'][0]['type'].errors[0].value == []\\n\", '    schema = {\\n', '    document = {\\n', '    assert_fail(document, schema, validator=validator)\\n', '    _det = validator.document_error_tree\\n', '    _set = validator.schema_error_tree\\n', '    assert len(_det.errors) == 0\\n', '    assert len(_set.errors) == 0\\n', \"    assert len(_det['a_dict'].errors) == 2\\n\", \"    assert len(_set['a_dict'].errors) == 0\\n\", \"    assert _det['a_dict'][0] is None\\n\", \"    assert len(_det['a_dict']['one'].errors) == 1\\n\", \"    assert len(_det['a_dict'][2].errors) == 1\\n\", \"    assert len(_det['a_dict']['three'].errors) == 2\\n\", \"    assert len(_set['a_dict']['keysrules'].errors) == 1\\n\", \"    assert len(_set['a_dict']['valuesrules'].errors) == 1\\n\", \"    assert len(_set['a_dict']['keysrules']['type'].errors) == 2\\n\", \"    assert len(_set['a_dict']['valuesrules']['regex'].errors) == 2\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['one'].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['keysrules']['type'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict'][2].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['valuesrules']['regex'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['three'].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['keysrules']['type'].errors[1] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['three'].errors[1] == _ref_err\\n\", \"    assert _set['a_dict']['valuesrules']['regex'].errors[1] == _ref_err\\n\", \"    assert len(_det['a_list'].errors) == 1\\n\", \"    assert len(_det['a_list'][0].errors) == 1\\n\", \"    assert _det['a_list'][1] is None\\n\", \"    assert len(_det['a_list'][2].errors) == 3\\n\", \"    assert len(_set['a_list'].errors) == 0\\n\", \"    assert len(_set['a_list']['itemsrules'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['type'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['oneof'][0]['regex'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['oneof'][1]['regex'].errors) == 1\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][0].errors[0] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['type'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[0] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[1] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'][0]['regex'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[2] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'][1]['regex'].errors[0] == _ref_err\\n\", \"    schema = {'foo': {'type': 'dict', 'schema': {'bar': {'type': 'number'}}}}\\n\", \"    document = {'foo': {'bar': 'zero'}}\\n\", '    validator = Validator(schema)\\n', '    validator(document)\\n', \"    assert 'foo' in validator.document_error_tree\\n\", \"    assert 'bar' in validator.document_error_tree['foo']\\n\", \"    assert 'foo' in validator.schema_error_tree\\n\", \"    assert 'schema' in validator.schema_error_tree['foo']\\n\", \"    assert errors.SCHEMA in validator.document_error_tree['foo'].errors\\n\", \"    assert errors.SCHEMA in validator.document_error_tree['foo']\\n\", \"    assert errors.TYPE in validator.document_error_tree['foo']['bar']\\n\", \"    assert errors.SCHEMA in validator.schema_error_tree['foo']['schema']\\n\", \"    assert errors.TYPE in validator.schema_error_tree['foo']['schema']['bar']['type']\\n\", \"        validator.document_error_tree['foo'][errors.SCHEMA].child_errors[0].code\\n\", '    handler = errors.BasicErrorHandler()\\n', '    _errors, ref = [], {}\\n', \"    _errors.append(ValidationError(['foo'], ['foo'], 0x63, 'readonly', True, None, ()))\\n\", \"    ref.update({'foo': [handler.messages[0x63]]})\\n\", '    assert handler(_errors) == ref\\n', \"    _errors.append(ValidationError(['bar'], ['foo'], 0x42, 'min', 1, 2, ()))\\n\", \"    ref.update({'bar': [handler.messages[0x42].format(constraint=1)]})\\n\", '    assert handler(_errors) == ref\\n', '    _errors.append(\\n', '        ValidationError(\\n', \"    ref.update({'zap': [{'foo': [handler.messages[0x24].format(constraint='string')]}]})\\n\", '    assert handler(_errors) == ref\\n', '    _errors.append(\\n', '        ValidationError(\\n', \"    ref['zap'][0]['foo'].append(handler.messages[0x41].format(constraint='^p[e]ng$'))\\n\", '    assert handler(_errors) == ref\\n', \"    schema = {'foo': {'oneof': ({'type': ('integer',)}, {'type': ('string',)})}}\\n\", \"    document = {'foo': 23.42}\\n\", \"    error = ('foo', ('foo', 'oneof'), errors.ONEOF, schema['foo']['oneof'], ())\\n\", \"        (error[0], error[1] + (0, 'type'), errors.TYPE, ('integer',)),\\n\", \"        (error[0], error[1] + (1, 'type'), errors.TYPE, ('string',)),\\n\", '        document, schema, validator=validator, error=error, child_errors=child_errors\\n', '    assert validator.errors == {\\n', '    validator.schema = {\\n', \"    validator({'test_list': ['test']})\\n\", '    assert validator.errors == {\\'test_list\\': [\"length of list should be 2, it is 1\"]}\\n']",
  "context": "\n\n\ndef test_basic_error_of_errors(validator):\n    schema = {'foo': {'oneof': ({'type': ('integer',)}, {'type': ('string',)})}}\n    document = {'foo': 23.42}\n    error = ('foo', "
 },
 "458": {
  "name": "document",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_errors.py",
  "lineno": "304",
  "column": "4",
  "slicing": "[\"    document = {'foo': 23.42}\\n\", '        document, schema, validator=validator, error=error, child_errors=child_errors\\n']",
  "context": "ype': ('integer',)}, {'type': ('string',)})}}\n    document = {'foo': 23.42}\n    error = ('foo', ('foo', 'oneof'), errors.ONEOF"
 },
 "459": {
  "name": "error",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_errors.py",
  "lineno": "305",
  "column": "4",
  "slicing": "['ValidationError = errors.ValidationError\\n', \"    v = Validator(schema={'foo': {'type': 'string'}})\\n\", \"    v.document = {'foo': 42}\\n\", \"    v._error('foo', errors.TYPE, 'string')\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'type')\\n\", '    assert error.code == 0x24\\n', \"    assert error.rule == 'type'\\n\", \"    assert error.constraint == ('string',)\\n\", '    assert error.value == 42\\n', \"    assert error.info == ('string',)\\n\", '    assert not error.is_group_error\\n', '    assert not error.is_logic_error\\n', \"    v = Validator(schema={'foo': {'keysrules': {'type': 'integer'}}})\\n\", \"    v.document = {'foo': {'0': 'bar'}}\\n\", \"    v._error('foo', errors.KEYSRULES, ())\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'keysrules')\\n\", '    assert error.code == 0x83\\n', \"    assert error.rule == 'keysrules'\\n\", \"    assert error.constraint == {'type': ('integer',)}\\n\", \"    assert error.value == {'0': 'bar'}\\n\", '    assert error.info == ((),)\\n', '    assert error.is_group_error\\n', '    assert not error.is_logic_error\\n', '    valids = (\\n', \"    v = Validator(schema={'foo': {'oneof': valids}})\\n\", \"    v.document = {'foo': '0x100'}\\n\", \"    v._error('foo', errors.ONEOF, (), 0, 2)\\n\", '    error = v._errors[0]\\n', \"    assert error.document_path == ('foo',)\\n\", \"    assert error.schema_path == ('foo', 'oneof')\\n\", '    assert error.code == 0x92\\n', \"    assert error.rule == 'oneof'\\n\", '    assert error.constraint == valids\\n', \"    assert error.value == '0x100'\\n\", '    assert error.info == ((), 0, 2)\\n', '    assert error.is_group_error\\n', '    assert error.is_logic_error\\n', \"    schema = {'foo': {'schema': {'bar': {'type': 'string'}}}}\\n\", \"    document = {'foo': {'bar': 0}}\\n\", '    assert_fail(document, schema, validator=validator)\\n', '    d_error_tree = validator.document_error_tree\\n', '    s_error_tree = validator.schema_error_tree\\n', \"    assert 'foo' in d_error_tree\\n\", \"    assert len(d_error_tree['foo'].errors) == 1, d_error_tree['foo']\\n\", \"    assert d_error_tree['foo'].errors[0].code == errors.SCHEMA.code\\n\", \"    assert 'bar' in d_error_tree['foo']\\n\", \"    assert d_error_tree['foo']['bar'].errors[0].value == 0\\n\", \"    assert d_error_tree.fetch_errors_from(('foo', 'bar'))[0].value == 0\\n\", \"    assert 'foo' in s_error_tree\\n\", \"    assert 'schema' in s_error_tree['foo']\\n\", \"    assert 'bar' in s_error_tree['foo']['schema']\\n\", \"    assert 'type' in s_error_tree['foo']['schema']['bar']\\n\", \"    assert s_error_tree['foo']['schema']['bar']['type'].errors[0].value == 0\\n\", \"        s_error_tree.fetch_errors_from(('foo', 'schema', 'bar', 'type'))[0].value == 0\\n\", \"    schema = {'foo': {'anyof': [{'type': 'string'}, {'type': 'integer'}]}}\\n\", \"    document = {'foo': []}\\n\", '    assert_fail(document, schema, validator=validator)\\n', '    d_error_tree = validator.document_error_tree\\n', '    s_error_tree = validator.schema_error_tree\\n', \"    assert 'foo' in d_error_tree\\n\", \"    assert d_error_tree['foo'].errors[0].value == []\\n\", \"    assert 'foo' in s_error_tree\\n\", \"    assert 'anyof' in s_error_tree['foo']\\n\", \"    assert 0 in s_error_tree['foo']['anyof']\\n\", \"    assert 1 in s_error_tree['foo']['anyof']\\n\", \"    assert 'type' in s_error_tree['foo']['anyof'][0]\\n\", \"    assert s_error_tree['foo']['anyof'][0]['type'].errors[0].value == []\\n\", '    schema = {\\n', '    document = {\\n', '    assert_fail(document, schema, validator=validator)\\n', '    _det = validator.document_error_tree\\n', '    _set = validator.schema_error_tree\\n', '    assert len(_det.errors) == 0\\n', '    assert len(_set.errors) == 0\\n', \"    assert len(_det['a_dict'].errors) == 2\\n\", \"    assert len(_set['a_dict'].errors) == 0\\n\", \"    assert _det['a_dict'][0] is None\\n\", \"    assert len(_det['a_dict']['one'].errors) == 1\\n\", \"    assert len(_det['a_dict'][2].errors) == 1\\n\", \"    assert len(_det['a_dict']['three'].errors) == 2\\n\", \"    assert len(_set['a_dict']['keysrules'].errors) == 1\\n\", \"    assert len(_set['a_dict']['valuesrules'].errors) == 1\\n\", \"    assert len(_set['a_dict']['keysrules']['type'].errors) == 2\\n\", \"    assert len(_set['a_dict']['valuesrules']['regex'].errors) == 2\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['one'].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['keysrules']['type'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict'][2].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['valuesrules']['regex'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['three'].errors[0] == _ref_err\\n\", \"    assert _set['a_dict']['keysrules']['type'].errors[1] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_dict']['three'].errors[1] == _ref_err\\n\", \"    assert _set['a_dict']['valuesrules']['regex'].errors[1] == _ref_err\\n\", \"    assert len(_det['a_list'].errors) == 1\\n\", \"    assert len(_det['a_list'][0].errors) == 1\\n\", \"    assert _det['a_list'][1] is None\\n\", \"    assert len(_det['a_list'][2].errors) == 3\\n\", \"    assert len(_set['a_list'].errors) == 0\\n\", \"    assert len(_set['a_list']['itemsrules'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['type'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['oneof'][0]['regex'].errors) == 1\\n\", \"    assert len(_set['a_list']['itemsrules']['oneof'][1]['regex'].errors) == 1\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][0].errors[0] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['type'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[0] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[1] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'][0]['regex'].errors[0] == _ref_err\\n\", '    _ref_err = ValidationError(\\n', \"    assert _det['a_list'][2].errors[2] == _ref_err\\n\", \"    assert _set['a_list']['itemsrules']['oneof'][1]['regex'].errors[0] == _ref_err\\n\", \"    schema = {'foo': {'type': 'dict', 'schema': {'bar': {'type': 'number'}}}}\\n\", \"    document = {'foo': {'bar': 'zero'}}\\n\", '    validator = Validator(schema)\\n', '    validator(document)\\n', \"    assert 'foo' in validator.document_error_tree\\n\", \"    assert 'bar' in validator.document_error_tree['foo']\\n\", \"    assert 'foo' in validator.schema_error_tree\\n\", \"    assert 'schema' in validator.schema_error_tree['foo']\\n\", \"    assert errors.SCHEMA in validator.document_error_tree['foo'].errors\\n\", \"    assert errors.SCHEMA in validator.document_error_tree['foo']\\n\", \"    assert errors.TYPE in validator.document_error_tree['foo']['bar']\\n\", \"    assert errors.SCHEMA in validator.schema_error_tree['foo']['schema']\\n\", \"    assert errors.TYPE in validator.schema_error_tree['foo']['schema']['bar']['type']\\n\", \"        validator.document_error_tree['foo'][errors.SCHEMA].child_errors[0].code\\n\", '    handler = errors.BasicErrorHandler()\\n', '    _errors, ref = [], {}\\n', \"    _errors.append(ValidationError(['foo'], ['foo'], 0x63, 'readonly', True, None, ()))\\n\", \"    ref.update({'foo': [handler.messages[0x63]]})\\n\", '    assert handler(_errors) == ref\\n', \"    _errors.append(ValidationError(['bar'], ['foo'], 0x42, 'min', 1, 2, ()))\\n\", \"    ref.update({'bar': [handler.messages[0x42].format(constraint=1)]})\\n\", '    assert handler(_errors) == ref\\n', '    _errors.append(\\n', '        ValidationError(\\n', \"    ref.update({'zap': [{'foo': [handler.messages[0x24].format(constraint='string')]}]})\\n\", '    assert handler(_errors) == ref\\n', '    _errors.append(\\n', '        ValidationError(\\n', \"    ref['zap'][0]['foo'].append(handler.messages[0x41].format(constraint='^p[e]ng$'))\\n\", '    assert handler(_errors) == ref\\n', \"    schema = {'foo': {'oneof': ({'type': ('integer',)}, {'type': ('string',)})}}\\n\", \"    document = {'foo': 23.42}\\n\", \"    error = ('foo', ('foo', 'oneof'), errors.ONEOF, schema['foo']['oneof'], ())\\n\", \"        (error[0], error[1] + (0, 'type'), errors.TYPE, ('integer',)),\\n\", \"        (error[0], error[1] + (1, 'type'), errors.TYPE, ('string',)),\\n\", '        document, schema, validator=validator, error=error, child_errors=child_errors\\n', '    assert validator.errors == {\\n', '    validator.schema = {\\n', \"    validator({'test_list': ['test']})\\n\", '    assert validator.errors == {\\'test_list\\': [\"length of list should be 2, it is 1\"]}\\n']",
  "context": "('string',)})}}\n    document = {'foo': 23.42}\n    error = ('foo', ('foo', 'oneof'), errors.ONEOF, schema['foo']['oneof'], ())\n    child_errors = [\n        (error[0], error[1] +"
 },
 "460": {
  "name": "child_errors",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_errors.py",
  "lineno": "306",
  "column": "4",
  "slicing": "['    child_errors = [\\n', '        document, schema, validator=validator, error=error, child_errors=child_errors\\n']",
  "context": "'), errors.ONEOF, schema['foo']['oneof'], ())\n    child_errors = [\n        (error[0], error[1] + (0, 'type'), errors."
 },
 "461": {
  "name": "sample_schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/conftest.py",
  "lineno": "23",
  "column": "0",
  "slicing": "['sample_schema = {\\n']",
  "context": "alidator():\n    return Validator(sample_schema)\n\n\nsample_schema = {\n    'a_string': {'type': 'string', 'minlength': 2,"
 },
 "462": {
  "name": "sample_document",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/conftest.py",
  "lineno": "79",
  "column": "0",
  "slicing": "[\"sample_document = {'name': 'john doe'}\\n\"]",
  "context": ",\n    'a_not_nullable_field_without_type': {},\n}\n\nsample_document = {'name': 'john doe'}\n"
 },
 "463": {
  "name": "exception",
  "type": "cerberus.base.DocumentError",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/tests/__init__.py",
  "lineno": "10",
  "column": "21",
  "slicing": "['def assert_exception(exception, document={}, schema=None, validator=None, msg=None):\\n', '        with pytest.raises(exception, match=re.escape(msg)):\\n', '    assert_exception(SchemaError, *args)\\n', '    assert_exception(DocumentError, *args)\\n']",
  "context": "ftest import sample_schema\n\n\ndef assert_exception(exception, document={}, schema=None, validator=None, msg=None):\n    \"\"\" Tests whether a specific exception is rais"
 },
 "464": {
  "name": "document",
  "type": "(None,dict,None,?)",
  "class": "imported",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/tests/__init__.py",
  "lineno": "10",
  "column": "32",
  "slicing": "['def assert_exception(exception, document={}, schema=None, validator=None, msg=None):\\n', '        validator = Validator()\\n', '            validator(document, schema)\\n', '        with pytest.raises(exception, match=re.escape(msg)):\\n', '            validator(document, schema)\\n', '    assert_exception(SchemaError, *args)\\n', '    assert_exception(DocumentError, *args)\\n', '    if validator is None:\\n', '        validator = Validator(sample_schema)\\n', '    result = validator(document, schema, update)\\n', '    assert isinstance(result, bool)\\n', '    assert not result\\n', '    actual_errors = validator._errors\\n', '        assert len(actual_errors) == 1\\n', '        assert_has_error(actual_errors, *error)\\n', '            assert len(actual_errors[0].child_errors) == len(child_errors)\\n', '            assert_has_errors(actual_errors[0].child_errors, child_errors)\\n', '        assert len(actual_errors) == len(errors)\\n', '        assert_has_errors(actual_errors, errors)\\n', '    return actual_errors\\n', '    if validator is None:\\n', '        validator = Validator(sample_schema)\\n', '    result = validator(document, schema, update)\\n', '    assert isinstance(result, bool)\\n', '    if not result:\\n', '        raise AssertionError(validator.errors)\\n', '    if validator is None:\\n', '    assert_success(document, schema, validator)\\n', '    assert validator.document == expected\\n']",
  "context": "t sample_schema\n\n\ndef assert_exception(exception, document={}, schema=None, validator=None, msg=None):\n    \"\"\" Tests whether a specific exception is rais"
 },
 "465": {
  "name": "validator",
  "type": "cerberus.Validator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/__init__.py",
  "lineno": "14",
  "column": "8",
  "slicing": "['def assert_exception(exception, document={}, schema=None, validator=None, msg=None):\\n', '        validator = Validator()\\n', '            validator(document, schema)\\n', '        with pytest.raises(exception, match=re.escape(msg)):\\n', '            validator(document, schema)\\n', '    assert_exception(SchemaError, *args)\\n', '    assert_exception(DocumentError, *args)\\n', '    if validator is None:\\n', '        validator = Validator(sample_schema)\\n', '    result = validator(document, schema, update)\\n', '    assert isinstance(result, bool)\\n', '    assert not result\\n', '    actual_errors = validator._errors\\n', '        assert len(actual_errors) == 1\\n', '        assert_has_error(actual_errors, *error)\\n', '            assert len(actual_errors[0].child_errors) == len(child_errors)\\n', '            assert_has_errors(actual_errors[0].child_errors, child_errors)\\n', '        assert len(actual_errors) == len(errors)\\n', '        assert_has_errors(actual_errors, errors)\\n', '    return actual_errors\\n', '    if validator is None:\\n', '        validator = Validator(sample_schema)\\n', '    result = validator(document, schema, update)\\n', '    assert isinstance(result, bool)\\n', '    if not result:\\n', '        raise AssertionError(validator.errors)\\n', '    if validator is None:\\n', '    assert_success(document, schema, validator)\\n', '    assert validator.document == expected\\n']",
  "context": "s expected. \"\"\"\n    if validator is None:\n        validator = Validator()\n    if msg is None:\n        with pytest.raises(exc"
 },
 "466": {
  "name": "document",
  "type": "dict",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/tests/__init__.py",
  "lineno": "36",
  "column": "4",
  "slicing": "['    document,\\n']",
  "context": "tion(DocumentError, *args)\n\n\ndef assert_fail(\n    document,\n    schema=None,\n    validator=None,\n    update=Fa"
 },
 "467": {
  "name": "validator",
  "type": "cerberus.Validator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/__init__.py",
  "lineno": "46",
  "column": "8",
  "slicing": "['def assert_exception(exception, document={}, schema=None, validator=None, msg=None):\\n', '        validator = Validator()\\n', '            validator(document, schema)\\n', '        with pytest.raises(exception, match=re.escape(msg)):\\n', '            validator(document, schema)\\n', '    assert_exception(SchemaError, *args)\\n', '    assert_exception(DocumentError, *args)\\n', '    if validator is None:\\n', '        validator = Validator(sample_schema)\\n', '    result = validator(document, schema, update)\\n', '    assert isinstance(result, bool)\\n', '    assert not result\\n', '    actual_errors = validator._errors\\n', '        assert len(actual_errors) == 1\\n', '        assert_has_error(actual_errors, *error)\\n', '            assert len(actual_errors[0].child_errors) == len(child_errors)\\n', '            assert_has_errors(actual_errors[0].child_errors, child_errors)\\n', '        assert len(actual_errors) == len(errors)\\n', '        assert_has_errors(actual_errors, errors)\\n', '    return actual_errors\\n', '    if validator is None:\\n', '        validator = Validator(sample_schema)\\n', '    result = validator(document, schema, update)\\n', '    assert isinstance(result, bool)\\n', '    if not result:\\n', '        raise AssertionError(validator.errors)\\n', '    if validator is None:\\n', '    assert_success(document, schema, validator)\\n', '    assert validator.document == expected\\n']",
  "context": "tion fails. \"\"\"\n    if validator is None:\n        validator = Validator(sample_schema)\n    result = validator(document, schema, update)\n "
 },
 "468": {
  "name": "result",
  "type": "validator",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/__init__.py",
  "lineno": "47",
  "column": "4",
  "slicing": "['def assert_exception(exception, document={}, schema=None, validator=None, msg=None):\\n', '        validator = Validator()\\n', '            validator(document, schema)\\n', '        with pytest.raises(exception, match=re.escape(msg)):\\n', '            validator(document, schema)\\n', '    assert_exception(SchemaError, *args)\\n', '    assert_exception(DocumentError, *args)\\n', '    if validator is None:\\n', '        validator = Validator(sample_schema)\\n', '    result = validator(document, schema, update)\\n', '    assert isinstance(result, bool)\\n', '    assert not result\\n', '    actual_errors = validator._errors\\n', '        assert len(actual_errors) == 1\\n', '        assert_has_error(actual_errors, *error)\\n', '            assert len(actual_errors[0].child_errors) == len(child_errors)\\n', '            assert_has_errors(actual_errors[0].child_errors, child_errors)\\n', '        assert len(actual_errors) == len(errors)\\n', '        assert_has_errors(actual_errors, errors)\\n', '    return actual_errors\\n', '    if validator is None:\\n', '        validator = Validator(sample_schema)\\n', '    result = validator(document, schema, update)\\n', '    assert isinstance(result, bool)\\n', '    if not result:\\n', '        raise AssertionError(validator.errors)\\n', '    if validator is None:\\n', '    assert_success(document, schema, validator)\\n', '    assert validator.document == expected\\n']",
  "context": "\n        validator = Validator(sample_schema)\n    result = validator(document, schema, update)\n    assert isinstance(result, bool)\n    assert not"
 },
 "469": {
  "name": "actual_errors",
  "type": "ErrorList",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/tests/__init__.py",
  "lineno": "51",
  "column": "4",
  "slicing": "['def assert_exception(exception, document={}, schema=None, validator=None, msg=None):\\n', '        validator = Validator()\\n', '            validator(document, schema)\\n', '        with pytest.raises(exception, match=re.escape(msg)):\\n', '            validator(document, schema)\\n', '    assert_exception(SchemaError, *args)\\n', '    assert_exception(DocumentError, *args)\\n', '    if validator is None:\\n', '        validator = Validator(sample_schema)\\n', '    result = validator(document, schema, update)\\n', '    assert isinstance(result, bool)\\n', '    assert not result\\n', '    actual_errors = validator._errors\\n', '        assert len(actual_errors) == 1\\n', '        assert_has_error(actual_errors, *error)\\n', '            assert len(actual_errors[0].child_errors) == len(child_errors)\\n', '            assert_has_errors(actual_errors[0].child_errors, child_errors)\\n', '        assert len(actual_errors) == len(errors)\\n', '        assert_has_errors(actual_errors, errors)\\n', '    return actual_errors\\n', '    if validator is None:\\n', '        validator = Validator(sample_schema)\\n', '    result = validator(document, schema, update)\\n', '    assert isinstance(result, bool)\\n', '    if not result:\\n', '        raise AssertionError(validator.errors)\\n', '    if validator is None:\\n', '    assert_success(document, schema, validator)\\n', '    assert validator.document == expected\\n']",
  "context": "instance(result, bool)\n    assert not result\n\n    actual_errors = validator._errors\n\n    assert not (error is not None and errors is n"
 },
 "470": {
  "name": "document",
  "type": "dict",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/tests/__init__.py",
  "lineno": "73",
  "column": "19",
  "slicing": "['def assert_success(document, schema=None, validator=None, update=False):\\n', '    assert_success(document, schema, validator)\\n']",
  "context": "s)\n\n    return actual_errors\n\n\ndef assert_success(document, schema=None, validator=None, update=False):\n    \"\"\" Tests whether a validation succeeds. \"\"\"\n "
 },
 "471": {
  "name": "validator",
  "type": "cerberus.Validator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/__init__.py",
  "lineno": "76",
  "column": "8",
  "slicing": "['def assert_exception(exception, document={}, schema=None, validator=None, msg=None):\\n', '        validator = Validator()\\n', '            validator(document, schema)\\n', '        with pytest.raises(exception, match=re.escape(msg)):\\n', '            validator(document, schema)\\n', '    assert_exception(SchemaError, *args)\\n', '    assert_exception(DocumentError, *args)\\n', '    if validator is None:\\n', '        validator = Validator(sample_schema)\\n', '    result = validator(document, schema, update)\\n', '    assert isinstance(result, bool)\\n', '    assert not result\\n', '    actual_errors = validator._errors\\n', '        assert len(actual_errors) == 1\\n', '        assert_has_error(actual_errors, *error)\\n', '            assert len(actual_errors[0].child_errors) == len(child_errors)\\n', '            assert_has_errors(actual_errors[0].child_errors, child_errors)\\n', '        assert len(actual_errors) == len(errors)\\n', '        assert_has_errors(actual_errors, errors)\\n', '    return actual_errors\\n', '    if validator is None:\\n', '        validator = Validator(sample_schema)\\n', '    result = validator(document, schema, update)\\n', '    assert isinstance(result, bool)\\n', '    if not result:\\n', '        raise AssertionError(validator.errors)\\n', '    if validator is None:\\n', '    assert_success(document, schema, validator)\\n', '    assert validator.document == expected\\n']",
  "context": "n succeeds. \"\"\"\n    if validator is None:\n        validator = Validator(sample_schema)\n    result = validator(document, schema, update)\n "
 },
 "472": {
  "name": "result",
  "type": "validator",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/__init__.py",
  "lineno": "77",
  "column": "4",
  "slicing": "['def assert_exception(exception, document={}, schema=None, validator=None, msg=None):\\n', '        validator = Validator()\\n', '            validator(document, schema)\\n', '        with pytest.raises(exception, match=re.escape(msg)):\\n', '            validator(document, schema)\\n', '    assert_exception(SchemaError, *args)\\n', '    assert_exception(DocumentError, *args)\\n', '    if validator is None:\\n', '        validator = Validator(sample_schema)\\n', '    result = validator(document, schema, update)\\n', '    assert isinstance(result, bool)\\n', '    assert not result\\n', '    actual_errors = validator._errors\\n', '        assert len(actual_errors) == 1\\n', '        assert_has_error(actual_errors, *error)\\n', '            assert len(actual_errors[0].child_errors) == len(child_errors)\\n', '            assert_has_errors(actual_errors[0].child_errors, child_errors)\\n', '        assert len(actual_errors) == len(errors)\\n', '        assert_has_errors(actual_errors, errors)\\n', '    return actual_errors\\n', '    if validator is None:\\n', '        validator = Validator(sample_schema)\\n', '    result = validator(document, schema, update)\\n', '    assert isinstance(result, bool)\\n', '    if not result:\\n', '        raise AssertionError(validator.errors)\\n', '    if validator is None:\\n', '    assert_success(document, schema, validator)\\n', '    assert validator.document == expected\\n']",
  "context": "\n        validator = Validator(sample_schema)\n    result = validator(document, schema, update)\n    assert isinstance(result, bool)\n    if not res"
 },
 "473": {
  "name": "d_path",
  "type": "((None,None),(None,None,None),ErrorDefinition,(dict,dict))",
  "class": "imported",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/tests/__init__.py",
  "lineno": "83",
  "column": "30",
  "slicing": "['def assert_has_error(_errors, d_path, s_path, error_def, constraint, info=()):\\n', '                doc_path=d_path,\\n']",
  "context": "validator.errors)\n\n\ndef assert_has_error(_errors, d_path, s_path, error_def, constraint, info=()):\n    if not isinstance(d_path, tuple):\n        d_pa"
 },
 "474": {
  "name": "info",
  "type": "()",
  "class": "imported",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/tests/__init__.py",
  "lineno": "83",
  "column": "69",
  "slicing": "['def assert_has_error(_errors, d_path, s_path, error_def, constraint, info=()):\\n']",
  "context": "r(_errors, d_path, s_path, error_def, constraint, info=()):\n    if not isinstance(d_path, tuple):\n        d_pa"
 },
 "475": {
  "name": "d_path",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/__init__.py",
  "lineno": "85",
  "column": "8",
  "slicing": "['def assert_exception(exception, document={}, schema=None, validator=None, msg=None):\\n', '        validator = Validator()\\n', '            validator(document, schema)\\n', '        with pytest.raises(exception, match=re.escape(msg)):\\n', '            validator(document, schema)\\n', '    assert_exception(SchemaError, *args)\\n', '    assert_exception(DocumentError, *args)\\n', '    if validator is None:\\n', '        validator = Validator(sample_schema)\\n', '    result = validator(document, schema, update)\\n', '    assert isinstance(result, bool)\\n', '    assert not result\\n', '    actual_errors = validator._errors\\n', '        assert len(actual_errors) == 1\\n', '        assert_has_error(actual_errors, *error)\\n', '            assert len(actual_errors[0].child_errors) == len(child_errors)\\n', '            assert_has_errors(actual_errors[0].child_errors, child_errors)\\n', '        assert len(actual_errors) == len(errors)\\n', '        assert_has_errors(actual_errors, errors)\\n', '    return actual_errors\\n', '    if validator is None:\\n', '        validator = Validator(sample_schema)\\n', '    result = validator(document, schema, update)\\n', '    assert isinstance(result, bool)\\n', '    if not result:\\n', '        raise AssertionError(validator.errors)\\n', '        d_path = (d_path,)\\n', '            assert error.document_path == d_path\\n', '                doc_path=d_path,\\n', '    if validator is None:\\n', '    assert_success(document, schema, validator)\\n', '    assert validator.document == expected\\n']",
  "context": ")):\n    if not isinstance(d_path, tuple):\n        d_path = (d_path,)\n    if not isinstance(info, tuple):\n        info ="
 },
 "476": {
  "name": "info",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/__init__.py",
  "lineno": "87",
  "column": "8",
  "slicing": "['def assert_exception(exception, document={}, schema=None, validator=None, msg=None):\\n', '        validator = Validator()\\n', '            validator(document, schema)\\n', '        with pytest.raises(exception, match=re.escape(msg)):\\n', '            validator(document, schema)\\n', '    assert_exception(SchemaError, *args)\\n', '    assert_exception(DocumentError, *args)\\n', '    if validator is None:\\n', '        validator = Validator(sample_schema)\\n', '    result = validator(document, schema, update)\\n', '    assert isinstance(result, bool)\\n', '    assert not result\\n', '    actual_errors = validator._errors\\n', '        assert len(actual_errors) == 1\\n', '        assert_has_error(actual_errors, *error)\\n', '            assert len(actual_errors[0].child_errors) == len(child_errors)\\n', '            assert_has_errors(actual_errors[0].child_errors, child_errors)\\n', '        assert len(actual_errors) == len(errors)\\n', '        assert_has_errors(actual_errors, errors)\\n', '    return actual_errors\\n', '    if validator is None:\\n', '        validator = Validator(sample_schema)\\n', '    result = validator(document, schema, update)\\n', '    assert isinstance(result, bool)\\n', '    if not result:\\n', '        raise AssertionError(validator.errors)\\n', '        d_path = (d_path,)\\n', '        info = (info,)\\n', '            assert error.document_path == d_path\\n', '                assert error.info == info\\n', '                doc_path=d_path,\\n', '                info=info,\\n', '    if validator is None:\\n', '    assert_success(document, schema, validator)\\n', '    assert validator.document == expected\\n']",
  "context": "ath,)\n    if not isinstance(info, tuple):\n        info = (info,)\n\n    assert isinstance(_errors, errors.ErrorList)\n"
 },
 "477": {
  "name": "document",
  "type": "dict",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/tests/__init__.py",
  "lineno": "144",
  "column": "22",
  "slicing": "['def assert_normalized(document, expected, schema=None, validator=None):\\n']",
  "context": "xpected error occurred.')\n\n\ndef assert_normalized(document, expected, schema=None, validator=None):\n    if validator is None:\n        validator = Vali"
 },
 "478": {
  "name": "expected",
  "type": "dict",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/tests/__init__.py",
  "lineno": "144",
  "column": "32",
  "slicing": "['def assert_normalized(document, expected, schema=None, validator=None):\\n']",
  "context": "ror occurred.')\n\n\ndef assert_normalized(document, expected, schema=None, validator=None):\n    if validator is None:\n        validator = Vali"
 },
 "479": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/tests/__init__.py",
  "lineno": "144",
  "column": "42",
  "slicing": "['def assert_normalized(document, expected, schema=None, validator=None):\\n']",
  "context": "ed.')\n\n\ndef assert_normalized(document, expected, schema=None, validator=None):\n    if validator is None:\n        validator = Vali"
 },
 "480": {
  "name": "validator",
  "type": "cerberus.Validator",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/tests/__init__.py",
  "lineno": "144",
  "column": "55",
  "slicing": "['def assert_normalized(document, expected, schema=None, validator=None):\\n']",
  "context": "ssert_normalized(document, expected, schema=None, validator=None):\n    if validator is None:\n        validator = Vali"
 },
 "481": {
  "name": "validator",
  "type": "cerberus.Validator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/__init__.py",
  "lineno": "146",
  "column": "8",
  "slicing": "['def assert_exception(exception, document={}, schema=None, validator=None, msg=None):\\n', '        validator = Validator()\\n', '            validator(document, schema)\\n', '        with pytest.raises(exception, match=re.escape(msg)):\\n', '            validator(document, schema)\\n', '    assert_exception(SchemaError, *args)\\n', '    assert_exception(DocumentError, *args)\\n', '    if validator is None:\\n', '        validator = Validator(sample_schema)\\n', '    result = validator(document, schema, update)\\n', '    assert isinstance(result, bool)\\n', '    assert not result\\n', '    actual_errors = validator._errors\\n', '        assert len(actual_errors) == 1\\n', '        assert_has_error(actual_errors, *error)\\n', '            assert len(actual_errors[0].child_errors) == len(child_errors)\\n', '            assert_has_errors(actual_errors[0].child_errors, child_errors)\\n', '        assert len(actual_errors) == len(errors)\\n', '        assert_has_errors(actual_errors, errors)\\n', '    return actual_errors\\n', '    if validator is None:\\n', '        validator = Validator(sample_schema)\\n', '    result = validator(document, schema, update)\\n', '    assert isinstance(result, bool)\\n', '    if not result:\\n', '        raise AssertionError(validator.errors)\\n', 'def assert_has_error(_errors, d_path, s_path, error_def, constraint, info=()):\\n', '        d_path = (d_path,)\\n', '        info = (info,)\\n', '    for i, error in enumerate(_errors):\\n', '        assert isinstance(error, errors.ValidationError)\\n', '            assert error.document_path == d_path\\n', '            assert error.schema_path == s_path\\n', '            assert error.code == error_def.code\\n', '            assert error.rule == error_def.rule\\n', '            assert error.constraint == constraint\\n', '            if not error.is_group_error:\\n', '                assert error.info == info\\n', '                doc_path=d_path,\\n', '                code=hex(error.code),\\n', '                info=info,\\n', '    return i\\n', '    for error in _exp_errors:\\n', '        assert isinstance(error, tuple)\\n', '        assert_has_error(_errors, *error)\\n', '        assert_has_error(_errors, *args, **kwargs)\\n', '    if validator is None:\\n', '        validator = Validator(sample_schema)\\n', '    assert_success(document, schema, validator)\\n', '    assert validator.document == expected\\n']",
  "context": "alidator=None):\n    if validator is None:\n        validator = Validator(sample_schema)\n    assert_success(document, schema, validator)\n  "
 },
 "482": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_readonly.py",
  "lineno": "6",
  "column": "4",
  "slicing": "['    schema = {\\n', \"    assert_success(document={'some_field': {}}, schema=schema)\\n\", \"            schema['some_field']['schema']['created']['readonly'],\\n\", \"            schema['some_field']['schema']['modified']['readonly'],\\n\", '        schema=schema,\\n', '        schema=schema,\\n', '    assert_success(document={}, schema=schema)\\n', \"            schema['created']['readonly'],\\n\", \"            schema['modified']['readonly'],\\n\", '        schema=schema,\\n', '        schema=schema,\\n']",
  "context": "s\n\n\ndef test_nested_readonly_with_defaults():\n    schema = {\n        'some_field': {\n            'type': 'dict'"
 },
 "483": {
  "name": "expected_errors",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_readonly.py",
  "lineno": "22",
  "column": "4",
  "slicing": "['    expected_errors = [\\n', '        errors=expected_errors,\\n', '        errors=expected_errors,\\n', '        errors=expected_errors,\\n', '        errors=expected_errors,\\n']",
  "context": "(document={'some_field': {}}, schema=schema)\n\n    expected_errors = [\n        (\n            ('some_field', 'created'),\n "
 },
 "484": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_readonly.py",
  "lineno": "69",
  "column": "4",
  "slicing": "['    schema = {\\n', '    assert_success(document={}, schema=schema)\\n', \"            schema['created']['readonly'],\\n\", \"            schema['modified']['readonly'],\\n\", '        schema=schema,\\n', '        schema=schema,\\n']",
  "context": "],\n    )\n\n\ndef test_readonly_with_defaults():\n    schema = {\n        'created': {'type': 'string', 'readonly': "
 },
 "485": {
  "name": "expected_errors",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_readonly.py",
  "lineno": "80",
  "column": "4",
  "slicing": "['    expected_errors = [\\n', '        errors=expected_errors,\\n', '        errors=expected_errors,\\n']",
  "context": "  assert_success(document={}, schema=schema)\n\n    expected_errors = [\n        (\n            'created',\n            ('cre"
 },
 "486": {
  "name": "error_node",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_valuesrules.py",
  "lineno": "32",
  "column": "4",
  "slicing": "[\"    error_node = validator.schema_error_tree['a_dict_with_valuesrules']['valuesrules']\\n\", '    assert len(error_node.descendants) == 1\\n']",
  "context": ".schema_error_tree['a_dict_with_valuesrules']\n    error_node = validator.schema_error_tree['a_dict_with_valuesrules']['valuesrules']\n    assert len(error_node.descendants) == 1\n"
 },
 "487": {
  "name": "value",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_allowed.py",
  "lineno": "20",
  "column": "4",
  "slicing": "[\"    value = ['agent', 'client', 'profit']\\n\", '        {field: value},\\n', '        {field: value},\\n', '            value,\\n']",
  "context": "wed_with_list_value():\n    field = 'an_array'\n    value = ['agent', 'client', 'profit']\n    assert_fail(\n        {field: value},\n        e"
 },
 "488": {
  "name": "doc",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_allowed.py",
  "lineno": "54",
  "column": "4",
  "slicing": "[\"    doc = {'letters': u''}\\n\", '    assert_fail(doc, schema)\\n', '    assert_success(doc, schema)\\n', '    assert_success(doc, schema)\\n', '        doc,\\n']",
  "context": "# http://github.com/pyeve/cerberus/issues/280\n    doc = {'letters': u''}\n\n    schema = {'letters': {'type': 'string', 'allo"
 },
 "489": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_allowed.py",
  "lineno": "56",
  "column": "4",
  "slicing": "[\"    schema = {'letters': {'type': 'string', 'allowed': ['a', 'b', 'c']}}\\n\", '    assert_fail(doc, schema)\\n', '    assert_success(doc, schema)\\n', '    assert_success(doc, schema)\\n', '        schema,\\n']",
  "context": "s/issues/280\n    doc = {'letters': u''}\n\n    schema = {'letters': {'type': 'string', 'allowed': ['a', 'b', 'c']}}\n    assert_fail(doc, schema)\n\n    schema = {'lette"
 },
 "490": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_allowed.py",
  "lineno": "59",
  "column": "4",
  "slicing": "[\"    schema = {'letters': {'type': 'string', 'allowed': [u'']}}\\n\", '    assert_success(doc, schema)\\n', '    assert_success(doc, schema)\\n', '        schema,\\n']",
  "context": "a', 'b', 'c']}}\n    assert_fail(doc, schema)\n\n    schema = {'letters': {'type': 'string', 'allowed': [u'']}}\n    assert_success(doc, schema)\n\n    schema = {'le"
 },
 "491": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_allowed.py",
  "lineno": "62",
  "column": "4",
  "slicing": "[\"    schema = {'letters': {'type': 'string', 'allowed': ['']}}\\n\", '    assert_success(doc, schema)\\n', '        schema,\\n']",
  "context": "[u'']}}\n    assert_success(doc, schema)\n\n    schema = {'letters': {'type': 'string', 'allowed': ['']}}\n    doc = {'letters': ''}\n    assert_success("
 },
 "492": {
  "name": "doc",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_allowed.py",
  "lineno": "63",
  "column": "4",
  "slicing": "[\"    doc = {'letters': ''}\\n\", '    assert_success(doc, schema)\\n', '        doc,\\n']",
  "context": "s': {'type': 'string', 'allowed': ['']}}\n    doc = {'letters': ''}\n    assert_success(doc, schema)\n\n\ndef test_allowed"
 },
 "493": {
  "name": "doc",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_allowed.py",
  "lineno": "69",
  "column": "4",
  "slicing": "[\"    doc = {'letters': [{'some': 'dict'}]}\\n\", '        doc,\\n']",
  "context": " https://github.com/pyeve/cerberus/issues/524\n    doc = {'letters': [{'some': 'dict'}]}\n    schema = {'letters': {'type': 'list', 'allowed"
 },
 "494": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_allowed.py",
  "lineno": "70",
  "column": "4",
  "slicing": "[\"    schema = {'letters': {'type': 'list', 'allowed': ['a', 'b', 'c']}}\\n\", '        schema,\\n']",
  "context": "524\n    doc = {'letters': [{'some': 'dict'}]}\n    schema = {'letters': {'type': 'list', 'allowed': ['a', 'b', 'c']}}\n\n    assert_fail(\n        doc,\n        schema,\n   "
 },
 "495": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_dependencies.py",
  "lineno": "8",
  "column": "4",
  "slicing": "['    schema = {\\n', \"    validator.validate({'field2': 7}, schema=schema)\\n\", \"    assert_success({'repo': 'somewhere', 'package': {'version': 1}}, schema)\\n\", '        schema,\\n', \"        document={'field': 'foobar', 'foo': 'foo', 'bar': 'bar'}, schema=schema\\n\", \"    schema['field']['required'] = False\\n\", \"    assert_success(document={'foo': 'bar', 'bar': 'foo'}, schema=schema)\\n\", '        schema=schema,\\n', \"    assert_fail(document={'field': 'foobar', 'a_dict': {}}, schema=schema)\\n\", \"    assert_fail(document={'field': 'foobar', 'a_dict': {'foo': 'foo'}}, schema=schema)\\n\"]",
  "context": "asic_error_handler_representation(validator):\n    schema = {\n        'field1': {'required': False},\n        'fi"
 },
 "496": {
  "name": "v",
  "type": "cerberus.Validator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_dependencies.py",
  "lineno": "20",
  "column": "4",
  "slicing": "['    schema = {\\n', \"    validator.validate({'field2': 7}, schema=schema)\\n\", '    expected_message = errors.BasicErrorHandler.messages[\\n', \"    assert validator.errors == {'field2': [expected_message]}\\n\", '    v = Validator(\\n', '        validator=v,\\n', \"    assert_success({'repo': 'somewhere', 'package': {'version': 1}}, schema)\\n\", '        schema,\\n', \"        document={'field': 'foobar', 'foo': 'foo', 'bar': 'bar'}, schema=schema\\n\", \"    schema['field']['required'] = False\\n\", \"    assert_success(document={'foo': 'bar', 'bar': 'foo'}, schema=schema)\\n\", '        schema=schema,\\n', \"    assert_fail(document={'field': 'foobar', 'a_dict': {}}, schema=schema)\\n\", \"    assert_fail(document={'field': 'foobar', 'a_dict': {'foo': 'foo'}}, schema=schema)\\n\"]",
  "context": "d_message]}\n\n\ndef test_dependencies_errors():\n    v = Validator(\n        {\n            'field1': {'required': False"
 },
 "497": {
  "name": "subschema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_dependencies.py",
  "lineno": "144",
  "column": "4",
  "slicing": "['    schema = {\\n', \"    validator.validate({'field2': 7}, schema=schema)\\n\", '    expected_message = errors.BasicErrorHandler.messages[\\n', \"    assert validator.errors == {'field2': [expected_message]}\\n\", '    v = Validator(\\n', '        validator=v,\\n', \"    subschema = {'version': {'dependencies': ('^repo',)}}\\n\", \"    schema = {'package': {'allow_unknown': True, 'schema': subschema}, 'repo': {}}\\n\", \"    assert_success({'repo': 'somewhere', 'package': {'version': 1}}, schema)\\n\", '        schema,\\n', \"        error=('package', ('package', 'schema'), errors.SCHEMA, subschema),\\n\", \"        document={'field': 'foobar', 'foo': 'foo', 'bar': 'bar'}, schema=schema\\n\", \"    schema['field']['required'] = False\\n\", \"    assert_success(document={'foo': 'bar', 'bar': 'foo'}, schema=schema)\\n\", '        schema=schema,\\n', \"    assert_fail(document={'field': 'foobar', 'a_dict': {}}, schema=schema)\\n\", \"    assert_fail(document={'field': 'foobar', 'a_dict': {'foo': 'foo'}}, schema=schema)\\n\"]",
  "context": " https://github.com/pyeve/cerberus/issues/288\n    subschema = {'version': {'dependencies': ('^repo',)}}\n    schema = {'package': {'allow_unknown': True, '"
 },
 "498": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_dependencies.py",
  "lineno": "145",
  "column": "4",
  "slicing": "['    schema = {\\n', \"    validator.validate({'field2': 7}, schema=schema)\\n\", '    expected_message = errors.BasicErrorHandler.messages[\\n', \"    assert validator.errors == {'field2': [expected_message]}\\n\", '    v = Validator(\\n', '        validator=v,\\n', \"    subschema = {'version': {'dependencies': ('^repo',)}}\\n\", \"    schema = {'package': {'allow_unknown': True, 'schema': subschema}, 'repo': {}}\\n\", \"    assert_success({'repo': 'somewhere', 'package': {'version': 1}}, schema)\\n\", '        schema,\\n', \"        error=('package', ('package', 'schema'), errors.SCHEMA, subschema),\\n\", \"        document={'field': 'foobar', 'foo': 'foo', 'bar': 'bar'}, schema=schema\\n\", \"    schema['field']['required'] = False\\n\", \"    assert_success(document={'foo': 'bar', 'bar': 'foo'}, schema=schema)\\n\", '        schema=schema,\\n', \"    assert_fail(document={'field': 'foobar', 'a_dict': {}}, schema=schema)\\n\", \"    assert_fail(document={'field': 'foobar', 'a_dict': {'foo': 'foo'}}, schema=schema)\\n\"]",
  "context": "a = {'version': {'dependencies': ('^repo',)}}\n    schema = {'package': {'allow_unknown': True, 'schema': subschema}, 'repo': {}}\n\n    assert_success({'repo': 'somewhere', 'package"
 },
 "499": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_dependencies.py",
  "lineno": "248",
  "column": "4",
  "slicing": "['    schema = {\\n', \"        document={'field': 'foobar', 'foo': 'foo', 'bar': 'bar'}, schema=schema\\n\", \"    schema['field']['required'] = False\\n\", \"    assert_success(document={'foo': 'bar', 'bar': 'foo'}, schema=schema)\\n\", '        schema=schema,\\n', \"    assert_fail(document={'field': 'foobar', 'a_dict': {}}, schema=schema)\\n\", \"    assert_fail(document={'field': 'foobar', 'a_dict': {'foo': 'foo'}}, schema=schema)\\n\"]",
  "context": "_required_rule_and_required_value_succeeds():\n    schema = {\n        'field': {'required': True, 'dependencies'"
 },
 "500": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_dependencies.py",
  "lineno": "294",
  "column": "4",
  "slicing": "['    schema = {\\n', '        schema=schema,\\n', \"    assert_fail(document={'field': 'foobar', 'a_dict': {}}, schema=schema)\\n\", \"    assert_fail(document={'field': 'foobar', 'a_dict': {'foo': 'foo'}}, schema=schema)\\n\"]",
  "context": "ar'},\n    )\n\n\ndef test_nested_dependencies():\n    schema = {\n        'field': {'dependencies': ['a_dict.foo', '"
 },
 "501": {
  "name": "validator",
  "type": "cerberus.Validator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_default.py",
  "lineno": "120",
  "column": "4",
  "slicing": "['    validator = Validator(\\n', '        validator=validator,\\n']",
  "context": "_default_in_schema_in_allow_unknown(default):\n    validator = Validator(\n        allow_unknown={\n            'type': 'dict'"
 },
 "502": {
  "name": "valid_parts",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_type.py",
  "lineno": "115",
  "column": "4",
  "slicing": "['    valid_parts = [\\n', \"        schema={'part': {'type': ['dict', 'string'], 'anyof': valid_parts}},\\n\"]",
  "context": "ing',)),\n    )\n\n\ndef test_type_skips_anyof():\n    valid_parts = [\n        {'schema': {'model number': {'type': 'stri"
 },
 "503": {
  "name": "_errors",
  "type": "cerberus.tests.assert_fail",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_type.py",
  "lineno": "119",
  "column": "4",
  "slicing": "['    valid_parts = [\\n', '    _errors = assert_fail(\\n', \"        schema={'part': {'type': ['dict', 'string'], 'anyof': valid_parts}},\\n\", '    assert len(_errors) == 1\\n']",
  "context": "ring'}, 'count': {'type': 'integer'}}},\n    ]\n    _errors = assert_fail(\n        schema={'part': {'type': ['dict', 'string'"
 },
 "504": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_rule_keysrules.py",
  "lineno": "5",
  "column": "4",
  "slicing": "['    schema = {\\n', \"    assert_success({'a_dict_with_keysrules': {'key': 'value'}}, schema=schema)\\n\", \"    assert_fail({'a_dict_with_keysrules': {'KEY': 'value'}}, schema=schema)\\n\"]",
  "context": "_fail, assert_success\n\n\ndef test_keysrules():\n    schema = {\n        'a_dict_with_keysrules': {\n            'ty"
 },
 "505": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_validation.py",
  "lineno": "40",
  "column": "4",
  "slicing": "['    document = \"not a dict\"\\n', '        document, sample_schema, None, errors.DOCUMENT_FORMAT.format(document)\\n', \"    field = 'surname'\\n\", \"        {field: 'doe'},\\n\", '        error=(field, (), errors.UNKNOWN_FIELD, None),\\n', \"    assert validator.errors == {field: ['unknown field']}\\n\", \"    field = 'name'\\n\", '    schema = {field: {}}\\n', '    assert_success(document, schema)\\n', \"    field = 'a_dict_with_valuesrules'\\n\", \"    schema_field = 'a_string'\\n\", \"    value = {schema_field: 'not an integer'}\\n\", '    exp_child_errors = [\\n', '            (field, schema_field),\\n', \"            (field, 'valuesrules', 'type'),\\n\", '        {field: value},\\n', '            field,\\n', \"            (field, 'valuesrules'),\\n\", '        child_errors=exp_child_errors,\\n', '    assert_success(document)\\n', \"    field = 'one_or_more_strings'\\n\", \"    assert_success({field: 'foo'})\\n\", \"    assert_success({field: ['foo', 'bar']})\\n\", '    exp_child_errors = [\\n', \"        ((field, 1), (field, 'itemsrules', 'type'), errors.TYPE, ('string',))\\n\", \"        {field: ['foo', 23]},\\n\", \"        error=(field, (field, 'itemsrules'), errors.ITEMSRULES, {'type': ('string',)}),\\n\", '        child_errors=exp_child_errors,\\n', \"        {field: 23}, error=((field,), (field, 'type'), errors.TYPE, ('string', 'list'))\\n\", '        field: [{1: [\"must be one of these types: (\\'string\\',)\"]}]\\n', '            if isodd and not bool(value & 1):\\n', \"                self._error(field, 'Not an odd number')\\n\", \"    schema = {'test_field': {'isodd': True}}\\n\", '    validator = MyValidator(schema)\\n', \"    assert_success({'test_field': 7}, validator=validator)\\n\", '        validator=validator,\\n', \"    assert validator.errors == {'test_field': ['Not an odd number']}\\n\", \"    field = 'test'\\n\", \"    schema = {field: {'type': ('string',), 'empty': False, 'required': False}}\\n\", '    document = {field: None}\\n', '    validator = Validator(schema, ignore_none_values=False)\\n', '    assert_fail(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", '    validator.schema.validate()\\n', '    _errors = assert_fail(document, validator=validator)\\n', \"        _errors, field, (field, 'required'), errors.REQUIRED_FIELD, True\\n\", '    validator = Validator(schema, ignore_none_values=True)\\n', \"    validator.schema[field]['required'] = False\\n\", '    validator.schema.validate()\\n', '    assert_success(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", \"    assert validator.schema[field].get('required') is True\\n\", '    _errors = assert_fail(document=document, validator=validator)\\n', \"    assert_has_error(_errors, field, (field, 'required'), errors.REQUIRED_FIELD, True)\\n\", \"    assert_not_has_error(_errors, field, (field, 'type'), errors.TYPE, 'string')\\n\", '    schema = {}\\n', '    v = Validator(allow_unknown=True, schema=schema)\\n', '    assert_success({\"unknown1\": True, \"unknown2\": \"yes\"}, validator=v)\\n', \"    v.allow_unknown = {'type': 'string'}\\n\", \"    assert_success(document={'name': 'mark'}, validator=v)\\n\", '    assert_fail({\"name\": 1}, validator=v)\\n', '    v.allow_unknown = False\\n', \"    assert_fail({'name': 'mark'}, validator=v)\\n\", '    validator.allow_unknown = True\\n', \"    document = {'a_dict': {'foo': 'foo_value', 'bar': 25}}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_dict': ['foo', 'bar']}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_list_of_dicts': [{'sku': 'YZ069', 'price': 25, 'extra': True}]}\\n\", '    assert_success(document, validator=validator)\\n', '            return value == \"foo\"\\n', '    validator = CustomValidator({})\\n', '    validator.allow_unknown = {\"check_with\": \"foo\"}\\n', '    assert_success(document={\"fred\": \"foo\", \"barney\": \"foo\"}, validator=validator)\\n', \"    schema = {'test_field': {'type': 'string'}}\\n\", '    validator = Validator(schema)\\n', \"    assert validator.validate({'test_field': 'foo'})\\n\", \"    assert validator({'test_field': 'foo'})\\n\", \"    assert not validator.validate({'test_field': 1})\\n\", \"    assert not validator({'test_field': 1})\\n\", \"                self._error(field, 'self.context is not the root doc!')\\n\", '    schema = {\\n', \"        {'sub': [{'foo': 'bar'}, {'foo': 'baz'}]}, validator=MyValidator(schema)\\n\", \"    validator.schema = {'property': {'type': 'string'}}\\n\", \"    document = {'property': 'string'}\\n\", '    assert validator.validated(document) == document\\n', \"    document = {'property': 0}\\n\", '    assert validator.validated(document) is None\\n', '    schema = {\\n', \"    document = {'info': {'name': 'my name'}}\\n\", '    assert_success(document, schema, validator=validator)\\n', '    v = Validator(schema)\\n', '    assert_success(document, schema, v)\\n', '    assert v.validate(document)\\n', '    assert_success(document, schema, validator=v)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = True\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({\"foo\": {\"bar\": \"baz\"}}, schema, validator)\\n', '        assert_fail({}, schema, validator)\\n', '        assert_success({}, schema, validator)\\n', '        assert_fail({\"foo\": {}}, schema, validator)\\n', '        assert_success({\"foo\": {}}, schema, validator)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    assert validator.errors == {}\\n']",
  "context": "ield_definition(document):\n    field = 'name'\n    schema = {field: {}}\n    assert_success(document, schema)\n\n\ndef test_ba"
 },
 "506": {
  "name": "value",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_validation.py",
  "lineno": "47",
  "column": "4",
  "slicing": "['    document = \"not a dict\"\\n', '        document, sample_schema, None, errors.DOCUMENT_FORMAT.format(document)\\n', \"    field = 'surname'\\n\", \"        {field: 'doe'},\\n\", '        error=(field, (), errors.UNKNOWN_FIELD, None),\\n', \"    assert validator.errors == {field: ['unknown field']}\\n\", \"    field = 'name'\\n\", '    schema = {field: {}}\\n', '    assert_success(document, schema)\\n', \"    field = 'a_dict_with_valuesrules'\\n\", \"    schema_field = 'a_string'\\n\", \"    value = {schema_field: 'not an integer'}\\n\", '    exp_child_errors = [\\n', '            (field, schema_field),\\n', \"            (field, 'valuesrules', 'type'),\\n\", '        {field: value},\\n', '            field,\\n', \"            (field, 'valuesrules'),\\n\", '        child_errors=exp_child_errors,\\n', '    assert_success(document)\\n', \"    field = 'one_or_more_strings'\\n\", \"    assert_success({field: 'foo'})\\n\", \"    assert_success({field: ['foo', 'bar']})\\n\", '    exp_child_errors = [\\n', \"        ((field, 1), (field, 'itemsrules', 'type'), errors.TYPE, ('string',))\\n\", \"        {field: ['foo', 23]},\\n\", \"        error=(field, (field, 'itemsrules'), errors.ITEMSRULES, {'type': ('string',)}),\\n\", '        child_errors=exp_child_errors,\\n', \"        {field: 23}, error=((field,), (field, 'type'), errors.TYPE, ('string', 'list'))\\n\", '        field: [{1: [\"must be one of these types: (\\'string\\',)\"]}]\\n', '            if isodd and not bool(value & 1):\\n', \"                self._error(field, 'Not an odd number')\\n\", \"    schema = {'test_field': {'isodd': True}}\\n\", '    validator = MyValidator(schema)\\n', \"    assert_success({'test_field': 7}, validator=validator)\\n\", '        validator=validator,\\n', \"    assert validator.errors == {'test_field': ['Not an odd number']}\\n\", \"    field = 'test'\\n\", \"    schema = {field: {'type': ('string',), 'empty': False, 'required': False}}\\n\", '    document = {field: None}\\n', '    validator = Validator(schema, ignore_none_values=False)\\n', '    assert_fail(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", '    validator.schema.validate()\\n', '    _errors = assert_fail(document, validator=validator)\\n', \"        _errors, field, (field, 'required'), errors.REQUIRED_FIELD, True\\n\", '    validator = Validator(schema, ignore_none_values=True)\\n', \"    validator.schema[field]['required'] = False\\n\", '    validator.schema.validate()\\n', '    assert_success(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", \"    assert validator.schema[field].get('required') is True\\n\", '    _errors = assert_fail(document=document, validator=validator)\\n', \"    assert_has_error(_errors, field, (field, 'required'), errors.REQUIRED_FIELD, True)\\n\", \"    assert_not_has_error(_errors, field, (field, 'type'), errors.TYPE, 'string')\\n\", '    schema = {}\\n', '    v = Validator(allow_unknown=True, schema=schema)\\n', '    assert_success({\"unknown1\": True, \"unknown2\": \"yes\"}, validator=v)\\n', \"    v.allow_unknown = {'type': 'string'}\\n\", \"    assert_success(document={'name': 'mark'}, validator=v)\\n\", '    assert_fail({\"name\": 1}, validator=v)\\n', '    v.allow_unknown = False\\n', \"    assert_fail({'name': 'mark'}, validator=v)\\n\", '    validator.allow_unknown = True\\n', \"    document = {'a_dict': {'foo': 'foo_value', 'bar': 25}}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_dict': ['foo', 'bar']}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_list_of_dicts': [{'sku': 'YZ069', 'price': 25, 'extra': True}]}\\n\", '    assert_success(document, validator=validator)\\n', '            return value == \"foo\"\\n', '    validator = CustomValidator({})\\n', '    validator.allow_unknown = {\"check_with\": \"foo\"}\\n', '    assert_success(document={\"fred\": \"foo\", \"barney\": \"foo\"}, validator=validator)\\n', \"    schema = {'test_field': {'type': 'string'}}\\n\", '    validator = Validator(schema)\\n', \"    assert validator.validate({'test_field': 'foo'})\\n\", \"    assert validator({'test_field': 'foo'})\\n\", \"    assert not validator.validate({'test_field': 1})\\n\", \"    assert not validator({'test_field': 1})\\n\", \"                self._error(field, 'self.context is not the root doc!')\\n\", '    schema = {\\n', \"        {'sub': [{'foo': 'bar'}, {'foo': 'baz'}]}, validator=MyValidator(schema)\\n\", \"    validator.schema = {'property': {'type': 'string'}}\\n\", \"    document = {'property': 'string'}\\n\", '    assert validator.validated(document) == document\\n', \"    document = {'property': 0}\\n\", '    assert validator.validated(document) is None\\n', '    schema = {\\n', \"    document = {'info': {'name': 'my name'}}\\n\", '    assert_success(document, schema, validator=validator)\\n', '    v = Validator(schema)\\n', '    assert_success(document, schema, v)\\n', '    assert v.validate(document)\\n', '    assert_success(document, schema, validator=v)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = True\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({\"foo\": {\"bar\": \"baz\"}}, schema, validator)\\n', '        assert_fail({}, schema, validator)\\n', '        assert_success({}, schema, validator)\\n', '        assert_fail({\"foo\": {}}, schema, validator)\\n', '        assert_success({\"foo\": {}}, schema, validator)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    assert validator.errors == {}\\n']",
  "context": "th_valuesrules'\n    schema_field = 'a_string'\n    value = {schema_field: 'not an integer'}\n\n    exp_child_errors = [\n        (\n            (f"
 },
 "507": {
  "name": "exp_child_errors",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_validation.py",
  "lineno": "49",
  "column": "4",
  "slicing": "['    exp_child_errors = [\\n', '        child_errors=exp_child_errors,\\n', '        child_errors=exp_child_errors,\\n']",
  "context": "    value = {schema_field: 'not an integer'}\n\n    exp_child_errors = [\n        (\n            (field, schema_field),\n     "
 },
 "508": {
  "name": "exp_child_errors",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_validation.py",
  "lineno": "110",
  "column": "4",
  "slicing": "['    exp_child_errors = [\\n', '        child_errors=exp_child_errors,\\n']",
  "context": ")\n    assert_success({field: ['foo', 'bar']})\n    exp_child_errors = [\n        ((field, 1), (field, 'itemsrules', 'type')"
 },
 "509": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_validation.py",
  "lineno": "134",
  "column": "4",
  "slicing": "['    document = \"not a dict\"\\n', '        document, sample_schema, None, errors.DOCUMENT_FORMAT.format(document)\\n', \"    field = 'surname'\\n\", \"        {field: 'doe'},\\n\", '        error=(field, (), errors.UNKNOWN_FIELD, None),\\n', \"    assert validator.errors == {field: ['unknown field']}\\n\", \"    field = 'name'\\n\", '    schema = {field: {}}\\n', '    assert_success(document, schema)\\n', \"    field = 'a_dict_with_valuesrules'\\n\", \"    schema_field = 'a_string'\\n\", \"    value = {schema_field: 'not an integer'}\\n\", '    exp_child_errors = [\\n', '            (field, schema_field),\\n', \"            (field, 'valuesrules', 'type'),\\n\", '        {field: value},\\n', '            field,\\n', \"            (field, 'valuesrules'),\\n\", '        child_errors=exp_child_errors,\\n', '    assert_success(document)\\n', \"    field = 'one_or_more_strings'\\n\", \"    assert_success({field: 'foo'})\\n\", \"    assert_success({field: ['foo', 'bar']})\\n\", '    exp_child_errors = [\\n', \"        ((field, 1), (field, 'itemsrules', 'type'), errors.TYPE, ('string',))\\n\", \"        {field: ['foo', 23]},\\n\", \"        error=(field, (field, 'itemsrules'), errors.ITEMSRULES, {'type': ('string',)}),\\n\", '        child_errors=exp_child_errors,\\n', \"        {field: 23}, error=((field,), (field, 'type'), errors.TYPE, ('string', 'list'))\\n\", '        field: [{1: [\"must be one of these types: (\\'string\\',)\"]}]\\n', '            if isodd and not bool(value & 1):\\n', \"                self._error(field, 'Not an odd number')\\n\", \"    schema = {'test_field': {'isodd': True}}\\n\", '    validator = MyValidator(schema)\\n', \"    assert_success({'test_field': 7}, validator=validator)\\n\", '        validator=validator,\\n', \"    assert validator.errors == {'test_field': ['Not an odd number']}\\n\", \"    field = 'test'\\n\", \"    schema = {field: {'type': ('string',), 'empty': False, 'required': False}}\\n\", '    document = {field: None}\\n', '    validator = Validator(schema, ignore_none_values=False)\\n', '    assert_fail(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", '    validator.schema.validate()\\n', '    _errors = assert_fail(document, validator=validator)\\n', \"        _errors, field, (field, 'required'), errors.REQUIRED_FIELD, True\\n\", '    validator = Validator(schema, ignore_none_values=True)\\n', \"    validator.schema[field]['required'] = False\\n\", '    validator.schema.validate()\\n', '    assert_success(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", \"    assert validator.schema[field].get('required') is True\\n\", '    _errors = assert_fail(document=document, validator=validator)\\n', \"    assert_has_error(_errors, field, (field, 'required'), errors.REQUIRED_FIELD, True)\\n\", \"    assert_not_has_error(_errors, field, (field, 'type'), errors.TYPE, 'string')\\n\", '    schema = {}\\n', '    v = Validator(allow_unknown=True, schema=schema)\\n', '    assert_success({\"unknown1\": True, \"unknown2\": \"yes\"}, validator=v)\\n', \"    v.allow_unknown = {'type': 'string'}\\n\", \"    assert_success(document={'name': 'mark'}, validator=v)\\n\", '    assert_fail({\"name\": 1}, validator=v)\\n', '    v.allow_unknown = False\\n', \"    assert_fail({'name': 'mark'}, validator=v)\\n\", '    validator.allow_unknown = True\\n', \"    document = {'a_dict': {'foo': 'foo_value', 'bar': 25}}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_dict': ['foo', 'bar']}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_list_of_dicts': [{'sku': 'YZ069', 'price': 25, 'extra': True}]}\\n\", '    assert_success(document, validator=validator)\\n', '            return value == \"foo\"\\n', '    validator = CustomValidator({})\\n', '    validator.allow_unknown = {\"check_with\": \"foo\"}\\n', '    assert_success(document={\"fred\": \"foo\", \"barney\": \"foo\"}, validator=validator)\\n', \"    schema = {'test_field': {'type': 'string'}}\\n\", '    validator = Validator(schema)\\n', \"    assert validator.validate({'test_field': 'foo'})\\n\", \"    assert validator({'test_field': 'foo'})\\n\", \"    assert not validator.validate({'test_field': 1})\\n\", \"    assert not validator({'test_field': 1})\\n\", \"                self._error(field, 'self.context is not the root doc!')\\n\", '    schema = {\\n', \"        {'sub': [{'foo': 'bar'}, {'foo': 'baz'}]}, validator=MyValidator(schema)\\n\", \"    validator.schema = {'property': {'type': 'string'}}\\n\", \"    document = {'property': 'string'}\\n\", '    assert validator.validated(document) == document\\n', \"    document = {'property': 0}\\n\", '    assert validator.validated(document) is None\\n', '    schema = {\\n', \"    document = {'info': {'name': 'my name'}}\\n\", '    assert_success(document, schema, validator=validator)\\n', '    v = Validator(schema)\\n', '    assert_success(document, schema, v)\\n', '    assert v.validate(document)\\n', '    assert_success(document, schema, validator=v)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = True\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({\"foo\": {\"bar\": \"baz\"}}, schema, validator)\\n', '        assert_fail({}, schema, validator)\\n', '        assert_success({}, schema, validator)\\n', '        assert_fail({\"foo\": {}}, schema, validator)\\n', '        assert_success({\"foo\": {}}, schema, validator)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    assert validator.errors == {}\\n']",
  "context": "     self._error(field, 'Not an odd number')\n\n    schema = {'test_field': {'isodd': True}}\n    validator = MyValidator(schema)\n    assert_suc"
 },
 "510": {
  "name": "validator",
  "type": "MyValidator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_validation.py",
  "lineno": "135",
  "column": "4",
  "slicing": "['    document = \"not a dict\"\\n', '        document, sample_schema, None, errors.DOCUMENT_FORMAT.format(document)\\n', \"    field = 'surname'\\n\", \"        {field: 'doe'},\\n\", '        error=(field, (), errors.UNKNOWN_FIELD, None),\\n', \"    assert validator.errors == {field: ['unknown field']}\\n\", \"    field = 'name'\\n\", '    schema = {field: {}}\\n', '    assert_success(document, schema)\\n', \"    field = 'a_dict_with_valuesrules'\\n\", \"    schema_field = 'a_string'\\n\", \"    value = {schema_field: 'not an integer'}\\n\", '    exp_child_errors = [\\n', '            (field, schema_field),\\n', \"            (field, 'valuesrules', 'type'),\\n\", '        {field: value},\\n', '            field,\\n', \"            (field, 'valuesrules'),\\n\", '        child_errors=exp_child_errors,\\n', '    assert_success(document)\\n', \"    field = 'one_or_more_strings'\\n\", \"    assert_success({field: 'foo'})\\n\", \"    assert_success({field: ['foo', 'bar']})\\n\", '    exp_child_errors = [\\n', \"        ((field, 1), (field, 'itemsrules', 'type'), errors.TYPE, ('string',))\\n\", \"        {field: ['foo', 23]},\\n\", \"        error=(field, (field, 'itemsrules'), errors.ITEMSRULES, {'type': ('string',)}),\\n\", '        child_errors=exp_child_errors,\\n', \"        {field: 23}, error=((field,), (field, 'type'), errors.TYPE, ('string', 'list'))\\n\", '        field: [{1: [\"must be one of these types: (\\'string\\',)\"]}]\\n', '            if isodd and not bool(value & 1):\\n', \"                self._error(field, 'Not an odd number')\\n\", \"    schema = {'test_field': {'isodd': True}}\\n\", '    validator = MyValidator(schema)\\n', \"    assert_success({'test_field': 7}, validator=validator)\\n\", '        validator=validator,\\n', \"    assert validator.errors == {'test_field': ['Not an odd number']}\\n\", \"    field = 'test'\\n\", \"    schema = {field: {'type': ('string',), 'empty': False, 'required': False}}\\n\", '    document = {field: None}\\n', '    validator = Validator(schema, ignore_none_values=False)\\n', '    assert_fail(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", '    validator.schema.validate()\\n', '    _errors = assert_fail(document, validator=validator)\\n', \"        _errors, field, (field, 'required'), errors.REQUIRED_FIELD, True\\n\", '    validator = Validator(schema, ignore_none_values=True)\\n', \"    validator.schema[field]['required'] = False\\n\", '    validator.schema.validate()\\n', '    assert_success(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", \"    assert validator.schema[field].get('required') is True\\n\", '    _errors = assert_fail(document=document, validator=validator)\\n', \"    assert_has_error(_errors, field, (field, 'required'), errors.REQUIRED_FIELD, True)\\n\", \"    assert_not_has_error(_errors, field, (field, 'type'), errors.TYPE, 'string')\\n\", '    schema = {}\\n', '    v = Validator(allow_unknown=True, schema=schema)\\n', '    assert_success({\"unknown1\": True, \"unknown2\": \"yes\"}, validator=v)\\n', \"    v.allow_unknown = {'type': 'string'}\\n\", \"    assert_success(document={'name': 'mark'}, validator=v)\\n\", '    assert_fail({\"name\": 1}, validator=v)\\n', '    v.allow_unknown = False\\n', \"    assert_fail({'name': 'mark'}, validator=v)\\n\", '    validator.allow_unknown = True\\n', \"    document = {'a_dict': {'foo': 'foo_value', 'bar': 25}}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_dict': ['foo', 'bar']}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_list_of_dicts': [{'sku': 'YZ069', 'price': 25, 'extra': True}]}\\n\", '    assert_success(document, validator=validator)\\n', '            return value == \"foo\"\\n', '    validator = CustomValidator({})\\n', '    validator.allow_unknown = {\"check_with\": \"foo\"}\\n', '    assert_success(document={\"fred\": \"foo\", \"barney\": \"foo\"}, validator=validator)\\n', \"    schema = {'test_field': {'type': 'string'}}\\n\", '    validator = Validator(schema)\\n', \"    assert validator.validate({'test_field': 'foo'})\\n\", \"    assert validator({'test_field': 'foo'})\\n\", \"    assert not validator.validate({'test_field': 1})\\n\", \"    assert not validator({'test_field': 1})\\n\", \"                self._error(field, 'self.context is not the root doc!')\\n\", '    schema = {\\n', \"        {'sub': [{'foo': 'bar'}, {'foo': 'baz'}]}, validator=MyValidator(schema)\\n\", \"    validator.schema = {'property': {'type': 'string'}}\\n\", \"    document = {'property': 'string'}\\n\", '    assert validator.validated(document) == document\\n', \"    document = {'property': 0}\\n\", '    assert validator.validated(document) is None\\n', '    schema = {\\n', \"    document = {'info': {'name': 'my name'}}\\n\", '    assert_success(document, schema, validator=validator)\\n', '    v = Validator(schema)\\n', '    assert_success(document, schema, v)\\n', '    assert v.validate(document)\\n', '    assert_success(document, schema, validator=v)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = True\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({\"foo\": {\"bar\": \"baz\"}}, schema, validator)\\n', '        assert_fail({}, schema, validator)\\n', '        assert_success({}, schema, validator)\\n', '        assert_fail({\"foo\": {}}, schema, validator)\\n', '        assert_success({\"foo\": {}}, schema, validator)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    assert validator.errors == {}\\n']",
  "context": "\n    schema = {'test_field': {'isodd': True}}\n    validator = MyValidator(schema)\n    assert_success({'test_field': 7}, validator=va"
 },
 "511": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_validation.py",
  "lineno": "151",
  "column": "4",
  "slicing": "['    document = \"not a dict\"\\n', '        document, sample_schema, None, errors.DOCUMENT_FORMAT.format(document)\\n', \"    field = 'surname'\\n\", \"        {field: 'doe'},\\n\", '        error=(field, (), errors.UNKNOWN_FIELD, None),\\n', \"    assert validator.errors == {field: ['unknown field']}\\n\", \"    field = 'name'\\n\", '    schema = {field: {}}\\n', '    assert_success(document, schema)\\n', \"    field = 'a_dict_with_valuesrules'\\n\", \"    schema_field = 'a_string'\\n\", \"    value = {schema_field: 'not an integer'}\\n\", '    exp_child_errors = [\\n', '            (field, schema_field),\\n', \"            (field, 'valuesrules', 'type'),\\n\", '        {field: value},\\n', '            field,\\n', \"            (field, 'valuesrules'),\\n\", '        child_errors=exp_child_errors,\\n', '    assert_success(document)\\n', \"    field = 'one_or_more_strings'\\n\", \"    assert_success({field: 'foo'})\\n\", \"    assert_success({field: ['foo', 'bar']})\\n\", '    exp_child_errors = [\\n', \"        ((field, 1), (field, 'itemsrules', 'type'), errors.TYPE, ('string',))\\n\", \"        {field: ['foo', 23]},\\n\", \"        error=(field, (field, 'itemsrules'), errors.ITEMSRULES, {'type': ('string',)}),\\n\", '        child_errors=exp_child_errors,\\n', \"        {field: 23}, error=((field,), (field, 'type'), errors.TYPE, ('string', 'list'))\\n\", '        field: [{1: [\"must be one of these types: (\\'string\\',)\"]}]\\n', '            if isodd and not bool(value & 1):\\n', \"                self._error(field, 'Not an odd number')\\n\", \"    schema = {'test_field': {'isodd': True}}\\n\", '    validator = MyValidator(schema)\\n', \"    assert_success({'test_field': 7}, validator=validator)\\n\", '        validator=validator,\\n', \"    assert validator.errors == {'test_field': ['Not an odd number']}\\n\", \"    field = 'test'\\n\", \"    schema = {field: {'type': ('string',), 'empty': False, 'required': False}}\\n\", '    document = {field: None}\\n', '    validator = Validator(schema, ignore_none_values=False)\\n', '    assert_fail(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", '    validator.schema.validate()\\n', '    _errors = assert_fail(document, validator=validator)\\n', \"        _errors, field, (field, 'required'), errors.REQUIRED_FIELD, True\\n\", '    validator = Validator(schema, ignore_none_values=True)\\n', \"    validator.schema[field]['required'] = False\\n\", '    validator.schema.validate()\\n', '    assert_success(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", \"    assert validator.schema[field].get('required') is True\\n\", '    _errors = assert_fail(document=document, validator=validator)\\n', \"    assert_has_error(_errors, field, (field, 'required'), errors.REQUIRED_FIELD, True)\\n\", \"    assert_not_has_error(_errors, field, (field, 'type'), errors.TYPE, 'string')\\n\", '    schema = {}\\n', '    v = Validator(allow_unknown=True, schema=schema)\\n', '    assert_success({\"unknown1\": True, \"unknown2\": \"yes\"}, validator=v)\\n', \"    v.allow_unknown = {'type': 'string'}\\n\", \"    assert_success(document={'name': 'mark'}, validator=v)\\n\", '    assert_fail({\"name\": 1}, validator=v)\\n', '    v.allow_unknown = False\\n', \"    assert_fail({'name': 'mark'}, validator=v)\\n\", '    validator.allow_unknown = True\\n', \"    document = {'a_dict': {'foo': 'foo_value', 'bar': 25}}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_dict': ['foo', 'bar']}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_list_of_dicts': [{'sku': 'YZ069', 'price': 25, 'extra': True}]}\\n\", '    assert_success(document, validator=validator)\\n', '            return value == \"foo\"\\n', '    validator = CustomValidator({})\\n', '    validator.allow_unknown = {\"check_with\": \"foo\"}\\n', '    assert_success(document={\"fred\": \"foo\", \"barney\": \"foo\"}, validator=validator)\\n', \"    schema = {'test_field': {'type': 'string'}}\\n\", '    validator = Validator(schema)\\n', \"    assert validator.validate({'test_field': 'foo'})\\n\", \"    assert validator({'test_field': 'foo'})\\n\", \"    assert not validator.validate({'test_field': 1})\\n\", \"    assert not validator({'test_field': 1})\\n\", \"                self._error(field, 'self.context is not the root doc!')\\n\", '    schema = {\\n', \"        {'sub': [{'foo': 'bar'}, {'foo': 'baz'}]}, validator=MyValidator(schema)\\n\", \"    validator.schema = {'property': {'type': 'string'}}\\n\", \"    document = {'property': 'string'}\\n\", '    assert validator.validated(document) == document\\n', \"    document = {'property': 0}\\n\", '    assert validator.validated(document) is None\\n', '    schema = {\\n', \"    document = {'info': {'name': 'my name'}}\\n\", '    assert_success(document, schema, validator=validator)\\n', '    v = Validator(schema)\\n', '    assert_success(document, schema, v)\\n', '    assert v.validate(document)\\n', '    assert_success(document, schema, validator=v)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = True\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({\"foo\": {\"bar\": \"baz\"}}, schema, validator)\\n', '        assert_fail({}, schema, validator)\\n', '        assert_success({}, schema, validator)\\n', '        assert_fail({\"foo\": {}}, schema, validator)\\n', '        assert_success({\"foo\": {}}, schema, validator)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    assert validator.errors == {}\\n']",
  "context": "67673716cb6e4e929fa9d7b77\n\n    field = 'test'\n    schema = {field: {'type': ('string',), 'empty': False, 'required': False}}\n    document = {field: None}\n\n    # Test normal be"
 },
 "512": {
  "name": "document",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_validation.py",
  "lineno": "152",
  "column": "4",
  "slicing": "['    document = \"not a dict\"\\n', '        document, sample_schema, None, errors.DOCUMENT_FORMAT.format(document)\\n', \"    field = 'surname'\\n\", \"        {field: 'doe'},\\n\", '        error=(field, (), errors.UNKNOWN_FIELD, None),\\n', \"    assert validator.errors == {field: ['unknown field']}\\n\", \"    field = 'name'\\n\", '    schema = {field: {}}\\n', '    assert_success(document, schema)\\n', \"    field = 'a_dict_with_valuesrules'\\n\", \"    schema_field = 'a_string'\\n\", \"    value = {schema_field: 'not an integer'}\\n\", '    exp_child_errors = [\\n', '            (field, schema_field),\\n', \"            (field, 'valuesrules', 'type'),\\n\", '        {field: value},\\n', '            field,\\n', \"            (field, 'valuesrules'),\\n\", '        child_errors=exp_child_errors,\\n', '    assert_success(document)\\n', \"    field = 'one_or_more_strings'\\n\", \"    assert_success({field: 'foo'})\\n\", \"    assert_success({field: ['foo', 'bar']})\\n\", '    exp_child_errors = [\\n', \"        ((field, 1), (field, 'itemsrules', 'type'), errors.TYPE, ('string',))\\n\", \"        {field: ['foo', 23]},\\n\", \"        error=(field, (field, 'itemsrules'), errors.ITEMSRULES, {'type': ('string',)}),\\n\", '        child_errors=exp_child_errors,\\n', \"        {field: 23}, error=((field,), (field, 'type'), errors.TYPE, ('string', 'list'))\\n\", '        field: [{1: [\"must be one of these types: (\\'string\\',)\"]}]\\n', '            if isodd and not bool(value & 1):\\n', \"                self._error(field, 'Not an odd number')\\n\", \"    schema = {'test_field': {'isodd': True}}\\n\", '    validator = MyValidator(schema)\\n', \"    assert_success({'test_field': 7}, validator=validator)\\n\", '        validator=validator,\\n', \"    assert validator.errors == {'test_field': ['Not an odd number']}\\n\", \"    field = 'test'\\n\", \"    schema = {field: {'type': ('string',), 'empty': False, 'required': False}}\\n\", '    document = {field: None}\\n', '    validator = Validator(schema, ignore_none_values=False)\\n', '    assert_fail(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", '    validator.schema.validate()\\n', '    _errors = assert_fail(document, validator=validator)\\n', \"        _errors, field, (field, 'required'), errors.REQUIRED_FIELD, True\\n\", '    validator = Validator(schema, ignore_none_values=True)\\n', \"    validator.schema[field]['required'] = False\\n\", '    validator.schema.validate()\\n', '    assert_success(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", \"    assert validator.schema[field].get('required') is True\\n\", '    _errors = assert_fail(document=document, validator=validator)\\n', \"    assert_has_error(_errors, field, (field, 'required'), errors.REQUIRED_FIELD, True)\\n\", \"    assert_not_has_error(_errors, field, (field, 'type'), errors.TYPE, 'string')\\n\", '    schema = {}\\n', '    v = Validator(allow_unknown=True, schema=schema)\\n', '    assert_success({\"unknown1\": True, \"unknown2\": \"yes\"}, validator=v)\\n', \"    v.allow_unknown = {'type': 'string'}\\n\", \"    assert_success(document={'name': 'mark'}, validator=v)\\n\", '    assert_fail({\"name\": 1}, validator=v)\\n', '    v.allow_unknown = False\\n', \"    assert_fail({'name': 'mark'}, validator=v)\\n\", '    validator.allow_unknown = True\\n', \"    document = {'a_dict': {'foo': 'foo_value', 'bar': 25}}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_dict': ['foo', 'bar']}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_list_of_dicts': [{'sku': 'YZ069', 'price': 25, 'extra': True}]}\\n\", '    assert_success(document, validator=validator)\\n', '            return value == \"foo\"\\n', '    validator = CustomValidator({})\\n', '    validator.allow_unknown = {\"check_with\": \"foo\"}\\n', '    assert_success(document={\"fred\": \"foo\", \"barney\": \"foo\"}, validator=validator)\\n', \"    schema = {'test_field': {'type': 'string'}}\\n\", '    validator = Validator(schema)\\n', \"    assert validator.validate({'test_field': 'foo'})\\n\", \"    assert validator({'test_field': 'foo'})\\n\", \"    assert not validator.validate({'test_field': 1})\\n\", \"    assert not validator({'test_field': 1})\\n\", \"                self._error(field, 'self.context is not the root doc!')\\n\", '    schema = {\\n', \"        {'sub': [{'foo': 'bar'}, {'foo': 'baz'}]}, validator=MyValidator(schema)\\n\", \"    validator.schema = {'property': {'type': 'string'}}\\n\", \"    document = {'property': 'string'}\\n\", '    assert validator.validated(document) == document\\n', \"    document = {'property': 0}\\n\", '    assert validator.validated(document) is None\\n', '    schema = {\\n', \"    document = {'info': {'name': 'my name'}}\\n\", '    assert_success(document, schema, validator=validator)\\n', '    v = Validator(schema)\\n', '    assert_success(document, schema, v)\\n', '    assert v.validate(document)\\n', '    assert_success(document, schema, validator=v)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = True\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({\"foo\": {\"bar\": \"baz\"}}, schema, validator)\\n', '        assert_fail({}, schema, validator)\\n', '        assert_success({}, schema, validator)\\n', '        assert_fail({\"foo\": {}}, schema, validator)\\n', '        assert_success({\"foo\": {}}, schema, validator)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    assert validator.errors == {}\\n']",
  "context": "tring',), 'empty': False, 'required': False}}\n    document = {field: None}\n\n    # Test normal behaviour\n    validator = Valid"
 },
 "513": {
  "name": "validator",
  "type": "cerberus.Validator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_validation.py",
  "lineno": "155",
  "column": "4",
  "slicing": "['    document = \"not a dict\"\\n', '        document, sample_schema, None, errors.DOCUMENT_FORMAT.format(document)\\n', \"    field = 'surname'\\n\", \"        {field: 'doe'},\\n\", '        error=(field, (), errors.UNKNOWN_FIELD, None),\\n', \"    assert validator.errors == {field: ['unknown field']}\\n\", \"    field = 'name'\\n\", '    schema = {field: {}}\\n', '    assert_success(document, schema)\\n', \"    field = 'a_dict_with_valuesrules'\\n\", \"    schema_field = 'a_string'\\n\", \"    value = {schema_field: 'not an integer'}\\n\", '    exp_child_errors = [\\n', '            (field, schema_field),\\n', \"            (field, 'valuesrules', 'type'),\\n\", '        {field: value},\\n', '            field,\\n', \"            (field, 'valuesrules'),\\n\", '        child_errors=exp_child_errors,\\n', '    assert_success(document)\\n', \"    field = 'one_or_more_strings'\\n\", \"    assert_success({field: 'foo'})\\n\", \"    assert_success({field: ['foo', 'bar']})\\n\", '    exp_child_errors = [\\n', \"        ((field, 1), (field, 'itemsrules', 'type'), errors.TYPE, ('string',))\\n\", \"        {field: ['foo', 23]},\\n\", \"        error=(field, (field, 'itemsrules'), errors.ITEMSRULES, {'type': ('string',)}),\\n\", '        child_errors=exp_child_errors,\\n', \"        {field: 23}, error=((field,), (field, 'type'), errors.TYPE, ('string', 'list'))\\n\", '        field: [{1: [\"must be one of these types: (\\'string\\',)\"]}]\\n', '            if isodd and not bool(value & 1):\\n', \"                self._error(field, 'Not an odd number')\\n\", \"    schema = {'test_field': {'isodd': True}}\\n\", '    validator = MyValidator(schema)\\n', \"    assert_success({'test_field': 7}, validator=validator)\\n\", '        validator=validator,\\n', \"    assert validator.errors == {'test_field': ['Not an odd number']}\\n\", \"    field = 'test'\\n\", \"    schema = {field: {'type': ('string',), 'empty': False, 'required': False}}\\n\", '    document = {field: None}\\n', '    validator = Validator(schema, ignore_none_values=False)\\n', '    assert_fail(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", '    validator.schema.validate()\\n', '    _errors = assert_fail(document, validator=validator)\\n', \"        _errors, field, (field, 'required'), errors.REQUIRED_FIELD, True\\n\", '    validator = Validator(schema, ignore_none_values=True)\\n', \"    validator.schema[field]['required'] = False\\n\", '    validator.schema.validate()\\n', '    assert_success(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", \"    assert validator.schema[field].get('required') is True\\n\", '    _errors = assert_fail(document=document, validator=validator)\\n', \"    assert_has_error(_errors, field, (field, 'required'), errors.REQUIRED_FIELD, True)\\n\", \"    assert_not_has_error(_errors, field, (field, 'type'), errors.TYPE, 'string')\\n\", '    schema = {}\\n', '    v = Validator(allow_unknown=True, schema=schema)\\n', '    assert_success({\"unknown1\": True, \"unknown2\": \"yes\"}, validator=v)\\n', \"    v.allow_unknown = {'type': 'string'}\\n\", \"    assert_success(document={'name': 'mark'}, validator=v)\\n\", '    assert_fail({\"name\": 1}, validator=v)\\n', '    v.allow_unknown = False\\n', \"    assert_fail({'name': 'mark'}, validator=v)\\n\", '    validator.allow_unknown = True\\n', \"    document = {'a_dict': {'foo': 'foo_value', 'bar': 25}}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_dict': ['foo', 'bar']}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_list_of_dicts': [{'sku': 'YZ069', 'price': 25, 'extra': True}]}\\n\", '    assert_success(document, validator=validator)\\n', '            return value == \"foo\"\\n', '    validator = CustomValidator({})\\n', '    validator.allow_unknown = {\"check_with\": \"foo\"}\\n', '    assert_success(document={\"fred\": \"foo\", \"barney\": \"foo\"}, validator=validator)\\n', \"    schema = {'test_field': {'type': 'string'}}\\n\", '    validator = Validator(schema)\\n', \"    assert validator.validate({'test_field': 'foo'})\\n\", \"    assert validator({'test_field': 'foo'})\\n\", \"    assert not validator.validate({'test_field': 1})\\n\", \"    assert not validator({'test_field': 1})\\n\", \"                self._error(field, 'self.context is not the root doc!')\\n\", '    schema = {\\n', \"        {'sub': [{'foo': 'bar'}, {'foo': 'baz'}]}, validator=MyValidator(schema)\\n\", \"    validator.schema = {'property': {'type': 'string'}}\\n\", \"    document = {'property': 'string'}\\n\", '    assert validator.validated(document) == document\\n', \"    document = {'property': 0}\\n\", '    assert validator.validated(document) is None\\n', '    schema = {\\n', \"    document = {'info': {'name': 'my name'}}\\n\", '    assert_success(document, schema, validator=validator)\\n', '    v = Validator(schema)\\n', '    assert_success(document, schema, v)\\n', '    assert v.validate(document)\\n', '    assert_success(document, schema, validator=v)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = True\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({\"foo\": {\"bar\": \"baz\"}}, schema, validator)\\n', '        assert_fail({}, schema, validator)\\n', '        assert_success({}, schema, validator)\\n', '        assert_fail({\"foo\": {}}, schema, validator)\\n', '        assert_success({\"foo\": {}}, schema, validator)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    assert validator.errors == {}\\n']",
  "context": " = {field: None}\n\n    # Test normal behaviour\n    validator = Validator(schema, ignore_none_values=False)\n    assert_fail(document, validator=validator)\n\n  "
 },
 "514": {
  "name": "_errors",
  "type": "cerberus.tests.assert_fail",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_validation.py",
  "lineno": "160",
  "column": "4",
  "slicing": "['    document = \"not a dict\"\\n', '        document, sample_schema, None, errors.DOCUMENT_FORMAT.format(document)\\n', \"    field = 'surname'\\n\", \"        {field: 'doe'},\\n\", '        error=(field, (), errors.UNKNOWN_FIELD, None),\\n', \"    assert validator.errors == {field: ['unknown field']}\\n\", \"    field = 'name'\\n\", '    schema = {field: {}}\\n', '    assert_success(document, schema)\\n', \"    field = 'a_dict_with_valuesrules'\\n\", \"    schema_field = 'a_string'\\n\", \"    value = {schema_field: 'not an integer'}\\n\", '    exp_child_errors = [\\n', '            (field, schema_field),\\n', \"            (field, 'valuesrules', 'type'),\\n\", '        {field: value},\\n', '            field,\\n', \"            (field, 'valuesrules'),\\n\", '        child_errors=exp_child_errors,\\n', '    assert_success(document)\\n', \"    field = 'one_or_more_strings'\\n\", \"    assert_success({field: 'foo'})\\n\", \"    assert_success({field: ['foo', 'bar']})\\n\", '    exp_child_errors = [\\n', \"        ((field, 1), (field, 'itemsrules', 'type'), errors.TYPE, ('string',))\\n\", \"        {field: ['foo', 23]},\\n\", \"        error=(field, (field, 'itemsrules'), errors.ITEMSRULES, {'type': ('string',)}),\\n\", '        child_errors=exp_child_errors,\\n', \"        {field: 23}, error=((field,), (field, 'type'), errors.TYPE, ('string', 'list'))\\n\", '        field: [{1: [\"must be one of these types: (\\'string\\',)\"]}]\\n', '            if isodd and not bool(value & 1):\\n', \"                self._error(field, 'Not an odd number')\\n\", \"    schema = {'test_field': {'isodd': True}}\\n\", '    validator = MyValidator(schema)\\n', \"    assert_success({'test_field': 7}, validator=validator)\\n\", '        validator=validator,\\n', \"    assert validator.errors == {'test_field': ['Not an odd number']}\\n\", \"    field = 'test'\\n\", \"    schema = {field: {'type': ('string',), 'empty': False, 'required': False}}\\n\", '    document = {field: None}\\n', '    validator = Validator(schema, ignore_none_values=False)\\n', '    assert_fail(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", '    validator.schema.validate()\\n', '    _errors = assert_fail(document, validator=validator)\\n', \"        _errors, field, (field, 'required'), errors.REQUIRED_FIELD, True\\n\", '    validator = Validator(schema, ignore_none_values=True)\\n', \"    validator.schema[field]['required'] = False\\n\", '    validator.schema.validate()\\n', '    assert_success(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", \"    assert validator.schema[field].get('required') is True\\n\", '    _errors = assert_fail(document=document, validator=validator)\\n', \"    assert_has_error(_errors, field, (field, 'required'), errors.REQUIRED_FIELD, True)\\n\", \"    assert_not_has_error(_errors, field, (field, 'type'), errors.TYPE, 'string')\\n\", '    schema = {}\\n', '    v = Validator(allow_unknown=True, schema=schema)\\n', '    assert_success({\"unknown1\": True, \"unknown2\": \"yes\"}, validator=v)\\n', \"    v.allow_unknown = {'type': 'string'}\\n\", \"    assert_success(document={'name': 'mark'}, validator=v)\\n\", '    assert_fail({\"name\": 1}, validator=v)\\n', '    v.allow_unknown = False\\n', \"    assert_fail({'name': 'mark'}, validator=v)\\n\", '    validator.allow_unknown = True\\n', \"    document = {'a_dict': {'foo': 'foo_value', 'bar': 25}}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_dict': ['foo', 'bar']}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_list_of_dicts': [{'sku': 'YZ069', 'price': 25, 'extra': True}]}\\n\", '    assert_success(document, validator=validator)\\n', '            return value == \"foo\"\\n', '    validator = CustomValidator({})\\n', '    validator.allow_unknown = {\"check_with\": \"foo\"}\\n', '    assert_success(document={\"fred\": \"foo\", \"barney\": \"foo\"}, validator=validator)\\n', \"    schema = {'test_field': {'type': 'string'}}\\n\", '    validator = Validator(schema)\\n', \"    assert validator.validate({'test_field': 'foo'})\\n\", \"    assert validator({'test_field': 'foo'})\\n\", \"    assert not validator.validate({'test_field': 1})\\n\", \"    assert not validator({'test_field': 1})\\n\", \"                self._error(field, 'self.context is not the root doc!')\\n\", '    schema = {\\n', \"        {'sub': [{'foo': 'bar'}, {'foo': 'baz'}]}, validator=MyValidator(schema)\\n\", \"    validator.schema = {'property': {'type': 'string'}}\\n\", \"    document = {'property': 'string'}\\n\", '    assert validator.validated(document) == document\\n', \"    document = {'property': 0}\\n\", '    assert validator.validated(document) is None\\n', '    schema = {\\n', \"    document = {'info': {'name': 'my name'}}\\n\", '    assert_success(document, schema, validator=validator)\\n', '    v = Validator(schema)\\n', '    assert_success(document, schema, v)\\n', '    assert v.validate(document)\\n', '    assert_success(document, schema, validator=v)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = True\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({\"foo\": {\"bar\": \"baz\"}}, schema, validator)\\n', '        assert_fail({}, schema, validator)\\n', '        assert_success({}, schema, validator)\\n', '        assert_fail({\"foo\": {}}, schema, validator)\\n', '        assert_success({\"foo\": {}}, schema, validator)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    assert validator.errors == {}\\n']",
  "context": "ired'] = True\n    validator.schema.validate()\n    _errors = assert_fail(document, validator=validator)\n    assert_not_has_error(\n        _errors, field, "
 },
 "515": {
  "name": "validator",
  "type": "cerberus.Validator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_validation.py",
  "lineno": "166",
  "column": "4",
  "slicing": "['    document = \"not a dict\"\\n', '        document, sample_schema, None, errors.DOCUMENT_FORMAT.format(document)\\n', \"    field = 'surname'\\n\", \"        {field: 'doe'},\\n\", '        error=(field, (), errors.UNKNOWN_FIELD, None),\\n', \"    assert validator.errors == {field: ['unknown field']}\\n\", \"    field = 'name'\\n\", '    schema = {field: {}}\\n', '    assert_success(document, schema)\\n', \"    field = 'a_dict_with_valuesrules'\\n\", \"    schema_field = 'a_string'\\n\", \"    value = {schema_field: 'not an integer'}\\n\", '    exp_child_errors = [\\n', '            (field, schema_field),\\n', \"            (field, 'valuesrules', 'type'),\\n\", '        {field: value},\\n', '            field,\\n', \"            (field, 'valuesrules'),\\n\", '        child_errors=exp_child_errors,\\n', '    assert_success(document)\\n', \"    field = 'one_or_more_strings'\\n\", \"    assert_success({field: 'foo'})\\n\", \"    assert_success({field: ['foo', 'bar']})\\n\", '    exp_child_errors = [\\n', \"        ((field, 1), (field, 'itemsrules', 'type'), errors.TYPE, ('string',))\\n\", \"        {field: ['foo', 23]},\\n\", \"        error=(field, (field, 'itemsrules'), errors.ITEMSRULES, {'type': ('string',)}),\\n\", '        child_errors=exp_child_errors,\\n', \"        {field: 23}, error=((field,), (field, 'type'), errors.TYPE, ('string', 'list'))\\n\", '        field: [{1: [\"must be one of these types: (\\'string\\',)\"]}]\\n', '            if isodd and not bool(value & 1):\\n', \"                self._error(field, 'Not an odd number')\\n\", \"    schema = {'test_field': {'isodd': True}}\\n\", '    validator = MyValidator(schema)\\n', \"    assert_success({'test_field': 7}, validator=validator)\\n\", '        validator=validator,\\n', \"    assert validator.errors == {'test_field': ['Not an odd number']}\\n\", \"    field = 'test'\\n\", \"    schema = {field: {'type': ('string',), 'empty': False, 'required': False}}\\n\", '    document = {field: None}\\n', '    validator = Validator(schema, ignore_none_values=False)\\n', '    assert_fail(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", '    validator.schema.validate()\\n', '    _errors = assert_fail(document, validator=validator)\\n', \"        _errors, field, (field, 'required'), errors.REQUIRED_FIELD, True\\n\", '    validator = Validator(schema, ignore_none_values=True)\\n', \"    validator.schema[field]['required'] = False\\n\", '    validator.schema.validate()\\n', '    assert_success(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", \"    assert validator.schema[field].get('required') is True\\n\", '    _errors = assert_fail(document=document, validator=validator)\\n', \"    assert_has_error(_errors, field, (field, 'required'), errors.REQUIRED_FIELD, True)\\n\", \"    assert_not_has_error(_errors, field, (field, 'type'), errors.TYPE, 'string')\\n\", '    schema = {}\\n', '    v = Validator(allow_unknown=True, schema=schema)\\n', '    assert_success({\"unknown1\": True, \"unknown2\": \"yes\"}, validator=v)\\n', \"    v.allow_unknown = {'type': 'string'}\\n\", \"    assert_success(document={'name': 'mark'}, validator=v)\\n\", '    assert_fail({\"name\": 1}, validator=v)\\n', '    v.allow_unknown = False\\n', \"    assert_fail({'name': 'mark'}, validator=v)\\n\", '    validator.allow_unknown = True\\n', \"    document = {'a_dict': {'foo': 'foo_value', 'bar': 25}}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_dict': ['foo', 'bar']}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_list_of_dicts': [{'sku': 'YZ069', 'price': 25, 'extra': True}]}\\n\", '    assert_success(document, validator=validator)\\n', '            return value == \"foo\"\\n', '    validator = CustomValidator({})\\n', '    validator.allow_unknown = {\"check_with\": \"foo\"}\\n', '    assert_success(document={\"fred\": \"foo\", \"barney\": \"foo\"}, validator=validator)\\n', \"    schema = {'test_field': {'type': 'string'}}\\n\", '    validator = Validator(schema)\\n', \"    assert validator.validate({'test_field': 'foo'})\\n\", \"    assert validator({'test_field': 'foo'})\\n\", \"    assert not validator.validate({'test_field': 1})\\n\", \"    assert not validator({'test_field': 1})\\n\", \"                self._error(field, 'self.context is not the root doc!')\\n\", '    schema = {\\n', \"        {'sub': [{'foo': 'bar'}, {'foo': 'baz'}]}, validator=MyValidator(schema)\\n\", \"    validator.schema = {'property': {'type': 'string'}}\\n\", \"    document = {'property': 'string'}\\n\", '    assert validator.validated(document) == document\\n', \"    document = {'property': 0}\\n\", '    assert validator.validated(document) is None\\n', '    schema = {\\n', \"    document = {'info': {'name': 'my name'}}\\n\", '    assert_success(document, schema, validator=validator)\\n', '    v = Validator(schema)\\n', '    assert_success(document, schema, v)\\n', '    assert v.validate(document)\\n', '    assert_success(document, schema, validator=v)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = True\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({\"foo\": {\"bar\": \"baz\"}}, schema, validator)\\n', '        assert_fail({}, schema, validator)\\n', '        assert_success({}, schema, validator)\\n', '        assert_fail({\"foo\": {}}, schema, validator)\\n', '        assert_success({\"foo\": {}}, schema, validator)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    assert validator.errors == {}\\n']",
  "context": " True\n    )\n\n    # Test ignore None behaviour\n    validator = Validator(schema, ignore_none_values=True)\n    validator.schema[field]['required'] = False\n  "
 },
 "516": {
  "name": "_errors",
  "type": "cerberus.tests.assert_fail",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_validation.py",
  "lineno": "173",
  "column": "4",
  "slicing": "['    document = \"not a dict\"\\n', '        document, sample_schema, None, errors.DOCUMENT_FORMAT.format(document)\\n', \"    field = 'surname'\\n\", \"        {field: 'doe'},\\n\", '        error=(field, (), errors.UNKNOWN_FIELD, None),\\n', \"    assert validator.errors == {field: ['unknown field']}\\n\", \"    field = 'name'\\n\", '    schema = {field: {}}\\n', '    assert_success(document, schema)\\n', \"    field = 'a_dict_with_valuesrules'\\n\", \"    schema_field = 'a_string'\\n\", \"    value = {schema_field: 'not an integer'}\\n\", '    exp_child_errors = [\\n', '            (field, schema_field),\\n', \"            (field, 'valuesrules', 'type'),\\n\", '        {field: value},\\n', '            field,\\n', \"            (field, 'valuesrules'),\\n\", '        child_errors=exp_child_errors,\\n', '    assert_success(document)\\n', \"    field = 'one_or_more_strings'\\n\", \"    assert_success({field: 'foo'})\\n\", \"    assert_success({field: ['foo', 'bar']})\\n\", '    exp_child_errors = [\\n', \"        ((field, 1), (field, 'itemsrules', 'type'), errors.TYPE, ('string',))\\n\", \"        {field: ['foo', 23]},\\n\", \"        error=(field, (field, 'itemsrules'), errors.ITEMSRULES, {'type': ('string',)}),\\n\", '        child_errors=exp_child_errors,\\n', \"        {field: 23}, error=((field,), (field, 'type'), errors.TYPE, ('string', 'list'))\\n\", '        field: [{1: [\"must be one of these types: (\\'string\\',)\"]}]\\n', '            if isodd and not bool(value & 1):\\n', \"                self._error(field, 'Not an odd number')\\n\", \"    schema = {'test_field': {'isodd': True}}\\n\", '    validator = MyValidator(schema)\\n', \"    assert_success({'test_field': 7}, validator=validator)\\n\", '        validator=validator,\\n', \"    assert validator.errors == {'test_field': ['Not an odd number']}\\n\", \"    field = 'test'\\n\", \"    schema = {field: {'type': ('string',), 'empty': False, 'required': False}}\\n\", '    document = {field: None}\\n', '    validator = Validator(schema, ignore_none_values=False)\\n', '    assert_fail(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", '    validator.schema.validate()\\n', '    _errors = assert_fail(document, validator=validator)\\n', \"        _errors, field, (field, 'required'), errors.REQUIRED_FIELD, True\\n\", '    validator = Validator(schema, ignore_none_values=True)\\n', \"    validator.schema[field]['required'] = False\\n\", '    validator.schema.validate()\\n', '    assert_success(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", \"    assert validator.schema[field].get('required') is True\\n\", '    _errors = assert_fail(document=document, validator=validator)\\n', \"    assert_has_error(_errors, field, (field, 'required'), errors.REQUIRED_FIELD, True)\\n\", \"    assert_not_has_error(_errors, field, (field, 'type'), errors.TYPE, 'string')\\n\", '    schema = {}\\n', '    v = Validator(allow_unknown=True, schema=schema)\\n', '    assert_success({\"unknown1\": True, \"unknown2\": \"yes\"}, validator=v)\\n', \"    v.allow_unknown = {'type': 'string'}\\n\", \"    assert_success(document={'name': 'mark'}, validator=v)\\n\", '    assert_fail({\"name\": 1}, validator=v)\\n', '    v.allow_unknown = False\\n', \"    assert_fail({'name': 'mark'}, validator=v)\\n\", '    validator.allow_unknown = True\\n', \"    document = {'a_dict': {'foo': 'foo_value', 'bar': 25}}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_dict': ['foo', 'bar']}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_list_of_dicts': [{'sku': 'YZ069', 'price': 25, 'extra': True}]}\\n\", '    assert_success(document, validator=validator)\\n', '            return value == \"foo\"\\n', '    validator = CustomValidator({})\\n', '    validator.allow_unknown = {\"check_with\": \"foo\"}\\n', '    assert_success(document={\"fred\": \"foo\", \"barney\": \"foo\"}, validator=validator)\\n', \"    schema = {'test_field': {'type': 'string'}}\\n\", '    validator = Validator(schema)\\n', \"    assert validator.validate({'test_field': 'foo'})\\n\", \"    assert validator({'test_field': 'foo'})\\n\", \"    assert not validator.validate({'test_field': 1})\\n\", \"    assert not validator({'test_field': 1})\\n\", \"                self._error(field, 'self.context is not the root doc!')\\n\", '    schema = {\\n', \"        {'sub': [{'foo': 'bar'}, {'foo': 'baz'}]}, validator=MyValidator(schema)\\n\", \"    validator.schema = {'property': {'type': 'string'}}\\n\", \"    document = {'property': 'string'}\\n\", '    assert validator.validated(document) == document\\n', \"    document = {'property': 0}\\n\", '    assert validator.validated(document) is None\\n', '    schema = {\\n', \"    document = {'info': {'name': 'my name'}}\\n\", '    assert_success(document, schema, validator=validator)\\n', '    v = Validator(schema)\\n', '    assert_success(document, schema, v)\\n', '    assert v.validate(document)\\n', '    assert_success(document, schema, validator=v)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = True\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({\"foo\": {\"bar\": \"baz\"}}, schema, validator)\\n', '        assert_fail({}, schema, validator)\\n', '        assert_success({}, schema, validator)\\n', '        assert_fail({\"foo\": {}}, schema, validator)\\n', '        assert_success({\"foo\": {}}, schema, validator)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    assert validator.errors == {}\\n']",
  "context": "lidator.schema[field].get('required') is True\n    _errors = assert_fail(document=document, validator=validator)\n    assert_has_error(_errors, field, (field, 'requ"
 },
 "517": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_validation.py",
  "lineno": "179",
  "column": "4",
  "slicing": "['    document = \"not a dict\"\\n', '        document, sample_schema, None, errors.DOCUMENT_FORMAT.format(document)\\n', \"    field = 'surname'\\n\", \"        {field: 'doe'},\\n\", '        error=(field, (), errors.UNKNOWN_FIELD, None),\\n', \"    assert validator.errors == {field: ['unknown field']}\\n\", \"    field = 'name'\\n\", '    schema = {field: {}}\\n', '    assert_success(document, schema)\\n', \"    field = 'a_dict_with_valuesrules'\\n\", \"    schema_field = 'a_string'\\n\", \"    value = {schema_field: 'not an integer'}\\n\", '    exp_child_errors = [\\n', '            (field, schema_field),\\n', \"            (field, 'valuesrules', 'type'),\\n\", '        {field: value},\\n', '            field,\\n', \"            (field, 'valuesrules'),\\n\", '        child_errors=exp_child_errors,\\n', '    assert_success(document)\\n', \"    field = 'one_or_more_strings'\\n\", \"    assert_success({field: 'foo'})\\n\", \"    assert_success({field: ['foo', 'bar']})\\n\", '    exp_child_errors = [\\n', \"        ((field, 1), (field, 'itemsrules', 'type'), errors.TYPE, ('string',))\\n\", \"        {field: ['foo', 23]},\\n\", \"        error=(field, (field, 'itemsrules'), errors.ITEMSRULES, {'type': ('string',)}),\\n\", '        child_errors=exp_child_errors,\\n', \"        {field: 23}, error=((field,), (field, 'type'), errors.TYPE, ('string', 'list'))\\n\", '        field: [{1: [\"must be one of these types: (\\'string\\',)\"]}]\\n', '            if isodd and not bool(value & 1):\\n', \"                self._error(field, 'Not an odd number')\\n\", \"    schema = {'test_field': {'isodd': True}}\\n\", '    validator = MyValidator(schema)\\n', \"    assert_success({'test_field': 7}, validator=validator)\\n\", '        validator=validator,\\n', \"    assert validator.errors == {'test_field': ['Not an odd number']}\\n\", \"    field = 'test'\\n\", \"    schema = {field: {'type': ('string',), 'empty': False, 'required': False}}\\n\", '    document = {field: None}\\n', '    validator = Validator(schema, ignore_none_values=False)\\n', '    assert_fail(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", '    validator.schema.validate()\\n', '    _errors = assert_fail(document, validator=validator)\\n', \"        _errors, field, (field, 'required'), errors.REQUIRED_FIELD, True\\n\", '    validator = Validator(schema, ignore_none_values=True)\\n', \"    validator.schema[field]['required'] = False\\n\", '    validator.schema.validate()\\n', '    assert_success(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", \"    assert validator.schema[field].get('required') is True\\n\", '    _errors = assert_fail(document=document, validator=validator)\\n', \"    assert_has_error(_errors, field, (field, 'required'), errors.REQUIRED_FIELD, True)\\n\", \"    assert_not_has_error(_errors, field, (field, 'type'), errors.TYPE, 'string')\\n\", '    schema = {}\\n', '    v = Validator(allow_unknown=True, schema=schema)\\n', '    assert_success({\"unknown1\": True, \"unknown2\": \"yes\"}, validator=v)\\n', \"    v.allow_unknown = {'type': 'string'}\\n\", \"    assert_success(document={'name': 'mark'}, validator=v)\\n\", '    assert_fail({\"name\": 1}, validator=v)\\n', '    v.allow_unknown = False\\n', \"    assert_fail({'name': 'mark'}, validator=v)\\n\", '    validator.allow_unknown = True\\n', \"    document = {'a_dict': {'foo': 'foo_value', 'bar': 25}}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_dict': ['foo', 'bar']}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_list_of_dicts': [{'sku': 'YZ069', 'price': 25, 'extra': True}]}\\n\", '    assert_success(document, validator=validator)\\n', '            return value == \"foo\"\\n', '    validator = CustomValidator({})\\n', '    validator.allow_unknown = {\"check_with\": \"foo\"}\\n', '    assert_success(document={\"fred\": \"foo\", \"barney\": \"foo\"}, validator=validator)\\n', \"    schema = {'test_field': {'type': 'string'}}\\n\", '    validator = Validator(schema)\\n', \"    assert validator.validate({'test_field': 'foo'})\\n\", \"    assert validator({'test_field': 'foo'})\\n\", \"    assert not validator.validate({'test_field': 1})\\n\", \"    assert not validator({'test_field': 1})\\n\", \"                self._error(field, 'self.context is not the root doc!')\\n\", '    schema = {\\n', \"        {'sub': [{'foo': 'bar'}, {'foo': 'baz'}]}, validator=MyValidator(schema)\\n\", \"    validator.schema = {'property': {'type': 'string'}}\\n\", \"    document = {'property': 'string'}\\n\", '    assert validator.validated(document) == document\\n', \"    document = {'property': 0}\\n\", '    assert validator.validated(document) is None\\n', '    schema = {\\n', \"    document = {'info': {'name': 'my name'}}\\n\", '    assert_success(document, schema, validator=validator)\\n', '    v = Validator(schema)\\n', '    assert_success(document, schema, v)\\n', '    assert v.validate(document)\\n', '    assert_success(document, schema, validator=v)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = True\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({\"foo\": {\"bar\": \"baz\"}}, schema, validator)\\n', '        assert_fail({}, schema, validator)\\n', '        assert_success({}, schema, validator)\\n', '        assert_fail({\"foo\": {}}, schema, validator)\\n', '        assert_success({\"foo\": {}}, schema, validator)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    assert validator.errors == {}\\n']",
  "context": "rs.TYPE, 'string')\n\n\ndef test_unknown_keys():\n    schema = {}\n\n    # test that unknown fields are allowed when a"
 },
 "518": {
  "name": "v",
  "type": "cerberus.Validator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_validation.py",
  "lineno": "182",
  "column": "4",
  "slicing": "['    document = \"not a dict\"\\n', '        document, sample_schema, None, errors.DOCUMENT_FORMAT.format(document)\\n', \"    field = 'surname'\\n\", \"        {field: 'doe'},\\n\", '        error=(field, (), errors.UNKNOWN_FIELD, None),\\n', \"    assert validator.errors == {field: ['unknown field']}\\n\", \"    field = 'name'\\n\", '    schema = {field: {}}\\n', '    assert_success(document, schema)\\n', \"    field = 'a_dict_with_valuesrules'\\n\", \"    schema_field = 'a_string'\\n\", \"    value = {schema_field: 'not an integer'}\\n\", '    exp_child_errors = [\\n', '            (field, schema_field),\\n', \"            (field, 'valuesrules', 'type'),\\n\", '        {field: value},\\n', '            field,\\n', \"            (field, 'valuesrules'),\\n\", '        child_errors=exp_child_errors,\\n', '    assert_success(document)\\n', \"    field = 'one_or_more_strings'\\n\", \"    assert_success({field: 'foo'})\\n\", \"    assert_success({field: ['foo', 'bar']})\\n\", '    exp_child_errors = [\\n', \"        ((field, 1), (field, 'itemsrules', 'type'), errors.TYPE, ('string',))\\n\", \"        {field: ['foo', 23]},\\n\", \"        error=(field, (field, 'itemsrules'), errors.ITEMSRULES, {'type': ('string',)}),\\n\", '        child_errors=exp_child_errors,\\n', \"        {field: 23}, error=((field,), (field, 'type'), errors.TYPE, ('string', 'list'))\\n\", '        field: [{1: [\"must be one of these types: (\\'string\\',)\"]}]\\n', '            if isodd and not bool(value & 1):\\n', \"                self._error(field, 'Not an odd number')\\n\", \"    schema = {'test_field': {'isodd': True}}\\n\", '    validator = MyValidator(schema)\\n', \"    assert_success({'test_field': 7}, validator=validator)\\n\", '        validator=validator,\\n', \"    assert validator.errors == {'test_field': ['Not an odd number']}\\n\", \"    field = 'test'\\n\", \"    schema = {field: {'type': ('string',), 'empty': False, 'required': False}}\\n\", '    document = {field: None}\\n', '    validator = Validator(schema, ignore_none_values=False)\\n', '    assert_fail(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", '    validator.schema.validate()\\n', '    _errors = assert_fail(document, validator=validator)\\n', \"        _errors, field, (field, 'required'), errors.REQUIRED_FIELD, True\\n\", '    validator = Validator(schema, ignore_none_values=True)\\n', \"    validator.schema[field]['required'] = False\\n\", '    validator.schema.validate()\\n', '    assert_success(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", \"    assert validator.schema[field].get('required') is True\\n\", '    _errors = assert_fail(document=document, validator=validator)\\n', \"    assert_has_error(_errors, field, (field, 'required'), errors.REQUIRED_FIELD, True)\\n\", \"    assert_not_has_error(_errors, field, (field, 'type'), errors.TYPE, 'string')\\n\", '    schema = {}\\n', '    v = Validator(allow_unknown=True, schema=schema)\\n', '    assert_success({\"unknown1\": True, \"unknown2\": \"yes\"}, validator=v)\\n', \"    v.allow_unknown = {'type': 'string'}\\n\", \"    assert_success(document={'name': 'mark'}, validator=v)\\n\", '    assert_fail({\"name\": 1}, validator=v)\\n', '    v.allow_unknown = False\\n', \"    assert_fail({'name': 'mark'}, validator=v)\\n\", '    validator.allow_unknown = True\\n', \"    document = {'a_dict': {'foo': 'foo_value', 'bar': 25}}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_dict': ['foo', 'bar']}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_list_of_dicts': [{'sku': 'YZ069', 'price': 25, 'extra': True}]}\\n\", '    assert_success(document, validator=validator)\\n', '            return value == \"foo\"\\n', '    validator = CustomValidator({})\\n', '    validator.allow_unknown = {\"check_with\": \"foo\"}\\n', '    assert_success(document={\"fred\": \"foo\", \"barney\": \"foo\"}, validator=validator)\\n', \"    schema = {'test_field': {'type': 'string'}}\\n\", '    validator = Validator(schema)\\n', \"    assert validator.validate({'test_field': 'foo'})\\n\", \"    assert validator({'test_field': 'foo'})\\n\", \"    assert not validator.validate({'test_field': 1})\\n\", \"    assert not validator({'test_field': 1})\\n\", \"                self._error(field, 'self.context is not the root doc!')\\n\", '    schema = {\\n', \"        {'sub': [{'foo': 'bar'}, {'foo': 'baz'}]}, validator=MyValidator(schema)\\n\", \"    validator.schema = {'property': {'type': 'string'}}\\n\", \"    document = {'property': 'string'}\\n\", '    assert validator.validated(document) == document\\n', \"    document = {'property': 0}\\n\", '    assert validator.validated(document) is None\\n', '    schema = {\\n', \"    document = {'info': {'name': 'my name'}}\\n\", '    assert_success(document, schema, validator=validator)\\n', '    v = Validator(schema)\\n', '    assert_success(document, schema, v)\\n', '    assert v.validate(document)\\n', '    assert_success(document, schema, validator=v)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = True\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({\"foo\": {\"bar\": \"baz\"}}, schema, validator)\\n', '        assert_fail({}, schema, validator)\\n', '        assert_success({}, schema, validator)\\n', '        assert_fail({\"foo\": {}}, schema, validator)\\n', '        assert_success({\"foo\": {}}, schema, validator)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    assert validator.errors == {}\\n']",
  "context": "ields are allowed when allow_unknown is True.\n    v = Validator(allow_unknown=True, schema=schema)\n    assert_success({\"unknown1\": True, \"unknown2\": "
 },
 "519": {
  "name": "document",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_validation.py",
  "lineno": "199",
  "column": "4",
  "slicing": "[\"    document = {'a_dict': {'foo': 'foo_value', 'bar': 25}}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    assert_success(document, {}, validator=validator)\\n', '    assert_success(document, validator=validator)\\n', '    assert validator.validated(document) == document\\n', '    assert validator.validated(document) is None\\n', '    assert_success(document, schema, validator=validator)\\n', '    assert_success(document, schema, v)\\n', '    assert v.validate(document)\\n', '    assert_success(document, schema, validator=v)\\n']",
  "context": "issues/177\n    validator.allow_unknown = True\n    document = {'a_dict': {'foo': 'foo_value', 'bar': 25}}\n    assert_success(document, {}, validator=validat"
 },
 "520": {
  "name": "document",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_validation.py",
  "lineno": "206",
  "column": "4",
  "slicing": "[\"    document = {'a_dict': ['foo', 'bar']}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    assert_success(document, validator=validator)\\n', '    assert validator.validated(document) == document\\n', '    assert validator.validated(document) is None\\n', '    assert_success(document, schema, validator=validator)\\n', '    assert_success(document, schema, v)\\n', '    assert v.validate(document)\\n', '    assert_success(document, schema, validator=v)\\n']",
  "context": "issues/177\n    validator.allow_unknown = True\n    document = {'a_dict': ['foo', 'bar']}\n    assert_success(document, {}, validator=validat"
 },
 "521": {
  "name": "document",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_validation.py",
  "lineno": "214",
  "column": "4",
  "slicing": "[\"    document = {'a_list_of_dicts': [{'sku': 'YZ069', 'price': 25, 'extra': True}]}\\n\", '    assert_success(document, validator=validator)\\n', '    assert validator.validated(document) == document\\n', '    assert validator.validated(document) is None\\n', '    assert_success(document, schema, validator=validator)\\n', '    assert_success(document, schema, v)\\n', '    assert v.validate(document)\\n', '    assert_success(document, schema, validator=v)\\n']",
  "context": "issues/67.\n    validator.allow_unknown = True\n    document = {'a_list_of_dicts': [{'sku': 'YZ069', 'price': 25, 'extra': True}]}\n    assert_success(document, validator=validator)\n"
 },
 "522": {
  "name": "validator",
  "type": "CustomValidator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_validation.py",
  "lineno": "225",
  "column": "4",
  "slicing": "['    document = \"not a dict\"\\n', '        document, sample_schema, None, errors.DOCUMENT_FORMAT.format(document)\\n', \"    field = 'surname'\\n\", \"        {field: 'doe'},\\n\", '        error=(field, (), errors.UNKNOWN_FIELD, None),\\n', \"    assert validator.errors == {field: ['unknown field']}\\n\", \"    field = 'name'\\n\", '    schema = {field: {}}\\n', '    assert_success(document, schema)\\n', \"    field = 'a_dict_with_valuesrules'\\n\", \"    schema_field = 'a_string'\\n\", \"    value = {schema_field: 'not an integer'}\\n\", '    exp_child_errors = [\\n', '            (field, schema_field),\\n', \"            (field, 'valuesrules', 'type'),\\n\", '        {field: value},\\n', '            field,\\n', \"            (field, 'valuesrules'),\\n\", '        child_errors=exp_child_errors,\\n', '    assert_success(document)\\n', \"    field = 'one_or_more_strings'\\n\", \"    assert_success({field: 'foo'})\\n\", \"    assert_success({field: ['foo', 'bar']})\\n\", '    exp_child_errors = [\\n', \"        ((field, 1), (field, 'itemsrules', 'type'), errors.TYPE, ('string',))\\n\", \"        {field: ['foo', 23]},\\n\", \"        error=(field, (field, 'itemsrules'), errors.ITEMSRULES, {'type': ('string',)}),\\n\", '        child_errors=exp_child_errors,\\n', \"        {field: 23}, error=((field,), (field, 'type'), errors.TYPE, ('string', 'list'))\\n\", '        field: [{1: [\"must be one of these types: (\\'string\\',)\"]}]\\n', '            if isodd and not bool(value & 1):\\n', \"                self._error(field, 'Not an odd number')\\n\", \"    schema = {'test_field': {'isodd': True}}\\n\", '    validator = MyValidator(schema)\\n', \"    assert_success({'test_field': 7}, validator=validator)\\n\", '        validator=validator,\\n', \"    assert validator.errors == {'test_field': ['Not an odd number']}\\n\", \"    field = 'test'\\n\", \"    schema = {field: {'type': ('string',), 'empty': False, 'required': False}}\\n\", '    document = {field: None}\\n', '    validator = Validator(schema, ignore_none_values=False)\\n', '    assert_fail(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", '    validator.schema.validate()\\n', '    _errors = assert_fail(document, validator=validator)\\n', \"        _errors, field, (field, 'required'), errors.REQUIRED_FIELD, True\\n\", '    validator = Validator(schema, ignore_none_values=True)\\n', \"    validator.schema[field]['required'] = False\\n\", '    validator.schema.validate()\\n', '    assert_success(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", \"    assert validator.schema[field].get('required') is True\\n\", '    _errors = assert_fail(document=document, validator=validator)\\n', \"    assert_has_error(_errors, field, (field, 'required'), errors.REQUIRED_FIELD, True)\\n\", \"    assert_not_has_error(_errors, field, (field, 'type'), errors.TYPE, 'string')\\n\", '    schema = {}\\n', '    v = Validator(allow_unknown=True, schema=schema)\\n', '    assert_success({\"unknown1\": True, \"unknown2\": \"yes\"}, validator=v)\\n', \"    v.allow_unknown = {'type': 'string'}\\n\", \"    assert_success(document={'name': 'mark'}, validator=v)\\n\", '    assert_fail({\"name\": 1}, validator=v)\\n', '    v.allow_unknown = False\\n', \"    assert_fail({'name': 'mark'}, validator=v)\\n\", '    validator.allow_unknown = True\\n', \"    document = {'a_dict': {'foo': 'foo_value', 'bar': 25}}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_dict': ['foo', 'bar']}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_list_of_dicts': [{'sku': 'YZ069', 'price': 25, 'extra': True}]}\\n\", '    assert_success(document, validator=validator)\\n', '            return value == \"foo\"\\n', '    validator = CustomValidator({})\\n', '    validator.allow_unknown = {\"check_with\": \"foo\"}\\n', '    assert_success(document={\"fred\": \"foo\", \"barney\": \"foo\"}, validator=validator)\\n', \"    schema = {'test_field': {'type': 'string'}}\\n\", '    validator = Validator(schema)\\n', \"    assert validator.validate({'test_field': 'foo'})\\n\", \"    assert validator({'test_field': 'foo'})\\n\", \"    assert not validator.validate({'test_field': 1})\\n\", \"    assert not validator({'test_field': 1})\\n\", \"                self._error(field, 'self.context is not the root doc!')\\n\", '    schema = {\\n', \"        {'sub': [{'foo': 'bar'}, {'foo': 'baz'}]}, validator=MyValidator(schema)\\n\", \"    validator.schema = {'property': {'type': 'string'}}\\n\", \"    document = {'property': 'string'}\\n\", '    assert validator.validated(document) == document\\n', \"    document = {'property': 0}\\n\", '    assert validator.validated(document) is None\\n', '    schema = {\\n', \"    document = {'info': {'name': 'my name'}}\\n\", '    assert_success(document, schema, validator=validator)\\n', '    v = Validator(schema)\\n', '    assert_success(document, schema, v)\\n', '    assert v.validate(document)\\n', '    assert_success(document, schema, validator=v)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = True\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({\"foo\": {\"bar\": \"baz\"}}, schema, validator)\\n', '        assert_fail({}, schema, validator)\\n', '        assert_success({}, schema, validator)\\n', '        assert_fail({\"foo\": {}}, schema, validator)\\n', '        assert_success({\"foo\": {}}, schema, validator)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    assert validator.errors == {}\\n']",
  "context": "d, value):\n            return value == \"foo\"\n\n    validator = CustomValidator({})\n    validator.allow_unknown = {\"check_with\": \"foo\""
 },
 "523": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_validation.py",
  "lineno": "235",
  "column": "4",
  "slicing": "['    document = \"not a dict\"\\n', '        document, sample_schema, None, errors.DOCUMENT_FORMAT.format(document)\\n', \"    field = 'surname'\\n\", \"        {field: 'doe'},\\n\", '        error=(field, (), errors.UNKNOWN_FIELD, None),\\n', \"    assert validator.errors == {field: ['unknown field']}\\n\", \"    field = 'name'\\n\", '    schema = {field: {}}\\n', '    assert_success(document, schema)\\n', \"    field = 'a_dict_with_valuesrules'\\n\", \"    schema_field = 'a_string'\\n\", \"    value = {schema_field: 'not an integer'}\\n\", '    exp_child_errors = [\\n', '            (field, schema_field),\\n', \"            (field, 'valuesrules', 'type'),\\n\", '        {field: value},\\n', '            field,\\n', \"            (field, 'valuesrules'),\\n\", '        child_errors=exp_child_errors,\\n', '    assert_success(document)\\n', \"    field = 'one_or_more_strings'\\n\", \"    assert_success({field: 'foo'})\\n\", \"    assert_success({field: ['foo', 'bar']})\\n\", '    exp_child_errors = [\\n', \"        ((field, 1), (field, 'itemsrules', 'type'), errors.TYPE, ('string',))\\n\", \"        {field: ['foo', 23]},\\n\", \"        error=(field, (field, 'itemsrules'), errors.ITEMSRULES, {'type': ('string',)}),\\n\", '        child_errors=exp_child_errors,\\n', \"        {field: 23}, error=((field,), (field, 'type'), errors.TYPE, ('string', 'list'))\\n\", '        field: [{1: [\"must be one of these types: (\\'string\\',)\"]}]\\n', '            if isodd and not bool(value & 1):\\n', \"                self._error(field, 'Not an odd number')\\n\", \"    schema = {'test_field': {'isodd': True}}\\n\", '    validator = MyValidator(schema)\\n', \"    assert_success({'test_field': 7}, validator=validator)\\n\", '        validator=validator,\\n', \"    assert validator.errors == {'test_field': ['Not an odd number']}\\n\", \"    field = 'test'\\n\", \"    schema = {field: {'type': ('string',), 'empty': False, 'required': False}}\\n\", '    document = {field: None}\\n', '    validator = Validator(schema, ignore_none_values=False)\\n', '    assert_fail(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", '    validator.schema.validate()\\n', '    _errors = assert_fail(document, validator=validator)\\n', \"        _errors, field, (field, 'required'), errors.REQUIRED_FIELD, True\\n\", '    validator = Validator(schema, ignore_none_values=True)\\n', \"    validator.schema[field]['required'] = False\\n\", '    validator.schema.validate()\\n', '    assert_success(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", \"    assert validator.schema[field].get('required') is True\\n\", '    _errors = assert_fail(document=document, validator=validator)\\n', \"    assert_has_error(_errors, field, (field, 'required'), errors.REQUIRED_FIELD, True)\\n\", \"    assert_not_has_error(_errors, field, (field, 'type'), errors.TYPE, 'string')\\n\", '    schema = {}\\n', '    v = Validator(allow_unknown=True, schema=schema)\\n', '    assert_success({\"unknown1\": True, \"unknown2\": \"yes\"}, validator=v)\\n', \"    v.allow_unknown = {'type': 'string'}\\n\", \"    assert_success(document={'name': 'mark'}, validator=v)\\n\", '    assert_fail({\"name\": 1}, validator=v)\\n', '    v.allow_unknown = False\\n', \"    assert_fail({'name': 'mark'}, validator=v)\\n\", '    validator.allow_unknown = True\\n', \"    document = {'a_dict': {'foo': 'foo_value', 'bar': 25}}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_dict': ['foo', 'bar']}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_list_of_dicts': [{'sku': 'YZ069', 'price': 25, 'extra': True}]}\\n\", '    assert_success(document, validator=validator)\\n', '            return value == \"foo\"\\n', '    validator = CustomValidator({})\\n', '    validator.allow_unknown = {\"check_with\": \"foo\"}\\n', '    assert_success(document={\"fred\": \"foo\", \"barney\": \"foo\"}, validator=validator)\\n', \"    schema = {'test_field': {'type': 'string'}}\\n\", '    validator = Validator(schema)\\n', \"    assert validator.validate({'test_field': 'foo'})\\n\", \"    assert validator({'test_field': 'foo'})\\n\", \"    assert not validator.validate({'test_field': 1})\\n\", \"    assert not validator({'test_field': 1})\\n\", \"                self._error(field, 'self.context is not the root doc!')\\n\", '    schema = {\\n', \"        {'sub': [{'foo': 'bar'}, {'foo': 'baz'}]}, validator=MyValidator(schema)\\n\", \"    validator.schema = {'property': {'type': 'string'}}\\n\", \"    document = {'property': 'string'}\\n\", '    assert validator.validated(document) == document\\n', \"    document = {'property': 0}\\n\", '    assert validator.validated(document) is None\\n', '    schema = {\\n', \"    document = {'info': {'name': 'my name'}}\\n\", '    assert_success(document, schema, validator=validator)\\n', '    v = Validator(schema)\\n', '    assert_success(document, schema, v)\\n', '    assert v.validate(document)\\n', '    assert_success(document, schema, validator=v)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = True\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({\"foo\": {\"bar\": \"baz\"}}, schema, validator)\\n', '        assert_fail({}, schema, validator)\\n', '        assert_success({}, schema, validator)\\n', '        assert_fail({\"foo\": {}}, schema, validator)\\n', '        assert_success({\"foo\": {}}, schema, validator)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    assert validator.errors == {}\\n']",
  "context": "orthand\n    passthrough to validate()\n    \"\"\"\n    schema = {'test_field': {'type': 'string'}}\n    validator = Validator(schema)\n    assert valid"
 },
 "524": {
  "name": "validator",
  "type": "cerberus.Validator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_validation.py",
  "lineno": "236",
  "column": "4",
  "slicing": "['    document = \"not a dict\"\\n', '        document, sample_schema, None, errors.DOCUMENT_FORMAT.format(document)\\n', \"    field = 'surname'\\n\", \"        {field: 'doe'},\\n\", '        error=(field, (), errors.UNKNOWN_FIELD, None),\\n', \"    assert validator.errors == {field: ['unknown field']}\\n\", \"    field = 'name'\\n\", '    schema = {field: {}}\\n', '    assert_success(document, schema)\\n', \"    field = 'a_dict_with_valuesrules'\\n\", \"    schema_field = 'a_string'\\n\", \"    value = {schema_field: 'not an integer'}\\n\", '    exp_child_errors = [\\n', '            (field, schema_field),\\n', \"            (field, 'valuesrules', 'type'),\\n\", '        {field: value},\\n', '            field,\\n', \"            (field, 'valuesrules'),\\n\", '        child_errors=exp_child_errors,\\n', '    assert_success(document)\\n', \"    field = 'one_or_more_strings'\\n\", \"    assert_success({field: 'foo'})\\n\", \"    assert_success({field: ['foo', 'bar']})\\n\", '    exp_child_errors = [\\n', \"        ((field, 1), (field, 'itemsrules', 'type'), errors.TYPE, ('string',))\\n\", \"        {field: ['foo', 23]},\\n\", \"        error=(field, (field, 'itemsrules'), errors.ITEMSRULES, {'type': ('string',)}),\\n\", '        child_errors=exp_child_errors,\\n', \"        {field: 23}, error=((field,), (field, 'type'), errors.TYPE, ('string', 'list'))\\n\", '        field: [{1: [\"must be one of these types: (\\'string\\',)\"]}]\\n', '            if isodd and not bool(value & 1):\\n', \"                self._error(field, 'Not an odd number')\\n\", \"    schema = {'test_field': {'isodd': True}}\\n\", '    validator = MyValidator(schema)\\n', \"    assert_success({'test_field': 7}, validator=validator)\\n\", '        validator=validator,\\n', \"    assert validator.errors == {'test_field': ['Not an odd number']}\\n\", \"    field = 'test'\\n\", \"    schema = {field: {'type': ('string',), 'empty': False, 'required': False}}\\n\", '    document = {field: None}\\n', '    validator = Validator(schema, ignore_none_values=False)\\n', '    assert_fail(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", '    validator.schema.validate()\\n', '    _errors = assert_fail(document, validator=validator)\\n', \"        _errors, field, (field, 'required'), errors.REQUIRED_FIELD, True\\n\", '    validator = Validator(schema, ignore_none_values=True)\\n', \"    validator.schema[field]['required'] = False\\n\", '    validator.schema.validate()\\n', '    assert_success(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", \"    assert validator.schema[field].get('required') is True\\n\", '    _errors = assert_fail(document=document, validator=validator)\\n', \"    assert_has_error(_errors, field, (field, 'required'), errors.REQUIRED_FIELD, True)\\n\", \"    assert_not_has_error(_errors, field, (field, 'type'), errors.TYPE, 'string')\\n\", '    schema = {}\\n', '    v = Validator(allow_unknown=True, schema=schema)\\n', '    assert_success({\"unknown1\": True, \"unknown2\": \"yes\"}, validator=v)\\n', \"    v.allow_unknown = {'type': 'string'}\\n\", \"    assert_success(document={'name': 'mark'}, validator=v)\\n\", '    assert_fail({\"name\": 1}, validator=v)\\n', '    v.allow_unknown = False\\n', \"    assert_fail({'name': 'mark'}, validator=v)\\n\", '    validator.allow_unknown = True\\n', \"    document = {'a_dict': {'foo': 'foo_value', 'bar': 25}}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_dict': ['foo', 'bar']}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_list_of_dicts': [{'sku': 'YZ069', 'price': 25, 'extra': True}]}\\n\", '    assert_success(document, validator=validator)\\n', '            return value == \"foo\"\\n', '    validator = CustomValidator({})\\n', '    validator.allow_unknown = {\"check_with\": \"foo\"}\\n', '    assert_success(document={\"fred\": \"foo\", \"barney\": \"foo\"}, validator=validator)\\n', \"    schema = {'test_field': {'type': 'string'}}\\n\", '    validator = Validator(schema)\\n', \"    assert validator.validate({'test_field': 'foo'})\\n\", \"    assert validator({'test_field': 'foo'})\\n\", \"    assert not validator.validate({'test_field': 1})\\n\", \"    assert not validator({'test_field': 1})\\n\", \"                self._error(field, 'self.context is not the root doc!')\\n\", '    schema = {\\n', \"        {'sub': [{'foo': 'bar'}, {'foo': 'baz'}]}, validator=MyValidator(schema)\\n\", \"    validator.schema = {'property': {'type': 'string'}}\\n\", \"    document = {'property': 'string'}\\n\", '    assert validator.validated(document) == document\\n', \"    document = {'property': 0}\\n\", '    assert validator.validated(document) is None\\n', '    schema = {\\n', \"    document = {'info': {'name': 'my name'}}\\n\", '    assert_success(document, schema, validator=validator)\\n', '    v = Validator(schema)\\n', '    assert_success(document, schema, v)\\n', '    assert v.validate(document)\\n', '    assert_success(document, schema, validator=v)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = True\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({\"foo\": {\"bar\": \"baz\"}}, schema, validator)\\n', '        assert_fail({}, schema, validator)\\n', '        assert_success({}, schema, validator)\\n', '        assert_fail({\"foo\": {}}, schema, validator)\\n', '        assert_success({\"foo\": {}}, schema, validator)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    assert validator.errors == {}\\n']",
  "context": "  schema = {'test_field': {'type': 'string'}}\n    validator = Validator(schema)\n    assert validator.validate({'test_field': 'foo'"
 },
 "525": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_validation.py",
  "lineno": "256",
  "column": "4",
  "slicing": "['    document = \"not a dict\"\\n', '        document, sample_schema, None, errors.DOCUMENT_FORMAT.format(document)\\n', \"    field = 'surname'\\n\", \"        {field: 'doe'},\\n\", '        error=(field, (), errors.UNKNOWN_FIELD, None),\\n', \"    assert validator.errors == {field: ['unknown field']}\\n\", \"    field = 'name'\\n\", '    schema = {field: {}}\\n', '    assert_success(document, schema)\\n', \"    field = 'a_dict_with_valuesrules'\\n\", \"    schema_field = 'a_string'\\n\", \"    value = {schema_field: 'not an integer'}\\n\", '    exp_child_errors = [\\n', '            (field, schema_field),\\n', \"            (field, 'valuesrules', 'type'),\\n\", '        {field: value},\\n', '            field,\\n', \"            (field, 'valuesrules'),\\n\", '        child_errors=exp_child_errors,\\n', '    assert_success(document)\\n', \"    field = 'one_or_more_strings'\\n\", \"    assert_success({field: 'foo'})\\n\", \"    assert_success({field: ['foo', 'bar']})\\n\", '    exp_child_errors = [\\n', \"        ((field, 1), (field, 'itemsrules', 'type'), errors.TYPE, ('string',))\\n\", \"        {field: ['foo', 23]},\\n\", \"        error=(field, (field, 'itemsrules'), errors.ITEMSRULES, {'type': ('string',)}),\\n\", '        child_errors=exp_child_errors,\\n', \"        {field: 23}, error=((field,), (field, 'type'), errors.TYPE, ('string', 'list'))\\n\", '        field: [{1: [\"must be one of these types: (\\'string\\',)\"]}]\\n', '            if isodd and not bool(value & 1):\\n', \"                self._error(field, 'Not an odd number')\\n\", \"    schema = {'test_field': {'isodd': True}}\\n\", '    validator = MyValidator(schema)\\n', \"    assert_success({'test_field': 7}, validator=validator)\\n\", '        validator=validator,\\n', \"    assert validator.errors == {'test_field': ['Not an odd number']}\\n\", \"    field = 'test'\\n\", \"    schema = {field: {'type': ('string',), 'empty': False, 'required': False}}\\n\", '    document = {field: None}\\n', '    validator = Validator(schema, ignore_none_values=False)\\n', '    assert_fail(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", '    validator.schema.validate()\\n', '    _errors = assert_fail(document, validator=validator)\\n', \"        _errors, field, (field, 'required'), errors.REQUIRED_FIELD, True\\n\", '    validator = Validator(schema, ignore_none_values=True)\\n', \"    validator.schema[field]['required'] = False\\n\", '    validator.schema.validate()\\n', '    assert_success(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", \"    assert validator.schema[field].get('required') is True\\n\", '    _errors = assert_fail(document=document, validator=validator)\\n', \"    assert_has_error(_errors, field, (field, 'required'), errors.REQUIRED_FIELD, True)\\n\", \"    assert_not_has_error(_errors, field, (field, 'type'), errors.TYPE, 'string')\\n\", '    schema = {}\\n', '    v = Validator(allow_unknown=True, schema=schema)\\n', '    assert_success({\"unknown1\": True, \"unknown2\": \"yes\"}, validator=v)\\n', \"    v.allow_unknown = {'type': 'string'}\\n\", \"    assert_success(document={'name': 'mark'}, validator=v)\\n\", '    assert_fail({\"name\": 1}, validator=v)\\n', '    v.allow_unknown = False\\n', \"    assert_fail({'name': 'mark'}, validator=v)\\n\", '    validator.allow_unknown = True\\n', \"    document = {'a_dict': {'foo': 'foo_value', 'bar': 25}}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_dict': ['foo', 'bar']}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_list_of_dicts': [{'sku': 'YZ069', 'price': 25, 'extra': True}]}\\n\", '    assert_success(document, validator=validator)\\n', '            return value == \"foo\"\\n', '    validator = CustomValidator({})\\n', '    validator.allow_unknown = {\"check_with\": \"foo\"}\\n', '    assert_success(document={\"fred\": \"foo\", \"barney\": \"foo\"}, validator=validator)\\n', \"    schema = {'test_field': {'type': 'string'}}\\n\", '    validator = Validator(schema)\\n', \"    assert validator.validate({'test_field': 'foo'})\\n\", \"    assert validator({'test_field': 'foo'})\\n\", \"    assert not validator.validate({'test_field': 1})\\n\", \"    assert not validator({'test_field': 1})\\n\", \"                self._error(field, 'self.context is not the root doc!')\\n\", '    schema = {\\n', \"        {'sub': [{'foo': 'bar'}, {'foo': 'baz'}]}, validator=MyValidator(schema)\\n\", \"    validator.schema = {'property': {'type': 'string'}}\\n\", \"    document = {'property': 'string'}\\n\", '    assert validator.validated(document) == document\\n', \"    document = {'property': 0}\\n\", '    assert validator.validated(document) is None\\n', '    schema = {\\n', \"    document = {'info': {'name': 'my name'}}\\n\", '    assert_success(document, schema, validator=validator)\\n', '    v = Validator(schema)\\n', '    assert_success(document, schema, v)\\n', '    assert v.validate(document)\\n', '    assert_success(document, schema, validator=v)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = True\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({\"foo\": {\"bar\": \"baz\"}}, schema, validator)\\n', '        assert_fail({}, schema, validator)\\n', '        assert_success({}, schema, validator)\\n', '        assert_fail({\"foo\": {}}, schema, validator)\\n', '        assert_success({\"foo\": {}}, schema, validator)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    assert validator.errors == {}\\n']",
  "context": "(field, 'self.context is not the root doc!')\n\n    schema = {\n        'sub': {\n            'type': 'list',\n     "
 },
 "526": {
  "name": "document",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_validation.py",
  "lineno": "273",
  "column": "4",
  "slicing": "[\"    document = {'property': 'string'}\\n\", '    assert validator.validated(document) == document\\n', '    assert validator.validated(document) is None\\n', '    assert_success(document, schema, validator=validator)\\n', '    assert_success(document, schema, v)\\n', '    assert v.validate(document)\\n', '    assert_success(document, schema, validator=v)\\n']",
  "context": "tor.schema = {'property': {'type': 'string'}}\n    document = {'property': 'string'}\n    assert validator.validated(document) == docume"
 },
 "527": {
  "name": "document",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_validation.py",
  "lineno": "275",
  "column": "4",
  "slicing": "[\"    document = {'property': 0}\\n\", '    assert validator.validated(document) is None\\n', '    assert_success(document, schema, validator=validator)\\n', '    assert_success(document, schema, v)\\n', '    assert v.validate(document)\\n', '    assert_success(document, schema, validator=v)\\n']",
  "context": "ert validator.validated(document) == document\n    document = {'property': 0}\n    assert validator.validated(document) is None\n\n"
 },
 "528": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_validation.py",
  "lineno": "281",
  "column": "4",
  "slicing": "['    document = \"not a dict\"\\n', '        document, sample_schema, None, errors.DOCUMENT_FORMAT.format(document)\\n', \"    field = 'surname'\\n\", \"        {field: 'doe'},\\n\", '        error=(field, (), errors.UNKNOWN_FIELD, None),\\n', \"    assert validator.errors == {field: ['unknown field']}\\n\", \"    field = 'name'\\n\", '    schema = {field: {}}\\n', '    assert_success(document, schema)\\n', \"    field = 'a_dict_with_valuesrules'\\n\", \"    schema_field = 'a_string'\\n\", \"    value = {schema_field: 'not an integer'}\\n\", '    exp_child_errors = [\\n', '            (field, schema_field),\\n', \"            (field, 'valuesrules', 'type'),\\n\", '        {field: value},\\n', '            field,\\n', \"            (field, 'valuesrules'),\\n\", '        child_errors=exp_child_errors,\\n', '    assert_success(document)\\n', \"    field = 'one_or_more_strings'\\n\", \"    assert_success({field: 'foo'})\\n\", \"    assert_success({field: ['foo', 'bar']})\\n\", '    exp_child_errors = [\\n', \"        ((field, 1), (field, 'itemsrules', 'type'), errors.TYPE, ('string',))\\n\", \"        {field: ['foo', 23]},\\n\", \"        error=(field, (field, 'itemsrules'), errors.ITEMSRULES, {'type': ('string',)}),\\n\", '        child_errors=exp_child_errors,\\n', \"        {field: 23}, error=((field,), (field, 'type'), errors.TYPE, ('string', 'list'))\\n\", '        field: [{1: [\"must be one of these types: (\\'string\\',)\"]}]\\n', '            if isodd and not bool(value & 1):\\n', \"                self._error(field, 'Not an odd number')\\n\", \"    schema = {'test_field': {'isodd': True}}\\n\", '    validator = MyValidator(schema)\\n', \"    assert_success({'test_field': 7}, validator=validator)\\n\", '        validator=validator,\\n', \"    assert validator.errors == {'test_field': ['Not an odd number']}\\n\", \"    field = 'test'\\n\", \"    schema = {field: {'type': ('string',), 'empty': False, 'required': False}}\\n\", '    document = {field: None}\\n', '    validator = Validator(schema, ignore_none_values=False)\\n', '    assert_fail(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", '    validator.schema.validate()\\n', '    _errors = assert_fail(document, validator=validator)\\n', \"        _errors, field, (field, 'required'), errors.REQUIRED_FIELD, True\\n\", '    validator = Validator(schema, ignore_none_values=True)\\n', \"    validator.schema[field]['required'] = False\\n\", '    validator.schema.validate()\\n', '    assert_success(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", \"    assert validator.schema[field].get('required') is True\\n\", '    _errors = assert_fail(document=document, validator=validator)\\n', \"    assert_has_error(_errors, field, (field, 'required'), errors.REQUIRED_FIELD, True)\\n\", \"    assert_not_has_error(_errors, field, (field, 'type'), errors.TYPE, 'string')\\n\", '    schema = {}\\n', '    v = Validator(allow_unknown=True, schema=schema)\\n', '    assert_success({\"unknown1\": True, \"unknown2\": \"yes\"}, validator=v)\\n', \"    v.allow_unknown = {'type': 'string'}\\n\", \"    assert_success(document={'name': 'mark'}, validator=v)\\n\", '    assert_fail({\"name\": 1}, validator=v)\\n', '    v.allow_unknown = False\\n', \"    assert_fail({'name': 'mark'}, validator=v)\\n\", '    validator.allow_unknown = True\\n', \"    document = {'a_dict': {'foo': 'foo_value', 'bar': 25}}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_dict': ['foo', 'bar']}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_list_of_dicts': [{'sku': 'YZ069', 'price': 25, 'extra': True}]}\\n\", '    assert_success(document, validator=validator)\\n', '            return value == \"foo\"\\n', '    validator = CustomValidator({})\\n', '    validator.allow_unknown = {\"check_with\": \"foo\"}\\n', '    assert_success(document={\"fred\": \"foo\", \"barney\": \"foo\"}, validator=validator)\\n', \"    schema = {'test_field': {'type': 'string'}}\\n\", '    validator = Validator(schema)\\n', \"    assert validator.validate({'test_field': 'foo'})\\n\", \"    assert validator({'test_field': 'foo'})\\n\", \"    assert not validator.validate({'test_field': 1})\\n\", \"    assert not validator({'test_field': 1})\\n\", \"                self._error(field, 'self.context is not the root doc!')\\n\", '    schema = {\\n', \"        {'sub': [{'foo': 'bar'}, {'foo': 'baz'}]}, validator=MyValidator(schema)\\n\", \"    validator.schema = {'property': {'type': 'string'}}\\n\", \"    document = {'property': 'string'}\\n\", '    assert validator.validated(document) == document\\n', \"    document = {'property': 0}\\n\", '    assert validator.validated(document) is None\\n', '    schema = {\\n', \"    document = {'info': {'name': 'my name'}}\\n\", '    assert_success(document, schema, validator=validator)\\n', '    v = Validator(schema)\\n', '    assert_success(document, schema, v)\\n', '    assert v.validate(document)\\n', '    assert_success(document, schema, validator=v)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = True\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({\"foo\": {\"bar\": \"baz\"}}, schema, validator)\\n', '        assert_fail({}, schema, validator)\\n', '        assert_success({}, schema, validator)\\n', '        assert_fail({\"foo\": {}}, schema, validator)\\n', '        assert_success({\"foo\": {}}, schema, validator)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    assert validator.errors == {}\\n']",
  "context": " https://github.com/pyeve/cerberus/issues/107\n    schema = {\n        'info': {\n            'type': 'dict',\n    "
 },
 "529": {
  "name": "document",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_validation.py",
  "lineno": "287",
  "column": "4",
  "slicing": "[\"    document = {'info': {'name': 'my name'}}\\n\", '    assert_success(document, schema, validator=validator)\\n', '    assert_success(document, schema, v)\\n', '    assert v.validate(document)\\n', '    assert_success(document, schema, validator=v)\\n']",
  "context": "'string', 'required': True}},\n        }\n    }\n    document = {'info': {'name': 'my name'}}\n    assert_success(document, schema, validator=val"
 },
 "530": {
  "name": "v",
  "type": "cerberus.Validator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_validation.py",
  "lineno": "290",
  "column": "4",
  "slicing": "['    document = \"not a dict\"\\n', '        document, sample_schema, None, errors.DOCUMENT_FORMAT.format(document)\\n', \"    field = 'surname'\\n\", \"        {field: 'doe'},\\n\", '        error=(field, (), errors.UNKNOWN_FIELD, None),\\n', \"    assert validator.errors == {field: ['unknown field']}\\n\", \"    field = 'name'\\n\", '    schema = {field: {}}\\n', '    assert_success(document, schema)\\n', \"    field = 'a_dict_with_valuesrules'\\n\", \"    schema_field = 'a_string'\\n\", \"    value = {schema_field: 'not an integer'}\\n\", '    exp_child_errors = [\\n', '            (field, schema_field),\\n', \"            (field, 'valuesrules', 'type'),\\n\", '        {field: value},\\n', '            field,\\n', \"            (field, 'valuesrules'),\\n\", '        child_errors=exp_child_errors,\\n', '    assert_success(document)\\n', \"    field = 'one_or_more_strings'\\n\", \"    assert_success({field: 'foo'})\\n\", \"    assert_success({field: ['foo', 'bar']})\\n\", '    exp_child_errors = [\\n', \"        ((field, 1), (field, 'itemsrules', 'type'), errors.TYPE, ('string',))\\n\", \"        {field: ['foo', 23]},\\n\", \"        error=(field, (field, 'itemsrules'), errors.ITEMSRULES, {'type': ('string',)}),\\n\", '        child_errors=exp_child_errors,\\n', \"        {field: 23}, error=((field,), (field, 'type'), errors.TYPE, ('string', 'list'))\\n\", '        field: [{1: [\"must be one of these types: (\\'string\\',)\"]}]\\n', '            if isodd and not bool(value & 1):\\n', \"                self._error(field, 'Not an odd number')\\n\", \"    schema = {'test_field': {'isodd': True}}\\n\", '    validator = MyValidator(schema)\\n', \"    assert_success({'test_field': 7}, validator=validator)\\n\", '        validator=validator,\\n', \"    assert validator.errors == {'test_field': ['Not an odd number']}\\n\", \"    field = 'test'\\n\", \"    schema = {field: {'type': ('string',), 'empty': False, 'required': False}}\\n\", '    document = {field: None}\\n', '    validator = Validator(schema, ignore_none_values=False)\\n', '    assert_fail(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", '    validator.schema.validate()\\n', '    _errors = assert_fail(document, validator=validator)\\n', \"        _errors, field, (field, 'required'), errors.REQUIRED_FIELD, True\\n\", '    validator = Validator(schema, ignore_none_values=True)\\n', \"    validator.schema[field]['required'] = False\\n\", '    validator.schema.validate()\\n', '    assert_success(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", \"    assert validator.schema[field].get('required') is True\\n\", '    _errors = assert_fail(document=document, validator=validator)\\n', \"    assert_has_error(_errors, field, (field, 'required'), errors.REQUIRED_FIELD, True)\\n\", \"    assert_not_has_error(_errors, field, (field, 'type'), errors.TYPE, 'string')\\n\", '    schema = {}\\n', '    v = Validator(allow_unknown=True, schema=schema)\\n', '    assert_success({\"unknown1\": True, \"unknown2\": \"yes\"}, validator=v)\\n', \"    v.allow_unknown = {'type': 'string'}\\n\", \"    assert_success(document={'name': 'mark'}, validator=v)\\n\", '    assert_fail({\"name\": 1}, validator=v)\\n', '    v.allow_unknown = False\\n', \"    assert_fail({'name': 'mark'}, validator=v)\\n\", '    validator.allow_unknown = True\\n', \"    document = {'a_dict': {'foo': 'foo_value', 'bar': 25}}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_dict': ['foo', 'bar']}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_list_of_dicts': [{'sku': 'YZ069', 'price': 25, 'extra': True}]}\\n\", '    assert_success(document, validator=validator)\\n', '            return value == \"foo\"\\n', '    validator = CustomValidator({})\\n', '    validator.allow_unknown = {\"check_with\": \"foo\"}\\n', '    assert_success(document={\"fred\": \"foo\", \"barney\": \"foo\"}, validator=validator)\\n', \"    schema = {'test_field': {'type': 'string'}}\\n\", '    validator = Validator(schema)\\n', \"    assert validator.validate({'test_field': 'foo'})\\n\", \"    assert validator({'test_field': 'foo'})\\n\", \"    assert not validator.validate({'test_field': 1})\\n\", \"    assert not validator({'test_field': 1})\\n\", \"                self._error(field, 'self.context is not the root doc!')\\n\", '    schema = {\\n', \"        {'sub': [{'foo': 'bar'}, {'foo': 'baz'}]}, validator=MyValidator(schema)\\n\", \"    validator.schema = {'property': {'type': 'string'}}\\n\", \"    document = {'property': 'string'}\\n\", '    assert validator.validated(document) == document\\n', \"    document = {'property': 0}\\n\", '    assert validator.validated(document) is None\\n', '    schema = {\\n', \"    document = {'info': {'name': 'my name'}}\\n\", '    assert_success(document, schema, validator=validator)\\n', '    v = Validator(schema)\\n', '    assert_success(document, schema, v)\\n', '    assert v.validate(document)\\n', '    assert_success(document, schema, validator=v)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = True\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({\"foo\": {\"bar\": \"baz\"}}, schema, validator)\\n', '        assert_fail({}, schema, validator)\\n', '        assert_success({}, schema, validator)\\n', '        assert_fail({\"foo\": {}}, schema, validator)\\n', '        assert_success({\"foo\": {}}, schema, validator)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    assert validator.errors == {}\\n']",
  "context": "ccess(document, schema, validator=validator)\n\n    v = Validator(schema)\n    assert_success(document, schema, v)\n    # it o"
 },
 "531": {
  "name": "v",
  "type": "DocumentPathTester",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_validation.py",
  "lineno": "305",
  "column": "4",
  "slicing": "['    document = \"not a dict\"\\n', '        document, sample_schema, None, errors.DOCUMENT_FORMAT.format(document)\\n', \"    field = 'surname'\\n\", \"        {field: 'doe'},\\n\", '        error=(field, (), errors.UNKNOWN_FIELD, None),\\n', \"    assert validator.errors == {field: ['unknown field']}\\n\", \"    field = 'name'\\n\", '    schema = {field: {}}\\n', '    assert_success(document, schema)\\n', \"    field = 'a_dict_with_valuesrules'\\n\", \"    schema_field = 'a_string'\\n\", \"    value = {schema_field: 'not an integer'}\\n\", '    exp_child_errors = [\\n', '            (field, schema_field),\\n', \"            (field, 'valuesrules', 'type'),\\n\", '        {field: value},\\n', '            field,\\n', \"            (field, 'valuesrules'),\\n\", '        child_errors=exp_child_errors,\\n', '    assert_success(document)\\n', \"    field = 'one_or_more_strings'\\n\", \"    assert_success({field: 'foo'})\\n\", \"    assert_success({field: ['foo', 'bar']})\\n\", '    exp_child_errors = [\\n', \"        ((field, 1), (field, 'itemsrules', 'type'), errors.TYPE, ('string',))\\n\", \"        {field: ['foo', 23]},\\n\", \"        error=(field, (field, 'itemsrules'), errors.ITEMSRULES, {'type': ('string',)}),\\n\", '        child_errors=exp_child_errors,\\n', \"        {field: 23}, error=((field,), (field, 'type'), errors.TYPE, ('string', 'list'))\\n\", '        field: [{1: [\"must be one of these types: (\\'string\\',)\"]}]\\n', '            if isodd and not bool(value & 1):\\n', \"                self._error(field, 'Not an odd number')\\n\", \"    schema = {'test_field': {'isodd': True}}\\n\", '    validator = MyValidator(schema)\\n', \"    assert_success({'test_field': 7}, validator=validator)\\n\", '        validator=validator,\\n', \"    assert validator.errors == {'test_field': ['Not an odd number']}\\n\", \"    field = 'test'\\n\", \"    schema = {field: {'type': ('string',), 'empty': False, 'required': False}}\\n\", '    document = {field: None}\\n', '    validator = Validator(schema, ignore_none_values=False)\\n', '    assert_fail(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", '    validator.schema.validate()\\n', '    _errors = assert_fail(document, validator=validator)\\n', \"        _errors, field, (field, 'required'), errors.REQUIRED_FIELD, True\\n\", '    validator = Validator(schema, ignore_none_values=True)\\n', \"    validator.schema[field]['required'] = False\\n\", '    validator.schema.validate()\\n', '    assert_success(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", \"    assert validator.schema[field].get('required') is True\\n\", '    _errors = assert_fail(document=document, validator=validator)\\n', \"    assert_has_error(_errors, field, (field, 'required'), errors.REQUIRED_FIELD, True)\\n\", \"    assert_not_has_error(_errors, field, (field, 'type'), errors.TYPE, 'string')\\n\", '    schema = {}\\n', '    v = Validator(allow_unknown=True, schema=schema)\\n', '    assert_success({\"unknown1\": True, \"unknown2\": \"yes\"}, validator=v)\\n', \"    v.allow_unknown = {'type': 'string'}\\n\", \"    assert_success(document={'name': 'mark'}, validator=v)\\n\", '    assert_fail({\"name\": 1}, validator=v)\\n', '    v.allow_unknown = False\\n', \"    assert_fail({'name': 'mark'}, validator=v)\\n\", '    validator.allow_unknown = True\\n', \"    document = {'a_dict': {'foo': 'foo_value', 'bar': 25}}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_dict': ['foo', 'bar']}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_list_of_dicts': [{'sku': 'YZ069', 'price': 25, 'extra': True}]}\\n\", '    assert_success(document, validator=validator)\\n', '            return value == \"foo\"\\n', '    validator = CustomValidator({})\\n', '    validator.allow_unknown = {\"check_with\": \"foo\"}\\n', '    assert_success(document={\"fred\": \"foo\", \"barney\": \"foo\"}, validator=validator)\\n', \"    schema = {'test_field': {'type': 'string'}}\\n\", '    validator = Validator(schema)\\n', \"    assert validator.validate({'test_field': 'foo'})\\n\", \"    assert validator({'test_field': 'foo'})\\n\", \"    assert not validator.validate({'test_field': 1})\\n\", \"    assert not validator({'test_field': 1})\\n\", \"                self._error(field, 'self.context is not the root doc!')\\n\", '    schema = {\\n', \"        {'sub': [{'foo': 'bar'}, {'foo': 'baz'}]}, validator=MyValidator(schema)\\n\", \"    validator.schema = {'property': {'type': 'string'}}\\n\", \"    document = {'property': 'string'}\\n\", '    assert validator.validated(document) == document\\n', \"    document = {'property': 0}\\n\", '    assert validator.validated(document) is None\\n', '    schema = {\\n', \"    document = {'info': {'name': 'my name'}}\\n\", '    assert_success(document, schema, validator=validator)\\n', '    v = Validator(schema)\\n', '    assert_success(document, schema, v)\\n', '    assert v.validate(document)\\n', '            test_doc = self.root_document\\n', '            for crumb in self.document_path:\\n', '                test_doc = test_doc[crumb]\\n', '            assert test_doc == self.document\\n', '    v = DocumentPathTester()\\n', '    assert_success(document, schema, validator=v)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = True\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({\"foo\": {\"bar\": \"baz\"}}, schema, validator)\\n', '        assert_fail({}, schema, validator)\\n', '        assert_success({}, schema, validator)\\n', '        assert_fail({\"foo\": {}}, schema, validator)\\n', '        assert_success({\"foo\": {}}, schema, validator)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    assert validator.errors == {}\\n']",
  "context": "            assert test_doc == self.document\n\n    v = DocumentPathTester()\n    schema = {'foo': {'schema': {'bar': {'trail': "
 },
 "532": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_validation.py",
  "lineno": "306",
  "column": "4",
  "slicing": "[\"    schema = {'foo': {'schema': {'bar': {'trail': True}}}}\\n\", '    assert_success(document, schema, validator=v)\\n', '        schema,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '        schema,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '        schema,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({\"foo\": {\"bar\": \"baz\"}}, schema, validator)\\n', '        assert_fail({}, schema, validator)\\n', '        assert_success({}, schema, validator)\\n', '        assert_fail({\"foo\": {}}, schema, validator)\\n', '        assert_success({\"foo\": {}}, schema, validator)\\n', '        schema,\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\"]",
  "context": "= self.document\n\n    v = DocumentPathTester()\n    schema = {'foo': {'schema': {'bar': {'trail': True}}}}\n    document = {'foo': {'bar': {}}}\n    assert_suc"
 },
 "533": {
  "name": "document",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_validation.py",
  "lineno": "307",
  "column": "4",
  "slicing": "[\"    document = {'foo': {'bar': {}}}\\n\", '    assert_success(document, schema, validator=v)\\n']",
  "context": "{'foo': {'schema': {'bar': {'trail': True}}}}\n    document = {'foo': {'bar': {}}}\n    assert_success(document, schema, validator=v)\n"
 },
 "534": {
  "name": "test_doc",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_validation.py",
  "lineno": "302",
  "column": "16",
  "slicing": "['    document = \"not a dict\"\\n', '        document, sample_schema, None, errors.DOCUMENT_FORMAT.format(document)\\n', \"    field = 'surname'\\n\", \"        {field: 'doe'},\\n\", '        error=(field, (), errors.UNKNOWN_FIELD, None),\\n', \"    assert validator.errors == {field: ['unknown field']}\\n\", \"    field = 'name'\\n\", '    schema = {field: {}}\\n', '    assert_success(document, schema)\\n', \"    field = 'a_dict_with_valuesrules'\\n\", \"    schema_field = 'a_string'\\n\", \"    value = {schema_field: 'not an integer'}\\n\", '    exp_child_errors = [\\n', '            (field, schema_field),\\n', \"            (field, 'valuesrules', 'type'),\\n\", '        {field: value},\\n', '            field,\\n', \"            (field, 'valuesrules'),\\n\", '        child_errors=exp_child_errors,\\n', '    assert_success(document)\\n', \"    field = 'one_or_more_strings'\\n\", \"    assert_success({field: 'foo'})\\n\", \"    assert_success({field: ['foo', 'bar']})\\n\", '    exp_child_errors = [\\n', \"        ((field, 1), (field, 'itemsrules', 'type'), errors.TYPE, ('string',))\\n\", \"        {field: ['foo', 23]},\\n\", \"        error=(field, (field, 'itemsrules'), errors.ITEMSRULES, {'type': ('string',)}),\\n\", '        child_errors=exp_child_errors,\\n', \"        {field: 23}, error=((field,), (field, 'type'), errors.TYPE, ('string', 'list'))\\n\", '        field: [{1: [\"must be one of these types: (\\'string\\',)\"]}]\\n', '            if isodd and not bool(value & 1):\\n', \"                self._error(field, 'Not an odd number')\\n\", \"    schema = {'test_field': {'isodd': True}}\\n\", '    validator = MyValidator(schema)\\n', \"    assert_success({'test_field': 7}, validator=validator)\\n\", '        validator=validator,\\n', \"    assert validator.errors == {'test_field': ['Not an odd number']}\\n\", \"    field = 'test'\\n\", \"    schema = {field: {'type': ('string',), 'empty': False, 'required': False}}\\n\", '    document = {field: None}\\n', '    validator = Validator(schema, ignore_none_values=False)\\n', '    assert_fail(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", '    validator.schema.validate()\\n', '    _errors = assert_fail(document, validator=validator)\\n', \"        _errors, field, (field, 'required'), errors.REQUIRED_FIELD, True\\n\", '    validator = Validator(schema, ignore_none_values=True)\\n', \"    validator.schema[field]['required'] = False\\n\", '    validator.schema.validate()\\n', '    assert_success(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", \"    assert validator.schema[field].get('required') is True\\n\", '    _errors = assert_fail(document=document, validator=validator)\\n', \"    assert_has_error(_errors, field, (field, 'required'), errors.REQUIRED_FIELD, True)\\n\", \"    assert_not_has_error(_errors, field, (field, 'type'), errors.TYPE, 'string')\\n\", '    schema = {}\\n', '    v = Validator(allow_unknown=True, schema=schema)\\n', '    assert_success({\"unknown1\": True, \"unknown2\": \"yes\"}, validator=v)\\n', \"    v.allow_unknown = {'type': 'string'}\\n\", \"    assert_success(document={'name': 'mark'}, validator=v)\\n\", '    assert_fail({\"name\": 1}, validator=v)\\n', '    v.allow_unknown = False\\n', \"    assert_fail({'name': 'mark'}, validator=v)\\n\", '    validator.allow_unknown = True\\n', \"    document = {'a_dict': {'foo': 'foo_value', 'bar': 25}}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_dict': ['foo', 'bar']}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_list_of_dicts': [{'sku': 'YZ069', 'price': 25, 'extra': True}]}\\n\", '    assert_success(document, validator=validator)\\n', '            return value == \"foo\"\\n', '    validator = CustomValidator({})\\n', '    validator.allow_unknown = {\"check_with\": \"foo\"}\\n', '    assert_success(document={\"fred\": \"foo\", \"barney\": \"foo\"}, validator=validator)\\n', \"    schema = {'test_field': {'type': 'string'}}\\n\", '    validator = Validator(schema)\\n', \"    assert validator.validate({'test_field': 'foo'})\\n\", \"    assert validator({'test_field': 'foo'})\\n\", \"    assert not validator.validate({'test_field': 1})\\n\", \"    assert not validator({'test_field': 1})\\n\", \"                self._error(field, 'self.context is not the root doc!')\\n\", '    schema = {\\n', \"        {'sub': [{'foo': 'bar'}, {'foo': 'baz'}]}, validator=MyValidator(schema)\\n\", \"    validator.schema = {'property': {'type': 'string'}}\\n\", \"    document = {'property': 'string'}\\n\", '    assert validator.validated(document) == document\\n', \"    document = {'property': 0}\\n\", '    assert validator.validated(document) is None\\n', '    schema = {\\n', \"    document = {'info': {'name': 'my name'}}\\n\", '    assert_success(document, schema, validator=validator)\\n', '    v = Validator(schema)\\n', '    assert_success(document, schema, v)\\n', '    assert v.validate(document)\\n', '            test_doc = self.root_document\\n', '            for crumb in self.document_path:\\n', '                test_doc = test_doc[crumb]\\n', '            assert test_doc == self.document\\n', '    assert_success(document, schema, validator=v)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = True\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({\"foo\": {\"bar\": \"baz\"}}, schema, validator)\\n', '        assert_fail({}, schema, validator)\\n', '        assert_success({}, schema, validator)\\n', '        assert_fail({\"foo\": {}}, schema, validator)\\n', '        assert_success({\"foo\": {}}, schema, validator)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    assert validator.errors == {}\\n']",
  "context": " for crumb in self.document_path:\n                test_doc = test_doc[crumb]\n            assert test_doc == self.document\n\n    "
 },
 "535": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_validation.py",
  "lineno": "312",
  "column": "4",
  "slicing": "[\"    schema = {'foo': {'type': 'string'}}\\n\", '        schema,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '        schema,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '        schema,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({\"foo\": {\"bar\": \"baz\"}}, schema, validator)\\n', '        assert_fail({}, schema, validator)\\n', '        assert_success({}, schema, validator)\\n', '        assert_fail({\"foo\": {}}, schema, validator)\\n', '        assert_success({\"foo\": {}}, schema, validator)\\n', '        schema,\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\"]",
  "context": "validator=v)\n\n\ndef test_require_all_simple():\n    schema = {'foo': {'type': 'string'}}\n    validator = Validator(require_all=True)\n    as"
 },
 "536": {
  "name": "validator",
  "type": "cerberus.Validator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_validation.py",
  "lineno": "313",
  "column": "4",
  "slicing": "['    document = \"not a dict\"\\n', '        document, sample_schema, None, errors.DOCUMENT_FORMAT.format(document)\\n', \"    field = 'surname'\\n\", \"        {field: 'doe'},\\n\", '        error=(field, (), errors.UNKNOWN_FIELD, None),\\n', \"    assert validator.errors == {field: ['unknown field']}\\n\", \"    field = 'name'\\n\", '    schema = {field: {}}\\n', '    assert_success(document, schema)\\n', \"    field = 'a_dict_with_valuesrules'\\n\", \"    schema_field = 'a_string'\\n\", \"    value = {schema_field: 'not an integer'}\\n\", '    exp_child_errors = [\\n', '            (field, schema_field),\\n', \"            (field, 'valuesrules', 'type'),\\n\", '        {field: value},\\n', '            field,\\n', \"            (field, 'valuesrules'),\\n\", '        child_errors=exp_child_errors,\\n', '    assert_success(document)\\n', \"    field = 'one_or_more_strings'\\n\", \"    assert_success({field: 'foo'})\\n\", \"    assert_success({field: ['foo', 'bar']})\\n\", '    exp_child_errors = [\\n', \"        ((field, 1), (field, 'itemsrules', 'type'), errors.TYPE, ('string',))\\n\", \"        {field: ['foo', 23]},\\n\", \"        error=(field, (field, 'itemsrules'), errors.ITEMSRULES, {'type': ('string',)}),\\n\", '        child_errors=exp_child_errors,\\n', \"        {field: 23}, error=((field,), (field, 'type'), errors.TYPE, ('string', 'list'))\\n\", '        field: [{1: [\"must be one of these types: (\\'string\\',)\"]}]\\n', '            if isodd and not bool(value & 1):\\n', \"                self._error(field, 'Not an odd number')\\n\", \"    schema = {'test_field': {'isodd': True}}\\n\", '    validator = MyValidator(schema)\\n', \"    assert_success({'test_field': 7}, validator=validator)\\n\", '        validator=validator,\\n', \"    assert validator.errors == {'test_field': ['Not an odd number']}\\n\", \"    field = 'test'\\n\", \"    schema = {field: {'type': ('string',), 'empty': False, 'required': False}}\\n\", '    document = {field: None}\\n', '    validator = Validator(schema, ignore_none_values=False)\\n', '    assert_fail(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", '    validator.schema.validate()\\n', '    _errors = assert_fail(document, validator=validator)\\n', \"        _errors, field, (field, 'required'), errors.REQUIRED_FIELD, True\\n\", '    validator = Validator(schema, ignore_none_values=True)\\n', \"    validator.schema[field]['required'] = False\\n\", '    validator.schema.validate()\\n', '    assert_success(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", \"    assert validator.schema[field].get('required') is True\\n\", '    _errors = assert_fail(document=document, validator=validator)\\n', \"    assert_has_error(_errors, field, (field, 'required'), errors.REQUIRED_FIELD, True)\\n\", \"    assert_not_has_error(_errors, field, (field, 'type'), errors.TYPE, 'string')\\n\", '    schema = {}\\n', '    v = Validator(allow_unknown=True, schema=schema)\\n', '    assert_success({\"unknown1\": True, \"unknown2\": \"yes\"}, validator=v)\\n', \"    v.allow_unknown = {'type': 'string'}\\n\", \"    assert_success(document={'name': 'mark'}, validator=v)\\n\", '    assert_fail({\"name\": 1}, validator=v)\\n', '    v.allow_unknown = False\\n', \"    assert_fail({'name': 'mark'}, validator=v)\\n\", '    validator.allow_unknown = True\\n', \"    document = {'a_dict': {'foo': 'foo_value', 'bar': 25}}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_dict': ['foo', 'bar']}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_list_of_dicts': [{'sku': 'YZ069', 'price': 25, 'extra': True}]}\\n\", '    assert_success(document, validator=validator)\\n', '            return value == \"foo\"\\n', '    validator = CustomValidator({})\\n', '    validator.allow_unknown = {\"check_with\": \"foo\"}\\n', '    assert_success(document={\"fred\": \"foo\", \"barney\": \"foo\"}, validator=validator)\\n', \"    schema = {'test_field': {'type': 'string'}}\\n\", '    validator = Validator(schema)\\n', \"    assert validator.validate({'test_field': 'foo'})\\n\", \"    assert validator({'test_field': 'foo'})\\n\", \"    assert not validator.validate({'test_field': 1})\\n\", \"    assert not validator({'test_field': 1})\\n\", \"                self._error(field, 'self.context is not the root doc!')\\n\", '    schema = {\\n', \"        {'sub': [{'foo': 'bar'}, {'foo': 'baz'}]}, validator=MyValidator(schema)\\n\", \"    validator.schema = {'property': {'type': 'string'}}\\n\", \"    document = {'property': 'string'}\\n\", '    assert validator.validated(document) == document\\n', \"    document = {'property': 0}\\n\", '    assert validator.validated(document) is None\\n', '    schema = {\\n', \"    document = {'info': {'name': 'my name'}}\\n\", '    assert_success(document, schema, validator=validator)\\n', '    v = Validator(schema)\\n', '    assert_success(document, schema, v)\\n', '    assert v.validate(document)\\n', '            test_doc = self.root_document\\n', '            for crumb in self.document_path:\\n', '                test_doc = test_doc[crumb]\\n', '            assert test_doc == self.document\\n', '    v = DocumentPathTester()\\n', \"    schema = {'foo': {'schema': {'bar': {'trail': True}}}}\\n\", \"    document = {'foo': {'bar': {}}}\\n\", '    assert_success(document, schema, validator=v)\\n', \"    schema = {'foo': {'type': 'string'}}\\n\", '    validator = Validator(require_all=True)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = True\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({\"foo\": {\"bar\": \"baz\"}}, schema, validator)\\n', '        assert_fail({}, schema, validator)\\n', '        assert_success({}, schema, validator)\\n', '        assert_fail({\"foo\": {}}, schema, validator)\\n', '        assert_success({\"foo\": {}}, schema, validator)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    assert validator.errors == {}\\n']",
  "context": "e():\n    schema = {'foo': {'type': 'string'}}\n    validator = Validator(require_all=True)\n    assert_fail(\n        {},\n        schema,\n     "
 },
 "537": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_validation.py",
  "lineno": "327",
  "column": "4",
  "slicing": "[\"    schema = {'foo': {'type': 'string', 'required': False}}\\n\", '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '        schema,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '        schema,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({\"foo\": {\"bar\": \"baz\"}}, schema, validator)\\n', '        assert_fail({}, schema, validator)\\n', '        assert_success({}, schema, validator)\\n', '        assert_fail({\"foo\": {}}, schema, validator)\\n', '        assert_success({\"foo\": {}}, schema, validator)\\n', '        schema,\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\"]",
  "context": "\ndef test_require_all_override_by_required():\n    schema = {'foo': {'type': 'string', 'required': False}}\n    validator = Validator(require_all=True)\n    as"
 },
 "538": {
  "name": "validator",
  "type": "cerberus.Validator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_validation.py",
  "lineno": "328",
  "column": "4",
  "slicing": "['    document = \"not a dict\"\\n', '        document, sample_schema, None, errors.DOCUMENT_FORMAT.format(document)\\n', \"    field = 'surname'\\n\", \"        {field: 'doe'},\\n\", '        error=(field, (), errors.UNKNOWN_FIELD, None),\\n', \"    assert validator.errors == {field: ['unknown field']}\\n\", \"    field = 'name'\\n\", '    schema = {field: {}}\\n', '    assert_success(document, schema)\\n', \"    field = 'a_dict_with_valuesrules'\\n\", \"    schema_field = 'a_string'\\n\", \"    value = {schema_field: 'not an integer'}\\n\", '    exp_child_errors = [\\n', '            (field, schema_field),\\n', \"            (field, 'valuesrules', 'type'),\\n\", '        {field: value},\\n', '            field,\\n', \"            (field, 'valuesrules'),\\n\", '        child_errors=exp_child_errors,\\n', '    assert_success(document)\\n', \"    field = 'one_or_more_strings'\\n\", \"    assert_success({field: 'foo'})\\n\", \"    assert_success({field: ['foo', 'bar']})\\n\", '    exp_child_errors = [\\n', \"        ((field, 1), (field, 'itemsrules', 'type'), errors.TYPE, ('string',))\\n\", \"        {field: ['foo', 23]},\\n\", \"        error=(field, (field, 'itemsrules'), errors.ITEMSRULES, {'type': ('string',)}),\\n\", '        child_errors=exp_child_errors,\\n', \"        {field: 23}, error=((field,), (field, 'type'), errors.TYPE, ('string', 'list'))\\n\", '        field: [{1: [\"must be one of these types: (\\'string\\',)\"]}]\\n', '            if isodd and not bool(value & 1):\\n', \"                self._error(field, 'Not an odd number')\\n\", \"    schema = {'test_field': {'isodd': True}}\\n\", '    validator = MyValidator(schema)\\n', \"    assert_success({'test_field': 7}, validator=validator)\\n\", '        validator=validator,\\n', \"    assert validator.errors == {'test_field': ['Not an odd number']}\\n\", \"    field = 'test'\\n\", \"    schema = {field: {'type': ('string',), 'empty': False, 'required': False}}\\n\", '    document = {field: None}\\n', '    validator = Validator(schema, ignore_none_values=False)\\n', '    assert_fail(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", '    validator.schema.validate()\\n', '    _errors = assert_fail(document, validator=validator)\\n', \"        _errors, field, (field, 'required'), errors.REQUIRED_FIELD, True\\n\", '    validator = Validator(schema, ignore_none_values=True)\\n', \"    validator.schema[field]['required'] = False\\n\", '    validator.schema.validate()\\n', '    assert_success(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", \"    assert validator.schema[field].get('required') is True\\n\", '    _errors = assert_fail(document=document, validator=validator)\\n', \"    assert_has_error(_errors, field, (field, 'required'), errors.REQUIRED_FIELD, True)\\n\", \"    assert_not_has_error(_errors, field, (field, 'type'), errors.TYPE, 'string')\\n\", '    schema = {}\\n', '    v = Validator(allow_unknown=True, schema=schema)\\n', '    assert_success({\"unknown1\": True, \"unknown2\": \"yes\"}, validator=v)\\n', \"    v.allow_unknown = {'type': 'string'}\\n\", \"    assert_success(document={'name': 'mark'}, validator=v)\\n\", '    assert_fail({\"name\": 1}, validator=v)\\n', '    v.allow_unknown = False\\n', \"    assert_fail({'name': 'mark'}, validator=v)\\n\", '    validator.allow_unknown = True\\n', \"    document = {'a_dict': {'foo': 'foo_value', 'bar': 25}}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_dict': ['foo', 'bar']}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_list_of_dicts': [{'sku': 'YZ069', 'price': 25, 'extra': True}]}\\n\", '    assert_success(document, validator=validator)\\n', '            return value == \"foo\"\\n', '    validator = CustomValidator({})\\n', '    validator.allow_unknown = {\"check_with\": \"foo\"}\\n', '    assert_success(document={\"fred\": \"foo\", \"barney\": \"foo\"}, validator=validator)\\n', \"    schema = {'test_field': {'type': 'string'}}\\n\", '    validator = Validator(schema)\\n', \"    assert validator.validate({'test_field': 'foo'})\\n\", \"    assert validator({'test_field': 'foo'})\\n\", \"    assert not validator.validate({'test_field': 1})\\n\", \"    assert not validator({'test_field': 1})\\n\", \"                self._error(field, 'self.context is not the root doc!')\\n\", '    schema = {\\n', \"        {'sub': [{'foo': 'bar'}, {'foo': 'baz'}]}, validator=MyValidator(schema)\\n\", \"    validator.schema = {'property': {'type': 'string'}}\\n\", \"    document = {'property': 'string'}\\n\", '    assert validator.validated(document) == document\\n', \"    document = {'property': 0}\\n\", '    assert validator.validated(document) is None\\n', '    schema = {\\n', \"    document = {'info': {'name': 'my name'}}\\n\", '    assert_success(document, schema, validator=validator)\\n', '    v = Validator(schema)\\n', '    assert_success(document, schema, v)\\n', '    assert v.validate(document)\\n', '            test_doc = self.root_document\\n', '            for crumb in self.document_path:\\n', '                test_doc = test_doc[crumb]\\n', '            assert test_doc == self.document\\n', '    v = DocumentPathTester()\\n', \"    schema = {'foo': {'schema': {'bar': {'trail': True}}}}\\n\", \"    document = {'foo': {'bar': {}}}\\n\", '    assert_success(document, schema, validator=v)\\n', \"    schema = {'foo': {'type': 'string'}}\\n\", '    validator = Validator(require_all=True)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", \"    schema = {'foo': {'type': 'string', 'required': False}}\\n\", '    validator = Validator(require_all=True)\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = True\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({\"foo\": {\"bar\": \"baz\"}}, schema, validator)\\n', '        assert_fail({}, schema, validator)\\n', '        assert_success({}, schema, validator)\\n', '        assert_fail({\"foo\": {}}, schema, validator)\\n', '        assert_success({\"foo\": {}}, schema, validator)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    assert validator.errors == {}\\n']",
  "context": "'foo': {'type': 'string', 'required': False}}\n    validator = Validator(require_all=True)\n    assert_success({}, schema, validator)\n    asse"
 },
 "539": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_validation.py",
  "lineno": "335",
  "column": "4",
  "slicing": "[\"    schema = {'foo': {'type': 'string', 'required': True}}\\n\", '        schema,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '        schema,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    assert_success({\"foo\": {\"bar\": \"baz\"}}, schema, validator)\\n', '        assert_fail({}, schema, validator)\\n', '        assert_success({}, schema, validator)\\n', '        assert_fail({\"foo\": {}}, schema, validator)\\n', '        assert_success({\"foo\": {}}, schema, validator)\\n', '        schema,\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\"]",
  "context": "t_success({'foo': 'bar'}, schema, validator)\n\n    schema = {'foo': {'type': 'string', 'required': True}}\n    validator.require_all = True\n    assert_fail(\n"
 },
 "540": {
  "name": "sub_schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_validation.py",
  "lineno": "361",
  "column": "4",
  "slicing": "['    sub_schema = {\"bar\": {\"type\": \"string\"}}\\n', '            \"schema\": sub_schema,\\n']",
  "context": "validator_require_all, sub_doc_require_all\n):\n    sub_schema = {\"bar\": {\"type\": \"string\"}}\n    schema = {\n        \"foo\": {\n            \"type\""
 },
 "541": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_validation.py",
  "lineno": "362",
  "column": "4",
  "slicing": "['    schema = {\\n', '    assert_success({\"foo\": {\"bar\": \"baz\"}}, schema, validator)\\n', '        assert_fail({}, schema, validator)\\n', '        assert_success({}, schema, validator)\\n', '        assert_fail({\"foo\": {}}, schema, validator)\\n', '        assert_success({\"foo\": {}}, schema, validator)\\n', '        schema,\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\"]",
  "context": "\n    sub_schema = {\"bar\": {\"type\": \"string\"}}\n    schema = {\n        \"foo\": {\n            \"type\": \"dict\",\n     "
 },
 "542": {
  "name": "validator",
  "type": "cerberus.Validator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_validation.py",
  "lineno": "369",
  "column": "4",
  "slicing": "['    document = \"not a dict\"\\n', '        document, sample_schema, None, errors.DOCUMENT_FORMAT.format(document)\\n', \"    field = 'surname'\\n\", \"        {field: 'doe'},\\n\", '        error=(field, (), errors.UNKNOWN_FIELD, None),\\n', \"    assert validator.errors == {field: ['unknown field']}\\n\", \"    field = 'name'\\n\", '    schema = {field: {}}\\n', '    assert_success(document, schema)\\n', \"    field = 'a_dict_with_valuesrules'\\n\", \"    schema_field = 'a_string'\\n\", \"    value = {schema_field: 'not an integer'}\\n\", '    exp_child_errors = [\\n', '            (field, schema_field),\\n', \"            (field, 'valuesrules', 'type'),\\n\", '        {field: value},\\n', '            field,\\n', \"            (field, 'valuesrules'),\\n\", '        child_errors=exp_child_errors,\\n', '    assert_success(document)\\n', \"    field = 'one_or_more_strings'\\n\", \"    assert_success({field: 'foo'})\\n\", \"    assert_success({field: ['foo', 'bar']})\\n\", '    exp_child_errors = [\\n', \"        ((field, 1), (field, 'itemsrules', 'type'), errors.TYPE, ('string',))\\n\", \"        {field: ['foo', 23]},\\n\", \"        error=(field, (field, 'itemsrules'), errors.ITEMSRULES, {'type': ('string',)}),\\n\", '        child_errors=exp_child_errors,\\n', \"        {field: 23}, error=((field,), (field, 'type'), errors.TYPE, ('string', 'list'))\\n\", '        field: [{1: [\"must be one of these types: (\\'string\\',)\"]}]\\n', '            if isodd and not bool(value & 1):\\n', \"                self._error(field, 'Not an odd number')\\n\", \"    schema = {'test_field': {'isodd': True}}\\n\", '    validator = MyValidator(schema)\\n', \"    assert_success({'test_field': 7}, validator=validator)\\n\", '        validator=validator,\\n', \"    assert validator.errors == {'test_field': ['Not an odd number']}\\n\", \"    field = 'test'\\n\", \"    schema = {field: {'type': ('string',), 'empty': False, 'required': False}}\\n\", '    document = {field: None}\\n', '    validator = Validator(schema, ignore_none_values=False)\\n', '    assert_fail(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", '    validator.schema.validate()\\n', '    _errors = assert_fail(document, validator=validator)\\n', \"        _errors, field, (field, 'required'), errors.REQUIRED_FIELD, True\\n\", '    validator = Validator(schema, ignore_none_values=True)\\n', \"    validator.schema[field]['required'] = False\\n\", '    validator.schema.validate()\\n', '    assert_success(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", \"    assert validator.schema[field].get('required') is True\\n\", '    _errors = assert_fail(document=document, validator=validator)\\n', \"    assert_has_error(_errors, field, (field, 'required'), errors.REQUIRED_FIELD, True)\\n\", \"    assert_not_has_error(_errors, field, (field, 'type'), errors.TYPE, 'string')\\n\", '    schema = {}\\n', '    v = Validator(allow_unknown=True, schema=schema)\\n', '    assert_success({\"unknown1\": True, \"unknown2\": \"yes\"}, validator=v)\\n', \"    v.allow_unknown = {'type': 'string'}\\n\", \"    assert_success(document={'name': 'mark'}, validator=v)\\n\", '    assert_fail({\"name\": 1}, validator=v)\\n', '    v.allow_unknown = False\\n', \"    assert_fail({'name': 'mark'}, validator=v)\\n\", '    validator.allow_unknown = True\\n', \"    document = {'a_dict': {'foo': 'foo_value', 'bar': 25}}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_dict': ['foo', 'bar']}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_list_of_dicts': [{'sku': 'YZ069', 'price': 25, 'extra': True}]}\\n\", '    assert_success(document, validator=validator)\\n', '            return value == \"foo\"\\n', '    validator = CustomValidator({})\\n', '    validator.allow_unknown = {\"check_with\": \"foo\"}\\n', '    assert_success(document={\"fred\": \"foo\", \"barney\": \"foo\"}, validator=validator)\\n', \"    schema = {'test_field': {'type': 'string'}}\\n\", '    validator = Validator(schema)\\n', \"    assert validator.validate({'test_field': 'foo'})\\n\", \"    assert validator({'test_field': 'foo'})\\n\", \"    assert not validator.validate({'test_field': 1})\\n\", \"    assert not validator({'test_field': 1})\\n\", \"                self._error(field, 'self.context is not the root doc!')\\n\", '    schema = {\\n', \"        {'sub': [{'foo': 'bar'}, {'foo': 'baz'}]}, validator=MyValidator(schema)\\n\", \"    validator.schema = {'property': {'type': 'string'}}\\n\", \"    document = {'property': 'string'}\\n\", '    assert validator.validated(document) == document\\n', \"    document = {'property': 0}\\n\", '    assert validator.validated(document) is None\\n', '    schema = {\\n', \"    document = {'info': {'name': 'my name'}}\\n\", '    assert_success(document, schema, validator=validator)\\n', '    v = Validator(schema)\\n', '    assert_success(document, schema, v)\\n', '    assert v.validate(document)\\n', '            test_doc = self.root_document\\n', '            for crumb in self.document_path:\\n', '                test_doc = test_doc[crumb]\\n', '            assert test_doc == self.document\\n', '    v = DocumentPathTester()\\n', \"    schema = {'foo': {'schema': {'bar': {'trail': True}}}}\\n\", \"    document = {'foo': {'bar': {}}}\\n\", '    assert_success(document, schema, validator=v)\\n', \"    schema = {'foo': {'type': 'string'}}\\n\", '    validator = Validator(require_all=True)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", \"    schema = {'foo': {'type': 'string', 'required': False}}\\n\", '    validator = Validator(require_all=True)\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", \"    schema = {'foo': {'type': 'string', 'required': True}}\\n\", '    validator.require_all = True\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    sub_schema = {\"bar\": {\"type\": \"string\"}}\\n', '    schema = {\\n', '            \"schema\": sub_schema,\\n', '    validator = Validator(require_all=validator_require_all)\\n', '    assert_success({\"foo\": {\"bar\": \"baz\"}}, schema, validator)\\n', '        assert_fail({}, schema, validator)\\n', '        assert_success({}, schema, validator)\\n', '        assert_fail({\"foo\": {}}, schema, validator)\\n', '        assert_success({\"foo\": {}}, schema, validator)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    assert validator.errors == {}\\n']",
  "context": "        \"schema\": sub_schema,\n        }\n    }\n    validator = Validator(require_all=validator_require_all)\n\n    assert_success({\"foo\": {\"bar\": \"baz\"}}, schem"
 },
 "543": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_validation.py",
  "lineno": "383",
  "column": "4",
  "slicing": "['    schema = {\\n', '        schema,\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\"]",
  "context": "idator)\n\n\ndef test_require_all_and_exclude():\n    schema = {\n        'foo': {'type': 'string', 'excludes': 'bar"
 },
 "544": {
  "name": "validator",
  "type": "cerberus.Validator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_validation.py",
  "lineno": "387",
  "column": "4",
  "slicing": "['    document = \"not a dict\"\\n', '        document, sample_schema, None, errors.DOCUMENT_FORMAT.format(document)\\n', \"    field = 'surname'\\n\", \"        {field: 'doe'},\\n\", '        error=(field, (), errors.UNKNOWN_FIELD, None),\\n', \"    assert validator.errors == {field: ['unknown field']}\\n\", \"    field = 'name'\\n\", '    schema = {field: {}}\\n', '    assert_success(document, schema)\\n', \"    field = 'a_dict_with_valuesrules'\\n\", \"    schema_field = 'a_string'\\n\", \"    value = {schema_field: 'not an integer'}\\n\", '    exp_child_errors = [\\n', '            (field, schema_field),\\n', \"            (field, 'valuesrules', 'type'),\\n\", '        {field: value},\\n', '            field,\\n', \"            (field, 'valuesrules'),\\n\", '        child_errors=exp_child_errors,\\n', '    assert_success(document)\\n', \"    field = 'one_or_more_strings'\\n\", \"    assert_success({field: 'foo'})\\n\", \"    assert_success({field: ['foo', 'bar']})\\n\", '    exp_child_errors = [\\n', \"        ((field, 1), (field, 'itemsrules', 'type'), errors.TYPE, ('string',))\\n\", \"        {field: ['foo', 23]},\\n\", \"        error=(field, (field, 'itemsrules'), errors.ITEMSRULES, {'type': ('string',)}),\\n\", '        child_errors=exp_child_errors,\\n', \"        {field: 23}, error=((field,), (field, 'type'), errors.TYPE, ('string', 'list'))\\n\", '        field: [{1: [\"must be one of these types: (\\'string\\',)\"]}]\\n', '            if isodd and not bool(value & 1):\\n', \"                self._error(field, 'Not an odd number')\\n\", \"    schema = {'test_field': {'isodd': True}}\\n\", '    validator = MyValidator(schema)\\n', \"    assert_success({'test_field': 7}, validator=validator)\\n\", '        validator=validator,\\n', \"    assert validator.errors == {'test_field': ['Not an odd number']}\\n\", \"    field = 'test'\\n\", \"    schema = {field: {'type': ('string',), 'empty': False, 'required': False}}\\n\", '    document = {field: None}\\n', '    validator = Validator(schema, ignore_none_values=False)\\n', '    assert_fail(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", '    validator.schema.validate()\\n', '    _errors = assert_fail(document, validator=validator)\\n', \"        _errors, field, (field, 'required'), errors.REQUIRED_FIELD, True\\n\", '    validator = Validator(schema, ignore_none_values=True)\\n', \"    validator.schema[field]['required'] = False\\n\", '    validator.schema.validate()\\n', '    assert_success(document, validator=validator)\\n', \"    validator.schema[field]['required'] = True\\n\", \"    assert validator.schema[field].get('required') is True\\n\", '    _errors = assert_fail(document=document, validator=validator)\\n', \"    assert_has_error(_errors, field, (field, 'required'), errors.REQUIRED_FIELD, True)\\n\", \"    assert_not_has_error(_errors, field, (field, 'type'), errors.TYPE, 'string')\\n\", '    schema = {}\\n', '    v = Validator(allow_unknown=True, schema=schema)\\n', '    assert_success({\"unknown1\": True, \"unknown2\": \"yes\"}, validator=v)\\n', \"    v.allow_unknown = {'type': 'string'}\\n\", \"    assert_success(document={'name': 'mark'}, validator=v)\\n\", '    assert_fail({\"name\": 1}, validator=v)\\n', '    v.allow_unknown = False\\n', \"    assert_fail({'name': 'mark'}, validator=v)\\n\", '    validator.allow_unknown = True\\n', \"    document = {'a_dict': {'foo': 'foo_value', 'bar': 25}}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_dict': ['foo', 'bar']}\\n\", '    assert_success(document, {}, validator=validator)\\n', '    validator.allow_unknown = True\\n', \"    document = {'a_list_of_dicts': [{'sku': 'YZ069', 'price': 25, 'extra': True}]}\\n\", '    assert_success(document, validator=validator)\\n', '            return value == \"foo\"\\n', '    validator = CustomValidator({})\\n', '    validator.allow_unknown = {\"check_with\": \"foo\"}\\n', '    assert_success(document={\"fred\": \"foo\", \"barney\": \"foo\"}, validator=validator)\\n', \"    schema = {'test_field': {'type': 'string'}}\\n\", '    validator = Validator(schema)\\n', \"    assert validator.validate({'test_field': 'foo'})\\n\", \"    assert validator({'test_field': 'foo'})\\n\", \"    assert not validator.validate({'test_field': 1})\\n\", \"    assert not validator({'test_field': 1})\\n\", \"                self._error(field, 'self.context is not the root doc!')\\n\", '    schema = {\\n', \"        {'sub': [{'foo': 'bar'}, {'foo': 'baz'}]}, validator=MyValidator(schema)\\n\", \"    validator.schema = {'property': {'type': 'string'}}\\n\", \"    document = {'property': 'string'}\\n\", '    assert validator.validated(document) == document\\n', \"    document = {'property': 0}\\n\", '    assert validator.validated(document) is None\\n', '    schema = {\\n', \"    document = {'info': {'name': 'my name'}}\\n\", '    assert_success(document, schema, validator=validator)\\n', '    v = Validator(schema)\\n', '    assert_success(document, schema, v)\\n', '    assert v.validate(document)\\n', '            test_doc = self.root_document\\n', '            for crumb in self.document_path:\\n', '                test_doc = test_doc[crumb]\\n', '            assert test_doc == self.document\\n', '    v = DocumentPathTester()\\n', \"    schema = {'foo': {'schema': {'bar': {'trail': True}}}}\\n\", \"    document = {'foo': {'bar': {}}}\\n\", '    assert_success(document, schema, validator=v)\\n', \"    schema = {'foo': {'type': 'string'}}\\n\", '    validator = Validator(require_all=True)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", \"    schema = {'foo': {'type': 'string', 'required': False}}\\n\", '    validator = Validator(require_all=True)\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", \"    schema = {'foo': {'type': 'string', 'required': True}}\\n\", '    validator.require_all = True\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    validator.require_all = False\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'bar'}, schema, validator)\\n\", '    sub_schema = {\"bar\": {\"type\": \"string\"}}\\n', '    schema = {\\n', '            \"schema\": sub_schema,\\n', '    validator = Validator(require_all=validator_require_all)\\n', '    assert_success({\"foo\": {\"bar\": \"baz\"}}, schema, validator)\\n', '        assert_fail({}, schema, validator)\\n', '        assert_success({}, schema, validator)\\n', '        assert_fail({\"foo\": {}}, schema, validator)\\n', '        assert_success({\"foo\": {}}, schema, validator)\\n', '    schema = {\\n', '    validator = Validator(require_all=True)\\n', '        schema,\\n', '        validator,\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    validator.require_all = False\\n', '    assert_success({}, schema, validator)\\n', \"    assert_success({'foo': 'value'}, schema, validator)\\n\", \"    assert_success({'bar': 'value'}, schema, validator)\\n\", \"    assert_fail({'foo': 'value', 'bar': 'value'}, schema, validator)\\n\", '    assert validator.errors == {}\\n']",
  "context": " {'type': 'string', 'excludes': 'foo'},\n    }\n    validator = Validator(require_all=True)\n    assert_fail(\n        {},\n        schema,\n     "
 },
 "545": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_normalization.py",
  "lineno": "9",
  "column": "4",
  "slicing": "[\"    schema = {'amount': {'coerce': int}}\\n\", \"    document = {'amount': '2'}\\n\", \"    expected = {'amount': 2}\\n\", '    assert_normalized(document, expected, schema)\\n', \"    schema = {'revision': {'coerce': int}}\\n\", \"    document = {'revision': '5', 'file': NamedTemporaryFile(mode='w+')}\\n\", \"    document['file'].write(r'foobar')\\n\", \"    document['file'].seek(0)\\n\", '    normalized = Validator(schema, allow_unknown=True).normalized(document)\\n', \"    assert normalized['revision'] == 5\\n\", \"    assert normalized['file'].read() == 'foobar'\\n\", \"    document['file'].close()\\n\", \"    normalized['file'].close()\\n\", \"    schema = {'thing': {'type': 'dict', 'schema': {'amount': {'coerce': int}}}}\\n\", \"    ref_obj = '2'\\n\", \"    document = {'thing': {'amount': ref_obj}}\\n\", '    normalized = Validator(schema).normalized(document)\\n', '    assert document is not normalized\\n', \"    assert normalized['thing']['amount'] == 2\\n\", \"    assert document['thing']['amount'] is ref_obj\\n\", '    schema = {\\n', \"    document = {'my_field': ('foo', 'bar', 42, 'albert', 'kandinsky', {'items': 23})}\\n\", '    assert_success(document, schema)\\n', '    normalized = Validator(schema).normalized(document)\\n', \"    assert normalized['my_field'] == (\\n\", '    schema = {\\n', '    validator = Validator(schema=schema, purge_readonly=True)\\n', \"    document = {'description': 'it is a thing'}\\n\", '    expected = deepcopy(document)\\n', \"    document['last_updated'] = 'future'\\n\", '    assert_normalized(document, expected, validator=validator)\\n', '    assert_normalized(document, expected, schema, validator)\\n', '    assert_normalized(document, expected, schema)\\n']",
  "context": "ized, assert_success\n\n\ndef test_normalized():\n    schema = {'amount': {'coerce': int}}\n    document = {'amount': '2'}\n    expected = {'am"
 },
 "546": {
  "name": "document",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_normalization.py",
  "lineno": "10",
  "column": "4",
  "slicing": "[\"    schema = {'amount': {'coerce': int}}\\n\", \"    document = {'amount': '2'}\\n\", \"    expected = {'amount': 2}\\n\", '    assert_normalized(document, expected, schema)\\n', \"    schema = {'revision': {'coerce': int}}\\n\", \"    document = {'revision': '5', 'file': NamedTemporaryFile(mode='w+')}\\n\", \"    document['file'].write(r'foobar')\\n\", \"    document['file'].seek(0)\\n\", '    normalized = Validator(schema, allow_unknown=True).normalized(document)\\n', \"    assert normalized['revision'] == 5\\n\", \"    assert normalized['file'].read() == 'foobar'\\n\", \"    document['file'].close()\\n\", \"    normalized['file'].close()\\n\", \"    schema = {'thing': {'type': 'dict', 'schema': {'amount': {'coerce': int}}}}\\n\", \"    ref_obj = '2'\\n\", \"    document = {'thing': {'amount': ref_obj}}\\n\", '    normalized = Validator(schema).normalized(document)\\n', '    assert document is not normalized\\n', \"    assert normalized['thing']['amount'] == 2\\n\", \"    assert document['thing']['amount'] is ref_obj\\n\", '    schema = {\\n', \"    document = {'my_field': ('foo', 'bar', 42, 'albert', 'kandinsky', {'items': 23})}\\n\", '    assert_success(document, schema)\\n', '    normalized = Validator(schema).normalized(document)\\n', \"    assert normalized['my_field'] == (\\n\", '    schema = {\\n', '    validator = Validator(schema=schema, purge_readonly=True)\\n', \"    document = {'description': 'it is a thing'}\\n\", '    expected = deepcopy(document)\\n', \"    document['last_updated'] = 'future'\\n\", '    assert_normalized(document, expected, validator=validator)\\n', '    assert_normalized(document, expected, schema, validator)\\n', '    assert_normalized(document, expected, schema)\\n']",
  "context": "d():\n    schema = {'amount': {'coerce': int}}\n    document = {'amount': '2'}\n    expected = {'amount': 2}\n    assert_normalized"
 },
 "547": {
  "name": "expected",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_normalization.py",
  "lineno": "11",
  "column": "4",
  "slicing": "[\"    expected = {'amount': 2}\\n\", '    assert_normalized(document, expected, schema)\\n', '    assert_normalized(document, expected, validator=validator)\\n', '    assert_normalized(document, expected, schema, validator)\\n', '    assert_normalized(document, expected, schema)\\n']",
  "context": "coerce': int}}\n    document = {'amount': '2'}\n    expected = {'amount': 2}\n    assert_normalized(document, expected, schema)\n"
 },
 "548": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_normalization.py",
  "lineno": "17",
  "column": "4",
  "slicing": "[\"    schema = {'amount': {'coerce': int}}\\n\", \"    document = {'amount': '2'}\\n\", \"    expected = {'amount': 2}\\n\", '    assert_normalized(document, expected, schema)\\n', \"    schema = {'revision': {'coerce': int}}\\n\", \"    document = {'revision': '5', 'file': NamedTemporaryFile(mode='w+')}\\n\", \"    document['file'].write(r'foobar')\\n\", \"    document['file'].seek(0)\\n\", '    normalized = Validator(schema, allow_unknown=True).normalized(document)\\n', \"    assert normalized['revision'] == 5\\n\", \"    assert normalized['file'].read() == 'foobar'\\n\", \"    document['file'].close()\\n\", \"    normalized['file'].close()\\n\", \"    schema = {'thing': {'type': 'dict', 'schema': {'amount': {'coerce': int}}}}\\n\", \"    ref_obj = '2'\\n\", \"    document = {'thing': {'amount': ref_obj}}\\n\", '    normalized = Validator(schema).normalized(document)\\n', '    assert document is not normalized\\n', \"    assert normalized['thing']['amount'] == 2\\n\", \"    assert document['thing']['amount'] is ref_obj\\n\", '    schema = {\\n', \"    document = {'my_field': ('foo', 'bar', 42, 'albert', 'kandinsky', {'items': 23})}\\n\", '    assert_success(document, schema)\\n', '    normalized = Validator(schema).normalized(document)\\n', \"    assert normalized['my_field'] == (\\n\", '    schema = {\\n', '    validator = Validator(schema=schema, purge_readonly=True)\\n', \"    document = {'description': 'it is a thing'}\\n\", '    expected = deepcopy(document)\\n', \"    document['last_updated'] = 'future'\\n\", '    assert_normalized(document, expected, validator=validator)\\n', '    assert_normalized(document, expected, schema, validator)\\n', '    assert_normalized(document, expected, schema)\\n']",
  "context": " https://github.com/pyeve/cerberus/issues/147\n    schema = {'revision': {'coerce': int}}\n    document = {'revision': '5', 'file': NamedTemp"
 },
 "549": {
  "name": "document",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_normalization.py",
  "lineno": "18",
  "column": "4",
  "slicing": "[\"    schema = {'amount': {'coerce': int}}\\n\", \"    document = {'amount': '2'}\\n\", \"    expected = {'amount': 2}\\n\", '    assert_normalized(document, expected, schema)\\n', \"    schema = {'revision': {'coerce': int}}\\n\", \"    document = {'revision': '5', 'file': NamedTemporaryFile(mode='w+')}\\n\", \"    document['file'].write(r'foobar')\\n\", \"    document['file'].seek(0)\\n\", '    normalized = Validator(schema, allow_unknown=True).normalized(document)\\n', \"    assert normalized['revision'] == 5\\n\", \"    assert normalized['file'].read() == 'foobar'\\n\", \"    document['file'].close()\\n\", \"    normalized['file'].close()\\n\", \"    schema = {'thing': {'type': 'dict', 'schema': {'amount': {'coerce': int}}}}\\n\", \"    ref_obj = '2'\\n\", \"    document = {'thing': {'amount': ref_obj}}\\n\", '    normalized = Validator(schema).normalized(document)\\n', '    assert document is not normalized\\n', \"    assert normalized['thing']['amount'] == 2\\n\", \"    assert document['thing']['amount'] is ref_obj\\n\", '    schema = {\\n', \"    document = {'my_field': ('foo', 'bar', 42, 'albert', 'kandinsky', {'items': 23})}\\n\", '    assert_success(document, schema)\\n', '    normalized = Validator(schema).normalized(document)\\n', \"    assert normalized['my_field'] == (\\n\", '    schema = {\\n', '    validator = Validator(schema=schema, purge_readonly=True)\\n', \"    document = {'description': 'it is a thing'}\\n\", '    expected = deepcopy(document)\\n', \"    document['last_updated'] = 'future'\\n\", '    assert_normalized(document, expected, validator=validator)\\n', '    assert_normalized(document, expected, schema, validator)\\n', '    assert_normalized(document, expected, schema)\\n']",
  "context": "47\n    schema = {'revision': {'coerce': int}}\n    document = {'revision': '5', 'file': NamedTemporaryFile(mode='w+')}\n    document['file'].write(r'foobar')\n    document"
 },
 "550": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_normalization.py",
  "lineno": "30",
  "column": "4",
  "slicing": "[\"    schema = {'amount': {'coerce': int}}\\n\", \"    document = {'amount': '2'}\\n\", \"    expected = {'amount': 2}\\n\", '    assert_normalized(document, expected, schema)\\n', \"    schema = {'revision': {'coerce': int}}\\n\", \"    document = {'revision': '5', 'file': NamedTemporaryFile(mode='w+')}\\n\", \"    document['file'].write(r'foobar')\\n\", \"    document['file'].seek(0)\\n\", '    normalized = Validator(schema, allow_unknown=True).normalized(document)\\n', \"    assert normalized['revision'] == 5\\n\", \"    assert normalized['file'].read() == 'foobar'\\n\", \"    document['file'].close()\\n\", \"    normalized['file'].close()\\n\", \"    schema = {'thing': {'type': 'dict', 'schema': {'amount': {'coerce': int}}}}\\n\", \"    ref_obj = '2'\\n\", \"    document = {'thing': {'amount': ref_obj}}\\n\", '    normalized = Validator(schema).normalized(document)\\n', '    assert document is not normalized\\n', \"    assert normalized['thing']['amount'] == 2\\n\", \"    assert document['thing']['amount'] is ref_obj\\n\", '    schema = {\\n', \"    document = {'my_field': ('foo', 'bar', 42, 'albert', 'kandinsky', {'items': 23})}\\n\", '    assert_success(document, schema)\\n', '    normalized = Validator(schema).normalized(document)\\n', \"    assert normalized['my_field'] == (\\n\", '    schema = {\\n', '    validator = Validator(schema=schema, purge_readonly=True)\\n', \"    document = {'description': 'it is a thing'}\\n\", '    expected = deepcopy(document)\\n', \"    document['last_updated'] = 'future'\\n\", '    assert_normalized(document, expected, validator=validator)\\n', '    assert_normalized(document, expected, schema, validator)\\n', '    assert_normalized(document, expected, schema)\\n']",
  "context": " https://github.com/pyeve/cerberus/issues/147\n    schema = {'thing': {'type': 'dict', 'schema': {'amount': {'coerce': int}}}}\n    ref_obj = '2'\n    document = {'thing': {'amoun"
 },
 "551": {
  "name": "document",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_normalization.py",
  "lineno": "32",
  "column": "4",
  "slicing": "[\"    schema = {'amount': {'coerce': int}}\\n\", \"    document = {'amount': '2'}\\n\", \"    expected = {'amount': 2}\\n\", '    assert_normalized(document, expected, schema)\\n', \"    schema = {'revision': {'coerce': int}}\\n\", \"    document = {'revision': '5', 'file': NamedTemporaryFile(mode='w+')}\\n\", \"    document['file'].write(r'foobar')\\n\", \"    document['file'].seek(0)\\n\", '    normalized = Validator(schema, allow_unknown=True).normalized(document)\\n', \"    assert normalized['revision'] == 5\\n\", \"    assert normalized['file'].read() == 'foobar'\\n\", \"    document['file'].close()\\n\", \"    normalized['file'].close()\\n\", \"    schema = {'thing': {'type': 'dict', 'schema': {'amount': {'coerce': int}}}}\\n\", \"    ref_obj = '2'\\n\", \"    document = {'thing': {'amount': ref_obj}}\\n\", '    normalized = Validator(schema).normalized(document)\\n', '    assert document is not normalized\\n', \"    assert normalized['thing']['amount'] == 2\\n\", \"    assert document['thing']['amount'] is ref_obj\\n\", '    schema = {\\n', \"    document = {'my_field': ('foo', 'bar', 42, 'albert', 'kandinsky', {'items': 23})}\\n\", '    assert_success(document, schema)\\n', '    normalized = Validator(schema).normalized(document)\\n', \"    assert normalized['my_field'] == (\\n\", '    schema = {\\n', '    validator = Validator(schema=schema, purge_readonly=True)\\n', \"    document = {'description': 'it is a thing'}\\n\", '    expected = deepcopy(document)\\n', \"    document['last_updated'] = 'future'\\n\", '    assert_normalized(document, expected, validator=validator)\\n', '    assert_normalized(document, expected, schema, validator)\\n', '    assert_normalized(document, expected, schema)\\n']",
  "context": "amount': {'coerce': int}}}}\n    ref_obj = '2'\n    document = {'thing': {'amount': ref_obj}}\n    normalized = Validator(schema).normalized(docu"
 },
 "552": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_normalization.py",
  "lineno": "41",
  "column": "4",
  "slicing": "[\"    schema = {'amount': {'coerce': int}}\\n\", \"    document = {'amount': '2'}\\n\", \"    expected = {'amount': 2}\\n\", '    assert_normalized(document, expected, schema)\\n', \"    schema = {'revision': {'coerce': int}}\\n\", \"    document = {'revision': '5', 'file': NamedTemporaryFile(mode='w+')}\\n\", \"    document['file'].write(r'foobar')\\n\", \"    document['file'].seek(0)\\n\", '    normalized = Validator(schema, allow_unknown=True).normalized(document)\\n', \"    assert normalized['revision'] == 5\\n\", \"    assert normalized['file'].read() == 'foobar'\\n\", \"    document['file'].close()\\n\", \"    normalized['file'].close()\\n\", \"    schema = {'thing': {'type': 'dict', 'schema': {'amount': {'coerce': int}}}}\\n\", \"    ref_obj = '2'\\n\", \"    document = {'thing': {'amount': ref_obj}}\\n\", '    normalized = Validator(schema).normalized(document)\\n', '    assert document is not normalized\\n', \"    assert normalized['thing']['amount'] == 2\\n\", \"    assert document['thing']['amount'] is ref_obj\\n\", '    schema = {\\n', \"    document = {'my_field': ('foo', 'bar', 42, 'albert', 'kandinsky', {'items': 23})}\\n\", '    assert_success(document, schema)\\n', '    normalized = Validator(schema).normalized(document)\\n', \"    assert normalized['my_field'] == (\\n\", '    schema = {\\n', '    validator = Validator(schema=schema, purge_readonly=True)\\n', \"    document = {'description': 'it is a thing'}\\n\", '    expected = deepcopy(document)\\n', \"    document['last_updated'] = 'future'\\n\", '    assert_normalized(document, expected, validator=validator)\\n', '    assert_normalized(document, expected, schema, validator)\\n', '    assert_normalized(document, expected, schema)\\n']",
  "context": " https://github.com/pyeve/cerberus/issues/271\n    schema = {\n        'my_field': {\n            'type': 'tuple',"
 },
 "553": {
  "name": "document",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_normalization.py",
  "lineno": "47",
  "column": "4",
  "slicing": "[\"    schema = {'amount': {'coerce': int}}\\n\", \"    document = {'amount': '2'}\\n\", \"    expected = {'amount': 2}\\n\", '    assert_normalized(document, expected, schema)\\n', \"    schema = {'revision': {'coerce': int}}\\n\", \"    document = {'revision': '5', 'file': NamedTemporaryFile(mode='w+')}\\n\", \"    document['file'].write(r'foobar')\\n\", \"    document['file'].seek(0)\\n\", '    normalized = Validator(schema, allow_unknown=True).normalized(document)\\n', \"    assert normalized['revision'] == 5\\n\", \"    assert normalized['file'].read() == 'foobar'\\n\", \"    document['file'].close()\\n\", \"    normalized['file'].close()\\n\", \"    schema = {'thing': {'type': 'dict', 'schema': {'amount': {'coerce': int}}}}\\n\", \"    ref_obj = '2'\\n\", \"    document = {'thing': {'amount': ref_obj}}\\n\", '    normalized = Validator(schema).normalized(document)\\n', '    assert document is not normalized\\n', \"    assert normalized['thing']['amount'] == 2\\n\", \"    assert document['thing']['amount'] is ref_obj\\n\", '    schema = {\\n', \"    document = {'my_field': ('foo', 'bar', 42, 'albert', 'kandinsky', {'items': 23})}\\n\", '    assert_success(document, schema)\\n', '    normalized = Validator(schema).normalized(document)\\n', \"    assert normalized['my_field'] == (\\n\", '    schema = {\\n', '    validator = Validator(schema=schema, purge_readonly=True)\\n', \"    document = {'description': 'it is a thing'}\\n\", '    expected = deepcopy(document)\\n', \"    document['last_updated'] = 'future'\\n\", '    assert_normalized(document, expected, validator=validator)\\n', '    assert_normalized(document, expected, schema, validator)\\n', '    assert_normalized(document, expected, schema)\\n']",
  "context": "'string', 'number', 'dict')},\n        }\n    }\n    document = {'my_field': ('foo', 'bar', 42, 'albert', 'kandinsky', {'items': 23})}\n    assert_success(document, schema)\n\n    normaliz"
 },
 "554": {
  "name": "normalized",
  "type": "dict",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/tests/test_normalization.py",
  "lineno": "50",
  "column": "4",
  "slicing": "[\"    schema = {'amount': {'coerce': int}}\\n\", \"    document = {'amount': '2'}\\n\", \"    expected = {'amount': 2}\\n\", '    assert_normalized(document, expected, schema)\\n', \"    schema = {'revision': {'coerce': int}}\\n\", \"    document = {'revision': '5', 'file': NamedTemporaryFile(mode='w+')}\\n\", \"    document['file'].write(r'foobar')\\n\", \"    document['file'].seek(0)\\n\", '    normalized = Validator(schema, allow_unknown=True).normalized(document)\\n', \"    assert normalized['revision'] == 5\\n\", \"    assert normalized['file'].read() == 'foobar'\\n\", \"    document['file'].close()\\n\", \"    normalized['file'].close()\\n\", \"    schema = {'thing': {'type': 'dict', 'schema': {'amount': {'coerce': int}}}}\\n\", \"    ref_obj = '2'\\n\", \"    document = {'thing': {'amount': ref_obj}}\\n\", '    normalized = Validator(schema).normalized(document)\\n', '    assert document is not normalized\\n', \"    assert normalized['thing']['amount'] == 2\\n\", \"    assert document['thing']['amount'] is ref_obj\\n\", '    schema = {\\n', \"    document = {'my_field': ('foo', 'bar', 42, 'albert', 'kandinsky', {'items': 23})}\\n\", '    assert_success(document, schema)\\n', '    normalized = Validator(schema).normalized(document)\\n', \"    assert normalized['my_field'] == (\\n\", '    schema = {\\n', '    validator = Validator(schema=schema, purge_readonly=True)\\n', \"    document = {'description': 'it is a thing'}\\n\", '    expected = deepcopy(document)\\n', \"    document['last_updated'] = 'future'\\n\", '    assert_normalized(document, expected, validator=validator)\\n', '    assert_normalized(document, expected, schema, validator)\\n', '    assert_normalized(document, expected, schema)\\n']",
  "context": ": 23})}\n    assert_success(document, schema)\n\n    normalized = Validator(schema).normalized(document)\n    assert normalized['my_field'] == (\n        'fo"
 },
 "555": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_normalization.py",
  "lineno": "62",
  "column": "4",
  "slicing": "[\"    schema = {'amount': {'coerce': int}}\\n\", \"    document = {'amount': '2'}\\n\", \"    expected = {'amount': 2}\\n\", '    assert_normalized(document, expected, schema)\\n', \"    schema = {'revision': {'coerce': int}}\\n\", \"    document = {'revision': '5', 'file': NamedTemporaryFile(mode='w+')}\\n\", \"    document['file'].write(r'foobar')\\n\", \"    document['file'].seek(0)\\n\", '    normalized = Validator(schema, allow_unknown=True).normalized(document)\\n', \"    assert normalized['revision'] == 5\\n\", \"    assert normalized['file'].read() == 'foobar'\\n\", \"    document['file'].close()\\n\", \"    normalized['file'].close()\\n\", \"    schema = {'thing': {'type': 'dict', 'schema': {'amount': {'coerce': int}}}}\\n\", \"    ref_obj = '2'\\n\", \"    document = {'thing': {'amount': ref_obj}}\\n\", '    normalized = Validator(schema).normalized(document)\\n', '    assert document is not normalized\\n', \"    assert normalized['thing']['amount'] == 2\\n\", \"    assert document['thing']['amount'] is ref_obj\\n\", '    schema = {\\n', \"    document = {'my_field': ('foo', 'bar', 42, 'albert', 'kandinsky', {'items': 23})}\\n\", '    assert_success(document, schema)\\n', '    normalized = Validator(schema).normalized(document)\\n', \"    assert normalized['my_field'] == (\\n\", '    schema = {\\n', '    validator = Validator(schema=schema, purge_readonly=True)\\n', \"    document = {'description': 'it is a thing'}\\n\", '    expected = deepcopy(document)\\n', \"    document['last_updated'] = 'future'\\n\", '    assert_normalized(document, expected, validator=validator)\\n', '    assert_normalized(document, expected, schema, validator)\\n', '    assert_normalized(document, expected, schema)\\n']",
  "context": "ems': 23},\n    )\n\n\ndef test_purge_readonly():\n    schema = {\n        'description': {'type': 'string', 'maxleng"
 },
 "556": {
  "name": "validator",
  "type": "cerberus.Validator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_normalization.py",
  "lineno": "66",
  "column": "4",
  "slicing": "[\"    schema = {'amount': {'coerce': int}}\\n\", \"    document = {'amount': '2'}\\n\", \"    expected = {'amount': 2}\\n\", '    assert_normalized(document, expected, schema)\\n', \"    schema = {'revision': {'coerce': int}}\\n\", \"    document = {'revision': '5', 'file': NamedTemporaryFile(mode='w+')}\\n\", \"    document['file'].write(r'foobar')\\n\", \"    document['file'].seek(0)\\n\", '    normalized = Validator(schema, allow_unknown=True).normalized(document)\\n', \"    assert normalized['revision'] == 5\\n\", \"    assert normalized['file'].read() == 'foobar'\\n\", \"    document['file'].close()\\n\", \"    normalized['file'].close()\\n\", \"    schema = {'thing': {'type': 'dict', 'schema': {'amount': {'coerce': int}}}}\\n\", \"    ref_obj = '2'\\n\", \"    document = {'thing': {'amount': ref_obj}}\\n\", '    normalized = Validator(schema).normalized(document)\\n', '    assert document is not normalized\\n', \"    assert normalized['thing']['amount'] == 2\\n\", \"    assert document['thing']['amount'] is ref_obj\\n\", '    schema = {\\n', \"    document = {'my_field': ('foo', 'bar', 42, 'albert', 'kandinsky', {'items': 23})}\\n\", '    assert_success(document, schema)\\n', '    normalized = Validator(schema).normalized(document)\\n', \"    assert normalized['my_field'] == (\\n\", '    schema = {\\n', '    validator = Validator(schema=schema, purge_readonly=True)\\n', \"    document = {'description': 'it is a thing'}\\n\", '    expected = deepcopy(document)\\n', \"    document['last_updated'] = 'future'\\n\", '    assert_normalized(document, expected, validator=validator)\\n', '    assert_normalized(document, expected, schema, validator)\\n', '    assert_normalized(document, expected, schema)\\n']",
  "context": "    'last_updated': {'readonly': True},\n    }\n    validator = Validator(schema=schema, purge_readonly=True)\n    document = {'description': 'it is a thing'}\n  "
 },
 "557": {
  "name": "document",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_normalization.py",
  "lineno": "67",
  "column": "4",
  "slicing": "[\"    schema = {'amount': {'coerce': int}}\\n\", \"    document = {'amount': '2'}\\n\", \"    expected = {'amount': 2}\\n\", '    assert_normalized(document, expected, schema)\\n', \"    schema = {'revision': {'coerce': int}}\\n\", \"    document = {'revision': '5', 'file': NamedTemporaryFile(mode='w+')}\\n\", \"    document['file'].write(r'foobar')\\n\", \"    document['file'].seek(0)\\n\", '    normalized = Validator(schema, allow_unknown=True).normalized(document)\\n', \"    assert normalized['revision'] == 5\\n\", \"    assert normalized['file'].read() == 'foobar'\\n\", \"    document['file'].close()\\n\", \"    normalized['file'].close()\\n\", \"    schema = {'thing': {'type': 'dict', 'schema': {'amount': {'coerce': int}}}}\\n\", \"    ref_obj = '2'\\n\", \"    document = {'thing': {'amount': ref_obj}}\\n\", '    normalized = Validator(schema).normalized(document)\\n', '    assert document is not normalized\\n', \"    assert normalized['thing']['amount'] == 2\\n\", \"    assert document['thing']['amount'] is ref_obj\\n\", '    schema = {\\n', \"    document = {'my_field': ('foo', 'bar', 42, 'albert', 'kandinsky', {'items': 23})}\\n\", '    assert_success(document, schema)\\n', '    normalized = Validator(schema).normalized(document)\\n', \"    assert normalized['my_field'] == (\\n\", '    schema = {\\n', '    validator = Validator(schema=schema, purge_readonly=True)\\n', \"    document = {'description': 'it is a thing'}\\n\", '    expected = deepcopy(document)\\n', \"    document['last_updated'] = 'future'\\n\", '    assert_normalized(document, expected, validator=validator)\\n', '    assert_normalized(document, expected, schema, validator)\\n', '    assert_normalized(document, expected, schema)\\n']",
  "context": "Validator(schema=schema, purge_readonly=True)\n    document = {'description': 'it is a thing'}\n    expected = deepcopy(document)\n    document['la"
 },
 "558": {
  "name": "expected",
  "type": "copy.deepcopy",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_normalization.py",
  "lineno": "68",
  "column": "4",
  "slicing": "[\"    schema = {'amount': {'coerce': int}}\\n\", \"    document = {'amount': '2'}\\n\", \"    expected = {'amount': 2}\\n\", '    assert_normalized(document, expected, schema)\\n', \"    schema = {'revision': {'coerce': int}}\\n\", \"    document = {'revision': '5', 'file': NamedTemporaryFile(mode='w+')}\\n\", \"    document['file'].write(r'foobar')\\n\", \"    document['file'].seek(0)\\n\", '    normalized = Validator(schema, allow_unknown=True).normalized(document)\\n', \"    assert normalized['revision'] == 5\\n\", \"    assert normalized['file'].read() == 'foobar'\\n\", \"    document['file'].close()\\n\", \"    normalized['file'].close()\\n\", \"    schema = {'thing': {'type': 'dict', 'schema': {'amount': {'coerce': int}}}}\\n\", \"    ref_obj = '2'\\n\", \"    document = {'thing': {'amount': ref_obj}}\\n\", '    normalized = Validator(schema).normalized(document)\\n', '    assert document is not normalized\\n', \"    assert normalized['thing']['amount'] == 2\\n\", \"    assert document['thing']['amount'] is ref_obj\\n\", '    schema = {\\n', \"    document = {'my_field': ('foo', 'bar', 42, 'albert', 'kandinsky', {'items': 23})}\\n\", '    assert_success(document, schema)\\n', '    normalized = Validator(schema).normalized(document)\\n', \"    assert normalized['my_field'] == (\\n\", '    schema = {\\n', '    validator = Validator(schema=schema, purge_readonly=True)\\n', \"    document = {'description': 'it is a thing'}\\n\", '    expected = deepcopy(document)\\n', \"    document['last_updated'] = 'future'\\n\", '    assert_normalized(document, expected, validator=validator)\\n', '    assert_normalized(document, expected, schema, validator)\\n', '    assert_normalized(document, expected, schema)\\n']",
  "context": "  document = {'description': 'it is a thing'}\n    expected = deepcopy(document)\n    document['last_updated'] = 'future'\n    assert"
 },
 "559": {
  "name": "validator",
  "type": "cerberus.Validator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_normalization.py",
  "lineno": "74",
  "column": "4",
  "slicing": "[\"    schema = {'amount': {'coerce': int}}\\n\", \"    document = {'amount': '2'}\\n\", \"    expected = {'amount': 2}\\n\", '    assert_normalized(document, expected, schema)\\n', \"    schema = {'revision': {'coerce': int}}\\n\", \"    document = {'revision': '5', 'file': NamedTemporaryFile(mode='w+')}\\n\", \"    document['file'].write(r'foobar')\\n\", \"    document['file'].seek(0)\\n\", '    normalized = Validator(schema, allow_unknown=True).normalized(document)\\n', \"    assert normalized['revision'] == 5\\n\", \"    assert normalized['file'].read() == 'foobar'\\n\", \"    document['file'].close()\\n\", \"    normalized['file'].close()\\n\", \"    schema = {'thing': {'type': 'dict', 'schema': {'amount': {'coerce': int}}}}\\n\", \"    ref_obj = '2'\\n\", \"    document = {'thing': {'amount': ref_obj}}\\n\", '    normalized = Validator(schema).normalized(document)\\n', '    assert document is not normalized\\n', \"    assert normalized['thing']['amount'] == 2\\n\", \"    assert document['thing']['amount'] is ref_obj\\n\", '    schema = {\\n', \"    document = {'my_field': ('foo', 'bar', 42, 'albert', 'kandinsky', {'items': 23})}\\n\", '    assert_success(document, schema)\\n', '    normalized = Validator(schema).normalized(document)\\n', \"    assert normalized['my_field'] == (\\n\", '    schema = {\\n', '    validator = Validator(schema=schema, purge_readonly=True)\\n', \"    document = {'description': 'it is a thing'}\\n\", '    expected = deepcopy(document)\\n', \"    document['last_updated'] = 'future'\\n\", '    assert_normalized(document, expected, validator=validator)\\n', '    validator = Validator(purge_unknown=True)\\n', '    assert_normalized(document, expected, schema, validator)\\n', '    assert_normalized(document, expected, schema)\\n']",
  "context": "idator=validator)\n\n\ndef test_purge_unknown():\n    validator = Validator(purge_unknown=True)\n    schema = {'foo': {'type': 'string'}}\n    docum"
 },
 "560": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_normalization.py",
  "lineno": "75",
  "column": "4",
  "slicing": "[\"    schema = {'foo': {'type': 'string'}}\\n\", '    assert_normalized(document, expected, schema, validator)\\n', '    assert_normalized(document, expected, schema)\\n']",
  "context": "    validator = Validator(purge_unknown=True)\n    schema = {'foo': {'type': 'string'}}\n    document = {'bar': 'foo'}\n    expected = {}\n  "
 },
 "561": {
  "name": "document",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_normalization.py",
  "lineno": "76",
  "column": "4",
  "slicing": "[\"    document = {'bar': 'foo'}\\n\", '    assert_normalized(document, expected, schema, validator)\\n', '    assert_normalized(document, expected, schema)\\n']",
  "context": "rue)\n    schema = {'foo': {'type': 'string'}}\n    document = {'bar': 'foo'}\n    expected = {}\n    assert_normalized(document, "
 },
 "562": {
  "name": "expected",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_normalization.py",
  "lineno": "77",
  "column": "4",
  "slicing": "['    expected = {}\\n', '    assert_normalized(document, expected, schema, validator)\\n', '    assert_normalized(document, expected, schema)\\n']",
  "context": "pe': 'string'}}\n    document = {'bar': 'foo'}\n    expected = {}\n    assert_normalized(document, expected, schema, "
 },
 "563": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_normalization.py",
  "lineno": "82",
  "column": "4",
  "slicing": "['    schema = {\\n', '    assert_normalized(document, expected, schema)\\n']",
  "context": "tor)\n\n\ndef test_purge_unknown_in_subschema():\n    schema = {\n        'foo': {\n            'type': 'dict',\n     "
 },
 "564": {
  "name": "document",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_normalization.py",
  "lineno": "89",
  "column": "4",
  "slicing": "[\"    document = {'foo': {'bar': ''}}\\n\", '    assert_normalized(document, expected, schema)\\n']",
  "context": "       'purge_unknown': True,\n        }\n    }\n    document = {'foo': {'bar': ''}}\n    expected = {'foo': {}}\n    assert_normalized(d"
 },
 "565": {
  "name": "expected",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_normalization.py",
  "lineno": "90",
  "column": "4",
  "slicing": "[\"    expected = {'foo': {}}\\n\", '    assert_normalized(document, expected, schema)\\n']",
  "context": "  }\n    }\n    document = {'foo': {'bar': ''}}\n    expected = {'foo': {}}\n    assert_normalized(document, expected, schema)\n"
 },
 "566": {
  "name": "v",
  "type": "InheritedValidator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_customization.py",
  "lineno": "21",
  "column": "4",
  "slicing": "['    v = InheritedValidator(\\n', \"    assert_success({'test': ['foo']}, validator=v)\\n\", \"    assert_success(document={'amount': 1}, validator=v)\\n\", '        validator=v,\\n', \"    assert v.validate(document={'an_integer': 1})\\n\", \"    assert not v.validate(document={'an_integer': 'a'})\\n\", \"    v.schema['an_integer']['tpe'] = 'int'\\n\", \"        v.validate(document={'an_integer': 1})\\n\", \"    v.schema['an_integer'].pop('tpe')\\n\"]",
  "context": " assert 'test' in InheritedValidator.checkers\n    v = InheritedValidator(\n        {'test': {'type': 'list', 'itemsrules': {'"
 },
 "567": {
  "name": "v",
  "type": "MyValidator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_customization.py",
  "lineno": "53",
  "column": "4",
  "slicing": "['    v = InheritedValidator(\\n', \"    assert_success({'test': ['foo']}, validator=v)\\n\", \"    v = MyValidator(schema={'amount': {'check_with': 'oddity'}})\\n\", \"    assert_success(document={'amount': 1}, validator=v)\\n\", '        validator=v,\\n', \"    assert v.validate(document={'an_integer': 1})\\n\", \"    assert not v.validate(document={'an_integer': 'a'})\\n\", \"    v.schema['an_integer']['tpe'] = 'int'\\n\", \"        v.validate(document={'an_integer': 1})\\n\", \"    v.schema['an_integer'].pop('tpe')\\n\"]",
  "context": " self._error(field, \"Must be an odd number\")\n\n    v = MyValidator(schema={'amount': {'check_with': 'oddity'}})\n    assert_success(document={'amount': 1}, validat"
 },
 "568": {
  "name": "v",
  "type": "cls",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_customization.py",
  "lineno": "70",
  "column": "4",
  "slicing": "['    v = InheritedValidator(\\n', \"    assert_success({'test': ['foo']}, validator=v)\\n\", \"    v = MyValidator(schema={'amount': {'check_with': 'oddity'}})\\n\", \"    assert_success(document={'amount': 1}, validator=v)\\n\", '        validator=v,\\n', '    v = cls(schema=sample_schema)\\n', \"    assert v.validate(document={'an_integer': 1})\\n\", \"    assert not v.validate(document={'an_integer': 'a'})\\n\", \"    v.schema['an_integer']['tpe'] = 'int'\\n\", \"        v.validate(document={'an_integer': 1})\\n\", \"    v.schema['an_integer'].pop('tpe')\\n\"]",
  "context": " test_schema_validation_can_be_disabled(cls):\n    v = cls(schema=sample_schema)\n    assert v.validate(document={'an_integer': 1})\n"
 },
 "569": {
  "name": "schema",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_customization.py",
  "lineno": "90",
  "column": "4",
  "slicing": "['    v = InheritedValidator(\\n', \"    assert_success({'test': ['foo']}, validator=v)\\n\", \"    v = MyValidator(schema={'amount': {'check_with': 'oddity'}})\\n\", \"    assert_success(document={'amount': 1}, validator=v)\\n\", '        validator=v,\\n', '    v = cls(schema=sample_schema)\\n', \"    assert v.validate(document={'an_integer': 1})\\n\", \"    assert not v.validate(document={'an_integer': 'a'})\\n\", \"    v.schema['an_integer']['tpe'] = 'int'\\n\", \"        v.validate(document={'an_integer': 1})\\n\", \"    v.schema['an_integer'].pop('tpe')\\n\", '        types_mapping = cerberus.Validator.types_mapping.copy()\\n', \"        types_mapping['number'] = cerberus.TypeDefinition('number', (int,), ())\\n\", \"    schema = {'test_field': {'min_number': 1, 'type': 'number'}}\\n\", '    validator = MyValidator(schema)\\n', '        validator=validator,\\n', '        validator=validator,\\n', \"    assert validator.errors == {'test_field': ['Below the min']}\\n\"]",
  "context": "         self._error(field, 'Below the min')\n\n    schema = {'test_field': {'min_number': 1, 'type': 'number'}}\n    validator = MyValidator(schema)\n    assert_fai"
 },
 "570": {
  "name": "validator",
  "type": "MyValidator",
  "class": "customized",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/tests/test_customization.py",
  "lineno": "91",
  "column": "4",
  "slicing": "['    v = InheritedValidator(\\n', \"    assert_success({'test': ['foo']}, validator=v)\\n\", \"    v = MyValidator(schema={'amount': {'check_with': 'oddity'}})\\n\", \"    assert_success(document={'amount': 1}, validator=v)\\n\", '        validator=v,\\n', '    v = cls(schema=sample_schema)\\n', \"    assert v.validate(document={'an_integer': 1})\\n\", \"    assert not v.validate(document={'an_integer': 'a'})\\n\", \"    v.schema['an_integer']['tpe'] = 'int'\\n\", \"        v.validate(document={'an_integer': 1})\\n\", \"    v.schema['an_integer'].pop('tpe')\\n\", '        types_mapping = cerberus.Validator.types_mapping.copy()\\n', \"        types_mapping['number'] = cerberus.TypeDefinition('number', (int,), ())\\n\", \"    schema = {'test_field': {'min_number': 1, 'type': 'number'}}\\n\", '    validator = MyValidator(schema)\\n', '        validator=validator,\\n', '        validator=validator,\\n', \"    assert validator.errors == {'test_field': ['Below the min']}\\n\"]",
  "context": "_field': {'min_number': 1, 'type': 'number'}}\n    validator = MyValidator(schema)\n    assert_fail(\n        {'test_field': 0.0},\n    "
 }
}