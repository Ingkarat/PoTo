{
 "1": {
  "name": "zfuse",
  "type": "None",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/explore.py",
  "lineno": "19",
  "column": "4",
  "slicing": "['    zfuse = None\\n', '        if zfuse:\\n', '        zfuse.mount(self.pool, args.mountpoint)\\n']",
  "context": " Pool\n\ntry:\n    from zfs import zfuse\nexcept:\n    zfuse = None\n\nVERBOSE_LEVELS = [\n    logging.CRITICAL,\n    logg"
 },
 "2": {
  "name": "VERBOSE_LEVELS",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/explore.py",
  "lineno": "21",
  "column": "0",
  "slicing": "['    zfuse = None\\n', 'VERBOSE_LEVELS = [\\n', 'TRY_LEVELS = [\\n', 'logger = logging.getLogger(__name__)\\n', \"        self.parser = parser = argparse.ArgumentParser(prog='explore')\\n\", '        subcommands = parser.add_subparsers(\\n', '        parser.set_defaults(func=lambda a: parser.print_help(), pool=None)\\n', '        pool_parser = argparse.ArgumentParser(add_help=False)\\n', \"        pool_parser.add_argument('--pool', '-p', action='append', required=True)\\n\", \"        pool_parser.add_argument('--vdev-id', type=int, default=None)\\n\", \"        pool_parser.add_argument('--label', '-L', type=int, default=None)\\n\", \"        pool_parser.add_argument('--txg', '-T', type=int, default=None)\\n\", \"        log_opts = parser.add_argument_group('logging options',\\n\", \"        log_opts.add_argument('--verbose', '-v', action='count', default=0,\\n\", \"            help='Increase verbosity. Add more instances (e.g., -vvv) to be even more verbose.'\\n\", '        for level in map(logging.getLevelName, VERBOSE_LEVELS):\\n', '            level = level.lower()\\n', \"            log_opts.add_argument(f'--{level}', metavar='MODULE', action='append', default=[],\\n\", '                help=f\"Set the log level for MODULE to {level}.\"\\n', \"        parser.add_argument('--try', '-t', dest='try_level', action='count',\\n\", \"        try_opts = parser.add_argument_group('Try harder', 'extra options for reading data.')\\n\", '        parser.set_defaults(try_config=[])\\n', '        for name, value in TryConfig.__members__.items():\\n', \"            arg_name = '--try-'+name.replace('_', '-')\\n\", \"            try_opts.add_argument(arg_name, dest='try_config', action='append_const', const=value)\\n\", \"        parser_ls = subcommands.add_parser('ls', parents=[pool_parser], help='list files')\\n\", '        parser_ls.set_defaults(func=self.list_cmd)\\n', \"        parser_ls.add_argument('path', default='/', nargs='?', help='List the items in PATH.')\\n\", \"        parser_cat = subcommands.add_parser('cat', parents=[pool_parser], help='cat file')\\n\", '        parser_cat.set_defaults(func=self.cat)\\n', \"        parser_cat.add_argument('path', help='Output the contents of PATH.')\\n\", \"        parser_objset = subcommands.add_parser('objectset', parents=[pool_parser], aliases=['objset'],\\n\", '        parser_objset.set_defaults(func=self.objset)\\n', \"        parser_objset.add_argument('--dataset', '-d',\\n\", \"        parser_objset.add_argument('--self', action='store_true',\\n\", \"        parser_objset.add_argument('--dump', metavar='FILE',\\n\", \"        parser_objset.add_argument('--execute', '-e', metavar='CODE',\\n\", '        objset_selector_group = parser_objset.add_mutually_exclusive_group(required=True)\\n', \"        objset_selector_group.add_argument('--all', '-a', action='store_true',\\n\", \"        objset_selector_group.add_argument('--everything', action='store_true',\\n\", \"        objset_selector_group.add_argument('object', type=int, nargs='?', help='Object to display.')\\n\", '        objset_exclusive_display = parser_objset.add_mutually_exclusive_group()\\n', \"        objset_exclusive_display.add_argument('--parse', '-P', action='store_true',\\n\", \"        objset_exclusive_display.add_argument('--dnode', '-D', action='store_true',\\n\", \"        parser_nvparse = subcommands.add_parser('nvparse', help='Parse an NVList from a file. WIP')\\n\", '        parser_nvparse.set_defaults(func=self.nvparse)\\n', \"        parser_nvparse.add_argument('file', help='The file to parse.')\\n\", \"        parser_label = subcommands.add_parser('label', parents=[pool_parser], help='View disk labels.')\\n\", '        parser_label.set_defaults(func=self.label)\\n', \"        parser_label.add_argument('label', type=int, default=0, nargs='?', choices=(0, 1, 2, 3),\\n\", \"        parser_label.add_argument('--uberblocks', '-u', action='store_true')\\n\", \"        parser_label.add_argument('--all', action='store_true')\\n\", \"        parser_dva = subcommands.add_parser('dva', parents=[pool_parser], help='Read arbitrary blocks.')\\n\", '        parser_dva.set_defaults(func=self.read_dva)\\n', \"        parser_dva.add_argument('dva', help='The DVA (data virtual address) to read.')\\n\", \"        parser_dva.add_argument('--dump', metavar='FILE', help='Write the data to FILE.')\\n\", \"        parser_fuse = subcommands.add_parser('fuse', parents=[pool_parser],\\n\", '        if zfuse:\\n', '            parser_fuse.set_defaults(func=self.mount_fuse)\\n', \"        parser_fuse.add_argument('mountpoint', help='Set the mountpoint')\\n\", \"        parser_fuse.epilog = '''This requires the `fusepy` module, which in turn depends on libfuse.\\n\", '        for level in VERBOSE_LEVELS:\\n', '            levelname = logging.getLevelName(level).lower()\\n', '            modules = getattr(args, levelname)\\n', '            for mod in modules:\\n', '                logging.getLogger(mod).setLevel(level)\\n', '        args = self.parser.parse_args(*a, **kw)\\n', '        level = VERBOSE_LEVELS[args.verbose]\\n', \"        logging.basicConfig(level=level, format='%(asctime)s %(name)-12s %(levelname)-8s %(message)s')\\n\", '        if level != logging.CRITICAL:\\n', \"            logger.log(level, 'this is the most verbose log level for this run')\\n\", '        self.setup_module_logs(args)\\n', '        if args.pool:\\n', '            self.pool = self.load_pool(args)\\n', '        if args.pool and args.vdev_id == None:\\n', '            args.vdev_id = int(self.pool.first_vdev().id)\\n', '        args.func(args)\\n', '        devices = [filedev.FileDev(path, args.label, args.txg) for path in args.pool]\\n', '        try_config = set(args.try_config).union(*TRY_LEVELS[:args.try_level+1])\\n', \"        logger.info('extra options: {}'.format(try_config))\\n\", '        pool = Pool(devices, try_config=try_config)\\n', '        return pool\\n', '        target = self.pool.open(args.path)\\n', '        if isinstance(target, zfs.posix.File):\\n', '            print(args.path)\\n', '            for file in sorted(target.keys()):\\n', '                print(file)\\n', '        sys.stdout.buffer.write(self.pool.read_file(args.path))\\n', '        if args.parse:\\n', '        elif args.dnode:\\n', '        elif args.dump:\\n', \"            f = open(args.dump, 'wb')\\n\", '            f.write(self.pool.read_dnode(obj))\\n', '            f.close()\\n', '        if args.execute:\\n', '                parsed = os.parse_dnode(obj)\\n', '                parsed = None\\n', \"                exec(args.execute, globals(), {'o':obj, 'os':os, 'p':parsed})\\n\", \"                logger.exception('execution failed on object {}'.format(obj.node_type))\\n\", '        if args.dataset:\\n', '            ds = self.pool.dataset_for(args.dataset)\\n', '            os = ds.objectset\\n', '            os = self.pool.objset_for_vdev(args.vdev_id)\\n', '        if args.self:\\n', '            print(os.raw_objectset)\\n', '            if args.dump:\\n', \"                f = open(args.dump, 'wb')\\n\", '                print(len(os.objset))\\n', '                f.write(os.objset)\\n', '                f.close()\\n', '        if not args.object:\\n', '            args.all = True\\n', '        if args.all:\\n', '            for i, obj in enumerate(os):\\n', '                if obj.node_type != ObjectType.NONE or args.everything:\\n', '                    if args.parse:\\n', \"                    print(i, end=' ')\\n\", '                    self.show_object(args, os, obj)\\n', '        elif args.object:\\n', '            obj = os.get_dnode(args.object)\\n', '            self.show_object(args, os, obj)\\n', \"        source = open(args.file, 'rb')\\n\", '        data = source.read()\\n', '        nv = NVList(data)\\n', '        pprint(nv.unpack_nvlist())\\n', '        vdev = self.pool.vdevs[args.vdev_id]\\n', '        label = vdev.best_label\\n', '        if args.label is not None:\\n', '            label = vdev.labels[args.label]\\n', '            pprint(label[0])\\n', '        if args.uberblocks:\\n', '            for i, uber in enumerate(label[1]):\\n', '                if args.all or uber.valid():\\n', '                    print(i, uber)\\n', '        zfuse.mount(self.pool, args.mountpoint)\\n', '        dva = args.dva\\n']",
  "context": "  from zfs import zfuse\nexcept:\n    zfuse = None\n\nVERBOSE_LEVELS = [\n    logging.CRITICAL,\n    logging.ERROR,\n    loggi"
 },
 "3": {
  "name": "TRY_LEVELS",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/explore.py",
  "lineno": "29",
  "column": "0",
  "slicing": "['    zfuse = None\\n', 'VERBOSE_LEVELS = [\\n', 'TRY_LEVELS = [\\n', 'logger = logging.getLogger(__name__)\\n', \"        self.parser = parser = argparse.ArgumentParser(prog='explore')\\n\", '        subcommands = parser.add_subparsers(\\n', '        parser.set_defaults(func=lambda a: parser.print_help(), pool=None)\\n', '        pool_parser = argparse.ArgumentParser(add_help=False)\\n', \"        pool_parser.add_argument('--pool', '-p', action='append', required=True)\\n\", \"        pool_parser.add_argument('--vdev-id', type=int, default=None)\\n\", \"        pool_parser.add_argument('--label', '-L', type=int, default=None)\\n\", \"        pool_parser.add_argument('--txg', '-T', type=int, default=None)\\n\", \"        log_opts = parser.add_argument_group('logging options',\\n\", \"        log_opts.add_argument('--verbose', '-v', action='count', default=0,\\n\", \"            help='Increase verbosity. Add more instances (e.g., -vvv) to be even more verbose.'\\n\", '        for level in map(logging.getLevelName, VERBOSE_LEVELS):\\n', '            level = level.lower()\\n', \"            log_opts.add_argument(f'--{level}', metavar='MODULE', action='append', default=[],\\n\", '                help=f\"Set the log level for MODULE to {level}.\"\\n', \"        parser.add_argument('--try', '-t', dest='try_level', action='count',\\n\", \"        try_opts = parser.add_argument_group('Try harder', 'extra options for reading data.')\\n\", '        parser.set_defaults(try_config=[])\\n', '        for name, value in TryConfig.__members__.items():\\n', \"            arg_name = '--try-'+name.replace('_', '-')\\n\", \"            try_opts.add_argument(arg_name, dest='try_config', action='append_const', const=value)\\n\", \"        parser_ls = subcommands.add_parser('ls', parents=[pool_parser], help='list files')\\n\", '        parser_ls.set_defaults(func=self.list_cmd)\\n', \"        parser_ls.add_argument('path', default='/', nargs='?', help='List the items in PATH.')\\n\", \"        parser_cat = subcommands.add_parser('cat', parents=[pool_parser], help='cat file')\\n\", '        parser_cat.set_defaults(func=self.cat)\\n', \"        parser_cat.add_argument('path', help='Output the contents of PATH.')\\n\", \"        parser_objset = subcommands.add_parser('objectset', parents=[pool_parser], aliases=['objset'],\\n\", '        parser_objset.set_defaults(func=self.objset)\\n', \"        parser_objset.add_argument('--dataset', '-d',\\n\", \"        parser_objset.add_argument('--self', action='store_true',\\n\", \"        parser_objset.add_argument('--dump', metavar='FILE',\\n\", \"        parser_objset.add_argument('--execute', '-e', metavar='CODE',\\n\", '        objset_selector_group = parser_objset.add_mutually_exclusive_group(required=True)\\n', \"        objset_selector_group.add_argument('--all', '-a', action='store_true',\\n\", \"        objset_selector_group.add_argument('--everything', action='store_true',\\n\", \"        objset_selector_group.add_argument('object', type=int, nargs='?', help='Object to display.')\\n\", '        objset_exclusive_display = parser_objset.add_mutually_exclusive_group()\\n', \"        objset_exclusive_display.add_argument('--parse', '-P', action='store_true',\\n\", \"        objset_exclusive_display.add_argument('--dnode', '-D', action='store_true',\\n\", \"        parser_nvparse = subcommands.add_parser('nvparse', help='Parse an NVList from a file. WIP')\\n\", '        parser_nvparse.set_defaults(func=self.nvparse)\\n', \"        parser_nvparse.add_argument('file', help='The file to parse.')\\n\", \"        parser_label = subcommands.add_parser('label', parents=[pool_parser], help='View disk labels.')\\n\", '        parser_label.set_defaults(func=self.label)\\n', \"        parser_label.add_argument('label', type=int, default=0, nargs='?', choices=(0, 1, 2, 3),\\n\", \"        parser_label.add_argument('--uberblocks', '-u', action='store_true')\\n\", \"        parser_label.add_argument('--all', action='store_true')\\n\", \"        parser_dva = subcommands.add_parser('dva', parents=[pool_parser], help='Read arbitrary blocks.')\\n\", '        parser_dva.set_defaults(func=self.read_dva)\\n', \"        parser_dva.add_argument('dva', help='The DVA (data virtual address) to read.')\\n\", \"        parser_dva.add_argument('--dump', metavar='FILE', help='Write the data to FILE.')\\n\", \"        parser_fuse = subcommands.add_parser('fuse', parents=[pool_parser],\\n\", '        if zfuse:\\n', '            parser_fuse.set_defaults(func=self.mount_fuse)\\n', \"        parser_fuse.add_argument('mountpoint', help='Set the mountpoint')\\n\", \"        parser_fuse.epilog = '''This requires the `fusepy` module, which in turn depends on libfuse.\\n\", '        for level in VERBOSE_LEVELS:\\n', '            levelname = logging.getLevelName(level).lower()\\n', '            modules = getattr(args, levelname)\\n', '            for mod in modules:\\n', '                logging.getLogger(mod).setLevel(level)\\n', '        args = self.parser.parse_args(*a, **kw)\\n', '        level = VERBOSE_LEVELS[args.verbose]\\n', \"        logging.basicConfig(level=level, format='%(asctime)s %(name)-12s %(levelname)-8s %(message)s')\\n\", '        if level != logging.CRITICAL:\\n', \"            logger.log(level, 'this is the most verbose log level for this run')\\n\", '        self.setup_module_logs(args)\\n', '        if args.pool:\\n', '            self.pool = self.load_pool(args)\\n', '        if args.pool and args.vdev_id == None:\\n', '            args.vdev_id = int(self.pool.first_vdev().id)\\n', '        args.func(args)\\n', '        devices = [filedev.FileDev(path, args.label, args.txg) for path in args.pool]\\n', '        try_config = set(args.try_config).union(*TRY_LEVELS[:args.try_level+1])\\n', \"        logger.info('extra options: {}'.format(try_config))\\n\", '        pool = Pool(devices, try_config=try_config)\\n', '        return pool\\n', '        target = self.pool.open(args.path)\\n', '        if isinstance(target, zfs.posix.File):\\n', '            print(args.path)\\n', '            for file in sorted(target.keys()):\\n', '                print(file)\\n', '        sys.stdout.buffer.write(self.pool.read_file(args.path))\\n', '        if args.parse:\\n', '        elif args.dnode:\\n', '        elif args.dump:\\n', \"            f = open(args.dump, 'wb')\\n\", '            f.write(self.pool.read_dnode(obj))\\n', '            f.close()\\n', '        if args.execute:\\n', '                parsed = os.parse_dnode(obj)\\n', '                parsed = None\\n', \"                exec(args.execute, globals(), {'o':obj, 'os':os, 'p':parsed})\\n\", \"                logger.exception('execution failed on object {}'.format(obj.node_type))\\n\", '        if args.dataset:\\n', '            ds = self.pool.dataset_for(args.dataset)\\n', '            os = ds.objectset\\n', '            os = self.pool.objset_for_vdev(args.vdev_id)\\n', '        if args.self:\\n', '            print(os.raw_objectset)\\n', '            if args.dump:\\n', \"                f = open(args.dump, 'wb')\\n\", '                print(len(os.objset))\\n', '                f.write(os.objset)\\n', '                f.close()\\n', '        if not args.object:\\n', '            args.all = True\\n', '        if args.all:\\n', '            for i, obj in enumerate(os):\\n', '                if obj.node_type != ObjectType.NONE or args.everything:\\n', '                    if args.parse:\\n', \"                    print(i, end=' ')\\n\", '                    self.show_object(args, os, obj)\\n', '        elif args.object:\\n', '            obj = os.get_dnode(args.object)\\n', '            self.show_object(args, os, obj)\\n', \"        source = open(args.file, 'rb')\\n\", '        data = source.read()\\n', '        nv = NVList(data)\\n', '        pprint(nv.unpack_nvlist())\\n', '        vdev = self.pool.vdevs[args.vdev_id]\\n', '        label = vdev.best_label\\n', '        if args.label is not None:\\n', '            label = vdev.labels[args.label]\\n', '            pprint(label[0])\\n', '        if args.uberblocks:\\n', '            for i, uber in enumerate(label[1]):\\n', '                if args.all or uber.valid():\\n', '                    print(i, uber)\\n', '        zfuse.mount(self.pool, args.mountpoint)\\n', '        dva = args.dva\\n']",
  "context": ".WARNING,\n    logging.INFO,\n    logging.DEBUG,\n]\n\nTRY_LEVELS = [\n    {}, # don't try anything extra\n    {TryConfig."
 },
 "4": {
  "name": "modules",
  "type": "getattr",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/explore.py",
  "lineno": "154",
  "column": "12",
  "slicing": "['    zfuse = None\\n', 'VERBOSE_LEVELS = [\\n', 'TRY_LEVELS = [\\n', 'logger = logging.getLogger(__name__)\\n', \"        self.parser = parser = argparse.ArgumentParser(prog='explore')\\n\", '        subcommands = parser.add_subparsers(\\n', '        parser.set_defaults(func=lambda a: parser.print_help(), pool=None)\\n', '        pool_parser = argparse.ArgumentParser(add_help=False)\\n', \"        pool_parser.add_argument('--pool', '-p', action='append', required=True)\\n\", \"        pool_parser.add_argument('--vdev-id', type=int, default=None)\\n\", \"        pool_parser.add_argument('--label', '-L', type=int, default=None)\\n\", \"        pool_parser.add_argument('--txg', '-T', type=int, default=None)\\n\", \"        log_opts = parser.add_argument_group('logging options',\\n\", \"        log_opts.add_argument('--verbose', '-v', action='count', default=0,\\n\", \"            help='Increase verbosity. Add more instances (e.g., -vvv) to be even more verbose.'\\n\", '        for level in map(logging.getLevelName, VERBOSE_LEVELS):\\n', '            level = level.lower()\\n', \"            log_opts.add_argument(f'--{level}', metavar='MODULE', action='append', default=[],\\n\", '                help=f\"Set the log level for MODULE to {level}.\"\\n', \"        parser.add_argument('--try', '-t', dest='try_level', action='count',\\n\", \"        try_opts = parser.add_argument_group('Try harder', 'extra options for reading data.')\\n\", '        parser.set_defaults(try_config=[])\\n', '        for name, value in TryConfig.__members__.items():\\n', \"            arg_name = '--try-'+name.replace('_', '-')\\n\", \"            try_opts.add_argument(arg_name, dest='try_config', action='append_const', const=value)\\n\", \"        parser_ls = subcommands.add_parser('ls', parents=[pool_parser], help='list files')\\n\", '        parser_ls.set_defaults(func=self.list_cmd)\\n', \"        parser_ls.add_argument('path', default='/', nargs='?', help='List the items in PATH.')\\n\", \"        parser_cat = subcommands.add_parser('cat', parents=[pool_parser], help='cat file')\\n\", '        parser_cat.set_defaults(func=self.cat)\\n', \"        parser_cat.add_argument('path', help='Output the contents of PATH.')\\n\", \"        parser_objset = subcommands.add_parser('objectset', parents=[pool_parser], aliases=['objset'],\\n\", '        parser_objset.set_defaults(func=self.objset)\\n', \"        parser_objset.add_argument('--dataset', '-d',\\n\", \"        parser_objset.add_argument('--self', action='store_true',\\n\", \"        parser_objset.add_argument('--dump', metavar='FILE',\\n\", \"        parser_objset.add_argument('--execute', '-e', metavar='CODE',\\n\", '        objset_selector_group = parser_objset.add_mutually_exclusive_group(required=True)\\n', \"        objset_selector_group.add_argument('--all', '-a', action='store_true',\\n\", \"        objset_selector_group.add_argument('--everything', action='store_true',\\n\", \"        objset_selector_group.add_argument('object', type=int, nargs='?', help='Object to display.')\\n\", '        objset_exclusive_display = parser_objset.add_mutually_exclusive_group()\\n', \"        objset_exclusive_display.add_argument('--parse', '-P', action='store_true',\\n\", \"        objset_exclusive_display.add_argument('--dnode', '-D', action='store_true',\\n\", \"        parser_nvparse = subcommands.add_parser('nvparse', help='Parse an NVList from a file. WIP')\\n\", '        parser_nvparse.set_defaults(func=self.nvparse)\\n', \"        parser_nvparse.add_argument('file', help='The file to parse.')\\n\", \"        parser_label = subcommands.add_parser('label', parents=[pool_parser], help='View disk labels.')\\n\", '        parser_label.set_defaults(func=self.label)\\n', \"        parser_label.add_argument('label', type=int, default=0, nargs='?', choices=(0, 1, 2, 3),\\n\", \"        parser_label.add_argument('--uberblocks', '-u', action='store_true')\\n\", \"        parser_label.add_argument('--all', action='store_true')\\n\", \"        parser_dva = subcommands.add_parser('dva', parents=[pool_parser], help='Read arbitrary blocks.')\\n\", '        parser_dva.set_defaults(func=self.read_dva)\\n', \"        parser_dva.add_argument('dva', help='The DVA (data virtual address) to read.')\\n\", \"        parser_dva.add_argument('--dump', metavar='FILE', help='Write the data to FILE.')\\n\", \"        parser_fuse = subcommands.add_parser('fuse', parents=[pool_parser],\\n\", '        if zfuse:\\n', '            parser_fuse.set_defaults(func=self.mount_fuse)\\n', \"        parser_fuse.add_argument('mountpoint', help='Set the mountpoint')\\n\", \"        parser_fuse.epilog = '''This requires the `fusepy` module, which in turn depends on libfuse.\\n\", '        for level in VERBOSE_LEVELS:\\n', '            levelname = logging.getLevelName(level).lower()\\n', '            modules = getattr(args, levelname)\\n', '            for mod in modules:\\n', '                logging.getLogger(mod).setLevel(level)\\n', '        args = self.parser.parse_args(*a, **kw)\\n', '        level = VERBOSE_LEVELS[args.verbose]\\n', \"        logging.basicConfig(level=level, format='%(asctime)s %(name)-12s %(levelname)-8s %(message)s')\\n\", '        if level != logging.CRITICAL:\\n', \"            logger.log(level, 'this is the most verbose log level for this run')\\n\", '        self.setup_module_logs(args)\\n', '        if args.pool:\\n', '            self.pool = self.load_pool(args)\\n', '        if args.pool and args.vdev_id == None:\\n', '            args.vdev_id = int(self.pool.first_vdev().id)\\n', '        args.func(args)\\n', '        devices = [filedev.FileDev(path, args.label, args.txg) for path in args.pool]\\n', '        try_config = set(args.try_config).union(*TRY_LEVELS[:args.try_level+1])\\n', \"        logger.info('extra options: {}'.format(try_config))\\n\", '        pool = Pool(devices, try_config=try_config)\\n', '        return pool\\n', '        target = self.pool.open(args.path)\\n', '        if isinstance(target, zfs.posix.File):\\n', '            print(args.path)\\n', '            for file in sorted(target.keys()):\\n', '                print(file)\\n', '        sys.stdout.buffer.write(self.pool.read_file(args.path))\\n', '        if args.parse:\\n', '        elif args.dnode:\\n', '        elif args.dump:\\n', \"            f = open(args.dump, 'wb')\\n\", '            f.write(self.pool.read_dnode(obj))\\n', '            f.close()\\n', '        if args.execute:\\n', '                parsed = os.parse_dnode(obj)\\n', '                parsed = None\\n', \"                exec(args.execute, globals(), {'o':obj, 'os':os, 'p':parsed})\\n\", \"                logger.exception('execution failed on object {}'.format(obj.node_type))\\n\", '        if args.dataset:\\n', '            ds = self.pool.dataset_for(args.dataset)\\n', '            os = ds.objectset\\n', '            os = self.pool.objset_for_vdev(args.vdev_id)\\n', '        if args.self:\\n', '            print(os.raw_objectset)\\n', '            if args.dump:\\n', \"                f = open(args.dump, 'wb')\\n\", '                print(len(os.objset))\\n', '                f.write(os.objset)\\n', '                f.close()\\n', '        if not args.object:\\n', '            args.all = True\\n', '        if args.all:\\n', '            for i, obj in enumerate(os):\\n', '                if obj.node_type != ObjectType.NONE or args.everything:\\n', '                    if args.parse:\\n', \"                    print(i, end=' ')\\n\", '                    self.show_object(args, os, obj)\\n', '        elif args.object:\\n', '            obj = os.get_dnode(args.object)\\n', '            self.show_object(args, os, obj)\\n', \"        source = open(args.file, 'rb')\\n\", '        data = source.read()\\n', '        nv = NVList(data)\\n', '        pprint(nv.unpack_nvlist())\\n', '        vdev = self.pool.vdevs[args.vdev_id]\\n', '        label = vdev.best_label\\n', '        if args.label is not None:\\n', '            label = vdev.labels[args.label]\\n', '            pprint(label[0])\\n', '        if args.uberblocks:\\n', '            for i, uber in enumerate(label[1]):\\n', '                if args.all or uber.valid():\\n', '                    print(i, uber)\\n', '        zfuse.mount(self.pool, args.mountpoint)\\n', '        dva = args.dva\\n']",
  "context": "= logging.getLevelName(level).lower()\n            modules = getattr(args, levelname)\n            for mod in modules:\n                lo"
 },
 "5": {
  "name": "level",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/explore.py",
  "lineno": "160",
  "column": "8",
  "slicing": "['    zfuse = None\\n', 'VERBOSE_LEVELS = [\\n', 'TRY_LEVELS = [\\n', 'logger = logging.getLogger(__name__)\\n', \"        self.parser = parser = argparse.ArgumentParser(prog='explore')\\n\", '        subcommands = parser.add_subparsers(\\n', '        parser.set_defaults(func=lambda a: parser.print_help(), pool=None)\\n', '        pool_parser = argparse.ArgumentParser(add_help=False)\\n', \"        pool_parser.add_argument('--pool', '-p', action='append', required=True)\\n\", \"        pool_parser.add_argument('--vdev-id', type=int, default=None)\\n\", \"        pool_parser.add_argument('--label', '-L', type=int, default=None)\\n\", \"        pool_parser.add_argument('--txg', '-T', type=int, default=None)\\n\", \"        log_opts = parser.add_argument_group('logging options',\\n\", \"        log_opts.add_argument('--verbose', '-v', action='count', default=0,\\n\", \"            help='Increase verbosity. Add more instances (e.g., -vvv) to be even more verbose.'\\n\", '        for level in map(logging.getLevelName, VERBOSE_LEVELS):\\n', '            level = level.lower()\\n', \"            log_opts.add_argument(f'--{level}', metavar='MODULE', action='append', default=[],\\n\", '                help=f\"Set the log level for MODULE to {level}.\"\\n', \"        parser.add_argument('--try', '-t', dest='try_level', action='count',\\n\", \"        try_opts = parser.add_argument_group('Try harder', 'extra options for reading data.')\\n\", '        parser.set_defaults(try_config=[])\\n', '        for name, value in TryConfig.__members__.items():\\n', \"            arg_name = '--try-'+name.replace('_', '-')\\n\", \"            try_opts.add_argument(arg_name, dest='try_config', action='append_const', const=value)\\n\", \"        parser_ls = subcommands.add_parser('ls', parents=[pool_parser], help='list files')\\n\", '        parser_ls.set_defaults(func=self.list_cmd)\\n', \"        parser_ls.add_argument('path', default='/', nargs='?', help='List the items in PATH.')\\n\", \"        parser_cat = subcommands.add_parser('cat', parents=[pool_parser], help='cat file')\\n\", '        parser_cat.set_defaults(func=self.cat)\\n', \"        parser_cat.add_argument('path', help='Output the contents of PATH.')\\n\", \"        parser_objset = subcommands.add_parser('objectset', parents=[pool_parser], aliases=['objset'],\\n\", '        parser_objset.set_defaults(func=self.objset)\\n', \"        parser_objset.add_argument('--dataset', '-d',\\n\", \"        parser_objset.add_argument('--self', action='store_true',\\n\", \"        parser_objset.add_argument('--dump', metavar='FILE',\\n\", \"        parser_objset.add_argument('--execute', '-e', metavar='CODE',\\n\", '        objset_selector_group = parser_objset.add_mutually_exclusive_group(required=True)\\n', \"        objset_selector_group.add_argument('--all', '-a', action='store_true',\\n\", \"        objset_selector_group.add_argument('--everything', action='store_true',\\n\", \"        objset_selector_group.add_argument('object', type=int, nargs='?', help='Object to display.')\\n\", '        objset_exclusive_display = parser_objset.add_mutually_exclusive_group()\\n', \"        objset_exclusive_display.add_argument('--parse', '-P', action='store_true',\\n\", \"        objset_exclusive_display.add_argument('--dnode', '-D', action='store_true',\\n\", \"        parser_nvparse = subcommands.add_parser('nvparse', help='Parse an NVList from a file. WIP')\\n\", '        parser_nvparse.set_defaults(func=self.nvparse)\\n', \"        parser_nvparse.add_argument('file', help='The file to parse.')\\n\", \"        parser_label = subcommands.add_parser('label', parents=[pool_parser], help='View disk labels.')\\n\", '        parser_label.set_defaults(func=self.label)\\n', \"        parser_label.add_argument('label', type=int, default=0, nargs='?', choices=(0, 1, 2, 3),\\n\", \"        parser_label.add_argument('--uberblocks', '-u', action='store_true')\\n\", \"        parser_label.add_argument('--all', action='store_true')\\n\", \"        parser_dva = subcommands.add_parser('dva', parents=[pool_parser], help='Read arbitrary blocks.')\\n\", '        parser_dva.set_defaults(func=self.read_dva)\\n', \"        parser_dva.add_argument('dva', help='The DVA (data virtual address) to read.')\\n\", \"        parser_dva.add_argument('--dump', metavar='FILE', help='Write the data to FILE.')\\n\", \"        parser_fuse = subcommands.add_parser('fuse', parents=[pool_parser],\\n\", '        if zfuse:\\n', '            parser_fuse.set_defaults(func=self.mount_fuse)\\n', \"        parser_fuse.add_argument('mountpoint', help='Set the mountpoint')\\n\", \"        parser_fuse.epilog = '''This requires the `fusepy` module, which in turn depends on libfuse.\\n\", '        for level in VERBOSE_LEVELS:\\n', '            levelname = logging.getLevelName(level).lower()\\n', '            modules = getattr(args, levelname)\\n', '            for mod in modules:\\n', '                logging.getLogger(mod).setLevel(level)\\n', '        args = self.parser.parse_args(*a, **kw)\\n', '        level = VERBOSE_LEVELS[args.verbose]\\n', \"        logging.basicConfig(level=level, format='%(asctime)s %(name)-12s %(levelname)-8s %(message)s')\\n\", '        if level != logging.CRITICAL:\\n', \"            logger.log(level, 'this is the most verbose log level for this run')\\n\", '        self.setup_module_logs(args)\\n', '        if args.pool:\\n', '            self.pool = self.load_pool(args)\\n', '        if args.pool and args.vdev_id == None:\\n', '            args.vdev_id = int(self.pool.first_vdev().id)\\n', '        args.func(args)\\n', '        devices = [filedev.FileDev(path, args.label, args.txg) for path in args.pool]\\n', '        try_config = set(args.try_config).union(*TRY_LEVELS[:args.try_level+1])\\n', \"        logger.info('extra options: {}'.format(try_config))\\n\", '        pool = Pool(devices, try_config=try_config)\\n', '        return pool\\n', '        target = self.pool.open(args.path)\\n', '        if isinstance(target, zfs.posix.File):\\n', '            print(args.path)\\n', '            for file in sorted(target.keys()):\\n', '                print(file)\\n', '        sys.stdout.buffer.write(self.pool.read_file(args.path))\\n', '        if args.parse:\\n', '        elif args.dnode:\\n', '        elif args.dump:\\n', \"            f = open(args.dump, 'wb')\\n\", '            f.write(self.pool.read_dnode(obj))\\n', '            f.close()\\n', '        if args.execute:\\n', '                parsed = os.parse_dnode(obj)\\n', '                parsed = None\\n', \"                exec(args.execute, globals(), {'o':obj, 'os':os, 'p':parsed})\\n\", \"                logger.exception('execution failed on object {}'.format(obj.node_type))\\n\", '        if args.dataset:\\n', '            ds = self.pool.dataset_for(args.dataset)\\n', '            os = ds.objectset\\n', '            os = self.pool.objset_for_vdev(args.vdev_id)\\n', '        if args.self:\\n', '            print(os.raw_objectset)\\n', '            if args.dump:\\n', \"                f = open(args.dump, 'wb')\\n\", '                print(len(os.objset))\\n', '                f.write(os.objset)\\n', '                f.close()\\n', '        if not args.object:\\n', '            args.all = True\\n', '        if args.all:\\n', '            for i, obj in enumerate(os):\\n', '                if obj.node_type != ObjectType.NONE or args.everything:\\n', '                    if args.parse:\\n', \"                    print(i, end=' ')\\n\", '                    self.show_object(args, os, obj)\\n', '        elif args.object:\\n', '            obj = os.get_dnode(args.object)\\n', '            self.show_object(args, os, obj)\\n', \"        source = open(args.file, 'rb')\\n\", '        data = source.read()\\n', '        nv = NVList(data)\\n', '        pprint(nv.unpack_nvlist())\\n', '        vdev = self.pool.vdevs[args.vdev_id]\\n', '        label = vdev.best_label\\n', '        if args.label is not None:\\n', '            label = vdev.labels[args.label]\\n', '            pprint(label[0])\\n', '        if args.uberblocks:\\n', '            for i, uber in enumerate(label[1]):\\n', '                if args.all or uber.valid():\\n', '                    print(i, uber)\\n', '        zfuse.mount(self.pool, args.mountpoint)\\n', '        dva = args.dva\\n']",
  "context": "  args = self.parser.parse_args(*a, **kw)\n        level = VERBOSE_LEVELS[args.verbose]\n        logging.basicConfig(level=level, format='%"
 },
 "6": {
  "name": "devices",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/explore.py",
  "lineno": "174",
  "column": "8",
  "slicing": "['    zfuse = None\\n', 'VERBOSE_LEVELS = [\\n', 'TRY_LEVELS = [\\n', 'logger = logging.getLogger(__name__)\\n', \"        self.parser = parser = argparse.ArgumentParser(prog='explore')\\n\", '        subcommands = parser.add_subparsers(\\n', '        parser.set_defaults(func=lambda a: parser.print_help(), pool=None)\\n', '        pool_parser = argparse.ArgumentParser(add_help=False)\\n', \"        pool_parser.add_argument('--pool', '-p', action='append', required=True)\\n\", \"        pool_parser.add_argument('--vdev-id', type=int, default=None)\\n\", \"        pool_parser.add_argument('--label', '-L', type=int, default=None)\\n\", \"        pool_parser.add_argument('--txg', '-T', type=int, default=None)\\n\", \"        log_opts = parser.add_argument_group('logging options',\\n\", \"        log_opts.add_argument('--verbose', '-v', action='count', default=0,\\n\", \"            help='Increase verbosity. Add more instances (e.g., -vvv) to be even more verbose.'\\n\", '        for level in map(logging.getLevelName, VERBOSE_LEVELS):\\n', '            level = level.lower()\\n', \"            log_opts.add_argument(f'--{level}', metavar='MODULE', action='append', default=[],\\n\", '                help=f\"Set the log level for MODULE to {level}.\"\\n', \"        parser.add_argument('--try', '-t', dest='try_level', action='count',\\n\", \"        try_opts = parser.add_argument_group('Try harder', 'extra options for reading data.')\\n\", '        parser.set_defaults(try_config=[])\\n', '        for name, value in TryConfig.__members__.items():\\n', \"            arg_name = '--try-'+name.replace('_', '-')\\n\", \"            try_opts.add_argument(arg_name, dest='try_config', action='append_const', const=value)\\n\", \"        parser_ls = subcommands.add_parser('ls', parents=[pool_parser], help='list files')\\n\", '        parser_ls.set_defaults(func=self.list_cmd)\\n', \"        parser_ls.add_argument('path', default='/', nargs='?', help='List the items in PATH.')\\n\", \"        parser_cat = subcommands.add_parser('cat', parents=[pool_parser], help='cat file')\\n\", '        parser_cat.set_defaults(func=self.cat)\\n', \"        parser_cat.add_argument('path', help='Output the contents of PATH.')\\n\", \"        parser_objset = subcommands.add_parser('objectset', parents=[pool_parser], aliases=['objset'],\\n\", '        parser_objset.set_defaults(func=self.objset)\\n', \"        parser_objset.add_argument('--dataset', '-d',\\n\", \"        parser_objset.add_argument('--self', action='store_true',\\n\", \"        parser_objset.add_argument('--dump', metavar='FILE',\\n\", \"        parser_objset.add_argument('--execute', '-e', metavar='CODE',\\n\", '        objset_selector_group = parser_objset.add_mutually_exclusive_group(required=True)\\n', \"        objset_selector_group.add_argument('--all', '-a', action='store_true',\\n\", \"        objset_selector_group.add_argument('--everything', action='store_true',\\n\", \"        objset_selector_group.add_argument('object', type=int, nargs='?', help='Object to display.')\\n\", '        objset_exclusive_display = parser_objset.add_mutually_exclusive_group()\\n', \"        objset_exclusive_display.add_argument('--parse', '-P', action='store_true',\\n\", \"        objset_exclusive_display.add_argument('--dnode', '-D', action='store_true',\\n\", \"        parser_nvparse = subcommands.add_parser('nvparse', help='Parse an NVList from a file. WIP')\\n\", '        parser_nvparse.set_defaults(func=self.nvparse)\\n', \"        parser_nvparse.add_argument('file', help='The file to parse.')\\n\", \"        parser_label = subcommands.add_parser('label', parents=[pool_parser], help='View disk labels.')\\n\", '        parser_label.set_defaults(func=self.label)\\n', \"        parser_label.add_argument('label', type=int, default=0, nargs='?', choices=(0, 1, 2, 3),\\n\", \"        parser_label.add_argument('--uberblocks', '-u', action='store_true')\\n\", \"        parser_label.add_argument('--all', action='store_true')\\n\", \"        parser_dva = subcommands.add_parser('dva', parents=[pool_parser], help='Read arbitrary blocks.')\\n\", '        parser_dva.set_defaults(func=self.read_dva)\\n', \"        parser_dva.add_argument('dva', help='The DVA (data virtual address) to read.')\\n\", \"        parser_dva.add_argument('--dump', metavar='FILE', help='Write the data to FILE.')\\n\", \"        parser_fuse = subcommands.add_parser('fuse', parents=[pool_parser],\\n\", '        if zfuse:\\n', '            parser_fuse.set_defaults(func=self.mount_fuse)\\n', \"        parser_fuse.add_argument('mountpoint', help='Set the mountpoint')\\n\", \"        parser_fuse.epilog = '''This requires the `fusepy` module, which in turn depends on libfuse.\\n\", '        for level in VERBOSE_LEVELS:\\n', '            levelname = logging.getLevelName(level).lower()\\n', '            modules = getattr(args, levelname)\\n', '            for mod in modules:\\n', '                logging.getLogger(mod).setLevel(level)\\n', '        args = self.parser.parse_args(*a, **kw)\\n', '        level = VERBOSE_LEVELS[args.verbose]\\n', \"        logging.basicConfig(level=level, format='%(asctime)s %(name)-12s %(levelname)-8s %(message)s')\\n\", '        if level != logging.CRITICAL:\\n', \"            logger.log(level, 'this is the most verbose log level for this run')\\n\", '        self.setup_module_logs(args)\\n', '        if args.pool:\\n', '            self.pool = self.load_pool(args)\\n', '        if args.pool and args.vdev_id == None:\\n', '            args.vdev_id = int(self.pool.first_vdev().id)\\n', '        args.func(args)\\n', '        devices = [filedev.FileDev(path, args.label, args.txg) for path in args.pool]\\n', '        try_config = set(args.try_config).union(*TRY_LEVELS[:args.try_level+1])\\n', \"        logger.info('extra options: {}'.format(try_config))\\n\", '        pool = Pool(devices, try_config=try_config)\\n', '        return pool\\n', '        target = self.pool.open(args.path)\\n', '        if isinstance(target, zfs.posix.File):\\n', '            print(args.path)\\n', '            for file in sorted(target.keys()):\\n', '                print(file)\\n', '        sys.stdout.buffer.write(self.pool.read_file(args.path))\\n', '        if args.parse:\\n', '        elif args.dnode:\\n', '        elif args.dump:\\n', \"            f = open(args.dump, 'wb')\\n\", '            f.write(self.pool.read_dnode(obj))\\n', '            f.close()\\n', '        if args.execute:\\n', '                parsed = os.parse_dnode(obj)\\n', '                parsed = None\\n', \"                exec(args.execute, globals(), {'o':obj, 'os':os, 'p':parsed})\\n\", \"                logger.exception('execution failed on object {}'.format(obj.node_type))\\n\", '        if args.dataset:\\n', '            ds = self.pool.dataset_for(args.dataset)\\n', '            os = ds.objectset\\n', '            os = self.pool.objset_for_vdev(args.vdev_id)\\n', '        if args.self:\\n', '            print(os.raw_objectset)\\n', '            if args.dump:\\n', \"                f = open(args.dump, 'wb')\\n\", '                print(len(os.objset))\\n', '                f.write(os.objset)\\n', '                f.close()\\n', '        if not args.object:\\n', '            args.all = True\\n', '        if args.all:\\n', '            for i, obj in enumerate(os):\\n', '                if obj.node_type != ObjectType.NONE or args.everything:\\n', '                    if args.parse:\\n', \"                    print(i, end=' ')\\n\", '                    self.show_object(args, os, obj)\\n', '        elif args.object:\\n', '            obj = os.get_dnode(args.object)\\n', '            self.show_object(args, os, obj)\\n', \"        source = open(args.file, 'rb')\\n\", '        data = source.read()\\n', '        nv = NVList(data)\\n', '        pprint(nv.unpack_nvlist())\\n', '        vdev = self.pool.vdevs[args.vdev_id]\\n', '        label = vdev.best_label\\n', '        if args.label is not None:\\n', '            label = vdev.labels[args.label]\\n', '            pprint(label[0])\\n', '        if args.uberblocks:\\n', '            for i, uber in enumerate(label[1]):\\n', '                if args.all or uber.valid():\\n', '                    print(i, uber)\\n', '        zfuse.mount(self.pool, args.mountpoint)\\n', '        dva = args.dva\\n']",
  "context": "ODO: parse disk label to find other vdevs\n        devices = [filedev.FileDev(path, args.label, args.txg) for path in args.pool]\n        try_config = set(args.try_config).union(*T"
 },
 "7": {
  "name": "pool",
  "type": "zfs.pool.Pool",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/explore.py",
  "lineno": "177",
  "column": "8",
  "slicing": "['    zfuse = None\\n', 'VERBOSE_LEVELS = [\\n', 'TRY_LEVELS = [\\n', 'logger = logging.getLogger(__name__)\\n', \"        self.parser = parser = argparse.ArgumentParser(prog='explore')\\n\", '        subcommands = parser.add_subparsers(\\n', '        parser.set_defaults(func=lambda a: parser.print_help(), pool=None)\\n', '        pool_parser = argparse.ArgumentParser(add_help=False)\\n', \"        pool_parser.add_argument('--pool', '-p', action='append', required=True)\\n\", \"        pool_parser.add_argument('--vdev-id', type=int, default=None)\\n\", \"        pool_parser.add_argument('--label', '-L', type=int, default=None)\\n\", \"        pool_parser.add_argument('--txg', '-T', type=int, default=None)\\n\", \"        log_opts = parser.add_argument_group('logging options',\\n\", \"        log_opts.add_argument('--verbose', '-v', action='count', default=0,\\n\", \"            help='Increase verbosity. Add more instances (e.g., -vvv) to be even more verbose.'\\n\", '        for level in map(logging.getLevelName, VERBOSE_LEVELS):\\n', '            level = level.lower()\\n', \"            log_opts.add_argument(f'--{level}', metavar='MODULE', action='append', default=[],\\n\", '                help=f\"Set the log level for MODULE to {level}.\"\\n', \"        parser.add_argument('--try', '-t', dest='try_level', action='count',\\n\", \"        try_opts = parser.add_argument_group('Try harder', 'extra options for reading data.')\\n\", '        parser.set_defaults(try_config=[])\\n', '        for name, value in TryConfig.__members__.items():\\n', \"            arg_name = '--try-'+name.replace('_', '-')\\n\", \"            try_opts.add_argument(arg_name, dest='try_config', action='append_const', const=value)\\n\", \"        parser_ls = subcommands.add_parser('ls', parents=[pool_parser], help='list files')\\n\", '        parser_ls.set_defaults(func=self.list_cmd)\\n', \"        parser_ls.add_argument('path', default='/', nargs='?', help='List the items in PATH.')\\n\", \"        parser_cat = subcommands.add_parser('cat', parents=[pool_parser], help='cat file')\\n\", '        parser_cat.set_defaults(func=self.cat)\\n', \"        parser_cat.add_argument('path', help='Output the contents of PATH.')\\n\", \"        parser_objset = subcommands.add_parser('objectset', parents=[pool_parser], aliases=['objset'],\\n\", '        parser_objset.set_defaults(func=self.objset)\\n', \"        parser_objset.add_argument('--dataset', '-d',\\n\", \"        parser_objset.add_argument('--self', action='store_true',\\n\", \"        parser_objset.add_argument('--dump', metavar='FILE',\\n\", \"        parser_objset.add_argument('--execute', '-e', metavar='CODE',\\n\", '        objset_selector_group = parser_objset.add_mutually_exclusive_group(required=True)\\n', \"        objset_selector_group.add_argument('--all', '-a', action='store_true',\\n\", \"        objset_selector_group.add_argument('--everything', action='store_true',\\n\", \"        objset_selector_group.add_argument('object', type=int, nargs='?', help='Object to display.')\\n\", '        objset_exclusive_display = parser_objset.add_mutually_exclusive_group()\\n', \"        objset_exclusive_display.add_argument('--parse', '-P', action='store_true',\\n\", \"        objset_exclusive_display.add_argument('--dnode', '-D', action='store_true',\\n\", \"        parser_nvparse = subcommands.add_parser('nvparse', help='Parse an NVList from a file. WIP')\\n\", '        parser_nvparse.set_defaults(func=self.nvparse)\\n', \"        parser_nvparse.add_argument('file', help='The file to parse.')\\n\", \"        parser_label = subcommands.add_parser('label', parents=[pool_parser], help='View disk labels.')\\n\", '        parser_label.set_defaults(func=self.label)\\n', \"        parser_label.add_argument('label', type=int, default=0, nargs='?', choices=(0, 1, 2, 3),\\n\", \"        parser_label.add_argument('--uberblocks', '-u', action='store_true')\\n\", \"        parser_label.add_argument('--all', action='store_true')\\n\", \"        parser_dva = subcommands.add_parser('dva', parents=[pool_parser], help='Read arbitrary blocks.')\\n\", '        parser_dva.set_defaults(func=self.read_dva)\\n', \"        parser_dva.add_argument('dva', help='The DVA (data virtual address) to read.')\\n\", \"        parser_dva.add_argument('--dump', metavar='FILE', help='Write the data to FILE.')\\n\", \"        parser_fuse = subcommands.add_parser('fuse', parents=[pool_parser],\\n\", '        if zfuse:\\n', '            parser_fuse.set_defaults(func=self.mount_fuse)\\n', \"        parser_fuse.add_argument('mountpoint', help='Set the mountpoint')\\n\", \"        parser_fuse.epilog = '''This requires the `fusepy` module, which in turn depends on libfuse.\\n\", '        for level in VERBOSE_LEVELS:\\n', '            levelname = logging.getLevelName(level).lower()\\n', '            modules = getattr(args, levelname)\\n', '            for mod in modules:\\n', '                logging.getLogger(mod).setLevel(level)\\n', '        args = self.parser.parse_args(*a, **kw)\\n', '        level = VERBOSE_LEVELS[args.verbose]\\n', \"        logging.basicConfig(level=level, format='%(asctime)s %(name)-12s %(levelname)-8s %(message)s')\\n\", '        if level != logging.CRITICAL:\\n', \"            logger.log(level, 'this is the most verbose log level for this run')\\n\", '        self.setup_module_logs(args)\\n', '        if args.pool:\\n', '            self.pool = self.load_pool(args)\\n', '        if args.pool and args.vdev_id == None:\\n', '            args.vdev_id = int(self.pool.first_vdev().id)\\n', '        args.func(args)\\n', '        devices = [filedev.FileDev(path, args.label, args.txg) for path in args.pool]\\n', '        try_config = set(args.try_config).union(*TRY_LEVELS[:args.try_level+1])\\n', \"        logger.info('extra options: {}'.format(try_config))\\n\", '        pool = Pool(devices, try_config=try_config)\\n', '        return pool\\n', '        target = self.pool.open(args.path)\\n', '        if isinstance(target, zfs.posix.File):\\n', '            print(args.path)\\n', '            for file in sorted(target.keys()):\\n', '                print(file)\\n', '        sys.stdout.buffer.write(self.pool.read_file(args.path))\\n', '        if args.parse:\\n', '        elif args.dnode:\\n', '        elif args.dump:\\n', \"            f = open(args.dump, 'wb')\\n\", '            f.write(self.pool.read_dnode(obj))\\n', '            f.close()\\n', '        if args.execute:\\n', '                parsed = os.parse_dnode(obj)\\n', '                parsed = None\\n', \"                exec(args.execute, globals(), {'o':obj, 'os':os, 'p':parsed})\\n\", \"                logger.exception('execution failed on object {}'.format(obj.node_type))\\n\", '        if args.dataset:\\n', '            ds = self.pool.dataset_for(args.dataset)\\n', '            os = ds.objectset\\n', '            os = self.pool.objset_for_vdev(args.vdev_id)\\n', '        if args.self:\\n', '            print(os.raw_objectset)\\n', '            if args.dump:\\n', \"                f = open(args.dump, 'wb')\\n\", '                print(len(os.objset))\\n', '                f.write(os.objset)\\n', '                f.close()\\n', '        if not args.object:\\n', '            args.all = True\\n', '        if args.all:\\n', '            for i, obj in enumerate(os):\\n', '                if obj.node_type != ObjectType.NONE or args.everything:\\n', '                    if args.parse:\\n', \"                    print(i, end=' ')\\n\", '                    self.show_object(args, os, obj)\\n', '        elif args.object:\\n', '            obj = os.get_dnode(args.object)\\n', '            self.show_object(args, os, obj)\\n', \"        source = open(args.file, 'rb')\\n\", '        data = source.read()\\n', '        nv = NVList(data)\\n', '        pprint(nv.unpack_nvlist())\\n', '        vdev = self.pool.vdevs[args.vdev_id]\\n', '        label = vdev.best_label\\n', '        if args.label is not None:\\n', '            label = vdev.labels[args.label]\\n', '            pprint(label[0])\\n', '        if args.uberblocks:\\n', '            for i, uber in enumerate(label[1]):\\n', '                if args.all or uber.valid():\\n', '                    print(i, uber)\\n', '        zfuse.mount(self.pool, args.mountpoint)\\n', '        dva = args.dva\\n']",
  "context": "o('extra options: {}'.format(try_config))\n        pool = Pool(devices, try_config=try_config)\n        return pool\n\n    def list_cmd(self, args):"
 },
 "8": {
  "name": "f",
  "type": "open",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/explore.py",
  "lineno": "203",
  "column": "12",
  "slicing": "['    zfuse = None\\n', 'VERBOSE_LEVELS = [\\n', 'TRY_LEVELS = [\\n', 'logger = logging.getLogger(__name__)\\n', \"        self.parser = parser = argparse.ArgumentParser(prog='explore')\\n\", '        subcommands = parser.add_subparsers(\\n', '        parser.set_defaults(func=lambda a: parser.print_help(), pool=None)\\n', '        pool_parser = argparse.ArgumentParser(add_help=False)\\n', \"        pool_parser.add_argument('--pool', '-p', action='append', required=True)\\n\", \"        pool_parser.add_argument('--vdev-id', type=int, default=None)\\n\", \"        pool_parser.add_argument('--label', '-L', type=int, default=None)\\n\", \"        pool_parser.add_argument('--txg', '-T', type=int, default=None)\\n\", \"        log_opts = parser.add_argument_group('logging options',\\n\", \"        log_opts.add_argument('--verbose', '-v', action='count', default=0,\\n\", \"            help='Increase verbosity. Add more instances (e.g., -vvv) to be even more verbose.'\\n\", '        for level in map(logging.getLevelName, VERBOSE_LEVELS):\\n', '            level = level.lower()\\n', \"            log_opts.add_argument(f'--{level}', metavar='MODULE', action='append', default=[],\\n\", '                help=f\"Set the log level for MODULE to {level}.\"\\n', \"        parser.add_argument('--try', '-t', dest='try_level', action='count',\\n\", \"        try_opts = parser.add_argument_group('Try harder', 'extra options for reading data.')\\n\", '        parser.set_defaults(try_config=[])\\n', '        for name, value in TryConfig.__members__.items():\\n', \"            arg_name = '--try-'+name.replace('_', '-')\\n\", \"            try_opts.add_argument(arg_name, dest='try_config', action='append_const', const=value)\\n\", \"        parser_ls = subcommands.add_parser('ls', parents=[pool_parser], help='list files')\\n\", '        parser_ls.set_defaults(func=self.list_cmd)\\n', \"        parser_ls.add_argument('path', default='/', nargs='?', help='List the items in PATH.')\\n\", \"        parser_cat = subcommands.add_parser('cat', parents=[pool_parser], help='cat file')\\n\", '        parser_cat.set_defaults(func=self.cat)\\n', \"        parser_cat.add_argument('path', help='Output the contents of PATH.')\\n\", \"        parser_objset = subcommands.add_parser('objectset', parents=[pool_parser], aliases=['objset'],\\n\", '        parser_objset.set_defaults(func=self.objset)\\n', \"        parser_objset.add_argument('--dataset', '-d',\\n\", \"        parser_objset.add_argument('--self', action='store_true',\\n\", \"        parser_objset.add_argument('--dump', metavar='FILE',\\n\", \"        parser_objset.add_argument('--execute', '-e', metavar='CODE',\\n\", '        objset_selector_group = parser_objset.add_mutually_exclusive_group(required=True)\\n', \"        objset_selector_group.add_argument('--all', '-a', action='store_true',\\n\", \"        objset_selector_group.add_argument('--everything', action='store_true',\\n\", \"        objset_selector_group.add_argument('object', type=int, nargs='?', help='Object to display.')\\n\", '        objset_exclusive_display = parser_objset.add_mutually_exclusive_group()\\n', \"        objset_exclusive_display.add_argument('--parse', '-P', action='store_true',\\n\", \"        objset_exclusive_display.add_argument('--dnode', '-D', action='store_true',\\n\", \"        parser_nvparse = subcommands.add_parser('nvparse', help='Parse an NVList from a file. WIP')\\n\", '        parser_nvparse.set_defaults(func=self.nvparse)\\n', \"        parser_nvparse.add_argument('file', help='The file to parse.')\\n\", \"        parser_label = subcommands.add_parser('label', parents=[pool_parser], help='View disk labels.')\\n\", '        parser_label.set_defaults(func=self.label)\\n', \"        parser_label.add_argument('label', type=int, default=0, nargs='?', choices=(0, 1, 2, 3),\\n\", \"        parser_label.add_argument('--uberblocks', '-u', action='store_true')\\n\", \"        parser_label.add_argument('--all', action='store_true')\\n\", \"        parser_dva = subcommands.add_parser('dva', parents=[pool_parser], help='Read arbitrary blocks.')\\n\", '        parser_dva.set_defaults(func=self.read_dva)\\n', \"        parser_dva.add_argument('dva', help='The DVA (data virtual address) to read.')\\n\", \"        parser_dva.add_argument('--dump', metavar='FILE', help='Write the data to FILE.')\\n\", \"        parser_fuse = subcommands.add_parser('fuse', parents=[pool_parser],\\n\", '        if zfuse:\\n', '            parser_fuse.set_defaults(func=self.mount_fuse)\\n', \"        parser_fuse.add_argument('mountpoint', help='Set the mountpoint')\\n\", \"        parser_fuse.epilog = '''This requires the `fusepy` module, which in turn depends on libfuse.\\n\", '        for level in VERBOSE_LEVELS:\\n', '            levelname = logging.getLevelName(level).lower()\\n', '            modules = getattr(args, levelname)\\n', '            for mod in modules:\\n', '                logging.getLogger(mod).setLevel(level)\\n', '        args = self.parser.parse_args(*a, **kw)\\n', '        level = VERBOSE_LEVELS[args.verbose]\\n', \"        logging.basicConfig(level=level, format='%(asctime)s %(name)-12s %(levelname)-8s %(message)s')\\n\", '        if level != logging.CRITICAL:\\n', \"            logger.log(level, 'this is the most verbose log level for this run')\\n\", '        self.setup_module_logs(args)\\n', '        if args.pool:\\n', '            self.pool = self.load_pool(args)\\n', '        if args.pool and args.vdev_id == None:\\n', '            args.vdev_id = int(self.pool.first_vdev().id)\\n', '        args.func(args)\\n', '        devices = [filedev.FileDev(path, args.label, args.txg) for path in args.pool]\\n', '        try_config = set(args.try_config).union(*TRY_LEVELS[:args.try_level+1])\\n', \"        logger.info('extra options: {}'.format(try_config))\\n\", '        pool = Pool(devices, try_config=try_config)\\n', '        return pool\\n', '        target = self.pool.open(args.path)\\n', '        if isinstance(target, zfs.posix.File):\\n', '            print(args.path)\\n', '            for file in sorted(target.keys()):\\n', '                print(file)\\n', '        sys.stdout.buffer.write(self.pool.read_file(args.path))\\n', '        if args.parse:\\n', '        elif args.dnode:\\n', '        elif args.dump:\\n', \"            f = open(args.dump, 'wb')\\n\", '            f.write(self.pool.read_dnode(obj))\\n', '            f.close()\\n', '        if args.execute:\\n', '                parsed = os.parse_dnode(obj)\\n', '                parsed = None\\n', \"                exec(args.execute, globals(), {'o':obj, 'os':os, 'p':parsed})\\n\", \"                logger.exception('execution failed on object {}'.format(obj.node_type))\\n\", '        if args.dataset:\\n', '            ds = self.pool.dataset_for(args.dataset)\\n', '            os = ds.objectset\\n', '            os = self.pool.objset_for_vdev(args.vdev_id)\\n', '        if args.self:\\n', '            print(os.raw_objectset)\\n', '            if args.dump:\\n', \"                f = open(args.dump, 'wb')\\n\", '                print(len(os.objset))\\n', '                f.write(os.objset)\\n', '                f.close()\\n', '        if not args.object:\\n', '            args.all = True\\n', '        if args.all:\\n', '            for i, obj in enumerate(os):\\n', '                if obj.node_type != ObjectType.NONE or args.everything:\\n', '                    if args.parse:\\n', \"                    print(i, end=' ')\\n\", '                    self.show_object(args, os, obj)\\n', '        elif args.object:\\n', '            obj = os.get_dnode(args.object)\\n', '            self.show_object(args, os, obj)\\n', \"        source = open(args.file, 'rb')\\n\", '        data = source.read()\\n', '        nv = NVList(data)\\n', '        pprint(nv.unpack_nvlist())\\n', '        vdev = self.pool.vdevs[args.vdev_id]\\n', '        label = vdev.best_label\\n', '        if args.label is not None:\\n', '            label = vdev.labels[args.label]\\n', '            pprint(label[0])\\n', '        if args.uberblocks:\\n', '            for i, uber in enumerate(label[1]):\\n', '                if args.all or uber.valid():\\n', '                    print(i, uber)\\n', '        zfuse.mount(self.pool, args.mountpoint)\\n', '        dva = args.dva\\n']",
  "context": "   print(obj)\n        elif args.dump:\n            f = open(args.dump, 'wb')\n            f.write(self.pool.read_dnode(obj))\n   "
 },
 "9": {
  "name": "parsed",
  "type": "None",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/explore.py",
  "lineno": "212",
  "column": "16",
  "slicing": "['                parsed = None\\n', \"                exec(args.execute, globals(), {'o':obj, 'os':os, 'p':parsed})\\n\"]",
  "context": "se_dnode(obj)\n            except:\n                parsed = None\n            try:\n                exec(args.execute"
 },
 "10": {
  "name": "f",
  "type": "open",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/explore.py",
  "lineno": "228",
  "column": "16",
  "slicing": "['    zfuse = None\\n', 'VERBOSE_LEVELS = [\\n', 'TRY_LEVELS = [\\n', 'logger = logging.getLogger(__name__)\\n', \"        self.parser = parser = argparse.ArgumentParser(prog='explore')\\n\", '        subcommands = parser.add_subparsers(\\n', '        parser.set_defaults(func=lambda a: parser.print_help(), pool=None)\\n', '        pool_parser = argparse.ArgumentParser(add_help=False)\\n', \"        pool_parser.add_argument('--pool', '-p', action='append', required=True)\\n\", \"        pool_parser.add_argument('--vdev-id', type=int, default=None)\\n\", \"        pool_parser.add_argument('--label', '-L', type=int, default=None)\\n\", \"        pool_parser.add_argument('--txg', '-T', type=int, default=None)\\n\", \"        log_opts = parser.add_argument_group('logging options',\\n\", \"        log_opts.add_argument('--verbose', '-v', action='count', default=0,\\n\", \"            help='Increase verbosity. Add more instances (e.g., -vvv) to be even more verbose.'\\n\", '        for level in map(logging.getLevelName, VERBOSE_LEVELS):\\n', '            level = level.lower()\\n', \"            log_opts.add_argument(f'--{level}', metavar='MODULE', action='append', default=[],\\n\", '                help=f\"Set the log level for MODULE to {level}.\"\\n', \"        parser.add_argument('--try', '-t', dest='try_level', action='count',\\n\", \"        try_opts = parser.add_argument_group('Try harder', 'extra options for reading data.')\\n\", '        parser.set_defaults(try_config=[])\\n', '        for name, value in TryConfig.__members__.items():\\n', \"            arg_name = '--try-'+name.replace('_', '-')\\n\", \"            try_opts.add_argument(arg_name, dest='try_config', action='append_const', const=value)\\n\", \"        parser_ls = subcommands.add_parser('ls', parents=[pool_parser], help='list files')\\n\", '        parser_ls.set_defaults(func=self.list_cmd)\\n', \"        parser_ls.add_argument('path', default='/', nargs='?', help='List the items in PATH.')\\n\", \"        parser_cat = subcommands.add_parser('cat', parents=[pool_parser], help='cat file')\\n\", '        parser_cat.set_defaults(func=self.cat)\\n', \"        parser_cat.add_argument('path', help='Output the contents of PATH.')\\n\", \"        parser_objset = subcommands.add_parser('objectset', parents=[pool_parser], aliases=['objset'],\\n\", '        parser_objset.set_defaults(func=self.objset)\\n', \"        parser_objset.add_argument('--dataset', '-d',\\n\", \"        parser_objset.add_argument('--self', action='store_true',\\n\", \"        parser_objset.add_argument('--dump', metavar='FILE',\\n\", \"        parser_objset.add_argument('--execute', '-e', metavar='CODE',\\n\", '        objset_selector_group = parser_objset.add_mutually_exclusive_group(required=True)\\n', \"        objset_selector_group.add_argument('--all', '-a', action='store_true',\\n\", \"        objset_selector_group.add_argument('--everything', action='store_true',\\n\", \"        objset_selector_group.add_argument('object', type=int, nargs='?', help='Object to display.')\\n\", '        objset_exclusive_display = parser_objset.add_mutually_exclusive_group()\\n', \"        objset_exclusive_display.add_argument('--parse', '-P', action='store_true',\\n\", \"        objset_exclusive_display.add_argument('--dnode', '-D', action='store_true',\\n\", \"        parser_nvparse = subcommands.add_parser('nvparse', help='Parse an NVList from a file. WIP')\\n\", '        parser_nvparse.set_defaults(func=self.nvparse)\\n', \"        parser_nvparse.add_argument('file', help='The file to parse.')\\n\", \"        parser_label = subcommands.add_parser('label', parents=[pool_parser], help='View disk labels.')\\n\", '        parser_label.set_defaults(func=self.label)\\n', \"        parser_label.add_argument('label', type=int, default=0, nargs='?', choices=(0, 1, 2, 3),\\n\", \"        parser_label.add_argument('--uberblocks', '-u', action='store_true')\\n\", \"        parser_label.add_argument('--all', action='store_true')\\n\", \"        parser_dva = subcommands.add_parser('dva', parents=[pool_parser], help='Read arbitrary blocks.')\\n\", '        parser_dva.set_defaults(func=self.read_dva)\\n', \"        parser_dva.add_argument('dva', help='The DVA (data virtual address) to read.')\\n\", \"        parser_dva.add_argument('--dump', metavar='FILE', help='Write the data to FILE.')\\n\", \"        parser_fuse = subcommands.add_parser('fuse', parents=[pool_parser],\\n\", '        if zfuse:\\n', '            parser_fuse.set_defaults(func=self.mount_fuse)\\n', \"        parser_fuse.add_argument('mountpoint', help='Set the mountpoint')\\n\", \"        parser_fuse.epilog = '''This requires the `fusepy` module, which in turn depends on libfuse.\\n\", '        for level in VERBOSE_LEVELS:\\n', '            levelname = logging.getLevelName(level).lower()\\n', '            modules = getattr(args, levelname)\\n', '            for mod in modules:\\n', '                logging.getLogger(mod).setLevel(level)\\n', '        args = self.parser.parse_args(*a, **kw)\\n', '        level = VERBOSE_LEVELS[args.verbose]\\n', \"        logging.basicConfig(level=level, format='%(asctime)s %(name)-12s %(levelname)-8s %(message)s')\\n\", '        if level != logging.CRITICAL:\\n', \"            logger.log(level, 'this is the most verbose log level for this run')\\n\", '        self.setup_module_logs(args)\\n', '        if args.pool:\\n', '            self.pool = self.load_pool(args)\\n', '        if args.pool and args.vdev_id == None:\\n', '            args.vdev_id = int(self.pool.first_vdev().id)\\n', '        args.func(args)\\n', '        devices = [filedev.FileDev(path, args.label, args.txg) for path in args.pool]\\n', '        try_config = set(args.try_config).union(*TRY_LEVELS[:args.try_level+1])\\n', \"        logger.info('extra options: {}'.format(try_config))\\n\", '        pool = Pool(devices, try_config=try_config)\\n', '        return pool\\n', '        target = self.pool.open(args.path)\\n', '        if isinstance(target, zfs.posix.File):\\n', '            print(args.path)\\n', '            for file in sorted(target.keys()):\\n', '                print(file)\\n', '        sys.stdout.buffer.write(self.pool.read_file(args.path))\\n', '        if args.parse:\\n', '        elif args.dnode:\\n', '        elif args.dump:\\n', \"            f = open(args.dump, 'wb')\\n\", '            f.write(self.pool.read_dnode(obj))\\n', '            f.close()\\n', '        if args.execute:\\n', '                parsed = os.parse_dnode(obj)\\n', '                parsed = None\\n', \"                exec(args.execute, globals(), {'o':obj, 'os':os, 'p':parsed})\\n\", \"                logger.exception('execution failed on object {}'.format(obj.node_type))\\n\", '        if args.dataset:\\n', '            ds = self.pool.dataset_for(args.dataset)\\n', '            os = ds.objectset\\n', '            os = self.pool.objset_for_vdev(args.vdev_id)\\n', '        if args.self:\\n', '            print(os.raw_objectset)\\n', '            if args.dump:\\n', \"                f = open(args.dump, 'wb')\\n\", '                print(len(os.objset))\\n', '                f.write(os.objset)\\n', '                f.close()\\n', '        if not args.object:\\n', '            args.all = True\\n', '        if args.all:\\n', '            for i, obj in enumerate(os):\\n', '                if obj.node_type != ObjectType.NONE or args.everything:\\n', '                    if args.parse:\\n', \"                    print(i, end=' ')\\n\", '                    self.show_object(args, os, obj)\\n', '        elif args.object:\\n', '            obj = os.get_dnode(args.object)\\n', '            self.show_object(args, os, obj)\\n', \"        source = open(args.file, 'rb')\\n\", '        data = source.read()\\n', '        nv = NVList(data)\\n', '        pprint(nv.unpack_nvlist())\\n', '        vdev = self.pool.vdevs[args.vdev_id]\\n', '        label = vdev.best_label\\n', '        if args.label is not None:\\n', '            label = vdev.labels[args.label]\\n', '            pprint(label[0])\\n', '        if args.uberblocks:\\n', '            for i, uber in enumerate(label[1]):\\n', '                if args.all or uber.valid():\\n', '                    print(i, uber)\\n', '        zfuse.mount(self.pool, args.mountpoint)\\n', '        dva = args.dva\\n']",
  "context": "ectset)\n            if args.dump:\n                f = open(args.dump, 'wb')\n                print(len(os.objset))\n            "
 },
 "11": {
  "name": "source",
  "type": "open",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/explore.py",
  "lineno": "248",
  "column": "8",
  "slicing": "['    zfuse = None\\n', 'VERBOSE_LEVELS = [\\n', 'TRY_LEVELS = [\\n', 'logger = logging.getLogger(__name__)\\n', \"        self.parser = parser = argparse.ArgumentParser(prog='explore')\\n\", '        subcommands = parser.add_subparsers(\\n', '        parser.set_defaults(func=lambda a: parser.print_help(), pool=None)\\n', '        pool_parser = argparse.ArgumentParser(add_help=False)\\n', \"        pool_parser.add_argument('--pool', '-p', action='append', required=True)\\n\", \"        pool_parser.add_argument('--vdev-id', type=int, default=None)\\n\", \"        pool_parser.add_argument('--label', '-L', type=int, default=None)\\n\", \"        pool_parser.add_argument('--txg', '-T', type=int, default=None)\\n\", \"        log_opts = parser.add_argument_group('logging options',\\n\", \"        log_opts.add_argument('--verbose', '-v', action='count', default=0,\\n\", \"            help='Increase verbosity. Add more instances (e.g., -vvv) to be even more verbose.'\\n\", '        for level in map(logging.getLevelName, VERBOSE_LEVELS):\\n', '            level = level.lower()\\n', \"            log_opts.add_argument(f'--{level}', metavar='MODULE', action='append', default=[],\\n\", '                help=f\"Set the log level for MODULE to {level}.\"\\n', \"        parser.add_argument('--try', '-t', dest='try_level', action='count',\\n\", \"        try_opts = parser.add_argument_group('Try harder', 'extra options for reading data.')\\n\", '        parser.set_defaults(try_config=[])\\n', '        for name, value in TryConfig.__members__.items():\\n', \"            arg_name = '--try-'+name.replace('_', '-')\\n\", \"            try_opts.add_argument(arg_name, dest='try_config', action='append_const', const=value)\\n\", \"        parser_ls = subcommands.add_parser('ls', parents=[pool_parser], help='list files')\\n\", '        parser_ls.set_defaults(func=self.list_cmd)\\n', \"        parser_ls.add_argument('path', default='/', nargs='?', help='List the items in PATH.')\\n\", \"        parser_cat = subcommands.add_parser('cat', parents=[pool_parser], help='cat file')\\n\", '        parser_cat.set_defaults(func=self.cat)\\n', \"        parser_cat.add_argument('path', help='Output the contents of PATH.')\\n\", \"        parser_objset = subcommands.add_parser('objectset', parents=[pool_parser], aliases=['objset'],\\n\", '        parser_objset.set_defaults(func=self.objset)\\n', \"        parser_objset.add_argument('--dataset', '-d',\\n\", \"        parser_objset.add_argument('--self', action='store_true',\\n\", \"        parser_objset.add_argument('--dump', metavar='FILE',\\n\", \"        parser_objset.add_argument('--execute', '-e', metavar='CODE',\\n\", '        objset_selector_group = parser_objset.add_mutually_exclusive_group(required=True)\\n', \"        objset_selector_group.add_argument('--all', '-a', action='store_true',\\n\", \"        objset_selector_group.add_argument('--everything', action='store_true',\\n\", \"        objset_selector_group.add_argument('object', type=int, nargs='?', help='Object to display.')\\n\", '        objset_exclusive_display = parser_objset.add_mutually_exclusive_group()\\n', \"        objset_exclusive_display.add_argument('--parse', '-P', action='store_true',\\n\", \"        objset_exclusive_display.add_argument('--dnode', '-D', action='store_true',\\n\", \"        parser_nvparse = subcommands.add_parser('nvparse', help='Parse an NVList from a file. WIP')\\n\", '        parser_nvparse.set_defaults(func=self.nvparse)\\n', \"        parser_nvparse.add_argument('file', help='The file to parse.')\\n\", \"        parser_label = subcommands.add_parser('label', parents=[pool_parser], help='View disk labels.')\\n\", '        parser_label.set_defaults(func=self.label)\\n', \"        parser_label.add_argument('label', type=int, default=0, nargs='?', choices=(0, 1, 2, 3),\\n\", \"        parser_label.add_argument('--uberblocks', '-u', action='store_true')\\n\", \"        parser_label.add_argument('--all', action='store_true')\\n\", \"        parser_dva = subcommands.add_parser('dva', parents=[pool_parser], help='Read arbitrary blocks.')\\n\", '        parser_dva.set_defaults(func=self.read_dva)\\n', \"        parser_dva.add_argument('dva', help='The DVA (data virtual address) to read.')\\n\", \"        parser_dva.add_argument('--dump', metavar='FILE', help='Write the data to FILE.')\\n\", \"        parser_fuse = subcommands.add_parser('fuse', parents=[pool_parser],\\n\", '        if zfuse:\\n', '            parser_fuse.set_defaults(func=self.mount_fuse)\\n', \"        parser_fuse.add_argument('mountpoint', help='Set the mountpoint')\\n\", \"        parser_fuse.epilog = '''This requires the `fusepy` module, which in turn depends on libfuse.\\n\", '        for level in VERBOSE_LEVELS:\\n', '            levelname = logging.getLevelName(level).lower()\\n', '            modules = getattr(args, levelname)\\n', '            for mod in modules:\\n', '                logging.getLogger(mod).setLevel(level)\\n', '        args = self.parser.parse_args(*a, **kw)\\n', '        level = VERBOSE_LEVELS[args.verbose]\\n', \"        logging.basicConfig(level=level, format='%(asctime)s %(name)-12s %(levelname)-8s %(message)s')\\n\", '        if level != logging.CRITICAL:\\n', \"            logger.log(level, 'this is the most verbose log level for this run')\\n\", '        self.setup_module_logs(args)\\n', '        if args.pool:\\n', '            self.pool = self.load_pool(args)\\n', '        if args.pool and args.vdev_id == None:\\n', '            args.vdev_id = int(self.pool.first_vdev().id)\\n', '        args.func(args)\\n', '        devices = [filedev.FileDev(path, args.label, args.txg) for path in args.pool]\\n', '        try_config = set(args.try_config).union(*TRY_LEVELS[:args.try_level+1])\\n', \"        logger.info('extra options: {}'.format(try_config))\\n\", '        pool = Pool(devices, try_config=try_config)\\n', '        return pool\\n', '        target = self.pool.open(args.path)\\n', '        if isinstance(target, zfs.posix.File):\\n', '            print(args.path)\\n', '            for file in sorted(target.keys()):\\n', '                print(file)\\n', '        sys.stdout.buffer.write(self.pool.read_file(args.path))\\n', '        if args.parse:\\n', '        elif args.dnode:\\n', '        elif args.dump:\\n', \"            f = open(args.dump, 'wb')\\n\", '            f.write(self.pool.read_dnode(obj))\\n', '            f.close()\\n', '        if args.execute:\\n', '                parsed = os.parse_dnode(obj)\\n', '                parsed = None\\n', \"                exec(args.execute, globals(), {'o':obj, 'os':os, 'p':parsed})\\n\", \"                logger.exception('execution failed on object {}'.format(obj.node_type))\\n\", '        if args.dataset:\\n', '            ds = self.pool.dataset_for(args.dataset)\\n', '            os = ds.objectset\\n', '            os = self.pool.objset_for_vdev(args.vdev_id)\\n', '        if args.self:\\n', '            print(os.raw_objectset)\\n', '            if args.dump:\\n', \"                f = open(args.dump, 'wb')\\n\", '                print(len(os.objset))\\n', '                f.write(os.objset)\\n', '                f.close()\\n', '        if not args.object:\\n', '            args.all = True\\n', '        if args.all:\\n', '            for i, obj in enumerate(os):\\n', '                if obj.node_type != ObjectType.NONE or args.everything:\\n', '                    if args.parse:\\n', \"                    print(i, end=' ')\\n\", '                    self.show_object(args, os, obj)\\n', '        elif args.object:\\n', '            obj = os.get_dnode(args.object)\\n', '            self.show_object(args, os, obj)\\n', \"        source = open(args.file, 'rb')\\n\", '        data = source.read()\\n', '        nv = NVList(data)\\n', '        pprint(nv.unpack_nvlist())\\n', '        vdev = self.pool.vdevs[args.vdev_id]\\n', '        label = vdev.best_label\\n', '        if args.label is not None:\\n', '            label = vdev.labels[args.label]\\n', '            pprint(label[0])\\n', '        if args.uberblocks:\\n', '            for i, uber in enumerate(label[1]):\\n', '                if args.all or uber.valid():\\n', '                    print(i, uber)\\n', '        zfuse.mount(self.pool, args.mountpoint)\\n', '        dva = args.dva\\n']",
  "context": "s, os, obj)\n\n    def nvparse(self, args):\n        source = open(args.file, 'rb')\n        data = source.read()\n        nv = NVList(d"
 },
 "12": {
  "name": "data",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "zfsp/explore.py",
  "lineno": "249",
  "column": "8",
  "slicing": "['    zfuse = None\\n', 'VERBOSE_LEVELS = [\\n', 'TRY_LEVELS = [\\n', 'logger = logging.getLogger(__name__)\\n', \"        self.parser = parser = argparse.ArgumentParser(prog='explore')\\n\", '        subcommands = parser.add_subparsers(\\n', '        parser.set_defaults(func=lambda a: parser.print_help(), pool=None)\\n', '        pool_parser = argparse.ArgumentParser(add_help=False)\\n', \"        pool_parser.add_argument('--pool', '-p', action='append', required=True)\\n\", \"        pool_parser.add_argument('--vdev-id', type=int, default=None)\\n\", \"        pool_parser.add_argument('--label', '-L', type=int, default=None)\\n\", \"        pool_parser.add_argument('--txg', '-T', type=int, default=None)\\n\", \"        log_opts = parser.add_argument_group('logging options',\\n\", \"        log_opts.add_argument('--verbose', '-v', action='count', default=0,\\n\", \"            help='Increase verbosity. Add more instances (e.g., -vvv) to be even more verbose.'\\n\", '        for level in map(logging.getLevelName, VERBOSE_LEVELS):\\n', '            level = level.lower()\\n', \"            log_opts.add_argument(f'--{level}', metavar='MODULE', action='append', default=[],\\n\", '                help=f\"Set the log level for MODULE to {level}.\"\\n', \"        parser.add_argument('--try', '-t', dest='try_level', action='count',\\n\", \"        try_opts = parser.add_argument_group('Try harder', 'extra options for reading data.')\\n\", '        parser.set_defaults(try_config=[])\\n', '        for name, value in TryConfig.__members__.items():\\n', \"            arg_name = '--try-'+name.replace('_', '-')\\n\", \"            try_opts.add_argument(arg_name, dest='try_config', action='append_const', const=value)\\n\", \"        parser_ls = subcommands.add_parser('ls', parents=[pool_parser], help='list files')\\n\", '        parser_ls.set_defaults(func=self.list_cmd)\\n', \"        parser_ls.add_argument('path', default='/', nargs='?', help='List the items in PATH.')\\n\", \"        parser_cat = subcommands.add_parser('cat', parents=[pool_parser], help='cat file')\\n\", '        parser_cat.set_defaults(func=self.cat)\\n', \"        parser_cat.add_argument('path', help='Output the contents of PATH.')\\n\", \"        parser_objset = subcommands.add_parser('objectset', parents=[pool_parser], aliases=['objset'],\\n\", '        parser_objset.set_defaults(func=self.objset)\\n', \"        parser_objset.add_argument('--dataset', '-d',\\n\", \"        parser_objset.add_argument('--self', action='store_true',\\n\", \"        parser_objset.add_argument('--dump', metavar='FILE',\\n\", \"        parser_objset.add_argument('--execute', '-e', metavar='CODE',\\n\", '        objset_selector_group = parser_objset.add_mutually_exclusive_group(required=True)\\n', \"        objset_selector_group.add_argument('--all', '-a', action='store_true',\\n\", \"        objset_selector_group.add_argument('--everything', action='store_true',\\n\", \"        objset_selector_group.add_argument('object', type=int, nargs='?', help='Object to display.')\\n\", '        objset_exclusive_display = parser_objset.add_mutually_exclusive_group()\\n', \"        objset_exclusive_display.add_argument('--parse', '-P', action='store_true',\\n\", \"        objset_exclusive_display.add_argument('--dnode', '-D', action='store_true',\\n\", \"        parser_nvparse = subcommands.add_parser('nvparse', help='Parse an NVList from a file. WIP')\\n\", '        parser_nvparse.set_defaults(func=self.nvparse)\\n', \"        parser_nvparse.add_argument('file', help='The file to parse.')\\n\", \"        parser_label = subcommands.add_parser('label', parents=[pool_parser], help='View disk labels.')\\n\", '        parser_label.set_defaults(func=self.label)\\n', \"        parser_label.add_argument('label', type=int, default=0, nargs='?', choices=(0, 1, 2, 3),\\n\", \"        parser_label.add_argument('--uberblocks', '-u', action='store_true')\\n\", \"        parser_label.add_argument('--all', action='store_true')\\n\", \"        parser_dva = subcommands.add_parser('dva', parents=[pool_parser], help='Read arbitrary blocks.')\\n\", '        parser_dva.set_defaults(func=self.read_dva)\\n', \"        parser_dva.add_argument('dva', help='The DVA (data virtual address) to read.')\\n\", \"        parser_dva.add_argument('--dump', metavar='FILE', help='Write the data to FILE.')\\n\", \"        parser_fuse = subcommands.add_parser('fuse', parents=[pool_parser],\\n\", '        if zfuse:\\n', '            parser_fuse.set_defaults(func=self.mount_fuse)\\n', \"        parser_fuse.add_argument('mountpoint', help='Set the mountpoint')\\n\", \"        parser_fuse.epilog = '''This requires the `fusepy` module, which in turn depends on libfuse.\\n\", '        for level in VERBOSE_LEVELS:\\n', '            levelname = logging.getLevelName(level).lower()\\n', '            modules = getattr(args, levelname)\\n', '            for mod in modules:\\n', '                logging.getLogger(mod).setLevel(level)\\n', '        args = self.parser.parse_args(*a, **kw)\\n', '        level = VERBOSE_LEVELS[args.verbose]\\n', \"        logging.basicConfig(level=level, format='%(asctime)s %(name)-12s %(levelname)-8s %(message)s')\\n\", '        if level != logging.CRITICAL:\\n', \"            logger.log(level, 'this is the most verbose log level for this run')\\n\", '        self.setup_module_logs(args)\\n', '        if args.pool:\\n', '            self.pool = self.load_pool(args)\\n', '        if args.pool and args.vdev_id == None:\\n', '            args.vdev_id = int(self.pool.first_vdev().id)\\n', '        args.func(args)\\n', '        devices = [filedev.FileDev(path, args.label, args.txg) for path in args.pool]\\n', '        try_config = set(args.try_config).union(*TRY_LEVELS[:args.try_level+1])\\n', \"        logger.info('extra options: {}'.format(try_config))\\n\", '        pool = Pool(devices, try_config=try_config)\\n', '        return pool\\n', '        target = self.pool.open(args.path)\\n', '        if isinstance(target, zfs.posix.File):\\n', '            print(args.path)\\n', '            for file in sorted(target.keys()):\\n', '                print(file)\\n', '        sys.stdout.buffer.write(self.pool.read_file(args.path))\\n', '        if args.parse:\\n', '        elif args.dnode:\\n', '        elif args.dump:\\n', \"            f = open(args.dump, 'wb')\\n\", '            f.write(self.pool.read_dnode(obj))\\n', '            f.close()\\n', '        if args.execute:\\n', '                parsed = os.parse_dnode(obj)\\n', '                parsed = None\\n', \"                exec(args.execute, globals(), {'o':obj, 'os':os, 'p':parsed})\\n\", \"                logger.exception('execution failed on object {}'.format(obj.node_type))\\n\", '        if args.dataset:\\n', '            ds = self.pool.dataset_for(args.dataset)\\n', '            os = ds.objectset\\n', '            os = self.pool.objset_for_vdev(args.vdev_id)\\n', '        if args.self:\\n', '            print(os.raw_objectset)\\n', '            if args.dump:\\n', \"                f = open(args.dump, 'wb')\\n\", '                print(len(os.objset))\\n', '                f.write(os.objset)\\n', '                f.close()\\n', '        if not args.object:\\n', '            args.all = True\\n', '        if args.all:\\n', '            for i, obj in enumerate(os):\\n', '                if obj.node_type != ObjectType.NONE or args.everything:\\n', '                    if args.parse:\\n', \"                    print(i, end=' ')\\n\", '                    self.show_object(args, os, obj)\\n', '        elif args.object:\\n', '            obj = os.get_dnode(args.object)\\n', '            self.show_object(args, os, obj)\\n', \"        source = open(args.file, 'rb')\\n\", '        data = source.read()\\n', '        nv = NVList(data)\\n', '        pprint(nv.unpack_nvlist())\\n', '        vdev = self.pool.vdevs[args.vdev_id]\\n', '        label = vdev.best_label\\n', '        if args.label is not None:\\n', '            label = vdev.labels[args.label]\\n', '            pprint(label[0])\\n', '        if args.uberblocks:\\n', '            for i, uber in enumerate(label[1]):\\n', '                if args.all or uber.valid():\\n', '                    print(i, uber)\\n', '        zfuse.mount(self.pool, args.mountpoint)\\n', '        dva = args.dva\\n']",
  "context": "):\n        source = open(args.file, 'rb')\n        data = source.read()\n        nv = NVList(data)\n        pprint(nv.unpack"
 },
 "13": {
  "name": "nv",
  "type": "nvlist.NVList",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/explore.py",
  "lineno": "250",
  "column": "8",
  "slicing": "['    zfuse = None\\n', 'VERBOSE_LEVELS = [\\n', 'TRY_LEVELS = [\\n', 'logger = logging.getLogger(__name__)\\n', \"        self.parser = parser = argparse.ArgumentParser(prog='explore')\\n\", '        subcommands = parser.add_subparsers(\\n', '        parser.set_defaults(func=lambda a: parser.print_help(), pool=None)\\n', '        pool_parser = argparse.ArgumentParser(add_help=False)\\n', \"        pool_parser.add_argument('--pool', '-p', action='append', required=True)\\n\", \"        pool_parser.add_argument('--vdev-id', type=int, default=None)\\n\", \"        pool_parser.add_argument('--label', '-L', type=int, default=None)\\n\", \"        pool_parser.add_argument('--txg', '-T', type=int, default=None)\\n\", \"        log_opts = parser.add_argument_group('logging options',\\n\", \"        log_opts.add_argument('--verbose', '-v', action='count', default=0,\\n\", \"            help='Increase verbosity. Add more instances (e.g., -vvv) to be even more verbose.'\\n\", '        for level in map(logging.getLevelName, VERBOSE_LEVELS):\\n', '            level = level.lower()\\n', \"            log_opts.add_argument(f'--{level}', metavar='MODULE', action='append', default=[],\\n\", '                help=f\"Set the log level for MODULE to {level}.\"\\n', \"        parser.add_argument('--try', '-t', dest='try_level', action='count',\\n\", \"        try_opts = parser.add_argument_group('Try harder', 'extra options for reading data.')\\n\", '        parser.set_defaults(try_config=[])\\n', '        for name, value in TryConfig.__members__.items():\\n', \"            arg_name = '--try-'+name.replace('_', '-')\\n\", \"            try_opts.add_argument(arg_name, dest='try_config', action='append_const', const=value)\\n\", \"        parser_ls = subcommands.add_parser('ls', parents=[pool_parser], help='list files')\\n\", '        parser_ls.set_defaults(func=self.list_cmd)\\n', \"        parser_ls.add_argument('path', default='/', nargs='?', help='List the items in PATH.')\\n\", \"        parser_cat = subcommands.add_parser('cat', parents=[pool_parser], help='cat file')\\n\", '        parser_cat.set_defaults(func=self.cat)\\n', \"        parser_cat.add_argument('path', help='Output the contents of PATH.')\\n\", \"        parser_objset = subcommands.add_parser('objectset', parents=[pool_parser], aliases=['objset'],\\n\", '        parser_objset.set_defaults(func=self.objset)\\n', \"        parser_objset.add_argument('--dataset', '-d',\\n\", \"        parser_objset.add_argument('--self', action='store_true',\\n\", \"        parser_objset.add_argument('--dump', metavar='FILE',\\n\", \"        parser_objset.add_argument('--execute', '-e', metavar='CODE',\\n\", '        objset_selector_group = parser_objset.add_mutually_exclusive_group(required=True)\\n', \"        objset_selector_group.add_argument('--all', '-a', action='store_true',\\n\", \"        objset_selector_group.add_argument('--everything', action='store_true',\\n\", \"        objset_selector_group.add_argument('object', type=int, nargs='?', help='Object to display.')\\n\", '        objset_exclusive_display = parser_objset.add_mutually_exclusive_group()\\n', \"        objset_exclusive_display.add_argument('--parse', '-P', action='store_true',\\n\", \"        objset_exclusive_display.add_argument('--dnode', '-D', action='store_true',\\n\", \"        parser_nvparse = subcommands.add_parser('nvparse', help='Parse an NVList from a file. WIP')\\n\", '        parser_nvparse.set_defaults(func=self.nvparse)\\n', \"        parser_nvparse.add_argument('file', help='The file to parse.')\\n\", \"        parser_label = subcommands.add_parser('label', parents=[pool_parser], help='View disk labels.')\\n\", '        parser_label.set_defaults(func=self.label)\\n', \"        parser_label.add_argument('label', type=int, default=0, nargs='?', choices=(0, 1, 2, 3),\\n\", \"        parser_label.add_argument('--uberblocks', '-u', action='store_true')\\n\", \"        parser_label.add_argument('--all', action='store_true')\\n\", \"        parser_dva = subcommands.add_parser('dva', parents=[pool_parser], help='Read arbitrary blocks.')\\n\", '        parser_dva.set_defaults(func=self.read_dva)\\n', \"        parser_dva.add_argument('dva', help='The DVA (data virtual address) to read.')\\n\", \"        parser_dva.add_argument('--dump', metavar='FILE', help='Write the data to FILE.')\\n\", \"        parser_fuse = subcommands.add_parser('fuse', parents=[pool_parser],\\n\", '        if zfuse:\\n', '            parser_fuse.set_defaults(func=self.mount_fuse)\\n', \"        parser_fuse.add_argument('mountpoint', help='Set the mountpoint')\\n\", \"        parser_fuse.epilog = '''This requires the `fusepy` module, which in turn depends on libfuse.\\n\", '        for level in VERBOSE_LEVELS:\\n', '            levelname = logging.getLevelName(level).lower()\\n', '            modules = getattr(args, levelname)\\n', '            for mod in modules:\\n', '                logging.getLogger(mod).setLevel(level)\\n', '        args = self.parser.parse_args(*a, **kw)\\n', '        level = VERBOSE_LEVELS[args.verbose]\\n', \"        logging.basicConfig(level=level, format='%(asctime)s %(name)-12s %(levelname)-8s %(message)s')\\n\", '        if level != logging.CRITICAL:\\n', \"            logger.log(level, 'this is the most verbose log level for this run')\\n\", '        self.setup_module_logs(args)\\n', '        if args.pool:\\n', '            self.pool = self.load_pool(args)\\n', '        if args.pool and args.vdev_id == None:\\n', '            args.vdev_id = int(self.pool.first_vdev().id)\\n', '        args.func(args)\\n', '        devices = [filedev.FileDev(path, args.label, args.txg) for path in args.pool]\\n', '        try_config = set(args.try_config).union(*TRY_LEVELS[:args.try_level+1])\\n', \"        logger.info('extra options: {}'.format(try_config))\\n\", '        pool = Pool(devices, try_config=try_config)\\n', '        return pool\\n', '        target = self.pool.open(args.path)\\n', '        if isinstance(target, zfs.posix.File):\\n', '            print(args.path)\\n', '            for file in sorted(target.keys()):\\n', '                print(file)\\n', '        sys.stdout.buffer.write(self.pool.read_file(args.path))\\n', '        if args.parse:\\n', '        elif args.dnode:\\n', '        elif args.dump:\\n', \"            f = open(args.dump, 'wb')\\n\", '            f.write(self.pool.read_dnode(obj))\\n', '            f.close()\\n', '        if args.execute:\\n', '                parsed = os.parse_dnode(obj)\\n', '                parsed = None\\n', \"                exec(args.execute, globals(), {'o':obj, 'os':os, 'p':parsed})\\n\", \"                logger.exception('execution failed on object {}'.format(obj.node_type))\\n\", '        if args.dataset:\\n', '            ds = self.pool.dataset_for(args.dataset)\\n', '            os = ds.objectset\\n', '            os = self.pool.objset_for_vdev(args.vdev_id)\\n', '        if args.self:\\n', '            print(os.raw_objectset)\\n', '            if args.dump:\\n', \"                f = open(args.dump, 'wb')\\n\", '                print(len(os.objset))\\n', '                f.write(os.objset)\\n', '                f.close()\\n', '        if not args.object:\\n', '            args.all = True\\n', '        if args.all:\\n', '            for i, obj in enumerate(os):\\n', '                if obj.node_type != ObjectType.NONE or args.everything:\\n', '                    if args.parse:\\n', \"                    print(i, end=' ')\\n\", '                    self.show_object(args, os, obj)\\n', '        elif args.object:\\n', '            obj = os.get_dnode(args.object)\\n', '            self.show_object(args, os, obj)\\n', \"        source = open(args.file, 'rb')\\n\", '        data = source.read()\\n', '        nv = NVList(data)\\n', '        pprint(nv.unpack_nvlist())\\n', '        vdev = self.pool.vdevs[args.vdev_id]\\n', '        label = vdev.best_label\\n', '        if args.label is not None:\\n', '            label = vdev.labels[args.label]\\n', '            pprint(label[0])\\n', '        if args.uberblocks:\\n', '            for i, uber in enumerate(label[1]):\\n', '                if args.all or uber.valid():\\n', '                    print(i, uber)\\n', '        zfuse.mount(self.pool, args.mountpoint)\\n', '        dva = args.dva\\n']",
  "context": ".file, 'rb')\n        data = source.read()\n        nv = NVList(data)\n        pprint(nv.unpack_nvlist())\n\n    def label("
 },
 "14": {
  "name": "vdev",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/explore.py",
  "lineno": "254",
  "column": "8",
  "slicing": "['    zfuse = None\\n', 'VERBOSE_LEVELS = [\\n', 'TRY_LEVELS = [\\n', 'logger = logging.getLogger(__name__)\\n', \"        self.parser = parser = argparse.ArgumentParser(prog='explore')\\n\", '        subcommands = parser.add_subparsers(\\n', '        parser.set_defaults(func=lambda a: parser.print_help(), pool=None)\\n', '        pool_parser = argparse.ArgumentParser(add_help=False)\\n', \"        pool_parser.add_argument('--pool', '-p', action='append', required=True)\\n\", \"        pool_parser.add_argument('--vdev-id', type=int, default=None)\\n\", \"        pool_parser.add_argument('--label', '-L', type=int, default=None)\\n\", \"        pool_parser.add_argument('--txg', '-T', type=int, default=None)\\n\", \"        log_opts = parser.add_argument_group('logging options',\\n\", \"        log_opts.add_argument('--verbose', '-v', action='count', default=0,\\n\", \"            help='Increase verbosity. Add more instances (e.g., -vvv) to be even more verbose.'\\n\", '        for level in map(logging.getLevelName, VERBOSE_LEVELS):\\n', '            level = level.lower()\\n', \"            log_opts.add_argument(f'--{level}', metavar='MODULE', action='append', default=[],\\n\", '                help=f\"Set the log level for MODULE to {level}.\"\\n', \"        parser.add_argument('--try', '-t', dest='try_level', action='count',\\n\", \"        try_opts = parser.add_argument_group('Try harder', 'extra options for reading data.')\\n\", '        parser.set_defaults(try_config=[])\\n', '        for name, value in TryConfig.__members__.items():\\n', \"            arg_name = '--try-'+name.replace('_', '-')\\n\", \"            try_opts.add_argument(arg_name, dest='try_config', action='append_const', const=value)\\n\", \"        parser_ls = subcommands.add_parser('ls', parents=[pool_parser], help='list files')\\n\", '        parser_ls.set_defaults(func=self.list_cmd)\\n', \"        parser_ls.add_argument('path', default='/', nargs='?', help='List the items in PATH.')\\n\", \"        parser_cat = subcommands.add_parser('cat', parents=[pool_parser], help='cat file')\\n\", '        parser_cat.set_defaults(func=self.cat)\\n', \"        parser_cat.add_argument('path', help='Output the contents of PATH.')\\n\", \"        parser_objset = subcommands.add_parser('objectset', parents=[pool_parser], aliases=['objset'],\\n\", '        parser_objset.set_defaults(func=self.objset)\\n', \"        parser_objset.add_argument('--dataset', '-d',\\n\", \"        parser_objset.add_argument('--self', action='store_true',\\n\", \"        parser_objset.add_argument('--dump', metavar='FILE',\\n\", \"        parser_objset.add_argument('--execute', '-e', metavar='CODE',\\n\", '        objset_selector_group = parser_objset.add_mutually_exclusive_group(required=True)\\n', \"        objset_selector_group.add_argument('--all', '-a', action='store_true',\\n\", \"        objset_selector_group.add_argument('--everything', action='store_true',\\n\", \"        objset_selector_group.add_argument('object', type=int, nargs='?', help='Object to display.')\\n\", '        objset_exclusive_display = parser_objset.add_mutually_exclusive_group()\\n', \"        objset_exclusive_display.add_argument('--parse', '-P', action='store_true',\\n\", \"        objset_exclusive_display.add_argument('--dnode', '-D', action='store_true',\\n\", \"        parser_nvparse = subcommands.add_parser('nvparse', help='Parse an NVList from a file. WIP')\\n\", '        parser_nvparse.set_defaults(func=self.nvparse)\\n', \"        parser_nvparse.add_argument('file', help='The file to parse.')\\n\", \"        parser_label = subcommands.add_parser('label', parents=[pool_parser], help='View disk labels.')\\n\", '        parser_label.set_defaults(func=self.label)\\n', \"        parser_label.add_argument('label', type=int, default=0, nargs='?', choices=(0, 1, 2, 3),\\n\", \"        parser_label.add_argument('--uberblocks', '-u', action='store_true')\\n\", \"        parser_label.add_argument('--all', action='store_true')\\n\", \"        parser_dva = subcommands.add_parser('dva', parents=[pool_parser], help='Read arbitrary blocks.')\\n\", '        parser_dva.set_defaults(func=self.read_dva)\\n', \"        parser_dva.add_argument('dva', help='The DVA (data virtual address) to read.')\\n\", \"        parser_dva.add_argument('--dump', metavar='FILE', help='Write the data to FILE.')\\n\", \"        parser_fuse = subcommands.add_parser('fuse', parents=[pool_parser],\\n\", '        if zfuse:\\n', '            parser_fuse.set_defaults(func=self.mount_fuse)\\n', \"        parser_fuse.add_argument('mountpoint', help='Set the mountpoint')\\n\", \"        parser_fuse.epilog = '''This requires the `fusepy` module, which in turn depends on libfuse.\\n\", '        for level in VERBOSE_LEVELS:\\n', '            levelname = logging.getLevelName(level).lower()\\n', '            modules = getattr(args, levelname)\\n', '            for mod in modules:\\n', '                logging.getLogger(mod).setLevel(level)\\n', '        args = self.parser.parse_args(*a, **kw)\\n', '        level = VERBOSE_LEVELS[args.verbose]\\n', \"        logging.basicConfig(level=level, format='%(asctime)s %(name)-12s %(levelname)-8s %(message)s')\\n\", '        if level != logging.CRITICAL:\\n', \"            logger.log(level, 'this is the most verbose log level for this run')\\n\", '        self.setup_module_logs(args)\\n', '        if args.pool:\\n', '            self.pool = self.load_pool(args)\\n', '        if args.pool and args.vdev_id == None:\\n', '            args.vdev_id = int(self.pool.first_vdev().id)\\n', '        args.func(args)\\n', '        devices = [filedev.FileDev(path, args.label, args.txg) for path in args.pool]\\n', '        try_config = set(args.try_config).union(*TRY_LEVELS[:args.try_level+1])\\n', \"        logger.info('extra options: {}'.format(try_config))\\n\", '        pool = Pool(devices, try_config=try_config)\\n', '        return pool\\n', '        target = self.pool.open(args.path)\\n', '        if isinstance(target, zfs.posix.File):\\n', '            print(args.path)\\n', '            for file in sorted(target.keys()):\\n', '                print(file)\\n', '        sys.stdout.buffer.write(self.pool.read_file(args.path))\\n', '        if args.parse:\\n', '        elif args.dnode:\\n', '        elif args.dump:\\n', \"            f = open(args.dump, 'wb')\\n\", '            f.write(self.pool.read_dnode(obj))\\n', '            f.close()\\n', '        if args.execute:\\n', '                parsed = os.parse_dnode(obj)\\n', '                parsed = None\\n', \"                exec(args.execute, globals(), {'o':obj, 'os':os, 'p':parsed})\\n\", \"                logger.exception('execution failed on object {}'.format(obj.node_type))\\n\", '        if args.dataset:\\n', '            ds = self.pool.dataset_for(args.dataset)\\n', '            os = ds.objectset\\n', '            os = self.pool.objset_for_vdev(args.vdev_id)\\n', '        if args.self:\\n', '            print(os.raw_objectset)\\n', '            if args.dump:\\n', \"                f = open(args.dump, 'wb')\\n\", '                print(len(os.objset))\\n', '                f.write(os.objset)\\n', '                f.close()\\n', '        if not args.object:\\n', '            args.all = True\\n', '        if args.all:\\n', '            for i, obj in enumerate(os):\\n', '                if obj.node_type != ObjectType.NONE or args.everything:\\n', '                    if args.parse:\\n', \"                    print(i, end=' ')\\n\", '                    self.show_object(args, os, obj)\\n', '        elif args.object:\\n', '            obj = os.get_dnode(args.object)\\n', '            self.show_object(args, os, obj)\\n', \"        source = open(args.file, 'rb')\\n\", '        data = source.read()\\n', '        nv = NVList(data)\\n', '        pprint(nv.unpack_nvlist())\\n', '        vdev = self.pool.vdevs[args.vdev_id]\\n', '        label = vdev.best_label\\n', '        if args.label is not None:\\n', '            label = vdev.labels[args.label]\\n', '            pprint(label[0])\\n', '        if args.uberblocks:\\n', '            for i, uber in enumerate(label[1]):\\n', '                if args.all or uber.valid():\\n', '                    print(i, uber)\\n', '        zfuse.mount(self.pool, args.mountpoint)\\n', '        dva = args.dva\\n']",
  "context": "ack_nvlist())\n\n    def label(self, args):\n        vdev = self.pool.vdevs[args.vdev_id]\n        label = vdev.best_label\n        if args.la"
 },
 "15": {
  "name": "label",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/explore.py",
  "lineno": "257",
  "column": "12",
  "slicing": "['    zfuse = None\\n', 'VERBOSE_LEVELS = [\\n', 'TRY_LEVELS = [\\n', 'logger = logging.getLogger(__name__)\\n', \"        self.parser = parser = argparse.ArgumentParser(prog='explore')\\n\", '        subcommands = parser.add_subparsers(\\n', '        parser.set_defaults(func=lambda a: parser.print_help(), pool=None)\\n', '        pool_parser = argparse.ArgumentParser(add_help=False)\\n', \"        pool_parser.add_argument('--pool', '-p', action='append', required=True)\\n\", \"        pool_parser.add_argument('--vdev-id', type=int, default=None)\\n\", \"        pool_parser.add_argument('--label', '-L', type=int, default=None)\\n\", \"        pool_parser.add_argument('--txg', '-T', type=int, default=None)\\n\", \"        log_opts = parser.add_argument_group('logging options',\\n\", \"        log_opts.add_argument('--verbose', '-v', action='count', default=0,\\n\", \"            help='Increase verbosity. Add more instances (e.g., -vvv) to be even more verbose.'\\n\", '        for level in map(logging.getLevelName, VERBOSE_LEVELS):\\n', '            level = level.lower()\\n', \"            log_opts.add_argument(f'--{level}', metavar='MODULE', action='append', default=[],\\n\", '                help=f\"Set the log level for MODULE to {level}.\"\\n', \"        parser.add_argument('--try', '-t', dest='try_level', action='count',\\n\", \"        try_opts = parser.add_argument_group('Try harder', 'extra options for reading data.')\\n\", '        parser.set_defaults(try_config=[])\\n', '        for name, value in TryConfig.__members__.items():\\n', \"            arg_name = '--try-'+name.replace('_', '-')\\n\", \"            try_opts.add_argument(arg_name, dest='try_config', action='append_const', const=value)\\n\", \"        parser_ls = subcommands.add_parser('ls', parents=[pool_parser], help='list files')\\n\", '        parser_ls.set_defaults(func=self.list_cmd)\\n', \"        parser_ls.add_argument('path', default='/', nargs='?', help='List the items in PATH.')\\n\", \"        parser_cat = subcommands.add_parser('cat', parents=[pool_parser], help='cat file')\\n\", '        parser_cat.set_defaults(func=self.cat)\\n', \"        parser_cat.add_argument('path', help='Output the contents of PATH.')\\n\", \"        parser_objset = subcommands.add_parser('objectset', parents=[pool_parser], aliases=['objset'],\\n\", '        parser_objset.set_defaults(func=self.objset)\\n', \"        parser_objset.add_argument('--dataset', '-d',\\n\", \"        parser_objset.add_argument('--self', action='store_true',\\n\", \"        parser_objset.add_argument('--dump', metavar='FILE',\\n\", \"        parser_objset.add_argument('--execute', '-e', metavar='CODE',\\n\", '        objset_selector_group = parser_objset.add_mutually_exclusive_group(required=True)\\n', \"        objset_selector_group.add_argument('--all', '-a', action='store_true',\\n\", \"        objset_selector_group.add_argument('--everything', action='store_true',\\n\", \"        objset_selector_group.add_argument('object', type=int, nargs='?', help='Object to display.')\\n\", '        objset_exclusive_display = parser_objset.add_mutually_exclusive_group()\\n', \"        objset_exclusive_display.add_argument('--parse', '-P', action='store_true',\\n\", \"        objset_exclusive_display.add_argument('--dnode', '-D', action='store_true',\\n\", \"        parser_nvparse = subcommands.add_parser('nvparse', help='Parse an NVList from a file. WIP')\\n\", '        parser_nvparse.set_defaults(func=self.nvparse)\\n', \"        parser_nvparse.add_argument('file', help='The file to parse.')\\n\", \"        parser_label = subcommands.add_parser('label', parents=[pool_parser], help='View disk labels.')\\n\", '        parser_label.set_defaults(func=self.label)\\n', \"        parser_label.add_argument('label', type=int, default=0, nargs='?', choices=(0, 1, 2, 3),\\n\", \"        parser_label.add_argument('--uberblocks', '-u', action='store_true')\\n\", \"        parser_label.add_argument('--all', action='store_true')\\n\", \"        parser_dva = subcommands.add_parser('dva', parents=[pool_parser], help='Read arbitrary blocks.')\\n\", '        parser_dva.set_defaults(func=self.read_dva)\\n', \"        parser_dva.add_argument('dva', help='The DVA (data virtual address) to read.')\\n\", \"        parser_dva.add_argument('--dump', metavar='FILE', help='Write the data to FILE.')\\n\", \"        parser_fuse = subcommands.add_parser('fuse', parents=[pool_parser],\\n\", '        if zfuse:\\n', '            parser_fuse.set_defaults(func=self.mount_fuse)\\n', \"        parser_fuse.add_argument('mountpoint', help='Set the mountpoint')\\n\", \"        parser_fuse.epilog = '''This requires the `fusepy` module, which in turn depends on libfuse.\\n\", '        for level in VERBOSE_LEVELS:\\n', '            levelname = logging.getLevelName(level).lower()\\n', '            modules = getattr(args, levelname)\\n', '            for mod in modules:\\n', '                logging.getLogger(mod).setLevel(level)\\n', '        args = self.parser.parse_args(*a, **kw)\\n', '        level = VERBOSE_LEVELS[args.verbose]\\n', \"        logging.basicConfig(level=level, format='%(asctime)s %(name)-12s %(levelname)-8s %(message)s')\\n\", '        if level != logging.CRITICAL:\\n', \"            logger.log(level, 'this is the most verbose log level for this run')\\n\", '        self.setup_module_logs(args)\\n', '        if args.pool:\\n', '            self.pool = self.load_pool(args)\\n', '        if args.pool and args.vdev_id == None:\\n', '            args.vdev_id = int(self.pool.first_vdev().id)\\n', '        args.func(args)\\n', '        devices = [filedev.FileDev(path, args.label, args.txg) for path in args.pool]\\n', '        try_config = set(args.try_config).union(*TRY_LEVELS[:args.try_level+1])\\n', \"        logger.info('extra options: {}'.format(try_config))\\n\", '        pool = Pool(devices, try_config=try_config)\\n', '        return pool\\n', '        target = self.pool.open(args.path)\\n', '        if isinstance(target, zfs.posix.File):\\n', '            print(args.path)\\n', '            for file in sorted(target.keys()):\\n', '                print(file)\\n', '        sys.stdout.buffer.write(self.pool.read_file(args.path))\\n', '        if args.parse:\\n', '        elif args.dnode:\\n', '        elif args.dump:\\n', \"            f = open(args.dump, 'wb')\\n\", '            f.write(self.pool.read_dnode(obj))\\n', '            f.close()\\n', '        if args.execute:\\n', '                parsed = os.parse_dnode(obj)\\n', '                parsed = None\\n', \"                exec(args.execute, globals(), {'o':obj, 'os':os, 'p':parsed})\\n\", \"                logger.exception('execution failed on object {}'.format(obj.node_type))\\n\", '        if args.dataset:\\n', '            ds = self.pool.dataset_for(args.dataset)\\n', '            os = ds.objectset\\n', '            os = self.pool.objset_for_vdev(args.vdev_id)\\n', '        if args.self:\\n', '            print(os.raw_objectset)\\n', '            if args.dump:\\n', \"                f = open(args.dump, 'wb')\\n\", '                print(len(os.objset))\\n', '                f.write(os.objset)\\n', '                f.close()\\n', '        if not args.object:\\n', '            args.all = True\\n', '        if args.all:\\n', '            for i, obj in enumerate(os):\\n', '                if obj.node_type != ObjectType.NONE or args.everything:\\n', '                    if args.parse:\\n', \"                    print(i, end=' ')\\n\", '                    self.show_object(args, os, obj)\\n', '        elif args.object:\\n', '            obj = os.get_dnode(args.object)\\n', '            self.show_object(args, os, obj)\\n', \"        source = open(args.file, 'rb')\\n\", '        data = source.read()\\n', '        nv = NVList(data)\\n', '        pprint(nv.unpack_nvlist())\\n', '        vdev = self.pool.vdevs[args.vdev_id]\\n', '        label = vdev.best_label\\n', '        if args.label is not None:\\n', '            label = vdev.labels[args.label]\\n', '            pprint(label[0])\\n', '        if args.uberblocks:\\n', '            for i, uber in enumerate(label[1]):\\n', '                if args.all or uber.valid():\\n', '                    print(i, uber)\\n', '        zfuse.mount(self.pool, args.mountpoint)\\n', '        dva = args.dva\\n']",
  "context": "el\n        if args.label is not None:\n            label = vdev.labels[args.label]\n            pprint(label[0])\n        if args.uberb"
 },
 "16": {
  "name": "px",
  "type": "PoolExplorer",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/explore.py",
  "lineno": "273",
  "column": "4",
  "slicing": "['    zfuse = None\\n', 'VERBOSE_LEVELS = [\\n', 'TRY_LEVELS = [\\n', 'logger = logging.getLogger(__name__)\\n', \"        self.parser = parser = argparse.ArgumentParser(prog='explore')\\n\", '        subcommands = parser.add_subparsers(\\n', '        parser.set_defaults(func=lambda a: parser.print_help(), pool=None)\\n', '        pool_parser = argparse.ArgumentParser(add_help=False)\\n', \"        pool_parser.add_argument('--pool', '-p', action='append', required=True)\\n\", \"        pool_parser.add_argument('--vdev-id', type=int, default=None)\\n\", \"        pool_parser.add_argument('--label', '-L', type=int, default=None)\\n\", \"        pool_parser.add_argument('--txg', '-T', type=int, default=None)\\n\", \"        log_opts = parser.add_argument_group('logging options',\\n\", \"        log_opts.add_argument('--verbose', '-v', action='count', default=0,\\n\", \"            help='Increase verbosity. Add more instances (e.g., -vvv) to be even more verbose.'\\n\", '        for level in map(logging.getLevelName, VERBOSE_LEVELS):\\n', '            level = level.lower()\\n', \"            log_opts.add_argument(f'--{level}', metavar='MODULE', action='append', default=[],\\n\", '                help=f\"Set the log level for MODULE to {level}.\"\\n', \"        parser.add_argument('--try', '-t', dest='try_level', action='count',\\n\", \"        try_opts = parser.add_argument_group('Try harder', 'extra options for reading data.')\\n\", '        parser.set_defaults(try_config=[])\\n', '        for name, value in TryConfig.__members__.items():\\n', \"            arg_name = '--try-'+name.replace('_', '-')\\n\", \"            try_opts.add_argument(arg_name, dest='try_config', action='append_const', const=value)\\n\", \"        parser_ls = subcommands.add_parser('ls', parents=[pool_parser], help='list files')\\n\", '        parser_ls.set_defaults(func=self.list_cmd)\\n', \"        parser_ls.add_argument('path', default='/', nargs='?', help='List the items in PATH.')\\n\", \"        parser_cat = subcommands.add_parser('cat', parents=[pool_parser], help='cat file')\\n\", '        parser_cat.set_defaults(func=self.cat)\\n', \"        parser_cat.add_argument('path', help='Output the contents of PATH.')\\n\", \"        parser_objset = subcommands.add_parser('objectset', parents=[pool_parser], aliases=['objset'],\\n\", '        parser_objset.set_defaults(func=self.objset)\\n', \"        parser_objset.add_argument('--dataset', '-d',\\n\", \"        parser_objset.add_argument('--self', action='store_true',\\n\", \"        parser_objset.add_argument('--dump', metavar='FILE',\\n\", \"        parser_objset.add_argument('--execute', '-e', metavar='CODE',\\n\", '        objset_selector_group = parser_objset.add_mutually_exclusive_group(required=True)\\n', \"        objset_selector_group.add_argument('--all', '-a', action='store_true',\\n\", \"        objset_selector_group.add_argument('--everything', action='store_true',\\n\", \"        objset_selector_group.add_argument('object', type=int, nargs='?', help='Object to display.')\\n\", '        objset_exclusive_display = parser_objset.add_mutually_exclusive_group()\\n', \"        objset_exclusive_display.add_argument('--parse', '-P', action='store_true',\\n\", \"        objset_exclusive_display.add_argument('--dnode', '-D', action='store_true',\\n\", \"        parser_nvparse = subcommands.add_parser('nvparse', help='Parse an NVList from a file. WIP')\\n\", '        parser_nvparse.set_defaults(func=self.nvparse)\\n', \"        parser_nvparse.add_argument('file', help='The file to parse.')\\n\", \"        parser_label = subcommands.add_parser('label', parents=[pool_parser], help='View disk labels.')\\n\", '        parser_label.set_defaults(func=self.label)\\n', \"        parser_label.add_argument('label', type=int, default=0, nargs='?', choices=(0, 1, 2, 3),\\n\", \"        parser_label.add_argument('--uberblocks', '-u', action='store_true')\\n\", \"        parser_label.add_argument('--all', action='store_true')\\n\", \"        parser_dva = subcommands.add_parser('dva', parents=[pool_parser], help='Read arbitrary blocks.')\\n\", '        parser_dva.set_defaults(func=self.read_dva)\\n', \"        parser_dva.add_argument('dva', help='The DVA (data virtual address) to read.')\\n\", \"        parser_dva.add_argument('--dump', metavar='FILE', help='Write the data to FILE.')\\n\", \"        parser_fuse = subcommands.add_parser('fuse', parents=[pool_parser],\\n\", '        if zfuse:\\n', '            parser_fuse.set_defaults(func=self.mount_fuse)\\n', \"        parser_fuse.add_argument('mountpoint', help='Set the mountpoint')\\n\", \"        parser_fuse.epilog = '''This requires the `fusepy` module, which in turn depends on libfuse.\\n\", '        for level in VERBOSE_LEVELS:\\n', '            levelname = logging.getLevelName(level).lower()\\n', '            modules = getattr(args, levelname)\\n', '            for mod in modules:\\n', '                logging.getLogger(mod).setLevel(level)\\n', '        args = self.parser.parse_args(*a, **kw)\\n', '        level = VERBOSE_LEVELS[args.verbose]\\n', \"        logging.basicConfig(level=level, format='%(asctime)s %(name)-12s %(levelname)-8s %(message)s')\\n\", '        if level != logging.CRITICAL:\\n', \"            logger.log(level, 'this is the most verbose log level for this run')\\n\", '        self.setup_module_logs(args)\\n', '        if args.pool:\\n', '            self.pool = self.load_pool(args)\\n', '        if args.pool and args.vdev_id == None:\\n', '            args.vdev_id = int(self.pool.first_vdev().id)\\n', '        args.func(args)\\n', '        devices = [filedev.FileDev(path, args.label, args.txg) for path in args.pool]\\n', '        try_config = set(args.try_config).union(*TRY_LEVELS[:args.try_level+1])\\n', \"        logger.info('extra options: {}'.format(try_config))\\n\", '        pool = Pool(devices, try_config=try_config)\\n', '        return pool\\n', '        target = self.pool.open(args.path)\\n', '        if isinstance(target, zfs.posix.File):\\n', '            print(args.path)\\n', '            for file in sorted(target.keys()):\\n', '                print(file)\\n', '        sys.stdout.buffer.write(self.pool.read_file(args.path))\\n', '        if args.parse:\\n', '        elif args.dnode:\\n', '        elif args.dump:\\n', \"            f = open(args.dump, 'wb')\\n\", '            f.write(self.pool.read_dnode(obj))\\n', '            f.close()\\n', '        if args.execute:\\n', '                parsed = os.parse_dnode(obj)\\n', '                parsed = None\\n', \"                exec(args.execute, globals(), {'o':obj, 'os':os, 'p':parsed})\\n\", \"                logger.exception('execution failed on object {}'.format(obj.node_type))\\n\", '        if args.dataset:\\n', '            ds = self.pool.dataset_for(args.dataset)\\n', '            os = ds.objectset\\n', '            os = self.pool.objset_for_vdev(args.vdev_id)\\n', '        if args.self:\\n', '            print(os.raw_objectset)\\n', '            if args.dump:\\n', \"                f = open(args.dump, 'wb')\\n\", '                print(len(os.objset))\\n', '                f.write(os.objset)\\n', '                f.close()\\n', '        if not args.object:\\n', '            args.all = True\\n', '        if args.all:\\n', '            for i, obj in enumerate(os):\\n', '                if obj.node_type != ObjectType.NONE or args.everything:\\n', '                    if args.parse:\\n', \"                    print(i, end=' ')\\n\", '                    self.show_object(args, os, obj)\\n', '        elif args.object:\\n', '            obj = os.get_dnode(args.object)\\n', '            self.show_object(args, os, obj)\\n', \"        source = open(args.file, 'rb')\\n\", '        data = source.read()\\n', '        nv = NVList(data)\\n', '        pprint(nv.unpack_nvlist())\\n', '        vdev = self.pool.vdevs[args.vdev_id]\\n', '        label = vdev.best_label\\n', '        if args.label is not None:\\n', '            label = vdev.labels[args.label]\\n', '            pprint(label[0])\\n', '        if args.uberblocks:\\n', '            for i, uber in enumerate(label[1]):\\n', '                if args.all or uber.valid():\\n', '                    print(i, uber)\\n', '        zfuse.mount(self.pool, args.mountpoint)\\n', '        dva = args.dva\\n', '    px = PoolExplorer()\\n', '    return px.cli()\\n']",
  "context": "urn NotImplemented\n\ndef cli(*args, **kwargs):\n    px = PoolExplorer()\n    return px.cli()\n\nif __name__ == '__main__':\n  "
 },
 "17": {
  "name": "values",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/nvlist/__init__.py",
  "lineno": "43",
  "column": "8",
  "slicing": "['        values = {}\\n', '                values[name] = v\\n', '                return values\\n']",
  "context": "!= 1:\n            raise Exception('asdf')\n        values = {}\n        while len(self.get_buffer()) - self.get_po"
 },
 "18": {
  "name": "name",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/nvlist/__init__.py",
  "lineno": "52",
  "column": "8",
  "slicing": "['        name, v = None, None\\n', \"                raise Exception('Unknown nvlist value type {} for key {}'.format(value_type, name))\\n\", '        return name, v\\n']",
  "context": "eturn values\n\n    def unpack_value(self):\n        name, v = None, None\n        decoded_length = self.unpack_uint()\n      "
 },
 "19": {
  "name": "v",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/nvlist/__init__.py",
  "lineno": "52",
  "column": "14",
  "slicing": "['        name, v = None, None\\n', '                    v.append(sub)\\n', '        return name, v\\n']",
  "context": "values\n\n    def unpack_value(self):\n        name, v = None, None\n        decoded_length = self.unpack_uint()\n      "
 },
 "20": {
  "name": "v",
  "type": "bool",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/nvlist/__init__.py",
  "lineno": "65",
  "column": "16",
  "slicing": "['                v = True\\n', '                    v.append(sub)\\n', '        return name, v\\n']",
  "context": "if value_type == NVTypes.BOOLEAN:\n                v = True\n            elif value_type == NVTypes.NVLIST:\n   "
 },
 "21": {
  "name": "v",
  "type": "dict",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "zfsp/nvlist/__init__.py",
  "lineno": "67",
  "column": "16",
  "slicing": "['        values = {}\\n', '            name, v = self.unpack_value()\\n', '            if name:\\n', '                values[name] = v\\n', '                return values\\n', '        name, v = None, None\\n', '        decoded_length = self.unpack_uint()\\n', '        if decoded_length > 0:\\n', '            name = self.unpack_string()\\n', '            value_type = self.unpack_uint()\\n', '            if value_type == NVTypes.UINT64:\\n', '                v = self.unpack_uhyper()\\n', '            elif value_type == NVTypes.STRING:\\n', '                v = self.unpack_string()\\n', '            elif value_type == NVTypes.BOOLEAN:\\n', '                v = True\\n', '            elif value_type == NVTypes.NVLIST:\\n', '                v = self.unpack_nvlist()\\n', '            elif value_type == NVTypes.NVLIST_ARRAY:\\n', '                    v.append(sub)\\n', \"                raise Exception('Unknown nvlist value type {} for key {}'.format(value_type, name))\\n\", '        return name, v\\n']",
  "context": "lif value_type == NVTypes.NVLIST:\n                v = self.unpack_nvlist()\n            elif value_type == NVTypes.NVLIST_ARRA"
 },
 "22": {
  "name": "v",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/nvlist/__init__.py",
  "lineno": "69",
  "column": "16",
  "slicing": "['                v = []\\n', '                    v.append(sub)\\n', '        return name, v\\n']",
  "context": "lue_type == NVTypes.NVLIST_ARRAY:\n                v = []\n                for x in range(value_count):\n     "
 },
 "23": {
  "name": "sub",
  "type": "dict",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "zfsp/nvlist/__init__.py",
  "lineno": "71",
  "column": "20",
  "slicing": "['        values = {}\\n', '            name, v = self.unpack_value()\\n', '            if name:\\n', '                values[name] = v\\n', '                return values\\n', '        name, v = None, None\\n', '        decoded_length = self.unpack_uint()\\n', '        if decoded_length > 0:\\n', '            name = self.unpack_string()\\n', '            value_type = self.unpack_uint()\\n', '            value_count = self.unpack_uint()\\n', '            if value_type == NVTypes.UINT64:\\n', '                v = self.unpack_uhyper()\\n', '            elif value_type == NVTypes.STRING:\\n', '                v = self.unpack_string()\\n', '            elif value_type == NVTypes.BOOLEAN:\\n', '                v = True\\n', '            elif value_type == NVTypes.NVLIST:\\n', '                v = self.unpack_nvlist()\\n', '            elif value_type == NVTypes.NVLIST_ARRAY:\\n', '                v = []\\n', '                for x in range(value_count):\\n', '                    sub = self.unpack_nvlist()\\n', '                    v.append(sub)\\n', \"                raise Exception('Unknown nvlist value type {} for key {}'.format(value_type, name))\\n\", '        return name, v\\n']",
  "context": " for x in range(value_count):\n                    sub = self.unpack_nvlist()\n                    v.append(sub)\n            else"
 },
 "24": {
  "name": "children",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/datasets.py",
  "lineno": "31",
  "column": "8",
  "slicing": "['        objset_block = self.pool.read_block(self.dsl_dataset.bp)\\n', '        self.objectset = objectset.ObjectSet.from_block(self.pool, objset_block, dataset=self)\\n', '        children = self.parent_objectset[self.dsl_dir.child_dir_zap]\\n', '        return ChildDatasets(children, self, self.parent_objectset, path=self.path)\\n']",
  "context": " child_datasets(self) -> 'ChildDatasets':\n        children = self.parent_objectset[self.dsl_dir.child_dir_zap]\n        return ChildDatasets(children, self, self."
 },
 "25": {
  "name": "snapshots",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/datasets.py",
  "lineno": "43",
  "column": "12",
  "slicing": "['            snapshots = {}\\n', '            self._snapshots = snapshots\\n']",
  "context": "et']:\n        if not self._snapshots:\n            snapshots = {}\n            for name, index in self.snapshot_names"
 },
 "26": {
  "name": "dsl_dataset",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/datasets.py",
  "lineno": "45",
  "column": "16",
  "slicing": "['        objset_block = self.pool.read_block(self.dsl_dataset.bp)\\n', '        self.objectset = objectset.ObjectSet.from_block(self.pool, objset_block, dataset=self)\\n', '        children = self.parent_objectset[self.dsl_dir.child_dir_zap]\\n', '        return ChildDatasets(children, self, self.parent_objectset, path=self.path)\\n', '            snapshots = {}\\n', '            for name, index in self.snapshot_names.items():\\n', '                dsl_dataset = self.parent_objectset[index]\\n', '                dataset = Dataset(\\n', '                    self.parent_objectset.objset[index],\\n', \"                    path=self.path+'@'+name\\n\", '            self._snapshots = snapshots\\n', '        d = dict(self.child_datasets.entries)\\n', '        d.update(self.root_directory.entries)\\n', '        return d\\n', \"        sa_attrs = self.objectset[self.objectset[1]['SA_ATTRS']]\\n\", \"        registry = self.objectset[sa_attrs['REGISTRY']]\\n\", \"        layout = self.objectset[sa_attrs['LAYOUTS']][key]\\n\", '        attrs = {}\\n', '        for k, attr in registry.items():\\n', \"            attrs[attr['attr_num']] = {\\n\", \"                'name': k,\\n\", \"                'byteswap': attr['byteswap'],\\n\", \"                'length': attr['length']\\n\", '        return [attrs[x] for x in layout]\\n', \"        root_dir_index = self.objectset[1]['ROOT']\\n\", '        root_dir = self.objectset[root_dir_index]\\n', '        root_dir.path = self.path\\n', '        return root_dir\\n', '        self.dataset = dataset\\n', '        return name in self.entries\\n', '        joined_path = os.path.join(self.path, name)\\n', '        if name not in self.resolved_entries:\\n', '                index = self.entries[name]\\n', '                obj = self.objectset[index]\\n', '                obj.path = joined_path\\n', '                self.resolved_entries[name] = obj\\n', \"                logger.exception(f'directory lookup failed for {joined_path}')\\n\", '                raise FileNotFoundError(joined_path)\\n', '        return self.resolved_entries[name]\\n', '        return ((k, self[k]) for k in self.keys())\\n']",
  "context": "x in self.snapshot_names.items():\n                dsl_dataset = self.parent_objectset[index]\n                dataset = Dataset(\n               "
 },
 "27": {
  "name": "dataset",
  "type": "Dataset",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/datasets.py",
  "lineno": "46",
  "column": "16",
  "slicing": "['        objset_block = self.pool.read_block(self.dsl_dataset.bp)\\n', '        self.objectset = objectset.ObjectSet.from_block(self.pool, objset_block, dataset=self)\\n', '        children = self.parent_objectset[self.dsl_dir.child_dir_zap]\\n', '        return ChildDatasets(children, self, self.parent_objectset, path=self.path)\\n', '            snapshots = {}\\n', '            for name, index in self.snapshot_names.items():\\n', '                dsl_dataset = self.parent_objectset[index]\\n', '                dataset = Dataset(\\n', '                    self.parent_objectset.objset[index],\\n', \"                    path=self.path+'@'+name\\n\", '            self._snapshots = snapshots\\n', '        d = dict(self.child_datasets.entries)\\n', '        d.update(self.root_directory.entries)\\n', '        return d\\n', \"        sa_attrs = self.objectset[self.objectset[1]['SA_ATTRS']]\\n\", \"        registry = self.objectset[sa_attrs['REGISTRY']]\\n\", \"        layout = self.objectset[sa_attrs['LAYOUTS']][key]\\n\", '        attrs = {}\\n', '        for k, attr in registry.items():\\n', \"            attrs[attr['attr_num']] = {\\n\", \"                'name': k,\\n\", \"                'byteswap': attr['byteswap'],\\n\", \"                'length': attr['length']\\n\", '        return [attrs[x] for x in layout]\\n', \"        root_dir_index = self.objectset[1]['ROOT']\\n\", '        root_dir = self.objectset[root_dir_index]\\n', '        root_dir.path = self.path\\n', '        return root_dir\\n', '        self.dataset = dataset\\n', '        return name in self.entries\\n', '        joined_path = os.path.join(self.path, name)\\n', '        if name not in self.resolved_entries:\\n', '                index = self.entries[name]\\n', '                obj = self.objectset[index]\\n', '                obj.path = joined_path\\n', '                self.resolved_entries[name] = obj\\n', \"                logger.exception(f'directory lookup failed for {joined_path}')\\n\", '                raise FileNotFoundError(joined_path)\\n', '        return self.resolved_entries[name]\\n', '        return ((k, self[k]) for k in self.keys())\\n']",
  "context": "et = self.parent_objectset[index]\n                dataset = Dataset(\n                    self.pool,\n                   "
 },
 "28": {
  "name": "d",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/datasets.py",
  "lineno": "58",
  "column": "8",
  "slicing": "['        objset_block = self.pool.read_block(self.dsl_dataset.bp)\\n', '        self.objectset = objectset.ObjectSet.from_block(self.pool, objset_block, dataset=self)\\n', '        children = self.parent_objectset[self.dsl_dir.child_dir_zap]\\n', '        return ChildDatasets(children, self, self.parent_objectset, path=self.path)\\n', '            snapshots = {}\\n', '            for name, index in self.snapshot_names.items():\\n', '                dsl_dataset = self.parent_objectset[index]\\n', '                dataset = Dataset(\\n', '                    self.parent_objectset.objset[index],\\n', \"                    path=self.path+'@'+name\\n\", '            self._snapshots = snapshots\\n', '        d = dict(self.child_datasets.entries)\\n', '        d.update(self.root_directory.entries)\\n', '        return d\\n', \"        sa_attrs = self.objectset[self.objectset[1]['SA_ATTRS']]\\n\", \"        registry = self.objectset[sa_attrs['REGISTRY']]\\n\", \"        layout = self.objectset[sa_attrs['LAYOUTS']][key]\\n\", '        attrs = {}\\n', '        for k, attr in registry.items():\\n', \"            attrs[attr['attr_num']] = {\\n\", \"                'name': k,\\n\", \"                'byteswap': attr['byteswap'],\\n\", \"                'length': attr['length']\\n\", '        return [attrs[x] for x in layout]\\n', \"        root_dir_index = self.objectset[1]['ROOT']\\n\", '        root_dir = self.objectset[root_dir_index]\\n', '        root_dir.path = self.path\\n', '        return root_dir\\n', '        self.dataset = dataset\\n', '        return name in self.entries\\n', '        joined_path = os.path.join(self.path, name)\\n', '        if name not in self.resolved_entries:\\n', '                index = self.entries[name]\\n', '                obj = self.objectset[index]\\n', '                obj.path = joined_path\\n', '                self.resolved_entries[name] = obj\\n', \"                logger.exception(f'directory lookup failed for {joined_path}')\\n\", '                raise FileNotFoundError(joined_path)\\n', '        return self.resolved_entries[name]\\n', '        return ((k, self[k]) for k in self.keys())\\n']",
  "context": "\n    def entries(self) -> Dict[str, Any]:\n        d = dict(self.child_datasets.entries)\n        d.update(self.root_directory.entries)\n    "
 },
 "29": {
  "name": "sa_attrs",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/datasets.py",
  "lineno": "78",
  "column": "8",
  "slicing": "['        objset_block = self.pool.read_block(self.dsl_dataset.bp)\\n', '        self.objectset = objectset.ObjectSet.from_block(self.pool, objset_block, dataset=self)\\n', '        children = self.parent_objectset[self.dsl_dir.child_dir_zap]\\n', '        return ChildDatasets(children, self, self.parent_objectset, path=self.path)\\n', '            snapshots = {}\\n', '            for name, index in self.snapshot_names.items():\\n', '                dsl_dataset = self.parent_objectset[index]\\n', '                dataset = Dataset(\\n', '                    self.parent_objectset.objset[index],\\n', \"                    path=self.path+'@'+name\\n\", '            self._snapshots = snapshots\\n', '        d = dict(self.child_datasets.entries)\\n', '        d.update(self.root_directory.entries)\\n', '        return d\\n', \"        sa_attrs = self.objectset[self.objectset[1]['SA_ATTRS']]\\n\", \"        registry = self.objectset[sa_attrs['REGISTRY']]\\n\", \"        layout = self.objectset[sa_attrs['LAYOUTS']][key]\\n\", '        attrs = {}\\n', '        for k, attr in registry.items():\\n', \"            attrs[attr['attr_num']] = {\\n\", \"                'name': k,\\n\", \"                'byteswap': attr['byteswap'],\\n\", \"                'length': attr['length']\\n\", '        return [attrs[x] for x in layout]\\n', \"        root_dir_index = self.objectset[1]['ROOT']\\n\", '        root_dir = self.objectset[root_dir_index]\\n', '        root_dir.path = self.path\\n', '        return root_dir\\n', '        self.dataset = dataset\\n', '        return name in self.entries\\n', '        joined_path = os.path.join(self.path, name)\\n', '        if name not in self.resolved_entries:\\n', '                index = self.entries[name]\\n', '                obj = self.objectset[index]\\n', '                obj.path = joined_path\\n', '                self.resolved_entries[name] = obj\\n', \"                logger.exception(f'directory lookup failed for {joined_path}')\\n\", '                raise FileNotFoundError(joined_path)\\n', '        return self.resolved_entries[name]\\n', '        return ((k, self[k]) for k in self.keys())\\n']",
  "context": "y.items()\n\n    def attributes(self, key):\n        sa_attrs = self.objectset[self.objectset[1]['SA_ATTRS']]\n        registry = self.objectset[sa_attrs['REGIST"
 },
 "30": {
  "name": "registry",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/datasets.py",
  "lineno": "79",
  "column": "8",
  "slicing": "['        objset_block = self.pool.read_block(self.dsl_dataset.bp)\\n', '        self.objectset = objectset.ObjectSet.from_block(self.pool, objset_block, dataset=self)\\n', '        children = self.parent_objectset[self.dsl_dir.child_dir_zap]\\n', '        return ChildDatasets(children, self, self.parent_objectset, path=self.path)\\n', '            snapshots = {}\\n', '            for name, index in self.snapshot_names.items():\\n', '                dsl_dataset = self.parent_objectset[index]\\n', '                dataset = Dataset(\\n', '                    self.parent_objectset.objset[index],\\n', \"                    path=self.path+'@'+name\\n\", '            self._snapshots = snapshots\\n', '        d = dict(self.child_datasets.entries)\\n', '        d.update(self.root_directory.entries)\\n', '        return d\\n', \"        sa_attrs = self.objectset[self.objectset[1]['SA_ATTRS']]\\n\", \"        registry = self.objectset[sa_attrs['REGISTRY']]\\n\", \"        layout = self.objectset[sa_attrs['LAYOUTS']][key]\\n\", '        attrs = {}\\n', '        for k, attr in registry.items():\\n', \"            attrs[attr['attr_num']] = {\\n\", \"                'name': k,\\n\", \"                'byteswap': attr['byteswap'],\\n\", \"                'length': attr['length']\\n\", '        return [attrs[x] for x in layout]\\n', \"        root_dir_index = self.objectset[1]['ROOT']\\n\", '        root_dir = self.objectset[root_dir_index]\\n', '        root_dir.path = self.path\\n', '        return root_dir\\n', '        self.dataset = dataset\\n', '        return name in self.entries\\n', '        joined_path = os.path.join(self.path, name)\\n', '        if name not in self.resolved_entries:\\n', '                index = self.entries[name]\\n', '                obj = self.objectset[index]\\n', '                obj.path = joined_path\\n', '                self.resolved_entries[name] = obj\\n', \"                logger.exception(f'directory lookup failed for {joined_path}')\\n\", '                raise FileNotFoundError(joined_path)\\n', '        return self.resolved_entries[name]\\n', '        return ((k, self[k]) for k in self.keys())\\n']",
  "context": ".objectset[self.objectset[1]['SA_ATTRS']]\n        registry = self.objectset[sa_attrs['REGISTRY']]\n        layout = self.objectset[sa_attrs['LAYOUTS'"
 },
 "31": {
  "name": "layout",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/datasets.py",
  "lineno": "80",
  "column": "8",
  "slicing": "['        objset_block = self.pool.read_block(self.dsl_dataset.bp)\\n', '        self.objectset = objectset.ObjectSet.from_block(self.pool, objset_block, dataset=self)\\n', '        children = self.parent_objectset[self.dsl_dir.child_dir_zap]\\n', '        return ChildDatasets(children, self, self.parent_objectset, path=self.path)\\n', '            snapshots = {}\\n', '            for name, index in self.snapshot_names.items():\\n', '                dsl_dataset = self.parent_objectset[index]\\n', '                dataset = Dataset(\\n', '                    self.parent_objectset.objset[index],\\n', \"                    path=self.path+'@'+name\\n\", '            self._snapshots = snapshots\\n', '        d = dict(self.child_datasets.entries)\\n', '        d.update(self.root_directory.entries)\\n', '        return d\\n', \"        sa_attrs = self.objectset[self.objectset[1]['SA_ATTRS']]\\n\", \"        registry = self.objectset[sa_attrs['REGISTRY']]\\n\", \"        layout = self.objectset[sa_attrs['LAYOUTS']][key]\\n\", '        attrs = {}\\n', '        for k, attr in registry.items():\\n', \"            attrs[attr['attr_num']] = {\\n\", \"                'name': k,\\n\", \"                'byteswap': attr['byteswap'],\\n\", \"                'length': attr['length']\\n\", '        return [attrs[x] for x in layout]\\n', \"        root_dir_index = self.objectset[1]['ROOT']\\n\", '        root_dir = self.objectset[root_dir_index]\\n', '        root_dir.path = self.path\\n', '        return root_dir\\n', '        self.dataset = dataset\\n', '        return name in self.entries\\n', '        joined_path = os.path.join(self.path, name)\\n', '        if name not in self.resolved_entries:\\n', '                index = self.entries[name]\\n', '                obj = self.objectset[index]\\n', '                obj.path = joined_path\\n', '                self.resolved_entries[name] = obj\\n', \"                logger.exception(f'directory lookup failed for {joined_path}')\\n\", '                raise FileNotFoundError(joined_path)\\n', '        return self.resolved_entries[name]\\n', '        return ((k, self[k]) for k in self.keys())\\n']",
  "context": "ry = self.objectset[sa_attrs['REGISTRY']]\n        layout = self.objectset[sa_attrs['LAYOUTS']][key]\n        attrs = {}\n        for k, attr in registry"
 },
 "32": {
  "name": "attrs",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/datasets.py",
  "lineno": "81",
  "column": "8",
  "slicing": "['        attrs = {}\\n', \"            attrs[attr['attr_num']] = {\\n\", '        return [attrs[x] for x in layout]\\n']",
  "context": " self.objectset[sa_attrs['LAYOUTS']][key]\n        attrs = {}\n        for k, attr in registry.items():\n         "
 },
 "33": {
  "name": "root_dir_index",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/datasets.py",
  "lineno": "92",
  "column": "8",
  "slicing": "['        objset_block = self.pool.read_block(self.dsl_dataset.bp)\\n', '        self.objectset = objectset.ObjectSet.from_block(self.pool, objset_block, dataset=self)\\n', '        children = self.parent_objectset[self.dsl_dir.child_dir_zap]\\n', '        return ChildDatasets(children, self, self.parent_objectset, path=self.path)\\n', '            snapshots = {}\\n', '            for name, index in self.snapshot_names.items():\\n', '                dsl_dataset = self.parent_objectset[index]\\n', '                dataset = Dataset(\\n', '                    self.parent_objectset.objset[index],\\n', \"                    path=self.path+'@'+name\\n\", '            self._snapshots = snapshots\\n', '        d = dict(self.child_datasets.entries)\\n', '        d.update(self.root_directory.entries)\\n', '        return d\\n', \"        sa_attrs = self.objectset[self.objectset[1]['SA_ATTRS']]\\n\", \"        registry = self.objectset[sa_attrs['REGISTRY']]\\n\", \"        layout = self.objectset[sa_attrs['LAYOUTS']][key]\\n\", '        attrs = {}\\n', '        for k, attr in registry.items():\\n', \"            attrs[attr['attr_num']] = {\\n\", \"                'name': k,\\n\", \"                'byteswap': attr['byteswap'],\\n\", \"                'length': attr['length']\\n\", '        return [attrs[x] for x in layout]\\n', \"        root_dir_index = self.objectset[1]['ROOT']\\n\", '        root_dir = self.objectset[root_dir_index]\\n', '        root_dir.path = self.path\\n', '        return root_dir\\n', '        self.dataset = dataset\\n', '        return name in self.entries\\n', '        joined_path = os.path.join(self.path, name)\\n', '        if name not in self.resolved_entries:\\n', '                index = self.entries[name]\\n', '                obj = self.objectset[index]\\n', '                obj.path = joined_path\\n', '                self.resolved_entries[name] = obj\\n', \"                logger.exception(f'directory lookup failed for {joined_path}')\\n\", '                raise FileNotFoundError(joined_path)\\n', '        return self.resolved_entries[name]\\n', '        return ((k, self[k]) for k in self.keys())\\n']",
  "context": "oot_directory(self) -> 'posix.Directory':\n        root_dir_index = self.objectset[1]['ROOT']\n        root_dir = self.objectset[root_dir_index]\n"
 },
 "34": {
  "name": "root_dir",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/datasets.py",
  "lineno": "93",
  "column": "8",
  "slicing": "['        objset_block = self.pool.read_block(self.dsl_dataset.bp)\\n', '        self.objectset = objectset.ObjectSet.from_block(self.pool, objset_block, dataset=self)\\n', '        children = self.parent_objectset[self.dsl_dir.child_dir_zap]\\n', '        return ChildDatasets(children, self, self.parent_objectset, path=self.path)\\n', '            snapshots = {}\\n', '            for name, index in self.snapshot_names.items():\\n', '                dsl_dataset = self.parent_objectset[index]\\n', '                dataset = Dataset(\\n', '                    self.parent_objectset.objset[index],\\n', \"                    path=self.path+'@'+name\\n\", '            self._snapshots = snapshots\\n', '        d = dict(self.child_datasets.entries)\\n', '        d.update(self.root_directory.entries)\\n', '        return d\\n', \"        sa_attrs = self.objectset[self.objectset[1]['SA_ATTRS']]\\n\", \"        registry = self.objectset[sa_attrs['REGISTRY']]\\n\", \"        layout = self.objectset[sa_attrs['LAYOUTS']][key]\\n\", '        attrs = {}\\n', '        for k, attr in registry.items():\\n', \"            attrs[attr['attr_num']] = {\\n\", \"                'name': k,\\n\", \"                'byteswap': attr['byteswap'],\\n\", \"                'length': attr['length']\\n\", '        return [attrs[x] for x in layout]\\n', \"        root_dir_index = self.objectset[1]['ROOT']\\n\", '        root_dir = self.objectset[root_dir_index]\\n', '        root_dir.path = self.path\\n', '        return root_dir\\n', '        self.dataset = dataset\\n', '        return name in self.entries\\n', '        joined_path = os.path.join(self.path, name)\\n', '        if name not in self.resolved_entries:\\n', '                index = self.entries[name]\\n', '                obj = self.objectset[index]\\n', '                obj.path = joined_path\\n', '                self.resolved_entries[name] = obj\\n', \"                logger.exception(f'directory lookup failed for {joined_path}')\\n\", '                raise FileNotFoundError(joined_path)\\n', '        return self.resolved_entries[name]\\n', '        return ((k, self[k]) for k in self.keys())\\n']",
  "context": "oot_dir_index = self.objectset[1]['ROOT']\n        root_dir = self.objectset[root_dir_index]\n        root_dir.path = self.path\n        return r"
 },
 "35": {
  "name": "entries",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/datasets.py",
  "lineno": "106",
  "column": "23",
  "slicing": "[\"    def __init__(self, entries: Dict[str, Any], dataset: Dataset, objectset: 'objectset.ObjectSet', path: str=None) -> None:\\n\"]",
  "context": "  )\n\n\nclass ChildDatasets:\n    def __init__(self, entries: Dict[str, Any], dataset: Dataset, objectset: 'objectset.ObjectSet', path: str=None) -> None:\n        self.entries = entries\n        self.path ="
 },
 "36": {
  "name": "dataset",
  "type": "Dataset",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/datasets.py",
  "lineno": "106",
  "column": "48",
  "slicing": "[\"    def __init__(self, entries: Dict[str, Any], dataset: Dataset, objectset: 'objectset.ObjectSet', path: str=None) -> None:\\n\"]",
  "context": ":\n    def __init__(self, entries: Dict[str, Any], dataset: Dataset, objectset: 'objectset.ObjectSet', path: str=None) -> None:\n        self.entries = entries\n        self.path ="
 },
 "37": {
  "name": "path",
  "type": "str",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/datasets.py",
  "lineno": "106",
  "column": "100",
  "slicing": "[\"    def __init__(self, entries: Dict[str, Any], dataset: Dataset, objectset: 'objectset.ObjectSet', path: str=None) -> None:\\n\"]",
  "context": "taset: Dataset, objectset: 'objectset.ObjectSet', path: str=None) -> None:\n        self.entries = entries\n        self.path ="
 },
 "38": {
  "name": "name",
  "type": "str",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/datasets.py",
  "lineno": "114",
  "column": "27",
  "slicing": "['    def __contains__(self, name: str) -> bool:\\n']",
  "context": "resolved_entries = {}\n\n    def __contains__(self, name: str) -> bool:\n        return name in self.entries\n\n    def __get"
 },
 "39": {
  "name": "name",
  "type": "str",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/datasets.py",
  "lineno": "117",
  "column": "26",
  "slicing": "['    def __getitem__(self, name: str) -> Any:\\n']",
  "context": "n name in self.entries\n\n    def __getitem__(self, name: str) -> Any:\n        joined_path = os.path.join(self.path, name"
 },
 "40": {
  "name": "joined_path",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/datasets.py",
  "lineno": "118",
  "column": "8",
  "slicing": "['        objset_block = self.pool.read_block(self.dsl_dataset.bp)\\n', '        self.objectset = objectset.ObjectSet.from_block(self.pool, objset_block, dataset=self)\\n', '        children = self.parent_objectset[self.dsl_dir.child_dir_zap]\\n', '        return ChildDatasets(children, self, self.parent_objectset, path=self.path)\\n', '            snapshots = {}\\n', '            for name, index in self.snapshot_names.items():\\n', '                dsl_dataset = self.parent_objectset[index]\\n', '                dataset = Dataset(\\n', '                    self.parent_objectset.objset[index],\\n', \"                    path=self.path+'@'+name\\n\", '            self._snapshots = snapshots\\n', '        d = dict(self.child_datasets.entries)\\n', '        d.update(self.root_directory.entries)\\n', '        return d\\n', \"        sa_attrs = self.objectset[self.objectset[1]['SA_ATTRS']]\\n\", \"        registry = self.objectset[sa_attrs['REGISTRY']]\\n\", \"        layout = self.objectset[sa_attrs['LAYOUTS']][key]\\n\", '        attrs = {}\\n', '        for k, attr in registry.items():\\n', \"            attrs[attr['attr_num']] = {\\n\", \"                'name': k,\\n\", \"                'byteswap': attr['byteswap'],\\n\", \"                'length': attr['length']\\n\", '        return [attrs[x] for x in layout]\\n', \"        root_dir_index = self.objectset[1]['ROOT']\\n\", '        root_dir = self.objectset[root_dir_index]\\n', '        root_dir.path = self.path\\n', '        return root_dir\\n', '        self.dataset = dataset\\n', '        return name in self.entries\\n', '        joined_path = os.path.join(self.path, name)\\n', '        if name not in self.resolved_entries:\\n', '                index = self.entries[name]\\n', '                obj = self.objectset[index]\\n', '                obj.path = joined_path\\n', '                self.resolved_entries[name] = obj\\n', \"                logger.exception(f'directory lookup failed for {joined_path}')\\n\", '                raise FileNotFoundError(joined_path)\\n', '        return self.resolved_entries[name]\\n', '        return ((k, self[k]) for k in self.keys())\\n']",
  "context": " def __getitem__(self, name: str) -> Any:\n        joined_path = os.path.join(self.path, name)\n        if name not in self.resolved_entries:\n    "
 },
 "41": {
  "name": "index",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/datasets.py",
  "lineno": "121",
  "column": "16",
  "slicing": "['        objset_block = self.pool.read_block(self.dsl_dataset.bp)\\n', '        self.objectset = objectset.ObjectSet.from_block(self.pool, objset_block, dataset=self)\\n', '        children = self.parent_objectset[self.dsl_dir.child_dir_zap]\\n', '        return ChildDatasets(children, self, self.parent_objectset, path=self.path)\\n', '            snapshots = {}\\n', '            for name, index in self.snapshot_names.items():\\n', '                dsl_dataset = self.parent_objectset[index]\\n', '                dataset = Dataset(\\n', '                    self.parent_objectset.objset[index],\\n', \"                    path=self.path+'@'+name\\n\", '            self._snapshots = snapshots\\n', '        d = dict(self.child_datasets.entries)\\n', '        d.update(self.root_directory.entries)\\n', '        return d\\n', \"        sa_attrs = self.objectset[self.objectset[1]['SA_ATTRS']]\\n\", \"        registry = self.objectset[sa_attrs['REGISTRY']]\\n\", \"        layout = self.objectset[sa_attrs['LAYOUTS']][key]\\n\", '        attrs = {}\\n', '        for k, attr in registry.items():\\n', \"            attrs[attr['attr_num']] = {\\n\", \"                'name': k,\\n\", \"                'byteswap': attr['byteswap'],\\n\", \"                'length': attr['length']\\n\", '        return [attrs[x] for x in layout]\\n', \"        root_dir_index = self.objectset[1]['ROOT']\\n\", '        root_dir = self.objectset[root_dir_index]\\n', '        root_dir.path = self.path\\n', '        return root_dir\\n', '        self.dataset = dataset\\n', '        return name in self.entries\\n', '        joined_path = os.path.join(self.path, name)\\n', '        if name not in self.resolved_entries:\\n', '                index = self.entries[name]\\n', '                obj = self.objectset[index]\\n', '                obj.path = joined_path\\n', '                self.resolved_entries[name] = obj\\n', \"                logger.exception(f'directory lookup failed for {joined_path}')\\n\", '                raise FileNotFoundError(joined_path)\\n', '        return self.resolved_entries[name]\\n', '        return ((k, self[k]) for k in self.keys())\\n']",
  "context": "esolved_entries:\n            try:\n                index = self.entries[name]\n                obj = self.objectset[index]\n      "
 },
 "42": {
  "name": "obj",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/datasets.py",
  "lineno": "122",
  "column": "16",
  "slicing": "['        objset_block = self.pool.read_block(self.dsl_dataset.bp)\\n', '        self.objectset = objectset.ObjectSet.from_block(self.pool, objset_block, dataset=self)\\n', '        children = self.parent_objectset[self.dsl_dir.child_dir_zap]\\n', '        return ChildDatasets(children, self, self.parent_objectset, path=self.path)\\n', '            snapshots = {}\\n', '            for name, index in self.snapshot_names.items():\\n', '                dsl_dataset = self.parent_objectset[index]\\n', '                dataset = Dataset(\\n', '                    self.parent_objectset.objset[index],\\n', \"                    path=self.path+'@'+name\\n\", '            self._snapshots = snapshots\\n', '        d = dict(self.child_datasets.entries)\\n', '        d.update(self.root_directory.entries)\\n', '        return d\\n', \"        sa_attrs = self.objectset[self.objectset[1]['SA_ATTRS']]\\n\", \"        registry = self.objectset[sa_attrs['REGISTRY']]\\n\", \"        layout = self.objectset[sa_attrs['LAYOUTS']][key]\\n\", '        attrs = {}\\n', '        for k, attr in registry.items():\\n', \"            attrs[attr['attr_num']] = {\\n\", \"                'name': k,\\n\", \"                'byteswap': attr['byteswap'],\\n\", \"                'length': attr['length']\\n\", '        return [attrs[x] for x in layout]\\n', \"        root_dir_index = self.objectset[1]['ROOT']\\n\", '        root_dir = self.objectset[root_dir_index]\\n', '        root_dir.path = self.path\\n', '        return root_dir\\n', '        self.dataset = dataset\\n', '        return name in self.entries\\n', '        joined_path = os.path.join(self.path, name)\\n', '        if name not in self.resolved_entries:\\n', '                index = self.entries[name]\\n', '                obj = self.objectset[index]\\n', '                obj.path = joined_path\\n', '                self.resolved_entries[name] = obj\\n', \"                logger.exception(f'directory lookup failed for {joined_path}')\\n\", '                raise FileNotFoundError(joined_path)\\n', '        return self.resolved_entries[name]\\n', '        return ((k, self[k]) for k in self.keys())\\n']",
  "context": "       index = self.entries[name]\n                obj = self.objectset[index]\n                obj.path = joined_path\n           "
 },
 "43": {
  "name": "LABELS",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/vdevs.py",
  "lineno": "19",
  "column": "4",
  "slicing": "['    LABELS = (\\n']",
  "context": "ing.getLogger(__name__)\n\n\nclass VDev(object):\n    LABELS = (\n        (0, os.SEEK_SET),\n        (262144, os.SEEK"
 },
 "44": {
  "name": "label_index",
  "type": "int",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/vdevs.py",
  "lineno": "26",
  "column": "23",
  "slicing": "['    def __init__(self, label_index: int=None, txg: int=None) -> None:\\n']",
  "context": "4288, os.SEEK_END),\n    )\n\n    def __init__(self, label_index: int=None, txg: int=None) -> None:\n        self.labels = [self.read_label(l) for l in"
 },
 "45": {
  "name": "txg",
  "type": "int",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/vdevs.py",
  "lineno": "26",
  "column": "46",
  "slicing": "['    def __init__(self, label_index: int=None, txg: int=None) -> None:\\n']",
  "context": " )\n\n    def __init__(self, label_index: int=None, txg: int=None) -> None:\n        self.labels = [self.read_label(l) for l in"
 },
 "46": {
  "name": "raw_uberblocks",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/vdevs.py",
  "lineno": "34",
  "column": "31",
  "slicing": "['    def parse_uberblocks(self, raw_uberblocks: List[ondisk.Uberblock]) -> List[ondisk.Uberblock]:\\n']",
  "context": "ct_uberblock(txg)\n\n    def parse_uberblocks(self, raw_uberblocks: List[ondisk.Uberblock]) -> List[ondisk.Uberblock]:\n        uber_list = list(filter(ondisk.Uberblock.v"
 },
 "47": {
  "name": "uber_list",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/vdevs.py",
  "lineno": "35",
  "column": "8",
  "slicing": "['        self.labels = [self.read_label(l) for l in self.LABELS]\\n', '        self.raw_uberblocks = [u for _, ubers in self.labels for u in ubers]\\n', '        uber_list = list(filter(ondisk.Uberblock.valid, raw_uberblocks))\\n', '        uber_list.sort(key=lambda x: x.txg, reverse=True)\\n', '        return uber_list\\n']",
  "context": "sk.Uberblock]) -> List[ondisk.Uberblock]:\n        uber_list = list(filter(ondisk.Uberblock.valid, raw_uberblocks))\n        uber_list.sort(key=lambda x: x.txg, revers"
 },
 "48": {
  "name": "txg",
  "type": "int",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/vdevs.py",
  "lineno": "39",
  "column": "31",
  "slicing": "['    def select_uberblock(self, txg: int) -> ondisk.Uberblock:\\n']",
  "context": " return uber_list\n\n    def select_uberblock(self, txg: int) -> ondisk.Uberblock:\n        txgs_available = sorted(list(set(x.txg for"
 },
 "49": {
  "name": "txgs_available",
  "type": "sorted",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/vdevs.py",
  "lineno": "40",
  "column": "8",
  "slicing": "['logger = logging.getLogger(__name__)\\n', '        self.labels = [self.read_label(l) for l in self.LABELS]\\n', '        self.raw_uberblocks = [u for _, ubers in self.labels for u in ubers]\\n', '        uber_list = list(filter(ondisk.Uberblock.valid, raw_uberblocks))\\n', '        uber_list.sort(key=lambda x: x.txg, reverse=True)\\n', '        return uber_list\\n', '        txgs_available = sorted(list(set(x.txg for x in self.uberblocks)))\\n', '        if txg in txgs_available:\\n', \"            logger.info('TXGs available: {}'.format(txgs_available))\\n\", '            candidates = [x for x in self.uberblocks if x.txg == txg]\\n', '            active_uberblock = candidates[0]\\n', \"                logger.error('Did not find desired txg {} on device {}'.format(txg, self))\\n\", \"                logger.info('TXGs available: {}'.format(txgs_available))\\n\", '        return active_uberblock\\n']",
  "context": "lock(self, txg: int) -> ondisk.Uberblock:\n        txgs_available = sorted(list(set(x.txg for x in self.uberblocks)))\n        if txg in txgs_available:\n            logg"
 },
 "50": {
  "name": "candidates",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/vdevs.py",
  "lineno": "43",
  "column": "12",
  "slicing": "['logger = logging.getLogger(__name__)\\n', '        self.labels = [self.read_label(l) for l in self.LABELS]\\n', '        self.raw_uberblocks = [u for _, ubers in self.labels for u in ubers]\\n', '        uber_list = list(filter(ondisk.Uberblock.valid, raw_uberblocks))\\n', '        uber_list.sort(key=lambda x: x.txg, reverse=True)\\n', '        return uber_list\\n', '        txgs_available = sorted(list(set(x.txg for x in self.uberblocks)))\\n', '        if txg in txgs_available:\\n', \"            logger.info('TXGs available: {}'.format(txgs_available))\\n\", '            candidates = [x for x in self.uberblocks if x.txg == txg]\\n', '            active_uberblock = candidates[0]\\n', \"                logger.error('Did not find desired txg {} on device {}'.format(txg, self))\\n\", \"                logger.info('TXGs available: {}'.format(txgs_available))\\n\", '        return active_uberblock\\n']",
  "context": "vailable: {}'.format(txgs_available))\n            candidates = [x for x in self.uberblocks if x.txg == txg]\n            active_uberblock = candidates[0]\n     "
 },
 "51": {
  "name": "active_uberblock",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/vdevs.py",
  "lineno": "44",
  "column": "12",
  "slicing": "['logger = logging.getLogger(__name__)\\n', '        self.labels = [self.read_label(l) for l in self.LABELS]\\n', '        self.raw_uberblocks = [u for _, ubers in self.labels for u in ubers]\\n', '        uber_list = list(filter(ondisk.Uberblock.valid, raw_uberblocks))\\n', '        uber_list.sort(key=lambda x: x.txg, reverse=True)\\n', '        return uber_list\\n', '        txgs_available = sorted(list(set(x.txg for x in self.uberblocks)))\\n', '        if txg in txgs_available:\\n', \"            logger.info('TXGs available: {}'.format(txgs_available))\\n\", '            candidates = [x for x in self.uberblocks if x.txg == txg]\\n', '            active_uberblock = candidates[0]\\n', \"                logger.error('Did not find desired txg {} on device {}'.format(txg, self))\\n\", \"                logger.info('TXGs available: {}'.format(txgs_available))\\n\", '        return active_uberblock\\n']",
  "context": "x in self.uberblocks if x.txg == txg]\n            active_uberblock = candidates[0]\n        else:\n            if txg:\n                "
 },
 "52": {
  "name": "active_uberblock",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/vdevs.py",
  "lineno": "49",
  "column": "12",
  "slicing": "['logger = logging.getLogger(__name__)\\n', '        self.labels = [self.read_label(l) for l in self.LABELS]\\n', '        self.raw_uberblocks = [u for _, ubers in self.labels for u in ubers]\\n', '        uber_list = list(filter(ondisk.Uberblock.valid, raw_uberblocks))\\n', '        uber_list.sort(key=lambda x: x.txg, reverse=True)\\n', '        return uber_list\\n', '        txgs_available = sorted(list(set(x.txg for x in self.uberblocks)))\\n', '        if txg in txgs_available:\\n', \"            logger.info('TXGs available: {}'.format(txgs_available))\\n\", '            candidates = [x for x in self.uberblocks if x.txg == txg]\\n', '            active_uberblock = candidates[0]\\n', \"                logger.error('Did not find desired txg {} on device {}'.format(txg, self))\\n\", \"                logger.info('TXGs available: {}'.format(txgs_available))\\n\", '            active_uberblock = self.uberblocks[0]\\n', '        return active_uberblock\\n']",
  "context": "vailable: {}'.format(txgs_available))\n            active_uberblock = self.uberblocks[0]\n        return active_uberblock\n\n    def _best_lab"
 },
 "53": {
  "name": "label_index",
  "type": "int",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/vdevs.py",
  "lineno": "52",
  "column": "26",
  "slicing": "['    def _best_label(self, label_index: int=None):\\n']",
  "context": "eturn active_uberblock\n\n    def _best_label(self, label_index: int=None):\n        retprops = {b'txg': 0}\n        for label i"
 },
 "54": {
  "name": "retprops",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/vdevs.py",
  "lineno": "53",
  "column": "8",
  "slicing": "['LABEL_PAD = 16384\\n', 'UBER_AREA = 1024 * 128  # 128 uberblock areas, each 1KiB long\\n', 'logger = logging.getLogger(__name__)\\n', '        self.labels = [self.read_label(l) for l in self.LABELS]\\n', '        self.raw_uberblocks = [u for _, ubers in self.labels for u in ubers]\\n', '        uber_list = list(filter(ondisk.Uberblock.valid, raw_uberblocks))\\n', '        uber_list.sort(key=lambda x: x.txg, reverse=True)\\n', '        return uber_list\\n', '        txgs_available = sorted(list(set(x.txg for x in self.uberblocks)))\\n', '        if txg in txgs_available:\\n', \"            logger.info('TXGs available: {}'.format(txgs_available))\\n\", '            candidates = [x for x in self.uberblocks if x.txg == txg]\\n', '            active_uberblock = candidates[0]\\n', \"                logger.error('Did not find desired txg {} on device {}'.format(txg, self))\\n\", \"                logger.info('TXGs available: {}'.format(txgs_available))\\n\", '            active_uberblock = self.uberblocks[0]\\n', '        return active_uberblock\\n', \"        retprops = {b'txg': 0}\\n\", '        for label in self.labels:\\n', '            props = label[0]\\n', \"            if props[b'txg'] > retprops[b'txg']:\\n\", '                retprops = props\\n', '            best_label = self.labels[label_index]\\n', '            best_label = retprops\\n', '        return best_label\\n', '            data = self.read(label, 262144)\\n', '            data = data[LABEL_PAD:]\\n', '            nvdata = data[:nvlist.NVAREA]\\n', '            data = data[nvlist.NVAREA:]\\n', '            properties = nvlist.NVList(nvdata).unpack_nvlist()\\n', '            uberblock_array = data[:UBER_AREA]\\n', '            for elem in range(128):\\n', '                elem *= 1024\\n', '                this_block = uberblock_array[elem:elem + 1024]\\n', '                b = ondisk.Uberblock(this_block)\\n', '                b.unpack(this_block)\\n', '                uberblocks.append(b)\\n', '        return properties, uberblocks\\n', '        return data\\n']",
  "context": "_best_label(self, label_index: int=None):\n        retprops = {b'txg': 0}\n        for label in self.labels:\n            prop"
 },
 "55": {
  "name": "props",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/vdevs.py",
  "lineno": "55",
  "column": "12",
  "slicing": "['LABEL_PAD = 16384\\n', 'UBER_AREA = 1024 * 128  # 128 uberblock areas, each 1KiB long\\n', 'logger = logging.getLogger(__name__)\\n', '        self.labels = [self.read_label(l) for l in self.LABELS]\\n', '        self.raw_uberblocks = [u for _, ubers in self.labels for u in ubers]\\n', '        uber_list = list(filter(ondisk.Uberblock.valid, raw_uberblocks))\\n', '        uber_list.sort(key=lambda x: x.txg, reverse=True)\\n', '        return uber_list\\n', '        txgs_available = sorted(list(set(x.txg for x in self.uberblocks)))\\n', '        if txg in txgs_available:\\n', \"            logger.info('TXGs available: {}'.format(txgs_available))\\n\", '            candidates = [x for x in self.uberblocks if x.txg == txg]\\n', '            active_uberblock = candidates[0]\\n', \"                logger.error('Did not find desired txg {} on device {}'.format(txg, self))\\n\", \"                logger.info('TXGs available: {}'.format(txgs_available))\\n\", '            active_uberblock = self.uberblocks[0]\\n', '        return active_uberblock\\n', \"        retprops = {b'txg': 0}\\n\", '        for label in self.labels:\\n', '            props = label[0]\\n', \"            if props[b'txg'] > retprops[b'txg']:\\n\", '                retprops = props\\n', '            best_label = self.labels[label_index]\\n', '            best_label = retprops\\n', '        return best_label\\n', '            data = self.read(label, 262144)\\n', '            data = data[LABEL_PAD:]\\n', '            nvdata = data[:nvlist.NVAREA]\\n', '            data = data[nvlist.NVAREA:]\\n', '            properties = nvlist.NVList(nvdata).unpack_nvlist()\\n', '            uberblock_array = data[:UBER_AREA]\\n', '            for elem in range(128):\\n', '                elem *= 1024\\n', '                this_block = uberblock_array[elem:elem + 1024]\\n', '                b = ondisk.Uberblock(this_block)\\n', '                b.unpack(this_block)\\n', '                uberblocks.append(b)\\n', '        return properties, uberblocks\\n', '        return data\\n']",
  "context": " 0}\n        for label in self.labels:\n            props = label[0]\n            if props[b'txg'] > retprops[b'txg']:\n "
 },
 "56": {
  "name": "retprops",
  "type": "props",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/vdevs.py",
  "lineno": "57",
  "column": "16",
  "slicing": "['LABEL_PAD = 16384\\n', 'UBER_AREA = 1024 * 128  # 128 uberblock areas, each 1KiB long\\n', 'logger = logging.getLogger(__name__)\\n', '        self.labels = [self.read_label(l) for l in self.LABELS]\\n', '        self.raw_uberblocks = [u for _, ubers in self.labels for u in ubers]\\n', '        uber_list = list(filter(ondisk.Uberblock.valid, raw_uberblocks))\\n', '        uber_list.sort(key=lambda x: x.txg, reverse=True)\\n', '        return uber_list\\n', '        txgs_available = sorted(list(set(x.txg for x in self.uberblocks)))\\n', '        if txg in txgs_available:\\n', \"            logger.info('TXGs available: {}'.format(txgs_available))\\n\", '            candidates = [x for x in self.uberblocks if x.txg == txg]\\n', '            active_uberblock = candidates[0]\\n', \"                logger.error('Did not find desired txg {} on device {}'.format(txg, self))\\n\", \"                logger.info('TXGs available: {}'.format(txgs_available))\\n\", '            active_uberblock = self.uberblocks[0]\\n', '        return active_uberblock\\n', \"        retprops = {b'txg': 0}\\n\", '        for label in self.labels:\\n', '            props = label[0]\\n', \"            if props[b'txg'] > retprops[b'txg']:\\n\", '                retprops = props\\n', '            best_label = self.labels[label_index]\\n', '            best_label = retprops\\n', '        return best_label\\n', '            data = self.read(label, 262144)\\n', '            data = data[LABEL_PAD:]\\n', '            nvdata = data[:nvlist.NVAREA]\\n', '            data = data[nvlist.NVAREA:]\\n', '            properties = nvlist.NVList(nvdata).unpack_nvlist()\\n', '            uberblock_array = data[:UBER_AREA]\\n', '            for elem in range(128):\\n', '                elem *= 1024\\n', '                this_block = uberblock_array[elem:elem + 1024]\\n', '                b = ondisk.Uberblock(this_block)\\n', '                b.unpack(this_block)\\n', '                uberblocks.append(b)\\n', '        return properties, uberblocks\\n', '        return data\\n']",
  "context": "props[b'txg'] > retprops[b'txg']:\n                retprops = props\n        if label_index:\n            best_label = s"
 },
 "57": {
  "name": "best_label",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/vdevs.py",
  "lineno": "59",
  "column": "12",
  "slicing": "['LABEL_PAD = 16384\\n', 'UBER_AREA = 1024 * 128  # 128 uberblock areas, each 1KiB long\\n', 'logger = logging.getLogger(__name__)\\n', '        self.labels = [self.read_label(l) for l in self.LABELS]\\n', '        self.raw_uberblocks = [u for _, ubers in self.labels for u in ubers]\\n', '        uber_list = list(filter(ondisk.Uberblock.valid, raw_uberblocks))\\n', '        uber_list.sort(key=lambda x: x.txg, reverse=True)\\n', '        return uber_list\\n', '        txgs_available = sorted(list(set(x.txg for x in self.uberblocks)))\\n', '        if txg in txgs_available:\\n', \"            logger.info('TXGs available: {}'.format(txgs_available))\\n\", '            candidates = [x for x in self.uberblocks if x.txg == txg]\\n', '            active_uberblock = candidates[0]\\n', \"                logger.error('Did not find desired txg {} on device {}'.format(txg, self))\\n\", \"                logger.info('TXGs available: {}'.format(txgs_available))\\n\", '            active_uberblock = self.uberblocks[0]\\n', '        return active_uberblock\\n', \"        retprops = {b'txg': 0}\\n\", '        for label in self.labels:\\n', '            props = label[0]\\n', \"            if props[b'txg'] > retprops[b'txg']:\\n\", '                retprops = props\\n', '            best_label = self.labels[label_index]\\n', '            best_label = retprops\\n', '        return best_label\\n', '            data = self.read(label, 262144)\\n', '            data = data[LABEL_PAD:]\\n', '            nvdata = data[:nvlist.NVAREA]\\n', '            data = data[nvlist.NVAREA:]\\n', '            properties = nvlist.NVList(nvdata).unpack_nvlist()\\n', '            uberblock_array = data[:UBER_AREA]\\n', '            for elem in range(128):\\n', '                elem *= 1024\\n', '                this_block = uberblock_array[elem:elem + 1024]\\n', '                b = ondisk.Uberblock(this_block)\\n', '                b.unpack(this_block)\\n', '                uberblocks.append(b)\\n', '        return properties, uberblocks\\n', '        return data\\n']",
  "context": "props = props\n        if label_index:\n            best_label = self.labels[label_index]\n        else:\n            best_label = retprops\n  "
 },
 "58": {
  "name": "best_label",
  "type": "retprops",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/vdevs.py",
  "lineno": "61",
  "column": "12",
  "slicing": "['LABEL_PAD = 16384\\n', 'UBER_AREA = 1024 * 128  # 128 uberblock areas, each 1KiB long\\n', 'logger = logging.getLogger(__name__)\\n', '        self.labels = [self.read_label(l) for l in self.LABELS]\\n', '        self.raw_uberblocks = [u for _, ubers in self.labels for u in ubers]\\n', '        uber_list = list(filter(ondisk.Uberblock.valid, raw_uberblocks))\\n', '        uber_list.sort(key=lambda x: x.txg, reverse=True)\\n', '        return uber_list\\n', '        txgs_available = sorted(list(set(x.txg for x in self.uberblocks)))\\n', '        if txg in txgs_available:\\n', \"            logger.info('TXGs available: {}'.format(txgs_available))\\n\", '            candidates = [x for x in self.uberblocks if x.txg == txg]\\n', '            active_uberblock = candidates[0]\\n', \"                logger.error('Did not find desired txg {} on device {}'.format(txg, self))\\n\", \"                logger.info('TXGs available: {}'.format(txgs_available))\\n\", '            active_uberblock = self.uberblocks[0]\\n', '        return active_uberblock\\n', \"        retprops = {b'txg': 0}\\n\", '        for label in self.labels:\\n', '            props = label[0]\\n', \"            if props[b'txg'] > retprops[b'txg']:\\n\", '                retprops = props\\n', '            best_label = self.labels[label_index]\\n', '            best_label = retprops\\n', '        return best_label\\n', '            data = self.read(label, 262144)\\n', '            data = data[LABEL_PAD:]\\n', '            nvdata = data[:nvlist.NVAREA]\\n', '            data = data[nvlist.NVAREA:]\\n', '            properties = nvlist.NVList(nvdata).unpack_nvlist()\\n', '            uberblock_array = data[:UBER_AREA]\\n', '            for elem in range(128):\\n', '                elem *= 1024\\n', '                this_block = uberblock_array[elem:elem + 1024]\\n', '                b = ondisk.Uberblock(this_block)\\n', '                b.unpack(this_block)\\n', '                uberblocks.append(b)\\n', '        return properties, uberblocks\\n', '        return data\\n']",
  "context": "elf.labels[label_index]\n        else:\n            best_label = retprops\n        return best_label\n\n    def read_label(self"
 },
 "59": {
  "name": "label",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/vdevs.py",
  "lineno": "64",
  "column": "25",
  "slicing": "['    def read_label(self, label: Tuple[int, int]):\\n']",
  "context": "      return best_label\n\n    def read_label(self, label: Tuple[int, int]):\n        try:\n            data = self.read(label, 2"
 },
 "60": {
  "name": "data",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/vdevs.py",
  "lineno": "68",
  "column": "12",
  "slicing": "['LABEL_PAD = 16384\\n', 'UBER_AREA = 1024 * 128  # 128 uberblock areas, each 1KiB long\\n', 'logger = logging.getLogger(__name__)\\n', '        self.labels = [self.read_label(l) for l in self.LABELS]\\n', '        self.raw_uberblocks = [u for _, ubers in self.labels for u in ubers]\\n', '        uber_list = list(filter(ondisk.Uberblock.valid, raw_uberblocks))\\n', '        uber_list.sort(key=lambda x: x.txg, reverse=True)\\n', '        return uber_list\\n', '        txgs_available = sorted(list(set(x.txg for x in self.uberblocks)))\\n', '        if txg in txgs_available:\\n', \"            logger.info('TXGs available: {}'.format(txgs_available))\\n\", '            candidates = [x for x in self.uberblocks if x.txg == txg]\\n', '            active_uberblock = candidates[0]\\n', \"                logger.error('Did not find desired txg {} on device {}'.format(txg, self))\\n\", \"                logger.info('TXGs available: {}'.format(txgs_available))\\n\", '            active_uberblock = self.uberblocks[0]\\n', '        return active_uberblock\\n', \"        retprops = {b'txg': 0}\\n\", '        for label in self.labels:\\n', '            props = label[0]\\n', \"            if props[b'txg'] > retprops[b'txg']:\\n\", '                retprops = props\\n', '            best_label = self.labels[label_index]\\n', '            best_label = retprops\\n', '        return best_label\\n', '            data = self.read(label, 262144)\\n', '            data = data[LABEL_PAD:]\\n', '            nvdata = data[:nvlist.NVAREA]\\n', '            data = data[nvlist.NVAREA:]\\n', '            properties = nvlist.NVList(nvdata).unpack_nvlist()\\n', '            uberblock_array = data[:UBER_AREA]\\n', '            for elem in range(128):\\n', '                elem *= 1024\\n', '                this_block = uberblock_array[elem:elem + 1024]\\n', '                b = ondisk.Uberblock(this_block)\\n', '                b.unpack(this_block)\\n', '                uberblocks.append(b)\\n', '        return properties, uberblocks\\n', '        return data\\n']",
  "context": "          # skip the reserved padding\n            data = data[LABEL_PAD:]\n            # pull the nvdata out\n            nvda"
 },
 "61": {
  "name": "nvdata",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/vdevs.py",
  "lineno": "70",
  "column": "12",
  "slicing": "['LABEL_PAD = 16384\\n', 'UBER_AREA = 1024 * 128  # 128 uberblock areas, each 1KiB long\\n', 'logger = logging.getLogger(__name__)\\n', '        self.labels = [self.read_label(l) for l in self.LABELS]\\n', '        self.raw_uberblocks = [u for _, ubers in self.labels for u in ubers]\\n', '        uber_list = list(filter(ondisk.Uberblock.valid, raw_uberblocks))\\n', '        uber_list.sort(key=lambda x: x.txg, reverse=True)\\n', '        return uber_list\\n', '        txgs_available = sorted(list(set(x.txg for x in self.uberblocks)))\\n', '        if txg in txgs_available:\\n', \"            logger.info('TXGs available: {}'.format(txgs_available))\\n\", '            candidates = [x for x in self.uberblocks if x.txg == txg]\\n', '            active_uberblock = candidates[0]\\n', \"                logger.error('Did not find desired txg {} on device {}'.format(txg, self))\\n\", \"                logger.info('TXGs available: {}'.format(txgs_available))\\n\", '            active_uberblock = self.uberblocks[0]\\n', '        return active_uberblock\\n', \"        retprops = {b'txg': 0}\\n\", '        for label in self.labels:\\n', '            props = label[0]\\n', \"            if props[b'txg'] > retprops[b'txg']:\\n\", '                retprops = props\\n', '            best_label = self.labels[label_index]\\n', '            best_label = retprops\\n', '        return best_label\\n', '            data = self.read(label, 262144)\\n', '            data = data[LABEL_PAD:]\\n', '            nvdata = data[:nvlist.NVAREA]\\n', '            data = data[nvlist.NVAREA:]\\n', '            properties = nvlist.NVList(nvdata).unpack_nvlist()\\n', '            uberblock_array = data[:UBER_AREA]\\n', '            for elem in range(128):\\n', '                elem *= 1024\\n', '                this_block = uberblock_array[elem:elem + 1024]\\n', '                b = ondisk.Uberblock(this_block)\\n', '                b.unpack(this_block)\\n', '                uberblocks.append(b)\\n', '        return properties, uberblocks\\n', '        return data\\n']",
  "context": "D:]\n            # pull the nvdata out\n            nvdata = data[:nvlist.NVAREA]\n            data = data[nvlist.NVAREA:]\n          "
 },
 "62": {
  "name": "data",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/vdevs.py",
  "lineno": "71",
  "column": "12",
  "slicing": "['LABEL_PAD = 16384\\n', 'UBER_AREA = 1024 * 128  # 128 uberblock areas, each 1KiB long\\n', 'logger = logging.getLogger(__name__)\\n', '        self.labels = [self.read_label(l) for l in self.LABELS]\\n', '        self.raw_uberblocks = [u for _, ubers in self.labels for u in ubers]\\n', '        uber_list = list(filter(ondisk.Uberblock.valid, raw_uberblocks))\\n', '        uber_list.sort(key=lambda x: x.txg, reverse=True)\\n', '        return uber_list\\n', '        txgs_available = sorted(list(set(x.txg for x in self.uberblocks)))\\n', '        if txg in txgs_available:\\n', \"            logger.info('TXGs available: {}'.format(txgs_available))\\n\", '            candidates = [x for x in self.uberblocks if x.txg == txg]\\n', '            active_uberblock = candidates[0]\\n', \"                logger.error('Did not find desired txg {} on device {}'.format(txg, self))\\n\", \"                logger.info('TXGs available: {}'.format(txgs_available))\\n\", '            active_uberblock = self.uberblocks[0]\\n', '        return active_uberblock\\n', \"        retprops = {b'txg': 0}\\n\", '        for label in self.labels:\\n', '            props = label[0]\\n', \"            if props[b'txg'] > retprops[b'txg']:\\n\", '                retprops = props\\n', '            best_label = self.labels[label_index]\\n', '            best_label = retprops\\n', '        return best_label\\n', '            data = self.read(label, 262144)\\n', '            data = data[LABEL_PAD:]\\n', '            nvdata = data[:nvlist.NVAREA]\\n', '            data = data[nvlist.NVAREA:]\\n', '            properties = nvlist.NVList(nvdata).unpack_nvlist()\\n', '            uberblock_array = data[:UBER_AREA]\\n', '            for elem in range(128):\\n', '                elem *= 1024\\n', '                this_block = uberblock_array[elem:elem + 1024]\\n', '                b = ondisk.Uberblock(this_block)\\n', '                b.unpack(this_block)\\n', '                uberblocks.append(b)\\n', '        return properties, uberblocks\\n', '        return data\\n']",
  "context": "        nvdata = data[:nvlist.NVAREA]\n            data = data[nvlist.NVAREA:]\n            # parse the nv data\n            proper"
 },
 "63": {
  "name": "properties",
  "type": "dict",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/vdevs.py",
  "lineno": "73",
  "column": "12",
  "slicing": "['LABEL_PAD = 16384\\n', 'UBER_AREA = 1024 * 128  # 128 uberblock areas, each 1KiB long\\n', 'logger = logging.getLogger(__name__)\\n', '        self.labels = [self.read_label(l) for l in self.LABELS]\\n', '        self.raw_uberblocks = [u for _, ubers in self.labels for u in ubers]\\n', '        uber_list = list(filter(ondisk.Uberblock.valid, raw_uberblocks))\\n', '        uber_list.sort(key=lambda x: x.txg, reverse=True)\\n', '        return uber_list\\n', '        txgs_available = sorted(list(set(x.txg for x in self.uberblocks)))\\n', '        if txg in txgs_available:\\n', \"            logger.info('TXGs available: {}'.format(txgs_available))\\n\", '            candidates = [x for x in self.uberblocks if x.txg == txg]\\n', '            active_uberblock = candidates[0]\\n', \"                logger.error('Did not find desired txg {} on device {}'.format(txg, self))\\n\", \"                logger.info('TXGs available: {}'.format(txgs_available))\\n\", '            active_uberblock = self.uberblocks[0]\\n', '        return active_uberblock\\n', \"        retprops = {b'txg': 0}\\n\", '        for label in self.labels:\\n', '            props = label[0]\\n', \"            if props[b'txg'] > retprops[b'txg']:\\n\", '                retprops = props\\n', '            best_label = self.labels[label_index]\\n', '            best_label = retprops\\n', '        return best_label\\n', '            data = self.read(label, 262144)\\n', '            data = data[LABEL_PAD:]\\n', '            nvdata = data[:nvlist.NVAREA]\\n', '            data = data[nvlist.NVAREA:]\\n', '            properties = nvlist.NVList(nvdata).unpack_nvlist()\\n', '            uberblock_array = data[:UBER_AREA]\\n', '            for elem in range(128):\\n', '                elem *= 1024\\n', '                this_block = uberblock_array[elem:elem + 1024]\\n', '                b = ondisk.Uberblock(this_block)\\n', '                b.unpack(this_block)\\n', '                uberblocks.append(b)\\n', '        return properties, uberblocks\\n', '        return data\\n']",
  "context": "REA:]\n            # parse the nv data\n            properties = nvlist.NVList(nvdata).unpack_nvlist()\n            # get the uberblock section (should be"
 },
 "64": {
  "name": "uberblock_array",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/vdevs.py",
  "lineno": "75",
  "column": "12",
  "slicing": "['LABEL_PAD = 16384\\n', 'UBER_AREA = 1024 * 128  # 128 uberblock areas, each 1KiB long\\n', 'logger = logging.getLogger(__name__)\\n', '        self.labels = [self.read_label(l) for l in self.LABELS]\\n', '        self.raw_uberblocks = [u for _, ubers in self.labels for u in ubers]\\n', '        uber_list = list(filter(ondisk.Uberblock.valid, raw_uberblocks))\\n', '        uber_list.sort(key=lambda x: x.txg, reverse=True)\\n', '        return uber_list\\n', '        txgs_available = sorted(list(set(x.txg for x in self.uberblocks)))\\n', '        if txg in txgs_available:\\n', \"            logger.info('TXGs available: {}'.format(txgs_available))\\n\", '            candidates = [x for x in self.uberblocks if x.txg == txg]\\n', '            active_uberblock = candidates[0]\\n', \"                logger.error('Did not find desired txg {} on device {}'.format(txg, self))\\n\", \"                logger.info('TXGs available: {}'.format(txgs_available))\\n\", '            active_uberblock = self.uberblocks[0]\\n', '        return active_uberblock\\n', \"        retprops = {b'txg': 0}\\n\", '        for label in self.labels:\\n', '            props = label[0]\\n', \"            if props[b'txg'] > retprops[b'txg']:\\n\", '                retprops = props\\n', '            best_label = self.labels[label_index]\\n', '            best_label = retprops\\n', '        return best_label\\n', '            data = self.read(label, 262144)\\n', '            data = data[LABEL_PAD:]\\n', '            nvdata = data[:nvlist.NVAREA]\\n', '            data = data[nvlist.NVAREA:]\\n', '            properties = nvlist.NVList(nvdata).unpack_nvlist()\\n', '            uberblock_array = data[:UBER_AREA]\\n', '            for elem in range(128):\\n', '                elem *= 1024\\n', '                this_block = uberblock_array[elem:elem + 1024]\\n', '                b = ondisk.Uberblock(this_block)\\n', '                b.unpack(this_block)\\n', '                uberblocks.append(b)\\n', '        return properties, uberblocks\\n', '        return data\\n']",
  "context": " section (should be the rest of data)\n            uberblock_array = data[:UBER_AREA]\n            uberblocks = []\n            for elem i"
 },
 "65": {
  "name": "uberblocks",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/vdevs.py",
  "lineno": "76",
  "column": "12",
  "slicing": "['            uberblocks = []\\n', '                uberblocks.append(b)\\n', '        return properties, uberblocks\\n']",
  "context": "   uberblock_array = data[:UBER_AREA]\n            uberblocks = []\n            for elem in range(128):\n              "
 },
 "66": {
  "name": "elem",
  "type": "int",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/vdevs.py",
  "lineno": "78",
  "column": "16",
  "slicing": "['LABEL_PAD = 16384\\n', 'UBER_AREA = 1024 * 128  # 128 uberblock areas, each 1KiB long\\n', 'logger = logging.getLogger(__name__)\\n', '        self.labels = [self.read_label(l) for l in self.LABELS]\\n', '        self.raw_uberblocks = [u for _, ubers in self.labels for u in ubers]\\n', '        uber_list = list(filter(ondisk.Uberblock.valid, raw_uberblocks))\\n', '        uber_list.sort(key=lambda x: x.txg, reverse=True)\\n', '        return uber_list\\n', '        txgs_available = sorted(list(set(x.txg for x in self.uberblocks)))\\n', '        if txg in txgs_available:\\n', \"            logger.info('TXGs available: {}'.format(txgs_available))\\n\", '            candidates = [x for x in self.uberblocks if x.txg == txg]\\n', '            active_uberblock = candidates[0]\\n', \"                logger.error('Did not find desired txg {} on device {}'.format(txg, self))\\n\", \"                logger.info('TXGs available: {}'.format(txgs_available))\\n\", '            active_uberblock = self.uberblocks[0]\\n', '        return active_uberblock\\n', \"        retprops = {b'txg': 0}\\n\", '        for label in self.labels:\\n', '            props = label[0]\\n', \"            if props[b'txg'] > retprops[b'txg']:\\n\", '                retprops = props\\n', '            best_label = self.labels[label_index]\\n', '            best_label = retprops\\n', '        return best_label\\n', '            data = self.read(label, 262144)\\n', '            data = data[LABEL_PAD:]\\n', '            nvdata = data[:nvlist.NVAREA]\\n', '            data = data[nvlist.NVAREA:]\\n', '            properties = nvlist.NVList(nvdata).unpack_nvlist()\\n', '            uberblock_array = data[:UBER_AREA]\\n', '            for elem in range(128):\\n', '                elem *= 1024\\n', '                this_block = uberblock_array[elem:elem + 1024]\\n', '                b = ondisk.Uberblock(this_block)\\n', '                b.unpack(this_block)\\n', '                uberblocks.append(b)\\n', '        return properties, uberblocks\\n', '        return data\\n']",
  "context": "          for elem in range(128):\n                elem *= 1024\n                this_block = uberblock_array[elem:"
 },
 "67": {
  "name": "this_block",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/vdevs.py",
  "lineno": "79",
  "column": "16",
  "slicing": "['LABEL_PAD = 16384\\n', 'UBER_AREA = 1024 * 128  # 128 uberblock areas, each 1KiB long\\n', 'logger = logging.getLogger(__name__)\\n', '        self.labels = [self.read_label(l) for l in self.LABELS]\\n', '        self.raw_uberblocks = [u for _, ubers in self.labels for u in ubers]\\n', '        uber_list = list(filter(ondisk.Uberblock.valid, raw_uberblocks))\\n', '        uber_list.sort(key=lambda x: x.txg, reverse=True)\\n', '        return uber_list\\n', '        txgs_available = sorted(list(set(x.txg for x in self.uberblocks)))\\n', '        if txg in txgs_available:\\n', \"            logger.info('TXGs available: {}'.format(txgs_available))\\n\", '            candidates = [x for x in self.uberblocks if x.txg == txg]\\n', '            active_uberblock = candidates[0]\\n', \"                logger.error('Did not find desired txg {} on device {}'.format(txg, self))\\n\", \"                logger.info('TXGs available: {}'.format(txgs_available))\\n\", '            active_uberblock = self.uberblocks[0]\\n', '        return active_uberblock\\n', \"        retprops = {b'txg': 0}\\n\", '        for label in self.labels:\\n', '            props = label[0]\\n', \"            if props[b'txg'] > retprops[b'txg']:\\n\", '                retprops = props\\n', '            best_label = self.labels[label_index]\\n', '            best_label = retprops\\n', '        return best_label\\n', '            data = self.read(label, 262144)\\n', '            data = data[LABEL_PAD:]\\n', '            nvdata = data[:nvlist.NVAREA]\\n', '            data = data[nvlist.NVAREA:]\\n', '            properties = nvlist.NVList(nvdata).unpack_nvlist()\\n', '            uberblock_array = data[:UBER_AREA]\\n', '            for elem in range(128):\\n', '                elem *= 1024\\n', '                this_block = uberblock_array[elem:elem + 1024]\\n', '                b = ondisk.Uberblock(this_block)\\n', '                b.unpack(this_block)\\n', '                uberblocks.append(b)\\n', '        return properties, uberblocks\\n', '        return data\\n']",
  "context": "28):\n                elem *= 1024\n                this_block = uberblock_array[elem:elem + 1024]\n                b = ondisk.Uberblock(this_block)\n "
 },
 "68": {
  "name": "offset",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/vdevs.py",
  "lineno": "93",
  "column": "19",
  "slicing": "['    def read(self, offset: Union[int, Tuple[int, int]], size: int) -> bytes:\\n']",
  "context": "ze * 512)\n        return data\n\n    def read(self, offset: Union[int, Tuple[int, int]], size: int) -> bytes:\n        raise NotImplementedError\n"
 },
 "69": {
  "name": "size",
  "type": "int",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/vdevs.py",
  "lineno": "93",
  "column": "56",
  "slicing": "['    def read(self, offset: Union[int, Tuple[int, int]], size: int) -> bytes:\\n']",
  "context": "f read(self, offset: Union[int, Tuple[int, int]], size: int) -> bytes:\n        raise NotImplementedError\n"
 },
 "70": {
  "name": "d",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/pool.py",
  "lineno": "16",
  "column": "4",
  "slicing": "['    d = {}\\n', '        d[v.id] = v\\n', '    return d\\n']",
  "context": " import posix\n\n\ndef vdev_list_to_dict(vdevs):\n    d = {}\n    for v in vdevs:\n        d[v.id] = v\n    return"
 },
 "71": {
  "name": "vdevs",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/pool.py",
  "lineno": "23",
  "column": "23",
  "slicing": "['    def __init__(self, vdevs: List[vdevs.VDev], try_config=None) -> None:\\n']",
  "context": "rn d\n\n\nclass Pool(object):\n    def __init__(self, vdevs: List[vdevs.VDev], try_config=None) -> None:\n        self.vdevs = vdev_list_to_dict(vdevs)\n    "
 },
 "72": {
  "name": "path",
  "type": "str",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/pool.py",
  "lineno": "54",
  "column": "24",
  "slicing": "['    def read_file(self, path: str) -> bytes:\\n']",
  "context": "text().read_dnode(dnode)\n\n    def read_file(self, path: str) -> bytes:\n        pathes = os.path.split(path)\n        if le"
 },
 "73": {
  "name": "filename",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/pool.py",
  "lineno": "58",
  "column": "8",
  "slicing": "['def vdev_list_to_dict(vdevs):\\n', '    d = {}\\n', '    for v in vdevs:\\n', '        d[v.id] = v\\n', '    return d\\n', '        self.vdevs = vdev_list_to_dict(vdevs)\\n', '    def first_vdev(self) -> vdevs.VDev:\\n', '        pathes = os.path.split(path)\\n', '        if len(pathes) != 2:\\n', '        filename = pathes[-1]\\n', '        dir_ents = self.open(pathes[0])\\n', '        if filename not in dir_ents:\\n', '            raise OSError(\"file not found: {}\".format(filename))\\n', '        return dir_ents[filename].read()\\n', '    def objset_for_vdev(self, vdev: vdevs.VDev) -> objectset.ObjectSet:\\n']",
  "context": " 2:\n            raise NotImplementedError\n        filename = pathes[-1]\n        dir_ents = self.open(pathes[0])\n        if"
 },
 "74": {
  "name": "vdev",
  "type": "int",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/pool.py",
  "lineno": "65",
  "column": "30",
  "slicing": "['    def objset_for_vdev(self, vdev: int) -> objectset.ObjectSet:\\n']",
  "context": "ad()\n\n    @overload\n    def objset_for_vdev(self, vdev: int) -> objectset.ObjectSet:\n        ...\n\n    @overload\n    def objset_for_vdev"
 },
 "75": {
  "name": "vdev",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/pool.py",
  "lineno": "74",
  "column": "12",
  "slicing": "['def vdev_list_to_dict(vdevs):\\n', '    d = {}\\n', '    for v in vdevs:\\n', '        d[v.id] = v\\n', '    return d\\n', '        self.vdevs = vdev_list_to_dict(vdevs)\\n', '    def first_vdev(self) -> vdevs.VDev:\\n', '        pathes = os.path.split(path)\\n', '        if len(pathes) != 2:\\n', '        filename = pathes[-1]\\n', '        dir_ents = self.open(pathes[0])\\n', '        if filename not in dir_ents:\\n', '            raise OSError(\"file not found: {}\".format(filename))\\n', '        return dir_ents[filename].read()\\n', '    def objset_for_vdev(self, vdev: vdevs.VDev) -> objectset.ObjectSet:\\n', '            vdev = self.vdevs[vdev]\\n', '        root = self.read_indirect(vdev.active_uberblock.root)\\n', '        vdev_id = vdev.id\\n', '        if vdev_id not in self._meta_object_sets:\\n', '            self._meta_object_sets[vdev_id] = objectset.ObjectSet.from_block(self, root)\\n', '        return self._meta_object_sets[vdev_id]\\n']",
  "context": "et:\n        if isinstance(vdev, int):\n            vdev = self.vdevs[vdev]\n        root = self.read_indirect(vdev.active_uber"
 },
 "76": {
  "name": "dir_index",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/pool.py",
  "lineno": "84",
  "column": "8",
  "slicing": "['def vdev_list_to_dict(vdevs):\\n', '    d = {}\\n', '    for v in vdevs:\\n', '        d[v.id] = v\\n', '    return d\\n', '        self.vdevs = vdev_list_to_dict(vdevs)\\n', '    def first_vdev(self) -> vdevs.VDev:\\n', '        pathes = os.path.split(path)\\n', '        if len(pathes) != 2:\\n', '        filename = pathes[-1]\\n', '        dir_ents = self.open(pathes[0])\\n', '        if filename not in dir_ents:\\n', '            raise OSError(\"file not found: {}\".format(filename))\\n', '        return dir_ents[filename].read()\\n', '    def objset_for_vdev(self, vdev: vdevs.VDev) -> objectset.ObjectSet:\\n', '            vdev = self.vdevs[vdev]\\n', '        root = self.read_indirect(vdev.active_uberblock.root)\\n', '        vdev_id = vdev.id\\n', '        if vdev_id not in self._meta_object_sets:\\n', '            self._meta_object_sets[vdev_id] = objectset.ObjectSet.from_block(self, root)\\n', '        return self._meta_object_sets[vdev_id]\\n', '        objset = self.objset_for_vdev(self.first_vdev())\\n', \"        dir_index = objset[1]['root_dataset']\\n\", '        dataset = objset[dir_index]\\n', '        return dataset\\n']",
  "context": "= self.objset_for_vdev(self.first_vdev())\n        dir_index = objset[1]['root_dataset']\n        dataset = objset[dir_index]\n        return"
 },
 "77": {
  "name": "dataset",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/pool.py",
  "lineno": "85",
  "column": "8",
  "slicing": "['def vdev_list_to_dict(vdevs):\\n', '    d = {}\\n', '    for v in vdevs:\\n', '        d[v.id] = v\\n', '    return d\\n', '        self.vdevs = vdev_list_to_dict(vdevs)\\n', '    def first_vdev(self) -> vdevs.VDev:\\n', '        pathes = os.path.split(path)\\n', '        if len(pathes) != 2:\\n', '        filename = pathes[-1]\\n', '        dir_ents = self.open(pathes[0])\\n', '        if filename not in dir_ents:\\n', '            raise OSError(\"file not found: {}\".format(filename))\\n', '        return dir_ents[filename].read()\\n', '    def objset_for_vdev(self, vdev: vdevs.VDev) -> objectset.ObjectSet:\\n', '            vdev = self.vdevs[vdev]\\n', '        root = self.read_indirect(vdev.active_uberblock.root)\\n', '        vdev_id = vdev.id\\n', '        if vdev_id not in self._meta_object_sets:\\n', '            self._meta_object_sets[vdev_id] = objectset.ObjectSet.from_block(self, root)\\n', '        return self._meta_object_sets[vdev_id]\\n', '        objset = self.objset_for_vdev(self.first_vdev())\\n', \"        dir_index = objset[1]['root_dataset']\\n\", '        dataset = objset[dir_index]\\n', '        return dataset\\n']",
  "context": "    dir_index = objset[1]['root_dataset']\n        dataset = objset[dir_index]\n        return dataset\n\n    def metaslab_array(sel"
 },
 "78": {
  "name": "location",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/pool.py",
  "lineno": "89",
  "column": "8",
  "slicing": "['def vdev_list_to_dict(vdevs):\\n', '    d = {}\\n', '    for v in vdevs:\\n', '        d[v.id] = v\\n', '    return d\\n', '        self.vdevs = vdev_list_to_dict(vdevs)\\n', '    def first_vdev(self) -> vdevs.VDev:\\n', '        pathes = os.path.split(path)\\n', '        if len(pathes) != 2:\\n', '        filename = pathes[-1]\\n', '        dir_ents = self.open(pathes[0])\\n', '        if filename not in dir_ents:\\n', '            raise OSError(\"file not found: {}\".format(filename))\\n', '        return dir_ents[filename].read()\\n', '    def objset_for_vdev(self, vdev: vdevs.VDev) -> objectset.ObjectSet:\\n', '            vdev = self.vdevs[vdev]\\n', '        root = self.read_indirect(vdev.active_uberblock.root)\\n', '        vdev_id = vdev.id\\n', '        if vdev_id not in self._meta_object_sets:\\n', '            self._meta_object_sets[vdev_id] = objectset.ObjectSet.from_block(self, root)\\n', '        return self._meta_object_sets[vdev_id]\\n', '        objset = self.objset_for_vdev(self.first_vdev())\\n', \"        dir_index = objset[1]['root_dataset']\\n\", '        dataset = objset[dir_index]\\n', '        return dataset\\n', \"        location = self.first_vdev().best_label[b'metaslab_array']\\n\", '        return self.objset_for_vdev(self.first_vdev())[location]\\n']",
  "context": "rn dataset\n\n    def metaslab_array(self):\n        location = self.first_vdev().best_label[b'metaslab_array']\n        return self.objset_for_vdev(self.first_vde"
 },
 "79": {
  "name": "dataset_expr",
  "type": "str",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/pool.py",
  "lineno": "92",
  "column": "26",
  "slicing": "['    def dataset_for(self, dataset_expr: str) -> datasets.Dataset:\\n']",
  "context": "irst_vdev())[location]\n\n    def dataset_for(self, dataset_expr: str) -> datasets.Dataset:\n        if '@' not in dataset_expr:\n            da"
 },
 "80": {
  "name": "path",
  "type": "str",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/pool.py",
  "lineno": "102",
  "column": "19",
  "slicing": "['    def open(self, path: str) -> Union[datasets.Dataset, posix.Directory]:\\n']",
  "context": "e:\n            raise KeyError\n\n    def open(self, path: str) -> Union[datasets.Dataset, posix.Directory]:\n        paths = path.lstrip('/').split('/')\n      "
 },
 "81": {
  "name": "current",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/pool.py",
  "lineno": "108",
  "column": "12",
  "slicing": "['def vdev_list_to_dict(vdevs):\\n', '    d = {}\\n', '    for v in vdevs:\\n', '        d[v.id] = v\\n', '    return d\\n', '        self.vdevs = vdev_list_to_dict(vdevs)\\n', '    def first_vdev(self) -> vdevs.VDev:\\n', '        pathes = os.path.split(path)\\n', '        if len(pathes) != 2:\\n', '        filename = pathes[-1]\\n', '        dir_ents = self.open(pathes[0])\\n', '        if filename not in dir_ents:\\n', '            raise OSError(\"file not found: {}\".format(filename))\\n', '        return dir_ents[filename].read()\\n', '    def objset_for_vdev(self, vdev: vdevs.VDev) -> objectset.ObjectSet:\\n', '            vdev = self.vdevs[vdev]\\n', '        root = self.read_indirect(vdev.active_uberblock.root)\\n', '        vdev_id = vdev.id\\n', '        if vdev_id not in self._meta_object_sets:\\n', '            self._meta_object_sets[vdev_id] = objectset.ObjectSet.from_block(self, root)\\n', '        return self._meta_object_sets[vdev_id]\\n', '        objset = self.objset_for_vdev(self.first_vdev())\\n', \"        dir_index = objset[1]['root_dataset']\\n\", '        dataset = objset[dir_index]\\n', '        return dataset\\n', \"        location = self.first_vdev().best_label[b'metaslab_array']\\n\", '        return self.objset_for_vdev(self.first_vdev())[location]\\n', \"            dataset_expr += '@'\\n\", \"        dataset_name, snapshot_name = dataset_expr.split('@', 1)\\n\", '        ds = self.open(dataset_name)\\n', '        if isinstance(ds, datasets.Dataset):\\n', '            return ds.snapshots.get(snapshot_name, ds)\\n', \"        paths = path.lstrip('/').split('/')\\n\", '        current = self.root_dataset\\n', \"        if paths == ['']:\\n\", '            return current\\n', '        for next_dir in paths:\\n', '            current = current[next_dir]\\n', '        return current\\n']",
  "context": "urrent\n        for next_dir in paths:\n            current = current[next_dir]\n        return current\n"
 },
 "82": {
  "name": "mode",
  "type": "stat.S_IFDIR",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/zfuse.py",
  "lineno": "50",
  "column": "20",
  "slicing": "['                    mode |= S_IFDIR\\n', \"                    'st_mode': mode,\\n\"]",
  "context": "stance(obj, posix.Directory):\n                    mode |= S_IFDIR\n                elif 'ZPL_SYMLINK' in attrs or att"
 },
 "83": {
  "name": "mode",
  "type": "stat.S_IFLNK",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/zfuse.py",
  "lineno": "52",
  "column": "20",
  "slicing": "['                    mode |= S_IFLNK\\n', \"                    'st_mode': mode,\\n\"]",
  "context": "le_type == PosixType.SYMLINK:\n                    mode |= S_IFLNK\n                elif isinstance(obj, posix.File):\n"
 },
 "84": {
  "name": "mode",
  "type": "stat.S_IFREG",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/zfuse.py",
  "lineno": "54",
  "column": "20",
  "slicing": "['                    mode |= S_IFREG\\n', \"                    'st_mode': mode,\\n\"]",
  "context": " isinstance(obj, posix.File):\n                    mode |= S_IFREG\n                return {\n                    'st_m"
 },
 "85": {
  "name": "names",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/zfuse.py",
  "lineno": "101",
  "column": "12",
  "slicing": "[\"            names = ['.', '..']\\n\", '                names.append(name)\\n', \"            logger.info(' '.join(names))\\n\", '            return names\\n']",
  "context": "readdir(self, path, fh):\n        try:\n            names = ['.', '..']\n            for name in self.pool.open(path).keys("
 },
 "86": {
  "name": "zf",
  "type": "ZFSFuse",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/zfuse.py",
  "lineno": "117",
  "column": "4",
  "slicing": "['logger = logging.getLogger(__name__)\\n', \"        logger.critical('...')\\n\", '            obj = self.pool.open(path)\\n', \"                logger.debug(f'asdf asdf {obj} {obj.attrs} {obj.dnode.index}')\\n\", '            if isinstance(obj, datasets.Dataset):\\n', '                obj = obj.root_directory\\n', '            if isinstance(obj, posix.PosixObject):\\n', '                attrs = obj.attrs\\n', \"                mode = attrs['ZPL_MODE'].perms\\n\", \"                logger.debug(f'{path}, {attrs.keys()}')\\n\", '                logger.debug(mode)\\n', '                if isinstance(obj, posix.Directory):\\n', '                    mode |= S_IFDIR\\n', \"                elif 'ZPL_SYMLINK' in attrs or attrs['ZPL_MODE'].file_type == PosixType.SYMLINK:\\n\", '                    mode |= S_IFLNK\\n', '                elif isinstance(obj, posix.File):\\n', '                    mode |= S_IFREG\\n', \"                    'st_mode': mode,\\n\", \"                    'st_uid': attrs['ZPL_UID'],\\n\", \"                    'st_gid': attrs['ZPL_GID'],\\n\", \"                    'st_size': attrs['ZPL_SIZE'],\\n\", \"                    'st_mtime': attrs['ZPL_MTIME'].seconds,\\n\", \"                    'st_atime': attrs['ZPL_ATIME'].seconds,\\n\", \"                    'st_ctime': attrs['ZPL_CTIME'].seconds,\\n\", \"            logger.exception('error in getattr')\\n\", \"            logger.debug(f'attempted to readlink {path}')\\n\", '            obj = self.pool.open(path)\\n', \"            return obj.attrs['ZPL_SYMLINK']\\n\", \"            logger.exception(f'readlink failed for {path}')\\n\", '            logger.exception(\"error in read\")\\n', \"            names = ['.', '..']\\n\", '            for name in self.pool.open(path).keys():\\n', '                if isinstance(name, bytes):\\n', \"                    name = name.decode('utf8')\\n\", '                names.append(name)\\n', \"            logger.info(' '.join(names))\\n\", '            return names\\n', '            logger.exception(\"error in readdir\")\\n', '    zf = ZFSFuse(pool)\\n', '    fuse = FUSE(zf, mountpoint,\\n']",
  "context": "f_bavail=2048)\n\n\ndef mount(pool, mountpoint):\n    zf = ZFSFuse(pool)\n    fuse = FUSE(zf, mountpoint,\n                fo"
 },
 "87": {
  "name": "fuse",
  "type": "fuse.FUSE",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/zfuse.py",
  "lineno": "118",
  "column": "4",
  "slicing": "['logger = logging.getLogger(__name__)\\n', \"        logger.critical('...')\\n\", '            obj = self.pool.open(path)\\n', \"                logger.debug(f'asdf asdf {obj} {obj.attrs} {obj.dnode.index}')\\n\", '            if isinstance(obj, datasets.Dataset):\\n', '                obj = obj.root_directory\\n', '            if isinstance(obj, posix.PosixObject):\\n', '                attrs = obj.attrs\\n', \"                mode = attrs['ZPL_MODE'].perms\\n\", \"                logger.debug(f'{path}, {attrs.keys()}')\\n\", '                logger.debug(mode)\\n', '                if isinstance(obj, posix.Directory):\\n', '                    mode |= S_IFDIR\\n', \"                elif 'ZPL_SYMLINK' in attrs or attrs['ZPL_MODE'].file_type == PosixType.SYMLINK:\\n\", '                    mode |= S_IFLNK\\n', '                elif isinstance(obj, posix.File):\\n', '                    mode |= S_IFREG\\n', \"                    'st_mode': mode,\\n\", \"                    'st_uid': attrs['ZPL_UID'],\\n\", \"                    'st_gid': attrs['ZPL_GID'],\\n\", \"                    'st_size': attrs['ZPL_SIZE'],\\n\", \"                    'st_mtime': attrs['ZPL_MTIME'].seconds,\\n\", \"                    'st_atime': attrs['ZPL_ATIME'].seconds,\\n\", \"                    'st_ctime': attrs['ZPL_CTIME'].seconds,\\n\", \"            logger.exception('error in getattr')\\n\", \"            logger.debug(f'attempted to readlink {path}')\\n\", '            obj = self.pool.open(path)\\n', \"            return obj.attrs['ZPL_SYMLINK']\\n\", \"            logger.exception(f'readlink failed for {path}')\\n\", '            logger.exception(\"error in read\")\\n', \"            names = ['.', '..']\\n\", '            for name in self.pool.open(path).keys():\\n', '                if isinstance(name, bytes):\\n', \"                    name = name.decode('utf8')\\n\", '                names.append(name)\\n', \"            logger.info(' '.join(names))\\n\", '            return names\\n', '            logger.exception(\"error in readdir\")\\n', '    zf = ZFSFuse(pool)\\n', '    fuse = FUSE(zf, mountpoint,\\n']",
  "context": "unt(pool, mountpoint):\n    zf = ZFSFuse(pool)\n    fuse = FUSE(zf, mountpoint,\n                foreground=True,\n                r"
 },
 "88": {
  "name": "bs",
  "type": "typing.ByteString",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/lzjb.py",
  "lineno": "4",
  "column": "15",
  "slicing": "['def decompress(bs: ByteString, size: int) -> ByteString:\\n']",
  "context": "from typing import ByteString\n\n\ndef decompress(bs: ByteString, size: int) -> ByteString:\n    bs = bytearray(bs)\n    out = bytearray()\n    b"
 },
 "89": {
  "name": "size",
  "type": "int",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/lzjb.py",
  "lineno": "4",
  "column": "31",
  "slicing": "['def decompress(bs: ByteString, size: int) -> ByteString:\\n']",
  "context": "mport ByteString\n\n\ndef decompress(bs: ByteString, size: int) -> ByteString:\n    bs = bytearray(bs)\n    out = bytearray()\n    b"
 },
 "90": {
  "name": "bs",
  "type": "bytearray",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/lzjb.py",
  "lineno": "5",
  "column": "4",
  "slicing": "['    bs = bytearray(bs)\\n', '    out = bytearray()\\n', '    blen = len(bs)\\n', '    pos = 0\\n', '    while pos < blen and len(out) < size:\\n', '        control = bs[pos]\\n', '        pos += 1\\n', '        for i in range(8):\\n', '            b = control & (1 << i) > 0\\n', '            if not pos < blen:\\n', '            if not b:\\n', '                out.append(bs[pos])\\n', '                pos += 1\\n', '                length = (bs[pos] >> 2) + 3\\n', '                distance = (bs[pos] & 0b11) << 8 | bs[pos+1]\\n', '                pos += 2\\n', '                backref = out[-distance:]\\n', '                lookup = backref * int(length / distance) + backref[:(length % distance)]\\n', '                out += lookup\\n', '    return out[:size]\\n']",
  "context": "ess(bs: ByteString, size: int) -> ByteString:\n    bs = bytearray(bs)\n    out = bytearray()\n    blen = len(bs)\n    pos ="
 },
 "91": {
  "name": "out",
  "type": "bytearray",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/lzjb.py",
  "lineno": "6",
  "column": "4",
  "slicing": "['    bs = bytearray(bs)\\n', '    out = bytearray()\\n', '    blen = len(bs)\\n', '    pos = 0\\n', '    while pos < blen and len(out) < size:\\n', '        control = bs[pos]\\n', '        pos += 1\\n', '        for i in range(8):\\n', '            b = control & (1 << i) > 0\\n', '            if not pos < blen:\\n', '            if not b:\\n', '                out.append(bs[pos])\\n', '                pos += 1\\n', '                length = (bs[pos] >> 2) + 3\\n', '                distance = (bs[pos] & 0b11) << 8 | bs[pos+1]\\n', '                pos += 2\\n', '                backref = out[-distance:]\\n', '                lookup = backref * int(length / distance) + backref[:(length % distance)]\\n', '                out += lookup\\n', '    return out[:size]\\n']",
  "context": "e: int) -> ByteString:\n    bs = bytearray(bs)\n    out = bytearray()\n    blen = len(bs)\n    pos = 0\n    while pos < ble"
 },
 "92": {
  "name": "blen",
  "type": "len",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/lzjb.py",
  "lineno": "7",
  "column": "4",
  "slicing": "['    bs = bytearray(bs)\\n', '    out = bytearray()\\n', '    blen = len(bs)\\n', '    pos = 0\\n', '    while pos < blen and len(out) < size:\\n', '        control = bs[pos]\\n', '        pos += 1\\n', '        for i in range(8):\\n', '            b = control & (1 << i) > 0\\n', '            if not pos < blen:\\n', '            if not b:\\n', '                out.append(bs[pos])\\n', '                pos += 1\\n', '                length = (bs[pos] >> 2) + 3\\n', '                distance = (bs[pos] & 0b11) << 8 | bs[pos+1]\\n', '                pos += 2\\n', '                backref = out[-distance:]\\n', '                lookup = backref * int(length / distance) + backref[:(length % distance)]\\n', '                out += lookup\\n', '    return out[:size]\\n']",
  "context": "\n    bs = bytearray(bs)\n    out = bytearray()\n    blen = len(bs)\n    pos = 0\n    while pos < blen and len(out) < si"
 },
 "93": {
  "name": "control",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/lzjb.py",
  "lineno": "10",
  "column": "8",
  "slicing": "['    bs = bytearray(bs)\\n', '    out = bytearray()\\n', '    blen = len(bs)\\n', '    pos = 0\\n', '    while pos < blen and len(out) < size:\\n', '        control = bs[pos]\\n', '        pos += 1\\n', '        for i in range(8):\\n', '            b = control & (1 << i) > 0\\n', '            if not pos < blen:\\n', '            if not b:\\n', '                out.append(bs[pos])\\n', '                pos += 1\\n', '                length = (bs[pos] >> 2) + 3\\n', '                distance = (bs[pos] & 0b11) << 8 | bs[pos+1]\\n', '                pos += 2\\n', '                backref = out[-distance:]\\n', '                lookup = backref * int(length / distance) + backref[:(length % distance)]\\n', '                out += lookup\\n', '    return out[:size]\\n']",
  "context": "    while pos < blen and len(out) < size:\n        control = bs[pos]\n        pos += 1\n        for i in range(8):\n      "
 },
 "94": {
  "name": "b",
  "type": "bool",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/lzjb.py",
  "lineno": "13",
  "column": "12",
  "slicing": "['    bs = bytearray(bs)\\n', '    out = bytearray()\\n', '    blen = len(bs)\\n', '    pos = 0\\n', '    while pos < blen and len(out) < size:\\n', '        control = bs[pos]\\n', '        pos += 1\\n', '        for i in range(8):\\n', '            b = control & (1 << i) > 0\\n', '            if not pos < blen:\\n', '            if not b:\\n', '                out.append(bs[pos])\\n', '                pos += 1\\n', '                length = (bs[pos] >> 2) + 3\\n', '                distance = (bs[pos] & 0b11) << 8 | bs[pos+1]\\n', '                pos += 2\\n', '                backref = out[-distance:]\\n', '                lookup = backref * int(length / distance) + backref[:(length % distance)]\\n', '                out += lookup\\n', '    return out[:size]\\n']",
  "context": "  pos += 1\n        for i in range(8):\n            b = control & (1 << i) > 0\n            if not pos < blen:\n                bre"
 },
 "95": {
  "name": "backref",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/lzjb.py",
  "lineno": "23",
  "column": "16",
  "slicing": "['    bs = bytearray(bs)\\n', '    out = bytearray()\\n', '    blen = len(bs)\\n', '    pos = 0\\n', '    while pos < blen and len(out) < size:\\n', '        control = bs[pos]\\n', '        pos += 1\\n', '        for i in range(8):\\n', '            b = control & (1 << i) > 0\\n', '            if not pos < blen:\\n', '            if not b:\\n', '                out.append(bs[pos])\\n', '                pos += 1\\n', '                length = (bs[pos] >> 2) + 3\\n', '                distance = (bs[pos] & 0b11) << 8 | bs[pos+1]\\n', '                pos += 2\\n', '                backref = out[-distance:]\\n', '                lookup = backref * int(length / distance) + backref[:(length % distance)]\\n', '                out += lookup\\n', '    return out[:size]\\n']",
  "context": "s[pos+1]\n                pos += 2\n                backref = out[-distance:]\n                lookup = backref * int(length / di"
 },
 "96": {
  "name": "lookup",
  "type": "int",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/lzjb.py",
  "lineno": "24",
  "column": "16",
  "slicing": "['    bs = bytearray(bs)\\n', '    out = bytearray()\\n', '    blen = len(bs)\\n', '    pos = 0\\n', '    while pos < blen and len(out) < size:\\n', '        control = bs[pos]\\n', '        pos += 1\\n', '        for i in range(8):\\n', '            b = control & (1 << i) > 0\\n', '            if not pos < blen:\\n', '            if not b:\\n', '                out.append(bs[pos])\\n', '                pos += 1\\n', '                length = (bs[pos] >> 2) + 3\\n', '                distance = (bs[pos] & 0b11) << 8 | bs[pos+1]\\n', '                pos += 2\\n', '                backref = out[-distance:]\\n', '                lookup = backref * int(length / distance) + backref[:(length % distance)]\\n', '                out += lookup\\n', '    return out[:size]\\n']",
  "context": "        backref = out[-distance:]\n                lookup = backref * int(length / distance) + backref[:(length % distance)]\n                out += lookup\n    return out[:size"
 },
 "97": {
  "name": "out",
  "type": "lookup",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/lzjb.py",
  "lineno": "25",
  "column": "16",
  "slicing": "['                out += lookup\\n', '    return out[:size]\\n']",
  "context": ") + backref[:(length % distance)]\n                out += lookup\n    return out[:size]\n"
 },
 "98": {
  "name": "buffer",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/history.py",
  "lineno": "19",
  "column": "23",
  "slicing": "['    def __init__(self, buffer: Union[BytesIO, bytes]) -> None:\\n']",
  "context": "ass HistoryParser(object):\n    def __init__(self, buffer: Union[BytesIO, bytes]) -> None:\n        if isinstance(buffer, bytes):\n            "
 },
 "99": {
  "name": "total_length",
  "type": "next_break_offset",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/history.py",
  "lineno": "38",
  "column": "8",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def next_break_offset(x):\\n', '    return (x + 7) & ~7\\n', '        total_length = next_break_offset(length)\\n', '        return self.buf.read(total_length)[:length]\\n', '        length = self.unpack_uint()\\n', '        return self.unpack_fstring(length)\\n', '        pos = self.buf.tell()\\n', '        total_length = self.unpack_uint()\\n', '        if total_length == 0:\\n', '        length = self.unpack_uint()\\n', '        value_count = self.unpack_uint()\\n', '        value_type = NVTypes(self.unpack_uint())\\n', '        key = self.unpack_fstring(length)\\n', \"        key = key.rstrip('\\\\x00')\\n\", '        remaining = total_length - (self.buf.tell() - pos)\\n', '        values = []\\n', '        for v in range(value_count):\\n', '            if value_type == NVTypes.UINT64:\\n', '                value = self.unpack_uhyper()\\n', '            elif value_type == NVTypes.INT32:\\n', '                value = self.unpack_uhyper()\\n', '            elif value_type == NVTypes.STRING:\\n', '                value = self.buf.read(remaining)\\n', \"                value = value.rstrip('\\\\x00')\\n\", '            elif value_type == NVTypes.NVLIST:\\n', '                value = self.unpack_nvlist(extra=True)\\n', '            elif value_type == NVTypes.BOOLEAN:\\n', '                value = self.unpack_uhyper()\\n', \"                logger.debug('saw type', value_type, value_count, remaining)\\n\", '                value = self.buf.read(remaining)\\n', '            values.append(value)\\n', '        remaining = total_length - (self.buf.tell() - pos)\\n', '        if remaining > 0:\\n', \"            logger.debug('remains', remaining, value_count, value_type)\\n\", '            values.append(self.buf.read(remaining))\\n', '        if len(values) == 1:\\n', '            values = values[0]\\n', '        return key, values\\n', '                values[name] = v\\n', '        return values\\n', '        while self.buf.tell() < total_length and history[-1]:\\n']",
  "context": "0]\n\n    def unpack_fstring(self, length):\n        total_length = next_break_offset(length)\n        return self.buf.read(total_length)[:length"
 },
 "100": {
  "name": "length",
  "type": "list",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/history.py",
  "lineno": "42",
  "column": "8",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def next_break_offset(x):\\n', '    return (x + 7) & ~7\\n', '        total_length = next_break_offset(length)\\n', '        return self.buf.read(total_length)[:length]\\n', '        length = self.unpack_uint()\\n', '        return self.unpack_fstring(length)\\n', '        pos = self.buf.tell()\\n', '        total_length = self.unpack_uint()\\n', '        if total_length == 0:\\n', '        length = self.unpack_uint()\\n', '        value_count = self.unpack_uint()\\n', '        value_type = NVTypes(self.unpack_uint())\\n', '        key = self.unpack_fstring(length)\\n', \"        key = key.rstrip('\\\\x00')\\n\", '        remaining = total_length - (self.buf.tell() - pos)\\n', '        values = []\\n', '        for v in range(value_count):\\n', '            if value_type == NVTypes.UINT64:\\n', '                value = self.unpack_uhyper()\\n', '            elif value_type == NVTypes.INT32:\\n', '                value = self.unpack_uhyper()\\n', '            elif value_type == NVTypes.STRING:\\n', '                value = self.buf.read(remaining)\\n', \"                value = value.rstrip('\\\\x00')\\n\", '            elif value_type == NVTypes.NVLIST:\\n', '                value = self.unpack_nvlist(extra=True)\\n', '            elif value_type == NVTypes.BOOLEAN:\\n', '                value = self.unpack_uhyper()\\n', \"                logger.debug('saw type', value_type, value_count, remaining)\\n\", '                value = self.buf.read(remaining)\\n', '            values.append(value)\\n', '        remaining = total_length - (self.buf.tell() - pos)\\n', '        if remaining > 0:\\n', \"            logger.debug('remains', remaining, value_count, value_type)\\n\", '            values.append(self.buf.read(remaining))\\n', '        if len(values) == 1:\\n', '            values = values[0]\\n', '        return key, values\\n', '                values[name] = v\\n', '        return values\\n', '        while self.buf.tell() < total_length and history[-1]:\\n']",
  "context": "h)[:length]\n\n    def unpack_string(self):\n        length = self.unpack_uint()\n        return self.unpack_fstring(length)\n\n    de"
 },
 "101": {
  "name": "total_length",
  "type": "list",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/history.py",
  "lineno": "47",
  "column": "8",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def next_break_offset(x):\\n', '    return (x + 7) & ~7\\n', '        total_length = next_break_offset(length)\\n', '        return self.buf.read(total_length)[:length]\\n', '        length = self.unpack_uint()\\n', '        return self.unpack_fstring(length)\\n', '        pos = self.buf.tell()\\n', '        total_length = self.unpack_uint()\\n', '        if total_length == 0:\\n', '        length = self.unpack_uint()\\n', '        value_count = self.unpack_uint()\\n', '        value_type = NVTypes(self.unpack_uint())\\n', '        key = self.unpack_fstring(length)\\n', \"        key = key.rstrip('\\\\x00')\\n\", '        remaining = total_length - (self.buf.tell() - pos)\\n', '        values = []\\n', '        for v in range(value_count):\\n', '            if value_type == NVTypes.UINT64:\\n', '                value = self.unpack_uhyper()\\n', '            elif value_type == NVTypes.INT32:\\n', '                value = self.unpack_uhyper()\\n', '            elif value_type == NVTypes.STRING:\\n', '                value = self.buf.read(remaining)\\n', \"                value = value.rstrip('\\\\x00')\\n\", '            elif value_type == NVTypes.NVLIST:\\n', '                value = self.unpack_nvlist(extra=True)\\n', '            elif value_type == NVTypes.BOOLEAN:\\n', '                value = self.unpack_uhyper()\\n', \"                logger.debug('saw type', value_type, value_count, remaining)\\n\", '                value = self.buf.read(remaining)\\n', '            values.append(value)\\n', '        remaining = total_length - (self.buf.tell() - pos)\\n', '        if remaining > 0:\\n', \"            logger.debug('remains', remaining, value_count, value_type)\\n\", '            values.append(self.buf.read(remaining))\\n', '        if len(values) == 1:\\n', '            values = values[0]\\n', '        return key, values\\n', '                values[name] = v\\n', '        return values\\n', '        while self.buf.tell() < total_length and history[-1]:\\n']",
  "context": "alue(self):\n        pos = self.buf.tell()\n        total_length = self.unpack_uint()\n        if total_length == 0:\n            return '"
 },
 "102": {
  "name": "length",
  "type": "list",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/history.py",
  "lineno": "50",
  "column": "8",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def next_break_offset(x):\\n', '    return (x + 7) & ~7\\n', '        total_length = next_break_offset(length)\\n', '        return self.buf.read(total_length)[:length]\\n', '        length = self.unpack_uint()\\n', '        return self.unpack_fstring(length)\\n', '        pos = self.buf.tell()\\n', '        total_length = self.unpack_uint()\\n', '        if total_length == 0:\\n', '        length = self.unpack_uint()\\n', '        value_count = self.unpack_uint()\\n', '        value_type = NVTypes(self.unpack_uint())\\n', '        key = self.unpack_fstring(length)\\n', \"        key = key.rstrip('\\\\x00')\\n\", '        remaining = total_length - (self.buf.tell() - pos)\\n', '        values = []\\n', '        for v in range(value_count):\\n', '            if value_type == NVTypes.UINT64:\\n', '                value = self.unpack_uhyper()\\n', '            elif value_type == NVTypes.INT32:\\n', '                value = self.unpack_uhyper()\\n', '            elif value_type == NVTypes.STRING:\\n', '                value = self.buf.read(remaining)\\n', \"                value = value.rstrip('\\\\x00')\\n\", '            elif value_type == NVTypes.NVLIST:\\n', '                value = self.unpack_nvlist(extra=True)\\n', '            elif value_type == NVTypes.BOOLEAN:\\n', '                value = self.unpack_uhyper()\\n', \"                logger.debug('saw type', value_type, value_count, remaining)\\n\", '                value = self.buf.read(remaining)\\n', '            values.append(value)\\n', '        remaining = total_length - (self.buf.tell() - pos)\\n', '        if remaining > 0:\\n', \"            logger.debug('remains', remaining, value_count, value_type)\\n\", '            values.append(self.buf.read(remaining))\\n', '        if len(values) == 1:\\n', '            values = values[0]\\n', '        return key, values\\n', '                values[name] = v\\n', '        return values\\n', '        while self.buf.tell() < total_length and history[-1]:\\n']",
  "context": "al_length == 0:\n            return '', ''\n        length = self.unpack_uint()\n        value_count = self.unpack_uint()\n        v"
 },
 "103": {
  "name": "value_count",
  "type": "list",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/history.py",
  "lineno": "51",
  "column": "8",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def next_break_offset(x):\\n', '    return (x + 7) & ~7\\n', '        total_length = next_break_offset(length)\\n', '        return self.buf.read(total_length)[:length]\\n', '        length = self.unpack_uint()\\n', '        return self.unpack_fstring(length)\\n', '        pos = self.buf.tell()\\n', '        total_length = self.unpack_uint()\\n', '        if total_length == 0:\\n', '        length = self.unpack_uint()\\n', '        value_count = self.unpack_uint()\\n', '        value_type = NVTypes(self.unpack_uint())\\n', '        key = self.unpack_fstring(length)\\n', \"        key = key.rstrip('\\\\x00')\\n\", '        remaining = total_length - (self.buf.tell() - pos)\\n', '        values = []\\n', '        for v in range(value_count):\\n', '            if value_type == NVTypes.UINT64:\\n', '                value = self.unpack_uhyper()\\n', '            elif value_type == NVTypes.INT32:\\n', '                value = self.unpack_uhyper()\\n', '            elif value_type == NVTypes.STRING:\\n', '                value = self.buf.read(remaining)\\n', \"                value = value.rstrip('\\\\x00')\\n\", '            elif value_type == NVTypes.NVLIST:\\n', '                value = self.unpack_nvlist(extra=True)\\n', '            elif value_type == NVTypes.BOOLEAN:\\n', '                value = self.unpack_uhyper()\\n', \"                logger.debug('saw type', value_type, value_count, remaining)\\n\", '                value = self.buf.read(remaining)\\n', '            values.append(value)\\n', '        remaining = total_length - (self.buf.tell() - pos)\\n', '        if remaining > 0:\\n', \"            logger.debug('remains', remaining, value_count, value_type)\\n\", '            values.append(self.buf.read(remaining))\\n', '        if len(values) == 1:\\n', '            values = values[0]\\n', '        return key, values\\n', '                values[name] = v\\n', '        return values\\n', '        while self.buf.tell() < total_length and history[-1]:\\n']",
  "context": "', ''\n        length = self.unpack_uint()\n        value_count = self.unpack_uint()\n        value_type = NVTypes(self.unpack_uint())\n "
 },
 "104": {
  "name": "value_type",
  "type": "nvlist.NVTypes",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/history.py",
  "lineno": "52",
  "column": "8",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def next_break_offset(x):\\n', '    return (x + 7) & ~7\\n', '        total_length = next_break_offset(length)\\n', '        return self.buf.read(total_length)[:length]\\n', '        length = self.unpack_uint()\\n', '        return self.unpack_fstring(length)\\n', '        pos = self.buf.tell()\\n', '        total_length = self.unpack_uint()\\n', '        if total_length == 0:\\n', '        length = self.unpack_uint()\\n', '        value_count = self.unpack_uint()\\n', '        value_type = NVTypes(self.unpack_uint())\\n', '        key = self.unpack_fstring(length)\\n', \"        key = key.rstrip('\\\\x00')\\n\", '        remaining = total_length - (self.buf.tell() - pos)\\n', '        values = []\\n', '        for v in range(value_count):\\n', '            if value_type == NVTypes.UINT64:\\n', '                value = self.unpack_uhyper()\\n', '            elif value_type == NVTypes.INT32:\\n', '                value = self.unpack_uhyper()\\n', '            elif value_type == NVTypes.STRING:\\n', '                value = self.buf.read(remaining)\\n', \"                value = value.rstrip('\\\\x00')\\n\", '            elif value_type == NVTypes.NVLIST:\\n', '                value = self.unpack_nvlist(extra=True)\\n', '            elif value_type == NVTypes.BOOLEAN:\\n', '                value = self.unpack_uhyper()\\n', \"                logger.debug('saw type', value_type, value_count, remaining)\\n\", '                value = self.buf.read(remaining)\\n', '            values.append(value)\\n', '        remaining = total_length - (self.buf.tell() - pos)\\n', '        if remaining > 0:\\n', \"            logger.debug('remains', remaining, value_count, value_type)\\n\", '            values.append(self.buf.read(remaining))\\n', '        if len(values) == 1:\\n', '            values = values[0]\\n', '        return key, values\\n', '                values[name] = v\\n', '        return values\\n', '        while self.buf.tell() < total_length and history[-1]:\\n']",
  "context": "\n        value_count = self.unpack_uint()\n        value_type = NVTypes(self.unpack_uint())\n        key = self.unpack_fstring(length)\n        "
 },
 "105": {
  "name": "remaining",
  "type": "list",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/history.py",
  "lineno": "56",
  "column": "8",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def next_break_offset(x):\\n', '    return (x + 7) & ~7\\n', '        total_length = next_break_offset(length)\\n', '        return self.buf.read(total_length)[:length]\\n', '        length = self.unpack_uint()\\n', '        return self.unpack_fstring(length)\\n', '        pos = self.buf.tell()\\n', '        total_length = self.unpack_uint()\\n', '        if total_length == 0:\\n', '        length = self.unpack_uint()\\n', '        value_count = self.unpack_uint()\\n', '        value_type = NVTypes(self.unpack_uint())\\n', '        key = self.unpack_fstring(length)\\n', \"        key = key.rstrip('\\\\x00')\\n\", '        remaining = total_length - (self.buf.tell() - pos)\\n', '        values = []\\n', '        for v in range(value_count):\\n', '            if value_type == NVTypes.UINT64:\\n', '                value = self.unpack_uhyper()\\n', '            elif value_type == NVTypes.INT32:\\n', '                value = self.unpack_uhyper()\\n', '            elif value_type == NVTypes.STRING:\\n', '                value = self.buf.read(remaining)\\n', \"                value = value.rstrip('\\\\x00')\\n\", '            elif value_type == NVTypes.NVLIST:\\n', '                value = self.unpack_nvlist(extra=True)\\n', '            elif value_type == NVTypes.BOOLEAN:\\n', '                value = self.unpack_uhyper()\\n', \"                logger.debug('saw type', value_type, value_count, remaining)\\n\", '                value = self.buf.read(remaining)\\n', '            values.append(value)\\n', '        remaining = total_length - (self.buf.tell() - pos)\\n', '        if remaining > 0:\\n', \"            logger.debug('remains', remaining, value_count, value_type)\\n\", '            values.append(self.buf.read(remaining))\\n', '        if len(values) == 1:\\n', '            values = values[0]\\n', '        return key, values\\n', '                values[name] = v\\n', '        return values\\n', '        while self.buf.tell() < total_length and history[-1]:\\n']",
  "context": "length)\n        key = key.rstrip('\\x00')\n\n        remaining = total_length - (self.buf.tell() - pos)\n\n        values = []\n        for v in range(value_"
 },
 "106": {
  "name": "values",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/history.py",
  "lineno": "58",
  "column": "8",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def next_break_offset(x):\\n', '    return (x + 7) & ~7\\n', '        total_length = next_break_offset(length)\\n', '        return self.buf.read(total_length)[:length]\\n', '        length = self.unpack_uint()\\n', '        return self.unpack_fstring(length)\\n', '        pos = self.buf.tell()\\n', '        total_length = self.unpack_uint()\\n', '        if total_length == 0:\\n', '        length = self.unpack_uint()\\n', '        value_count = self.unpack_uint()\\n', '        value_type = NVTypes(self.unpack_uint())\\n', '        key = self.unpack_fstring(length)\\n', \"        key = key.rstrip('\\\\x00')\\n\", '        remaining = total_length - (self.buf.tell() - pos)\\n', '        values = []\\n', '        for v in range(value_count):\\n', '            if value_type == NVTypes.UINT64:\\n', '                value = self.unpack_uhyper()\\n', '            elif value_type == NVTypes.INT32:\\n', '                value = self.unpack_uhyper()\\n', '            elif value_type == NVTypes.STRING:\\n', '                value = self.buf.read(remaining)\\n', \"                value = value.rstrip('\\\\x00')\\n\", '            elif value_type == NVTypes.NVLIST:\\n', '                value = self.unpack_nvlist(extra=True)\\n', '            elif value_type == NVTypes.BOOLEAN:\\n', '                value = self.unpack_uhyper()\\n', \"                logger.debug('saw type', value_type, value_count, remaining)\\n\", '                value = self.buf.read(remaining)\\n', '            values.append(value)\\n', '        remaining = total_length - (self.buf.tell() - pos)\\n', '        if remaining > 0:\\n', \"            logger.debug('remains', remaining, value_count, value_type)\\n\", '            values.append(self.buf.read(remaining))\\n', '        if len(values) == 1:\\n', '            values = values[0]\\n', '        return key, values\\n', '                values[name] = v\\n', '        return values\\n', '        while self.buf.tell() < total_length and history[-1]:\\n']",
  "context": "= total_length - (self.buf.tell() - pos)\n\n        values = []\n        for v in range(value_count):\n            i"
 },
 "107": {
  "name": "value",
  "type": "list",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/history.py",
  "lineno": "61",
  "column": "16",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def next_break_offset(x):\\n', '    return (x + 7) & ~7\\n', '        total_length = next_break_offset(length)\\n', '        return self.buf.read(total_length)[:length]\\n', '        length = self.unpack_uint()\\n', '        return self.unpack_fstring(length)\\n', '        pos = self.buf.tell()\\n', '        total_length = self.unpack_uint()\\n', '        if total_length == 0:\\n', '        length = self.unpack_uint()\\n', '        value_count = self.unpack_uint()\\n', '        value_type = NVTypes(self.unpack_uint())\\n', '        key = self.unpack_fstring(length)\\n', \"        key = key.rstrip('\\\\x00')\\n\", '        remaining = total_length - (self.buf.tell() - pos)\\n', '        values = []\\n', '        for v in range(value_count):\\n', '            if value_type == NVTypes.UINT64:\\n', '                value = self.unpack_uhyper()\\n', '            elif value_type == NVTypes.INT32:\\n', '                value = self.unpack_uhyper()\\n', '            elif value_type == NVTypes.STRING:\\n', '                value = self.buf.read(remaining)\\n', \"                value = value.rstrip('\\\\x00')\\n\", '            elif value_type == NVTypes.NVLIST:\\n', '                value = self.unpack_nvlist(extra=True)\\n', '            elif value_type == NVTypes.BOOLEAN:\\n', '                value = self.unpack_uhyper()\\n', \"                logger.debug('saw type', value_type, value_count, remaining)\\n\", '                value = self.buf.read(remaining)\\n', '            values.append(value)\\n', '        remaining = total_length - (self.buf.tell() - pos)\\n', '        if remaining > 0:\\n', \"            logger.debug('remains', remaining, value_count, value_type)\\n\", '            values.append(self.buf.read(remaining))\\n', '        if len(values) == 1:\\n', '            values = values[0]\\n', '        return key, values\\n', '                values[name] = v\\n', '        return values\\n', '        while self.buf.tell() < total_length and history[-1]:\\n']",
  "context": " if value_type == NVTypes.UINT64:\n                value = self.unpack_uhyper()\n            elif value_type == NVTypes.INT32:\n    "
 },
 "108": {
  "name": "remaining",
  "type": "list",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/history.py",
  "lineno": "76",
  "column": "8",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def next_break_offset(x):\\n', '    return (x + 7) & ~7\\n', '        total_length = next_break_offset(length)\\n', '        return self.buf.read(total_length)[:length]\\n', '        length = self.unpack_uint()\\n', '        return self.unpack_fstring(length)\\n', '        pos = self.buf.tell()\\n', '        total_length = self.unpack_uint()\\n', '        if total_length == 0:\\n', '        length = self.unpack_uint()\\n', '        value_count = self.unpack_uint()\\n', '        value_type = NVTypes(self.unpack_uint())\\n', '        key = self.unpack_fstring(length)\\n', \"        key = key.rstrip('\\\\x00')\\n\", '        remaining = total_length - (self.buf.tell() - pos)\\n', '        values = []\\n', '        for v in range(value_count):\\n', '            if value_type == NVTypes.UINT64:\\n', '                value = self.unpack_uhyper()\\n', '            elif value_type == NVTypes.INT32:\\n', '                value = self.unpack_uhyper()\\n', '            elif value_type == NVTypes.STRING:\\n', '                value = self.buf.read(remaining)\\n', \"                value = value.rstrip('\\\\x00')\\n\", '            elif value_type == NVTypes.NVLIST:\\n', '                value = self.unpack_nvlist(extra=True)\\n', '            elif value_type == NVTypes.BOOLEAN:\\n', '                value = self.unpack_uhyper()\\n', \"                logger.debug('saw type', value_type, value_count, remaining)\\n\", '                value = self.buf.read(remaining)\\n', '            values.append(value)\\n', '        remaining = total_length - (self.buf.tell() - pos)\\n', '        if remaining > 0:\\n', \"            logger.debug('remains', remaining, value_count, value_type)\\n\", '            values.append(self.buf.read(remaining))\\n', '        if len(values) == 1:\\n', '            values = values[0]\\n', '        return key, values\\n', '                values[name] = v\\n', '        return values\\n', '        while self.buf.tell() < total_length and history[-1]:\\n']",
  "context": "maining)\n            values.append(value)\n        remaining = total_length - (self.buf.tell() - pos)\n        if remaining > 0:\n            logger.debug"
 },
 "109": {
  "name": "values",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/history.py",
  "lineno": "81",
  "column": "12",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def next_break_offset(x):\\n', '    return (x + 7) & ~7\\n', '        total_length = next_break_offset(length)\\n', '        return self.buf.read(total_length)[:length]\\n', '        length = self.unpack_uint()\\n', '        return self.unpack_fstring(length)\\n', '        pos = self.buf.tell()\\n', '        total_length = self.unpack_uint()\\n', '        if total_length == 0:\\n', '        length = self.unpack_uint()\\n', '        value_count = self.unpack_uint()\\n', '        value_type = NVTypes(self.unpack_uint())\\n', '        key = self.unpack_fstring(length)\\n', \"        key = key.rstrip('\\\\x00')\\n\", '        remaining = total_length - (self.buf.tell() - pos)\\n', '        values = []\\n', '        for v in range(value_count):\\n', '            if value_type == NVTypes.UINT64:\\n', '                value = self.unpack_uhyper()\\n', '            elif value_type == NVTypes.INT32:\\n', '                value = self.unpack_uhyper()\\n', '            elif value_type == NVTypes.STRING:\\n', '                value = self.buf.read(remaining)\\n', \"                value = value.rstrip('\\\\x00')\\n\", '            elif value_type == NVTypes.NVLIST:\\n', '                value = self.unpack_nvlist(extra=True)\\n', '            elif value_type == NVTypes.BOOLEAN:\\n', '                value = self.unpack_uhyper()\\n', \"                logger.debug('saw type', value_type, value_count, remaining)\\n\", '                value = self.buf.read(remaining)\\n', '            values.append(value)\\n', '        remaining = total_length - (self.buf.tell() - pos)\\n', '        if remaining > 0:\\n', \"            logger.debug('remains', remaining, value_count, value_type)\\n\", '            values.append(self.buf.read(remaining))\\n', '        if len(values) == 1:\\n', '            values = values[0]\\n', '        return key, values\\n', '                values[name] = v\\n', '        return values\\n', '        while self.buf.tell() < total_length and history[-1]:\\n']",
  "context": "aining))\n        if len(values) == 1:\n            values = values[0]\n        return key, values\n\n    def unpack_nvlist("
 },
 "110": {
  "name": "value",
  "type": "list",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/history.py",
  "lineno": "63",
  "column": "16",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def next_break_offset(x):\\n', '    return (x + 7) & ~7\\n', '        total_length = next_break_offset(length)\\n', '        return self.buf.read(total_length)[:length]\\n', '        length = self.unpack_uint()\\n', '        return self.unpack_fstring(length)\\n', '        pos = self.buf.tell()\\n', '        total_length = self.unpack_uint()\\n', '        if total_length == 0:\\n', '        length = self.unpack_uint()\\n', '        value_count = self.unpack_uint()\\n', '        value_type = NVTypes(self.unpack_uint())\\n', '        key = self.unpack_fstring(length)\\n', \"        key = key.rstrip('\\\\x00')\\n\", '        remaining = total_length - (self.buf.tell() - pos)\\n', '        values = []\\n', '        for v in range(value_count):\\n', '            if value_type == NVTypes.UINT64:\\n', '                value = self.unpack_uhyper()\\n', '            elif value_type == NVTypes.INT32:\\n', '                value = self.unpack_uhyper()\\n', '            elif value_type == NVTypes.STRING:\\n', '                value = self.buf.read(remaining)\\n', \"                value = value.rstrip('\\\\x00')\\n\", '            elif value_type == NVTypes.NVLIST:\\n', '                value = self.unpack_nvlist(extra=True)\\n', '            elif value_type == NVTypes.BOOLEAN:\\n', '                value = self.unpack_uhyper()\\n', \"                logger.debug('saw type', value_type, value_count, remaining)\\n\", '                value = self.buf.read(remaining)\\n', '            values.append(value)\\n', '        remaining = total_length - (self.buf.tell() - pos)\\n', '        if remaining > 0:\\n', \"            logger.debug('remains', remaining, value_count, value_type)\\n\", '            values.append(self.buf.read(remaining))\\n', '        if len(values) == 1:\\n', '            values = values[0]\\n', '        return key, values\\n', '                values[name] = v\\n', '        return values\\n', '        while self.buf.tell() < total_length and history[-1]:\\n']",
  "context": "elif value_type == NVTypes.INT32:\n                value = self.unpack_uhyper()\n            elif value_type == NVTypes.STRING:\n   "
 },
 "111": {
  "name": "value",
  "type": "list",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/history.py",
  "lineno": "71",
  "column": "16",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def next_break_offset(x):\\n', '    return (x + 7) & ~7\\n', '        total_length = next_break_offset(length)\\n', '        return self.buf.read(total_length)[:length]\\n', '        length = self.unpack_uint()\\n', '        return self.unpack_fstring(length)\\n', '        pos = self.buf.tell()\\n', '        total_length = self.unpack_uint()\\n', '        if total_length == 0:\\n', '        length = self.unpack_uint()\\n', '        value_count = self.unpack_uint()\\n', '        value_type = NVTypes(self.unpack_uint())\\n', '        key = self.unpack_fstring(length)\\n', \"        key = key.rstrip('\\\\x00')\\n\", '        remaining = total_length - (self.buf.tell() - pos)\\n', '        values = []\\n', '        for v in range(value_count):\\n', '            if value_type == NVTypes.UINT64:\\n', '                value = self.unpack_uhyper()\\n', '            elif value_type == NVTypes.INT32:\\n', '                value = self.unpack_uhyper()\\n', '            elif value_type == NVTypes.STRING:\\n', '                value = self.buf.read(remaining)\\n', \"                value = value.rstrip('\\\\x00')\\n\", '            elif value_type == NVTypes.NVLIST:\\n', '                value = self.unpack_nvlist(extra=True)\\n', '            elif value_type == NVTypes.BOOLEAN:\\n', '                value = self.unpack_uhyper()\\n', \"                logger.debug('saw type', value_type, value_count, remaining)\\n\", '                value = self.buf.read(remaining)\\n', '            values.append(value)\\n', '        remaining = total_length - (self.buf.tell() - pos)\\n', '        if remaining > 0:\\n', \"            logger.debug('remains', remaining, value_count, value_type)\\n\", '            values.append(self.buf.read(remaining))\\n', '        if len(values) == 1:\\n', '            values = values[0]\\n', '        return key, values\\n', '                values[name] = v\\n', '        return values\\n', '        while self.buf.tell() < total_length and history[-1]:\\n']",
  "context": "if value_type == NVTypes.BOOLEAN:\n                value = self.unpack_uhyper()\n            else:\n                logger.debug('sa"
 },
 "112": {
  "name": "values",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/history.py",
  "lineno": "85",
  "column": "8",
  "slicing": "['        values = {}\\n', '                values[name] = v\\n', '        return values\\n']",
  "context": "    def unpack_nvlist(self, extra=False):\n        values = {}\n        this_length = self.unpack_uhyper()\n       "
 },
 "113": {
  "name": "this_length",
  "type": "list",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/history.py",
  "lineno": "86",
  "column": "8",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def next_break_offset(x):\\n', '    return (x + 7) & ~7\\n', '        total_length = next_break_offset(length)\\n', '        return self.buf.read(total_length)[:length]\\n', '        length = self.unpack_uint()\\n', '        return self.unpack_fstring(length)\\n', '        pos = self.buf.tell()\\n', '        total_length = self.unpack_uint()\\n', '        if total_length == 0:\\n', '        length = self.unpack_uint()\\n', '        value_count = self.unpack_uint()\\n', '        value_type = NVTypes(self.unpack_uint())\\n', '        key = self.unpack_fstring(length)\\n', \"        key = key.rstrip('\\\\x00')\\n\", '        remaining = total_length - (self.buf.tell() - pos)\\n', '        values = []\\n', '        for v in range(value_count):\\n', '            if value_type == NVTypes.UINT64:\\n', '                value = self.unpack_uhyper()\\n', '            elif value_type == NVTypes.INT32:\\n', '                value = self.unpack_uhyper()\\n', '            elif value_type == NVTypes.STRING:\\n', '                value = self.buf.read(remaining)\\n', \"                value = value.rstrip('\\\\x00')\\n\", '            elif value_type == NVTypes.NVLIST:\\n', '                value = self.unpack_nvlist(extra=True)\\n', '            elif value_type == NVTypes.BOOLEAN:\\n', '                value = self.unpack_uhyper()\\n', \"                logger.debug('saw type', value_type, value_count, remaining)\\n\", '                value = self.buf.read(remaining)\\n', '            values.append(value)\\n', '        remaining = total_length - (self.buf.tell() - pos)\\n', '        if remaining > 0:\\n', \"            logger.debug('remains', remaining, value_count, value_type)\\n\", '            values.append(self.buf.read(remaining))\\n', '        if len(values) == 1:\\n', '            values = values[0]\\n', '        return key, values\\n', '        values = {}\\n', '        this_length = self.unpack_uhyper()\\n', '        start = self.buf.tell()\\n', '        end_offset = start + this_length\\n', '        while self.buf.tell() <= end_offset:\\n', '                values[name] = v\\n', '        return values\\n', '        while self.buf.tell() < total_length and history[-1]:\\n']",
  "context": "t(self, extra=False):\n        values = {}\n        this_length = self.unpack_uhyper()\n        unknown2 = self.unpack_uhyper()\n        un"
 },
 "114": {
  "name": "unknown2",
  "type": "list",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/history.py",
  "lineno": "87",
  "column": "8",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def next_break_offset(x):\\n', '    return (x + 7) & ~7\\n', '        total_length = next_break_offset(length)\\n', '        return self.buf.read(total_length)[:length]\\n', '        length = self.unpack_uint()\\n', '        return self.unpack_fstring(length)\\n', '        pos = self.buf.tell()\\n', '        total_length = self.unpack_uint()\\n', '        if total_length == 0:\\n', '        length = self.unpack_uint()\\n', '        value_count = self.unpack_uint()\\n', '        value_type = NVTypes(self.unpack_uint())\\n', '        key = self.unpack_fstring(length)\\n', \"        key = key.rstrip('\\\\x00')\\n\", '        remaining = total_length - (self.buf.tell() - pos)\\n', '        values = []\\n', '        for v in range(value_count):\\n', '            if value_type == NVTypes.UINT64:\\n', '                value = self.unpack_uhyper()\\n', '            elif value_type == NVTypes.INT32:\\n', '                value = self.unpack_uhyper()\\n', '            elif value_type == NVTypes.STRING:\\n', '                value = self.buf.read(remaining)\\n', \"                value = value.rstrip('\\\\x00')\\n\", '            elif value_type == NVTypes.NVLIST:\\n', '                value = self.unpack_nvlist(extra=True)\\n', '            elif value_type == NVTypes.BOOLEAN:\\n', '                value = self.unpack_uhyper()\\n', \"                logger.debug('saw type', value_type, value_count, remaining)\\n\", '                value = self.buf.read(remaining)\\n', '            values.append(value)\\n', '        remaining = total_length - (self.buf.tell() - pos)\\n', '        if remaining > 0:\\n', \"            logger.debug('remains', remaining, value_count, value_type)\\n\", '            values.append(self.buf.read(remaining))\\n', '        if len(values) == 1:\\n', '            values = values[0]\\n', '        return key, values\\n', '        values = {}\\n', '        unknown2 = self.unpack_uhyper()\\n', '                values[name] = v\\n', '        return values\\n', '        while self.buf.tell() < total_length and history[-1]:\\n']",
  "context": "       this_length = self.unpack_uhyper()\n        unknown2 = self.unpack_uhyper()\n        unknown3 = self.unpack_uint()\n        star"
 },
 "115": {
  "name": "unknown3",
  "type": "list",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/history.py",
  "lineno": "88",
  "column": "8",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def next_break_offset(x):\\n', '    return (x + 7) & ~7\\n', '        total_length = next_break_offset(length)\\n', '        return self.buf.read(total_length)[:length]\\n', '        length = self.unpack_uint()\\n', '        return self.unpack_fstring(length)\\n', '        pos = self.buf.tell()\\n', '        total_length = self.unpack_uint()\\n', '        if total_length == 0:\\n', '        length = self.unpack_uint()\\n', '        value_count = self.unpack_uint()\\n', '        value_type = NVTypes(self.unpack_uint())\\n', '        key = self.unpack_fstring(length)\\n', \"        key = key.rstrip('\\\\x00')\\n\", '        remaining = total_length - (self.buf.tell() - pos)\\n', '        values = []\\n', '        for v in range(value_count):\\n', '            if value_type == NVTypes.UINT64:\\n', '                value = self.unpack_uhyper()\\n', '            elif value_type == NVTypes.INT32:\\n', '                value = self.unpack_uhyper()\\n', '            elif value_type == NVTypes.STRING:\\n', '                value = self.buf.read(remaining)\\n', \"                value = value.rstrip('\\\\x00')\\n\", '            elif value_type == NVTypes.NVLIST:\\n', '                value = self.unpack_nvlist(extra=True)\\n', '            elif value_type == NVTypes.BOOLEAN:\\n', '                value = self.unpack_uhyper()\\n', \"                logger.debug('saw type', value_type, value_count, remaining)\\n\", '                value = self.buf.read(remaining)\\n', '            values.append(value)\\n', '        remaining = total_length - (self.buf.tell() - pos)\\n', '        if remaining > 0:\\n', \"            logger.debug('remains', remaining, value_count, value_type)\\n\", '            values.append(self.buf.read(remaining))\\n', '        if len(values) == 1:\\n', '            values = values[0]\\n', '        return key, values\\n', '        values = {}\\n', '        unknown3 = self.unpack_uint()\\n', '                values[name] = v\\n', '        return values\\n', '        while self.buf.tell() < total_length and history[-1]:\\n']",
  "context": ")\n        unknown2 = self.unpack_uhyper()\n        unknown3 = self.unpack_uint()\n        start = self.buf.tell()\n        if extra:\n"
 },
 "116": {
  "name": "end_offset",
  "type": "list",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/history.py",
  "lineno": "92",
  "column": "8",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def next_break_offset(x):\\n', '    return (x + 7) & ~7\\n', '        total_length = next_break_offset(length)\\n', '        return self.buf.read(total_length)[:length]\\n', '        length = self.unpack_uint()\\n', '        return self.unpack_fstring(length)\\n', '        pos = self.buf.tell()\\n', '        total_length = self.unpack_uint()\\n', '        if total_length == 0:\\n', '        length = self.unpack_uint()\\n', '        value_count = self.unpack_uint()\\n', '        value_type = NVTypes(self.unpack_uint())\\n', '        key = self.unpack_fstring(length)\\n', \"        key = key.rstrip('\\\\x00')\\n\", '        remaining = total_length - (self.buf.tell() - pos)\\n', '        values = []\\n', '        for v in range(value_count):\\n', '            if value_type == NVTypes.UINT64:\\n', '                value = self.unpack_uhyper()\\n', '            elif value_type == NVTypes.INT32:\\n', '                value = self.unpack_uhyper()\\n', '            elif value_type == NVTypes.STRING:\\n', '                value = self.buf.read(remaining)\\n', \"                value = value.rstrip('\\\\x00')\\n\", '            elif value_type == NVTypes.NVLIST:\\n', '                value = self.unpack_nvlist(extra=True)\\n', '            elif value_type == NVTypes.BOOLEAN:\\n', '                value = self.unpack_uhyper()\\n', \"                logger.debug('saw type', value_type, value_count, remaining)\\n\", '                value = self.buf.read(remaining)\\n', '            values.append(value)\\n', '        remaining = total_length - (self.buf.tell() - pos)\\n', '        if remaining > 0:\\n', \"            logger.debug('remains', remaining, value_count, value_type)\\n\", '            values.append(self.buf.read(remaining))\\n', '        if len(values) == 1:\\n', '            values = values[0]\\n', '        return key, values\\n', '        values = {}\\n', '        this_length = self.unpack_uhyper()\\n', '        start = self.buf.tell()\\n', '        end_offset = start + this_length\\n', '        while self.buf.tell() <= end_offset:\\n', '                values[name] = v\\n', '        return values\\n', '        while self.buf.tell() < total_length and history[-1]:\\n']",
  "context": " if extra:\n            self.unpack_uint()\n        end_offset = start + this_length\n        while self.buf.tell() <= end_offset:\n     "
 },
 "117": {
  "name": "total_length",
  "type": "int",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/history.py",
  "lineno": "102",
  "column": "8",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def next_break_offset(x):\\n', '    return (x + 7) & ~7\\n', '        total_length = next_break_offset(length)\\n', '        return self.buf.read(total_length)[:length]\\n', '        length = self.unpack_uint()\\n', '        return self.unpack_fstring(length)\\n', '        pos = self.buf.tell()\\n', '        total_length = self.unpack_uint()\\n', '        if total_length == 0:\\n', '        length = self.unpack_uint()\\n', '        value_count = self.unpack_uint()\\n', '        value_type = NVTypes(self.unpack_uint())\\n', '        key = self.unpack_fstring(length)\\n', \"        key = key.rstrip('\\\\x00')\\n\", '        remaining = total_length - (self.buf.tell() - pos)\\n', '        values = []\\n', '        for v in range(value_count):\\n', '            if value_type == NVTypes.UINT64:\\n', '                value = self.unpack_uhyper()\\n', '            elif value_type == NVTypes.INT32:\\n', '                value = self.unpack_uhyper()\\n', '            elif value_type == NVTypes.STRING:\\n', '                value = self.buf.read(remaining)\\n', \"                value = value.rstrip('\\\\x00')\\n\", '            elif value_type == NVTypes.NVLIST:\\n', '                value = self.unpack_nvlist(extra=True)\\n', '            elif value_type == NVTypes.BOOLEAN:\\n', '                value = self.unpack_uhyper()\\n', \"                logger.debug('saw type', value_type, value_count, remaining)\\n\", '                value = self.buf.read(remaining)\\n', '            values.append(value)\\n', '        remaining = total_length - (self.buf.tell() - pos)\\n', '        if remaining > 0:\\n', \"            logger.debug('remains', remaining, value_count, value_type)\\n\", '            values.append(self.buf.read(remaining))\\n', '        if len(values) == 1:\\n', '            values = values[0]\\n', '        return key, values\\n', '        values = {}\\n', '        this_length = self.unpack_uhyper()\\n', '        start = self.buf.tell()\\n', '        end_offset = start + this_length\\n', '        while self.buf.tell() <= end_offset:\\n', '            name, v = self.unpack_value()\\n', '            if name:\\n', '                values[name] = v\\n', '        return values\\n', '        total_length = len(self.buf.getvalue()) - 24\\n', '        while self.buf.tell() < total_length and history[-1]:\\n']",
  "context": "urn values\n\n    def unpack_history(self):\n        total_length = len(self.buf.getvalue()) - 24\n        history = [True]\n        while self.buf.te"
 },
 "118": {
  "name": "history",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/history.py",
  "lineno": "103",
  "column": "8",
  "slicing": "['        history = [True]\\n', '        while self.buf.tell() < total_length and history[-1]:\\n', '            history.append(self.unpack_nvlist())\\n', '        return history[1:-1]\\n']",
  "context": "al_length = len(self.buf.getvalue()) - 24\n        history = [True]\n        while self.buf.tell() < total_length and h"
 },
 "119": {
  "name": "read_all_dvas",
  "type": "bool",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/constants.py",
  "lineno": "47",
  "column": "4",
  "slicing": "['    read_all_dvas = True\\n']",
  "context": " 2\n    ZVOL = 3\n\n\nclass TryConfig(enum.Enum):\n    read_all_dvas = True\n\n\nclass ObjectType(enum.IntEnum):\n    NONE = 0\n   "
 },
 "120": {
  "name": "lz4",
  "type": "None",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/util.py",
  "lineno": "23",
  "column": "4",
  "slicing": "['    lz4 = None\\n', '    elif mode == Compression.LZ4 and lz4:\\n', \"        return lz4.block.decompress(struct.pack('<i', size) + data)\\n\", '        if mode == Compression.LZ4 and not lz4:\\n']",
  "context": " lz4\n    import lz4.block\nexcept ImportError:\n    lz4 = None\n    logger.warn(\"import lz4 failed, lz4 decompress"
 },
 "121": {
  "name": "data",
  "type": "bytes",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/util.py",
  "lineno": "30",
  "column": "15",
  "slicing": "['def decompress(data: bytes, mode: Compression, size: int, inherit=None) -> bytes:\\n']",
  "context": " __import__('itertools').count()\n\n\ndef decompress(data: bytes, mode: Compression, size: int, inherit=None) -> bytes:\n    if mode == Compression.INHERIT:\n        mode ="
 },
 "122": {
  "name": "mode",
  "type": "constants.Compression",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/util.py",
  "lineno": "30",
  "column": "28",
  "slicing": "['def decompress(data: bytes, mode: Compression, size: int, inherit=None) -> bytes:\\n']",
  "context": "itertools').count()\n\n\ndef decompress(data: bytes, mode: Compression, size: int, inherit=None) -> bytes:\n    if mode == Compression.INHERIT:\n        mode ="
 },
 "123": {
  "name": "size",
  "type": "int",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/util.py",
  "lineno": "30",
  "column": "47",
  "slicing": "['def decompress(data: bytes, mode: Compression, size: int, inherit=None) -> bytes:\\n']",
  "context": "\n\n\ndef decompress(data: bytes, mode: Compression, size: int, inherit=None) -> bytes:\n    if mode == Compression.INHERIT:\n        mode ="
 },
 "124": {
  "name": "mode",
  "type": "inherit",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/util.py",
  "lineno": "32",
  "column": "8",
  "slicing": "['logger = logging.getLogger(__name__)\\n', '    logger.warn(\"import lz4 failed, lz4 decompression will not be available.\")\\n', '        mode = inherit\\n', '    if mode in (Compression.ON, Compression.LZJB):\\n', '    elif mode == Compression.LZ4 and lz4:\\n', \"    elif mode.name.startswith('GZIP_'):\\n\", '    elif mode == Compression.OFF:\\n', '        if mode == Compression.LZ4 and not lz4:\\n', '        raise ValueError(mode)\\n', '    if mode == Checksum.INHERIT:\\n', '    if mode == Checksum.FLETCHER_4:\\n', '    elif mode == Checksum.FLETCHER_2:\\n', '    elif mode == Checksum.SHA256:\\n', '    elif mode == Checksum.OFF:\\n', '        raise ValueError(mode)\\n']",
  "context": "ytes:\n    if mode == Compression.INHERIT:\n        mode = inherit\n    if mode in (Compression.ON, Compression.LZJB):"
 },
 "125": {
  "name": "length",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/util.py",
  "lineno": "36",
  "column": "8",
  "slicing": "['logger = logging.getLogger(__name__)\\n', '    lz4 = None\\n', '    logger.warn(\"import lz4 failed, lz4 decompression will not be available.\")\\n', '        mode = inherit\\n', '    if mode in (Compression.ON, Compression.LZJB):\\n', '    elif mode == Compression.LZ4 and lz4:\\n', \"        length = struct.unpack('>I', data[:4])[0]\\n\", '        data = data[4:length + 4]\\n', \"        return lz4.block.decompress(struct.pack('<i', size) + data)\\n\", \"    elif mode.name.startswith('GZIP_'):\\n\", '        data = zlib.decompress(data)\\n', '        return data[:size]\\n', '    elif mode == Compression.OFF:\\n', '        return data\\n', '        if mode == Compression.LZ4 and not lz4:\\n', '        raise ValueError(mode)\\n', 'ChecksumType = Tuple[int, int, int, int]\\n', '            valid: ChecksumType,\\n', '            chk: ChecksumType=None\\n', '    valid = tuple(valid)\\n', '    if mode == Checksum.INHERIT:\\n', '        mode = inherit\\n', '    if mode == Checksum.FLETCHER_4:\\n', '        chk = fletcher4(data)\\n', '    elif mode == Checksum.FLETCHER_2:\\n', '        chk = fletcher2(data)\\n', '    elif mode == Checksum.SHA256:\\n', '        chk = sha256(data)\\n', '    elif mode == Checksum.OFF:\\n', '        raise ValueError(mode)\\n', '    return all(c == v for c, v in zip(chk, valid))\\n', 'def sha256(data: bytes) -> ChecksumType:\\n', \"    return struct.unpack('>QQQQ', hashlib.sha256(data).digest())\\n\", 'def unpack(data: bytes, code: str):\\n', '    s = struct.calcsize(code)\\n', '    return struct.unpack(code*int(len(data)/s), data)\\n', 'def fletcher2(data: bytes) -> ChecksumType:\\n', '    mod = 1 << 64\\n', \"    un_data = list(unpack(data, 'Q'))\\n\", '    a = 0\\n', '    b = 0\\n', '    c = 0\\n', '    d = 0\\n', '    for first, second in zip(un_data[0::2], un_data[1::2]):\\n', '        a = (a + first) % mod\\n', '        b = (b + second) % mod\\n', '        c = (c + a) % mod\\n', '        d = (d + b) % mod\\n', '    return a, b, c, d\\n', 'def fletcher4(data: bytes) -> ChecksumType:\\n', '    mod = 1 << 64\\n', '    a = 0\\n', '    b = 0\\n', '    c = 0\\n', '    d = 0\\n', \"    for w in unpack(data, 'I'):\\n\", '        a = (a + w) % mod\\n', '        b = (b + a) % mod\\n', '        c = (c + b) % mod\\n', '        d = (d + c) % mod\\n', '    return a, b, c, d\\n']",
  "context": "    elif mode == Compression.LZ4 and lz4:\n        length = struct.unpack('>I', data[:4])[0]\n        data = data[4:length + 4]\n        return l"
 },
 "126": {
  "name": "data",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/util.py",
  "lineno": "37",
  "column": "8",
  "slicing": "['logger = logging.getLogger(__name__)\\n', '    lz4 = None\\n', '    logger.warn(\"import lz4 failed, lz4 decompression will not be available.\")\\n', '        mode = inherit\\n', '    if mode in (Compression.ON, Compression.LZJB):\\n', '    elif mode == Compression.LZ4 and lz4:\\n', \"        length = struct.unpack('>I', data[:4])[0]\\n\", '        data = data[4:length + 4]\\n', \"        return lz4.block.decompress(struct.pack('<i', size) + data)\\n\", \"    elif mode.name.startswith('GZIP_'):\\n\", '        data = zlib.decompress(data)\\n', '        return data[:size]\\n', '    elif mode == Compression.OFF:\\n', '        return data\\n', '        if mode == Compression.LZ4 and not lz4:\\n', '        raise ValueError(mode)\\n', 'ChecksumType = Tuple[int, int, int, int]\\n', '            valid: ChecksumType,\\n', '            chk: ChecksumType=None\\n', '    valid = tuple(valid)\\n', '    if mode == Checksum.INHERIT:\\n', '        mode = inherit\\n', '    if mode == Checksum.FLETCHER_4:\\n', '        chk = fletcher4(data)\\n', '    elif mode == Checksum.FLETCHER_2:\\n', '        chk = fletcher2(data)\\n', '    elif mode == Checksum.SHA256:\\n', '        chk = sha256(data)\\n', '    elif mode == Checksum.OFF:\\n', '        raise ValueError(mode)\\n', '    return all(c == v for c, v in zip(chk, valid))\\n', 'def sha256(data: bytes) -> ChecksumType:\\n', \"    return struct.unpack('>QQQQ', hashlib.sha256(data).digest())\\n\", 'def unpack(data: bytes, code: str):\\n', '    s = struct.calcsize(code)\\n', '    return struct.unpack(code*int(len(data)/s), data)\\n', 'def fletcher2(data: bytes) -> ChecksumType:\\n', '    mod = 1 << 64\\n', \"    un_data = list(unpack(data, 'Q'))\\n\", '    a = 0\\n', '    b = 0\\n', '    c = 0\\n', '    d = 0\\n', '    for first, second in zip(un_data[0::2], un_data[1::2]):\\n', '        a = (a + first) % mod\\n', '        b = (b + second) % mod\\n', '        c = (c + a) % mod\\n', '        d = (d + b) % mod\\n', '    return a, b, c, d\\n', 'def fletcher4(data: bytes) -> ChecksumType:\\n', '    mod = 1 << 64\\n', '    a = 0\\n', '    b = 0\\n', '    c = 0\\n', '    d = 0\\n', \"    for w in unpack(data, 'I'):\\n\", '        a = (a + w) % mod\\n', '        b = (b + a) % mod\\n', '        c = (c + b) % mod\\n', '        d = (d + c) % mod\\n', '    return a, b, c, d\\n']",
  "context": "length = struct.unpack('>I', data[:4])[0]\n        data = data[4:length + 4]\n        return lz4.block.decompress(struct.pack('<"
 },
 "127": {
  "name": "data",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/util.py",
  "lineno": "40",
  "column": "8",
  "slicing": "['logger = logging.getLogger(__name__)\\n', '    lz4 = None\\n', '    logger.warn(\"import lz4 failed, lz4 decompression will not be available.\")\\n', '        mode = inherit\\n', '    if mode in (Compression.ON, Compression.LZJB):\\n', '    elif mode == Compression.LZ4 and lz4:\\n', \"        length = struct.unpack('>I', data[:4])[0]\\n\", '        data = data[4:length + 4]\\n', \"        return lz4.block.decompress(struct.pack('<i', size) + data)\\n\", \"    elif mode.name.startswith('GZIP_'):\\n\", '        data = zlib.decompress(data)\\n', '        return data[:size]\\n', '    elif mode == Compression.OFF:\\n', '        return data\\n', '        if mode == Compression.LZ4 and not lz4:\\n', '        raise ValueError(mode)\\n', 'ChecksumType = Tuple[int, int, int, int]\\n', '            valid: ChecksumType,\\n', '            chk: ChecksumType=None\\n', '    valid = tuple(valid)\\n', '    if mode == Checksum.INHERIT:\\n', '        mode = inherit\\n', '    if mode == Checksum.FLETCHER_4:\\n', '        chk = fletcher4(data)\\n', '    elif mode == Checksum.FLETCHER_2:\\n', '        chk = fletcher2(data)\\n', '    elif mode == Checksum.SHA256:\\n', '        chk = sha256(data)\\n', '    elif mode == Checksum.OFF:\\n', '        raise ValueError(mode)\\n', '    return all(c == v for c, v in zip(chk, valid))\\n', 'def sha256(data: bytes) -> ChecksumType:\\n', \"    return struct.unpack('>QQQQ', hashlib.sha256(data).digest())\\n\", 'def unpack(data: bytes, code: str):\\n', '    s = struct.calcsize(code)\\n', '    return struct.unpack(code*int(len(data)/s), data)\\n', 'def fletcher2(data: bytes) -> ChecksumType:\\n', '    mod = 1 << 64\\n', \"    un_data = list(unpack(data, 'Q'))\\n\", '    a = 0\\n', '    b = 0\\n', '    c = 0\\n', '    d = 0\\n', '    for first, second in zip(un_data[0::2], un_data[1::2]):\\n', '        a = (a + first) % mod\\n', '        b = (b + second) % mod\\n', '        c = (c + a) % mod\\n', '        d = (d + b) % mod\\n', '    return a, b, c, d\\n', 'def fletcher4(data: bytes) -> ChecksumType:\\n', '    mod = 1 << 64\\n', '    a = 0\\n', '    b = 0\\n', '    c = 0\\n', '    d = 0\\n', \"    for w in unpack(data, 'I'):\\n\", '        a = (a + w) % mod\\n', '        b = (b + a) % mod\\n', '        c = (c + b) % mod\\n', '        d = (d + c) % mod\\n', '    return a, b, c, d\\n']",
  "context": ")\n    elif mode.name.startswith('GZIP_'):\n        data = zlib.decompress(data)\n        return data[:size]\n    elif mode == Compre"
 },
 "128": {
  "name": "ChecksumType",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/util.py",
  "lineno": "50",
  "column": "0",
  "slicing": "['logger = logging.getLogger(__name__)\\n', '    lz4 = None\\n', '    logger.warn(\"import lz4 failed, lz4 decompression will not be available.\")\\n', '        mode = inherit\\n', '    if mode in (Compression.ON, Compression.LZJB):\\n', '    elif mode == Compression.LZ4 and lz4:\\n', \"        length = struct.unpack('>I', data[:4])[0]\\n\", '        data = data[4:length + 4]\\n', \"        return lz4.block.decompress(struct.pack('<i', size) + data)\\n\", \"    elif mode.name.startswith('GZIP_'):\\n\", '        data = zlib.decompress(data)\\n', '        return data[:size]\\n', '    elif mode == Compression.OFF:\\n', '        return data\\n', '        if mode == Compression.LZ4 and not lz4:\\n', '        raise ValueError(mode)\\n', 'ChecksumType = Tuple[int, int, int, int]\\n', '            valid: ChecksumType,\\n', '            chk: ChecksumType=None\\n', '    valid = tuple(valid)\\n', '    if mode == Checksum.INHERIT:\\n', '        mode = inherit\\n', '    if mode == Checksum.FLETCHER_4:\\n', '        chk = fletcher4(data)\\n', '    elif mode == Checksum.FLETCHER_2:\\n', '        chk = fletcher2(data)\\n', '    elif mode == Checksum.SHA256:\\n', '        chk = sha256(data)\\n', '    elif mode == Checksum.OFF:\\n', '        raise ValueError(mode)\\n', '    return all(c == v for c, v in zip(chk, valid))\\n', 'def sha256(data: bytes) -> ChecksumType:\\n', \"    return struct.unpack('>QQQQ', hashlib.sha256(data).digest())\\n\", 'def unpack(data: bytes, code: str):\\n', '    s = struct.calcsize(code)\\n', '    return struct.unpack(code*int(len(data)/s), data)\\n', 'def fletcher2(data: bytes) -> ChecksumType:\\n', '    mod = 1 << 64\\n', \"    un_data = list(unpack(data, 'Q'))\\n\", '    a = 0\\n', '    b = 0\\n', '    c = 0\\n', '    d = 0\\n', '    for first, second in zip(un_data[0::2], un_data[1::2]):\\n', '        a = (a + first) % mod\\n', '        b = (b + second) % mod\\n', '        c = (c + a) % mod\\n', '        d = (d + b) % mod\\n', '    return a, b, c, d\\n', 'def fletcher4(data: bytes) -> ChecksumType:\\n', '    mod = 1 << 64\\n', '    a = 0\\n', '    b = 0\\n', '    c = 0\\n', '    d = 0\\n', \"    for w in unpack(data, 'I'):\\n\", '        a = (a + w) % mod\\n', '        b = (b + a) % mod\\n', '        c = (c + b) % mod\\n', '        d = (d + c) % mod\\n', '    return a, b, c, d\\n']",
  "context": "lz4` available\")\n        raise ValueError(mode)\n\n\nChecksumType = Tuple[int, int, int, int]\n\n\ndef checksum(data: bytes,\n            valid: Che"
 },
 "129": {
  "name": "data",
  "type": "bytes",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/util.py",
  "lineno": "53",
  "column": "13",
  "slicing": "['def checksum(data: bytes,\\n']",
  "context": "umType = Tuple[int, int, int, int]\n\n\ndef checksum(data: bytes,\n            valid: ChecksumType,\n            mode:"
 },
 "130": {
  "name": "valid",
  "type": "ChecksumType",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/util.py",
  "lineno": "54",
  "column": "12",
  "slicing": "['            valid: ChecksumType,\\n']",
  "context": "int, int]\n\n\ndef checksum(data: bytes,\n            valid: ChecksumType,\n            mode: Checksum,\n            inherit: C"
 },
 "131": {
  "name": "mode",
  "type": "constants.Checksum",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/util.py",
  "lineno": "55",
  "column": "12",
  "slicing": "['            mode: Checksum,\\n']",
  "context": "tes,\n            valid: ChecksumType,\n            mode: Checksum,\n            inherit: Checksum=None,\n            ch"
 },
 "132": {
  "name": "inherit",
  "type": "constants.Checksum",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/util.py",
  "lineno": "56",
  "column": "12",
  "slicing": "['            inherit: Checksum=None,\\n']",
  "context": "ksumType,\n            mode: Checksum,\n            inherit: Checksum=None,\n            chk: ChecksumType=None\n    ) -> bool:\n"
 },
 "133": {
  "name": "chk",
  "type": "ChecksumType",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/util.py",
  "lineno": "57",
  "column": "12",
  "slicing": "['            chk: ChecksumType=None\\n']",
  "context": ",\n            inherit: Checksum=None,\n            chk: ChecksumType=None\n    ) -> bool:\n    valid = tuple(valid)\n    if mod"
 },
 "134": {
  "name": "valid",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/util.py",
  "lineno": "59",
  "column": "4",
  "slicing": "['logger = logging.getLogger(__name__)\\n', '    lz4 = None\\n', '    logger.warn(\"import lz4 failed, lz4 decompression will not be available.\")\\n', '        mode = inherit\\n', '    if mode in (Compression.ON, Compression.LZJB):\\n', '    elif mode == Compression.LZ4 and lz4:\\n', \"        length = struct.unpack('>I', data[:4])[0]\\n\", '        data = data[4:length + 4]\\n', \"        return lz4.block.decompress(struct.pack('<i', size) + data)\\n\", \"    elif mode.name.startswith('GZIP_'):\\n\", '        data = zlib.decompress(data)\\n', '        return data[:size]\\n', '    elif mode == Compression.OFF:\\n', '        return data\\n', '        if mode == Compression.LZ4 and not lz4:\\n', '        raise ValueError(mode)\\n', 'ChecksumType = Tuple[int, int, int, int]\\n', '            valid: ChecksumType,\\n', '            chk: ChecksumType=None\\n', '    valid = tuple(valid)\\n', '    if mode == Checksum.INHERIT:\\n', '        mode = inherit\\n', '    if mode == Checksum.FLETCHER_4:\\n', '        chk = fletcher4(data)\\n', '    elif mode == Checksum.FLETCHER_2:\\n', '        chk = fletcher2(data)\\n', '    elif mode == Checksum.SHA256:\\n', '        chk = sha256(data)\\n', '    elif mode == Checksum.OFF:\\n', '        raise ValueError(mode)\\n', '    return all(c == v for c, v in zip(chk, valid))\\n', 'def sha256(data: bytes) -> ChecksumType:\\n', \"    return struct.unpack('>QQQQ', hashlib.sha256(data).digest())\\n\", 'def unpack(data: bytes, code: str):\\n', '    s = struct.calcsize(code)\\n', '    return struct.unpack(code*int(len(data)/s), data)\\n', 'def fletcher2(data: bytes) -> ChecksumType:\\n', '    mod = 1 << 64\\n', \"    un_data = list(unpack(data, 'Q'))\\n\", '    a = 0\\n', '    b = 0\\n', '    c = 0\\n', '    d = 0\\n', '    for first, second in zip(un_data[0::2], un_data[1::2]):\\n', '        a = (a + first) % mod\\n', '        b = (b + second) % mod\\n', '        c = (c + a) % mod\\n', '        d = (d + b) % mod\\n', '    return a, b, c, d\\n', 'def fletcher4(data: bytes) -> ChecksumType:\\n', '    mod = 1 << 64\\n', '    a = 0\\n', '    b = 0\\n', '    c = 0\\n', '    d = 0\\n', \"    for w in unpack(data, 'I'):\\n\", '        a = (a + w) % mod\\n', '        b = (b + a) % mod\\n', '        c = (c + b) % mod\\n', '        d = (d + c) % mod\\n', '    return a, b, c, d\\n']",
  "context": "        chk: ChecksumType=None\n    ) -> bool:\n    valid = tuple(valid)\n    if mode == Checksum.INHERIT:\n        mode = in"
 },
 "135": {
  "name": "mode",
  "type": "inherit",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/util.py",
  "lineno": "61",
  "column": "8",
  "slicing": "['logger = logging.getLogger(__name__)\\n', '    lz4 = None\\n', '    logger.warn(\"import lz4 failed, lz4 decompression will not be available.\")\\n', '        mode = inherit\\n', '    if mode in (Compression.ON, Compression.LZJB):\\n', '    elif mode == Compression.LZ4 and lz4:\\n', \"        length = struct.unpack('>I', data[:4])[0]\\n\", '        data = data[4:length + 4]\\n', \"        return lz4.block.decompress(struct.pack('<i', size) + data)\\n\", \"    elif mode.name.startswith('GZIP_'):\\n\", '        data = zlib.decompress(data)\\n', '        return data[:size]\\n', '    elif mode == Compression.OFF:\\n', '        return data\\n', '        if mode == Compression.LZ4 and not lz4:\\n', '        raise ValueError(mode)\\n', 'ChecksumType = Tuple[int, int, int, int]\\n', '            valid: ChecksumType,\\n', '            chk: ChecksumType=None\\n', '    valid = tuple(valid)\\n', '    if mode == Checksum.INHERIT:\\n', '        mode = inherit\\n', '    if mode == Checksum.FLETCHER_4:\\n', '        chk = fletcher4(data)\\n', '    elif mode == Checksum.FLETCHER_2:\\n', '        chk = fletcher2(data)\\n', '    elif mode == Checksum.SHA256:\\n', '        chk = sha256(data)\\n', '    elif mode == Checksum.OFF:\\n', '        raise ValueError(mode)\\n', '    return all(c == v for c, v in zip(chk, valid))\\n', 'def sha256(data: bytes) -> ChecksumType:\\n', \"    return struct.unpack('>QQQQ', hashlib.sha256(data).digest())\\n\", 'def unpack(data: bytes, code: str):\\n', '    s = struct.calcsize(code)\\n', '    return struct.unpack(code*int(len(data)/s), data)\\n', 'def fletcher2(data: bytes) -> ChecksumType:\\n', '    mod = 1 << 64\\n', \"    un_data = list(unpack(data, 'Q'))\\n\", '    a = 0\\n', '    b = 0\\n', '    c = 0\\n', '    d = 0\\n', '    for first, second in zip(un_data[0::2], un_data[1::2]):\\n', '        a = (a + first) % mod\\n', '        b = (b + second) % mod\\n', '        c = (c + a) % mod\\n', '        d = (d + b) % mod\\n', '    return a, b, c, d\\n', 'def fletcher4(data: bytes) -> ChecksumType:\\n', '    mod = 1 << 64\\n', '    a = 0\\n', '    b = 0\\n', '    c = 0\\n', '    d = 0\\n', \"    for w in unpack(data, 'I'):\\n\", '        a = (a + w) % mod\\n', '        b = (b + a) % mod\\n', '        c = (c + b) % mod\\n', '        d = (d + c) % mod\\n', '    return a, b, c, d\\n']",
  "context": "e(valid)\n    if mode == Checksum.INHERIT:\n        mode = inherit\n    if mode == Checksum.FLETCHER_4:\n        chk = "
 },
 "136": {
  "name": "chk",
  "type": "fletcher4",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/util.py",
  "lineno": "63",
  "column": "8",
  "slicing": "['logger = logging.getLogger(__name__)\\n', '    lz4 = None\\n', '    logger.warn(\"import lz4 failed, lz4 decompression will not be available.\")\\n', '        mode = inherit\\n', '    if mode in (Compression.ON, Compression.LZJB):\\n', '    elif mode == Compression.LZ4 and lz4:\\n', \"        length = struct.unpack('>I', data[:4])[0]\\n\", '        data = data[4:length + 4]\\n', \"        return lz4.block.decompress(struct.pack('<i', size) + data)\\n\", \"    elif mode.name.startswith('GZIP_'):\\n\", '        data = zlib.decompress(data)\\n', '        return data[:size]\\n', '    elif mode == Compression.OFF:\\n', '        return data\\n', '        if mode == Compression.LZ4 and not lz4:\\n', '        raise ValueError(mode)\\n', 'ChecksumType = Tuple[int, int, int, int]\\n', '            valid: ChecksumType,\\n', '            chk: ChecksumType=None\\n', '    valid = tuple(valid)\\n', '    if mode == Checksum.INHERIT:\\n', '        mode = inherit\\n', '    if mode == Checksum.FLETCHER_4:\\n', '        chk = fletcher4(data)\\n', '    elif mode == Checksum.FLETCHER_2:\\n', '        chk = fletcher2(data)\\n', '    elif mode == Checksum.SHA256:\\n', '        chk = sha256(data)\\n', '    elif mode == Checksum.OFF:\\n', '        raise ValueError(mode)\\n', '    return all(c == v for c, v in zip(chk, valid))\\n', 'def sha256(data: bytes) -> ChecksumType:\\n', \"    return struct.unpack('>QQQQ', hashlib.sha256(data).digest())\\n\", 'def unpack(data: bytes, code: str):\\n', '    s = struct.calcsize(code)\\n', '    return struct.unpack(code*int(len(data)/s), data)\\n', 'def fletcher2(data: bytes) -> ChecksumType:\\n', '    mod = 1 << 64\\n', \"    un_data = list(unpack(data, 'Q'))\\n\", '    a = 0\\n', '    b = 0\\n', '    c = 0\\n', '    d = 0\\n', '    for first, second in zip(un_data[0::2], un_data[1::2]):\\n', '        a = (a + first) % mod\\n', '        b = (b + second) % mod\\n', '        c = (c + a) % mod\\n', '        d = (d + b) % mod\\n', '    return a, b, c, d\\n', 'def fletcher4(data: bytes) -> ChecksumType:\\n', '    mod = 1 << 64\\n', '    a = 0\\n', '    b = 0\\n', '    c = 0\\n', '    d = 0\\n', \"    for w in unpack(data, 'I'):\\n\", '        a = (a + w) % mod\\n', '        b = (b + a) % mod\\n', '        c = (c + b) % mod\\n', '        d = (d + c) % mod\\n', '    return a, b, c, d\\n']",
  "context": "herit\n    if mode == Checksum.FLETCHER_4:\n        chk = fletcher4(data)\n    elif mode == Checksum.FLETCHER_2:\n        chk "
 },
 "137": {
  "name": "chk",
  "type": "fletcher2",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/util.py",
  "lineno": "65",
  "column": "8",
  "slicing": "['logger = logging.getLogger(__name__)\\n', '    lz4 = None\\n', '    logger.warn(\"import lz4 failed, lz4 decompression will not be available.\")\\n', '        mode = inherit\\n', '    if mode in (Compression.ON, Compression.LZJB):\\n', '    elif mode == Compression.LZ4 and lz4:\\n', \"        length = struct.unpack('>I', data[:4])[0]\\n\", '        data = data[4:length + 4]\\n', \"        return lz4.block.decompress(struct.pack('<i', size) + data)\\n\", \"    elif mode.name.startswith('GZIP_'):\\n\", '        data = zlib.decompress(data)\\n', '        return data[:size]\\n', '    elif mode == Compression.OFF:\\n', '        return data\\n', '        if mode == Compression.LZ4 and not lz4:\\n', '        raise ValueError(mode)\\n', 'ChecksumType = Tuple[int, int, int, int]\\n', '            valid: ChecksumType,\\n', '            chk: ChecksumType=None\\n', '    valid = tuple(valid)\\n', '    if mode == Checksum.INHERIT:\\n', '        mode = inherit\\n', '    if mode == Checksum.FLETCHER_4:\\n', '        chk = fletcher4(data)\\n', '    elif mode == Checksum.FLETCHER_2:\\n', '        chk = fletcher2(data)\\n', '    elif mode == Checksum.SHA256:\\n', '        chk = sha256(data)\\n', '    elif mode == Checksum.OFF:\\n', '        raise ValueError(mode)\\n', '    return all(c == v for c, v in zip(chk, valid))\\n', 'def sha256(data: bytes) -> ChecksumType:\\n', \"    return struct.unpack('>QQQQ', hashlib.sha256(data).digest())\\n\", 'def unpack(data: bytes, code: str):\\n', '    s = struct.calcsize(code)\\n', '    return struct.unpack(code*int(len(data)/s), data)\\n', 'def fletcher2(data: bytes) -> ChecksumType:\\n', '    mod = 1 << 64\\n', \"    un_data = list(unpack(data, 'Q'))\\n\", '    a = 0\\n', '    b = 0\\n', '    c = 0\\n', '    d = 0\\n', '    for first, second in zip(un_data[0::2], un_data[1::2]):\\n', '        a = (a + first) % mod\\n', '        b = (b + second) % mod\\n', '        c = (c + a) % mod\\n', '        d = (d + b) % mod\\n', '    return a, b, c, d\\n', 'def fletcher4(data: bytes) -> ChecksumType:\\n', '    mod = 1 << 64\\n', '    a = 0\\n', '    b = 0\\n', '    c = 0\\n', '    d = 0\\n', \"    for w in unpack(data, 'I'):\\n\", '        a = (a + w) % mod\\n', '        b = (b + a) % mod\\n', '        c = (c + b) % mod\\n', '        d = (d + c) % mod\\n', '    return a, b, c, d\\n']",
  "context": "ta)\n    elif mode == Checksum.FLETCHER_2:\n        chk = fletcher2(data)\n    elif mode == Checksum.SHA256:\n        chk = sh"
 },
 "138": {
  "name": "chk",
  "type": "sha256",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/util.py",
  "lineno": "67",
  "column": "8",
  "slicing": "['logger = logging.getLogger(__name__)\\n', '    lz4 = None\\n', '    logger.warn(\"import lz4 failed, lz4 decompression will not be available.\")\\n', '        mode = inherit\\n', '    if mode in (Compression.ON, Compression.LZJB):\\n', '    elif mode == Compression.LZ4 and lz4:\\n', \"        length = struct.unpack('>I', data[:4])[0]\\n\", '        data = data[4:length + 4]\\n', \"        return lz4.block.decompress(struct.pack('<i', size) + data)\\n\", \"    elif mode.name.startswith('GZIP_'):\\n\", '        data = zlib.decompress(data)\\n', '        return data[:size]\\n', '    elif mode == Compression.OFF:\\n', '        return data\\n', '        if mode == Compression.LZ4 and not lz4:\\n', '        raise ValueError(mode)\\n', 'ChecksumType = Tuple[int, int, int, int]\\n', '            valid: ChecksumType,\\n', '            chk: ChecksumType=None\\n', '    valid = tuple(valid)\\n', '    if mode == Checksum.INHERIT:\\n', '        mode = inherit\\n', '    if mode == Checksum.FLETCHER_4:\\n', '        chk = fletcher4(data)\\n', '    elif mode == Checksum.FLETCHER_2:\\n', '        chk = fletcher2(data)\\n', '    elif mode == Checksum.SHA256:\\n', '        chk = sha256(data)\\n', '    elif mode == Checksum.OFF:\\n', '        raise ValueError(mode)\\n', '    return all(c == v for c, v in zip(chk, valid))\\n', 'def sha256(data: bytes) -> ChecksumType:\\n', \"    return struct.unpack('>QQQQ', hashlib.sha256(data).digest())\\n\", 'def unpack(data: bytes, code: str):\\n', '    s = struct.calcsize(code)\\n', '    return struct.unpack(code*int(len(data)/s), data)\\n', 'def fletcher2(data: bytes) -> ChecksumType:\\n', '    mod = 1 << 64\\n', \"    un_data = list(unpack(data, 'Q'))\\n\", '    a = 0\\n', '    b = 0\\n', '    c = 0\\n', '    d = 0\\n', '    for first, second in zip(un_data[0::2], un_data[1::2]):\\n', '        a = (a + first) % mod\\n', '        b = (b + second) % mod\\n', '        c = (c + a) % mod\\n', '        d = (d + b) % mod\\n', '    return a, b, c, d\\n', 'def fletcher4(data: bytes) -> ChecksumType:\\n', '    mod = 1 << 64\\n', '    a = 0\\n', '    b = 0\\n', '    c = 0\\n', '    d = 0\\n', \"    for w in unpack(data, 'I'):\\n\", '        a = (a + w) % mod\\n', '        b = (b + a) % mod\\n', '        c = (c + b) % mod\\n', '        d = (d + c) % mod\\n', '    return a, b, c, d\\n']",
  "context": "2(data)\n    elif mode == Checksum.SHA256:\n        chk = sha256(data)\n    elif mode == Checksum.OFF:\n        return True"
 },
 "139": {
  "name": "data",
  "type": "bytes",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/util.py",
  "lineno": "75",
  "column": "11",
  "slicing": "['def sha256(data: bytes) -> ChecksumType:\\n']",
  "context": "(c == v for c, v in zip(chk, valid))\n\n\ndef sha256(data: bytes) -> ChecksumType:\n    return struct.unpack('>QQQQ', hashlib.sha256(d"
 },
 "140": {
  "name": "data",
  "type": "bytes",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/util.py",
  "lineno": "79",
  "column": "11",
  "slicing": "['logger = logging.getLogger(__name__)\\n', '    lz4 = None\\n', '    logger.warn(\"import lz4 failed, lz4 decompression will not be available.\")\\n', '        mode = inherit\\n', '    if mode in (Compression.ON, Compression.LZJB):\\n', '    elif mode == Compression.LZ4 and lz4:\\n', \"        length = struct.unpack('>I', data[:4])[0]\\n\", '        data = data[4:length + 4]\\n', \"        return lz4.block.decompress(struct.pack('<i', size) + data)\\n\", \"    elif mode.name.startswith('GZIP_'):\\n\", '        data = zlib.decompress(data)\\n', '        return data[:size]\\n', '    elif mode == Compression.OFF:\\n', '        return data\\n', '        if mode == Compression.LZ4 and not lz4:\\n', '        raise ValueError(mode)\\n', 'ChecksumType = Tuple[int, int, int, int]\\n', '            valid: ChecksumType,\\n', '            chk: ChecksumType=None\\n', '    valid = tuple(valid)\\n', '    if mode == Checksum.INHERIT:\\n', '        mode = inherit\\n', '    if mode == Checksum.FLETCHER_4:\\n', '        chk = fletcher4(data)\\n', '    elif mode == Checksum.FLETCHER_2:\\n', '        chk = fletcher2(data)\\n', '    elif mode == Checksum.SHA256:\\n', '        chk = sha256(data)\\n', '    elif mode == Checksum.OFF:\\n', '        raise ValueError(mode)\\n', '    return all(c == v for c, v in zip(chk, valid))\\n', 'def sha256(data: bytes) -> ChecksumType:\\n', \"    return struct.unpack('>QQQQ', hashlib.sha256(data).digest())\\n\", 'def unpack(data: bytes, code: str):\\n', '    s = struct.calcsize(code)\\n', '    return struct.unpack(code*int(len(data)/s), data)\\n', 'def fletcher2(data: bytes) -> ChecksumType:\\n', '    mod = 1 << 64\\n', \"    un_data = list(unpack(data, 'Q'))\\n\", '    a = 0\\n', '    b = 0\\n', '    c = 0\\n', '    d = 0\\n', '    for first, second in zip(un_data[0::2], un_data[1::2]):\\n', '        a = (a + first) % mod\\n', '        b = (b + second) % mod\\n', '        c = (c + a) % mod\\n', '        d = (d + b) % mod\\n', '    return a, b, c, d\\n', 'def fletcher4(data: bytes) -> ChecksumType:\\n', '    mod = 1 << 64\\n', '    a = 0\\n', '    b = 0\\n', '    c = 0\\n', '    d = 0\\n', \"    for w in unpack(data, 'I'):\\n\", '        a = (a + w) % mod\\n', '        b = (b + a) % mod\\n', '        c = (c + b) % mod\\n', '        d = (d + c) % mod\\n', '    return a, b, c, d\\n']",
  "context": "QQQ', hashlib.sha256(data).digest())\n\n\ndef unpack(data: bytes, code: str):\n    s = struct.calcsize(code)\n    return struct.un"
 },
 "141": {
  "name": "code",
  "type": "str",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/util.py",
  "lineno": "79",
  "column": "24",
  "slicing": "['def unpack(data: bytes, code: str):\\n', '    return struct.unpack(code*int(len(data)/s), data)\\n']",
  "context": ".sha256(data).digest())\n\n\ndef unpack(data: bytes, code: str):\n    s = struct.calcsize(code)\n    return struct.un"
 },
 "142": {
  "name": "s",
  "type": "int",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/util.py",
  "lineno": "80",
  "column": "4",
  "slicing": "['logger = logging.getLogger(__name__)\\n', '    lz4 = None\\n', '    logger.warn(\"import lz4 failed, lz4 decompression will not be available.\")\\n', '        mode = inherit\\n', '    if mode in (Compression.ON, Compression.LZJB):\\n', '    elif mode == Compression.LZ4 and lz4:\\n', \"        length = struct.unpack('>I', data[:4])[0]\\n\", '        data = data[4:length + 4]\\n', \"        return lz4.block.decompress(struct.pack('<i', size) + data)\\n\", \"    elif mode.name.startswith('GZIP_'):\\n\", '        data = zlib.decompress(data)\\n', '        return data[:size]\\n', '    elif mode == Compression.OFF:\\n', '        return data\\n', '        if mode == Compression.LZ4 and not lz4:\\n', '        raise ValueError(mode)\\n', 'ChecksumType = Tuple[int, int, int, int]\\n', '            valid: ChecksumType,\\n', '            chk: ChecksumType=None\\n', '    valid = tuple(valid)\\n', '    if mode == Checksum.INHERIT:\\n', '        mode = inherit\\n', '    if mode == Checksum.FLETCHER_4:\\n', '        chk = fletcher4(data)\\n', '    elif mode == Checksum.FLETCHER_2:\\n', '        chk = fletcher2(data)\\n', '    elif mode == Checksum.SHA256:\\n', '        chk = sha256(data)\\n', '    elif mode == Checksum.OFF:\\n', '        raise ValueError(mode)\\n', '    return all(c == v for c, v in zip(chk, valid))\\n', 'def sha256(data: bytes) -> ChecksumType:\\n', \"    return struct.unpack('>QQQQ', hashlib.sha256(data).digest())\\n\", 'def unpack(data: bytes, code: str):\\n', '    s = struct.calcsize(code)\\n', '    return struct.unpack(code*int(len(data)/s), data)\\n', 'def fletcher2(data: bytes) -> ChecksumType:\\n', '    mod = 1 << 64\\n', \"    un_data = list(unpack(data, 'Q'))\\n\", '    a = 0\\n', '    b = 0\\n', '    c = 0\\n', '    d = 0\\n', '    for first, second in zip(un_data[0::2], un_data[1::2]):\\n', '        a = (a + first) % mod\\n', '        b = (b + second) % mod\\n', '        c = (c + a) % mod\\n', '        d = (d + b) % mod\\n', '    return a, b, c, d\\n', 'def fletcher4(data: bytes) -> ChecksumType:\\n', '    mod = 1 << 64\\n', '    a = 0\\n', '    b = 0\\n', '    c = 0\\n', '    d = 0\\n', \"    for w in unpack(data, 'I'):\\n\", '        a = (a + w) % mod\\n', '        b = (b + a) % mod\\n', '        c = (c + b) % mod\\n', '        d = (d + c) % mod\\n', '    return a, b, c, d\\n']",
  "context": "gest())\n\n\ndef unpack(data: bytes, code: str):\n    s = struct.calcsize(code)\n    return struct.unpack(code*int(len(data)/s), da"
 },
 "143": {
  "name": "data",
  "type": "bytes",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/util.py",
  "lineno": "84",
  "column": "14",
  "slicing": "['def fletcher2(data: bytes) -> ChecksumType:\\n']",
  "context": "pack(code*int(len(data)/s), data)\n\n\ndef fletcher2(data: bytes) -> ChecksumType:\n    mod = 1 << 64\n    un_data = list(unpack(data, "
 },
 "144": {
  "name": "un_data",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/util.py",
  "lineno": "86",
  "column": "4",
  "slicing": "['logger = logging.getLogger(__name__)\\n', '    lz4 = None\\n', '    logger.warn(\"import lz4 failed, lz4 decompression will not be available.\")\\n', '        mode = inherit\\n', '    if mode in (Compression.ON, Compression.LZJB):\\n', '    elif mode == Compression.LZ4 and lz4:\\n', \"        length = struct.unpack('>I', data[:4])[0]\\n\", '        data = data[4:length + 4]\\n', \"        return lz4.block.decompress(struct.pack('<i', size) + data)\\n\", \"    elif mode.name.startswith('GZIP_'):\\n\", '        data = zlib.decompress(data)\\n', '        return data[:size]\\n', '    elif mode == Compression.OFF:\\n', '        return data\\n', '        if mode == Compression.LZ4 and not lz4:\\n', '        raise ValueError(mode)\\n', 'ChecksumType = Tuple[int, int, int, int]\\n', '            valid: ChecksumType,\\n', '            chk: ChecksumType=None\\n', '    valid = tuple(valid)\\n', '    if mode == Checksum.INHERIT:\\n', '        mode = inherit\\n', '    if mode == Checksum.FLETCHER_4:\\n', '        chk = fletcher4(data)\\n', '    elif mode == Checksum.FLETCHER_2:\\n', '        chk = fletcher2(data)\\n', '    elif mode == Checksum.SHA256:\\n', '        chk = sha256(data)\\n', '    elif mode == Checksum.OFF:\\n', '        raise ValueError(mode)\\n', '    return all(c == v for c, v in zip(chk, valid))\\n', 'def sha256(data: bytes) -> ChecksumType:\\n', \"    return struct.unpack('>QQQQ', hashlib.sha256(data).digest())\\n\", 'def unpack(data: bytes, code: str):\\n', '    s = struct.calcsize(code)\\n', '    return struct.unpack(code*int(len(data)/s), data)\\n', 'def fletcher2(data: bytes) -> ChecksumType:\\n', '    mod = 1 << 64\\n', \"    un_data = list(unpack(data, 'Q'))\\n\", '    a = 0\\n', '    b = 0\\n', '    c = 0\\n', '    d = 0\\n', '    for first, second in zip(un_data[0::2], un_data[1::2]):\\n', '        a = (a + first) % mod\\n', '        b = (b + second) % mod\\n', '        c = (c + a) % mod\\n', '        d = (d + b) % mod\\n', '    return a, b, c, d\\n', 'def fletcher4(data: bytes) -> ChecksumType:\\n', '    mod = 1 << 64\\n', '    a = 0\\n', '    b = 0\\n', '    c = 0\\n', '    d = 0\\n', \"    for w in unpack(data, 'I'):\\n\", '        a = (a + w) % mod\\n', '        b = (b + a) % mod\\n', '        c = (c + b) % mod\\n', '        d = (d + c) % mod\\n', '    return a, b, c, d\\n']",
  "context": "ta: bytes) -> ChecksumType:\n    mod = 1 << 64\n    un_data = list(unpack(data, 'Q'))\n    a = 0\n    b = 0\n    c = 0\n    d = 0\n    for fi"
 },
 "145": {
  "name": "data",
  "type": "bytes",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/util.py",
  "lineno": "99",
  "column": "14",
  "slicing": "['def fletcher4(data: bytes) -> ChecksumType:\\n']",
  "context": " + b) % mod\n    return a, b, c, d\n\n\ndef fletcher4(data: bytes) -> ChecksumType:\n    mod = 1 << 64\n    a = 0\n    b = 0\n    c = 0\n  "
 },
 "146": {
  "name": "MicroZAPType",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/objectset.py",
  "lineno": "24",
  "column": "0",
  "slicing": "['MicroZAPType = Union[zfs.ondisk.zap.SARegistrationMicroZAP, zfs.ondisk.zap.MicroZAP]\\n']",
  "context": "ObjectType\n\nlogger = logging.getLogger(__name__)\n\nMicroZAPType = Union[zfs.ondisk.zap.SARegistrationMicroZAP, zfs.ondisk.zap.MicroZAP]\n\n\nclass ObjectSet(object):\n    @classmethod\n    de"
 },
 "147": {
  "name": "cls",
  "type": "ObjectSet",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/objectset.py",
  "lineno": "29",
  "column": "20",
  "slicing": "[\"    def from_struct(cls, pool, strct: ondisk.Objectsets, dataset: 'datasets.Dataset' = None) -> 'ObjectSet':\\n\"]",
  "context": "Set(object):\n    @classmethod\n    def from_struct(cls, pool, strct: ondisk.Objectsets, dataset: 'datasets.Dataset' = None) -> 'ObjectSet':\n        blocks = []\n        for blkptr in strct.me"
 },
 "148": {
  "name": "blocks",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/objectset.py",
  "lineno": "30",
  "column": "8",
  "slicing": "['        blocks = []\\n', '            blocks.append(block)\\n', \"        return ObjectSet(pool, strct, b''.join(blocks), dataset=dataset)\\n\"]",
  "context": "datasets.Dataset' = None) -> 'ObjectSet':\n        blocks = []\n        for blkptr in strct.meta_dnode.blkptr:\n   "
 },
 "149": {
  "name": "cls",
  "type": "ObjectSet",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/objectset.py",
  "lineno": "37",
  "column": "19",
  "slicing": "[\"    def from_block(cls, pool, block: bytes, dataset: 'datasets.Dataset' = None) -> 'ObjectSet':\\n\"]",
  "context": "set=dataset)\n\n    @classmethod\n    def from_block(cls, pool, block: bytes, dataset: 'datasets.Dataset' = None) -> 'ObjectSet':\n        objset_struct = ondisk.Objset_for(pool.ver"
 },
 "150": {
  "name": "block",
  "type": "bytes",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/objectset.py",
  "lineno": "37",
  "column": "30",
  "slicing": "[\"    def from_block(cls, pool, block: bytes, dataset: 'datasets.Dataset' = None) -> 'ObjectSet':\\n\"]",
  "context": ")\n\n    @classmethod\n    def from_block(cls, pool, block: bytes, dataset: 'datasets.Dataset' = None) -> 'ObjectSet':\n        objset_struct = ondisk.Objset_for(pool.ver"
 },
 "151": {
  "name": "objset",
  "type": "ObjectSet",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/objectset.py",
  "lineno": "39",
  "column": "8",
  "slicing": "['        blocks = []\\n', '        for blkptr in strct.meta_dnode.blkptr:\\n', '            block = pool.read_indirect(blkptr)\\n', '            blocks.append(block)\\n', \"        return ObjectSet(pool, strct, b''.join(blocks), dataset=dataset)\\n\", '        objset_struct = ondisk.Objset_for(pool.version)(block)\\n', '        objset = ObjectSet.from_struct(pool, objset_struct, dataset=dataset)\\n', '        return objset\\n', '        self.objset = objset\\n']",
  "context": " = ondisk.Objset_for(pool.version)(block)\n        objset = ObjectSet.from_struct(pool, objset_struct, dataset=dataset)\n        return objset\n\n    def __init__(self, pool"
 },
 "152": {
  "name": "objset",
  "type": "bytes",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/objectset.py",
  "lineno": "42",
  "column": "63",
  "slicing": "['    def __init__(self, pool, raw_objectset: ondisk.Objectsets, objset: bytes, dataset=None) -> None:\\n']",
  "context": "t__(self, pool, raw_objectset: ondisk.Objectsets, objset: bytes, dataset=None) -> None:\n        self.raw_objectset = raw_objectset\n       "
 },
 "153": {
  "name": "index",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/objectset.py",
  "lineno": "50",
  "column": "26",
  "slicing": "['    def __getitem__(self, index: Union[int, slice]) -> Any:\\n']",
  "context": "elf.parsed_objset = {}\n\n    def __getitem__(self, index: Union[int, slice]) -> Any:\n        if isinstance(index, slice):\n            r"
 },
 "154": {
  "name": "length",
  "type": "int",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/objectset.py",
  "lineno": "59",
  "column": "8",
  "slicing": "['logger = logging.getLogger(__name__)\\n', '        blocks = []\\n', '        for blkptr in strct.meta_dnode.blkptr:\\n', '            block = pool.read_indirect(blkptr)\\n', '            blocks.append(block)\\n', \"        return ObjectSet(pool, strct, b''.join(blocks), dataset=dataset)\\n\", '        objset_struct = ondisk.Objset_for(pool.version)(block)\\n', '        objset = ObjectSet.from_struct(pool, objset_struct, dataset=dataset)\\n', '        return objset\\n', '        self.objset = objset\\n', '            return [self[i] for i in range(index.start or 0, index.stop or len(self.objset)//512, index.step or 1)]\\n', '        length = len(self.objset)//512\\n', '        for i in range(length):\\n', '            yield self.get_dnode(i)\\n', '            offset = index * 512\\n', '            dn = ondisk.DNode(self.objset[offset:offset+512])\\n', '            dn.index = index\\n', '            self.dnodes[index] = dn\\n', '        nt = dnode.node_type\\n', '            if nt == ObjectType.NONE:\\n', '            elif nt == ObjectType.OBJECT_DIRECTORY:\\n', '            elif nt == ObjectType.DSL_DIR_CHILD_MAP:\\n', '            elif nt == ObjectType.DSL_DS_SNAP_MAP:\\n', '            elif nt == ObjectType.NEXT_CLONES:\\n', '            elif nt == ObjectType.DEADLIST:\\n', '            elif nt == ObjectType.DSL_CLONES:\\n', '            elif nt == ObjectType.MASTER_NODE:\\n', '            elif nt == ObjectType.PLAIN_FILE_CONTENTS:\\n', '            elif nt == ObjectType.DIRECTORY_CONTENTS:\\n', '            elif nt == ObjectType.SA_MASTER_NODE:\\n', '            elif nt == ObjectType.UNLINKED_SET:\\n', '            elif nt == ObjectType.SA_ATTR_REGISTRATION:\\n', '            elif nt == ObjectType.SA_ATTR_LAYOUTS:\\n', '            elif nt == ObjectType.DSL_PROPS:\\n', '            elif nt == ObjectType.FEATURE_DESCRIPTION:\\n', '            elif nt == ObjectType.ZVOL_PROP:\\n', '            elif nt == ObjectType.SPA_HISTORY:\\n', '            elif nt == ObjectType.OBJECT_ARRAY:\\n', '            elif nt == ObjectType.PACKED_NVLIST:\\n', '            elif nt == ObjectType.DSL_DATASET:\\n', '            elif nt == ObjectType.DSL_DIR:\\n', '            elif nt == ObjectType.BPOBJ:\\n', \"                ds = self.dataset.path.replace('/', '-')\\n\", \"                with open('failed/{}_{}_{}'.format(ds, nt.name, index or '-'), 'wb') as f:\\n\", '                    f.write(self.pool.read_dnode(dnode))\\n', '        entries = self.read_zap(dnode)\\n', '        newdir = posix.Directory(dnode, entries, self.dataset, self)\\n', '        return newdir\\n', '        raw_zap = self.pool.read_dnode(dnode)\\n', '        zap = BytesIO(raw_zap)\\n', '        hdr = zfs.ondisk.zap.MicroZAPHeader(zap)\\n', '        if hdr.block_type == zfs.ondisk.zap.ZapType.ZAPHeader:\\n', '            return self._read_fatzap(raw_zap)\\n', '            return self._read_microzap(dnode, hdr, zap)\\n', '        node_type = dnode.node_type\\n', '        max_entries = int((len(zap.getvalue()) - 128) / 64)\\n', '        mzaps = []\\n', '        if node_type == ObjectType.SA_ATTR_REGISTRATION:\\n', '            mzap_type = zfs.ondisk.zap.SARegistrationMicroZAP\\n', '            mzap_type = zfs.ondisk.zap.MicroZAP\\n', '        if hdr.block_type == zfs.ondisk.zap.ZapType.MicroZAP:\\n', '            while len(mzaps) <= max_entries:\\n', '                mzaps.append(mzap_type(zap))\\n', '        if node_type == ObjectType.SA_ATTR_REGISTRATION:\\n', \"            r = {z.hdr.name: z for z in mzaps if z.hdr.name != ''}\\n\", '            return r\\n', \"            r = {z.hdr.name: z.value for z in mzaps if z.hdr.name != ''}\\n\", '            return r\\n', '        data = self.read_zap(dnode)\\n', '        ret = {}\\n', '        for k, v in data.items():\\n', '            ret[k] = {\\n', \"                'attr_num': v.attr_num,\\n\", \"                'byteswap': v.byteswap,\\n\", \"                'length': v.length,\\n\", '        return ret\\n', \"        logger.debug('reading a fatzap')\\n\", '        data = ondisk.fatzap.parse_fatzap(raw_fz)\\n', '        return data\\n', '        hdr = ondisk.BPObjHeader(dnode.bonus)\\n', '        logger.info(hdr)\\n', '        data = self.pool.read_dnode(dnode)\\n', '        data = BytesIO(data)\\n', '        return [ondisk.Blockptr(data) for _ in range(hdr.length)]\\n', '        data = self.pool.read_dnode(dnode)\\n', '        length = int(len(data) / 8)\\n', \"        format_code = '<' + (length * 'Q')\\n\", '        return {i+1: x for i, x in enumerate(struct.unpack(format_code, data)) if x != 0}\\n', '        nv = self.pool.read_block(dnode.blkptr[0])\\n', '        nv = nv[:dnode.used]\\n', '        nvl = nvlist.NVList(nv)\\n', '        nvdata = nvl.unpack_nvlist()\\n', '        return nvdata\\n', '        dsl_dir = ondisk.DSLDir(dnode.bonus)\\n', '        return datasets.Dataset(self.pool, dsl_dir, self, dnode)\\n', '        data = self.pool.read_dnode(dnode)\\n', '        history_parser = history.HistoryParser(data)\\n', '        return history_parser.unpack_history()\\n']",
  "context": "dex]\n\n    def __iter__(self) -> Iterator:\n        length = len(self.objset)//512\n        for i in range(length):\n            yield "
 },
 "155": {
  "name": "index",
  "type": "int",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/objectset.py",
  "lineno": "63",
  "column": "24",
  "slicing": "['    def get_dnode(self, index: int) -> ondisk.DNode:\\n']",
  "context": " yield self.get_dnode(i)\n\n    def get_dnode(self, index: int) -> ondisk.DNode:\n        if index not in self.dnodes:\n            o"
 },
 "156": {
  "name": "index",
  "type": "int",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/objectset.py",
  "lineno": "71",
  "column": "47",
  "slicing": "['    def parse_dnode(self, dnode: ondisk.DNode, index: int = None) -> Any:\\n']",
  "context": "]\n\n    def parse_dnode(self, dnode: ondisk.DNode, index: int = None) -> Any:\n        nt = dnode.node_type\n        try:\n        "
 },
 "157": {
  "name": "entries",
  "type": "dict",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/objectset.py",
  "lineno": "137",
  "column": "8",
  "slicing": "['logger = logging.getLogger(__name__)\\n', '        blocks = []\\n', '        for blkptr in strct.meta_dnode.blkptr:\\n', '            block = pool.read_indirect(blkptr)\\n', '            blocks.append(block)\\n', \"        return ObjectSet(pool, strct, b''.join(blocks), dataset=dataset)\\n\", '        objset_struct = ondisk.Objset_for(pool.version)(block)\\n', '        objset = ObjectSet.from_struct(pool, objset_struct, dataset=dataset)\\n', '        return objset\\n', '        self.objset = objset\\n', '            return [self[i] for i in range(index.start or 0, index.stop or len(self.objset)//512, index.step or 1)]\\n', '        length = len(self.objset)//512\\n', '        for i in range(length):\\n', '            yield self.get_dnode(i)\\n', '            offset = index * 512\\n', '            dn = ondisk.DNode(self.objset[offset:offset+512])\\n', '            dn.index = index\\n', '            self.dnodes[index] = dn\\n', '        nt = dnode.node_type\\n', '            if nt == ObjectType.NONE:\\n', '            elif nt == ObjectType.OBJECT_DIRECTORY:\\n', '            elif nt == ObjectType.DSL_DIR_CHILD_MAP:\\n', '            elif nt == ObjectType.DSL_DS_SNAP_MAP:\\n', '            elif nt == ObjectType.NEXT_CLONES:\\n', '            elif nt == ObjectType.DEADLIST:\\n', '            elif nt == ObjectType.DSL_CLONES:\\n', '            elif nt == ObjectType.MASTER_NODE:\\n', '            elif nt == ObjectType.PLAIN_FILE_CONTENTS:\\n', '            elif nt == ObjectType.DIRECTORY_CONTENTS:\\n', '            elif nt == ObjectType.SA_MASTER_NODE:\\n', '            elif nt == ObjectType.UNLINKED_SET:\\n', '            elif nt == ObjectType.SA_ATTR_REGISTRATION:\\n', '            elif nt == ObjectType.SA_ATTR_LAYOUTS:\\n', '            elif nt == ObjectType.DSL_PROPS:\\n', '            elif nt == ObjectType.FEATURE_DESCRIPTION:\\n', '            elif nt == ObjectType.ZVOL_PROP:\\n', '            elif nt == ObjectType.SPA_HISTORY:\\n', '            elif nt == ObjectType.OBJECT_ARRAY:\\n', '            elif nt == ObjectType.PACKED_NVLIST:\\n', '            elif nt == ObjectType.DSL_DATASET:\\n', '            elif nt == ObjectType.DSL_DIR:\\n', '            elif nt == ObjectType.BPOBJ:\\n', \"                ds = self.dataset.path.replace('/', '-')\\n\", \"                with open('failed/{}_{}_{}'.format(ds, nt.name, index or '-'), 'wb') as f:\\n\", '                    f.write(self.pool.read_dnode(dnode))\\n', '        entries = self.read_zap(dnode)\\n', '        newdir = posix.Directory(dnode, entries, self.dataset, self)\\n', '        return newdir\\n', '        raw_zap = self.pool.read_dnode(dnode)\\n', '        zap = BytesIO(raw_zap)\\n', '        hdr = zfs.ondisk.zap.MicroZAPHeader(zap)\\n', '        if hdr.block_type == zfs.ondisk.zap.ZapType.ZAPHeader:\\n', '            return self._read_fatzap(raw_zap)\\n', '            return self._read_microzap(dnode, hdr, zap)\\n', '        node_type = dnode.node_type\\n', '        max_entries = int((len(zap.getvalue()) - 128) / 64)\\n', '        mzaps = []\\n', '        if node_type == ObjectType.SA_ATTR_REGISTRATION:\\n', '            mzap_type = zfs.ondisk.zap.SARegistrationMicroZAP\\n', '            mzap_type = zfs.ondisk.zap.MicroZAP\\n', '        if hdr.block_type == zfs.ondisk.zap.ZapType.MicroZAP:\\n', '            while len(mzaps) <= max_entries:\\n', '                mzaps.append(mzap_type(zap))\\n', '        if node_type == ObjectType.SA_ATTR_REGISTRATION:\\n', \"            r = {z.hdr.name: z for z in mzaps if z.hdr.name != ''}\\n\", '            return r\\n', \"            r = {z.hdr.name: z.value for z in mzaps if z.hdr.name != ''}\\n\", '            return r\\n', '        data = self.read_zap(dnode)\\n', '        ret = {}\\n', '        for k, v in data.items():\\n', '            ret[k] = {\\n', \"                'attr_num': v.attr_num,\\n\", \"                'byteswap': v.byteswap,\\n\", \"                'length': v.length,\\n\", '        return ret\\n', \"        logger.debug('reading a fatzap')\\n\", '        data = ondisk.fatzap.parse_fatzap(raw_fz)\\n', '        return data\\n', '        hdr = ondisk.BPObjHeader(dnode.bonus)\\n', '        logger.info(hdr)\\n', '        data = self.pool.read_dnode(dnode)\\n', '        data = BytesIO(data)\\n', '        return [ondisk.Blockptr(data) for _ in range(hdr.length)]\\n', '        data = self.pool.read_dnode(dnode)\\n', '        length = int(len(data) / 8)\\n', \"        format_code = '<' + (length * 'Q')\\n\", '        return {i+1: x for i, x in enumerate(struct.unpack(format_code, data)) if x != 0}\\n', '        nv = self.pool.read_block(dnode.blkptr[0])\\n', '        nv = nv[:dnode.used]\\n', '        nvl = nvlist.NVList(nv)\\n', '        nvdata = nvl.unpack_nvlist()\\n', '        return nvdata\\n', '        dsl_dir = ondisk.DSLDir(dnode.bonus)\\n', '        return datasets.Dataset(self.pool, dsl_dir, self, dnode)\\n', '        data = self.pool.read_dnode(dnode)\\n', '        history_parser = history.HistoryParser(data)\\n', '        return history_parser.unpack_history()\\n']",
  "context": "node: ondisk.DNode) -> 'posix.Directory':\n        entries = self.read_zap(dnode)\n        newdir = posix.Directory(dnode, entries, s"
 },
 "158": {
  "name": "zap",
  "type": "io.BytesIO",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/objectset.py",
  "lineno": "146",
  "column": "8",
  "slicing": "['logger = logging.getLogger(__name__)\\n', '        blocks = []\\n', '        for blkptr in strct.meta_dnode.blkptr:\\n', '            block = pool.read_indirect(blkptr)\\n', '            blocks.append(block)\\n', \"        return ObjectSet(pool, strct, b''.join(blocks), dataset=dataset)\\n\", '        objset_struct = ondisk.Objset_for(pool.version)(block)\\n', '        objset = ObjectSet.from_struct(pool, objset_struct, dataset=dataset)\\n', '        return objset\\n', '        self.objset = objset\\n', '            return [self[i] for i in range(index.start or 0, index.stop or len(self.objset)//512, index.step or 1)]\\n', '        length = len(self.objset)//512\\n', '        for i in range(length):\\n', '            yield self.get_dnode(i)\\n', '            offset = index * 512\\n', '            dn = ondisk.DNode(self.objset[offset:offset+512])\\n', '            dn.index = index\\n', '            self.dnodes[index] = dn\\n', '        nt = dnode.node_type\\n', '            if nt == ObjectType.NONE:\\n', '            elif nt == ObjectType.OBJECT_DIRECTORY:\\n', '            elif nt == ObjectType.DSL_DIR_CHILD_MAP:\\n', '            elif nt == ObjectType.DSL_DS_SNAP_MAP:\\n', '            elif nt == ObjectType.NEXT_CLONES:\\n', '            elif nt == ObjectType.DEADLIST:\\n', '            elif nt == ObjectType.DSL_CLONES:\\n', '            elif nt == ObjectType.MASTER_NODE:\\n', '            elif nt == ObjectType.PLAIN_FILE_CONTENTS:\\n', '            elif nt == ObjectType.DIRECTORY_CONTENTS:\\n', '            elif nt == ObjectType.SA_MASTER_NODE:\\n', '            elif nt == ObjectType.UNLINKED_SET:\\n', '            elif nt == ObjectType.SA_ATTR_REGISTRATION:\\n', '            elif nt == ObjectType.SA_ATTR_LAYOUTS:\\n', '            elif nt == ObjectType.DSL_PROPS:\\n', '            elif nt == ObjectType.FEATURE_DESCRIPTION:\\n', '            elif nt == ObjectType.ZVOL_PROP:\\n', '            elif nt == ObjectType.SPA_HISTORY:\\n', '            elif nt == ObjectType.OBJECT_ARRAY:\\n', '            elif nt == ObjectType.PACKED_NVLIST:\\n', '            elif nt == ObjectType.DSL_DATASET:\\n', '            elif nt == ObjectType.DSL_DIR:\\n', '            elif nt == ObjectType.BPOBJ:\\n', \"                ds = self.dataset.path.replace('/', '-')\\n\", \"                with open('failed/{}_{}_{}'.format(ds, nt.name, index or '-'), 'wb') as f:\\n\", '                    f.write(self.pool.read_dnode(dnode))\\n', '        entries = self.read_zap(dnode)\\n', '        newdir = posix.Directory(dnode, entries, self.dataset, self)\\n', '        return newdir\\n', '        raw_zap = self.pool.read_dnode(dnode)\\n', '        zap = BytesIO(raw_zap)\\n', '        hdr = zfs.ondisk.zap.MicroZAPHeader(zap)\\n', '        if hdr.block_type == zfs.ondisk.zap.ZapType.ZAPHeader:\\n', '            return self._read_fatzap(raw_zap)\\n', '            return self._read_microzap(dnode, hdr, zap)\\n', '        node_type = dnode.node_type\\n', '        max_entries = int((len(zap.getvalue()) - 128) / 64)\\n', '        mzaps = []\\n', '        if node_type == ObjectType.SA_ATTR_REGISTRATION:\\n', '            mzap_type = zfs.ondisk.zap.SARegistrationMicroZAP\\n', '            mzap_type = zfs.ondisk.zap.MicroZAP\\n', '        if hdr.block_type == zfs.ondisk.zap.ZapType.MicroZAP:\\n', '            while len(mzaps) <= max_entries:\\n', '                mzaps.append(mzap_type(zap))\\n', '        if node_type == ObjectType.SA_ATTR_REGISTRATION:\\n', \"            r = {z.hdr.name: z for z in mzaps if z.hdr.name != ''}\\n\", '            return r\\n', \"            r = {z.hdr.name: z.value for z in mzaps if z.hdr.name != ''}\\n\", '            return r\\n', '        data = self.read_zap(dnode)\\n', '        ret = {}\\n', '        for k, v in data.items():\\n', '            ret[k] = {\\n', \"                'attr_num': v.attr_num,\\n\", \"                'byteswap': v.byteswap,\\n\", \"                'length': v.length,\\n\", '        return ret\\n', \"        logger.debug('reading a fatzap')\\n\", '        data = ondisk.fatzap.parse_fatzap(raw_fz)\\n', '        return data\\n', '        hdr = ondisk.BPObjHeader(dnode.bonus)\\n', '        logger.info(hdr)\\n', '        data = self.pool.read_dnode(dnode)\\n', '        data = BytesIO(data)\\n', '        return [ondisk.Blockptr(data) for _ in range(hdr.length)]\\n', '        data = self.pool.read_dnode(dnode)\\n', '        length = int(len(data) / 8)\\n', \"        format_code = '<' + (length * 'Q')\\n\", '        return {i+1: x for i, x in enumerate(struct.unpack(format_code, data)) if x != 0}\\n', '        nv = self.pool.read_block(dnode.blkptr[0])\\n', '        nv = nv[:dnode.used]\\n', '        nvl = nvlist.NVList(nv)\\n', '        nvdata = nvl.unpack_nvlist()\\n', '        return nvdata\\n', '        dsl_dir = ondisk.DSLDir(dnode.bonus)\\n', '        return datasets.Dataset(self.pool, dsl_dir, self, dnode)\\n', '        data = self.pool.read_dnode(dnode)\\n', '        history_parser = history.HistoryParser(data)\\n', '        return history_parser.unpack_history()\\n']",
  "context": "    raw_zap = self.pool.read_dnode(dnode)\n        zap = BytesIO(raw_zap)\n        hdr = zfs.ondisk.zap.MicroZAPHeader(zap)\n "
 },
 "159": {
  "name": "zap",
  "type": "io.BytesIO",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/objectset.py",
  "lineno": "153",
  "column": "86",
  "slicing": "['    def _read_microzap(self, dnode: ondisk.DNode, hdr: zfs.ondisk.zap.MicroZAPHeader, zap: BytesIO) -> Dict[str, Any]:\\n']",
  "context": "ondisk.DNode, hdr: zfs.ondisk.zap.MicroZAPHeader, zap: BytesIO) -> Dict[str, Any]:\n        node_type = dnode.node_type\n        max_en"
 },
 "160": {
  "name": "max_entries",
  "type": "int",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/objectset.py",
  "lineno": "155",
  "column": "8",
  "slicing": "['logger = logging.getLogger(__name__)\\n', '        blocks = []\\n', '        for blkptr in strct.meta_dnode.blkptr:\\n', '            block = pool.read_indirect(blkptr)\\n', '            blocks.append(block)\\n', \"        return ObjectSet(pool, strct, b''.join(blocks), dataset=dataset)\\n\", '        objset_struct = ondisk.Objset_for(pool.version)(block)\\n', '        objset = ObjectSet.from_struct(pool, objset_struct, dataset=dataset)\\n', '        return objset\\n', '        self.objset = objset\\n', '            return [self[i] for i in range(index.start or 0, index.stop or len(self.objset)//512, index.step or 1)]\\n', '        length = len(self.objset)//512\\n', '        for i in range(length):\\n', '            yield self.get_dnode(i)\\n', '            offset = index * 512\\n', '            dn = ondisk.DNode(self.objset[offset:offset+512])\\n', '            dn.index = index\\n', '            self.dnodes[index] = dn\\n', '        nt = dnode.node_type\\n', '            if nt == ObjectType.NONE:\\n', '            elif nt == ObjectType.OBJECT_DIRECTORY:\\n', '            elif nt == ObjectType.DSL_DIR_CHILD_MAP:\\n', '            elif nt == ObjectType.DSL_DS_SNAP_MAP:\\n', '            elif nt == ObjectType.NEXT_CLONES:\\n', '            elif nt == ObjectType.DEADLIST:\\n', '            elif nt == ObjectType.DSL_CLONES:\\n', '            elif nt == ObjectType.MASTER_NODE:\\n', '            elif nt == ObjectType.PLAIN_FILE_CONTENTS:\\n', '            elif nt == ObjectType.DIRECTORY_CONTENTS:\\n', '            elif nt == ObjectType.SA_MASTER_NODE:\\n', '            elif nt == ObjectType.UNLINKED_SET:\\n', '            elif nt == ObjectType.SA_ATTR_REGISTRATION:\\n', '            elif nt == ObjectType.SA_ATTR_LAYOUTS:\\n', '            elif nt == ObjectType.DSL_PROPS:\\n', '            elif nt == ObjectType.FEATURE_DESCRIPTION:\\n', '            elif nt == ObjectType.ZVOL_PROP:\\n', '            elif nt == ObjectType.SPA_HISTORY:\\n', '            elif nt == ObjectType.OBJECT_ARRAY:\\n', '            elif nt == ObjectType.PACKED_NVLIST:\\n', '            elif nt == ObjectType.DSL_DATASET:\\n', '            elif nt == ObjectType.DSL_DIR:\\n', '            elif nt == ObjectType.BPOBJ:\\n', \"                ds = self.dataset.path.replace('/', '-')\\n\", \"                with open('failed/{}_{}_{}'.format(ds, nt.name, index or '-'), 'wb') as f:\\n\", '                    f.write(self.pool.read_dnode(dnode))\\n', '        entries = self.read_zap(dnode)\\n', '        newdir = posix.Directory(dnode, entries, self.dataset, self)\\n', '        return newdir\\n', '        raw_zap = self.pool.read_dnode(dnode)\\n', '        zap = BytesIO(raw_zap)\\n', '        hdr = zfs.ondisk.zap.MicroZAPHeader(zap)\\n', '        if hdr.block_type == zfs.ondisk.zap.ZapType.ZAPHeader:\\n', '            return self._read_fatzap(raw_zap)\\n', '            return self._read_microzap(dnode, hdr, zap)\\n', '        node_type = dnode.node_type\\n', '        max_entries = int((len(zap.getvalue()) - 128) / 64)\\n', '        mzaps = []\\n', '        if node_type == ObjectType.SA_ATTR_REGISTRATION:\\n', '            mzap_type = zfs.ondisk.zap.SARegistrationMicroZAP\\n', '            mzap_type = zfs.ondisk.zap.MicroZAP\\n', '        if hdr.block_type == zfs.ondisk.zap.ZapType.MicroZAP:\\n', '            while len(mzaps) <= max_entries:\\n', '                mzaps.append(mzap_type(zap))\\n', '        if node_type == ObjectType.SA_ATTR_REGISTRATION:\\n', \"            r = {z.hdr.name: z for z in mzaps if z.hdr.name != ''}\\n\", '            return r\\n', \"            r = {z.hdr.name: z.value for z in mzaps if z.hdr.name != ''}\\n\", '            return r\\n', '        data = self.read_zap(dnode)\\n', '        ret = {}\\n', '        for k, v in data.items():\\n', '            ret[k] = {\\n', \"                'attr_num': v.attr_num,\\n\", \"                'byteswap': v.byteswap,\\n\", \"                'length': v.length,\\n\", '        return ret\\n', \"        logger.debug('reading a fatzap')\\n\", '        data = ondisk.fatzap.parse_fatzap(raw_fz)\\n', '        return data\\n', '        hdr = ondisk.BPObjHeader(dnode.bonus)\\n', '        logger.info(hdr)\\n', '        data = self.pool.read_dnode(dnode)\\n', '        data = BytesIO(data)\\n', '        return [ondisk.Blockptr(data) for _ in range(hdr.length)]\\n', '        data = self.pool.read_dnode(dnode)\\n', '        length = int(len(data) / 8)\\n', \"        format_code = '<' + (length * 'Q')\\n\", '        return {i+1: x for i, x in enumerate(struct.unpack(format_code, data)) if x != 0}\\n', '        nv = self.pool.read_block(dnode.blkptr[0])\\n', '        nv = nv[:dnode.used]\\n', '        nvl = nvlist.NVList(nv)\\n', '        nvdata = nvl.unpack_nvlist()\\n', '        return nvdata\\n', '        dsl_dir = ondisk.DSLDir(dnode.bonus)\\n', '        return datasets.Dataset(self.pool, dsl_dir, self, dnode)\\n', '        data = self.pool.read_dnode(dnode)\\n', '        history_parser = history.HistoryParser(data)\\n', '        return history_parser.unpack_history()\\n']",
  "context": "Any]:\n        node_type = dnode.node_type\n        max_entries = int((len(zap.getvalue()) - 128) / 64)\n        mzaps = []\n        if node_type == ObjectT"
 },
 "161": {
  "name": "mzaps",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/objectset.py",
  "lineno": "156",
  "column": "8",
  "slicing": "['logger = logging.getLogger(__name__)\\n', '        blocks = []\\n', '        for blkptr in strct.meta_dnode.blkptr:\\n', '            block = pool.read_indirect(blkptr)\\n', '            blocks.append(block)\\n', \"        return ObjectSet(pool, strct, b''.join(blocks), dataset=dataset)\\n\", '        objset_struct = ondisk.Objset_for(pool.version)(block)\\n', '        objset = ObjectSet.from_struct(pool, objset_struct, dataset=dataset)\\n', '        return objset\\n', '        self.objset = objset\\n', '            return [self[i] for i in range(index.start or 0, index.stop or len(self.objset)//512, index.step or 1)]\\n', '        length = len(self.objset)//512\\n', '        for i in range(length):\\n', '            yield self.get_dnode(i)\\n', '            offset = index * 512\\n', '            dn = ondisk.DNode(self.objset[offset:offset+512])\\n', '            dn.index = index\\n', '            self.dnodes[index] = dn\\n', '        nt = dnode.node_type\\n', '            if nt == ObjectType.NONE:\\n', '            elif nt == ObjectType.OBJECT_DIRECTORY:\\n', '            elif nt == ObjectType.DSL_DIR_CHILD_MAP:\\n', '            elif nt == ObjectType.DSL_DS_SNAP_MAP:\\n', '            elif nt == ObjectType.NEXT_CLONES:\\n', '            elif nt == ObjectType.DEADLIST:\\n', '            elif nt == ObjectType.DSL_CLONES:\\n', '            elif nt == ObjectType.MASTER_NODE:\\n', '            elif nt == ObjectType.PLAIN_FILE_CONTENTS:\\n', '            elif nt == ObjectType.DIRECTORY_CONTENTS:\\n', '            elif nt == ObjectType.SA_MASTER_NODE:\\n', '            elif nt == ObjectType.UNLINKED_SET:\\n', '            elif nt == ObjectType.SA_ATTR_REGISTRATION:\\n', '            elif nt == ObjectType.SA_ATTR_LAYOUTS:\\n', '            elif nt == ObjectType.DSL_PROPS:\\n', '            elif nt == ObjectType.FEATURE_DESCRIPTION:\\n', '            elif nt == ObjectType.ZVOL_PROP:\\n', '            elif nt == ObjectType.SPA_HISTORY:\\n', '            elif nt == ObjectType.OBJECT_ARRAY:\\n', '            elif nt == ObjectType.PACKED_NVLIST:\\n', '            elif nt == ObjectType.DSL_DATASET:\\n', '            elif nt == ObjectType.DSL_DIR:\\n', '            elif nt == ObjectType.BPOBJ:\\n', \"                ds = self.dataset.path.replace('/', '-')\\n\", \"                with open('failed/{}_{}_{}'.format(ds, nt.name, index or '-'), 'wb') as f:\\n\", '                    f.write(self.pool.read_dnode(dnode))\\n', '        entries = self.read_zap(dnode)\\n', '        newdir = posix.Directory(dnode, entries, self.dataset, self)\\n', '        return newdir\\n', '        raw_zap = self.pool.read_dnode(dnode)\\n', '        zap = BytesIO(raw_zap)\\n', '        hdr = zfs.ondisk.zap.MicroZAPHeader(zap)\\n', '        if hdr.block_type == zfs.ondisk.zap.ZapType.ZAPHeader:\\n', '            return self._read_fatzap(raw_zap)\\n', '            return self._read_microzap(dnode, hdr, zap)\\n', '        node_type = dnode.node_type\\n', '        max_entries = int((len(zap.getvalue()) - 128) / 64)\\n', '        mzaps = []\\n', '        if node_type == ObjectType.SA_ATTR_REGISTRATION:\\n', '            mzap_type = zfs.ondisk.zap.SARegistrationMicroZAP\\n', '            mzap_type = zfs.ondisk.zap.MicroZAP\\n', '        if hdr.block_type == zfs.ondisk.zap.ZapType.MicroZAP:\\n', '            while len(mzaps) <= max_entries:\\n', '                mzaps.append(mzap_type(zap))\\n', '        if node_type == ObjectType.SA_ATTR_REGISTRATION:\\n', \"            r = {z.hdr.name: z for z in mzaps if z.hdr.name != ''}\\n\", '            return r\\n', \"            r = {z.hdr.name: z.value for z in mzaps if z.hdr.name != ''}\\n\", '            return r\\n', '        data = self.read_zap(dnode)\\n', '        ret = {}\\n', '        for k, v in data.items():\\n', '            ret[k] = {\\n', \"                'attr_num': v.attr_num,\\n\", \"                'byteswap': v.byteswap,\\n\", \"                'length': v.length,\\n\", '        return ret\\n', \"        logger.debug('reading a fatzap')\\n\", '        data = ondisk.fatzap.parse_fatzap(raw_fz)\\n', '        return data\\n', '        hdr = ondisk.BPObjHeader(dnode.bonus)\\n', '        logger.info(hdr)\\n', '        data = self.pool.read_dnode(dnode)\\n', '        data = BytesIO(data)\\n', '        return [ondisk.Blockptr(data) for _ in range(hdr.length)]\\n', '        data = self.pool.read_dnode(dnode)\\n', '        length = int(len(data) / 8)\\n', \"        format_code = '<' + (length * 'Q')\\n\", '        return {i+1: x for i, x in enumerate(struct.unpack(format_code, data)) if x != 0}\\n', '        nv = self.pool.read_block(dnode.blkptr[0])\\n', '        nv = nv[:dnode.used]\\n', '        nvl = nvlist.NVList(nv)\\n', '        nvdata = nvl.unpack_nvlist()\\n', '        return nvdata\\n', '        dsl_dir = ondisk.DSLDir(dnode.bonus)\\n', '        return datasets.Dataset(self.pool, dsl_dir, self, dnode)\\n', '        data = self.pool.read_dnode(dnode)\\n', '        history_parser = history.HistoryParser(data)\\n', '        return history_parser.unpack_history()\\n']",
  "context": "s = int((len(zap.getvalue()) - 128) / 64)\n        mzaps = []\n        if node_type == ObjectType.SA_ATTR_REGISTR"
 },
 "162": {
  "name": "r",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/objectset.py",
  "lineno": "165",
  "column": "12",
  "slicing": "['logger = logging.getLogger(__name__)\\n', '        blocks = []\\n', '        for blkptr in strct.meta_dnode.blkptr:\\n', '            block = pool.read_indirect(blkptr)\\n', '            blocks.append(block)\\n', \"        return ObjectSet(pool, strct, b''.join(blocks), dataset=dataset)\\n\", '        objset_struct = ondisk.Objset_for(pool.version)(block)\\n', '        objset = ObjectSet.from_struct(pool, objset_struct, dataset=dataset)\\n', '        return objset\\n', '        self.objset = objset\\n', '            return [self[i] for i in range(index.start or 0, index.stop or len(self.objset)//512, index.step or 1)]\\n', '        length = len(self.objset)//512\\n', '        for i in range(length):\\n', '            yield self.get_dnode(i)\\n', '            offset = index * 512\\n', '            dn = ondisk.DNode(self.objset[offset:offset+512])\\n', '            dn.index = index\\n', '            self.dnodes[index] = dn\\n', '        nt = dnode.node_type\\n', '            if nt == ObjectType.NONE:\\n', '            elif nt == ObjectType.OBJECT_DIRECTORY:\\n', '            elif nt == ObjectType.DSL_DIR_CHILD_MAP:\\n', '            elif nt == ObjectType.DSL_DS_SNAP_MAP:\\n', '            elif nt == ObjectType.NEXT_CLONES:\\n', '            elif nt == ObjectType.DEADLIST:\\n', '            elif nt == ObjectType.DSL_CLONES:\\n', '            elif nt == ObjectType.MASTER_NODE:\\n', '            elif nt == ObjectType.PLAIN_FILE_CONTENTS:\\n', '            elif nt == ObjectType.DIRECTORY_CONTENTS:\\n', '            elif nt == ObjectType.SA_MASTER_NODE:\\n', '            elif nt == ObjectType.UNLINKED_SET:\\n', '            elif nt == ObjectType.SA_ATTR_REGISTRATION:\\n', '            elif nt == ObjectType.SA_ATTR_LAYOUTS:\\n', '            elif nt == ObjectType.DSL_PROPS:\\n', '            elif nt == ObjectType.FEATURE_DESCRIPTION:\\n', '            elif nt == ObjectType.ZVOL_PROP:\\n', '            elif nt == ObjectType.SPA_HISTORY:\\n', '            elif nt == ObjectType.OBJECT_ARRAY:\\n', '            elif nt == ObjectType.PACKED_NVLIST:\\n', '            elif nt == ObjectType.DSL_DATASET:\\n', '            elif nt == ObjectType.DSL_DIR:\\n', '            elif nt == ObjectType.BPOBJ:\\n', \"                ds = self.dataset.path.replace('/', '-')\\n\", \"                with open('failed/{}_{}_{}'.format(ds, nt.name, index or '-'), 'wb') as f:\\n\", '                    f.write(self.pool.read_dnode(dnode))\\n', '        entries = self.read_zap(dnode)\\n', '        newdir = posix.Directory(dnode, entries, self.dataset, self)\\n', '        return newdir\\n', '        raw_zap = self.pool.read_dnode(dnode)\\n', '        zap = BytesIO(raw_zap)\\n', '        hdr = zfs.ondisk.zap.MicroZAPHeader(zap)\\n', '        if hdr.block_type == zfs.ondisk.zap.ZapType.ZAPHeader:\\n', '            return self._read_fatzap(raw_zap)\\n', '            return self._read_microzap(dnode, hdr, zap)\\n', '        node_type = dnode.node_type\\n', '        max_entries = int((len(zap.getvalue()) - 128) / 64)\\n', '        mzaps = []\\n', '        if node_type == ObjectType.SA_ATTR_REGISTRATION:\\n', '            mzap_type = zfs.ondisk.zap.SARegistrationMicroZAP\\n', '            mzap_type = zfs.ondisk.zap.MicroZAP\\n', '        if hdr.block_type == zfs.ondisk.zap.ZapType.MicroZAP:\\n', '            while len(mzaps) <= max_entries:\\n', '                mzaps.append(mzap_type(zap))\\n', '        if node_type == ObjectType.SA_ATTR_REGISTRATION:\\n', \"            r = {z.hdr.name: z for z in mzaps if z.hdr.name != ''}\\n\", '            return r\\n', \"            r = {z.hdr.name: z.value for z in mzaps if z.hdr.name != ''}\\n\", '            return r\\n', '        data = self.read_zap(dnode)\\n', '        ret = {}\\n', '        for k, v in data.items():\\n', '            ret[k] = {\\n', \"                'attr_num': v.attr_num,\\n\", \"                'byteswap': v.byteswap,\\n\", \"                'length': v.length,\\n\", '        return ret\\n', \"        logger.debug('reading a fatzap')\\n\", '        data = ondisk.fatzap.parse_fatzap(raw_fz)\\n', '        return data\\n', '        hdr = ondisk.BPObjHeader(dnode.bonus)\\n', '        logger.info(hdr)\\n', '        data = self.pool.read_dnode(dnode)\\n', '        data = BytesIO(data)\\n', '        return [ondisk.Blockptr(data) for _ in range(hdr.length)]\\n', '        data = self.pool.read_dnode(dnode)\\n', '        length = int(len(data) / 8)\\n', \"        format_code = '<' + (length * 'Q')\\n\", '        return {i+1: x for i, x in enumerate(struct.unpack(format_code, data)) if x != 0}\\n', '        nv = self.pool.read_block(dnode.blkptr[0])\\n', '        nv = nv[:dnode.used]\\n', '        nvl = nvlist.NVList(nv)\\n', '        nvdata = nvl.unpack_nvlist()\\n', '        return nvdata\\n', '        dsl_dir = ondisk.DSLDir(dnode.bonus)\\n', '        return datasets.Dataset(self.pool, dsl_dir, self, dnode)\\n', '        data = self.pool.read_dnode(dnode)\\n', '        history_parser = history.HistoryParser(data)\\n', '        return history_parser.unpack_history()\\n']",
  "context": "e == ObjectType.SA_ATTR_REGISTRATION:\n            r = {z.hdr.name: z for z in mzaps if z.hdr.name != ''}\n            return r\n        else:\n            r ="
 },
 "163": {
  "name": "r",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/objectset.py",
  "lineno": "168",
  "column": "12",
  "slicing": "['logger = logging.getLogger(__name__)\\n', '        blocks = []\\n', '        for blkptr in strct.meta_dnode.blkptr:\\n', '            block = pool.read_indirect(blkptr)\\n', '            blocks.append(block)\\n', \"        return ObjectSet(pool, strct, b''.join(blocks), dataset=dataset)\\n\", '        objset_struct = ondisk.Objset_for(pool.version)(block)\\n', '        objset = ObjectSet.from_struct(pool, objset_struct, dataset=dataset)\\n', '        return objset\\n', '        self.objset = objset\\n', '            return [self[i] for i in range(index.start or 0, index.stop or len(self.objset)//512, index.step or 1)]\\n', '        length = len(self.objset)//512\\n', '        for i in range(length):\\n', '            yield self.get_dnode(i)\\n', '            offset = index * 512\\n', '            dn = ondisk.DNode(self.objset[offset:offset+512])\\n', '            dn.index = index\\n', '            self.dnodes[index] = dn\\n', '        nt = dnode.node_type\\n', '            if nt == ObjectType.NONE:\\n', '            elif nt == ObjectType.OBJECT_DIRECTORY:\\n', '            elif nt == ObjectType.DSL_DIR_CHILD_MAP:\\n', '            elif nt == ObjectType.DSL_DS_SNAP_MAP:\\n', '            elif nt == ObjectType.NEXT_CLONES:\\n', '            elif nt == ObjectType.DEADLIST:\\n', '            elif nt == ObjectType.DSL_CLONES:\\n', '            elif nt == ObjectType.MASTER_NODE:\\n', '            elif nt == ObjectType.PLAIN_FILE_CONTENTS:\\n', '            elif nt == ObjectType.DIRECTORY_CONTENTS:\\n', '            elif nt == ObjectType.SA_MASTER_NODE:\\n', '            elif nt == ObjectType.UNLINKED_SET:\\n', '            elif nt == ObjectType.SA_ATTR_REGISTRATION:\\n', '            elif nt == ObjectType.SA_ATTR_LAYOUTS:\\n', '            elif nt == ObjectType.DSL_PROPS:\\n', '            elif nt == ObjectType.FEATURE_DESCRIPTION:\\n', '            elif nt == ObjectType.ZVOL_PROP:\\n', '            elif nt == ObjectType.SPA_HISTORY:\\n', '            elif nt == ObjectType.OBJECT_ARRAY:\\n', '            elif nt == ObjectType.PACKED_NVLIST:\\n', '            elif nt == ObjectType.DSL_DATASET:\\n', '            elif nt == ObjectType.DSL_DIR:\\n', '            elif nt == ObjectType.BPOBJ:\\n', \"                ds = self.dataset.path.replace('/', '-')\\n\", \"                with open('failed/{}_{}_{}'.format(ds, nt.name, index or '-'), 'wb') as f:\\n\", '                    f.write(self.pool.read_dnode(dnode))\\n', '        entries = self.read_zap(dnode)\\n', '        newdir = posix.Directory(dnode, entries, self.dataset, self)\\n', '        return newdir\\n', '        raw_zap = self.pool.read_dnode(dnode)\\n', '        zap = BytesIO(raw_zap)\\n', '        hdr = zfs.ondisk.zap.MicroZAPHeader(zap)\\n', '        if hdr.block_type == zfs.ondisk.zap.ZapType.ZAPHeader:\\n', '            return self._read_fatzap(raw_zap)\\n', '            return self._read_microzap(dnode, hdr, zap)\\n', '        node_type = dnode.node_type\\n', '        max_entries = int((len(zap.getvalue()) - 128) / 64)\\n', '        mzaps = []\\n', '        if node_type == ObjectType.SA_ATTR_REGISTRATION:\\n', '            mzap_type = zfs.ondisk.zap.SARegistrationMicroZAP\\n', '            mzap_type = zfs.ondisk.zap.MicroZAP\\n', '        if hdr.block_type == zfs.ondisk.zap.ZapType.MicroZAP:\\n', '            while len(mzaps) <= max_entries:\\n', '                mzaps.append(mzap_type(zap))\\n', '        if node_type == ObjectType.SA_ATTR_REGISTRATION:\\n', \"            r = {z.hdr.name: z for z in mzaps if z.hdr.name != ''}\\n\", '            return r\\n', \"            r = {z.hdr.name: z.value for z in mzaps if z.hdr.name != ''}\\n\", '            return r\\n', '        data = self.read_zap(dnode)\\n', '        ret = {}\\n', '        for k, v in data.items():\\n', '            ret[k] = {\\n', \"                'attr_num': v.attr_num,\\n\", \"                'byteswap': v.byteswap,\\n\", \"                'length': v.length,\\n\", '        return ret\\n', \"        logger.debug('reading a fatzap')\\n\", '        data = ondisk.fatzap.parse_fatzap(raw_fz)\\n', '        return data\\n', '        hdr = ondisk.BPObjHeader(dnode.bonus)\\n', '        logger.info(hdr)\\n', '        data = self.pool.read_dnode(dnode)\\n', '        data = BytesIO(data)\\n', '        return [ondisk.Blockptr(data) for _ in range(hdr.length)]\\n', '        data = self.pool.read_dnode(dnode)\\n', '        length = int(len(data) / 8)\\n', \"        format_code = '<' + (length * 'Q')\\n\", '        return {i+1: x for i, x in enumerate(struct.unpack(format_code, data)) if x != 0}\\n', '        nv = self.pool.read_block(dnode.blkptr[0])\\n', '        nv = nv[:dnode.used]\\n', '        nvl = nvlist.NVList(nv)\\n', '        nvdata = nvl.unpack_nvlist()\\n', '        return nvdata\\n', '        dsl_dir = ondisk.DSLDir(dnode.bonus)\\n', '        return datasets.Dataset(self.pool, dsl_dir, self, dnode)\\n', '        data = self.pool.read_dnode(dnode)\\n', '        history_parser = history.HistoryParser(data)\\n', '        return history_parser.unpack_history()\\n']",
  "context": "'}\n            return r\n        else:\n            r = {z.hdr.name: z.value for z in mzaps if z.hdr.name != ''}\n            return r\n\n    def read_attr_registrati"
 },
 "164": {
  "name": "data",
  "type": "dict",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/objectset.py",
  "lineno": "172",
  "column": "8",
  "slicing": "['logger = logging.getLogger(__name__)\\n', '        blocks = []\\n', '        for blkptr in strct.meta_dnode.blkptr:\\n', '            block = pool.read_indirect(blkptr)\\n', '            blocks.append(block)\\n', \"        return ObjectSet(pool, strct, b''.join(blocks), dataset=dataset)\\n\", '        objset_struct = ondisk.Objset_for(pool.version)(block)\\n', '        objset = ObjectSet.from_struct(pool, objset_struct, dataset=dataset)\\n', '        return objset\\n', '        self.objset = objset\\n', '            return [self[i] for i in range(index.start or 0, index.stop or len(self.objset)//512, index.step or 1)]\\n', '        length = len(self.objset)//512\\n', '        for i in range(length):\\n', '            yield self.get_dnode(i)\\n', '            offset = index * 512\\n', '            dn = ondisk.DNode(self.objset[offset:offset+512])\\n', '            dn.index = index\\n', '            self.dnodes[index] = dn\\n', '        nt = dnode.node_type\\n', '            if nt == ObjectType.NONE:\\n', '            elif nt == ObjectType.OBJECT_DIRECTORY:\\n', '            elif nt == ObjectType.DSL_DIR_CHILD_MAP:\\n', '            elif nt == ObjectType.DSL_DS_SNAP_MAP:\\n', '            elif nt == ObjectType.NEXT_CLONES:\\n', '            elif nt == ObjectType.DEADLIST:\\n', '            elif nt == ObjectType.DSL_CLONES:\\n', '            elif nt == ObjectType.MASTER_NODE:\\n', '            elif nt == ObjectType.PLAIN_FILE_CONTENTS:\\n', '            elif nt == ObjectType.DIRECTORY_CONTENTS:\\n', '            elif nt == ObjectType.SA_MASTER_NODE:\\n', '            elif nt == ObjectType.UNLINKED_SET:\\n', '            elif nt == ObjectType.SA_ATTR_REGISTRATION:\\n', '            elif nt == ObjectType.SA_ATTR_LAYOUTS:\\n', '            elif nt == ObjectType.DSL_PROPS:\\n', '            elif nt == ObjectType.FEATURE_DESCRIPTION:\\n', '            elif nt == ObjectType.ZVOL_PROP:\\n', '            elif nt == ObjectType.SPA_HISTORY:\\n', '            elif nt == ObjectType.OBJECT_ARRAY:\\n', '            elif nt == ObjectType.PACKED_NVLIST:\\n', '            elif nt == ObjectType.DSL_DATASET:\\n', '            elif nt == ObjectType.DSL_DIR:\\n', '            elif nt == ObjectType.BPOBJ:\\n', \"                ds = self.dataset.path.replace('/', '-')\\n\", \"                with open('failed/{}_{}_{}'.format(ds, nt.name, index or '-'), 'wb') as f:\\n\", '                    f.write(self.pool.read_dnode(dnode))\\n', '        entries = self.read_zap(dnode)\\n', '        newdir = posix.Directory(dnode, entries, self.dataset, self)\\n', '        return newdir\\n', '        raw_zap = self.pool.read_dnode(dnode)\\n', '        zap = BytesIO(raw_zap)\\n', '        hdr = zfs.ondisk.zap.MicroZAPHeader(zap)\\n', '        if hdr.block_type == zfs.ondisk.zap.ZapType.ZAPHeader:\\n', '            return self._read_fatzap(raw_zap)\\n', '            return self._read_microzap(dnode, hdr, zap)\\n', '        node_type = dnode.node_type\\n', '        max_entries = int((len(zap.getvalue()) - 128) / 64)\\n', '        mzaps = []\\n', '        if node_type == ObjectType.SA_ATTR_REGISTRATION:\\n', '            mzap_type = zfs.ondisk.zap.SARegistrationMicroZAP\\n', '            mzap_type = zfs.ondisk.zap.MicroZAP\\n', '        if hdr.block_type == zfs.ondisk.zap.ZapType.MicroZAP:\\n', '            while len(mzaps) <= max_entries:\\n', '                mzaps.append(mzap_type(zap))\\n', '        if node_type == ObjectType.SA_ATTR_REGISTRATION:\\n', \"            r = {z.hdr.name: z for z in mzaps if z.hdr.name != ''}\\n\", '            return r\\n', \"            r = {z.hdr.name: z.value for z in mzaps if z.hdr.name != ''}\\n\", '            return r\\n', '        data = self.read_zap(dnode)\\n', '        ret = {}\\n', '        for k, v in data.items():\\n', '            ret[k] = {\\n', \"                'attr_num': v.attr_num,\\n\", \"                'byteswap': v.byteswap,\\n\", \"                'length': v.length,\\n\", '        return ret\\n', \"        logger.debug('reading a fatzap')\\n\", '        data = ondisk.fatzap.parse_fatzap(raw_fz)\\n', '        return data\\n', '        hdr = ondisk.BPObjHeader(dnode.bonus)\\n', '        logger.info(hdr)\\n', '        data = self.pool.read_dnode(dnode)\\n', '        data = BytesIO(data)\\n', '        return [ondisk.Blockptr(data) for _ in range(hdr.length)]\\n', '        data = self.pool.read_dnode(dnode)\\n', '        length = int(len(data) / 8)\\n', \"        format_code = '<' + (length * 'Q')\\n\", '        return {i+1: x for i, x in enumerate(struct.unpack(format_code, data)) if x != 0}\\n', '        nv = self.pool.read_block(dnode.blkptr[0])\\n', '        nv = nv[:dnode.used]\\n', '        nvl = nvlist.NVList(nv)\\n', '        nvdata = nvl.unpack_nvlist()\\n', '        return nvdata\\n', '        dsl_dir = ondisk.DSLDir(dnode.bonus)\\n', '        return datasets.Dataset(self.pool, dsl_dir, self, dnode)\\n', '        data = self.pool.read_dnode(dnode)\\n', '        history_parser = history.HistoryParser(data)\\n', '        return history_parser.unpack_history()\\n']",
  "context": "ation(self, dnode: ondisk.DNode) -> Dict:\n        data = self.read_zap(dnode)\n        ret = {}\n        for k, v in data.items():"
 },
 "165": {
  "name": "ret",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/objectset.py",
  "lineno": "173",
  "column": "8",
  "slicing": "['        ret = {}\\n', '            ret[k] = {\\n', '        return ret\\n']",
  "context": "Dict:\n        data = self.read_zap(dnode)\n        ret = {}\n        for k, v in data.items():\n            ret["
 },
 "166": {
  "name": "raw_fz",
  "type": "bytes",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/objectset.py",
  "lineno": "182",
  "column": "27",
  "slicing": "['    def _read_fatzap(self, raw_fz: bytes) -> Dict[str, Any]:\\n']",
  "context": " }\n        return ret\n\n    def _read_fatzap(self, raw_fz: bytes) -> Dict[str, Any]:\n        logger.debug('reading a fatzap')\n        d"
 },
 "167": {
  "name": "data",
  "type": "io.BytesIO",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/objectset.py",
  "lineno": "191",
  "column": "8",
  "slicing": "['logger = logging.getLogger(__name__)\\n', '        blocks = []\\n', '        for blkptr in strct.meta_dnode.blkptr:\\n', '            block = pool.read_indirect(blkptr)\\n', '            blocks.append(block)\\n', \"        return ObjectSet(pool, strct, b''.join(blocks), dataset=dataset)\\n\", '        objset_struct = ondisk.Objset_for(pool.version)(block)\\n', '        objset = ObjectSet.from_struct(pool, objset_struct, dataset=dataset)\\n', '        return objset\\n', '        self.objset = objset\\n', '            return [self[i] for i in range(index.start or 0, index.stop or len(self.objset)//512, index.step or 1)]\\n', '        length = len(self.objset)//512\\n', '        for i in range(length):\\n', '            yield self.get_dnode(i)\\n', '            offset = index * 512\\n', '            dn = ondisk.DNode(self.objset[offset:offset+512])\\n', '            dn.index = index\\n', '            self.dnodes[index] = dn\\n', '        nt = dnode.node_type\\n', '            if nt == ObjectType.NONE:\\n', '            elif nt == ObjectType.OBJECT_DIRECTORY:\\n', '            elif nt == ObjectType.DSL_DIR_CHILD_MAP:\\n', '            elif nt == ObjectType.DSL_DS_SNAP_MAP:\\n', '            elif nt == ObjectType.NEXT_CLONES:\\n', '            elif nt == ObjectType.DEADLIST:\\n', '            elif nt == ObjectType.DSL_CLONES:\\n', '            elif nt == ObjectType.MASTER_NODE:\\n', '            elif nt == ObjectType.PLAIN_FILE_CONTENTS:\\n', '            elif nt == ObjectType.DIRECTORY_CONTENTS:\\n', '            elif nt == ObjectType.SA_MASTER_NODE:\\n', '            elif nt == ObjectType.UNLINKED_SET:\\n', '            elif nt == ObjectType.SA_ATTR_REGISTRATION:\\n', '            elif nt == ObjectType.SA_ATTR_LAYOUTS:\\n', '            elif nt == ObjectType.DSL_PROPS:\\n', '            elif nt == ObjectType.FEATURE_DESCRIPTION:\\n', '            elif nt == ObjectType.ZVOL_PROP:\\n', '            elif nt == ObjectType.SPA_HISTORY:\\n', '            elif nt == ObjectType.OBJECT_ARRAY:\\n', '            elif nt == ObjectType.PACKED_NVLIST:\\n', '            elif nt == ObjectType.DSL_DATASET:\\n', '            elif nt == ObjectType.DSL_DIR:\\n', '            elif nt == ObjectType.BPOBJ:\\n', \"                ds = self.dataset.path.replace('/', '-')\\n\", \"                with open('failed/{}_{}_{}'.format(ds, nt.name, index or '-'), 'wb') as f:\\n\", '                    f.write(self.pool.read_dnode(dnode))\\n', '        entries = self.read_zap(dnode)\\n', '        newdir = posix.Directory(dnode, entries, self.dataset, self)\\n', '        return newdir\\n', '        raw_zap = self.pool.read_dnode(dnode)\\n', '        zap = BytesIO(raw_zap)\\n', '        hdr = zfs.ondisk.zap.MicroZAPHeader(zap)\\n', '        if hdr.block_type == zfs.ondisk.zap.ZapType.ZAPHeader:\\n', '            return self._read_fatzap(raw_zap)\\n', '            return self._read_microzap(dnode, hdr, zap)\\n', '        node_type = dnode.node_type\\n', '        max_entries = int((len(zap.getvalue()) - 128) / 64)\\n', '        mzaps = []\\n', '        if node_type == ObjectType.SA_ATTR_REGISTRATION:\\n', '            mzap_type = zfs.ondisk.zap.SARegistrationMicroZAP\\n', '            mzap_type = zfs.ondisk.zap.MicroZAP\\n', '        if hdr.block_type == zfs.ondisk.zap.ZapType.MicroZAP:\\n', '            while len(mzaps) <= max_entries:\\n', '                mzaps.append(mzap_type(zap))\\n', '        if node_type == ObjectType.SA_ATTR_REGISTRATION:\\n', \"            r = {z.hdr.name: z for z in mzaps if z.hdr.name != ''}\\n\", '            return r\\n', \"            r = {z.hdr.name: z.value for z in mzaps if z.hdr.name != ''}\\n\", '            return r\\n', '        data = self.read_zap(dnode)\\n', '        ret = {}\\n', '        for k, v in data.items():\\n', '            ret[k] = {\\n', \"                'attr_num': v.attr_num,\\n\", \"                'byteswap': v.byteswap,\\n\", \"                'length': v.length,\\n\", '        return ret\\n', \"        logger.debug('reading a fatzap')\\n\", '        data = ondisk.fatzap.parse_fatzap(raw_fz)\\n', '        return data\\n', '        hdr = ondisk.BPObjHeader(dnode.bonus)\\n', '        logger.info(hdr)\\n', '        data = self.pool.read_dnode(dnode)\\n', '        data = BytesIO(data)\\n', '        return [ondisk.Blockptr(data) for _ in range(hdr.length)]\\n', '        data = self.pool.read_dnode(dnode)\\n', '        length = int(len(data) / 8)\\n', \"        format_code = '<' + (length * 'Q')\\n\", '        return {i+1: x for i, x in enumerate(struct.unpack(format_code, data)) if x != 0}\\n', '        nv = self.pool.read_block(dnode.blkptr[0])\\n', '        nv = nv[:dnode.used]\\n', '        nvl = nvlist.NVList(nv)\\n', '        nvdata = nvl.unpack_nvlist()\\n', '        return nvdata\\n', '        dsl_dir = ondisk.DSLDir(dnode.bonus)\\n', '        return datasets.Dataset(self.pool, dsl_dir, self, dnode)\\n', '        data = self.pool.read_dnode(dnode)\\n', '        history_parser = history.HistoryParser(data)\\n', '        return history_parser.unpack_history()\\n']",
  "context": "       data = self.pool.read_dnode(dnode)\n        data = BytesIO(data)\n        return [ondisk.Blockptr(data) for _ in ran"
 },
 "168": {
  "name": "length",
  "type": "int",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/objectset.py",
  "lineno": "196",
  "column": "8",
  "slicing": "['logger = logging.getLogger(__name__)\\n', '        blocks = []\\n', '        for blkptr in strct.meta_dnode.blkptr:\\n', '            block = pool.read_indirect(blkptr)\\n', '            blocks.append(block)\\n', \"        return ObjectSet(pool, strct, b''.join(blocks), dataset=dataset)\\n\", '        objset_struct = ondisk.Objset_for(pool.version)(block)\\n', '        objset = ObjectSet.from_struct(pool, objset_struct, dataset=dataset)\\n', '        return objset\\n', '        self.objset = objset\\n', '            return [self[i] for i in range(index.start or 0, index.stop or len(self.objset)//512, index.step or 1)]\\n', '        length = len(self.objset)//512\\n', '        for i in range(length):\\n', '            yield self.get_dnode(i)\\n', '            offset = index * 512\\n', '            dn = ondisk.DNode(self.objset[offset:offset+512])\\n', '            dn.index = index\\n', '            self.dnodes[index] = dn\\n', '        nt = dnode.node_type\\n', '            if nt == ObjectType.NONE:\\n', '            elif nt == ObjectType.OBJECT_DIRECTORY:\\n', '            elif nt == ObjectType.DSL_DIR_CHILD_MAP:\\n', '            elif nt == ObjectType.DSL_DS_SNAP_MAP:\\n', '            elif nt == ObjectType.NEXT_CLONES:\\n', '            elif nt == ObjectType.DEADLIST:\\n', '            elif nt == ObjectType.DSL_CLONES:\\n', '            elif nt == ObjectType.MASTER_NODE:\\n', '            elif nt == ObjectType.PLAIN_FILE_CONTENTS:\\n', '            elif nt == ObjectType.DIRECTORY_CONTENTS:\\n', '            elif nt == ObjectType.SA_MASTER_NODE:\\n', '            elif nt == ObjectType.UNLINKED_SET:\\n', '            elif nt == ObjectType.SA_ATTR_REGISTRATION:\\n', '            elif nt == ObjectType.SA_ATTR_LAYOUTS:\\n', '            elif nt == ObjectType.DSL_PROPS:\\n', '            elif nt == ObjectType.FEATURE_DESCRIPTION:\\n', '            elif nt == ObjectType.ZVOL_PROP:\\n', '            elif nt == ObjectType.SPA_HISTORY:\\n', '            elif nt == ObjectType.OBJECT_ARRAY:\\n', '            elif nt == ObjectType.PACKED_NVLIST:\\n', '            elif nt == ObjectType.DSL_DATASET:\\n', '            elif nt == ObjectType.DSL_DIR:\\n', '            elif nt == ObjectType.BPOBJ:\\n', \"                ds = self.dataset.path.replace('/', '-')\\n\", \"                with open('failed/{}_{}_{}'.format(ds, nt.name, index or '-'), 'wb') as f:\\n\", '                    f.write(self.pool.read_dnode(dnode))\\n', '        entries = self.read_zap(dnode)\\n', '        newdir = posix.Directory(dnode, entries, self.dataset, self)\\n', '        return newdir\\n', '        raw_zap = self.pool.read_dnode(dnode)\\n', '        zap = BytesIO(raw_zap)\\n', '        hdr = zfs.ondisk.zap.MicroZAPHeader(zap)\\n', '        if hdr.block_type == zfs.ondisk.zap.ZapType.ZAPHeader:\\n', '            return self._read_fatzap(raw_zap)\\n', '            return self._read_microzap(dnode, hdr, zap)\\n', '        node_type = dnode.node_type\\n', '        max_entries = int((len(zap.getvalue()) - 128) / 64)\\n', '        mzaps = []\\n', '        if node_type == ObjectType.SA_ATTR_REGISTRATION:\\n', '            mzap_type = zfs.ondisk.zap.SARegistrationMicroZAP\\n', '            mzap_type = zfs.ondisk.zap.MicroZAP\\n', '        if hdr.block_type == zfs.ondisk.zap.ZapType.MicroZAP:\\n', '            while len(mzaps) <= max_entries:\\n', '                mzaps.append(mzap_type(zap))\\n', '        if node_type == ObjectType.SA_ATTR_REGISTRATION:\\n', \"            r = {z.hdr.name: z for z in mzaps if z.hdr.name != ''}\\n\", '            return r\\n', \"            r = {z.hdr.name: z.value for z in mzaps if z.hdr.name != ''}\\n\", '            return r\\n', '        data = self.read_zap(dnode)\\n', '        ret = {}\\n', '        for k, v in data.items():\\n', '            ret[k] = {\\n', \"                'attr_num': v.attr_num,\\n\", \"                'byteswap': v.byteswap,\\n\", \"                'length': v.length,\\n\", '        return ret\\n', \"        logger.debug('reading a fatzap')\\n\", '        data = ondisk.fatzap.parse_fatzap(raw_fz)\\n', '        return data\\n', '        hdr = ondisk.BPObjHeader(dnode.bonus)\\n', '        logger.info(hdr)\\n', '        data = self.pool.read_dnode(dnode)\\n', '        data = BytesIO(data)\\n', '        return [ondisk.Blockptr(data) for _ in range(hdr.length)]\\n', '        data = self.pool.read_dnode(dnode)\\n', '        length = int(len(data) / 8)\\n', \"        format_code = '<' + (length * 'Q')\\n\", '        return {i+1: x for i, x in enumerate(struct.unpack(format_code, data)) if x != 0}\\n', '        nv = self.pool.read_block(dnode.blkptr[0])\\n', '        nv = nv[:dnode.used]\\n', '        nvl = nvlist.NVList(nv)\\n', '        nvdata = nvl.unpack_nvlist()\\n', '        return nvdata\\n', '        dsl_dir = ondisk.DSLDir(dnode.bonus)\\n', '        return datasets.Dataset(self.pool, dsl_dir, self, dnode)\\n', '        data = self.pool.read_dnode(dnode)\\n', '        history_parser = history.HistoryParser(data)\\n', '        return history_parser.unpack_history()\\n']",
  "context": "       data = self.pool.read_dnode(dnode)\n        length = int(len(data) / 8)\n        format_code = '<' + (length * 'Q')\n       "
 },
 "169": {
  "name": "nv",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/objectset.py",
  "lineno": "202",
  "column": "8",
  "slicing": "['logger = logging.getLogger(__name__)\\n', '        blocks = []\\n', '        for blkptr in strct.meta_dnode.blkptr:\\n', '            block = pool.read_indirect(blkptr)\\n', '            blocks.append(block)\\n', \"        return ObjectSet(pool, strct, b''.join(blocks), dataset=dataset)\\n\", '        objset_struct = ondisk.Objset_for(pool.version)(block)\\n', '        objset = ObjectSet.from_struct(pool, objset_struct, dataset=dataset)\\n', '        return objset\\n', '        self.objset = objset\\n', '            return [self[i] for i in range(index.start or 0, index.stop or len(self.objset)//512, index.step or 1)]\\n', '        length = len(self.objset)//512\\n', '        for i in range(length):\\n', '            yield self.get_dnode(i)\\n', '            offset = index * 512\\n', '            dn = ondisk.DNode(self.objset[offset:offset+512])\\n', '            dn.index = index\\n', '            self.dnodes[index] = dn\\n', '        nt = dnode.node_type\\n', '            if nt == ObjectType.NONE:\\n', '            elif nt == ObjectType.OBJECT_DIRECTORY:\\n', '            elif nt == ObjectType.DSL_DIR_CHILD_MAP:\\n', '            elif nt == ObjectType.DSL_DS_SNAP_MAP:\\n', '            elif nt == ObjectType.NEXT_CLONES:\\n', '            elif nt == ObjectType.DEADLIST:\\n', '            elif nt == ObjectType.DSL_CLONES:\\n', '            elif nt == ObjectType.MASTER_NODE:\\n', '            elif nt == ObjectType.PLAIN_FILE_CONTENTS:\\n', '            elif nt == ObjectType.DIRECTORY_CONTENTS:\\n', '            elif nt == ObjectType.SA_MASTER_NODE:\\n', '            elif nt == ObjectType.UNLINKED_SET:\\n', '            elif nt == ObjectType.SA_ATTR_REGISTRATION:\\n', '            elif nt == ObjectType.SA_ATTR_LAYOUTS:\\n', '            elif nt == ObjectType.DSL_PROPS:\\n', '            elif nt == ObjectType.FEATURE_DESCRIPTION:\\n', '            elif nt == ObjectType.ZVOL_PROP:\\n', '            elif nt == ObjectType.SPA_HISTORY:\\n', '            elif nt == ObjectType.OBJECT_ARRAY:\\n', '            elif nt == ObjectType.PACKED_NVLIST:\\n', '            elif nt == ObjectType.DSL_DATASET:\\n', '            elif nt == ObjectType.DSL_DIR:\\n', '            elif nt == ObjectType.BPOBJ:\\n', \"                ds = self.dataset.path.replace('/', '-')\\n\", \"                with open('failed/{}_{}_{}'.format(ds, nt.name, index or '-'), 'wb') as f:\\n\", '                    f.write(self.pool.read_dnode(dnode))\\n', '        entries = self.read_zap(dnode)\\n', '        newdir = posix.Directory(dnode, entries, self.dataset, self)\\n', '        return newdir\\n', '        raw_zap = self.pool.read_dnode(dnode)\\n', '        zap = BytesIO(raw_zap)\\n', '        hdr = zfs.ondisk.zap.MicroZAPHeader(zap)\\n', '        if hdr.block_type == zfs.ondisk.zap.ZapType.ZAPHeader:\\n', '            return self._read_fatzap(raw_zap)\\n', '            return self._read_microzap(dnode, hdr, zap)\\n', '        node_type = dnode.node_type\\n', '        max_entries = int((len(zap.getvalue()) - 128) / 64)\\n', '        mzaps = []\\n', '        if node_type == ObjectType.SA_ATTR_REGISTRATION:\\n', '            mzap_type = zfs.ondisk.zap.SARegistrationMicroZAP\\n', '            mzap_type = zfs.ondisk.zap.MicroZAP\\n', '        if hdr.block_type == zfs.ondisk.zap.ZapType.MicroZAP:\\n', '            while len(mzaps) <= max_entries:\\n', '                mzaps.append(mzap_type(zap))\\n', '        if node_type == ObjectType.SA_ATTR_REGISTRATION:\\n', \"            r = {z.hdr.name: z for z in mzaps if z.hdr.name != ''}\\n\", '            return r\\n', \"            r = {z.hdr.name: z.value for z in mzaps if z.hdr.name != ''}\\n\", '            return r\\n', '        data = self.read_zap(dnode)\\n', '        ret = {}\\n', '        for k, v in data.items():\\n', '            ret[k] = {\\n', \"                'attr_num': v.attr_num,\\n\", \"                'byteswap': v.byteswap,\\n\", \"                'length': v.length,\\n\", '        return ret\\n', \"        logger.debug('reading a fatzap')\\n\", '        data = ondisk.fatzap.parse_fatzap(raw_fz)\\n', '        return data\\n', '        hdr = ondisk.BPObjHeader(dnode.bonus)\\n', '        logger.info(hdr)\\n', '        data = self.pool.read_dnode(dnode)\\n', '        data = BytesIO(data)\\n', '        return [ondisk.Blockptr(data) for _ in range(hdr.length)]\\n', '        data = self.pool.read_dnode(dnode)\\n', '        length = int(len(data) / 8)\\n', \"        format_code = '<' + (length * 'Q')\\n\", '        return {i+1: x for i, x in enumerate(struct.unpack(format_code, data)) if x != 0}\\n', '        nv = self.pool.read_block(dnode.blkptr[0])\\n', '        nv = nv[:dnode.used]\\n', '        nvl = nvlist.NVList(nv)\\n', '        nvdata = nvl.unpack_nvlist()\\n', '        return nvdata\\n', '        dsl_dir = ondisk.DSLDir(dnode.bonus)\\n', '        return datasets.Dataset(self.pool, dsl_dir, self, dnode)\\n', '        data = self.pool.read_dnode(dnode)\\n', '        history_parser = history.HistoryParser(data)\\n', '        return history_parser.unpack_history()\\n']",
  "context": "v = self.pool.read_block(dnode.blkptr[0])\n        nv = nv[:dnode.used]\n        nvl = nvlist.NVList(nv)\n        nvdata = n"
 },
 "170": {
  "name": "nvl",
  "type": "nvlist.NVList",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/objectset.py",
  "lineno": "203",
  "column": "8",
  "slicing": "['logger = logging.getLogger(__name__)\\n', '        blocks = []\\n', '        for blkptr in strct.meta_dnode.blkptr:\\n', '            block = pool.read_indirect(blkptr)\\n', '            blocks.append(block)\\n', \"        return ObjectSet(pool, strct, b''.join(blocks), dataset=dataset)\\n\", '        objset_struct = ondisk.Objset_for(pool.version)(block)\\n', '        objset = ObjectSet.from_struct(pool, objset_struct, dataset=dataset)\\n', '        return objset\\n', '        self.objset = objset\\n', '            return [self[i] for i in range(index.start or 0, index.stop or len(self.objset)//512, index.step or 1)]\\n', '        length = len(self.objset)//512\\n', '        for i in range(length):\\n', '            yield self.get_dnode(i)\\n', '            offset = index * 512\\n', '            dn = ondisk.DNode(self.objset[offset:offset+512])\\n', '            dn.index = index\\n', '            self.dnodes[index] = dn\\n', '        nt = dnode.node_type\\n', '            if nt == ObjectType.NONE:\\n', '            elif nt == ObjectType.OBJECT_DIRECTORY:\\n', '            elif nt == ObjectType.DSL_DIR_CHILD_MAP:\\n', '            elif nt == ObjectType.DSL_DS_SNAP_MAP:\\n', '            elif nt == ObjectType.NEXT_CLONES:\\n', '            elif nt == ObjectType.DEADLIST:\\n', '            elif nt == ObjectType.DSL_CLONES:\\n', '            elif nt == ObjectType.MASTER_NODE:\\n', '            elif nt == ObjectType.PLAIN_FILE_CONTENTS:\\n', '            elif nt == ObjectType.DIRECTORY_CONTENTS:\\n', '            elif nt == ObjectType.SA_MASTER_NODE:\\n', '            elif nt == ObjectType.UNLINKED_SET:\\n', '            elif nt == ObjectType.SA_ATTR_REGISTRATION:\\n', '            elif nt == ObjectType.SA_ATTR_LAYOUTS:\\n', '            elif nt == ObjectType.DSL_PROPS:\\n', '            elif nt == ObjectType.FEATURE_DESCRIPTION:\\n', '            elif nt == ObjectType.ZVOL_PROP:\\n', '            elif nt == ObjectType.SPA_HISTORY:\\n', '            elif nt == ObjectType.OBJECT_ARRAY:\\n', '            elif nt == ObjectType.PACKED_NVLIST:\\n', '            elif nt == ObjectType.DSL_DATASET:\\n', '            elif nt == ObjectType.DSL_DIR:\\n', '            elif nt == ObjectType.BPOBJ:\\n', \"                ds = self.dataset.path.replace('/', '-')\\n\", \"                with open('failed/{}_{}_{}'.format(ds, nt.name, index or '-'), 'wb') as f:\\n\", '                    f.write(self.pool.read_dnode(dnode))\\n', '        entries = self.read_zap(dnode)\\n', '        newdir = posix.Directory(dnode, entries, self.dataset, self)\\n', '        return newdir\\n', '        raw_zap = self.pool.read_dnode(dnode)\\n', '        zap = BytesIO(raw_zap)\\n', '        hdr = zfs.ondisk.zap.MicroZAPHeader(zap)\\n', '        if hdr.block_type == zfs.ondisk.zap.ZapType.ZAPHeader:\\n', '            return self._read_fatzap(raw_zap)\\n', '            return self._read_microzap(dnode, hdr, zap)\\n', '        node_type = dnode.node_type\\n', '        max_entries = int((len(zap.getvalue()) - 128) / 64)\\n', '        mzaps = []\\n', '        if node_type == ObjectType.SA_ATTR_REGISTRATION:\\n', '            mzap_type = zfs.ondisk.zap.SARegistrationMicroZAP\\n', '            mzap_type = zfs.ondisk.zap.MicroZAP\\n', '        if hdr.block_type == zfs.ondisk.zap.ZapType.MicroZAP:\\n', '            while len(mzaps) <= max_entries:\\n', '                mzaps.append(mzap_type(zap))\\n', '        if node_type == ObjectType.SA_ATTR_REGISTRATION:\\n', \"            r = {z.hdr.name: z for z in mzaps if z.hdr.name != ''}\\n\", '            return r\\n', \"            r = {z.hdr.name: z.value for z in mzaps if z.hdr.name != ''}\\n\", '            return r\\n', '        data = self.read_zap(dnode)\\n', '        ret = {}\\n', '        for k, v in data.items():\\n', '            ret[k] = {\\n', \"                'attr_num': v.attr_num,\\n\", \"                'byteswap': v.byteswap,\\n\", \"                'length': v.length,\\n\", '        return ret\\n', \"        logger.debug('reading a fatzap')\\n\", '        data = ondisk.fatzap.parse_fatzap(raw_fz)\\n', '        return data\\n', '        hdr = ondisk.BPObjHeader(dnode.bonus)\\n', '        logger.info(hdr)\\n', '        data = self.pool.read_dnode(dnode)\\n', '        data = BytesIO(data)\\n', '        return [ondisk.Blockptr(data) for _ in range(hdr.length)]\\n', '        data = self.pool.read_dnode(dnode)\\n', '        length = int(len(data) / 8)\\n', \"        format_code = '<' + (length * 'Q')\\n\", '        return {i+1: x for i, x in enumerate(struct.unpack(format_code, data)) if x != 0}\\n', '        nv = self.pool.read_block(dnode.blkptr[0])\\n', '        nv = nv[:dnode.used]\\n', '        nvl = nvlist.NVList(nv)\\n', '        nvdata = nvl.unpack_nvlist()\\n', '        return nvdata\\n', '        dsl_dir = ondisk.DSLDir(dnode.bonus)\\n', '        return datasets.Dataset(self.pool, dsl_dir, self, dnode)\\n', '        data = self.pool.read_dnode(dnode)\\n', '        history_parser = history.HistoryParser(data)\\n', '        return history_parser.unpack_history()\\n']",
  "context": "e.blkptr[0])\n        nv = nv[:dnode.used]\n        nvl = nvlist.NVList(nv)\n        nvdata = nvl.unpack_nvlist()\n        retur"
 },
 "171": {
  "name": "nvdata",
  "type": "dict",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/objectset.py",
  "lineno": "204",
  "column": "8",
  "slicing": "['logger = logging.getLogger(__name__)\\n', '        blocks = []\\n', '        for blkptr in strct.meta_dnode.blkptr:\\n', '            block = pool.read_indirect(blkptr)\\n', '            blocks.append(block)\\n', \"        return ObjectSet(pool, strct, b''.join(blocks), dataset=dataset)\\n\", '        objset_struct = ondisk.Objset_for(pool.version)(block)\\n', '        objset = ObjectSet.from_struct(pool, objset_struct, dataset=dataset)\\n', '        return objset\\n', '        self.objset = objset\\n', '            return [self[i] for i in range(index.start or 0, index.stop or len(self.objset)//512, index.step or 1)]\\n', '        length = len(self.objset)//512\\n', '        for i in range(length):\\n', '            yield self.get_dnode(i)\\n', '            offset = index * 512\\n', '            dn = ondisk.DNode(self.objset[offset:offset+512])\\n', '            dn.index = index\\n', '            self.dnodes[index] = dn\\n', '        nt = dnode.node_type\\n', '            if nt == ObjectType.NONE:\\n', '            elif nt == ObjectType.OBJECT_DIRECTORY:\\n', '            elif nt == ObjectType.DSL_DIR_CHILD_MAP:\\n', '            elif nt == ObjectType.DSL_DS_SNAP_MAP:\\n', '            elif nt == ObjectType.NEXT_CLONES:\\n', '            elif nt == ObjectType.DEADLIST:\\n', '            elif nt == ObjectType.DSL_CLONES:\\n', '            elif nt == ObjectType.MASTER_NODE:\\n', '            elif nt == ObjectType.PLAIN_FILE_CONTENTS:\\n', '            elif nt == ObjectType.DIRECTORY_CONTENTS:\\n', '            elif nt == ObjectType.SA_MASTER_NODE:\\n', '            elif nt == ObjectType.UNLINKED_SET:\\n', '            elif nt == ObjectType.SA_ATTR_REGISTRATION:\\n', '            elif nt == ObjectType.SA_ATTR_LAYOUTS:\\n', '            elif nt == ObjectType.DSL_PROPS:\\n', '            elif nt == ObjectType.FEATURE_DESCRIPTION:\\n', '            elif nt == ObjectType.ZVOL_PROP:\\n', '            elif nt == ObjectType.SPA_HISTORY:\\n', '            elif nt == ObjectType.OBJECT_ARRAY:\\n', '            elif nt == ObjectType.PACKED_NVLIST:\\n', '            elif nt == ObjectType.DSL_DATASET:\\n', '            elif nt == ObjectType.DSL_DIR:\\n', '            elif nt == ObjectType.BPOBJ:\\n', \"                ds = self.dataset.path.replace('/', '-')\\n\", \"                with open('failed/{}_{}_{}'.format(ds, nt.name, index or '-'), 'wb') as f:\\n\", '                    f.write(self.pool.read_dnode(dnode))\\n', '        entries = self.read_zap(dnode)\\n', '        newdir = posix.Directory(dnode, entries, self.dataset, self)\\n', '        return newdir\\n', '        raw_zap = self.pool.read_dnode(dnode)\\n', '        zap = BytesIO(raw_zap)\\n', '        hdr = zfs.ondisk.zap.MicroZAPHeader(zap)\\n', '        if hdr.block_type == zfs.ondisk.zap.ZapType.ZAPHeader:\\n', '            return self._read_fatzap(raw_zap)\\n', '            return self._read_microzap(dnode, hdr, zap)\\n', '        node_type = dnode.node_type\\n', '        max_entries = int((len(zap.getvalue()) - 128) / 64)\\n', '        mzaps = []\\n', '        if node_type == ObjectType.SA_ATTR_REGISTRATION:\\n', '            mzap_type = zfs.ondisk.zap.SARegistrationMicroZAP\\n', '            mzap_type = zfs.ondisk.zap.MicroZAP\\n', '        if hdr.block_type == zfs.ondisk.zap.ZapType.MicroZAP:\\n', '            while len(mzaps) <= max_entries:\\n', '                mzaps.append(mzap_type(zap))\\n', '        if node_type == ObjectType.SA_ATTR_REGISTRATION:\\n', \"            r = {z.hdr.name: z for z in mzaps if z.hdr.name != ''}\\n\", '            return r\\n', \"            r = {z.hdr.name: z.value for z in mzaps if z.hdr.name != ''}\\n\", '            return r\\n', '        data = self.read_zap(dnode)\\n', '        ret = {}\\n', '        for k, v in data.items():\\n', '            ret[k] = {\\n', \"                'attr_num': v.attr_num,\\n\", \"                'byteswap': v.byteswap,\\n\", \"                'length': v.length,\\n\", '        return ret\\n', \"        logger.debug('reading a fatzap')\\n\", '        data = ondisk.fatzap.parse_fatzap(raw_fz)\\n', '        return data\\n', '        hdr = ondisk.BPObjHeader(dnode.bonus)\\n', '        logger.info(hdr)\\n', '        data = self.pool.read_dnode(dnode)\\n', '        data = BytesIO(data)\\n', '        return [ondisk.Blockptr(data) for _ in range(hdr.length)]\\n', '        data = self.pool.read_dnode(dnode)\\n', '        length = int(len(data) / 8)\\n', \"        format_code = '<' + (length * 'Q')\\n\", '        return {i+1: x for i, x in enumerate(struct.unpack(format_code, data)) if x != 0}\\n', '        nv = self.pool.read_block(dnode.blkptr[0])\\n', '        nv = nv[:dnode.used]\\n', '        nvl = nvlist.NVList(nv)\\n', '        nvdata = nvl.unpack_nvlist()\\n', '        return nvdata\\n', '        dsl_dir = ondisk.DSLDir(dnode.bonus)\\n', '        return datasets.Dataset(self.pool, dsl_dir, self, dnode)\\n', '        data = self.pool.read_dnode(dnode)\\n', '        history_parser = history.HistoryParser(data)\\n', '        return history_parser.unpack_history()\\n']",
  "context": "ode.used]\n        nvl = nvlist.NVList(nv)\n        nvdata = nvl.unpack_nvlist()\n        return nvdata\n\n    def read_dataset(self, "
 },
 "172": {
  "name": "data",
  "type": "bytes",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/readcontext.py",
  "lineno": "22",
  "column": "23",
  "slicing": "['    def checksum(self, data: bytes, valid, checksum) -> bool:\\n']",
  "context": "f.try_config = try_config\n\n    def checksum(self, data: bytes, valid, checksum) -> bool:\n        return util.checksum(data, valid, checksum"
 },
 "173": {
  "name": "data",
  "type": "bytes",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/readcontext.py",
  "lineno": "25",
  "column": "25",
  "slicing": "['    def decompress(self, data: bytes, compression: Compression, actual_size: int) -> bytes:\\n']",
  "context": " self.default_checksum)\n\n    def decompress(self, data: bytes, compression: Compression, actual_size: int) -> bytes:\n        return util.decompress(data, compression, "
 },
 "174": {
  "name": "compression",
  "type": "constants.Compression",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/readcontext.py",
  "lineno": "25",
  "column": "38",
  "slicing": "['    def decompress(self, data: bytes, compression: Compression, actual_size: int) -> bytes:\\n']",
  "context": "_checksum)\n\n    def decompress(self, data: bytes, compression: Compression, actual_size: int) -> bytes:\n        return util.decompress(data, compression, "
 },
 "175": {
  "name": "actual_size",
  "type": "int",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/readcontext.py",
  "lineno": "25",
  "column": "64",
  "slicing": "['    def decompress(self, data: bytes, compression: Compression, actual_size: int) -> bytes:\\n']",
  "context": "ress(self, data: bytes, compression: Compression, actual_size: int) -> bytes:\n        return util.decompress(data, compression, "
 },
 "176": {
  "name": "compression",
  "type": "constants.Compression",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/readcontext.py",
  "lineno": "28",
  "column": "29",
  "slicing": "['    def update_inherit(self, compression: Compression, checksum: Checksum) -> None:\\n']",
  "context": "efault_compression)\n\n    def update_inherit(self, compression: Compression, checksum: Checksum) -> None:\n        if compression != Compression.INHERIT:\n   "
 },
 "177": {
  "name": "checksum",
  "type": "constants.Checksum",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/readcontext.py",
  "lineno": "28",
  "column": "55",
  "slicing": "['    def update_inherit(self, compression: Compression, checksum: Checksum) -> None:\\n']",
  "context": "ef update_inherit(self, compression: Compression, checksum: Checksum) -> None:\n        if compression != Compression.INHERIT:\n   "
 },
 "178": {
  "name": "block",
  "type": "list",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/readcontext.py",
  "lineno": "36",
  "column": "12",
  "slicing": "['            block = self.read_block_thorough(blkptr)\\n', '            return block\\n', '            return block\\n', '            return block\\n', '                        blocks.append(block)\\n', '                        bad.append(block)\\n']",
  "context": "fig.read_all_dvas in self.try_config:\n            block = self.read_block_thorough(blkptr)\n            return block\n        elif blkptr.embed"
 },
 "179": {
  "name": "first_log",
  "type": "bool",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/readcontext.py",
  "lineno": "57",
  "column": "8",
  "slicing": "['        first_log = True\\n', '                    if first_log:\\n']",
  "context": "}'.format(blkptr))\n            return b''\n        first_log = True\n        blocks = []\n        bad = []\n        for d"
 },
 "180": {
  "name": "blocks",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/readcontext.py",
  "lineno": "58",
  "column": "8",
  "slicing": "['        blocks = []\\n', '                        blocks.append(block)\\n', '        if len(blocks) == 1:\\n', '            return blocks[0]\\n', '        elif len(blocks) > 1:\\n', '            if not all(x == y for x, y in zip(blocks, blocks[1:])):\\n', \"                logger.info('data lengths were {}'.format(list(map(len, blocks))))\\n\", \"                logger.debug('{}'.format([codecs.encode(b, 'hex') for b in blocks]))\\n\", '            return blocks[0]\\n']",
  "context": "      return b''\n        first_log = True\n        blocks = []\n        bad = []\n        for dva in blkptr.dvas:\n "
 },
 "181": {
  "name": "bad",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/readcontext.py",
  "lineno": "59",
  "column": "8",
  "slicing": "['        bad = []\\n', '                        bad.append(block)\\n']",
  "context": "     first_log = True\n        blocks = []\n        bad = []\n        for dva in blkptr.dvas:\n            if dva"
 },
 "182": {
  "name": "first_log",
  "type": "bool",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/readcontext.py",
  "lineno": "72",
  "column": "24",
  "slicing": "['                        first_log = False\\n']",
  "context": "inter {}'.format(blkptr))\n                        first_log = False\n                    logger.exception('failed to re"
 },
 "183": {
  "name": "vdev",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/readcontext.py",
  "lineno": "94",
  "column": "8",
  "slicing": "['logger = logging.getLogger(__name__)\\n', '            block = self.read_block_thorough(blkptr)\\n', '            return block\\n', '            block = self._read_block_embedded(blkptr)\\n', '            return block\\n', '            block, valid = self._read_block(blkptr, blkptr.dvas[dva_offset])\\n', '            if not valid:\\n', \"                logger.error('bad checksum in block {}'.format(blkptr))\\n\", '            return block\\n', '        if all(dva.asize == 0 for dva in blkptr.dvas):\\n', \"            logger.debug('read an empty block pointer: {}'.format(blkptr))\\n\", '        first_log = True\\n', '        blocks = []\\n', '        bad = []\\n', '        for dva in blkptr.dvas:\\n', '            if dva.asize != 0:\\n', '                    block, valid = self._read_block(blkptr, dva)\\n', '                    if valid:\\n', '                        blocks.append(block)\\n', \"                        logger.error('checksum failed')\\n\", '                        bad.append(block)\\n', '                    if first_log:\\n', \"                        logger.info('block pointer {}'.format(blkptr))\\n\", '                        first_log = False\\n', \"                    logger.exception('failed to read DVA {}'.format(dva))\\n\", '        if len(blocks) == 1:\\n', '            return blocks[0]\\n', '        elif len(blocks) > 1:\\n', '            if not all(x == y for x, y in zip(blocks, blocks[1:])):\\n', \"                logger.error('block pointer {} had multiple allocated DVAs with different data!'.format(blkptr))\\n\", \"                logger.info('data lengths were {}'.format(list(map(len, blocks))))\\n\", \"                logger.debug('{}'.format([codecs.encode(b, 'hex') for b in blocks]))\\n\", '            return blocks[0]\\n', \"            logger.error('failed to read any DVAs in block pointer {}'.format(blkptr))\\n\", '        embedded_blkptr = blkptr.to_embedded()\\n', '        raw_data = embedded_blkptr.data\\n', '        data = self.decompress(raw_data, embedded_blkptr.compression, embedded_blkptr.logical_size+1)\\n', '        return data\\n', '        vdev = self.vdevs[dva.vdev]\\n', '        data = vdev.read_dva(dva)\\n', '        physical_size = (blkptr.physical_size + 1) * 512\\n', '        data = data[:physical_size]\\n', '        valid_chk = self.checksum(data, blkptr.checksum, blkptr.checksum_type)\\n', '        logical_size = (blkptr.logical_size + 1) * 512\\n', '        if valid_chk:\\n', \"            logger.debug('decompress: {} {} {}'.format(blkptr, physical_size, logical_size))\\n\", '            data = self.decompress(data, blkptr.compression, logical_size)\\n', '        return data, valid_chk\\n', '            data = self.read_block(blkptr)\\n', '            indirect = ondisk.indirect(size=blkptr.logical_size + 1)\\n', '            ind = indirect(data)\\n', '            for ptr in ind.blocks:\\n', '                resolved.append(self.read_indirect(ptr))\\n']",
  "context": ", dva: ondisk.dva) -> Tuple[bytes, bool]:\n        vdev = self.vdevs[dva.vdev]\n        data = vdev.read_dva(dva)\n        physical"
 },
 "184": {
  "name": "data",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/readcontext.py",
  "lineno": "97",
  "column": "8",
  "slicing": "['logger = logging.getLogger(__name__)\\n', '            block = self.read_block_thorough(blkptr)\\n', '            return block\\n', '            block = self._read_block_embedded(blkptr)\\n', '            return block\\n', '            block, valid = self._read_block(blkptr, blkptr.dvas[dva_offset])\\n', '            if not valid:\\n', \"                logger.error('bad checksum in block {}'.format(blkptr))\\n\", '            return block\\n', '        if all(dva.asize == 0 for dva in blkptr.dvas):\\n', \"            logger.debug('read an empty block pointer: {}'.format(blkptr))\\n\", '        first_log = True\\n', '        blocks = []\\n', '        bad = []\\n', '        for dva in blkptr.dvas:\\n', '            if dva.asize != 0:\\n', '                    block, valid = self._read_block(blkptr, dva)\\n', '                    if valid:\\n', '                        blocks.append(block)\\n', \"                        logger.error('checksum failed')\\n\", '                        bad.append(block)\\n', '                    if first_log:\\n', \"                        logger.info('block pointer {}'.format(blkptr))\\n\", '                        first_log = False\\n', \"                    logger.exception('failed to read DVA {}'.format(dva))\\n\", '        if len(blocks) == 1:\\n', '            return blocks[0]\\n', '        elif len(blocks) > 1:\\n', '            if not all(x == y for x, y in zip(blocks, blocks[1:])):\\n', \"                logger.error('block pointer {} had multiple allocated DVAs with different data!'.format(blkptr))\\n\", \"                logger.info('data lengths were {}'.format(list(map(len, blocks))))\\n\", \"                logger.debug('{}'.format([codecs.encode(b, 'hex') for b in blocks]))\\n\", '            return blocks[0]\\n', \"            logger.error('failed to read any DVAs in block pointer {}'.format(blkptr))\\n\", '        embedded_blkptr = blkptr.to_embedded()\\n', '        raw_data = embedded_blkptr.data\\n', '        data = self.decompress(raw_data, embedded_blkptr.compression, embedded_blkptr.logical_size+1)\\n', '        return data\\n', '        vdev = self.vdevs[dva.vdev]\\n', '        data = vdev.read_dva(dva)\\n', '        physical_size = (blkptr.physical_size + 1) * 512\\n', '        data = data[:physical_size]\\n', '        valid_chk = self.checksum(data, blkptr.checksum, blkptr.checksum_type)\\n', '        logical_size = (blkptr.logical_size + 1) * 512\\n', '        if valid_chk:\\n', \"            logger.debug('decompress: {} {} {}'.format(blkptr, physical_size, logical_size))\\n\", '            data = self.decompress(data, blkptr.compression, logical_size)\\n', '        return data, valid_chk\\n', '            data = self.read_block(blkptr)\\n', '            indirect = ondisk.indirect(size=blkptr.logical_size + 1)\\n', '            ind = indirect(data)\\n', '            for ptr in ind.blocks:\\n', '                resolved.append(self.read_indirect(ptr))\\n']",
  "context": "l_size = (blkptr.physical_size + 1) * 512\n        data = data[:physical_size]\n        valid_chk = self.checksum(data, blkptr.che"
 },
 "185": {
  "name": "resolved",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/readcontext.py",
  "lineno": "106",
  "column": "8",
  "slicing": "['        resolved = []\\n', '                resolved.append(self.read_indirect(ptr))\\n', \"        return b''.join(resolved)\\n\"]",
  "context": "(self, blkptr: ondisk.Blockptr) -> bytes:\n        resolved = []\n        if blkptr.level > 0:\n            data = se"
 },
 "186": {
  "name": "data",
  "type": "list",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/readcontext.py",
  "lineno": "108",
  "column": "12",
  "slicing": "['logger = logging.getLogger(__name__)\\n', '            block = self.read_block_thorough(blkptr)\\n', '            return block\\n', '            block = self._read_block_embedded(blkptr)\\n', '            return block\\n', '            block, valid = self._read_block(blkptr, blkptr.dvas[dva_offset])\\n', '            if not valid:\\n', \"                logger.error('bad checksum in block {}'.format(blkptr))\\n\", '            return block\\n', '        if all(dva.asize == 0 for dva in blkptr.dvas):\\n', \"            logger.debug('read an empty block pointer: {}'.format(blkptr))\\n\", '        first_log = True\\n', '        blocks = []\\n', '        bad = []\\n', '        for dva in blkptr.dvas:\\n', '            if dva.asize != 0:\\n', '                    block, valid = self._read_block(blkptr, dva)\\n', '                    if valid:\\n', '                        blocks.append(block)\\n', \"                        logger.error('checksum failed')\\n\", '                        bad.append(block)\\n', '                    if first_log:\\n', \"                        logger.info('block pointer {}'.format(blkptr))\\n\", '                        first_log = False\\n', \"                    logger.exception('failed to read DVA {}'.format(dva))\\n\", '        if len(blocks) == 1:\\n', '            return blocks[0]\\n', '        elif len(blocks) > 1:\\n', '            if not all(x == y for x, y in zip(blocks, blocks[1:])):\\n', \"                logger.error('block pointer {} had multiple allocated DVAs with different data!'.format(blkptr))\\n\", \"                logger.info('data lengths were {}'.format(list(map(len, blocks))))\\n\", \"                logger.debug('{}'.format([codecs.encode(b, 'hex') for b in blocks]))\\n\", '            return blocks[0]\\n', \"            logger.error('failed to read any DVAs in block pointer {}'.format(blkptr))\\n\", '        embedded_blkptr = blkptr.to_embedded()\\n', '        raw_data = embedded_blkptr.data\\n', '        data = self.decompress(raw_data, embedded_blkptr.compression, embedded_blkptr.logical_size+1)\\n', '        return data\\n', '        vdev = self.vdevs[dva.vdev]\\n', '        data = vdev.read_dva(dva)\\n', '        physical_size = (blkptr.physical_size + 1) * 512\\n', '        data = data[:physical_size]\\n', '        valid_chk = self.checksum(data, blkptr.checksum, blkptr.checksum_type)\\n', '        logical_size = (blkptr.logical_size + 1) * 512\\n', '        if valid_chk:\\n', \"            logger.debug('decompress: {} {} {}'.format(blkptr, physical_size, logical_size))\\n\", '            data = self.decompress(data, blkptr.compression, logical_size)\\n', '        return data, valid_chk\\n', '            data = self.read_block(blkptr)\\n', '            indirect = ondisk.indirect(size=blkptr.logical_size + 1)\\n', '            ind = indirect(data)\\n', '            for ptr in ind.blocks:\\n', '                resolved.append(self.read_indirect(ptr))\\n']",
  "context": "ved = []\n        if blkptr.level > 0:\n            data = self.read_block(blkptr)\n            indirect = ondisk.indirect(size=blkptr"
 },
 "187": {
  "name": "ind",
  "type": "indirect",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/readcontext.py",
  "lineno": "110",
  "column": "12",
  "slicing": "['logger = logging.getLogger(__name__)\\n', '            block = self.read_block_thorough(blkptr)\\n', '            return block\\n', '            block = self._read_block_embedded(blkptr)\\n', '            return block\\n', '            block, valid = self._read_block(blkptr, blkptr.dvas[dva_offset])\\n', '            if not valid:\\n', \"                logger.error('bad checksum in block {}'.format(blkptr))\\n\", '            return block\\n', '        if all(dva.asize == 0 for dva in blkptr.dvas):\\n', \"            logger.debug('read an empty block pointer: {}'.format(blkptr))\\n\", '        first_log = True\\n', '        blocks = []\\n', '        bad = []\\n', '        for dva in blkptr.dvas:\\n', '            if dva.asize != 0:\\n', '                    block, valid = self._read_block(blkptr, dva)\\n', '                    if valid:\\n', '                        blocks.append(block)\\n', \"                        logger.error('checksum failed')\\n\", '                        bad.append(block)\\n', '                    if first_log:\\n', \"                        logger.info('block pointer {}'.format(blkptr))\\n\", '                        first_log = False\\n', \"                    logger.exception('failed to read DVA {}'.format(dva))\\n\", '        if len(blocks) == 1:\\n', '            return blocks[0]\\n', '        elif len(blocks) > 1:\\n', '            if not all(x == y for x, y in zip(blocks, blocks[1:])):\\n', \"                logger.error('block pointer {} had multiple allocated DVAs with different data!'.format(blkptr))\\n\", \"                logger.info('data lengths were {}'.format(list(map(len, blocks))))\\n\", \"                logger.debug('{}'.format([codecs.encode(b, 'hex') for b in blocks]))\\n\", '            return blocks[0]\\n', \"            logger.error('failed to read any DVAs in block pointer {}'.format(blkptr))\\n\", '        embedded_blkptr = blkptr.to_embedded()\\n', '        raw_data = embedded_blkptr.data\\n', '        data = self.decompress(raw_data, embedded_blkptr.compression, embedded_blkptr.logical_size+1)\\n', '        return data\\n', '        vdev = self.vdevs[dva.vdev]\\n', '        data = vdev.read_dva(dva)\\n', '        physical_size = (blkptr.physical_size + 1) * 512\\n', '        data = data[:physical_size]\\n', '        valid_chk = self.checksum(data, blkptr.checksum, blkptr.checksum_type)\\n', '        logical_size = (blkptr.logical_size + 1) * 512\\n', '        if valid_chk:\\n', \"            logger.debug('decompress: {} {} {}'.format(blkptr, physical_size, logical_size))\\n\", '            data = self.decompress(data, blkptr.compression, logical_size)\\n', '        return data, valid_chk\\n', '            data = self.read_block(blkptr)\\n', '            indirect = ondisk.indirect(size=blkptr.logical_size + 1)\\n', '            ind = indirect(data)\\n', '            for ptr in ind.blocks:\\n', '                resolved.append(self.read_indirect(ptr))\\n']",
  "context": "ndirect(size=blkptr.logical_size + 1)\n            ind = indirect(data)\n            for ptr in ind.blocks:\n               "
 },
 "188": {
  "name": "disks",
  "type": "int",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/raidzdev.py",
  "lineno": "13",
  "column": "21",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def convert(k, base, disks, parity):\\n', '    off = (disks+parity+2)/base\\n', '    k -= base\\n', '    if k >= 230:\\n', '        off -= 3\\n', '    return (k + off) % disks\\n', 'def should_resize(offset, size, disks, parity):\\n', '    base = (size % 10)\\n', '    if size >= 8 and base in (4, 8):\\n', '        return convert(size, base, disks, parity) == offset % disks\\n', 'def locate_data(disks, parity, offset, size):\\n', '    first_col = parity\\n', '    ret = [disks, first_col]\\n', '    vdevs = []\\n', '    bit_12 = (offset >> 11) & 1\\n', '    vdev_ids = list(range(disks))\\n', '    order = list(range(disks))\\n', '    if bit_12:\\n', '        order[0:2] = reversed(order[0:2])\\n', '    for i in order:\\n', '        dva = ondisk.dva()\\n', '        dva.vdev = vdev_ids[(offset + i) % disks]\\n', '        dva.offset = int((offset + i) / disks)\\n', '        vdevs.append(dva)\\n', '    vdev_order = [d.vdev for d in vdevs]\\n', \"        logger.debug('*'*30, size)\\n\", '    if disks == 5 and should_resize(offset, size, disks, parity):\\n', \"        logger.debug('!!!!!! size decrease {} {:} {:} {} {:} {}'.format(offset % disks, offset, size, list(map(int, vdev_order)), size, bit_12))\\n\", '        size -= 1\\n', '    for _, next_vdev in zip(range(size), itertools.cycle(vdevs)):\\n', '        next_vdev.asize += 1\\n', '    ret.append(tuple(vdevs))\\n', '    return ret\\n', 'def xor_blocks(*args):\\n', '    args = [x for x in args if len(x)]\\n', '    if len(args) == 0:\\n', '    size = min(len(x) for x in args)\\n', '    args = [x[:size] for x in args]\\n', \"    format_str = '>'\\n\", '    if size >= 8:\\n', \"        format_str += '{}Q'.format(int(size/8))\\n\", '    if size % 8:\\n', \"        format_str += '{}B'.format(size % 8)\\n\", '    structure = struct.Struct(format_str)\\n', '    out = [reduce(operator.xor, t) for t in zip(*(structure.unpack(x) for x in args))]\\n', '    return structure.pack(*out)\\n', 'class RaidZDev(vdevs.VDev):\\n', '        self.parity = parity\\n', '        return self.devs[dva.vdev].read_dva(dva)\\n', '        offset = dva.offset\\n', '        num_disks = len(self.devs)\\n', '        parity = self.parity\\n', '        columns, first, addrs = locate_data(num_disks, parity, offset, dva.asize)\\n', '        if columns == num_disks:\\n', '            blocks = [self._read_resolved(addr) for addr in addrs]\\n', \"            data = b''.join(blocks[first:])\\n\", \"            raise Exception('wtf? {}'.format(addrs))\\n\", '        computed = xor_blocks(*blocks[first:])\\n', '        self.blocks = blocks[:] + [computed]\\n', '        self.last_dva = dva, addrs\\n', '        return data\\n']",
  "context": "ogging.getLogger(__name__)\n\n\ndef convert(k, base, disks, parity):\n    off = (disks+parity+2)/base\n    k -= base\n    "
 },
 "189": {
  "name": "off",
  "type": "int",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/raidzdev.py",
  "lineno": "14",
  "column": "4",
  "slicing": "['    off = (disks+parity+2)/base\\n', '    return (k + off) % disks\\n']",
  "context": "ame__)\n\n\ndef convert(k, base, disks, parity):\n    off = (disks+parity+2)/base\n    k -= base\n    if k >= 230:\n        off -= 3\n  "
 },
 "190": {
  "name": "k",
  "type": "base",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/raidzdev.py",
  "lineno": "15",
  "column": "4",
  "slicing": "['    k -= base\\n', '    if k >= 230:\\n', '    return (k + off) % disks\\n']",
  "context": "sks, parity):\n    off = (disks+parity+2)/base\n    k -= base\n    if k >= 230:\n        off -= 3\n    return (k + "
 },
 "191": {
  "name": "off",
  "type": "int",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/raidzdev.py",
  "lineno": "17",
  "column": "8",
  "slicing": "['        off -= 3\\n', '    return (k + off) % disks\\n']",
  "context": "ty+2)/base\n    k -= base\n    if k >= 230:\n        off -= 3\n    return (k + off) % disks\n\n\ndef should_resize(o"
 },
 "192": {
  "name": "disks",
  "type": "int",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/raidzdev.py",
  "lineno": "21",
  "column": "32",
  "slicing": "['def should_resize(offset, size, disks, parity):\\n', '    if disks == 5 and should_resize(offset, size, disks, parity):\\n', \"        logger.debug('!!!!!! size decrease {} {:} {:} {} {:} {}'.format(offset % disks, offset, size, list(map(int, vdev_order)), size, bit_12))\\n\"]",
  "context": " + off) % disks\n\n\ndef should_resize(offset, size, disks, parity):\n    base = (size % 10)\n    if size >= 8 and base i"
 },
 "193": {
  "name": "disks",
  "type": "int",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/raidzdev.py",
  "lineno": "30",
  "column": "16",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def convert(k, base, disks, parity):\\n', '    off = (disks+parity+2)/base\\n', '    k -= base\\n', '    if k >= 230:\\n', '        off -= 3\\n', '    return (k + off) % disks\\n', 'def should_resize(offset, size, disks, parity):\\n', '    base = (size % 10)\\n', '    if size >= 8 and base in (4, 8):\\n', '        return convert(size, base, disks, parity) == offset % disks\\n', 'def locate_data(disks, parity, offset, size):\\n', '    first_col = parity\\n', '    ret = [disks, first_col]\\n', '    vdevs = []\\n', '    bit_12 = (offset >> 11) & 1\\n', '    vdev_ids = list(range(disks))\\n', '    order = list(range(disks))\\n', '    if bit_12:\\n', '        order[0:2] = reversed(order[0:2])\\n', '    for i in order:\\n', '        dva = ondisk.dva()\\n', '        dva.vdev = vdev_ids[(offset + i) % disks]\\n', '        dva.offset = int((offset + i) / disks)\\n', '        vdevs.append(dva)\\n', '    vdev_order = [d.vdev for d in vdevs]\\n', \"        logger.debug('*'*30, size)\\n\", '    if disks == 5 and should_resize(offset, size, disks, parity):\\n', \"        logger.debug('!!!!!! size decrease {} {:} {:} {} {:} {}'.format(offset % disks, offset, size, list(map(int, vdev_order)), size, bit_12))\\n\", '        size -= 1\\n', '    for _, next_vdev in zip(range(size), itertools.cycle(vdevs)):\\n', '        next_vdev.asize += 1\\n', '    ret.append(tuple(vdevs))\\n', '    return ret\\n', 'def xor_blocks(*args):\\n', '    args = [x for x in args if len(x)]\\n', '    if len(args) == 0:\\n', '    size = min(len(x) for x in args)\\n', '    args = [x[:size] for x in args]\\n', \"    format_str = '>'\\n\", '    if size >= 8:\\n', \"        format_str += '{}Q'.format(int(size/8))\\n\", '    if size % 8:\\n', \"        format_str += '{}B'.format(size % 8)\\n\", '    structure = struct.Struct(format_str)\\n', '    out = [reduce(operator.xor, t) for t in zip(*(structure.unpack(x) for x in args))]\\n', '    return structure.pack(*out)\\n', 'class RaidZDev(vdevs.VDev):\\n', '        self.parity = parity\\n', '        return self.devs[dva.vdev].read_dva(dva)\\n', '        offset = dva.offset\\n', '        num_disks = len(self.devs)\\n', '        parity = self.parity\\n', '        columns, first, addrs = locate_data(num_disks, parity, offset, dva.asize)\\n', '        if columns == num_disks:\\n', '            blocks = [self._read_resolved(addr) for addr in addrs]\\n', \"            data = b''.join(blocks[first:])\\n\", \"            raise Exception('wtf? {}'.format(addrs))\\n\", '        computed = xor_blocks(*blocks[first:])\\n', '        self.blocks = blocks[:] + [computed]\\n', '        self.last_dva = dva, addrs\\n', '        return data\\n']",
  "context": " return False\n\n\n# thanks aschmitz\ndef locate_data(disks, parity, offset, size):\n    first_col = parity\n    ret = [disks, first_col"
 },
 "194": {
  "name": "first_col",
  "type": "parity",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/raidzdev.py",
  "lineno": "31",
  "column": "4",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def convert(k, base, disks, parity):\\n', '    off = (disks+parity+2)/base\\n', '    k -= base\\n', '    if k >= 230:\\n', '        off -= 3\\n', '    return (k + off) % disks\\n', 'def should_resize(offset, size, disks, parity):\\n', '    base = (size % 10)\\n', '    if size >= 8 and base in (4, 8):\\n', '        return convert(size, base, disks, parity) == offset % disks\\n', 'def locate_data(disks, parity, offset, size):\\n', '    first_col = parity\\n', '    ret = [disks, first_col]\\n', '    vdevs = []\\n', '    bit_12 = (offset >> 11) & 1\\n', '    vdev_ids = list(range(disks))\\n', '    order = list(range(disks))\\n', '    if bit_12:\\n', '        order[0:2] = reversed(order[0:2])\\n', '    for i in order:\\n', '        dva = ondisk.dva()\\n', '        dva.vdev = vdev_ids[(offset + i) % disks]\\n', '        dva.offset = int((offset + i) / disks)\\n', '        vdevs.append(dva)\\n', '    vdev_order = [d.vdev for d in vdevs]\\n', \"        logger.debug('*'*30, size)\\n\", '    if disks == 5 and should_resize(offset, size, disks, parity):\\n', \"        logger.debug('!!!!!! size decrease {} {:} {:} {} {:} {}'.format(offset % disks, offset, size, list(map(int, vdev_order)), size, bit_12))\\n\", '        size -= 1\\n', '    for _, next_vdev in zip(range(size), itertools.cycle(vdevs)):\\n', '        next_vdev.asize += 1\\n', '    ret.append(tuple(vdevs))\\n', '    return ret\\n', 'def xor_blocks(*args):\\n', '    args = [x for x in args if len(x)]\\n', '    if len(args) == 0:\\n', '    size = min(len(x) for x in args)\\n', '    args = [x[:size] for x in args]\\n', \"    format_str = '>'\\n\", '    if size >= 8:\\n', \"        format_str += '{}Q'.format(int(size/8))\\n\", '    if size % 8:\\n', \"        format_str += '{}B'.format(size % 8)\\n\", '    structure = struct.Struct(format_str)\\n', '    out = [reduce(operator.xor, t) for t in zip(*(structure.unpack(x) for x in args))]\\n', '    return structure.pack(*out)\\n', 'class RaidZDev(vdevs.VDev):\\n', '        self.parity = parity\\n', '        return self.devs[dva.vdev].read_dva(dva)\\n', '        offset = dva.offset\\n', '        num_disks = len(self.devs)\\n', '        parity = self.parity\\n', '        columns, first, addrs = locate_data(num_disks, parity, offset, dva.asize)\\n', '        if columns == num_disks:\\n', '            blocks = [self._read_resolved(addr) for addr in addrs]\\n', \"            data = b''.join(blocks[first:])\\n\", \"            raise Exception('wtf? {}'.format(addrs))\\n\", '        computed = xor_blocks(*blocks[first:])\\n', '        self.blocks = blocks[:] + [computed]\\n', '        self.last_dva = dva, addrs\\n', '        return data\\n']",
  "context": "def locate_data(disks, parity, offset, size):\n    first_col = parity\n    ret = [disks, first_col]\n    vdevs = []\n    bi"
 },
 "195": {
  "name": "ret",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/raidzdev.py",
  "lineno": "32",
  "column": "4",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def convert(k, base, disks, parity):\\n', '    off = (disks+parity+2)/base\\n', '    k -= base\\n', '    if k >= 230:\\n', '        off -= 3\\n', '    return (k + off) % disks\\n', 'def should_resize(offset, size, disks, parity):\\n', '    base = (size % 10)\\n', '    if size >= 8 and base in (4, 8):\\n', '        return convert(size, base, disks, parity) == offset % disks\\n', 'def locate_data(disks, parity, offset, size):\\n', '    first_col = parity\\n', '    ret = [disks, first_col]\\n', '    vdevs = []\\n', '    bit_12 = (offset >> 11) & 1\\n', '    vdev_ids = list(range(disks))\\n', '    order = list(range(disks))\\n', '    if bit_12:\\n', '        order[0:2] = reversed(order[0:2])\\n', '    for i in order:\\n', '        dva = ondisk.dva()\\n', '        dva.vdev = vdev_ids[(offset + i) % disks]\\n', '        dva.offset = int((offset + i) / disks)\\n', '        vdevs.append(dva)\\n', '    vdev_order = [d.vdev for d in vdevs]\\n', \"        logger.debug('*'*30, size)\\n\", '    if disks == 5 and should_resize(offset, size, disks, parity):\\n', \"        logger.debug('!!!!!! size decrease {} {:} {:} {} {:} {}'.format(offset % disks, offset, size, list(map(int, vdev_order)), size, bit_12))\\n\", '        size -= 1\\n', '    for _, next_vdev in zip(range(size), itertools.cycle(vdevs)):\\n', '        next_vdev.asize += 1\\n', '    ret.append(tuple(vdevs))\\n', '    return ret\\n', 'def xor_blocks(*args):\\n', '    args = [x for x in args if len(x)]\\n', '    if len(args) == 0:\\n', '    size = min(len(x) for x in args)\\n', '    args = [x[:size] for x in args]\\n', \"    format_str = '>'\\n\", '    if size >= 8:\\n', \"        format_str += '{}Q'.format(int(size/8))\\n\", '    if size % 8:\\n', \"        format_str += '{}B'.format(size % 8)\\n\", '    structure = struct.Struct(format_str)\\n', '    out = [reduce(operator.xor, t) for t in zip(*(structure.unpack(x) for x in args))]\\n', '    return structure.pack(*out)\\n', 'class RaidZDev(vdevs.VDev):\\n', '        self.parity = parity\\n', '        return self.devs[dva.vdev].read_dva(dva)\\n', '        offset = dva.offset\\n', '        num_disks = len(self.devs)\\n', '        parity = self.parity\\n', '        columns, first, addrs = locate_data(num_disks, parity, offset, dva.asize)\\n', '        if columns == num_disks:\\n', '            blocks = [self._read_resolved(addr) for addr in addrs]\\n', \"            data = b''.join(blocks[first:])\\n\", \"            raise Exception('wtf? {}'.format(addrs))\\n\", '        computed = xor_blocks(*blocks[first:])\\n', '        self.blocks = blocks[:] + [computed]\\n', '        self.last_dva = dva, addrs\\n', '        return data\\n']",
  "context": "parity, offset, size):\n    first_col = parity\n    ret = [disks, first_col]\n    vdevs = []\n    bit_12 = (offset >> 11) & 1\n   "
 },
 "196": {
  "name": "vdevs",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/raidzdev.py",
  "lineno": "33",
  "column": "4",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def convert(k, base, disks, parity):\\n', '    off = (disks+parity+2)/base\\n', '    k -= base\\n', '    if k >= 230:\\n', '        off -= 3\\n', '    return (k + off) % disks\\n', 'def should_resize(offset, size, disks, parity):\\n', '    base = (size % 10)\\n', '    if size >= 8 and base in (4, 8):\\n', '        return convert(size, base, disks, parity) == offset % disks\\n', 'def locate_data(disks, parity, offset, size):\\n', '    first_col = parity\\n', '    ret = [disks, first_col]\\n', '    vdevs = []\\n', '    bit_12 = (offset >> 11) & 1\\n', '    vdev_ids = list(range(disks))\\n', '    order = list(range(disks))\\n', '    if bit_12:\\n', '        order[0:2] = reversed(order[0:2])\\n', '    for i in order:\\n', '        dva = ondisk.dva()\\n', '        dva.vdev = vdev_ids[(offset + i) % disks]\\n', '        dva.offset = int((offset + i) / disks)\\n', '        vdevs.append(dva)\\n', '    vdev_order = [d.vdev for d in vdevs]\\n', \"        logger.debug('*'*30, size)\\n\", '    if disks == 5 and should_resize(offset, size, disks, parity):\\n', \"        logger.debug('!!!!!! size decrease {} {:} {:} {} {:} {}'.format(offset % disks, offset, size, list(map(int, vdev_order)), size, bit_12))\\n\", '        size -= 1\\n', '    for _, next_vdev in zip(range(size), itertools.cycle(vdevs)):\\n', '        next_vdev.asize += 1\\n', '    ret.append(tuple(vdevs))\\n', '    return ret\\n', 'def xor_blocks(*args):\\n', '    args = [x for x in args if len(x)]\\n', '    if len(args) == 0:\\n', '    size = min(len(x) for x in args)\\n', '    args = [x[:size] for x in args]\\n', \"    format_str = '>'\\n\", '    if size >= 8:\\n', \"        format_str += '{}Q'.format(int(size/8))\\n\", '    if size % 8:\\n', \"        format_str += '{}B'.format(size % 8)\\n\", '    structure = struct.Struct(format_str)\\n', '    out = [reduce(operator.xor, t) for t in zip(*(structure.unpack(x) for x in args))]\\n', '    return structure.pack(*out)\\n', 'class RaidZDev(vdevs.VDev):\\n', '        self.parity = parity\\n', '        return self.devs[dva.vdev].read_dva(dva)\\n', '        offset = dva.offset\\n', '        num_disks = len(self.devs)\\n', '        parity = self.parity\\n', '        columns, first, addrs = locate_data(num_disks, parity, offset, dva.asize)\\n', '        if columns == num_disks:\\n', '            blocks = [self._read_resolved(addr) for addr in addrs]\\n', \"            data = b''.join(blocks[first:])\\n\", \"            raise Exception('wtf? {}'.format(addrs))\\n\", '        computed = xor_blocks(*blocks[first:])\\n', '        self.blocks = blocks[:] + [computed]\\n', '        self.last_dva = dva, addrs\\n', '        return data\\n']",
  "context": "rst_col = parity\n    ret = [disks, first_col]\n    vdevs = []\n    bit_12 = (offset >> 11) & 1\n    vdev_ids = lis"
 },
 "197": {
  "name": "vdev_ids",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/raidzdev.py",
  "lineno": "35",
  "column": "4",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def convert(k, base, disks, parity):\\n', '    off = (disks+parity+2)/base\\n', '    k -= base\\n', '    if k >= 230:\\n', '        off -= 3\\n', '    return (k + off) % disks\\n', 'def should_resize(offset, size, disks, parity):\\n', '    base = (size % 10)\\n', '    if size >= 8 and base in (4, 8):\\n', '        return convert(size, base, disks, parity) == offset % disks\\n', 'def locate_data(disks, parity, offset, size):\\n', '    first_col = parity\\n', '    ret = [disks, first_col]\\n', '    vdevs = []\\n', '    bit_12 = (offset >> 11) & 1\\n', '    vdev_ids = list(range(disks))\\n', '    order = list(range(disks))\\n', '    if bit_12:\\n', '        order[0:2] = reversed(order[0:2])\\n', '    for i in order:\\n', '        dva = ondisk.dva()\\n', '        dva.vdev = vdev_ids[(offset + i) % disks]\\n', '        dva.offset = int((offset + i) / disks)\\n', '        vdevs.append(dva)\\n', '    vdev_order = [d.vdev for d in vdevs]\\n', \"        logger.debug('*'*30, size)\\n\", '    if disks == 5 and should_resize(offset, size, disks, parity):\\n', \"        logger.debug('!!!!!! size decrease {} {:} {:} {} {:} {}'.format(offset % disks, offset, size, list(map(int, vdev_order)), size, bit_12))\\n\", '        size -= 1\\n', '    for _, next_vdev in zip(range(size), itertools.cycle(vdevs)):\\n', '        next_vdev.asize += 1\\n', '    ret.append(tuple(vdevs))\\n', '    return ret\\n', 'def xor_blocks(*args):\\n', '    args = [x for x in args if len(x)]\\n', '    if len(args) == 0:\\n', '    size = min(len(x) for x in args)\\n', '    args = [x[:size] for x in args]\\n', \"    format_str = '>'\\n\", '    if size >= 8:\\n', \"        format_str += '{}Q'.format(int(size/8))\\n\", '    if size % 8:\\n', \"        format_str += '{}B'.format(size % 8)\\n\", '    structure = struct.Struct(format_str)\\n', '    out = [reduce(operator.xor, t) for t in zip(*(structure.unpack(x) for x in args))]\\n', '    return structure.pack(*out)\\n', 'class RaidZDev(vdevs.VDev):\\n', '        self.parity = parity\\n', '        return self.devs[dva.vdev].read_dva(dva)\\n', '        offset = dva.offset\\n', '        num_disks = len(self.devs)\\n', '        parity = self.parity\\n', '        columns, first, addrs = locate_data(num_disks, parity, offset, dva.asize)\\n', '        if columns == num_disks:\\n', '            blocks = [self._read_resolved(addr) for addr in addrs]\\n', \"            data = b''.join(blocks[first:])\\n\", \"            raise Exception('wtf? {}'.format(addrs))\\n\", '        computed = xor_blocks(*blocks[first:])\\n', '        self.blocks = blocks[:] + [computed]\\n', '        self.last_dva = dva, addrs\\n', '        return data\\n']",
  "context": "   vdevs = []\n    bit_12 = (offset >> 11) & 1\n    vdev_ids = list(range(disks))\n    order = list(range(disks))\n    if bit_12:\n    "
 },
 "198": {
  "name": "order",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/raidzdev.py",
  "lineno": "36",
  "column": "4",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def convert(k, base, disks, parity):\\n', '    off = (disks+parity+2)/base\\n', '    k -= base\\n', '    if k >= 230:\\n', '        off -= 3\\n', '    return (k + off) % disks\\n', 'def should_resize(offset, size, disks, parity):\\n', '    base = (size % 10)\\n', '    if size >= 8 and base in (4, 8):\\n', '        return convert(size, base, disks, parity) == offset % disks\\n', 'def locate_data(disks, parity, offset, size):\\n', '    first_col = parity\\n', '    ret = [disks, first_col]\\n', '    vdevs = []\\n', '    bit_12 = (offset >> 11) & 1\\n', '    vdev_ids = list(range(disks))\\n', '    order = list(range(disks))\\n', '    if bit_12:\\n', '        order[0:2] = reversed(order[0:2])\\n', '    for i in order:\\n', '        dva = ondisk.dva()\\n', '        dva.vdev = vdev_ids[(offset + i) % disks]\\n', '        dva.offset = int((offset + i) / disks)\\n', '        vdevs.append(dva)\\n', '    vdev_order = [d.vdev for d in vdevs]\\n', \"        logger.debug('*'*30, size)\\n\", '    if disks == 5 and should_resize(offset, size, disks, parity):\\n', \"        logger.debug('!!!!!! size decrease {} {:} {:} {} {:} {}'.format(offset % disks, offset, size, list(map(int, vdev_order)), size, bit_12))\\n\", '        size -= 1\\n', '    for _, next_vdev in zip(range(size), itertools.cycle(vdevs)):\\n', '        next_vdev.asize += 1\\n', '    ret.append(tuple(vdevs))\\n', '    return ret\\n', 'def xor_blocks(*args):\\n', '    args = [x for x in args if len(x)]\\n', '    if len(args) == 0:\\n', '    size = min(len(x) for x in args)\\n', '    args = [x[:size] for x in args]\\n', \"    format_str = '>'\\n\", '    if size >= 8:\\n', \"        format_str += '{}Q'.format(int(size/8))\\n\", '    if size % 8:\\n', \"        format_str += '{}B'.format(size % 8)\\n\", '    structure = struct.Struct(format_str)\\n', '    out = [reduce(operator.xor, t) for t in zip(*(structure.unpack(x) for x in args))]\\n', '    return structure.pack(*out)\\n', 'class RaidZDev(vdevs.VDev):\\n', '        self.parity = parity\\n', '        return self.devs[dva.vdev].read_dva(dva)\\n', '        offset = dva.offset\\n', '        num_disks = len(self.devs)\\n', '        parity = self.parity\\n', '        columns, first, addrs = locate_data(num_disks, parity, offset, dva.asize)\\n', '        if columns == num_disks:\\n', '            blocks = [self._read_resolved(addr) for addr in addrs]\\n', \"            data = b''.join(blocks[first:])\\n\", \"            raise Exception('wtf? {}'.format(addrs))\\n\", '        computed = xor_blocks(*blocks[first:])\\n', '        self.blocks = blocks[:] + [computed]\\n', '        self.last_dva = dva, addrs\\n', '        return data\\n']",
  "context": " >> 11) & 1\n    vdev_ids = list(range(disks))\n    order = list(range(disks))\n    if bit_12:\n        order[0:2] = reversed(order"
 },
 "199": {
  "name": "vdev_order",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/raidzdev.py",
  "lineno": "44",
  "column": "4",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def convert(k, base, disks, parity):\\n', '    off = (disks+parity+2)/base\\n', '    k -= base\\n', '    if k >= 230:\\n', '        off -= 3\\n', '    return (k + off) % disks\\n', 'def should_resize(offset, size, disks, parity):\\n', '    base = (size % 10)\\n', '    if size >= 8 and base in (4, 8):\\n', '        return convert(size, base, disks, parity) == offset % disks\\n', 'def locate_data(disks, parity, offset, size):\\n', '    first_col = parity\\n', '    ret = [disks, first_col]\\n', '    vdevs = []\\n', '    bit_12 = (offset >> 11) & 1\\n', '    vdev_ids = list(range(disks))\\n', '    order = list(range(disks))\\n', '    if bit_12:\\n', '        order[0:2] = reversed(order[0:2])\\n', '    for i in order:\\n', '        dva = ondisk.dva()\\n', '        dva.vdev = vdev_ids[(offset + i) % disks]\\n', '        dva.offset = int((offset + i) / disks)\\n', '        vdevs.append(dva)\\n', '    vdev_order = [d.vdev for d in vdevs]\\n', \"        logger.debug('*'*30, size)\\n\", '    if disks == 5 and should_resize(offset, size, disks, parity):\\n', \"        logger.debug('!!!!!! size decrease {} {:} {:} {} {:} {}'.format(offset % disks, offset, size, list(map(int, vdev_order)), size, bit_12))\\n\", '        size -= 1\\n', '    for _, next_vdev in zip(range(size), itertools.cycle(vdevs)):\\n', '        next_vdev.asize += 1\\n', '    ret.append(tuple(vdevs))\\n', '    return ret\\n', 'def xor_blocks(*args):\\n', '    args = [x for x in args if len(x)]\\n', '    if len(args) == 0:\\n', '    size = min(len(x) for x in args)\\n', '    args = [x[:size] for x in args]\\n', \"    format_str = '>'\\n\", '    if size >= 8:\\n', \"        format_str += '{}Q'.format(int(size/8))\\n\", '    if size % 8:\\n', \"        format_str += '{}B'.format(size % 8)\\n\", '    structure = struct.Struct(format_str)\\n', '    out = [reduce(operator.xor, t) for t in zip(*(structure.unpack(x) for x in args))]\\n', '    return structure.pack(*out)\\n', 'class RaidZDev(vdevs.VDev):\\n', '        self.parity = parity\\n', '        return self.devs[dva.vdev].read_dva(dva)\\n', '        offset = dva.offset\\n', '        num_disks = len(self.devs)\\n', '        parity = self.parity\\n', '        columns, first, addrs = locate_data(num_disks, parity, offset, dva.asize)\\n', '        if columns == num_disks:\\n', '            blocks = [self._read_resolved(addr) for addr in addrs]\\n', \"            data = b''.join(blocks[first:])\\n\", \"            raise Exception('wtf? {}'.format(addrs))\\n\", '        computed = xor_blocks(*blocks[first:])\\n', '        self.blocks = blocks[:] + [computed]\\n', '        self.last_dva = dva, addrs\\n', '        return data\\n']",
  "context": "ffset + i) / disks)\n        vdevs.append(dva)\n    vdev_order = [d.vdev for d in vdevs]\n    if size > 318:\n        logger.debug('*'*30, si"
 },
 "200": {
  "name": "args",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/raidzdev.py",
  "lineno": "57",
  "column": "4",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def convert(k, base, disks, parity):\\n', '    off = (disks+parity+2)/base\\n', '    k -= base\\n', '    if k >= 230:\\n', '        off -= 3\\n', '    return (k + off) % disks\\n', 'def should_resize(offset, size, disks, parity):\\n', '    base = (size % 10)\\n', '    if size >= 8 and base in (4, 8):\\n', '        return convert(size, base, disks, parity) == offset % disks\\n', 'def locate_data(disks, parity, offset, size):\\n', '    first_col = parity\\n', '    ret = [disks, first_col]\\n', '    vdevs = []\\n', '    bit_12 = (offset >> 11) & 1\\n', '    vdev_ids = list(range(disks))\\n', '    order = list(range(disks))\\n', '    if bit_12:\\n', '        order[0:2] = reversed(order[0:2])\\n', '    for i in order:\\n', '        dva = ondisk.dva()\\n', '        dva.vdev = vdev_ids[(offset + i) % disks]\\n', '        dva.offset = int((offset + i) / disks)\\n', '        vdevs.append(dva)\\n', '    vdev_order = [d.vdev for d in vdevs]\\n', \"        logger.debug('*'*30, size)\\n\", '    if disks == 5 and should_resize(offset, size, disks, parity):\\n', \"        logger.debug('!!!!!! size decrease {} {:} {:} {} {:} {}'.format(offset % disks, offset, size, list(map(int, vdev_order)), size, bit_12))\\n\", '        size -= 1\\n', '    for _, next_vdev in zip(range(size), itertools.cycle(vdevs)):\\n', '        next_vdev.asize += 1\\n', '    ret.append(tuple(vdevs))\\n', '    return ret\\n', 'def xor_blocks(*args):\\n', '    args = [x for x in args if len(x)]\\n', '    if len(args) == 0:\\n', '    size = min(len(x) for x in args)\\n', '    args = [x[:size] for x in args]\\n', \"    format_str = '>'\\n\", '    if size >= 8:\\n', \"        format_str += '{}Q'.format(int(size/8))\\n\", '    if size % 8:\\n', \"        format_str += '{}B'.format(size % 8)\\n\", '    structure = struct.Struct(format_str)\\n', '    out = [reduce(operator.xor, t) for t in zip(*(structure.unpack(x) for x in args))]\\n', '    return structure.pack(*out)\\n', 'class RaidZDev(vdevs.VDev):\\n', '        self.parity = parity\\n', '        return self.devs[dva.vdev].read_dva(dva)\\n', '        offset = dva.offset\\n', '        num_disks = len(self.devs)\\n', '        parity = self.parity\\n', '        columns, first, addrs = locate_data(num_disks, parity, offset, dva.asize)\\n', '        if columns == num_disks:\\n', '            blocks = [self._read_resolved(addr) for addr in addrs]\\n', \"            data = b''.join(blocks[first:])\\n\", \"            raise Exception('wtf? {}'.format(addrs))\\n\", '        computed = xor_blocks(*blocks[first:])\\n', '        self.blocks = blocks[:] + [computed]\\n', '        self.last_dva = dva, addrs\\n', '        return data\\n']",
  "context": "evs))\n    return ret\n\n\ndef xor_blocks(*args):\n    args = [x for x in args if len(x)]\n    if len(args) == 0:\n        return ''\n    size "
 },
 "201": {
  "name": "size",
  "type": "min",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/raidzdev.py",
  "lineno": "60",
  "column": "4",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def convert(k, base, disks, parity):\\n', '    off = (disks+parity+2)/base\\n', '    k -= base\\n', '    if k >= 230:\\n', '        off -= 3\\n', '    return (k + off) % disks\\n', 'def should_resize(offset, size, disks, parity):\\n', '    base = (size % 10)\\n', '    if size >= 8 and base in (4, 8):\\n', '        return convert(size, base, disks, parity) == offset % disks\\n', 'def locate_data(disks, parity, offset, size):\\n', '    first_col = parity\\n', '    ret = [disks, first_col]\\n', '    vdevs = []\\n', '    bit_12 = (offset >> 11) & 1\\n', '    vdev_ids = list(range(disks))\\n', '    order = list(range(disks))\\n', '    if bit_12:\\n', '        order[0:2] = reversed(order[0:2])\\n', '    for i in order:\\n', '        dva = ondisk.dva()\\n', '        dva.vdev = vdev_ids[(offset + i) % disks]\\n', '        dva.offset = int((offset + i) / disks)\\n', '        vdevs.append(dva)\\n', '    vdev_order = [d.vdev for d in vdevs]\\n', \"        logger.debug('*'*30, size)\\n\", '    if disks == 5 and should_resize(offset, size, disks, parity):\\n', \"        logger.debug('!!!!!! size decrease {} {:} {:} {} {:} {}'.format(offset % disks, offset, size, list(map(int, vdev_order)), size, bit_12))\\n\", '        size -= 1\\n', '    for _, next_vdev in zip(range(size), itertools.cycle(vdevs)):\\n', '        next_vdev.asize += 1\\n', '    ret.append(tuple(vdevs))\\n', '    return ret\\n', 'def xor_blocks(*args):\\n', '    args = [x for x in args if len(x)]\\n', '    if len(args) == 0:\\n', '    size = min(len(x) for x in args)\\n', '    args = [x[:size] for x in args]\\n', \"    format_str = '>'\\n\", '    if size >= 8:\\n', \"        format_str += '{}Q'.format(int(size/8))\\n\", '    if size % 8:\\n', \"        format_str += '{}B'.format(size % 8)\\n\", '    structure = struct.Struct(format_str)\\n', '    out = [reduce(operator.xor, t) for t in zip(*(structure.unpack(x) for x in args))]\\n', '    return structure.pack(*out)\\n', 'class RaidZDev(vdevs.VDev):\\n', '        self.parity = parity\\n', '        return self.devs[dva.vdev].read_dva(dva)\\n', '        offset = dva.offset\\n', '        num_disks = len(self.devs)\\n', '        parity = self.parity\\n', '        columns, first, addrs = locate_data(num_disks, parity, offset, dva.asize)\\n', '        if columns == num_disks:\\n', '            blocks = [self._read_resolved(addr) for addr in addrs]\\n', \"            data = b''.join(blocks[first:])\\n\", \"            raise Exception('wtf? {}'.format(addrs))\\n\", '        computed = xor_blocks(*blocks[first:])\\n', '        self.blocks = blocks[:] + [computed]\\n', '        self.last_dva = dva, addrs\\n', '        return data\\n']",
  "context": "(x)]\n    if len(args) == 0:\n        return ''\n    size = min(len(x) for x in args)\n    args = [x[:size] for x in args]\n    format_str"
 },
 "202": {
  "name": "args",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/raidzdev.py",
  "lineno": "61",
  "column": "4",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def convert(k, base, disks, parity):\\n', '    off = (disks+parity+2)/base\\n', '    k -= base\\n', '    if k >= 230:\\n', '        off -= 3\\n', '    return (k + off) % disks\\n', 'def should_resize(offset, size, disks, parity):\\n', '    base = (size % 10)\\n', '    if size >= 8 and base in (4, 8):\\n', '        return convert(size, base, disks, parity) == offset % disks\\n', 'def locate_data(disks, parity, offset, size):\\n', '    first_col = parity\\n', '    ret = [disks, first_col]\\n', '    vdevs = []\\n', '    bit_12 = (offset >> 11) & 1\\n', '    vdev_ids = list(range(disks))\\n', '    order = list(range(disks))\\n', '    if bit_12:\\n', '        order[0:2] = reversed(order[0:2])\\n', '    for i in order:\\n', '        dva = ondisk.dva()\\n', '        dva.vdev = vdev_ids[(offset + i) % disks]\\n', '        dva.offset = int((offset + i) / disks)\\n', '        vdevs.append(dva)\\n', '    vdev_order = [d.vdev for d in vdevs]\\n', \"        logger.debug('*'*30, size)\\n\", '    if disks == 5 and should_resize(offset, size, disks, parity):\\n', \"        logger.debug('!!!!!! size decrease {} {:} {:} {} {:} {}'.format(offset % disks, offset, size, list(map(int, vdev_order)), size, bit_12))\\n\", '        size -= 1\\n', '    for _, next_vdev in zip(range(size), itertools.cycle(vdevs)):\\n', '        next_vdev.asize += 1\\n', '    ret.append(tuple(vdevs))\\n', '    return ret\\n', 'def xor_blocks(*args):\\n', '    args = [x for x in args if len(x)]\\n', '    if len(args) == 0:\\n', '    size = min(len(x) for x in args)\\n', '    args = [x[:size] for x in args]\\n', \"    format_str = '>'\\n\", '    if size >= 8:\\n', \"        format_str += '{}Q'.format(int(size/8))\\n\", '    if size % 8:\\n', \"        format_str += '{}B'.format(size % 8)\\n\", '    structure = struct.Struct(format_str)\\n', '    out = [reduce(operator.xor, t) for t in zip(*(structure.unpack(x) for x in args))]\\n', '    return structure.pack(*out)\\n', 'class RaidZDev(vdevs.VDev):\\n', '        self.parity = parity\\n', '        return self.devs[dva.vdev].read_dva(dva)\\n', '        offset = dva.offset\\n', '        num_disks = len(self.devs)\\n', '        parity = self.parity\\n', '        columns, first, addrs = locate_data(num_disks, parity, offset, dva.asize)\\n', '        if columns == num_disks:\\n', '            blocks = [self._read_resolved(addr) for addr in addrs]\\n', \"            data = b''.join(blocks[first:])\\n\", \"            raise Exception('wtf? {}'.format(addrs))\\n\", '        computed = xor_blocks(*blocks[first:])\\n', '        self.blocks = blocks[:] + [computed]\\n', '        self.last_dva = dva, addrs\\n', '        return data\\n']",
  "context": "eturn ''\n    size = min(len(x) for x in args)\n    args = [x[:size] for x in args]\n    format_str = '>'\n    if size >= 8:\n        for"
 },
 "203": {
  "name": "structure",
  "type": "Struct",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/raidzdev.py",
  "lineno": "67",
  "column": "4",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def convert(k, base, disks, parity):\\n', '    off = (disks+parity+2)/base\\n', '    k -= base\\n', '    if k >= 230:\\n', '        off -= 3\\n', '    return (k + off) % disks\\n', 'def should_resize(offset, size, disks, parity):\\n', '    base = (size % 10)\\n', '    if size >= 8 and base in (4, 8):\\n', '        return convert(size, base, disks, parity) == offset % disks\\n', 'def locate_data(disks, parity, offset, size):\\n', '    first_col = parity\\n', '    ret = [disks, first_col]\\n', '    vdevs = []\\n', '    bit_12 = (offset >> 11) & 1\\n', '    vdev_ids = list(range(disks))\\n', '    order = list(range(disks))\\n', '    if bit_12:\\n', '        order[0:2] = reversed(order[0:2])\\n', '    for i in order:\\n', '        dva = ondisk.dva()\\n', '        dva.vdev = vdev_ids[(offset + i) % disks]\\n', '        dva.offset = int((offset + i) / disks)\\n', '        vdevs.append(dva)\\n', '    vdev_order = [d.vdev for d in vdevs]\\n', \"        logger.debug('*'*30, size)\\n\", '    if disks == 5 and should_resize(offset, size, disks, parity):\\n', \"        logger.debug('!!!!!! size decrease {} {:} {:} {} {:} {}'.format(offset % disks, offset, size, list(map(int, vdev_order)), size, bit_12))\\n\", '        size -= 1\\n', '    for _, next_vdev in zip(range(size), itertools.cycle(vdevs)):\\n', '        next_vdev.asize += 1\\n', '    ret.append(tuple(vdevs))\\n', '    return ret\\n', 'def xor_blocks(*args):\\n', '    args = [x for x in args if len(x)]\\n', '    if len(args) == 0:\\n', '    size = min(len(x) for x in args)\\n', '    args = [x[:size] for x in args]\\n', \"    format_str = '>'\\n\", '    if size >= 8:\\n', \"        format_str += '{}Q'.format(int(size/8))\\n\", '    if size % 8:\\n', \"        format_str += '{}B'.format(size % 8)\\n\", '    structure = struct.Struct(format_str)\\n', '    out = [reduce(operator.xor, t) for t in zip(*(structure.unpack(x) for x in args))]\\n', '    return structure.pack(*out)\\n', 'class RaidZDev(vdevs.VDev):\\n', '        self.parity = parity\\n', '        return self.devs[dva.vdev].read_dva(dva)\\n', '        offset = dva.offset\\n', '        num_disks = len(self.devs)\\n', '        parity = self.parity\\n', '        columns, first, addrs = locate_data(num_disks, parity, offset, dva.asize)\\n', '        if columns == num_disks:\\n', '            blocks = [self._read_resolved(addr) for addr in addrs]\\n', \"            data = b''.join(blocks[first:])\\n\", \"            raise Exception('wtf? {}'.format(addrs))\\n\", '        computed = xor_blocks(*blocks[first:])\\n', '        self.blocks = blocks[:] + [computed]\\n', '        self.last_dva = dva, addrs\\n', '        return data\\n']",
  "context": "\n        format_str += '{}B'.format(size % 8)\n    structure = struct.Struct(format_str)\n    out = [reduce(operator.xor, t) for t in zip(*("
 },
 "204": {
  "name": "out",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/raidzdev.py",
  "lineno": "68",
  "column": "4",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def convert(k, base, disks, parity):\\n', '    off = (disks+parity+2)/base\\n', '    k -= base\\n', '    if k >= 230:\\n', '        off -= 3\\n', '    return (k + off) % disks\\n', 'def should_resize(offset, size, disks, parity):\\n', '    base = (size % 10)\\n', '    if size >= 8 and base in (4, 8):\\n', '        return convert(size, base, disks, parity) == offset % disks\\n', 'def locate_data(disks, parity, offset, size):\\n', '    first_col = parity\\n', '    ret = [disks, first_col]\\n', '    vdevs = []\\n', '    bit_12 = (offset >> 11) & 1\\n', '    vdev_ids = list(range(disks))\\n', '    order = list(range(disks))\\n', '    if bit_12:\\n', '        order[0:2] = reversed(order[0:2])\\n', '    for i in order:\\n', '        dva = ondisk.dva()\\n', '        dva.vdev = vdev_ids[(offset + i) % disks]\\n', '        dva.offset = int((offset + i) / disks)\\n', '        vdevs.append(dva)\\n', '    vdev_order = [d.vdev for d in vdevs]\\n', \"        logger.debug('*'*30, size)\\n\", '    if disks == 5 and should_resize(offset, size, disks, parity):\\n', \"        logger.debug('!!!!!! size decrease {} {:} {:} {} {:} {}'.format(offset % disks, offset, size, list(map(int, vdev_order)), size, bit_12))\\n\", '        size -= 1\\n', '    for _, next_vdev in zip(range(size), itertools.cycle(vdevs)):\\n', '        next_vdev.asize += 1\\n', '    ret.append(tuple(vdevs))\\n', '    return ret\\n', 'def xor_blocks(*args):\\n', '    args = [x for x in args if len(x)]\\n', '    if len(args) == 0:\\n', '    size = min(len(x) for x in args)\\n', '    args = [x[:size] for x in args]\\n', \"    format_str = '>'\\n\", '    if size >= 8:\\n', \"        format_str += '{}Q'.format(int(size/8))\\n\", '    if size % 8:\\n', \"        format_str += '{}B'.format(size % 8)\\n\", '    structure = struct.Struct(format_str)\\n', '    out = [reduce(operator.xor, t) for t in zip(*(structure.unpack(x) for x in args))]\\n', '    return structure.pack(*out)\\n', 'class RaidZDev(vdevs.VDev):\\n', '        self.parity = parity\\n', '        return self.devs[dva.vdev].read_dva(dva)\\n', '        offset = dva.offset\\n', '        num_disks = len(self.devs)\\n', '        parity = self.parity\\n', '        columns, first, addrs = locate_data(num_disks, parity, offset, dva.asize)\\n', '        if columns == num_disks:\\n', '            blocks = [self._read_resolved(addr) for addr in addrs]\\n', \"            data = b''.join(blocks[first:])\\n\", \"            raise Exception('wtf? {}'.format(addrs))\\n\", '        computed = xor_blocks(*blocks[first:])\\n', '        self.blocks = blocks[:] + [computed]\\n', '        self.last_dva = dva, addrs\\n', '        return data\\n']",
  "context": " 8)\n    structure = struct.Struct(format_str)\n    out = [reduce(operator.xor, t) for t in zip(*(structure.unpack(x) for x in args))]\n    return structure.pack(*out)\n\n\nclass RaidZDev(v"
 },
 "205": {
  "name": "num_disks",
  "type": "len",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/raidzdev.py",
  "lineno": "86",
  "column": "8",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def convert(k, base, disks, parity):\\n', '    off = (disks+parity+2)/base\\n', '    k -= base\\n', '    if k >= 230:\\n', '        off -= 3\\n', '    return (k + off) % disks\\n', 'def should_resize(offset, size, disks, parity):\\n', '    base = (size % 10)\\n', '    if size >= 8 and base in (4, 8):\\n', '        return convert(size, base, disks, parity) == offset % disks\\n', 'def locate_data(disks, parity, offset, size):\\n', '    first_col = parity\\n', '    ret = [disks, first_col]\\n', '    vdevs = []\\n', '    bit_12 = (offset >> 11) & 1\\n', '    vdev_ids = list(range(disks))\\n', '    order = list(range(disks))\\n', '    if bit_12:\\n', '        order[0:2] = reversed(order[0:2])\\n', '    for i in order:\\n', '        dva = ondisk.dva()\\n', '        dva.vdev = vdev_ids[(offset + i) % disks]\\n', '        dva.offset = int((offset + i) / disks)\\n', '        vdevs.append(dva)\\n', '    vdev_order = [d.vdev for d in vdevs]\\n', \"        logger.debug('*'*30, size)\\n\", '    if disks == 5 and should_resize(offset, size, disks, parity):\\n', \"        logger.debug('!!!!!! size decrease {} {:} {:} {} {:} {}'.format(offset % disks, offset, size, list(map(int, vdev_order)), size, bit_12))\\n\", '        size -= 1\\n', '    for _, next_vdev in zip(range(size), itertools.cycle(vdevs)):\\n', '        next_vdev.asize += 1\\n', '    ret.append(tuple(vdevs))\\n', '    return ret\\n', 'def xor_blocks(*args):\\n', '    args = [x for x in args if len(x)]\\n', '    if len(args) == 0:\\n', '    size = min(len(x) for x in args)\\n', '    args = [x[:size] for x in args]\\n', \"    format_str = '>'\\n\", '    if size >= 8:\\n', \"        format_str += '{}Q'.format(int(size/8))\\n\", '    if size % 8:\\n', \"        format_str += '{}B'.format(size % 8)\\n\", '    structure = struct.Struct(format_str)\\n', '    out = [reduce(operator.xor, t) for t in zip(*(structure.unpack(x) for x in args))]\\n', '    return structure.pack(*out)\\n', 'class RaidZDev(vdevs.VDev):\\n', '        self.parity = parity\\n', '        return self.devs[dva.vdev].read_dva(dva)\\n', '        offset = dva.offset\\n', '        num_disks = len(self.devs)\\n', '        parity = self.parity\\n', '        columns, first, addrs = locate_data(num_disks, parity, offset, dva.asize)\\n', '        if columns == num_disks:\\n', '            blocks = [self._read_resolved(addr) for addr in addrs]\\n', \"            data = b''.join(blocks[first:])\\n\", \"            raise Exception('wtf? {}'.format(addrs))\\n\", '        computed = xor_blocks(*blocks[first:])\\n', '        self.blocks = blocks[:] + [computed]\\n', '        self.last_dva = dva, addrs\\n', '        return data\\n']",
  "context": "a(self, dva):\n        offset = dva.offset\n        num_disks = len(self.devs)\n        parity = self.parity\n        columns, firs"
 },
 "206": {
  "name": "columns",
  "type": "locate_data",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/raidzdev.py",
  "lineno": "88",
  "column": "8",
  "slicing": "['        columns, first, addrs = locate_data(num_disks, parity, offset, dva.asize)\\n', '        if columns == num_disks:\\n']",
  "context": "n(self.devs)\n        parity = self.parity\n        columns, first, addrs = locate_data(num_disks, parity, offset, dva.asize)\n        if columns == num_disks:\n            block"
 },
 "207": {
  "name": "first",
  "type": "locate_data",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/raidzdev.py",
  "lineno": "88",
  "column": "17",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def convert(k, base, disks, parity):\\n', '    off = (disks+parity+2)/base\\n', '    k -= base\\n', '    if k >= 230:\\n', '        off -= 3\\n', '    return (k + off) % disks\\n', 'def should_resize(offset, size, disks, parity):\\n', '    base = (size % 10)\\n', '    if size >= 8 and base in (4, 8):\\n', '        return convert(size, base, disks, parity) == offset % disks\\n', 'def locate_data(disks, parity, offset, size):\\n', '    first_col = parity\\n', '    ret = [disks, first_col]\\n', '    vdevs = []\\n', '    bit_12 = (offset >> 11) & 1\\n', '    vdev_ids = list(range(disks))\\n', '    order = list(range(disks))\\n', '    if bit_12:\\n', '        order[0:2] = reversed(order[0:2])\\n', '    for i in order:\\n', '        dva = ondisk.dva()\\n', '        dva.vdev = vdev_ids[(offset + i) % disks]\\n', '        dva.offset = int((offset + i) / disks)\\n', '        vdevs.append(dva)\\n', '    vdev_order = [d.vdev for d in vdevs]\\n', \"        logger.debug('*'*30, size)\\n\", '    if disks == 5 and should_resize(offset, size, disks, parity):\\n', \"        logger.debug('!!!!!! size decrease {} {:} {:} {} {:} {}'.format(offset % disks, offset, size, list(map(int, vdev_order)), size, bit_12))\\n\", '        size -= 1\\n', '    for _, next_vdev in zip(range(size), itertools.cycle(vdevs)):\\n', '        next_vdev.asize += 1\\n', '    ret.append(tuple(vdevs))\\n', '    return ret\\n', 'def xor_blocks(*args):\\n', '    args = [x for x in args if len(x)]\\n', '    if len(args) == 0:\\n', '    size = min(len(x) for x in args)\\n', '    args = [x[:size] for x in args]\\n', \"    format_str = '>'\\n\", '    if size >= 8:\\n', \"        format_str += '{}Q'.format(int(size/8))\\n\", '    if size % 8:\\n', \"        format_str += '{}B'.format(size % 8)\\n\", '    structure = struct.Struct(format_str)\\n', '    out = [reduce(operator.xor, t) for t in zip(*(structure.unpack(x) for x in args))]\\n', '    return structure.pack(*out)\\n', 'class RaidZDev(vdevs.VDev):\\n', '        self.parity = parity\\n', '        return self.devs[dva.vdev].read_dva(dva)\\n', '        offset = dva.offset\\n', '        num_disks = len(self.devs)\\n', '        parity = self.parity\\n', '        columns, first, addrs = locate_data(num_disks, parity, offset, dva.asize)\\n', '        if columns == num_disks:\\n', '            blocks = [self._read_resolved(addr) for addr in addrs]\\n', \"            data = b''.join(blocks[first:])\\n\", \"            raise Exception('wtf? {}'.format(addrs))\\n\", '        computed = xor_blocks(*blocks[first:])\\n', '        self.blocks = blocks[:] + [computed]\\n', '        self.last_dva = dva, addrs\\n', '        return data\\n']",
  "context": "vs)\n        parity = self.parity\n        columns, first, addrs = locate_data(num_disks, parity, offset, dva.asize)\n        if columns == num_disks:\n            block"
 },
 "208": {
  "name": "addrs",
  "type": "locate_data",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/raidzdev.py",
  "lineno": "88",
  "column": "24",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def convert(k, base, disks, parity):\\n', '    off = (disks+parity+2)/base\\n', '    k -= base\\n', '    if k >= 230:\\n', '        off -= 3\\n', '    return (k + off) % disks\\n', 'def should_resize(offset, size, disks, parity):\\n', '    base = (size % 10)\\n', '    if size >= 8 and base in (4, 8):\\n', '        return convert(size, base, disks, parity) == offset % disks\\n', 'def locate_data(disks, parity, offset, size):\\n', '    first_col = parity\\n', '    ret = [disks, first_col]\\n', '    vdevs = []\\n', '    bit_12 = (offset >> 11) & 1\\n', '    vdev_ids = list(range(disks))\\n', '    order = list(range(disks))\\n', '    if bit_12:\\n', '        order[0:2] = reversed(order[0:2])\\n', '    for i in order:\\n', '        dva = ondisk.dva()\\n', '        dva.vdev = vdev_ids[(offset + i) % disks]\\n', '        dva.offset = int((offset + i) / disks)\\n', '        vdevs.append(dva)\\n', '    vdev_order = [d.vdev for d in vdevs]\\n', \"        logger.debug('*'*30, size)\\n\", '    if disks == 5 and should_resize(offset, size, disks, parity):\\n', \"        logger.debug('!!!!!! size decrease {} {:} {:} {} {:} {}'.format(offset % disks, offset, size, list(map(int, vdev_order)), size, bit_12))\\n\", '        size -= 1\\n', '    for _, next_vdev in zip(range(size), itertools.cycle(vdevs)):\\n', '        next_vdev.asize += 1\\n', '    ret.append(tuple(vdevs))\\n', '    return ret\\n', 'def xor_blocks(*args):\\n', '    args = [x for x in args if len(x)]\\n', '    if len(args) == 0:\\n', '    size = min(len(x) for x in args)\\n', '    args = [x[:size] for x in args]\\n', \"    format_str = '>'\\n\", '    if size >= 8:\\n', \"        format_str += '{}Q'.format(int(size/8))\\n\", '    if size % 8:\\n', \"        format_str += '{}B'.format(size % 8)\\n\", '    structure = struct.Struct(format_str)\\n', '    out = [reduce(operator.xor, t) for t in zip(*(structure.unpack(x) for x in args))]\\n', '    return structure.pack(*out)\\n', 'class RaidZDev(vdevs.VDev):\\n', '        self.parity = parity\\n', '        return self.devs[dva.vdev].read_dva(dva)\\n', '        offset = dva.offset\\n', '        num_disks = len(self.devs)\\n', '        parity = self.parity\\n', '        columns, first, addrs = locate_data(num_disks, parity, offset, dva.asize)\\n', '        if columns == num_disks:\\n', '            blocks = [self._read_resolved(addr) for addr in addrs]\\n', \"            data = b''.join(blocks[first:])\\n\", \"            raise Exception('wtf? {}'.format(addrs))\\n\", '        computed = xor_blocks(*blocks[first:])\\n', '        self.blocks = blocks[:] + [computed]\\n', '        self.last_dva = dva, addrs\\n', '        return data\\n']",
  "context": "     parity = self.parity\n        columns, first, addrs = locate_data(num_disks, parity, offset, dva.asize)\n        if columns == num_disks:\n            block"
 },
 "209": {
  "name": "blocks",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/raidzdev.py",
  "lineno": "90",
  "column": "12",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def convert(k, base, disks, parity):\\n', '    off = (disks+parity+2)/base\\n', '    k -= base\\n', '    if k >= 230:\\n', '        off -= 3\\n', '    return (k + off) % disks\\n', 'def should_resize(offset, size, disks, parity):\\n', '    base = (size % 10)\\n', '    if size >= 8 and base in (4, 8):\\n', '        return convert(size, base, disks, parity) == offset % disks\\n', 'def locate_data(disks, parity, offset, size):\\n', '    first_col = parity\\n', '    ret = [disks, first_col]\\n', '    vdevs = []\\n', '    bit_12 = (offset >> 11) & 1\\n', '    vdev_ids = list(range(disks))\\n', '    order = list(range(disks))\\n', '    if bit_12:\\n', '        order[0:2] = reversed(order[0:2])\\n', '    for i in order:\\n', '        dva = ondisk.dva()\\n', '        dva.vdev = vdev_ids[(offset + i) % disks]\\n', '        dva.offset = int((offset + i) / disks)\\n', '        vdevs.append(dva)\\n', '    vdev_order = [d.vdev for d in vdevs]\\n', \"        logger.debug('*'*30, size)\\n\", '    if disks == 5 and should_resize(offset, size, disks, parity):\\n', \"        logger.debug('!!!!!! size decrease {} {:} {:} {} {:} {}'.format(offset % disks, offset, size, list(map(int, vdev_order)), size, bit_12))\\n\", '        size -= 1\\n', '    for _, next_vdev in zip(range(size), itertools.cycle(vdevs)):\\n', '        next_vdev.asize += 1\\n', '    ret.append(tuple(vdevs))\\n', '    return ret\\n', 'def xor_blocks(*args):\\n', '    args = [x for x in args if len(x)]\\n', '    if len(args) == 0:\\n', '    size = min(len(x) for x in args)\\n', '    args = [x[:size] for x in args]\\n', \"    format_str = '>'\\n\", '    if size >= 8:\\n', \"        format_str += '{}Q'.format(int(size/8))\\n\", '    if size % 8:\\n', \"        format_str += '{}B'.format(size % 8)\\n\", '    structure = struct.Struct(format_str)\\n', '    out = [reduce(operator.xor, t) for t in zip(*(structure.unpack(x) for x in args))]\\n', '    return structure.pack(*out)\\n', 'class RaidZDev(vdevs.VDev):\\n', '        self.parity = parity\\n', '        return self.devs[dva.vdev].read_dva(dva)\\n', '        offset = dva.offset\\n', '        num_disks = len(self.devs)\\n', '        parity = self.parity\\n', '        columns, first, addrs = locate_data(num_disks, parity, offset, dva.asize)\\n', '        if columns == num_disks:\\n', '            blocks = [self._read_resolved(addr) for addr in addrs]\\n', \"            data = b''.join(blocks[first:])\\n\", \"            raise Exception('wtf? {}'.format(addrs))\\n\", '        computed = xor_blocks(*blocks[first:])\\n', '        self.blocks = blocks[:] + [computed]\\n', '        self.last_dva = dva, addrs\\n', '        return data\\n']",
  "context": "ize)\n        if columns == num_disks:\n            blocks = [self._read_resolved(addr) for addr in addrs]\n            data = b''.join(blocks[first:])\n      "
 },
 "210": {
  "name": "computed",
  "type": "xor_blocks",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/raidzdev.py",
  "lineno": "94",
  "column": "8",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def convert(k, base, disks, parity):\\n', '    off = (disks+parity+2)/base\\n', '    k -= base\\n', '    if k >= 230:\\n', '        off -= 3\\n', '    return (k + off) % disks\\n', 'def should_resize(offset, size, disks, parity):\\n', '    base = (size % 10)\\n', '    if size >= 8 and base in (4, 8):\\n', '        return convert(size, base, disks, parity) == offset % disks\\n', 'def locate_data(disks, parity, offset, size):\\n', '    first_col = parity\\n', '    ret = [disks, first_col]\\n', '    vdevs = []\\n', '    bit_12 = (offset >> 11) & 1\\n', '    vdev_ids = list(range(disks))\\n', '    order = list(range(disks))\\n', '    if bit_12:\\n', '        order[0:2] = reversed(order[0:2])\\n', '    for i in order:\\n', '        dva = ondisk.dva()\\n', '        dva.vdev = vdev_ids[(offset + i) % disks]\\n', '        dva.offset = int((offset + i) / disks)\\n', '        vdevs.append(dva)\\n', '    vdev_order = [d.vdev for d in vdevs]\\n', \"        logger.debug('*'*30, size)\\n\", '    if disks == 5 and should_resize(offset, size, disks, parity):\\n', \"        logger.debug('!!!!!! size decrease {} {:} {:} {} {:} {}'.format(offset % disks, offset, size, list(map(int, vdev_order)), size, bit_12))\\n\", '        size -= 1\\n', '    for _, next_vdev in zip(range(size), itertools.cycle(vdevs)):\\n', '        next_vdev.asize += 1\\n', '    ret.append(tuple(vdevs))\\n', '    return ret\\n', 'def xor_blocks(*args):\\n', '    args = [x for x in args if len(x)]\\n', '    if len(args) == 0:\\n', '    size = min(len(x) for x in args)\\n', '    args = [x[:size] for x in args]\\n', \"    format_str = '>'\\n\", '    if size >= 8:\\n', \"        format_str += '{}Q'.format(int(size/8))\\n\", '    if size % 8:\\n', \"        format_str += '{}B'.format(size % 8)\\n\", '    structure = struct.Struct(format_str)\\n', '    out = [reduce(operator.xor, t) for t in zip(*(structure.unpack(x) for x in args))]\\n', '    return structure.pack(*out)\\n', 'class RaidZDev(vdevs.VDev):\\n', '        self.parity = parity\\n', '        return self.devs[dva.vdev].read_dva(dva)\\n', '        offset = dva.offset\\n', '        num_disks = len(self.devs)\\n', '        parity = self.parity\\n', '        columns, first, addrs = locate_data(num_disks, parity, offset, dva.asize)\\n', '        if columns == num_disks:\\n', '            blocks = [self._read_resolved(addr) for addr in addrs]\\n', \"            data = b''.join(blocks[first:])\\n\", \"            raise Exception('wtf? {}'.format(addrs))\\n\", '        computed = xor_blocks(*blocks[first:])\\n', '        self.blocks = blocks[:] + [computed]\\n', '        self.last_dva = dva, addrs\\n', '        return data\\n']",
  "context": " raise Exception('wtf? {}'.format(addrs))\n        computed = xor_blocks(*blocks[first:])\n        self.blocks = blocks[:] + [computed]\n     "
 },
 "211": {
  "name": "offset",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/raidzdev.py",
  "lineno": "99",
  "column": "19",
  "slicing": "['    def read(self, offset: Union[int, Tuple[int, int]], size: int) -> bytes:\\n']",
  "context": "va, addrs\n        return data\n\n    def read(self, offset: Union[int, Tuple[int, int]], size: int) -> bytes:\n        raise Exception\n\n"
 },
 "212": {
  "name": "size",
  "type": "int",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/raidzdev.py",
  "lineno": "99",
  "column": "56",
  "slicing": "['    def read(self, offset: Union[int, Tuple[int, int]], size: int) -> bytes:\\n']",
  "context": "f read(self, offset: Union[int, Tuple[int, int]], size: int) -> bytes:\n        raise Exception\n\n"
 },
 "213": {
  "name": "block",
  "type": "uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "21",
  "column": "4",
  "slicing": "['    block = uint64()\\n']",
  "context": "interTable(Struct):\n    __ENDIAN__ = 'little'\n    block = uint64()\n    num_blocks = uint64()\n    shift = uint64()\n   "
 },
 "214": {
  "name": "num_blocks",
  "type": "uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "22",
  "column": "4",
  "slicing": "['    num_blocks = uint64()\\n']",
  "context": "   __ENDIAN__ = 'little'\n    block = uint64()\n    num_blocks = uint64()\n    shift = uint64()\n    next_block = uint64()\n   "
 },
 "215": {
  "name": "shift",
  "type": "uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "23",
  "column": "4",
  "slicing": "['    shift = uint64()\\n']",
  "context": "   block = uint64()\n    num_blocks = uint64()\n    shift = uint64()\n    next_block = uint64()\n    blocks_copied = uint"
 },
 "216": {
  "name": "next_block",
  "type": "uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "24",
  "column": "4",
  "slicing": "['    next_block = uint64()\\n']",
  "context": "   num_blocks = uint64()\n    shift = uint64()\n    next_block = uint64()\n    blocks_copied = uint64()\n\n\nclass LeafHeader(St"
 },
 "217": {
  "name": "blocks_copied",
  "type": "uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "25",
  "column": "4",
  "slicing": "['    blocks_copied = uint64()\\n']",
  "context": "   shift = uint64()\n    next_block = uint64()\n    blocks_copied = uint64()\n\n\nclass LeafHeader(Struct):\n    __ENDIAN__ = 'litt"
 },
 "218": {
  "name": "header",
  "type": "uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "30",
  "column": "4",
  "slicing": "['    header = uint64(enum=constants.ZapType)\\n', '    data = bytestring(length=23)\\n', '    padding = padding(length=2)\\n', '    data = bytestring(length=21)\\n', 'CHUNK_TYPES = {\\n', 'def parse_chunk(chunk: Union[LeafChunk, BytesIO]) -> LeafType:\\n', '        ch = LeafChunk(chunk)\\n', '        ch = chunk\\n', '    return CHUNK_TYPES[ch.chunk_type](ch.data)\\n', '    reader = BytesIO(data)\\n', '    header = FatZAPHeader(reader)\\n', '    ret = OrderedDict()\\n', '    for i in range(header.num_leafs):\\n', '        i += 1\\n', '        reader.seek(8*2048*i)\\n', '        _leaf_hdr = LeafHeader(reader)\\n', '        hashes = reader.read(1 << header.ptr_info.shift)\\n', '        chunks = []\\n', '                c = parse_chunk(reader)\\n', '                chunks.append(c)\\n', '        ret.update(reconstruct_data(chunks))\\n', '    return ret\\n', 'def read_linked(chunks: List[LeafType], first: int) -> bytes:\\n', '    index = first\\n', '    out = []\\n', '    while index < 65535:\\n', '            c = chunks[index]\\n', '            out.append(c.data)\\n', '            index = c.next\\n', \"    return b''.join(out)\\n\", 'formats = {\\n', '    for entry in chunks:\\n', '        if isinstance(entry, LeafEntry):\\n', '            key = read_linked(chunks, entry.name_chunk)[:entry.name_length-1]\\n', '            raw_value = read_linked(chunks, entry.value_chunk)[:entry.size * entry.value_length]\\n', '            if entry.size in formats:\\n', \"                format_code = '>' + formats[entry.size] * entry.value_length\\n\", '                value = struct.unpack(format_code, raw_value)\\n', '                if len(value) == 1:\\n', '                    value = value[0]\\n', \"                items[key.decode('utf-8')] = value\\n\"]",
  "context": "LeafHeader(Struct):\n    __ENDIAN__ = 'little'\n    header = uint64(enum=constants.ZapType)\n    next = uint64()\n    prefix = uint64()\n    magi"
 },
 "219": {
  "name": "next",
  "type": "uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "31",
  "column": "4",
  "slicing": "['    next = uint64()\\n']",
  "context": "'\n    header = uint64(enum=constants.ZapType)\n    next = uint64()\n    prefix = uint64()\n    magic = uint64()\n    num"
 },
 "220": {
  "name": "prefix",
  "type": "uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "32",
  "column": "4",
  "slicing": "['    prefix = uint64()\\n']",
  "context": "4(enum=constants.ZapType)\n    next = uint64()\n    prefix = uint64()\n    magic = uint64()\n    num_free = uint16()\n    n"
 },
 "221": {
  "name": "magic",
  "type": "uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "33",
  "column": "4",
  "slicing": "['    magic = uint64()\\n']",
  "context": "pe)\n    next = uint64()\n    prefix = uint64()\n    magic = uint64()\n    num_free = uint16()\n    n_entries = uint64()\n "
 },
 "222": {
  "name": "num_free",
  "type": "uint16",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "34",
  "column": "4",
  "slicing": "['    num_free = uint16()\\n']",
  "context": "()\n    prefix = uint64()\n    magic = uint64()\n    num_free = uint16()\n    n_entries = uint64()\n    prefix_len = uint16()"
 },
 "223": {
  "name": "n_entries",
  "type": "uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "35",
  "column": "4",
  "slicing": "['    n_entries = uint64()\\n']",
  "context": "\n    magic = uint64()\n    num_free = uint16()\n    n_entries = uint64()\n    prefix_len = uint16()\n    freelist = uint16()\n"
 },
 "224": {
  "name": "prefix_len",
  "type": "uint16",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "36",
  "column": "4",
  "slicing": "['    prefix_len = uint16()\\n']",
  "context": " num_free = uint16()\n    n_entries = uint64()\n    prefix_len = uint16()\n    freelist = uint16()\n    _padding = padding(len"
 },
 "225": {
  "name": "freelist",
  "type": "uint16",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "37",
  "column": "4",
  "slicing": "['    freelist = uint16()\\n']",
  "context": "_entries = uint64()\n    prefix_len = uint16()\n    freelist = uint16()\n    _padding = padding(length=2)\n\n\nclass FatZAPHea"
 },
 "226": {
  "name": "_padding",
  "type": "padding",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "38",
  "column": "4",
  "slicing": "['    _padding = padding(length=2)\\n']",
  "context": "prefix_len = uint16()\n    freelist = uint16()\n    _padding = padding(length=2)\n\n\nclass FatZAPHeader(Struct):\n\n    class MAGIC(enu"
 },
 "227": {
  "name": "block_type",
  "type": "uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "47",
  "column": "4",
  "slicing": "['    block_type = uint64(enum=constants.ZapType)\\n']",
  "context": " ZAP = 0x2F52AB2AB\n\n    __ENDIAN__ = 'little'\n    block_type = uint64(enum=constants.ZapType)\n    magic = uint64(enum=MAGIC)\n    ptr_info = Poin"
 },
 "228": {
  "name": "magic",
  "type": "uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "48",
  "column": "4",
  "slicing": "['    magic = uint64(enum=MAGIC)\\n']",
  "context": "  block_type = uint64(enum=constants.ZapType)\n    magic = uint64(enum=MAGIC)\n    ptr_info = PointerTable()\n    first_free = uin"
 },
 "229": {
  "name": "ptr_info",
  "type": "PointerTable",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "49",
  "column": "4",
  "slicing": "['    ptr_info = PointerTable()\\n']",
  "context": "tants.ZapType)\n    magic = uint64(enum=MAGIC)\n    ptr_info = PointerTable()\n    first_free = uint64()\n    num_leafs = uint64()"
 },
 "230": {
  "name": "first_free",
  "type": "uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "50",
  "column": "4",
  "slicing": "['    first_free = uint64()\\n']",
  "context": "t64(enum=MAGIC)\n    ptr_info = PointerTable()\n    first_free = uint64()\n    num_leafs = uint64()\n    num_entries = uint64("
 },
 "231": {
  "name": "num_leafs",
  "type": "uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "51",
  "column": "4",
  "slicing": "['    num_leafs = uint64()\\n']",
  "context": "fo = PointerTable()\n    first_free = uint64()\n    num_leafs = uint64()\n    num_entries = uint64()\n    salt = uint64()\n\n\nc"
 },
 "232": {
  "name": "num_entries",
  "type": "uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "52",
  "column": "4",
  "slicing": "['    num_entries = uint64()\\n']",
  "context": "irst_free = uint64()\n    num_leafs = uint64()\n    num_entries = uint64()\n    salt = uint64()\n\n\nclass LeafChunk(Struct):\n   "
 },
 "233": {
  "name": "salt",
  "type": "uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "53",
  "column": "4",
  "slicing": "['    salt = uint64()\\n']",
  "context": "m_leafs = uint64()\n    num_entries = uint64()\n    salt = uint64()\n\n\nclass LeafChunk(Struct):\n    __ENDIAN__ = 'littl"
 },
 "234": {
  "name": "chunk_type",
  "type": "uint8",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "58",
  "column": "4",
  "slicing": "['    chunk_type = uint8()\\n']",
  "context": " LeafChunk(Struct):\n    __ENDIAN__ = 'little'\n    chunk_type = uint8()\n    data = bytestring(length=23)\n\n\nclass LeafType("
 },
 "235": {
  "name": "data",
  "type": "bytestring",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "59",
  "column": "4",
  "slicing": "['    header = uint64(enum=constants.ZapType)\\n', '    data = bytestring(length=23)\\n', '    padding = padding(length=2)\\n', '    data = bytestring(length=21)\\n', 'CHUNK_TYPES = {\\n', 'def parse_chunk(chunk: Union[LeafChunk, BytesIO]) -> LeafType:\\n', '        ch = LeafChunk(chunk)\\n', '        ch = chunk\\n', '    return CHUNK_TYPES[ch.chunk_type](ch.data)\\n', '    reader = BytesIO(data)\\n', '    header = FatZAPHeader(reader)\\n', '    ret = OrderedDict()\\n', '    for i in range(header.num_leafs):\\n', '        i += 1\\n', '        reader.seek(8*2048*i)\\n', '        _leaf_hdr = LeafHeader(reader)\\n', '        hashes = reader.read(1 << header.ptr_info.shift)\\n', '        chunks = []\\n', '                c = parse_chunk(reader)\\n', '                chunks.append(c)\\n', '        ret.update(reconstruct_data(chunks))\\n', '    return ret\\n', 'def read_linked(chunks: List[LeafType], first: int) -> bytes:\\n', '    index = first\\n', '    out = []\\n', '    while index < 65535:\\n', '            c = chunks[index]\\n', '            out.append(c.data)\\n', '            index = c.next\\n', \"    return b''.join(out)\\n\", 'formats = {\\n', '    for entry in chunks:\\n', '        if isinstance(entry, LeafEntry):\\n', '            key = read_linked(chunks, entry.name_chunk)[:entry.name_length-1]\\n', '            raw_value = read_linked(chunks, entry.value_chunk)[:entry.size * entry.value_length]\\n', '            if entry.size in formats:\\n', \"                format_code = '>' + formats[entry.size] * entry.value_length\\n\", '                value = struct.unpack(format_code, raw_value)\\n', '                if len(value) == 1:\\n', '                    value = value[0]\\n', \"                items[key.decode('utf-8')] = value\\n\"]",
  "context": "_ENDIAN__ = 'little'\n    chunk_type = uint8()\n    data = bytestring(length=23)\n\n\nclass LeafType(Struct):\n    pass\n\n\nclass LeafEnt"
 },
 "236": {
  "name": "size",
  "type": "uint8",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "67",
  "column": "4",
  "slicing": "['    size = uint8()\\n']",
  "context": "truct):\n    pass\n\n\nclass LeafEntry(LeafType):\n    size = uint8()\n    next = uint16()\n    name_chunk = uint16()\n    "
 },
 "237": {
  "name": "next",
  "type": "uint16",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "68",
  "column": "4",
  "slicing": "['    next = uint16()\\n']",
  "context": "class LeafEntry(LeafType):\n    size = uint8()\n    next = uint16()\n    name_chunk = uint16()\n    name_length = uint16"
 },
 "238": {
  "name": "name_chunk",
  "type": "uint16",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "69",
  "column": "4",
  "slicing": "['    name_chunk = uint16()\\n']",
  "context": "Type):\n    size = uint8()\n    next = uint16()\n    name_chunk = uint16()\n    name_length = uint16()\n    value_chunk = uint1"
 },
 "239": {
  "name": "name_length",
  "type": "uint16",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "70",
  "column": "4",
  "slicing": "['    name_length = uint16()\\n']",
  "context": "    next = uint16()\n    name_chunk = uint16()\n    name_length = uint16()\n    value_chunk = uint16()\n    value_length = uint"
 },
 "240": {
  "name": "value_chunk",
  "type": "uint16",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "71",
  "column": "4",
  "slicing": "['    value_chunk = uint16()\\n']",
  "context": "e_chunk = uint16()\n    name_length = uint16()\n    value_chunk = uint16()\n    value_length = uint16()\n    collision = uint16"
 },
 "241": {
  "name": "value_length",
  "type": "uint16",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "72",
  "column": "4",
  "slicing": "['    value_length = uint16()\\n']",
  "context": "_length = uint16()\n    value_chunk = uint16()\n    value_length = uint16()\n    collision = uint16()\n    padding = padding(len"
 },
 "242": {
  "name": "collision",
  "type": "uint16",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "73",
  "column": "4",
  "slicing": "['    collision = uint16()\\n']",
  "context": "_chunk = uint16()\n    value_length = uint16()\n    collision = uint16()\n    padding = padding(length=2)\n    hash = uint64("
 },
 "243": {
  "name": "padding",
  "type": "padding",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "74",
  "column": "4",
  "slicing": "['    padding = padding(length=2)\\n']",
  "context": "ue_length = uint16()\n    collision = uint16()\n    padding = padding(length=2)\n    hash = uint64()\n\n\nclass LeafArray(LeafType):\n "
 },
 "244": {
  "name": "hash",
  "type": "uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "75",
  "column": "4",
  "slicing": "['    padding = padding(length=2)\\n', '    hash = uint64()\\n']",
  "context": "on = uint16()\n    padding = padding(length=2)\n    hash = uint64()\n\n\nclass LeafArray(LeafType):\n    data = bytestring"
 },
 "245": {
  "name": "data",
  "type": "bytestring",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "79",
  "column": "4",
  "slicing": "['    header = uint64(enum=constants.ZapType)\\n', '    data = bytestring(length=23)\\n', '    padding = padding(length=2)\\n', '    data = bytestring(length=21)\\n', 'CHUNK_TYPES = {\\n', 'def parse_chunk(chunk: Union[LeafChunk, BytesIO]) -> LeafType:\\n', '        ch = LeafChunk(chunk)\\n', '        ch = chunk\\n', '    return CHUNK_TYPES[ch.chunk_type](ch.data)\\n', '    reader = BytesIO(data)\\n', '    header = FatZAPHeader(reader)\\n', '    ret = OrderedDict()\\n', '    for i in range(header.num_leafs):\\n', '        i += 1\\n', '        reader.seek(8*2048*i)\\n', '        _leaf_hdr = LeafHeader(reader)\\n', '        hashes = reader.read(1 << header.ptr_info.shift)\\n', '        chunks = []\\n', '                c = parse_chunk(reader)\\n', '                chunks.append(c)\\n', '        ret.update(reconstruct_data(chunks))\\n', '    return ret\\n', 'def read_linked(chunks: List[LeafType], first: int) -> bytes:\\n', '    index = first\\n', '    out = []\\n', '    while index < 65535:\\n', '            c = chunks[index]\\n', '            out.append(c.data)\\n', '            index = c.next\\n', \"    return b''.join(out)\\n\", 'formats = {\\n', '    for entry in chunks:\\n', '        if isinstance(entry, LeafEntry):\\n', '            key = read_linked(chunks, entry.name_chunk)[:entry.name_length-1]\\n', '            raw_value = read_linked(chunks, entry.value_chunk)[:entry.size * entry.value_length]\\n', '            if entry.size in formats:\\n', \"                format_code = '>' + formats[entry.size] * entry.value_length\\n\", '                value = struct.unpack(format_code, raw_value)\\n', '                if len(value) == 1:\\n', '                    value = value[0]\\n', \"                items[key.decode('utf-8')] = value\\n\"]",
  "context": " hash = uint64()\n\n\nclass LeafArray(LeafType):\n    data = bytestring(length=21)\n    next = uint16()\n\n\nclass LeafFree(LeafType):\n  "
 },
 "246": {
  "name": "next",
  "type": "uint16",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "80",
  "column": "4",
  "slicing": "['    padding = padding(length=2)\\n', '    next = uint16()\\n']",
  "context": "y(LeafType):\n    data = bytestring(length=21)\n    next = uint16()\n\n\nclass LeafFree(LeafType):\n    _padding = bytestr"
 },
 "247": {
  "name": "_padding",
  "type": "bytestring",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "84",
  "column": "4",
  "slicing": "['    padding = padding(length=2)\\n', '    _padding = bytestring(length=21)\\n']",
  "context": "  next = uint16()\n\n\nclass LeafFree(LeafType):\n    _padding = bytestring(length=21)\n    next = uint16()\n\n\nCHUNK_TYPES = {\n    251: Lea"
 },
 "248": {
  "name": "next",
  "type": "uint16",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "85",
  "column": "4",
  "slicing": "['    padding = padding(length=2)\\n', '    next = uint16()\\n']",
  "context": "afType):\n    _padding = bytestring(length=21)\n    next = uint16()\n\n\nCHUNK_TYPES = {\n    251: LeafArray,\n    252: Lea"
 },
 "249": {
  "name": "CHUNK_TYPES",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "88",
  "column": "0",
  "slicing": "['CHUNK_TYPES = {\\n', '    return CHUNK_TYPES[ch.chunk_type](ch.data)\\n']",
  "context": "ing = bytestring(length=21)\n    next = uint16()\n\n\nCHUNK_TYPES = {\n    251: LeafArray,\n    252: LeafEntry,\n    253: L"
 },
 "250": {
  "name": "chunk",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "95",
  "column": "16",
  "slicing": "['    header = uint64(enum=constants.ZapType)\\n', '    data = bytestring(length=23)\\n', '    padding = padding(length=2)\\n', '    data = bytestring(length=21)\\n', 'CHUNK_TYPES = {\\n', 'def parse_chunk(chunk: Union[LeafChunk, BytesIO]) -> LeafType:\\n', '        ch = LeafChunk(chunk)\\n', '        ch = chunk\\n', '    return CHUNK_TYPES[ch.chunk_type](ch.data)\\n', '    reader = BytesIO(data)\\n', '    header = FatZAPHeader(reader)\\n', '    ret = OrderedDict()\\n', '    for i in range(header.num_leafs):\\n', '        i += 1\\n', '        reader.seek(8*2048*i)\\n', '        _leaf_hdr = LeafHeader(reader)\\n', '        hashes = reader.read(1 << header.ptr_info.shift)\\n', '        chunks = []\\n', '                c = parse_chunk(reader)\\n', '                chunks.append(c)\\n', '        ret.update(reconstruct_data(chunks))\\n', '    return ret\\n', 'def read_linked(chunks: List[LeafType], first: int) -> bytes:\\n', '    index = first\\n', '    out = []\\n', '    while index < 65535:\\n', '            c = chunks[index]\\n', '            out.append(c.data)\\n', '            index = c.next\\n', \"    return b''.join(out)\\n\", 'formats = {\\n', '    for entry in chunks:\\n', '        if isinstance(entry, LeafEntry):\\n', '            key = read_linked(chunks, entry.name_chunk)[:entry.name_length-1]\\n', '            raw_value = read_linked(chunks, entry.value_chunk)[:entry.size * entry.value_length]\\n', '            if entry.size in formats:\\n', \"                format_code = '>' + formats[entry.size] * entry.value_length\\n\", '                value = struct.unpack(format_code, raw_value)\\n', '                if len(value) == 1:\\n', '                    value = value[0]\\n', \"                items[key.decode('utf-8')] = value\\n\"]",
  "context": "LeafEntry,\n    253: LeafFree,\n}\n\n\ndef parse_chunk(chunk: Union[LeafChunk, BytesIO]) -> LeafType:\n    if isinstance(chunk, BytesIO):\n        ch = Le"
 },
 "251": {
  "name": "ch",
  "type": "LeafChunk",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "97",
  "column": "8",
  "slicing": "['    padding = padding(length=2)\\n', '        ch = LeafChunk(chunk)\\n', '    return CHUNK_TYPES[ch.chunk_type](ch.data)\\n']",
  "context": "fType:\n    if isinstance(chunk, BytesIO):\n        ch = LeafChunk(chunk)\n    else:\n        ch = chunk\n    return CHUNK_TYPE"
 },
 "252": {
  "name": "ch",
  "type": "chunk",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "99",
  "column": "8",
  "slicing": "['    padding = padding(length=2)\\n', '        ch = chunk\\n', '    return CHUNK_TYPES[ch.chunk_type](ch.data)\\n']",
  "context": ":\n        ch = LeafChunk(chunk)\n    else:\n        ch = chunk\n    return CHUNK_TYPES[ch.chunk_type](ch.data)\n\n\nd"
 },
 "253": {
  "name": "data",
  "type": "bytes",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "103",
  "column": "17",
  "slicing": "['def parse_fatzap(data: bytes) -> Dict[str, Any]:\\n']",
  "context": "_TYPES[ch.chunk_type](ch.data)\n\n\ndef parse_fatzap(data: bytes) -> Dict[str, Any]:\n    reader = BytesIO(data)\n    header = FatZAPHead"
 },
 "254": {
  "name": "reader",
  "type": "io.BytesIO",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "104",
  "column": "4",
  "slicing": "['    header = uint64(enum=constants.ZapType)\\n', '    data = bytestring(length=23)\\n', '    padding = padding(length=2)\\n', '    data = bytestring(length=21)\\n', 'CHUNK_TYPES = {\\n', 'def parse_chunk(chunk: Union[LeafChunk, BytesIO]) -> LeafType:\\n', '        ch = LeafChunk(chunk)\\n', '        ch = chunk\\n', '    return CHUNK_TYPES[ch.chunk_type](ch.data)\\n', '    reader = BytesIO(data)\\n', '    header = FatZAPHeader(reader)\\n', '    ret = OrderedDict()\\n', '    for i in range(header.num_leafs):\\n', '        i += 1\\n', '        reader.seek(8*2048*i)\\n', '        _leaf_hdr = LeafHeader(reader)\\n', '        hashes = reader.read(1 << header.ptr_info.shift)\\n', '        chunks = []\\n', '                c = parse_chunk(reader)\\n', '                chunks.append(c)\\n', '        ret.update(reconstruct_data(chunks))\\n', '    return ret\\n', 'def read_linked(chunks: List[LeafType], first: int) -> bytes:\\n', '    index = first\\n', '    out = []\\n', '    while index < 65535:\\n', '            c = chunks[index]\\n', '            out.append(c.data)\\n', '            index = c.next\\n', \"    return b''.join(out)\\n\", 'formats = {\\n', '    for entry in chunks:\\n', '        if isinstance(entry, LeafEntry):\\n', '            key = read_linked(chunks, entry.name_chunk)[:entry.name_length-1]\\n', '            raw_value = read_linked(chunks, entry.value_chunk)[:entry.size * entry.value_length]\\n', '            if entry.size in formats:\\n', \"                format_code = '>' + formats[entry.size] * entry.value_length\\n\", '                value = struct.unpack(format_code, raw_value)\\n', '                if len(value) == 1:\\n', '                    value = value[0]\\n', \"                items[key.decode('utf-8')] = value\\n\"]",
  "context": " parse_fatzap(data: bytes) -> Dict[str, Any]:\n    reader = BytesIO(data)\n    header = FatZAPHeader(reader)\n    ret = Ordere"
 },
 "255": {
  "name": "header",
  "type": "FatZAPHeader",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "105",
  "column": "4",
  "slicing": "['    header = uint64(enum=constants.ZapType)\\n', '    data = bytestring(length=23)\\n', '    padding = padding(length=2)\\n', '    data = bytestring(length=21)\\n', 'CHUNK_TYPES = {\\n', 'def parse_chunk(chunk: Union[LeafChunk, BytesIO]) -> LeafType:\\n', '        ch = LeafChunk(chunk)\\n', '        ch = chunk\\n', '    return CHUNK_TYPES[ch.chunk_type](ch.data)\\n', '    reader = BytesIO(data)\\n', '    header = FatZAPHeader(reader)\\n', '    ret = OrderedDict()\\n', '    for i in range(header.num_leafs):\\n', '        i += 1\\n', '        reader.seek(8*2048*i)\\n', '        _leaf_hdr = LeafHeader(reader)\\n', '        hashes = reader.read(1 << header.ptr_info.shift)\\n', '        chunks = []\\n', '                c = parse_chunk(reader)\\n', '                chunks.append(c)\\n', '        ret.update(reconstruct_data(chunks))\\n', '    return ret\\n', 'def read_linked(chunks: List[LeafType], first: int) -> bytes:\\n', '    index = first\\n', '    out = []\\n', '    while index < 65535:\\n', '            c = chunks[index]\\n', '            out.append(c.data)\\n', '            index = c.next\\n', \"    return b''.join(out)\\n\", 'formats = {\\n', '    for entry in chunks:\\n', '        if isinstance(entry, LeafEntry):\\n', '            key = read_linked(chunks, entry.name_chunk)[:entry.name_length-1]\\n', '            raw_value = read_linked(chunks, entry.value_chunk)[:entry.size * entry.value_length]\\n', '            if entry.size in formats:\\n', \"                format_code = '>' + formats[entry.size] * entry.value_length\\n\", '                value = struct.unpack(format_code, raw_value)\\n', '                if len(value) == 1:\\n', '                    value = value[0]\\n', \"                items[key.decode('utf-8')] = value\\n\"]",
  "context": "-> Dict[str, Any]:\n    reader = BytesIO(data)\n    header = FatZAPHeader(reader)\n    ret = OrderedDict()\n    for i in range(header."
 },
 "256": {
  "name": "ret",
  "type": "collections.OrderedDict",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "106",
  "column": "4",
  "slicing": "['    header = uint64(enum=constants.ZapType)\\n', '    data = bytestring(length=23)\\n', '    padding = padding(length=2)\\n', '    data = bytestring(length=21)\\n', 'CHUNK_TYPES = {\\n', 'def parse_chunk(chunk: Union[LeafChunk, BytesIO]) -> LeafType:\\n', '        ch = LeafChunk(chunk)\\n', '        ch = chunk\\n', '    return CHUNK_TYPES[ch.chunk_type](ch.data)\\n', '    reader = BytesIO(data)\\n', '    header = FatZAPHeader(reader)\\n', '    ret = OrderedDict()\\n', '    for i in range(header.num_leafs):\\n', '        i += 1\\n', '        reader.seek(8*2048*i)\\n', '        _leaf_hdr = LeafHeader(reader)\\n', '        hashes = reader.read(1 << header.ptr_info.shift)\\n', '        chunks = []\\n', '                c = parse_chunk(reader)\\n', '                chunks.append(c)\\n', '        ret.update(reconstruct_data(chunks))\\n', '    return ret\\n', 'def read_linked(chunks: List[LeafType], first: int) -> bytes:\\n', '    index = first\\n', '    out = []\\n', '    while index < 65535:\\n', '            c = chunks[index]\\n', '            out.append(c.data)\\n', '            index = c.next\\n', \"    return b''.join(out)\\n\", 'formats = {\\n', '    for entry in chunks:\\n', '        if isinstance(entry, LeafEntry):\\n', '            key = read_linked(chunks, entry.name_chunk)[:entry.name_length-1]\\n', '            raw_value = read_linked(chunks, entry.value_chunk)[:entry.size * entry.value_length]\\n', '            if entry.size in formats:\\n', \"                format_code = '>' + formats[entry.size] * entry.value_length\\n\", '                value = struct.unpack(format_code, raw_value)\\n', '                if len(value) == 1:\\n', '                    value = value[0]\\n', \"                items[key.decode('utf-8')] = value\\n\"]",
  "context": "tesIO(data)\n    header = FatZAPHeader(reader)\n    ret = OrderedDict()\n    for i in range(header.num_leafs):\n        i +="
 },
 "257": {
  "name": "i",
  "type": "int",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "108",
  "column": "8",
  "slicing": "['        i += 1\\n', '        reader.seek(8*2048*i)\\n']",
  "context": "t()\n    for i in range(header.num_leafs):\n        i += 1\n        reader.seek(8*2048*i)\n        # created on"
 },
 "258": {
  "name": "_leaf_hdr",
  "type": "LeafHeader",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "111",
  "column": "8",
  "slicing": "['    header = uint64(enum=constants.ZapType)\\n', '    data = bytestring(length=23)\\n', '    padding = padding(length=2)\\n', '    data = bytestring(length=21)\\n', 'CHUNK_TYPES = {\\n', 'def parse_chunk(chunk: Union[LeafChunk, BytesIO]) -> LeafType:\\n', '        ch = LeafChunk(chunk)\\n', '        ch = chunk\\n', '    return CHUNK_TYPES[ch.chunk_type](ch.data)\\n', '    reader = BytesIO(data)\\n', '    header = FatZAPHeader(reader)\\n', '    ret = OrderedDict()\\n', '    for i in range(header.num_leafs):\\n', '        i += 1\\n', '        reader.seek(8*2048*i)\\n', '        _leaf_hdr = LeafHeader(reader)\\n', '        hashes = reader.read(1 << header.ptr_info.shift)\\n', '        chunks = []\\n', '                c = parse_chunk(reader)\\n', '                chunks.append(c)\\n', '        ret.update(reconstruct_data(chunks))\\n', '    return ret\\n', 'def read_linked(chunks: List[LeafType], first: int) -> bytes:\\n', '    index = first\\n', '    out = []\\n', '    while index < 65535:\\n', '            c = chunks[index]\\n', '            out.append(c.data)\\n', '            index = c.next\\n', \"    return b''.join(out)\\n\", 'formats = {\\n', '    for entry in chunks:\\n', '        if isinstance(entry, LeafEntry):\\n', '            key = read_linked(chunks, entry.name_chunk)[:entry.name_length-1]\\n', '            raw_value = read_linked(chunks, entry.value_chunk)[:entry.size * entry.value_length]\\n', '            if entry.size in formats:\\n', \"                format_code = '>' + formats[entry.size] * entry.value_length\\n\", '                value = struct.unpack(format_code, raw_value)\\n', '                if len(value) == 1:\\n', '                    value = value[0]\\n', \"                items[key.decode('utf-8')] = value\\n\"]",
  "context": "     # created only to advance the reader\n        _leaf_hdr = LeafHeader(reader)\n        hashes = reader.read(1 << header.ptr_info."
 },
 "259": {
  "name": "chunks",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "114",
  "column": "8",
  "slicing": "['    header = uint64(enum=constants.ZapType)\\n', '    data = bytestring(length=23)\\n', '    padding = padding(length=2)\\n', '    data = bytestring(length=21)\\n', 'CHUNK_TYPES = {\\n', 'def parse_chunk(chunk: Union[LeafChunk, BytesIO]) -> LeafType:\\n', '        ch = LeafChunk(chunk)\\n', '        ch = chunk\\n', '    return CHUNK_TYPES[ch.chunk_type](ch.data)\\n', '    reader = BytesIO(data)\\n', '    header = FatZAPHeader(reader)\\n', '    ret = OrderedDict()\\n', '    for i in range(header.num_leafs):\\n', '        i += 1\\n', '        reader.seek(8*2048*i)\\n', '        _leaf_hdr = LeafHeader(reader)\\n', '        hashes = reader.read(1 << header.ptr_info.shift)\\n', '        chunks = []\\n', '                c = parse_chunk(reader)\\n', '                chunks.append(c)\\n', '        ret.update(reconstruct_data(chunks))\\n', '    return ret\\n', 'def read_linked(chunks: List[LeafType], first: int) -> bytes:\\n', '    index = first\\n', '    out = []\\n', '    while index < 65535:\\n', '            c = chunks[index]\\n', '            out.append(c.data)\\n', '            index = c.next\\n', \"    return b''.join(out)\\n\", 'formats = {\\n', '    for entry in chunks:\\n', '        if isinstance(entry, LeafEntry):\\n', '            key = read_linked(chunks, entry.name_chunk)[:entry.name_length-1]\\n', '            raw_value = read_linked(chunks, entry.value_chunk)[:entry.size * entry.value_length]\\n', '            if entry.size in formats:\\n', \"                format_code = '>' + formats[entry.size] * entry.value_length\\n\", '                value = struct.unpack(format_code, raw_value)\\n', '                if len(value) == 1:\\n', '                    value = value[0]\\n', \"                items[key.decode('utf-8')] = value\\n\"]",
  "context": " reader.read(1 << header.ptr_info.shift)\n\n        chunks = []\n        for x in range(638):\n            try:\n    "
 },
 "260": {
  "name": "c",
  "type": "parse_chunk",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "117",
  "column": "16",
  "slicing": "['    header = uint64(enum=constants.ZapType)\\n', '    data = bytestring(length=23)\\n', '    padding = padding(length=2)\\n', '    data = bytestring(length=21)\\n', 'CHUNK_TYPES = {\\n', 'def parse_chunk(chunk: Union[LeafChunk, BytesIO]) -> LeafType:\\n', '        ch = LeafChunk(chunk)\\n', '        ch = chunk\\n', '    return CHUNK_TYPES[ch.chunk_type](ch.data)\\n', '    reader = BytesIO(data)\\n', '    header = FatZAPHeader(reader)\\n', '    ret = OrderedDict()\\n', '    for i in range(header.num_leafs):\\n', '        i += 1\\n', '        reader.seek(8*2048*i)\\n', '        _leaf_hdr = LeafHeader(reader)\\n', '        hashes = reader.read(1 << header.ptr_info.shift)\\n', '        chunks = []\\n', '                c = parse_chunk(reader)\\n', '                chunks.append(c)\\n', '        ret.update(reconstruct_data(chunks))\\n', '    return ret\\n', 'def read_linked(chunks: List[LeafType], first: int) -> bytes:\\n', '    index = first\\n', '    out = []\\n', '    while index < 65535:\\n', '            c = chunks[index]\\n', '            out.append(c.data)\\n', '            index = c.next\\n', \"    return b''.join(out)\\n\", 'formats = {\\n', '    for entry in chunks:\\n', '        if isinstance(entry, LeafEntry):\\n', '            key = read_linked(chunks, entry.name_chunk)[:entry.name_length-1]\\n', '            raw_value = read_linked(chunks, entry.value_chunk)[:entry.size * entry.value_length]\\n', '            if entry.size in formats:\\n', \"                format_code = '>' + formats[entry.size] * entry.value_length\\n\", '                value = struct.unpack(format_code, raw_value)\\n', '                if len(value) == 1:\\n', '                    value = value[0]\\n', \"                items[key.decode('utf-8')] = value\\n\"]",
  "context": "x in range(638):\n            try:\n                c = parse_chunk(reader)\n                chunks.append(c)\n            excep"
 },
 "261": {
  "name": "chunks",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "125",
  "column": "16",
  "slicing": "['    header = uint64(enum=constants.ZapType)\\n', '    data = bytestring(length=23)\\n', '    padding = padding(length=2)\\n', '    data = bytestring(length=21)\\n', 'CHUNK_TYPES = {\\n', 'def parse_chunk(chunk: Union[LeafChunk, BytesIO]) -> LeafType:\\n', '        ch = LeafChunk(chunk)\\n', '        ch = chunk\\n', '    return CHUNK_TYPES[ch.chunk_type](ch.data)\\n', '    reader = BytesIO(data)\\n', '    header = FatZAPHeader(reader)\\n', '    ret = OrderedDict()\\n', '    for i in range(header.num_leafs):\\n', '        i += 1\\n', '        reader.seek(8*2048*i)\\n', '        _leaf_hdr = LeafHeader(reader)\\n', '        hashes = reader.read(1 << header.ptr_info.shift)\\n', '        chunks = []\\n', '                c = parse_chunk(reader)\\n', '                chunks.append(c)\\n', '        ret.update(reconstruct_data(chunks))\\n', '    return ret\\n', 'def read_linked(chunks: List[LeafType], first: int) -> bytes:\\n', '    index = first\\n', '    out = []\\n', '    while index < 65535:\\n', '            c = chunks[index]\\n', '            out.append(c.data)\\n', '            index = c.next\\n', \"    return b''.join(out)\\n\", 'formats = {\\n', '    for entry in chunks:\\n', '        if isinstance(entry, LeafEntry):\\n', '            key = read_linked(chunks, entry.name_chunk)[:entry.name_length-1]\\n', '            raw_value = read_linked(chunks, entry.value_chunk)[:entry.size * entry.value_length]\\n', '            if entry.size in formats:\\n', \"                format_code = '>' + formats[entry.size] * entry.value_length\\n\", '                value = struct.unpack(format_code, raw_value)\\n', '                if len(value) == 1:\\n', '                    value = value[0]\\n', \"                items[key.decode('utf-8')] = value\\n\"]",
  "context": "ct_data(chunks))\n    return ret\n\n\ndef read_linked(chunks: List[LeafType], first: int) -> bytes:\n    index = first\n    out = []\n    while index < 6"
 },
 "262": {
  "name": "first",
  "type": "int",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "125",
  "column": "40",
  "slicing": "['    header = uint64(enum=constants.ZapType)\\n', '    data = bytestring(length=23)\\n', '    padding = padding(length=2)\\n', '    data = bytestring(length=21)\\n', 'CHUNK_TYPES = {\\n', 'def parse_chunk(chunk: Union[LeafChunk, BytesIO]) -> LeafType:\\n', '        ch = LeafChunk(chunk)\\n', '        ch = chunk\\n', '    return CHUNK_TYPES[ch.chunk_type](ch.data)\\n', '    reader = BytesIO(data)\\n', '    header = FatZAPHeader(reader)\\n', '    ret = OrderedDict()\\n', '    for i in range(header.num_leafs):\\n', '        i += 1\\n', '        reader.seek(8*2048*i)\\n', '        _leaf_hdr = LeafHeader(reader)\\n', '        hashes = reader.read(1 << header.ptr_info.shift)\\n', '        chunks = []\\n', '                c = parse_chunk(reader)\\n', '                chunks.append(c)\\n', '        ret.update(reconstruct_data(chunks))\\n', '    return ret\\n', 'def read_linked(chunks: List[LeafType], first: int) -> bytes:\\n', '    index = first\\n', '    out = []\\n', '    while index < 65535:\\n', '            c = chunks[index]\\n', '            out.append(c.data)\\n', '            index = c.next\\n', \"    return b''.join(out)\\n\", 'formats = {\\n', '    for entry in chunks:\\n', '        if isinstance(entry, LeafEntry):\\n', '            key = read_linked(chunks, entry.name_chunk)[:entry.name_length-1]\\n', '            raw_value = read_linked(chunks, entry.value_chunk)[:entry.size * entry.value_length]\\n', '            if entry.size in formats:\\n', \"                format_code = '>' + formats[entry.size] * entry.value_length\\n\", '                value = struct.unpack(format_code, raw_value)\\n', '                if len(value) == 1:\\n', '                    value = value[0]\\n', \"                items[key.decode('utf-8')] = value\\n\"]",
  "context": "urn ret\n\n\ndef read_linked(chunks: List[LeafType], first: int) -> bytes:\n    index = first\n    out = []\n    while index < 6"
 },
 "263": {
  "name": "index",
  "type": "first",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "126",
  "column": "4",
  "slicing": "['    header = uint64(enum=constants.ZapType)\\n', '    data = bytestring(length=23)\\n', '    padding = padding(length=2)\\n', '    data = bytestring(length=21)\\n', 'CHUNK_TYPES = {\\n', 'def parse_chunk(chunk: Union[LeafChunk, BytesIO]) -> LeafType:\\n', '        ch = LeafChunk(chunk)\\n', '        ch = chunk\\n', '    return CHUNK_TYPES[ch.chunk_type](ch.data)\\n', '    reader = BytesIO(data)\\n', '    header = FatZAPHeader(reader)\\n', '    ret = OrderedDict()\\n', '    for i in range(header.num_leafs):\\n', '        i += 1\\n', '        reader.seek(8*2048*i)\\n', '        _leaf_hdr = LeafHeader(reader)\\n', '        hashes = reader.read(1 << header.ptr_info.shift)\\n', '        chunks = []\\n', '                c = parse_chunk(reader)\\n', '                chunks.append(c)\\n', '        ret.update(reconstruct_data(chunks))\\n', '    return ret\\n', 'def read_linked(chunks: List[LeafType], first: int) -> bytes:\\n', '    index = first\\n', '    out = []\\n', '    while index < 65535:\\n', '            c = chunks[index]\\n', '            out.append(c.data)\\n', '            index = c.next\\n', \"    return b''.join(out)\\n\", 'formats = {\\n', '    for entry in chunks:\\n', '        if isinstance(entry, LeafEntry):\\n', '            key = read_linked(chunks, entry.name_chunk)[:entry.name_length-1]\\n', '            raw_value = read_linked(chunks, entry.value_chunk)[:entry.size * entry.value_length]\\n', '            if entry.size in formats:\\n', \"                format_code = '>' + formats[entry.size] * entry.value_length\\n\", '                value = struct.unpack(format_code, raw_value)\\n', '                if len(value) == 1:\\n', '                    value = value[0]\\n', \"                items[key.decode('utf-8')] = value\\n\"]",
  "context": "chunks: List[LeafType], first: int) -> bytes:\n    index = first\n    out = []\n    while index < 65535:\n        try:"
 },
 "264": {
  "name": "out",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "127",
  "column": "4",
  "slicing": "['    out = []\\n', '            out.append(c.data)\\n', \"    return b''.join(out)\\n\"]",
  "context": "ype], first: int) -> bytes:\n    index = first\n    out = []\n    while index < 65535:\n        try:\n            "
 },
 "265": {
  "name": "c",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "130",
  "column": "12",
  "slicing": "['    header = uint64(enum=constants.ZapType)\\n', '    data = bytestring(length=23)\\n', '    padding = padding(length=2)\\n', '    data = bytestring(length=21)\\n', 'CHUNK_TYPES = {\\n', 'def parse_chunk(chunk: Union[LeafChunk, BytesIO]) -> LeafType:\\n', '        ch = LeafChunk(chunk)\\n', '        ch = chunk\\n', '    return CHUNK_TYPES[ch.chunk_type](ch.data)\\n', '    reader = BytesIO(data)\\n', '    header = FatZAPHeader(reader)\\n', '    ret = OrderedDict()\\n', '    for i in range(header.num_leafs):\\n', '        i += 1\\n', '        reader.seek(8*2048*i)\\n', '        _leaf_hdr = LeafHeader(reader)\\n', '        hashes = reader.read(1 << header.ptr_info.shift)\\n', '        chunks = []\\n', '                c = parse_chunk(reader)\\n', '                chunks.append(c)\\n', '        ret.update(reconstruct_data(chunks))\\n', '    return ret\\n', 'def read_linked(chunks: List[LeafType], first: int) -> bytes:\\n', '    index = first\\n', '    out = []\\n', '    while index < 65535:\\n', '            c = chunks[index]\\n', '            out.append(c.data)\\n', '            index = c.next\\n', \"    return b''.join(out)\\n\", 'formats = {\\n', '    for entry in chunks:\\n', '        if isinstance(entry, LeafEntry):\\n', '            key = read_linked(chunks, entry.name_chunk)[:entry.name_length-1]\\n', '            raw_value = read_linked(chunks, entry.value_chunk)[:entry.size * entry.value_length]\\n', '            if entry.size in formats:\\n', \"                format_code = '>' + formats[entry.size] * entry.value_length\\n\", '                value = struct.unpack(format_code, raw_value)\\n', '                if len(value) == 1:\\n', '                    value = value[0]\\n', \"                items[key.decode('utf-8')] = value\\n\"]",
  "context": "    while index < 65535:\n        try:\n            c = chunks[index]\n            out.append(c.data)\n            index ="
 },
 "266": {
  "name": "formats",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "138",
  "column": "0",
  "slicing": "['    header = uint64(enum=constants.ZapType)\\n', '    data = bytestring(length=23)\\n', '    padding = padding(length=2)\\n', '    data = bytestring(length=21)\\n', 'CHUNK_TYPES = {\\n', 'def parse_chunk(chunk: Union[LeafChunk, BytesIO]) -> LeafType:\\n', '        ch = LeafChunk(chunk)\\n', '        ch = chunk\\n', '    return CHUNK_TYPES[ch.chunk_type](ch.data)\\n', '    reader = BytesIO(data)\\n', '    header = FatZAPHeader(reader)\\n', '    ret = OrderedDict()\\n', '    for i in range(header.num_leafs):\\n', '        i += 1\\n', '        reader.seek(8*2048*i)\\n', '        _leaf_hdr = LeafHeader(reader)\\n', '        hashes = reader.read(1 << header.ptr_info.shift)\\n', '        chunks = []\\n', '                c = parse_chunk(reader)\\n', '                chunks.append(c)\\n', '        ret.update(reconstruct_data(chunks))\\n', '    return ret\\n', 'def read_linked(chunks: List[LeafType], first: int) -> bytes:\\n', '    index = first\\n', '    out = []\\n', '    while index < 65535:\\n', '            c = chunks[index]\\n', '            out.append(c.data)\\n', '            index = c.next\\n', \"    return b''.join(out)\\n\", 'formats = {\\n', '    for entry in chunks:\\n', '        if isinstance(entry, LeafEntry):\\n', '            key = read_linked(chunks, entry.name_chunk)[:entry.name_length-1]\\n', '            raw_value = read_linked(chunks, entry.value_chunk)[:entry.size * entry.value_length]\\n', '            if entry.size in formats:\\n', \"                format_code = '>' + formats[entry.size] * entry.value_length\\n\", '                value = struct.unpack(format_code, raw_value)\\n', '                if len(value) == 1:\\n', '                    value = value[0]\\n', \"                items[key.decode('utf-8')] = value\\n\"]",
  "context": "ion:\n            raise\n    return b''.join(out)\n\n\nformats = {\n    1: 'B',\n    2: 'H',\n    4: 'I',\n    8: 'Q',\n}\n"
 },
 "267": {
  "name": "chunks",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "146",
  "column": "21",
  "slicing": "['def reconstruct_data(chunks: List[LeafType]) -> Dict[str, Any]:\\n']",
  "context": "\n    4: 'I',\n    8: 'Q',\n}\n\n\ndef reconstruct_data(chunks: List[LeafType]) -> Dict[str, Any]:\n    items = OrderedDict()\n    for entry in chunks:"
 },
 "268": {
  "name": "items",
  "type": "collections.OrderedDict",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "147",
  "column": "4",
  "slicing": "['    header = uint64(enum=constants.ZapType)\\n', '    data = bytestring(length=23)\\n', '    padding = padding(length=2)\\n', '    data = bytestring(length=21)\\n', 'CHUNK_TYPES = {\\n', 'def parse_chunk(chunk: Union[LeafChunk, BytesIO]) -> LeafType:\\n', '        ch = LeafChunk(chunk)\\n', '        ch = chunk\\n', '    return CHUNK_TYPES[ch.chunk_type](ch.data)\\n', '    reader = BytesIO(data)\\n', '    header = FatZAPHeader(reader)\\n', '    ret = OrderedDict()\\n', '    for i in range(header.num_leafs):\\n', '        i += 1\\n', '        reader.seek(8*2048*i)\\n', '        _leaf_hdr = LeafHeader(reader)\\n', '        hashes = reader.read(1 << header.ptr_info.shift)\\n', '        chunks = []\\n', '                c = parse_chunk(reader)\\n', '                chunks.append(c)\\n', '        ret.update(reconstruct_data(chunks))\\n', '    return ret\\n', 'def read_linked(chunks: List[LeafType], first: int) -> bytes:\\n', '    index = first\\n', '    out = []\\n', '    while index < 65535:\\n', '            c = chunks[index]\\n', '            out.append(c.data)\\n', '            index = c.next\\n', \"    return b''.join(out)\\n\", 'formats = {\\n', '    items = OrderedDict()\\n', '    for entry in chunks:\\n', '        if isinstance(entry, LeafEntry):\\n', '            key = read_linked(chunks, entry.name_chunk)[:entry.name_length-1]\\n', '            raw_value = read_linked(chunks, entry.value_chunk)[:entry.size * entry.value_length]\\n', '            if entry.size in formats:\\n', \"                format_code = '>' + formats[entry.size] * entry.value_length\\n\", '                value = struct.unpack(format_code, raw_value)\\n', '                if len(value) == 1:\\n', '                    value = value[0]\\n', \"                items[key.decode('utf-8')] = value\\n\", '    return items\\n']",
  "context": "ta(chunks: List[LeafType]) -> Dict[str, Any]:\n    items = OrderedDict()\n    for entry in chunks:\n        if isinstance(ent"
 },
 "269": {
  "name": "key",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "151",
  "column": "12",
  "slicing": "['    header = uint64(enum=constants.ZapType)\\n', '    data = bytestring(length=23)\\n', '    padding = padding(length=2)\\n', '    data = bytestring(length=21)\\n', 'CHUNK_TYPES = {\\n', 'def parse_chunk(chunk: Union[LeafChunk, BytesIO]) -> LeafType:\\n', '        ch = LeafChunk(chunk)\\n', '        ch = chunk\\n', '    return CHUNK_TYPES[ch.chunk_type](ch.data)\\n', '    reader = BytesIO(data)\\n', '    header = FatZAPHeader(reader)\\n', '    ret = OrderedDict()\\n', '    for i in range(header.num_leafs):\\n', '        i += 1\\n', '        reader.seek(8*2048*i)\\n', '        _leaf_hdr = LeafHeader(reader)\\n', '        hashes = reader.read(1 << header.ptr_info.shift)\\n', '        chunks = []\\n', '                c = parse_chunk(reader)\\n', '                chunks.append(c)\\n', '        ret.update(reconstruct_data(chunks))\\n', '    return ret\\n', 'def read_linked(chunks: List[LeafType], first: int) -> bytes:\\n', '    index = first\\n', '    out = []\\n', '    while index < 65535:\\n', '            c = chunks[index]\\n', '            out.append(c.data)\\n', '            index = c.next\\n', \"    return b''.join(out)\\n\", 'formats = {\\n', '    for entry in chunks:\\n', '        if isinstance(entry, LeafEntry):\\n', '            key = read_linked(chunks, entry.name_chunk)[:entry.name_length-1]\\n', '            raw_value = read_linked(chunks, entry.value_chunk)[:entry.size * entry.value_length]\\n', '            if entry.size in formats:\\n', \"                format_code = '>' + formats[entry.size] * entry.value_length\\n\", '                value = struct.unpack(format_code, raw_value)\\n', '                if len(value) == 1:\\n', '                    value = value[0]\\n', \"                items[key.decode('utf-8')] = value\\n\"]",
  "context": "he length includes the NUL terminator\n            key = read_linked(chunks, entry.name_chunk)[:entry.name_length-1]\n            raw_value = read_linked(chunks, entry."
 },
 "270": {
  "name": "raw_value",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "152",
  "column": "12",
  "slicing": "['    header = uint64(enum=constants.ZapType)\\n', '    data = bytestring(length=23)\\n', '    padding = padding(length=2)\\n', '    data = bytestring(length=21)\\n', 'CHUNK_TYPES = {\\n', 'def parse_chunk(chunk: Union[LeafChunk, BytesIO]) -> LeafType:\\n', '        ch = LeafChunk(chunk)\\n', '        ch = chunk\\n', '    return CHUNK_TYPES[ch.chunk_type](ch.data)\\n', '    reader = BytesIO(data)\\n', '    header = FatZAPHeader(reader)\\n', '    ret = OrderedDict()\\n', '    for i in range(header.num_leafs):\\n', '        i += 1\\n', '        reader.seek(8*2048*i)\\n', '        _leaf_hdr = LeafHeader(reader)\\n', '        hashes = reader.read(1 << header.ptr_info.shift)\\n', '        chunks = []\\n', '                c = parse_chunk(reader)\\n', '                chunks.append(c)\\n', '        ret.update(reconstruct_data(chunks))\\n', '    return ret\\n', 'def read_linked(chunks: List[LeafType], first: int) -> bytes:\\n', '    index = first\\n', '    out = []\\n', '    while index < 65535:\\n', '            c = chunks[index]\\n', '            out.append(c.data)\\n', '            index = c.next\\n', \"    return b''.join(out)\\n\", 'formats = {\\n', '    for entry in chunks:\\n', '        if isinstance(entry, LeafEntry):\\n', '            key = read_linked(chunks, entry.name_chunk)[:entry.name_length-1]\\n', '            raw_value = read_linked(chunks, entry.value_chunk)[:entry.size * entry.value_length]\\n', '            if entry.size in formats:\\n', \"                format_code = '>' + formats[entry.size] * entry.value_length\\n\", '                value = struct.unpack(format_code, raw_value)\\n', '                if len(value) == 1:\\n', '                    value = value[0]\\n', \"                items[key.decode('utf-8')] = value\\n\"]",
  "context": "try.name_chunk)[:entry.name_length-1]\n            raw_value = read_linked(chunks, entry.value_chunk)[:entry.size * entry.value_length]\n            if entry.size in formats:\n            "
 },
 "271": {
  "name": "value",
  "type": "()",
  "class": "imported",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "155",
  "column": "16",
  "slicing": "['    header = uint64(enum=constants.ZapType)\\n', '    data = bytestring(length=23)\\n', '    padding = padding(length=2)\\n', '    data = bytestring(length=21)\\n', 'CHUNK_TYPES = {\\n', 'def parse_chunk(chunk: Union[LeafChunk, BytesIO]) -> LeafType:\\n', '        ch = LeafChunk(chunk)\\n', '        ch = chunk\\n', '    return CHUNK_TYPES[ch.chunk_type](ch.data)\\n', '    reader = BytesIO(data)\\n', '    header = FatZAPHeader(reader)\\n', '    ret = OrderedDict()\\n', '    for i in range(header.num_leafs):\\n', '        i += 1\\n', '        reader.seek(8*2048*i)\\n', '        _leaf_hdr = LeafHeader(reader)\\n', '        hashes = reader.read(1 << header.ptr_info.shift)\\n', '        chunks = []\\n', '                c = parse_chunk(reader)\\n', '                chunks.append(c)\\n', '        ret.update(reconstruct_data(chunks))\\n', '    return ret\\n', 'def read_linked(chunks: List[LeafType], first: int) -> bytes:\\n', '    index = first\\n', '    out = []\\n', '    while index < 65535:\\n', '            c = chunks[index]\\n', '            out.append(c.data)\\n', '            index = c.next\\n', \"    return b''.join(out)\\n\", 'formats = {\\n', '    for entry in chunks:\\n', '        if isinstance(entry, LeafEntry):\\n', '            key = read_linked(chunks, entry.name_chunk)[:entry.name_length-1]\\n', '            raw_value = read_linked(chunks, entry.value_chunk)[:entry.size * entry.value_length]\\n', '            if entry.size in formats:\\n', \"                format_code = '>' + formats[entry.size] * entry.value_length\\n\", '                value = struct.unpack(format_code, raw_value)\\n', '                if len(value) == 1:\\n', '                    value = value[0]\\n', \"                items[key.decode('utf-8')] = value\\n\"]",
  "context": "[entry.size] * entry.value_length\n                value = struct.unpack(format_code, raw_value)\n                if len(value) == 1:\n              "
 },
 "272": {
  "name": "value",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/fatzap.py",
  "lineno": "157",
  "column": "20",
  "slicing": "['    header = uint64(enum=constants.ZapType)\\n', '    data = bytestring(length=23)\\n', '    padding = padding(length=2)\\n', '    data = bytestring(length=21)\\n', 'CHUNK_TYPES = {\\n', 'def parse_chunk(chunk: Union[LeafChunk, BytesIO]) -> LeafType:\\n', '        ch = LeafChunk(chunk)\\n', '        ch = chunk\\n', '    return CHUNK_TYPES[ch.chunk_type](ch.data)\\n', '    reader = BytesIO(data)\\n', '    header = FatZAPHeader(reader)\\n', '    ret = OrderedDict()\\n', '    for i in range(header.num_leafs):\\n', '        i += 1\\n', '        reader.seek(8*2048*i)\\n', '        _leaf_hdr = LeafHeader(reader)\\n', '        hashes = reader.read(1 << header.ptr_info.shift)\\n', '        chunks = []\\n', '                c = parse_chunk(reader)\\n', '                chunks.append(c)\\n', '        ret.update(reconstruct_data(chunks))\\n', '    return ret\\n', 'def read_linked(chunks: List[LeafType], first: int) -> bytes:\\n', '    index = first\\n', '    out = []\\n', '    while index < 65535:\\n', '            c = chunks[index]\\n', '            out.append(c.data)\\n', '            index = c.next\\n', \"    return b''.join(out)\\n\", 'formats = {\\n', '    for entry in chunks:\\n', '        if isinstance(entry, LeafEntry):\\n', '            key = read_linked(chunks, entry.name_chunk)[:entry.name_length-1]\\n', '            raw_value = read_linked(chunks, entry.value_chunk)[:entry.size * entry.value_length]\\n', '            if entry.size in formats:\\n', \"                format_code = '>' + formats[entry.size] * entry.value_length\\n\", '                value = struct.unpack(format_code, raw_value)\\n', '                if len(value) == 1:\\n', '                    value = value[0]\\n', \"                items[key.decode('utf-8')] = value\\n\"]",
  "context": "          if len(value) == 1:\n                    value = value[0]\n                items[key.decode('utf-8')] = value"
 },
 "273": {
  "name": "block_type",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/zap.py",
  "lineno": "14",
  "column": "4",
  "slicing": "['    block_type = uint64(enum=ZapType)\\n']",
  "context": "ZAPHeader(Struct):\n    __ENDIAN__ = 'little'\n\n    block_type = uint64(enum=ZapType)\n    salt = uint64()\n    flags = uint64()\n    _pad "
 },
 "274": {
  "name": "salt",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/zap.py",
  "lineno": "15",
  "column": "4",
  "slicing": "['    salt = uint64()\\n']",
  "context": "ittle'\n\n    block_type = uint64(enum=ZapType)\n    salt = uint64()\n    flags = uint64()\n    _pad = padding(length=5 *"
 },
 "275": {
  "name": "flags",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/zap.py",
  "lineno": "16",
  "column": "4",
  "slicing": "['    flags = uint64()\\n']",
  "context": "pe = uint64(enum=ZapType)\n    salt = uint64()\n    flags = uint64()\n    _pad = padding(length=5 * 8)\n\n\nclass MicroZAPC"
 },
 "276": {
  "name": "_pad",
  "type": "pyndata.padding",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/zap.py",
  "lineno": "17",
  "column": "4",
  "slicing": "['    _pad = padding(length=5 * 8)\\n']",
  "context": "ype)\n    salt = uint64()\n    flags = uint64()\n    _pad = padding(length=5 * 8)\n\n\nclass MicroZAPCommon(Struct):\n    __ENDIAN__ = '"
 },
 "277": {
  "name": "_pad",
  "type": "pyndata.uint16",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/zap.py",
  "lineno": "23",
  "column": "4",
  "slicing": "['    _pad = uint16()\\n']",
  "context": "ZAPCommon(Struct):\n    __ENDIAN__ = 'little'\n\n    _pad = uint16()\n    collision = uint32()\n    name = nullstring(pad"
 },
 "278": {
  "name": "collision",
  "type": "pyndata.uint32",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/zap.py",
  "lineno": "24",
  "column": "4",
  "slicing": "['    collision = uint32()\\n']",
  "context": "   __ENDIAN__ = 'little'\n\n    _pad = uint16()\n    collision = uint32()\n    name = nullstring(padded=True, max_length=50)\n"
 },
 "279": {
  "name": "name",
  "type": "pyndata.nullstring",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/zap.py",
  "lineno": "25",
  "column": "4",
  "slicing": "['    name = nullstring(padded=True, max_length=50)\\n']",
  "context": "\n    _pad = uint16()\n    collision = uint32()\n    name = nullstring(padded=True, max_length=50)\n\n\nclass MicroZAP(Struct):\n    __ENDIAN__ = 'little"
 },
 "280": {
  "name": "value",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/zap.py",
  "lineno": "31",
  "column": "4",
  "slicing": "['    value = uint64()\\n']",
  "context": " MicroZAP(Struct):\n    __ENDIAN__ = 'little'\n\n    value = uint64()\n    hdr = MicroZAPCommon()\n\n\nclass SARegistrationM"
 },
 "281": {
  "name": "hdr",
  "type": "MicroZAPCommon",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/zap.py",
  "lineno": "32",
  "column": "4",
  "slicing": "['    hdr = MicroZAPCommon()\\n']",
  "context": "  __ENDIAN__ = 'little'\n\n    value = uint64()\n    hdr = MicroZAPCommon()\n\n\nclass SARegistrationMicroZAP(Struct):\n    __ENDI"
 },
 "282": {
  "name": "_value",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/zap.py",
  "lineno": "38",
  "column": "4",
  "slicing": "['    _value = uint64()\\n', '    attr_num = BitField(_value, 8, 0)\\n', '    byteswap = BitField(_value, 8, 16)\\n', '    length = BitField(_value, 16, 24)\\n']",
  "context": "nMicroZAP(Struct):\n    __ENDIAN__ = 'little'\n\n    _value = uint64()\n    attr_num = BitField(_value, 8, 0)\n    byteswap"
 },
 "283": {
  "name": "attr_num",
  "type": "pyndata.BitField",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/zap.py",
  "lineno": "39",
  "column": "4",
  "slicing": "['    _value = uint64()\\n', '    attr_num = BitField(_value, 8, 0)\\n', '    byteswap = BitField(_value, 8, 16)\\n', '    length = BitField(_value, 16, 24)\\n']",
  "context": " __ENDIAN__ = 'little'\n\n    _value = uint64()\n    attr_num = BitField(_value, 8, 0)\n    byteswap = BitField(_value, 8, 16)\n    length "
 },
 "284": {
  "name": "byteswap",
  "type": "pyndata.BitField",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/zap.py",
  "lineno": "40",
  "column": "4",
  "slicing": "['    _value = uint64()\\n', '    attr_num = BitField(_value, 8, 0)\\n', '    byteswap = BitField(_value, 8, 16)\\n', '    length = BitField(_value, 16, 24)\\n']",
  "context": "int64()\n    attr_num = BitField(_value, 8, 0)\n    byteswap = BitField(_value, 8, 16)\n    length = BitField(_value, 16, 24)\n    hdr = Mi"
 },
 "285": {
  "name": "length",
  "type": "pyndata.BitField",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/zap.py",
  "lineno": "41",
  "column": "4",
  "slicing": "['    _value = uint64()\\n', '    attr_num = BitField(_value, 8, 0)\\n', '    byteswap = BitField(_value, 8, 16)\\n', '    length = BitField(_value, 16, 24)\\n']",
  "context": " 8, 0)\n    byteswap = BitField(_value, 8, 16)\n    length = BitField(_value, 16, 24)\n    hdr = MicroZAPCommon()\n"
 },
 "286": {
  "name": "hdr",
  "type": "MicroZAPCommon",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/zap.py",
  "lineno": "42",
  "column": "4",
  "slicing": "['    _value = uint64()\\n', '    attr_num = BitField(_value, 8, 0)\\n', '    byteswap = BitField(_value, 8, 16)\\n', '    length = BitField(_value, 16, 24)\\n', '    hdr = MicroZAPCommon()\\n']",
  "context": " 8, 16)\n    length = BitField(_value, 16, 24)\n    hdr = MicroZAPCommon()\n"
 },
 "287": {
  "name": "_first",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "20",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n']",
  "context": "class dva(Struct):\n    __ENDIAN__ = 'little'\n\n    _first = uint64()\n    vdev = BitField(_first, 32, 32)\n    grid = Bit"
 },
 "288": {
  "name": "vdev",
  "type": "pyndata.BitField",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "21",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n']",
  "context": " __ENDIAN__ = 'little'\n\n    _first = uint64()\n    vdev = BitField(_first, 32, 32)\n    grid = BitField(_first, 8, 23)\n    asize = Bit"
 },
 "289": {
  "name": "grid",
  "type": "pyndata.BitField",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "22",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n']",
  "context": " uint64()\n    vdev = BitField(_first, 32, 32)\n    grid = BitField(_first, 8, 23)\n    asize = BitField(_first, 24, 0)\n    _offset = "
 },
 "290": {
  "name": "asize",
  "type": "pyndata.BitField",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "23",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n']",
  "context": "t, 32, 32)\n    grid = BitField(_first, 8, 23)\n    asize = BitField(_first, 24, 0)\n    _offset = uint64()\n    gang = BitField(_offset"
 },
 "291": {
  "name": "_offset",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "24",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n']",
  "context": "t, 8, 23)\n    asize = BitField(_first, 24, 0)\n    _offset = uint64()\n    gang = BitField(_offset, 1, 63)\n    offset = B"
 },
 "292": {
  "name": "gang",
  "type": "pyndata.BitField",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "25",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n']",
  "context": "itField(_first, 24, 0)\n    _offset = uint64()\n    gang = BitField(_offset, 1, 63)\n    offset = BitField(_offset, 63, 0)\n\n    def __r"
 },
 "293": {
  "name": "offset",
  "type": "pyndata.BitField",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "26",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n']",
  "context": " uint64()\n    gang = BitField(_offset, 1, 63)\n    offset = BitField(_offset, 63, 0)\n\n    def __repr__(self):\n        return '{}:{:X}:{"
 },
 "294": {
  "name": "dvas",
  "type": "pyndata.array",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "35",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    dvas = array(dva(), length=3)\\n']",
  "context": " Blockptr(Struct):\n    __ENDIAN__ = 'little'\n\n    dvas = array(dva(), length=3)\n    _prop = uint64()\n    logical_size = BitField(_"
 },
 "295": {
  "name": "_prop",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "36",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n']",
  "context": "= 'little'\n\n    dvas = array(dva(), length=3)\n    _prop = uint64()\n    logical_size = BitField(_prop, 16, 0)\n    phys"
 },
 "296": {
  "name": "logical_size",
  "type": "pyndata.BitField",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "37",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n']",
  "context": "= array(dva(), length=3)\n    _prop = uint64()\n    logical_size = BitField(_prop, 16, 0)\n    physical_size = BitField(_prop, 16, 16)\n    co"
 },
 "297": {
  "name": "physical_size",
  "type": "pyndata.BitField",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "38",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n']",
  "context": "4()\n    logical_size = BitField(_prop, 16, 0)\n    physical_size = BitField(_prop, 16, 16)\n    compression = BitField(_prop, 6, 32, enum=cons"
 },
 "298": {
  "name": "compression",
  "type": "pyndata.BitField",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "39",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n']",
  "context": ")\n    physical_size = BitField(_prop, 16, 16)\n    compression = BitField(_prop, 6, 32, enum=constants.Compression)\n    encryption = BitField(_prop, 1, 38)\n    embedd"
 },
 "299": {
  "name": "encryption",
  "type": "pyndata.BitField",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "40",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n']",
  "context": "eld(_prop, 6, 32, enum=constants.Compression)\n    encryption = BitField(_prop, 1, 38)\n    embedded = BitField(_prop, 1, 39)\n    checksum"
 },
 "300": {
  "name": "embedded",
  "type": "pyndata.BitField",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "41",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n']",
  "context": "sion)\n    encryption = BitField(_prop, 1, 38)\n    embedded = BitField(_prop, 1, 39)\n    checksum_type = BitField(_prop, 8, 40, enum=co"
 },
 "301": {
  "name": "checksum_type",
  "type": "pyndata.BitField",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "42",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n']",
  "context": " 1, 38)\n    embedded = BitField(_prop, 1, 39)\n    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\n    object_type = BitField(_prop, 8, 48, enum=cons"
 },
 "302": {
  "name": "object_type",
  "type": "pyndata.BitField",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "43",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n']",
  "context": "tField(_prop, 8, 40, enum=constants.Checksum)\n    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\n    level = BitField(_prop, 5, 56)\n    dedup = Bit"
 },
 "303": {
  "name": "level",
  "type": "pyndata.BitField",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "44",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n']",
  "context": "ield(_prop, 8, 48, enum=constants.ObjectType)\n    level = BitField(_prop, 5, 56)\n    dedup = BitField(_prop, 1, 62)\n    endian = Bi"
 },
 "304": {
  "name": "dedup",
  "type": "pyndata.BitField",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "45",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n']",
  "context": "bjectType)\n    level = BitField(_prop, 5, 56)\n    dedup = BitField(_prop, 1, 62)\n    endian = BitField(_prop, 1, 63)\n\n    pad = pad"
 },
 "305": {
  "name": "endian",
  "type": "pyndata.BitField",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "46",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n']",
  "context": "op, 5, 56)\n    dedup = BitField(_prop, 1, 62)\n    endian = BitField(_prop, 1, 63)\n\n    pad = padding(length=16)\n    phys_birth = uin"
 },
 "306": {
  "name": "pad",
  "type": "pyndata.padding",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "48",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '    pad = padding(length=16)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n']",
  "context": ", 1, 62)\n    endian = BitField(_prop, 1, 63)\n\n    pad = padding(length=16)\n    phys_birth = uint64()\n    birth = uint64()\n   "
 },
 "307": {
  "name": "phys_birth",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "49",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '    phys_birth = uint64()\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n']",
  "context": "d(_prop, 1, 63)\n\n    pad = padding(length=16)\n    phys_birth = uint64()\n    birth = uint64()\n    fill = uint64()\n    check"
 },
 "308": {
  "name": "birth",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "50",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '    birth = uint64()\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n']",
  "context": " padding(length=16)\n    phys_birth = uint64()\n    birth = uint64()\n    fill = uint64()\n    checksum = array(uint64(),"
 },
 "309": {
  "name": "fill",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "51",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '    fill = uint64()\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n']",
  "context": "   phys_birth = uint64()\n    birth = uint64()\n    fill = uint64()\n    checksum = array(uint64(), 4)\n\n    def to_embe"
 },
 "310": {
  "name": "checksum",
  "type": "pyndata.array",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "52",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '    checksum = array(uint64(), 4)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n']",
  "context": "64()\n    birth = uint64()\n    fill = uint64()\n    checksum = array(uint64(), 4)\n\n    def to_embedded(self):\n        raw_blkptr = s"
 },
 "311": {
  "name": "data1",
  "type": "pyndata.bytestring",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "62",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    data1 = bytestring(length=6*8)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n']",
  "context": "dBlockptr(Struct):\n    __ENDIAN__ = 'little'\n\n    data1 = bytestring(length=6*8)\n    _prop = uint64()\n    logical_size = BitField(_"
 },
 "312": {
  "name": "_prop",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "63",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n']",
  "context": " 'little'\n\n    data1 = bytestring(length=6*8)\n    _prop = uint64()\n    logical_size = BitField(_prop, 25)\n    physica"
 },
 "313": {
  "name": "logical_size",
  "type": "pyndata.BitField",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "64",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n']",
  "context": "= bytestring(length=6*8)\n    _prop = uint64()\n    logical_size = BitField(_prop, 25)\n    physical_size = BitField(_prop, 7)\n    compres"
 },
 "314": {
  "name": "physical_size",
  "type": "pyndata.BitField",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "65",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n']",
  "context": "nt64()\n    logical_size = BitField(_prop, 25)\n    physical_size = BitField(_prop, 7)\n    compression = BitField(_prop, 7)\n    embedded "
 },
 "315": {
  "name": "compression",
  "type": "pyndata.BitField",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "66",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n']",
  "context": "p, 25)\n    physical_size = BitField(_prop, 7)\n    compression = BitField(_prop, 7)\n    embedded = BitField(_prop, 1)\n    embedded_typ"
 },
 "316": {
  "name": "embedded",
  "type": "pyndata.BitField",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "67",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n']",
  "context": "prop, 7)\n    compression = BitField(_prop, 7)\n    embedded = BitField(_prop, 1)\n    embedded_type = BitField(_prop, 8)\n    type_ ="
 },
 "317": {
  "name": "embedded_type",
  "type": "pyndata.BitField",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "68",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n']",
  "context": "d(_prop, 7)\n    embedded = BitField(_prop, 1)\n    embedded_type = BitField(_prop, 8)\n    type_ = BitField(_prop, 8)\n    level = BitFiel"
 },
 "318": {
  "name": "type_",
  "type": "pyndata.BitField",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "69",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n']",
  "context": "op, 1)\n    embedded_type = BitField(_prop, 8)\n    type_ = BitField(_prop, 8)\n    level = BitField(_prop, 5)\n    encryption = Bi"
 },
 "319": {
  "name": "level",
  "type": "pyndata.BitField",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "70",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n']",
  "context": "ield(_prop, 8)\n    type_ = BitField(_prop, 8)\n    level = BitField(_prop, 5)\n    encryption = BitField(_prop, 1)\n    dedup = Bi"
 },
 "320": {
  "name": "encryption",
  "type": "pyndata.BitField",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "71",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n']",
  "context": "ield(_prop, 8)\n    level = BitField(_prop, 5)\n    encryption = BitField(_prop, 1)\n    dedup = BitField(_prop, 1)\n    endian = BitFie"
 },
 "321": {
  "name": "dedup",
  "type": "pyndata.BitField",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "72",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n']",
  "context": "_prop, 5)\n    encryption = BitField(_prop, 1)\n    dedup = BitField(_prop, 1)\n    endian = BitField(_prop, 1)\n    data2 = bytest"
 },
 "322": {
  "name": "endian",
  "type": "pyndata.BitField",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "73",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n']",
  "context": "ield(_prop, 1)\n    dedup = BitField(_prop, 1)\n    endian = BitField(_prop, 1)\n    data2 = bytestring(length=3*8)\n    birth = uin"
 },
 "323": {
  "name": "data2",
  "type": "pyndata.bytestring",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "74",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '    data2 = bytestring(length=3*8)\\n']",
  "context": "eld(_prop, 1)\n    endian = BitField(_prop, 1)\n    data2 = bytestring(length=3*8)\n    birth = uint64()\n    data3 = bytestring(length"
 },
 "324": {
  "name": "birth",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "75",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '    birth = uint64()\\n']",
  "context": "(_prop, 1)\n    data2 = bytestring(length=3*8)\n    birth = uint64()\n    data3 = bytestring(length=5*8)\n\n    @property\n"
 },
 "325": {
  "name": "data3",
  "type": "pyndata.bytestring",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "76",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '    data3 = bytestring(length=5*8)\\n']",
  "context": "= bytestring(length=3*8)\n    birth = uint64()\n    data3 = bytestring(length=5*8)\n\n    @property\n    def data(self):\n        data = "
 },
 "326": {
  "name": "data",
  "type": "pyndata.bytestring",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "80",
  "column": "8",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n']",
  "context": "h=5*8)\n\n    @property\n    def data(self):\n        data = self.data1 + self.data2 + self.data3\n        assert len(data) == 112\n        return dat"
 },
 "327": {
  "name": "blocks",
  "type": "pyndata.array",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "87",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    blocks = array(Blockptr(), length=3)\\n']",
  "context": "gBlock(Struct):\n    MAGIC = 0x210da7ab10c7a11\n    blocks = array(Blockptr(), length=3)\n    _pad = padding(length=88)\n    magic = uint64()"
 },
 "328": {
  "name": "_pad",
  "type": "pyndata.padding",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "88",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    _pad = padding(length=88)\\n']",
  "context": "7a11\n    blocks = array(Blockptr(), length=3)\n    _pad = padding(length=88)\n    magic = uint64()\n    checksum = array(uint64()"
 },
 "329": {
  "name": "magic",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "89",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    magic = uint64()\\n']",
  "context": "tr(), length=3)\n    _pad = padding(length=88)\n    magic = uint64()\n    checksum = array(uint64(), 4)\n\n\nclass Uberbloc"
 },
 "330": {
  "name": "checksum",
  "type": "pyndata.array",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "90",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    checksum = array(uint64(), 4)\\n']",
  "context": "pad = padding(length=88)\n    magic = uint64()\n    checksum = array(uint64(), 4)\n\n\nclass Uberblock(Struct):\n    __ENDIAN__ = 'littl"
 },
 "331": {
  "name": "magic",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "97",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    magic = uint64()\\n']",
  "context": "__ENDIAN__ = 'little'\n    MAGIC = 0x00bab10c\n\n    magic = uint64()\n    version = uint64()\n    txg = uint64()\n    guid"
 },
 "332": {
  "name": "version",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "98",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    version = uint64()\\n', '    if version in range(1, 15):\\n']",
  "context": "\n    MAGIC = 0x00bab10c\n\n    magic = uint64()\n    version = uint64()\n    txg = uint64()\n    guid_sum = uint64()\n    tim"
 },
 "333": {
  "name": "txg",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "99",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    txg = uint64()\\n']",
  "context": "\n\n    magic = uint64()\n    version = uint64()\n    txg = uint64()\n    guid_sum = uint64()\n    timestamp = uint64()\n "
 },
 "334": {
  "name": "guid_sum",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "100",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    guid_sum = uint64()\\n']",
  "context": "4()\n    version = uint64()\n    txg = uint64()\n    guid_sum = uint64()\n    timestamp = uint64()\n    root = Blockptr()\n   "
 },
 "335": {
  "name": "timestamp",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "101",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    timestamp = uint64()\\n']",
  "context": "()\n    txg = uint64()\n    guid_sum = uint64()\n    timestamp = uint64()\n    root = Blockptr()\n    software_version = uint6"
 },
 "336": {
  "name": "root",
  "type": "Blockptr",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "102",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    root = Blockptr()\\n']",
  "context": " guid_sum = uint64()\n    timestamp = uint64()\n    root = Blockptr()\n    software_version = uint64()\n\n    def valid(sel"
 },
 "337": {
  "name": "software_version",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "103",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    software_version = uint64()\\n']",
  "context": "   timestamp = uint64()\n    root = Blockptr()\n    software_version = uint64()\n\n    def valid(self):\n        if self.magic != sel"
 },
 "338": {
  "name": "node_type",
  "type": "pyndata.uint8",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "117",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    node_type = uint8(enum=constants.ObjectType)\\n']",
  "context": "ass DNode(Struct):\n    __ENDIAN__ = 'little'\n\n    node_type = uint8(enum=constants.ObjectType)\n    indirect_blockshift = uint8()\n    indirect_lev"
 },
 "339": {
  "name": "indirect_blockshift",
  "type": "pyndata.uint8",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "118",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    indirect_blockshift = uint8()\\n']",
  "context": " node_type = uint8(enum=constants.ObjectType)\n    indirect_blockshift = uint8()\n    indirect_levels = uint8()\n    num_blockptrs = "
 },
 "340": {
  "name": "indirect_levels",
  "type": "pyndata.uint8",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "119",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    indirect_levels = uint8()\\n']",
  "context": "ObjectType)\n    indirect_blockshift = uint8()\n    indirect_levels = uint8()\n    num_blockptrs = uint8()\n    bonustype = uint8("
 },
 "341": {
  "name": "num_blockptrs",
  "type": "pyndata.uint8",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "120",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n']",
  "context": "shift = uint8()\n    indirect_levels = uint8()\n    num_blockptrs = uint8()\n    bonustype = uint8(enum=constants.ObjectType)\n "
 },
 "342": {
  "name": "bonustype",
  "type": "pyndata.uint8",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "121",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    bonustype = uint8(enum=constants.ObjectType)\\n']",
  "context": "_levels = uint8()\n    num_blockptrs = uint8()\n    bonustype = uint8(enum=constants.ObjectType)\n    checksum_type = uint8(enum=constants.Checksum)"
 },
 "343": {
  "name": "checksum_type",
  "type": "pyndata.uint8",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "122",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    checksum_type = uint8(enum=constants.Checksum)\\n']",
  "context": " bonustype = uint8(enum=constants.ObjectType)\n    checksum_type = uint8(enum=constants.Checksum)\n    compression_type = uint8(enum=constants.Compre"
 },
 "344": {
  "name": "compression_type",
  "type": "pyndata.uint8",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "123",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    compression_type = uint8(enum=constants.Compression)\\n']",
  "context": "hecksum_type = uint8(enum=constants.Checksum)\n    compression_type = uint8(enum=constants.Compression)\n    _dnode_flags = uint8()  # TODO: dnode flag bit"
 },
 "345": {
  "name": "_dnode_flags",
  "type": "pyndata.uint8",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "124",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n']",
  "context": "sion_type = uint8(enum=constants.Compression)\n    _dnode_flags = uint8()  # TODO: dnode flag bitfields\n    used_bytes = BitField(_dnode_flags, 1, 0)\n    "
 },
 "346": {
  "name": "used_bytes",
  "type": "pyndata.BitField",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "125",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n']",
  "context": "flags = uint8()  # TODO: dnode flag bitfields\n    used_bytes = BitField(_dnode_flags, 1, 0)\n    userused = BitField(_dnode_flags, 1, 1)\n    sp"
 },
 "347": {
  "name": "userused",
  "type": "pyndata.BitField",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "126",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n']",
  "context": "    used_bytes = BitField(_dnode_flags, 1, 0)\n    userused = BitField(_dnode_flags, 1, 1)\n    spill_blkptr = BitField(_dnode_flags, 1, 3)\n  "
 },
 "348": {
  "name": "spill_blkptr",
  "type": "pyndata.BitField",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "127",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n']",
  "context": ")\n    userused = BitField(_dnode_flags, 1, 1)\n    spill_blkptr = BitField(_dnode_flags, 1, 3)\n    data_sectors = uint16()\n    bonuslen = uint16("
 },
 "349": {
  "name": "data_sectors",
  "type": "pyndata.uint16",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "128",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    data_sectors = uint16()\\n']",
  "context": "  spill_blkptr = BitField(_dnode_flags, 1, 3)\n    data_sectors = uint16()\n    bonuslen = uint16()\n    _pad = padding(length="
 },
 "350": {
  "name": "bonuslen",
  "type": "pyndata.uint16",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "129",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    bonuslen = uint16()\\n']",
  "context": "node_flags, 1, 3)\n    data_sectors = uint16()\n    bonuslen = uint16()\n    _pad = padding(length=4)\n    max_block_id = ui"
 },
 "351": {
  "name": "_pad",
  "type": "pyndata.padding",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "130",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    _pad = padding(length=4)\\n']",
  "context": "ta_sectors = uint16()\n    bonuslen = uint16()\n    _pad = padding(length=4)\n    max_block_id = uint64()\n    used = uint64()\n  "
 },
 "352": {
  "name": "max_block_id",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "131",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    max_block_id = uint64()\\n']",
  "context": "uslen = uint16()\n    _pad = padding(length=4)\n    max_block_id = uint64()\n    used = uint64()\n    _pad2 = padding(length=4 *"
 },
 "353": {
  "name": "used",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "132",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    used = uint64()\\n']",
  "context": "padding(length=4)\n    max_block_id = uint64()\n    used = uint64()\n    _pad2 = padding(length=4 * 8)\n    blkptr = arr"
 },
 "354": {
  "name": "_pad2",
  "type": "pyndata.padding",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "133",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    _pad2 = padding(length=4 * 8)\\n']",
  "context": "  max_block_id = uint64()\n    used = uint64()\n    _pad2 = padding(length=4 * 8)\n    blkptr = array(Blockptr(), length=num_blockptr"
 },
 "355": {
  "name": "blkptr",
  "type": "pyndata.array",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "134",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n']",
  "context": " = uint64()\n    _pad2 = padding(length=4 * 8)\n    blkptr = array(Blockptr(), length=num_blockptrs)\n\n    def bonus_length(self, o=None):\n        if se"
 },
 "356": {
  "name": "bonus",
  "type": "pyndata.bytestring",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "143",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', '    bonus = bytestring(length=bonus_length)  # TODO: finish\\n']",
  "context": "       else:\n            return self.bonuslen\n    bonus = bytestring(length=bonus_length)  # TODO: finish\n    _final_pad = padding(length=64)\n\n\nclass ZILHea"
 },
 "357": {
  "name": "_final_pad",
  "type": "pyndata.padding",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "144",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', '    _final_pad = padding(length=64)\\n']",
  "context": "testring(length=bonus_length)  # TODO: finish\n    _final_pad = padding(length=64)\n\n\nclass ZILHeader(Struct):\n    claim_txg = uint64("
 },
 "358": {
  "name": "claim_txg",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "148",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', '    claim_txg = uint64()\\n']",
  "context": "padding(length=64)\n\n\nclass ZILHeader(Struct):\n    claim_txg = uint64()\n    replay_seq = uint64()\n    log = Blockptr()\n   "
 },
 "359": {
  "name": "replay_seq",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "149",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', '    replay_seq = uint64()\\n']",
  "context": "s ZILHeader(Struct):\n    claim_txg = uint64()\n    replay_seq = uint64()\n    log = Blockptr()\n    claim_seq = uint64()\n    "
 },
 "360": {
  "name": "log",
  "type": "Blockptr",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "150",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', '    log = Blockptr()\\n']",
  "context": "laim_txg = uint64()\n    replay_seq = uint64()\n    log = Blockptr()\n    claim_seq = uint64()\n    _pad = padding(length"
 },
 "361": {
  "name": "claim_seq",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "151",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', '    claim_seq = uint64()\\n']",
  "context": "   replay_seq = uint64()\n    log = Blockptr()\n    claim_seq = uint64()\n    _pad = padding(length=5 * 8)\n\n\nclass ZILRecord"
 },
 "362": {
  "name": "_pad",
  "type": "pyndata.padding",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "152",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', '    _pad = padding(length=5 * 8)\\n']",
  "context": "    log = Blockptr()\n    claim_seq = uint64()\n    _pad = padding(length=5 * 8)\n\n\nclass ZILRecord(Struct):\n    tx_type = uint64(en"
 },
 "363": {
  "name": "tx_type",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "156",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', '    tx_type = uint64(enum=constants.ZILTypes)\\n']",
  "context": "ding(length=5 * 8)\n\n\nclass ZILRecord(Struct):\n    tx_type = uint64(enum=constants.ZILTypes)\n    length = uint64()\n    txg = uint64()\n    seq ="
 },
 "364": {
  "name": "length",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "157",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', '    length = uint64()\\n']",
  "context": "    tx_type = uint64(enum=constants.ZILTypes)\n    length = uint64()\n    txg = uint64()\n    seq = uint64()\n\n\nclass Objs"
 },
 "365": {
  "name": "txg",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "158",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', '    txg = uint64()\\n']",
  "context": "num=constants.ZILTypes)\n    length = uint64()\n    txg = uint64()\n    seq = uint64()\n\n\nclass ObjsetV1(Struct):\n    _"
 },
 "366": {
  "name": "seq",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "159",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', '    seq = uint64()\\n']",
  "context": "pes)\n    length = uint64()\n    txg = uint64()\n    seq = uint64()\n\n\nclass ObjsetV1(Struct):\n    __ENDIAN__ = 'little"
 },
 "367": {
  "name": "meta_dnode",
  "type": "DNode",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "165",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', '    meta_dnode = DNode()\\n']",
  "context": " ObjsetV1(Struct):\n    __ENDIAN__ = 'little'\n\n    meta_dnode = DNode()\n    zil_header = ZILHeader()\n    os_type = uint64("
 },
 "368": {
  "name": "zil_header",
  "type": "ZILHeader",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "166",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', '    zil_header = ZILHeader()\\n']",
  "context": "ENDIAN__ = 'little'\n\n    meta_dnode = DNode()\n    zil_header = ZILHeader()\n    os_type = uint64(enum=constants.ObjectSetType)"
 },
 "369": {
  "name": "os_type",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "167",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', '    os_type = uint64(enum=constants.ObjectSetType)\\n']",
  "context": "_dnode = DNode()\n    zil_header = ZILHeader()\n    os_type = uint64(enum=constants.ObjectSetType)\n\n\nObjset = ObjsetV1\n\n\nclass ObjsetV15(Struct):\n   "
 },
 "370": {
  "name": "Objset",
  "type": "ObjsetV1",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "170",
  "column": "0",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', 'Objset = ObjsetV1\\n']",
  "context": " os_type = uint64(enum=constants.ObjectSetType)\n\n\nObjset = ObjsetV1\n\n\nclass ObjsetV15(Struct):\n    __ENDIAN__ = 'littl"
 },
 "371": {
  "name": "meta_dnode",
  "type": "DNode",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "176",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', '    meta_dnode = DNode()\\n']",
  "context": "ObjsetV15(Struct):\n    __ENDIAN__ = 'little'\n\n    meta_dnode = DNode()\n    zil_header = ZILHeader()\n    os_type = uint64("
 },
 "372": {
  "name": "zil_header",
  "type": "ZILHeader",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "177",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', '    zil_header = ZILHeader()\\n']",
  "context": "ENDIAN__ = 'little'\n\n    meta_dnode = DNode()\n    zil_header = ZILHeader()\n    os_type = uint64(enum=constants.ObjectSetType)"
 },
 "373": {
  "name": "os_type",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "178",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', '    os_type = uint64(enum=constants.ObjectSetType)\\n']",
  "context": "_dnode = DNode()\n    zil_header = ZILHeader()\n    os_type = uint64(enum=constants.ObjectSetType)\n    os_flags = uint64()  # TODO: flag values\n    _"
 },
 "374": {
  "name": "os_flags",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "179",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', '    os_flags = uint64()  # TODO: flag values\\n']",
  "context": "s_type = uint64(enum=constants.ObjectSetType)\n    os_flags = uint64()  # TODO: flag values\n    _pad = padding(length=112)\n    userused = DNod"
 },
 "375": {
  "name": "_pad",
  "type": "pyndata.padding",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "180",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', '    _pad = padding(length=112)\\n']",
  "context": "\n    os_flags = uint64()  # TODO: flag values\n    _pad = padding(length=112)\n    userused = DNode()\n    groupused = DNode()\n\n\nO"
 },
 "376": {
  "name": "userused",
  "type": "DNode",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "181",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', '    userused = DNode()\\n']",
  "context": "O: flag values\n    _pad = padding(length=112)\n    userused = DNode()\n    groupused = DNode()\n\n\nObjectsetTypes = Union[T"
 },
 "377": {
  "name": "groupused",
  "type": "DNode",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "182",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', '    groupused = DNode()\\n']",
  "context": " = padding(length=112)\n    userused = DNode()\n    groupused = DNode()\n\n\nObjectsetTypes = Union[Type[ObjsetV1], Type[Objs"
 },
 "378": {
  "name": "ObjectsetTypes",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "185",
  "column": "0",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', 'ObjectsetTypes = Union[Type[ObjsetV1], Type[ObjsetV15]]\\n', 'def Objset_for(version) -> ObjectsetTypes:\\n']",
  "context": "\n    userused = DNode()\n    groupused = DNode()\n\n\nObjectsetTypes = Union[Type[ObjsetV1], Type[ObjsetV15]]\nObjectsets = Union[ObjsetV1, ObjsetV15]\n\n\ndef Objs"
 },
 "379": {
  "name": "Objectsets",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "186",
  "column": "0",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', 'Objectsets = Union[ObjsetV1, ObjsetV15]\\n']",
  "context": "setTypes = Union[Type[ObjsetV1], Type[ObjsetV15]]\nObjectsets = Union[ObjsetV1, ObjsetV15]\n\n\ndef Objset_for(version) -> ObjectsetTypes:\n    i"
 },
 "380": {
  "name": "indirect_cache",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "196",
  "column": "0",
  "slicing": "['indirect_cache = {}\\n', '    if size not in indirect_cache:\\n', '        indirect_cache[size] = IndirectBlock\\n', '    return indirect_cache[size]\\n']",
  "context": "urn ObjsetV1\n    else:\n        return ObjsetV15\n\n\nindirect_cache = {}\n\n\ndef indirect(size=None, shift=None):\n    size = "
 },
 "381": {
  "name": "size",
  "type": "bool",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "200",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    version = uint64()\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', 'ObjectsetTypes = Union[Type[ObjsetV1], Type[ObjsetV15]]\\n', 'def Objset_for(version) -> ObjectsetTypes:\\n', '    if version in range(1, 15):\\n', 'indirect_cache = {}\\n', '    size = (size * 512) or (1 << shift)\\n', '    count = int(size / 128)\\n', '    if size not in indirect_cache:\\n', '            blocks = array(Blockptr(), length=count)\\n', \"        IndirectBlock.__name__ = 'Indirect' + str(size)\\n\", '        indirect_cache[size] = IndirectBlock\\n', '    return indirect_cache[size]\\n']",
  "context": "e = {}\n\n\ndef indirect(size=None, shift=None):\n    size = (size * 512) or (1 << shift)\n    count = int(size / 128)\n\n    if size not in in"
 },
 "382": {
  "name": "count",
  "type": "int",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "201",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    version = uint64()\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', 'ObjectsetTypes = Union[Type[ObjsetV1], Type[ObjsetV15]]\\n', 'def Objset_for(version) -> ObjectsetTypes:\\n', '    if version in range(1, 15):\\n', 'indirect_cache = {}\\n', '    size = (size * 512) or (1 << shift)\\n', '    count = int(size / 128)\\n', '    if size not in indirect_cache:\\n', '            blocks = array(Blockptr(), length=count)\\n', \"        IndirectBlock.__name__ = 'Indirect' + str(size)\\n\", '        indirect_cache[size] = IndirectBlock\\n', '    return indirect_cache[size]\\n']",
  "context": "one):\n    size = (size * 512) or (1 << shift)\n    count = int(size / 128)\n\n    if size not in indirect_cache:\n\n        class"
 },
 "383": {
  "name": "blocks",
  "type": "pyndata.array",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "207",
  "column": "12",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    version = uint64()\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', 'ObjectsetTypes = Union[Type[ObjsetV1], Type[ObjsetV15]]\\n', 'def Objset_for(version) -> ObjectsetTypes:\\n', '    if version in range(1, 15):\\n', 'indirect_cache = {}\\n', '    size = (size * 512) or (1 << shift)\\n', '    count = int(size / 128)\\n', '    if size not in indirect_cache:\\n', '            blocks = array(Blockptr(), length=count)\\n', \"        IndirectBlock.__name__ = 'Indirect' + str(size)\\n\", '        indirect_cache[size] = IndirectBlock\\n', '    return indirect_cache[size]\\n']",
  "context": "t):\n            __ENDIAN__ = 'little'\n            blocks = array(Blockptr(), length=count)\n\n        IndirectBlock.__name__ = 'Indirect' + str"
 },
 "384": {
  "name": "creation_time",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "219",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    version = uint64()\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', 'ObjectsetTypes = Union[Type[ObjsetV1], Type[ObjsetV15]]\\n', 'def Objset_for(version) -> ObjectsetTypes:\\n', '    if version in range(1, 15):\\n', 'indirect_cache = {}\\n', '    size = (size * 512) or (1 << shift)\\n', '    count = int(size / 128)\\n', '    if size not in indirect_cache:\\n', '            blocks = array(Blockptr(), length=count)\\n', \"        IndirectBlock.__name__ = 'Indirect' + str(size)\\n\", '        indirect_cache[size] = IndirectBlock\\n', '    return indirect_cache[size]\\n', '    creation_time = uint64()\\n']",
  "context": "ss DSLDir(Struct):\n    __ENDIAN__ = 'little'\n\n    creation_time = uint64()\n    head_dataset = uint64()\n    parent = uint64()\n"
 },
 "385": {
  "name": "head_dataset",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "220",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    version = uint64()\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', 'ObjectsetTypes = Union[Type[ObjsetV1], Type[ObjsetV15]]\\n', 'def Objset_for(version) -> ObjectsetTypes:\\n', '    if version in range(1, 15):\\n', 'indirect_cache = {}\\n', '    size = (size * 512) or (1 << shift)\\n', '    count = int(size / 128)\\n', '    if size not in indirect_cache:\\n', '            blocks = array(Blockptr(), length=count)\\n', \"        IndirectBlock.__name__ = 'Indirect' + str(size)\\n\", '        indirect_cache[size] = IndirectBlock\\n', '    return indirect_cache[size]\\n', '    head_dataset = uint64()\\n']",
  "context": "AN__ = 'little'\n\n    creation_time = uint64()\n    head_dataset = uint64()\n    parent = uint64()\n    clone_parent = uint64()\n"
 },
 "386": {
  "name": "parent",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "221",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    version = uint64()\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', 'ObjectsetTypes = Union[Type[ObjsetV1], Type[ObjsetV15]]\\n', 'def Objset_for(version) -> ObjectsetTypes:\\n', '    if version in range(1, 15):\\n', 'indirect_cache = {}\\n', '    size = (size * 512) or (1 << shift)\\n', '    count = int(size / 128)\\n', '    if size not in indirect_cache:\\n', '            blocks = array(Blockptr(), length=count)\\n', \"        IndirectBlock.__name__ = 'Indirect' + str(size)\\n\", '        indirect_cache[size] = IndirectBlock\\n', '    return indirect_cache[size]\\n', '    parent = uint64()\\n']",
  "context": "n_time = uint64()\n    head_dataset = uint64()\n    parent = uint64()\n    clone_parent = uint64()\n    child_dir_zap = ui"
 },
 "387": {
  "name": "clone_parent",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "222",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    version = uint64()\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', 'ObjectsetTypes = Union[Type[ObjsetV1], Type[ObjsetV15]]\\n', 'def Objset_for(version) -> ObjectsetTypes:\\n', '    if version in range(1, 15):\\n', 'indirect_cache = {}\\n', '    size = (size * 512) or (1 << shift)\\n', '    count = int(size / 128)\\n', '    if size not in indirect_cache:\\n', '            blocks = array(Blockptr(), length=count)\\n', \"        IndirectBlock.__name__ = 'Indirect' + str(size)\\n\", '        indirect_cache[size] = IndirectBlock\\n', '    return indirect_cache[size]\\n', '    clone_parent = uint64()\\n']",
  "context": "head_dataset = uint64()\n    parent = uint64()\n    clone_parent = uint64()\n    child_dir_zap = uint64()\n    used_bytes = uint"
 },
 "388": {
  "name": "child_dir_zap",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "223",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    version = uint64()\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', 'ObjectsetTypes = Union[Type[ObjsetV1], Type[ObjsetV15]]\\n', 'def Objset_for(version) -> ObjectsetTypes:\\n', '    if version in range(1, 15):\\n', 'indirect_cache = {}\\n', '    size = (size * 512) or (1 << shift)\\n', '    count = int(size / 128)\\n', '    if size not in indirect_cache:\\n', '            blocks = array(Blockptr(), length=count)\\n', \"        IndirectBlock.__name__ = 'Indirect' + str(size)\\n\", '        indirect_cache[size] = IndirectBlock\\n', '    return indirect_cache[size]\\n', '    child_dir_zap = uint64()\\n']",
  "context": "parent = uint64()\n    clone_parent = uint64()\n    child_dir_zap = uint64()\n    used_bytes = uint64()\n    compressed_bytes = u"
 },
 "389": {
  "name": "used_bytes",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "224",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    version = uint64()\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', 'ObjectsetTypes = Union[Type[ObjsetV1], Type[ObjsetV15]]\\n', 'def Objset_for(version) -> ObjectsetTypes:\\n', '    if version in range(1, 15):\\n', 'indirect_cache = {}\\n', '    size = (size * 512) or (1 << shift)\\n', '    count = int(size / 128)\\n', '    if size not in indirect_cache:\\n', '            blocks = array(Blockptr(), length=count)\\n', \"        IndirectBlock.__name__ = 'Indirect' + str(size)\\n\", '        indirect_cache[size] = IndirectBlock\\n', '    return indirect_cache[size]\\n', '    used_bytes = uint64()\\n']",
  "context": "arent = uint64()\n    child_dir_zap = uint64()\n    used_bytes = uint64()\n    compressed_bytes = uint64()\n    uncompressed_b"
 },
 "390": {
  "name": "compressed_bytes",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "225",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    version = uint64()\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', 'ObjectsetTypes = Union[Type[ObjsetV1], Type[ObjsetV15]]\\n', 'def Objset_for(version) -> ObjectsetTypes:\\n', '    if version in range(1, 15):\\n', 'indirect_cache = {}\\n', '    size = (size * 512) or (1 << shift)\\n', '    count = int(size / 128)\\n', '    if size not in indirect_cache:\\n', '            blocks = array(Blockptr(), length=count)\\n', \"        IndirectBlock.__name__ = 'Indirect' + str(size)\\n\", '        indirect_cache[size] = IndirectBlock\\n', '    return indirect_cache[size]\\n', '    compressed_bytes = uint64()\\n']",
  "context": "_dir_zap = uint64()\n    used_bytes = uint64()\n    compressed_bytes = uint64()\n    uncompressed_bytes = uint64()\n    quota = uint"
 },
 "391": {
  "name": "uncompressed_bytes",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "226",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    version = uint64()\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', 'ObjectsetTypes = Union[Type[ObjsetV1], Type[ObjsetV15]]\\n', 'def Objset_for(version) -> ObjectsetTypes:\\n', '    if version in range(1, 15):\\n', 'indirect_cache = {}\\n', '    size = (size * 512) or (1 << shift)\\n', '    count = int(size / 128)\\n', '    if size not in indirect_cache:\\n', '            blocks = array(Blockptr(), length=count)\\n', \"        IndirectBlock.__name__ = 'Indirect' + str(size)\\n\", '        indirect_cache[size] = IndirectBlock\\n', '    return indirect_cache[size]\\n', '    uncompressed_bytes = uint64()\\n']",
  "context": "es = uint64()\n    compressed_bytes = uint64()\n    uncompressed_bytes = uint64()\n    quota = uint64()\n    props_zap = uint64()\n    "
 },
 "392": {
  "name": "quota",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "227",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    version = uint64()\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', 'ObjectsetTypes = Union[Type[ObjsetV1], Type[ObjsetV15]]\\n', 'def Objset_for(version) -> ObjectsetTypes:\\n', '    if version in range(1, 15):\\n', 'indirect_cache = {}\\n', '    size = (size * 512) or (1 << shift)\\n', '    count = int(size / 128)\\n', '    if size not in indirect_cache:\\n', '            blocks = array(Blockptr(), length=count)\\n', \"        IndirectBlock.__name__ = 'Indirect' + str(size)\\n\", '        indirect_cache[size] = IndirectBlock\\n', '    return indirect_cache[size]\\n', '    quota = uint64()\\n']",
  "context": " = uint64()\n    uncompressed_bytes = uint64()\n    quota = uint64()\n    props_zap = uint64()\n    _pad = padding(length"
 },
 "393": {
  "name": "props_zap",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "228",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    version = uint64()\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', 'ObjectsetTypes = Union[Type[ObjsetV1], Type[ObjsetV15]]\\n', 'def Objset_for(version) -> ObjectsetTypes:\\n', '    if version in range(1, 15):\\n', 'indirect_cache = {}\\n', '    size = (size * 512) or (1 << shift)\\n', '    count = int(size / 128)\\n', '    if size not in indirect_cache:\\n', '            blocks = array(Blockptr(), length=count)\\n', \"        IndirectBlock.__name__ = 'Indirect' + str(size)\\n\", '        indirect_cache[size] = IndirectBlock\\n', '    return indirect_cache[size]\\n', '    props_zap = uint64()\\n']",
  "context": "pressed_bytes = uint64()\n    quota = uint64()\n    props_zap = uint64()\n    _pad = padding(length=21 * 8)\n\n\nclass DSLDatas"
 },
 "394": {
  "name": "_pad",
  "type": "pyndata.padding",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "229",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    version = uint64()\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', 'ObjectsetTypes = Union[Type[ObjsetV1], Type[ObjsetV15]]\\n', 'def Objset_for(version) -> ObjectsetTypes:\\n', '    if version in range(1, 15):\\n', 'indirect_cache = {}\\n', '    size = (size * 512) or (1 << shift)\\n', '    count = int(size / 128)\\n', '    if size not in indirect_cache:\\n', '            blocks = array(Blockptr(), length=count)\\n', \"        IndirectBlock.__name__ = 'Indirect' + str(size)\\n\", '        indirect_cache[size] = IndirectBlock\\n', '    return indirect_cache[size]\\n', '    _pad = padding(length=21 * 8)\\n']",
  "context": "    quota = uint64()\n    props_zap = uint64()\n    _pad = padding(length=21 * 8)\n\n\nclass DSLDataset(Struct):\n    __ENDIAN__ = 'litt"
 },
 "395": {
  "name": "dir",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "235",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    version = uint64()\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', 'ObjectsetTypes = Union[Type[ObjsetV1], Type[ObjsetV15]]\\n', 'def Objset_for(version) -> ObjectsetTypes:\\n', '    if version in range(1, 15):\\n', 'indirect_cache = {}\\n', '    size = (size * 512) or (1 << shift)\\n', '    count = int(size / 128)\\n', '    if size not in indirect_cache:\\n', '            blocks = array(Blockptr(), length=count)\\n', \"        IndirectBlock.__name__ = 'Indirect' + str(size)\\n\", '        indirect_cache[size] = IndirectBlock\\n', '    return indirect_cache[size]\\n', '    dir = uint64()\\n']",
  "context": "SLDataset(Struct):\n    __ENDIAN__ = 'little'\n\n    dir = uint64()\n    prev_snapshot = uint64()\n    prev_snapshot_txg"
 },
 "396": {
  "name": "prev_snapshot",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "236",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    version = uint64()\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', 'ObjectsetTypes = Union[Type[ObjsetV1], Type[ObjsetV15]]\\n', 'def Objset_for(version) -> ObjectsetTypes:\\n', '    if version in range(1, 15):\\n', 'indirect_cache = {}\\n', '    size = (size * 512) or (1 << shift)\\n', '    count = int(size / 128)\\n', '    if size not in indirect_cache:\\n', '            blocks = array(Blockptr(), length=count)\\n', \"        IndirectBlock.__name__ = 'Indirect' + str(size)\\n\", '        indirect_cache[size] = IndirectBlock\\n', '    return indirect_cache[size]\\n', '    prev_snapshot = uint64()\\n']",
  "context": "    __ENDIAN__ = 'little'\n\n    dir = uint64()\n    prev_snapshot = uint64()\n    prev_snapshot_txg = uint64()\n    next_snapshot"
 },
 "397": {
  "name": "prev_snapshot_txg",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "237",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    version = uint64()\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', 'ObjectsetTypes = Union[Type[ObjsetV1], Type[ObjsetV15]]\\n', 'def Objset_for(version) -> ObjectsetTypes:\\n', '    if version in range(1, 15):\\n', 'indirect_cache = {}\\n', '    size = (size * 512) or (1 << shift)\\n', '    count = int(size / 128)\\n', '    if size not in indirect_cache:\\n', '            blocks = array(Blockptr(), length=count)\\n', \"        IndirectBlock.__name__ = 'Indirect' + str(size)\\n\", '        indirect_cache[size] = IndirectBlock\\n', '    return indirect_cache[size]\\n', '    prev_snapshot_txg = uint64()\\n']",
  "context": "  dir = uint64()\n    prev_snapshot = uint64()\n    prev_snapshot_txg = uint64()\n    next_snapshot = uint64()\n    snapnames_zap = u"
 },
 "398": {
  "name": "next_snapshot",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "238",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    version = uint64()\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', 'ObjectsetTypes = Union[Type[ObjsetV1], Type[ObjsetV15]]\\n', 'def Objset_for(version) -> ObjectsetTypes:\\n', '    if version in range(1, 15):\\n', 'indirect_cache = {}\\n', '    size = (size * 512) or (1 << shift)\\n', '    count = int(size / 128)\\n', '    if size not in indirect_cache:\\n', '            blocks = array(Blockptr(), length=count)\\n', \"        IndirectBlock.__name__ = 'Indirect' + str(size)\\n\", '        indirect_cache[size] = IndirectBlock\\n', '    return indirect_cache[size]\\n', '    next_snapshot = uint64()\\n']",
  "context": "t = uint64()\n    prev_snapshot_txg = uint64()\n    next_snapshot = uint64()\n    snapnames_zap = uint64()\n    num_children = ui"
 },
 "399": {
  "name": "snapnames_zap",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "239",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    version = uint64()\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', 'ObjectsetTypes = Union[Type[ObjsetV1], Type[ObjsetV15]]\\n', 'def Objset_for(version) -> ObjectsetTypes:\\n', '    if version in range(1, 15):\\n', 'indirect_cache = {}\\n', '    size = (size * 512) or (1 << shift)\\n', '    count = int(size / 128)\\n', '    if size not in indirect_cache:\\n', '            blocks = array(Blockptr(), length=count)\\n', \"        IndirectBlock.__name__ = 'Indirect' + str(size)\\n\", '        indirect_cache[size] = IndirectBlock\\n', '    return indirect_cache[size]\\n', '    snapnames_zap = uint64()\\n']",
  "context": "t_txg = uint64()\n    next_snapshot = uint64()\n    snapnames_zap = uint64()\n    num_children = uint64()\n    creation_time = ui"
 },
 "400": {
  "name": "num_children",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "240",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    version = uint64()\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', 'ObjectsetTypes = Union[Type[ObjsetV1], Type[ObjsetV15]]\\n', 'def Objset_for(version) -> ObjectsetTypes:\\n', '    if version in range(1, 15):\\n', 'indirect_cache = {}\\n', '    size = (size * 512) or (1 << shift)\\n', '    count = int(size / 128)\\n', '    if size not in indirect_cache:\\n', '            blocks = array(Blockptr(), length=count)\\n', \"        IndirectBlock.__name__ = 'Indirect' + str(size)\\n\", '        indirect_cache[size] = IndirectBlock\\n', '    return indirect_cache[size]\\n', '    num_children = uint64()\\n']",
  "context": "pshot = uint64()\n    snapnames_zap = uint64()\n    num_children = uint64()\n    creation_time = uint64()\n    creation_txg = ui"
 },
 "401": {
  "name": "creation_time",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "241",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    version = uint64()\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', 'ObjectsetTypes = Union[Type[ObjsetV1], Type[ObjsetV15]]\\n', 'def Objset_for(version) -> ObjectsetTypes:\\n', '    if version in range(1, 15):\\n', 'indirect_cache = {}\\n', '    size = (size * 512) or (1 << shift)\\n', '    count = int(size / 128)\\n', '    if size not in indirect_cache:\\n', '            blocks = array(Blockptr(), length=count)\\n', \"        IndirectBlock.__name__ = 'Indirect' + str(size)\\n\", '        indirect_cache[size] = IndirectBlock\\n', '    return indirect_cache[size]\\n', '    creation_time = uint64()\\n']",
  "context": "es_zap = uint64()\n    num_children = uint64()\n    creation_time = uint64()\n    creation_txg = uint64()\n    deadlist = uint64("
 },
 "402": {
  "name": "creation_txg",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "242",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    version = uint64()\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', 'ObjectsetTypes = Union[Type[ObjsetV1], Type[ObjsetV15]]\\n', 'def Objset_for(version) -> ObjectsetTypes:\\n', '    if version in range(1, 15):\\n', 'indirect_cache = {}\\n', '    size = (size * 512) or (1 << shift)\\n', '    count = int(size / 128)\\n', '    if size not in indirect_cache:\\n', '            blocks = array(Blockptr(), length=count)\\n', \"        IndirectBlock.__name__ = 'Indirect' + str(size)\\n\", '        indirect_cache[size] = IndirectBlock\\n', '    return indirect_cache[size]\\n', '    creation_txg = uint64()\\n']",
  "context": "ldren = uint64()\n    creation_time = uint64()\n    creation_txg = uint64()\n    deadlist = uint64()\n    used_bytes = uint64()\n"
 },
 "403": {
  "name": "deadlist",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "243",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    version = uint64()\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', 'ObjectsetTypes = Union[Type[ObjsetV1], Type[ObjsetV15]]\\n', 'def Objset_for(version) -> ObjectsetTypes:\\n', '    if version in range(1, 15):\\n', 'indirect_cache = {}\\n', '    size = (size * 512) or (1 << shift)\\n', '    count = int(size / 128)\\n', '    if size not in indirect_cache:\\n', '            blocks = array(Blockptr(), length=count)\\n', \"        IndirectBlock.__name__ = 'Indirect' + str(size)\\n\", '        indirect_cache[size] = IndirectBlock\\n', '    return indirect_cache[size]\\n', '    deadlist = uint64()\\n']",
  "context": "n_time = uint64()\n    creation_txg = uint64()\n    deadlist = uint64()\n    used_bytes = uint64()\n    compressed_bytes = u"
 },
 "404": {
  "name": "used_bytes",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "244",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    version = uint64()\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', 'ObjectsetTypes = Union[Type[ObjsetV1], Type[ObjsetV15]]\\n', 'def Objset_for(version) -> ObjectsetTypes:\\n', '    if version in range(1, 15):\\n', 'indirect_cache = {}\\n', '    size = (size * 512) or (1 << shift)\\n', '    count = int(size / 128)\\n', '    if size not in indirect_cache:\\n', '            blocks = array(Blockptr(), length=count)\\n', \"        IndirectBlock.__name__ = 'Indirect' + str(size)\\n\", '        indirect_cache[size] = IndirectBlock\\n', '    return indirect_cache[size]\\n', '    used_bytes = uint64()\\n']",
  "context": "eation_txg = uint64()\n    deadlist = uint64()\n    used_bytes = uint64()\n    compressed_bytes = uint64()\n    uncompressed_b"
 },
 "405": {
  "name": "compressed_bytes",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "245",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    version = uint64()\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', 'ObjectsetTypes = Union[Type[ObjsetV1], Type[ObjsetV15]]\\n', 'def Objset_for(version) -> ObjectsetTypes:\\n', '    if version in range(1, 15):\\n', 'indirect_cache = {}\\n', '    size = (size * 512) or (1 << shift)\\n', '    count = int(size / 128)\\n', '    if size not in indirect_cache:\\n', '            blocks = array(Blockptr(), length=count)\\n', \"        IndirectBlock.__name__ = 'Indirect' + str(size)\\n\", '        indirect_cache[size] = IndirectBlock\\n', '    return indirect_cache[size]\\n', '    compressed_bytes = uint64()\\n']",
  "context": "deadlist = uint64()\n    used_bytes = uint64()\n    compressed_bytes = uint64()\n    uncompressed_bytes = uint64()\n    unique_bytes"
 },
 "406": {
  "name": "uncompressed_bytes",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "246",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    version = uint64()\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', 'ObjectsetTypes = Union[Type[ObjsetV1], Type[ObjsetV15]]\\n', 'def Objset_for(version) -> ObjectsetTypes:\\n', '    if version in range(1, 15):\\n', 'indirect_cache = {}\\n', '    size = (size * 512) or (1 << shift)\\n', '    count = int(size / 128)\\n', '    if size not in indirect_cache:\\n', '            blocks = array(Blockptr(), length=count)\\n', \"        IndirectBlock.__name__ = 'Indirect' + str(size)\\n\", '        indirect_cache[size] = IndirectBlock\\n', '    return indirect_cache[size]\\n', '    uncompressed_bytes = uint64()\\n']",
  "context": "es = uint64()\n    compressed_bytes = uint64()\n    uncompressed_bytes = uint64()\n    unique_bytes = uint64()\n    fsid_guid = uint64"
 },
 "407": {
  "name": "unique_bytes",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "247",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    version = uint64()\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', 'ObjectsetTypes = Union[Type[ObjsetV1], Type[ObjsetV15]]\\n', 'def Objset_for(version) -> ObjectsetTypes:\\n', '    if version in range(1, 15):\\n', 'indirect_cache = {}\\n', '    size = (size * 512) or (1 << shift)\\n', '    count = int(size / 128)\\n', '    if size not in indirect_cache:\\n', '            blocks = array(Blockptr(), length=count)\\n', \"        IndirectBlock.__name__ = 'Indirect' + str(size)\\n\", '        indirect_cache[size] = IndirectBlock\\n', '    return indirect_cache[size]\\n', '    unique_bytes = uint64()\\n']",
  "context": " = uint64()\n    uncompressed_bytes = uint64()\n    unique_bytes = uint64()\n    fsid_guid = uint64()\n    guid = uint64()\n    f"
 },
 "408": {
  "name": "fsid_guid",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "248",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    version = uint64()\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', 'ObjectsetTypes = Union[Type[ObjsetV1], Type[ObjsetV15]]\\n', 'def Objset_for(version) -> ObjectsetTypes:\\n', '    if version in range(1, 15):\\n', 'indirect_cache = {}\\n', '    size = (size * 512) or (1 << shift)\\n', '    count = int(size / 128)\\n', '    if size not in indirect_cache:\\n', '            blocks = array(Blockptr(), length=count)\\n', \"        IndirectBlock.__name__ = 'Indirect' + str(size)\\n\", '        indirect_cache[size] = IndirectBlock\\n', '    return indirect_cache[size]\\n', '    fsid_guid = uint64()\\n']",
  "context": "_bytes = uint64()\n    unique_bytes = uint64()\n    fsid_guid = uint64()\n    guid = uint64()\n    flags = uint64()\n    bp = "
 },
 "409": {
  "name": "guid",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "249",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    version = uint64()\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', 'ObjectsetTypes = Union[Type[ObjsetV1], Type[ObjsetV15]]\\n', 'def Objset_for(version) -> ObjectsetTypes:\\n', '    if version in range(1, 15):\\n', 'indirect_cache = {}\\n', '    size = (size * 512) or (1 << shift)\\n', '    count = int(size / 128)\\n', '    if size not in indirect_cache:\\n', '            blocks = array(Blockptr(), length=count)\\n', \"        IndirectBlock.__name__ = 'Indirect' + str(size)\\n\", '        indirect_cache[size] = IndirectBlock\\n', '    return indirect_cache[size]\\n', '    guid = uint64()\\n']",
  "context": "que_bytes = uint64()\n    fsid_guid = uint64()\n    guid = uint64()\n    flags = uint64()\n    bp = Blockptr()\n    _pad "
 },
 "410": {
  "name": "flags",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "250",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    version = uint64()\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', 'ObjectsetTypes = Union[Type[ObjsetV1], Type[ObjsetV15]]\\n', 'def Objset_for(version) -> ObjectsetTypes:\\n', '    if version in range(1, 15):\\n', 'indirect_cache = {}\\n', '    size = (size * 512) or (1 << shift)\\n', '    count = int(size / 128)\\n', '    if size not in indirect_cache:\\n', '            blocks = array(Blockptr(), length=count)\\n', \"        IndirectBlock.__name__ = 'Indirect' + str(size)\\n\", '        indirect_cache[size] = IndirectBlock\\n', '    return indirect_cache[size]\\n', '    flags = uint64()\\n']",
  "context": "\n    fsid_guid = uint64()\n    guid = uint64()\n    flags = uint64()\n    bp = Blockptr()\n    _pad = padding(length=8 * "
 },
 "411": {
  "name": "bp",
  "type": "Blockptr",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "251",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    version = uint64()\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', 'ObjectsetTypes = Union[Type[ObjsetV1], Type[ObjsetV15]]\\n', 'def Objset_for(version) -> ObjectsetTypes:\\n', '    if version in range(1, 15):\\n', 'indirect_cache = {}\\n', '    size = (size * 512) or (1 << shift)\\n', '    count = int(size / 128)\\n', '    if size not in indirect_cache:\\n', '            blocks = array(Blockptr(), length=count)\\n', \"        IndirectBlock.__name__ = 'Indirect' + str(size)\\n\", '        indirect_cache[size] = IndirectBlock\\n', '    return indirect_cache[size]\\n', '    bp = Blockptr()\\n']",
  "context": "64()\n    guid = uint64()\n    flags = uint64()\n    bp = Blockptr()\n    _pad = padding(length=8 * 8)\n\n\nclass BPObjHead"
 },
 "412": {
  "name": "_pad",
  "type": "pyndata.padding",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "252",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    version = uint64()\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', 'ObjectsetTypes = Union[Type[ObjsetV1], Type[ObjsetV15]]\\n', 'def Objset_for(version) -> ObjectsetTypes:\\n', '    if version in range(1, 15):\\n', 'indirect_cache = {}\\n', '    size = (size * 512) or (1 << shift)\\n', '    count = int(size / 128)\\n', '    if size not in indirect_cache:\\n', '            blocks = array(Blockptr(), length=count)\\n', \"        IndirectBlock.__name__ = 'Indirect' + str(size)\\n\", '        indirect_cache[size] = IndirectBlock\\n', '    return indirect_cache[size]\\n', '    _pad = padding(length=8 * 8)\\n']",
  "context": "64()\n    flags = uint64()\n    bp = Blockptr()\n    _pad = padding(length=8 * 8)\n\n\nclass BPObjHeader(Struct):\n    __ENDIAN__ = 'lit"
 },
 "413": {
  "name": "length",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "258",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    version = uint64()\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', 'ObjectsetTypes = Union[Type[ObjsetV1], Type[ObjsetV15]]\\n', 'def Objset_for(version) -> ObjectsetTypes:\\n', '    if version in range(1, 15):\\n', 'indirect_cache = {}\\n', '    size = (size * 512) or (1 << shift)\\n', '    count = int(size / 128)\\n', '    if size not in indirect_cache:\\n', '            blocks = array(Blockptr(), length=count)\\n', \"        IndirectBlock.__name__ = 'Indirect' + str(size)\\n\", '        indirect_cache[size] = IndirectBlock\\n', '    return indirect_cache[size]\\n', '    length = uint64()\\n']",
  "context": "ObjHeader(Struct):\n    __ENDIAN__ = 'little'\n\n    length = uint64()\n    unknown = array(uint16(), length=20)\n\n"
 },
 "414": {
  "name": "unknown",
  "type": "pyndata.array",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/ondisk/__init__.py",
  "lineno": "259",
  "column": "4",
  "slicing": "['    _first = uint64()\\n', '    vdev = BitField(_first, 32, 32)\\n', '    grid = BitField(_first, 8, 23)\\n', '    asize = BitField(_first, 24, 0)\\n', '    _offset = uint64()\\n', '    gang = BitField(_offset, 1, 63)\\n', '    offset = BitField(_offset, 63, 0)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 16, 0)\\n', '    physical_size = BitField(_prop, 16, 16)\\n', '    compression = BitField(_prop, 6, 32, enum=constants.Compression)\\n', '    encryption = BitField(_prop, 1, 38)\\n', '    embedded = BitField(_prop, 1, 39)\\n', '    checksum_type = BitField(_prop, 8, 40, enum=constants.Checksum)\\n', '    object_type = BitField(_prop, 8, 48, enum=constants.ObjectType)\\n', '    level = BitField(_prop, 5, 56)\\n', '    dedup = BitField(_prop, 1, 62)\\n', '    endian = BitField(_prop, 1, 63)\\n', '        raw_blkptr = self.pack()\\n', '        return EmbeddedBlockptr(raw_blkptr)\\n', '    _prop = uint64()\\n', '    logical_size = BitField(_prop, 25)\\n', '    physical_size = BitField(_prop, 7)\\n', '    compression = BitField(_prop, 7)\\n', '    embedded = BitField(_prop, 1)\\n', '    embedded_type = BitField(_prop, 8)\\n', '    type_ = BitField(_prop, 8)\\n', '    level = BitField(_prop, 5)\\n', '    encryption = BitField(_prop, 1)\\n', '    dedup = BitField(_prop, 1)\\n', '    endian = BitField(_prop, 1)\\n', '        data = self.data1 + self.data2 + self.data3\\n', '        assert len(data) == 112\\n', '        return data\\n', '    version = uint64()\\n', '    num_blockptrs = uint8()\\n', '    _dnode_flags = uint8()  # TODO: dnode flag bitfields\\n', '    used_bytes = BitField(_dnode_flags, 1, 0)\\n', '    userused = BitField(_dnode_flags, 1, 1)\\n', '    spill_blkptr = BitField(_dnode_flags, 1, 3)\\n', '    blkptr = array(Blockptr(), length=num_blockptrs)\\n', 'ObjectsetTypes = Union[Type[ObjsetV1], Type[ObjsetV15]]\\n', 'def Objset_for(version) -> ObjectsetTypes:\\n', '    if version in range(1, 15):\\n', 'indirect_cache = {}\\n', '    size = (size * 512) or (1 << shift)\\n', '    count = int(size / 128)\\n', '    if size not in indirect_cache:\\n', '            blocks = array(Blockptr(), length=count)\\n', \"        IndirectBlock.__name__ = 'Indirect' + str(size)\\n\", '        indirect_cache[size] = IndirectBlock\\n', '    return indirect_cache[size]\\n', '    unknown = array(uint16(), length=20)\\n']",
  "context": " __ENDIAN__ = 'little'\n\n    length = uint64()\n    unknown = array(uint16(), length=20)\n\n"
 },
 "415": {
  "name": "name",
  "type": "pyndata.nullstring",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/posix/directory.py",
  "lineno": "23",
  "column": "4",
  "slicing": "['    name = pyndata.nullstring(max_length=256)\\n', '    value = pyndata.uint64()\\n', '    value.__SHOW__ = False\\n', '    object_type = pyndata.BitField(value, 4, 60, enum=PosixType)\\n', '    number = pyndata.BitField(value, 48)\\n', '        return name in self.entries\\n', '        joined_path = os.path.join(self.path, name)\\n', '        if name not in self.resolved_entries:\\n', '                entry_value = self.entries[name]\\n', '                entry = DirectoryEntry(name=name, value=entry_value)\\n', '                obj = self.objectset[entry.number]\\n', '                if isinstance(obj, (Directory, zfs.posix.File)):\\n', '                    obj.path = joined_path\\n', '                self.resolved_entries[name] = obj\\n', \"                logger.warning('directory lookup failed for {}'.format(joined_path))\\n\", '                raise FileNotFoundError(joined_path)\\n', '        return self.resolved_entries[name]\\n']",
  "context": "eal on-disk struct\n    __ENDIAN__ = 'little'\n\n    name = pyndata.nullstring(max_length=256)\n    value = pyndata.uint64()\n    value.__SHOW__ = "
 },
 "416": {
  "name": "value",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/posix/directory.py",
  "lineno": "24",
  "column": "4",
  "slicing": "['    value = pyndata.uint64()\\n', '    value.__SHOW__ = False\\n', '    object_type = pyndata.BitField(value, 4, 60, enum=PosixType)\\n', '    number = pyndata.BitField(value, 48)\\n']",
  "context": "    name = pyndata.nullstring(max_length=256)\n    value = pyndata.uint64()\n    value.__SHOW__ = False\n    object_type = pynda"
 },
 "417": {
  "name": "object_type",
  "type": "pyndata.BitField",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/posix/directory.py",
  "lineno": "26",
  "column": "4",
  "slicing": "['    value = pyndata.uint64()\\n', '    value.__SHOW__ = False\\n', '    object_type = pyndata.BitField(value, 4, 60, enum=PosixType)\\n', '    number = pyndata.BitField(value, 48)\\n']",
  "context": "= pyndata.uint64()\n    value.__SHOW__ = False\n    object_type = pyndata.BitField(value, 4, 60, enum=PosixType)\n    number = pyndata.BitField(value, 48)\n\n\nclass D"
 },
 "418": {
  "name": "number",
  "type": "pyndata.BitField",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/posix/directory.py",
  "lineno": "27",
  "column": "4",
  "slicing": "['    value = pyndata.uint64()\\n', '    value.__SHOW__ = False\\n', '    object_type = pyndata.BitField(value, 4, 60, enum=PosixType)\\n', '    number = pyndata.BitField(value, 48)\\n']",
  "context": "yndata.BitField(value, 4, 60, enum=PosixType)\n    number = pyndata.BitField(value, 48)\n\n\nclass Directory(PosixObject):\n    def __init__(s"
 },
 "419": {
  "name": "name",
  "type": "str",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/posix/directory.py",
  "lineno": "39",
  "column": "27",
  "slicing": "['    def __contains__(self, name: str) -> bool:\\n']",
  "context": "resolved_entries = {}\n\n    def __contains__(self, name: str) -> bool:\n        return name in self.entries\n\n    def __get"
 },
 "420": {
  "name": "name",
  "type": "str",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/posix/directory.py",
  "lineno": "42",
  "column": "26",
  "slicing": "['    def __getitem__(self, name: str) -> Any:\\n']",
  "context": "n name in self.entries\n\n    def __getitem__(self, name: str) -> Any:\n        joined_path = os.path.join(self.path, name"
 },
 "421": {
  "name": "joined_path",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/posix/directory.py",
  "lineno": "43",
  "column": "8",
  "slicing": "['    name = pyndata.nullstring(max_length=256)\\n', '    value = pyndata.uint64()\\n', '    value.__SHOW__ = False\\n', '    object_type = pyndata.BitField(value, 4, 60, enum=PosixType)\\n', '    number = pyndata.BitField(value, 48)\\n', '        return name in self.entries\\n', '        joined_path = os.path.join(self.path, name)\\n', '        if name not in self.resolved_entries:\\n', '                entry_value = self.entries[name]\\n', '                entry = DirectoryEntry(name=name, value=entry_value)\\n', '                obj = self.objectset[entry.number]\\n', '                if isinstance(obj, (Directory, zfs.posix.File)):\\n', '                    obj.path = joined_path\\n', '                self.resolved_entries[name] = obj\\n', \"                logger.warning('directory lookup failed for {}'.format(joined_path))\\n\", '                raise FileNotFoundError(joined_path)\\n', '        return self.resolved_entries[name]\\n']",
  "context": " def __getitem__(self, name: str) -> Any:\n        joined_path = os.path.join(self.path, name)\n        if name not in self.resolved_entries:\n    "
 },
 "422": {
  "name": "entry_value",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/posix/directory.py",
  "lineno": "46",
  "column": "16",
  "slicing": "['    name = pyndata.nullstring(max_length=256)\\n', '    value = pyndata.uint64()\\n', '    value.__SHOW__ = False\\n', '    object_type = pyndata.BitField(value, 4, 60, enum=PosixType)\\n', '    number = pyndata.BitField(value, 48)\\n', '        return name in self.entries\\n', '        joined_path = os.path.join(self.path, name)\\n', '        if name not in self.resolved_entries:\\n', '                entry_value = self.entries[name]\\n', '                entry = DirectoryEntry(name=name, value=entry_value)\\n', '                obj = self.objectset[entry.number]\\n', '                if isinstance(obj, (Directory, zfs.posix.File)):\\n', '                    obj.path = joined_path\\n', '                self.resolved_entries[name] = obj\\n', \"                logger.warning('directory lookup failed for {}'.format(joined_path))\\n\", '                raise FileNotFoundError(joined_path)\\n', '        return self.resolved_entries[name]\\n']",
  "context": "esolved_entries:\n            try:\n                entry_value = self.entries[name]\n                entry = DirectoryEntry(name=name, "
 },
 "423": {
  "name": "entry",
  "type": "DirectoryEntry",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/posix/directory.py",
  "lineno": "47",
  "column": "16",
  "slicing": "['    name = pyndata.nullstring(max_length=256)\\n', '    value = pyndata.uint64()\\n', '    value.__SHOW__ = False\\n', '    object_type = pyndata.BitField(value, 4, 60, enum=PosixType)\\n', '    number = pyndata.BitField(value, 48)\\n', '        return name in self.entries\\n', '        joined_path = os.path.join(self.path, name)\\n', '        if name not in self.resolved_entries:\\n', '                entry_value = self.entries[name]\\n', '                entry = DirectoryEntry(name=name, value=entry_value)\\n', '                obj = self.objectset[entry.number]\\n', '                if isinstance(obj, (Directory, zfs.posix.File)):\\n', '                    obj.path = joined_path\\n', '                self.resolved_entries[name] = obj\\n', \"                logger.warning('directory lookup failed for {}'.format(joined_path))\\n\", '                raise FileNotFoundError(joined_path)\\n', '        return self.resolved_entries[name]\\n']",
  "context": " entry_value = self.entries[name]\n                entry = DirectoryEntry(name=name, value=entry_value)\n                obj = self.objectset[entry.number]"
 },
 "424": {
  "name": "obj",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/posix/directory.py",
  "lineno": "48",
  "column": "16",
  "slicing": "['    name = pyndata.nullstring(max_length=256)\\n', '    value = pyndata.uint64()\\n', '    value.__SHOW__ = False\\n', '    object_type = pyndata.BitField(value, 4, 60, enum=PosixType)\\n', '    number = pyndata.BitField(value, 48)\\n', '        return name in self.entries\\n', '        joined_path = os.path.join(self.path, name)\\n', '        if name not in self.resolved_entries:\\n', '                entry_value = self.entries[name]\\n', '                entry = DirectoryEntry(name=name, value=entry_value)\\n', '                obj = self.objectset[entry.number]\\n', '                if isinstance(obj, (Directory, zfs.posix.File)):\\n', '                    obj.path = joined_path\\n', '                self.resolved_entries[name] = obj\\n', \"                logger.warning('directory lookup failed for {}'.format(joined_path))\\n\", '                raise FileNotFoundError(joined_path)\\n', '        return self.resolved_entries[name]\\n']",
  "context": "try(name=name, value=entry_value)\n                obj = self.objectset[entry.number]\n                if isinstance(obj, (Directory, zfs"
 },
 "425": {
  "name": "attr",
  "type": "simple_attribute",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/posix/attributes/systemattributes.py",
  "lineno": "18",
  "column": "4",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def simple_attribute(data, attrs):\\n', '    attr = simple_attribute(data, attrs)\\n', '    logger.info(attr)\\n', '    return attr\\n', 'def eat_remainder(data, attrs):\\n', '    d = data.read()\\n', '    return d\\n', \"    return eat_remainder(data, attrs).decode('utf-8')\\n\", \"    if 'ZPL_DACL_COUNT' not in attrs:\\n\", \"        logger.error('found acl entry but no count!')\\n\", \"    count = attrs['ZPL_DACL_COUNT']\\n\", '    acls = []\\n', '    for x in range(count):\\n', '        acls.append(data.read(8))\\n', \"    logger.debug(f'{data.tell()}/{len(data.getvalue())}')\\n\", '    return acls\\n', 'def no_attrs(f):\\n', '        return f(data)\\n', \"    'ZPL_MODE': no_attrs(Mode),\\n\", \"    'ZPL_ATIME': no_attrs(Timestamp),\\n\", \"    'ZPL_MTIME': no_attrs(Timestamp),\\n\", \"    'ZPL_CTIME': no_attrs(Timestamp),\\n\", \"    'ZPL_CRTIME': no_attrs(Timestamp),\\n\", '        attributes = {}\\n', '        logger.debug(repr(data[:4]))\\n', '        data = BytesIO(data)\\n', \"        attributes['header'] = hdr = SystemAttributeMagic(data)\\n\", '        logger.debug(hdr)\\n', '        for attr in self.dataset.attributes(str(hdr.layout)):\\n', \"            name = attr['name']\\n\", \"            logger.debug(f'processing attr {name}')\\n\", \"            if attr['length'] > 0:\\n\", \"                d = data.read(attr['length'])\\n\", '                d = data\\n', '            if name not in SYSTEM_ATTRIBUTES:\\n', \"                logger.debug('unknown attribute {}'.format(attr))\\n\", '            attributes[name] = SYSTEM_ATTRIBUTES.get(name, eat_remainder)(d, attrs=attributes)\\n', '        return attributes\\n']",
  "context": "0]\n\n\ndef debug_simple_attribute(data, attrs):\n    attr = simple_attribute(data, attrs)\n    logger.info(attr)\n    return attr\n\n\ndef eat_re"
 },
 "426": {
  "name": "count",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/posix/attributes/systemattributes.py",
  "lineno": "34",
  "column": "4",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def simple_attribute(data, attrs):\\n', '    attr = simple_attribute(data, attrs)\\n', '    logger.info(attr)\\n', '    return attr\\n', 'def eat_remainder(data, attrs):\\n', '    d = data.read()\\n', '    return d\\n', \"    return eat_remainder(data, attrs).decode('utf-8')\\n\", \"    if 'ZPL_DACL_COUNT' not in attrs:\\n\", \"        logger.error('found acl entry but no count!')\\n\", \"    count = attrs['ZPL_DACL_COUNT']\\n\", '    acls = []\\n', '    for x in range(count):\\n', '        acls.append(data.read(8))\\n', \"    logger.debug(f'{data.tell()}/{len(data.getvalue())}')\\n\", '    return acls\\n', 'def no_attrs(f):\\n', '        return f(data)\\n', \"    'ZPL_MODE': no_attrs(Mode),\\n\", \"    'ZPL_ATIME': no_attrs(Timestamp),\\n\", \"    'ZPL_MTIME': no_attrs(Timestamp),\\n\", \"    'ZPL_CTIME': no_attrs(Timestamp),\\n\", \"    'ZPL_CRTIME': no_attrs(Timestamp),\\n\", '        attributes = {}\\n', '        logger.debug(repr(data[:4]))\\n', '        data = BytesIO(data)\\n', \"        attributes['header'] = hdr = SystemAttributeMagic(data)\\n\", '        logger.debug(hdr)\\n', '        for attr in self.dataset.attributes(str(hdr.layout)):\\n', \"            name = attr['name']\\n\", \"            logger.debug(f'processing attr {name}')\\n\", \"            if attr['length'] > 0:\\n\", \"                d = data.read(attr['length'])\\n\", '                d = data\\n', '            if name not in SYSTEM_ATTRIBUTES:\\n', \"                logger.debug('unknown attribute {}'.format(attr))\\n\", '            attributes[name] = SYSTEM_ATTRIBUTES.get(name, eat_remainder)(d, attrs=attributes)\\n', '        return attributes\\n']",
  "context": "   raise KeyError('ZPL_DACL_COUNT not found')\n    count = attrs['ZPL_DACL_COUNT']\n    acls = []\n    for x in range(count):\n        a"
 },
 "427": {
  "name": "acls",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/posix/attributes/systemattributes.py",
  "lineno": "35",
  "column": "4",
  "slicing": "['    acls = []\\n', '        acls.append(data.read(8))\\n', '    return acls\\n']",
  "context": "t found')\n    count = attrs['ZPL_DACL_COUNT']\n    acls = []\n    for x in range(count):\n        acls.append(dat"
 },
 "428": {
  "name": "SYSTEM_ATTRIBUTES",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/posix/attributes/systemattributes.py",
  "lineno": "48",
  "column": "0",
  "slicing": "['SYSTEM_ATTRIBUTES = {\\n', '            if name not in SYSTEM_ATTRIBUTES:\\n', '            attributes[name] = SYSTEM_ATTRIBUTES.get(name, eat_remainder)(d, attrs=attributes)\\n']",
  "context": "attrs):\n        return f(data)\n    return inner\n\n\nSYSTEM_ATTRIBUTES = {\n    'ZPL_MODE': no_attrs(Mode),\n    'ZPL_SIZE': si"
 },
 "429": {
  "name": "magic",
  "type": "pyndata.bytestring",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/posix/attributes/systemattributes.py",
  "lineno": "69",
  "column": "4",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def simple_attribute(data, attrs):\\n', '    attr = simple_attribute(data, attrs)\\n', '    logger.info(attr)\\n', '    return attr\\n', 'def eat_remainder(data, attrs):\\n', '    d = data.read()\\n', '    return d\\n', \"    return eat_remainder(data, attrs).decode('utf-8')\\n\", \"    if 'ZPL_DACL_COUNT' not in attrs:\\n\", \"        logger.error('found acl entry but no count!')\\n\", \"    count = attrs['ZPL_DACL_COUNT']\\n\", '    acls = []\\n', '    for x in range(count):\\n', '        acls.append(data.read(8))\\n', \"    logger.debug(f'{data.tell()}/{len(data.getvalue())}')\\n\", '    return acls\\n', 'def no_attrs(f):\\n', '        return f(data)\\n', \"    'ZPL_MODE': no_attrs(Mode),\\n\", \"    'ZPL_ATIME': no_attrs(Timestamp),\\n\", \"    'ZPL_MTIME': no_attrs(Timestamp),\\n\", \"    'ZPL_CTIME': no_attrs(Timestamp),\\n\", \"    'ZPL_CRTIME': no_attrs(Timestamp),\\n\", '    magic = pyndata.bytestring(length=4)\\n', '        attributes = {}\\n', '        logger.debug(repr(data[:4]))\\n', '        data = BytesIO(data)\\n', \"        attributes['header'] = hdr = SystemAttributeMagic(data)\\n\", '        logger.debug(hdr)\\n', '        for attr in self.dataset.attributes(str(hdr.layout)):\\n', \"            name = attr['name']\\n\", \"            logger.debug(f'processing attr {name}')\\n\", \"            if attr['length'] > 0:\\n\", \"                d = data.read(attr['length'])\\n\", '                d = data\\n', '            if name not in SYSTEM_ATTRIBUTES:\\n', \"                logger.debug('unknown attribute {}'.format(attr))\\n\", '            attributes[name] = SYSTEM_ATTRIBUTES.get(name, eat_remainder)(d, attrs=attributes)\\n', '        return attributes\\n']",
  "context": "\n\nclass SystemAttributeMagic(pyndata.Struct):\n    magic = pyndata.bytestring(length=4)\n    layout = pyndata.uint8()\n    unknown1 = pyndat"
 },
 "430": {
  "name": "layout",
  "type": "pyndata.uint8",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/posix/attributes/systemattributes.py",
  "lineno": "70",
  "column": "4",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def simple_attribute(data, attrs):\\n', '    attr = simple_attribute(data, attrs)\\n', '    logger.info(attr)\\n', '    return attr\\n', 'def eat_remainder(data, attrs):\\n', '    d = data.read()\\n', '    return d\\n', \"    return eat_remainder(data, attrs).decode('utf-8')\\n\", \"    if 'ZPL_DACL_COUNT' not in attrs:\\n\", \"        logger.error('found acl entry but no count!')\\n\", \"    count = attrs['ZPL_DACL_COUNT']\\n\", '    acls = []\\n', '    for x in range(count):\\n', '        acls.append(data.read(8))\\n', \"    logger.debug(f'{data.tell()}/{len(data.getvalue())}')\\n\", '    return acls\\n', 'def no_attrs(f):\\n', '        return f(data)\\n', \"    'ZPL_MODE': no_attrs(Mode),\\n\", \"    'ZPL_ATIME': no_attrs(Timestamp),\\n\", \"    'ZPL_MTIME': no_attrs(Timestamp),\\n\", \"    'ZPL_CTIME': no_attrs(Timestamp),\\n\", \"    'ZPL_CRTIME': no_attrs(Timestamp),\\n\", '    layout = pyndata.uint8()\\n', '        attributes = {}\\n', '        logger.debug(repr(data[:4]))\\n', '        data = BytesIO(data)\\n', \"        attributes['header'] = hdr = SystemAttributeMagic(data)\\n\", '        logger.debug(hdr)\\n', '        for attr in self.dataset.attributes(str(hdr.layout)):\\n', \"            name = attr['name']\\n\", \"            logger.debug(f'processing attr {name}')\\n\", \"            if attr['length'] > 0:\\n\", \"                d = data.read(attr['length'])\\n\", '                d = data\\n', '            if name not in SYSTEM_ATTRIBUTES:\\n', \"                logger.debug('unknown attribute {}'.format(attr))\\n\", '            attributes[name] = SYSTEM_ATTRIBUTES.get(name, eat_remainder)(d, attrs=attributes)\\n', '        return attributes\\n']",
  "context": "ct):\n    magic = pyndata.bytestring(length=4)\n    layout = pyndata.uint8()\n    unknown1 = pyndata.uint8()\n    unknown2 = pynd"
 },
 "431": {
  "name": "unknown1",
  "type": "pyndata.uint8",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/posix/attributes/systemattributes.py",
  "lineno": "71",
  "column": "4",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def simple_attribute(data, attrs):\\n', '    attr = simple_attribute(data, attrs)\\n', '    logger.info(attr)\\n', '    return attr\\n', 'def eat_remainder(data, attrs):\\n', '    d = data.read()\\n', '    return d\\n', \"    return eat_remainder(data, attrs).decode('utf-8')\\n\", \"    if 'ZPL_DACL_COUNT' not in attrs:\\n\", \"        logger.error('found acl entry but no count!')\\n\", \"    count = attrs['ZPL_DACL_COUNT']\\n\", '    acls = []\\n', '    for x in range(count):\\n', '        acls.append(data.read(8))\\n', \"    logger.debug(f'{data.tell()}/{len(data.getvalue())}')\\n\", '    return acls\\n', 'def no_attrs(f):\\n', '        return f(data)\\n', \"    'ZPL_MODE': no_attrs(Mode),\\n\", \"    'ZPL_ATIME': no_attrs(Timestamp),\\n\", \"    'ZPL_MTIME': no_attrs(Timestamp),\\n\", \"    'ZPL_CTIME': no_attrs(Timestamp),\\n\", \"    'ZPL_CRTIME': no_attrs(Timestamp),\\n\", '    unknown1 = pyndata.uint8()\\n', '        attributes = {}\\n', '        logger.debug(repr(data[:4]))\\n', '        data = BytesIO(data)\\n', \"        attributes['header'] = hdr = SystemAttributeMagic(data)\\n\", '        logger.debug(hdr)\\n', '        for attr in self.dataset.attributes(str(hdr.layout)):\\n', \"            name = attr['name']\\n\", \"            logger.debug(f'processing attr {name}')\\n\", \"            if attr['length'] > 0:\\n\", \"                d = data.read(attr['length'])\\n\", '                d = data\\n', '            if name not in SYSTEM_ATTRIBUTES:\\n', \"                logger.debug('unknown attribute {}'.format(attr))\\n\", '            attributes[name] = SYSTEM_ATTRIBUTES.get(name, eat_remainder)(d, attrs=attributes)\\n', '        return attributes\\n']",
  "context": "string(length=4)\n    layout = pyndata.uint8()\n    unknown1 = pyndata.uint8()\n    unknown2 = pyndata.padding(length=2)\n    unkno"
 },
 "432": {
  "name": "unknown2",
  "type": "pyndata.padding",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/posix/attributes/systemattributes.py",
  "lineno": "72",
  "column": "4",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def simple_attribute(data, attrs):\\n', '    attr = simple_attribute(data, attrs)\\n', '    logger.info(attr)\\n', '    return attr\\n', 'def eat_remainder(data, attrs):\\n', '    d = data.read()\\n', '    return d\\n', \"    return eat_remainder(data, attrs).decode('utf-8')\\n\", \"    if 'ZPL_DACL_COUNT' not in attrs:\\n\", \"        logger.error('found acl entry but no count!')\\n\", \"    count = attrs['ZPL_DACL_COUNT']\\n\", '    acls = []\\n', '    for x in range(count):\\n', '        acls.append(data.read(8))\\n', \"    logger.debug(f'{data.tell()}/{len(data.getvalue())}')\\n\", '    return acls\\n', 'def no_attrs(f):\\n', '        return f(data)\\n', \"    'ZPL_MODE': no_attrs(Mode),\\n\", \"    'ZPL_ATIME': no_attrs(Timestamp),\\n\", \"    'ZPL_MTIME': no_attrs(Timestamp),\\n\", \"    'ZPL_CTIME': no_attrs(Timestamp),\\n\", \"    'ZPL_CRTIME': no_attrs(Timestamp),\\n\", '    unknown2 = pyndata.padding(length=2)\\n', '        attributes = {}\\n', '        logger.debug(repr(data[:4]))\\n', '        data = BytesIO(data)\\n', \"        attributes['header'] = hdr = SystemAttributeMagic(data)\\n\", '        logger.debug(hdr)\\n', '        for attr in self.dataset.attributes(str(hdr.layout)):\\n', \"            name = attr['name']\\n\", \"            logger.debug(f'processing attr {name}')\\n\", \"            if attr['length'] > 0:\\n\", \"                d = data.read(attr['length'])\\n\", '                d = data\\n', '            if name not in SYSTEM_ATTRIBUTES:\\n', \"                logger.debug('unknown attribute {}'.format(attr))\\n\", '            attributes[name] = SYSTEM_ATTRIBUTES.get(name, eat_remainder)(d, attrs=attributes)\\n', '        return attributes\\n']",
  "context": "yndata.uint8()\n    unknown1 = pyndata.uint8()\n    unknown2 = pyndata.padding(length=2)\n    unknown3 = pyndata.bytestring(length=lambda s,"
 },
 "433": {
  "name": "unknown3",
  "type": "pyndata.bytestring",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/posix/attributes/systemattributes.py",
  "lineno": "73",
  "column": "4",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def simple_attribute(data, attrs):\\n', '    attr = simple_attribute(data, attrs)\\n', '    logger.info(attr)\\n', '    return attr\\n', 'def eat_remainder(data, attrs):\\n', '    d = data.read()\\n', '    return d\\n', \"    return eat_remainder(data, attrs).decode('utf-8')\\n\", \"    if 'ZPL_DACL_COUNT' not in attrs:\\n\", \"        logger.error('found acl entry but no count!')\\n\", \"    count = attrs['ZPL_DACL_COUNT']\\n\", '    acls = []\\n', '    for x in range(count):\\n', '        acls.append(data.read(8))\\n', \"    logger.debug(f'{data.tell()}/{len(data.getvalue())}')\\n\", '    return acls\\n', 'def no_attrs(f):\\n', '        return f(data)\\n', \"    'ZPL_MODE': no_attrs(Mode),\\n\", \"    'ZPL_ATIME': no_attrs(Timestamp),\\n\", \"    'ZPL_MTIME': no_attrs(Timestamp),\\n\", \"    'ZPL_CTIME': no_attrs(Timestamp),\\n\", \"    'ZPL_CRTIME': no_attrs(Timestamp),\\n\", '    unknown3 = pyndata.bytestring(length=lambda s, x=None: 8 if s.unknown1 == 8 else 0)\\n', '        attributes = {}\\n', '        logger.debug(repr(data[:4]))\\n', '        data = BytesIO(data)\\n', \"        attributes['header'] = hdr = SystemAttributeMagic(data)\\n\", '        logger.debug(hdr)\\n', '        for attr in self.dataset.attributes(str(hdr.layout)):\\n', \"            name = attr['name']\\n\", \"            logger.debug(f'processing attr {name}')\\n\", \"            if attr['length'] > 0:\\n\", \"                d = data.read(attr['length'])\\n\", '                d = data\\n', '            if name not in SYSTEM_ATTRIBUTES:\\n', \"                logger.debug('unknown attribute {}'.format(attr))\\n\", '            attributes[name] = SYSTEM_ATTRIBUTES.get(name, eat_remainder)(d, attrs=attributes)\\n', '        return attributes\\n']",
  "context": "t8()\n    unknown2 = pyndata.padding(length=2)\n    unknown3 = pyndata.bytestring(length=lambda s, x=None: 8 if s.unknown1 == 8 else 0)\n\n\nclass SystemAttributes(object):\n    def __init__"
 },
 "434": {
  "name": "attributes",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/posix/attributes/systemattributes.py",
  "lineno": "81",
  "column": "8",
  "slicing": "['        attributes = {}\\n', \"        attributes['header'] = hdr = SystemAttributeMagic(data)\\n\", '            attributes[name] = SYSTEM_ATTRIBUTES.get(name, eat_remainder)(d, attrs=attributes)\\n', '        return attributes\\n']",
  "context": " = dataset\n\n    def __call__(self, data):\n        attributes = {}\n        logger.debug(repr(data[:4]))\n        data "
 },
 "435": {
  "name": "data",
  "type": "io.BytesIO",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/posix/attributes/systemattributes.py",
  "lineno": "83",
  "column": "8",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def simple_attribute(data, attrs):\\n', '    attr = simple_attribute(data, attrs)\\n', '    logger.info(attr)\\n', '    return attr\\n', 'def eat_remainder(data, attrs):\\n', '    d = data.read()\\n', '    return d\\n', \"    return eat_remainder(data, attrs).decode('utf-8')\\n\", \"    if 'ZPL_DACL_COUNT' not in attrs:\\n\", \"        logger.error('found acl entry but no count!')\\n\", \"    count = attrs['ZPL_DACL_COUNT']\\n\", '    acls = []\\n', '    for x in range(count):\\n', '        acls.append(data.read(8))\\n', \"    logger.debug(f'{data.tell()}/{len(data.getvalue())}')\\n\", '    return acls\\n', 'def no_attrs(f):\\n', '        return f(data)\\n', \"    'ZPL_MODE': no_attrs(Mode),\\n\", \"    'ZPL_ATIME': no_attrs(Timestamp),\\n\", \"    'ZPL_MTIME': no_attrs(Timestamp),\\n\", \"    'ZPL_CTIME': no_attrs(Timestamp),\\n\", \"    'ZPL_CRTIME': no_attrs(Timestamp),\\n\", '        attributes = {}\\n', '        logger.debug(repr(data[:4]))\\n', '        data = BytesIO(data)\\n', \"        attributes['header'] = hdr = SystemAttributeMagic(data)\\n\", '        logger.debug(hdr)\\n', '        for attr in self.dataset.attributes(str(hdr.layout)):\\n', \"            name = attr['name']\\n\", \"            logger.debug(f'processing attr {name}')\\n\", \"            if attr['length'] > 0:\\n\", \"                d = data.read(attr['length'])\\n\", '                d = data\\n', '            if name not in SYSTEM_ATTRIBUTES:\\n', \"                logger.debug('unknown attribute {}'.format(attr))\\n\", '            attributes[name] = SYSTEM_ATTRIBUTES.get(name, eat_remainder)(d, attrs=attributes)\\n', '        return attributes\\n']",
  "context": "= {}\n        logger.debug(repr(data[:4]))\n        data = BytesIO(data)\n        attributes['header'] = hdr = SystemAttribu"
 },
 "436": {
  "name": "hdr",
  "type": "SystemAttributeMagic",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/posix/attributes/systemattributes.py",
  "lineno": "84",
  "column": "31",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def simple_attribute(data, attrs):\\n', '    attr = simple_attribute(data, attrs)\\n', '    logger.info(attr)\\n', '    return attr\\n', 'def eat_remainder(data, attrs):\\n', '    d = data.read()\\n', '    return d\\n', \"    return eat_remainder(data, attrs).decode('utf-8')\\n\", \"    if 'ZPL_DACL_COUNT' not in attrs:\\n\", \"        logger.error('found acl entry but no count!')\\n\", \"    count = attrs['ZPL_DACL_COUNT']\\n\", '    acls = []\\n', '    for x in range(count):\\n', '        acls.append(data.read(8))\\n', \"    logger.debug(f'{data.tell()}/{len(data.getvalue())}')\\n\", '    return acls\\n', 'def no_attrs(f):\\n', '        return f(data)\\n', \"    'ZPL_MODE': no_attrs(Mode),\\n\", \"    'ZPL_ATIME': no_attrs(Timestamp),\\n\", \"    'ZPL_MTIME': no_attrs(Timestamp),\\n\", \"    'ZPL_CTIME': no_attrs(Timestamp),\\n\", \"    'ZPL_CRTIME': no_attrs(Timestamp),\\n\", '        attributes = {}\\n', '        logger.debug(repr(data[:4]))\\n', '        data = BytesIO(data)\\n', \"        attributes['header'] = hdr = SystemAttributeMagic(data)\\n\", '        logger.debug(hdr)\\n', '        for attr in self.dataset.attributes(str(hdr.layout)):\\n', \"            name = attr['name']\\n\", \"            logger.debug(f'processing attr {name}')\\n\", \"            if attr['length'] > 0:\\n\", \"                d = data.read(attr['length'])\\n\", '                d = data\\n', '            if name not in SYSTEM_ATTRIBUTES:\\n', \"                logger.debug('unknown attribute {}'.format(attr))\\n\", '            attributes[name] = SYSTEM_ATTRIBUTES.get(name, eat_remainder)(d, attrs=attributes)\\n', '        return attributes\\n']",
  "context": "ta = BytesIO(data)\n        attributes['header'] = hdr = SystemAttributeMagic(data)\n        logger.debug(hdr)\n        for attr in self"
 },
 "437": {
  "name": "name",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/zfs/posix/attributes/systemattributes.py",
  "lineno": "87",
  "column": "12",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def simple_attribute(data, attrs):\\n', '    attr = simple_attribute(data, attrs)\\n', '    logger.info(attr)\\n', '    return attr\\n', 'def eat_remainder(data, attrs):\\n', '    d = data.read()\\n', '    return d\\n', \"    return eat_remainder(data, attrs).decode('utf-8')\\n\", \"    if 'ZPL_DACL_COUNT' not in attrs:\\n\", \"        logger.error('found acl entry but no count!')\\n\", \"    count = attrs['ZPL_DACL_COUNT']\\n\", '    acls = []\\n', '    for x in range(count):\\n', '        acls.append(data.read(8))\\n', \"    logger.debug(f'{data.tell()}/{len(data.getvalue())}')\\n\", '    return acls\\n', 'def no_attrs(f):\\n', '        return f(data)\\n', \"    'ZPL_MODE': no_attrs(Mode),\\n\", \"    'ZPL_ATIME': no_attrs(Timestamp),\\n\", \"    'ZPL_MTIME': no_attrs(Timestamp),\\n\", \"    'ZPL_CTIME': no_attrs(Timestamp),\\n\", \"    'ZPL_CRTIME': no_attrs(Timestamp),\\n\", '        attributes = {}\\n', '        logger.debug(repr(data[:4]))\\n', '        data = BytesIO(data)\\n', \"        attributes['header'] = hdr = SystemAttributeMagic(data)\\n\", '        logger.debug(hdr)\\n', '        for attr in self.dataset.attributes(str(hdr.layout)):\\n', \"            name = attr['name']\\n\", \"            logger.debug(f'processing attr {name}')\\n\", \"            if attr['length'] > 0:\\n\", \"                d = data.read(attr['length'])\\n\", '                d = data\\n', '            if name not in SYSTEM_ATTRIBUTES:\\n', \"                logger.debug('unknown attribute {}'.format(attr))\\n\", '            attributes[name] = SYSTEM_ATTRIBUTES.get(name, eat_remainder)(d, attrs=attributes)\\n', '        return attributes\\n']",
  "context": ".dataset.attributes(str(hdr.layout)):\n            name = attr['name']\n            logger.debug(f'processing attr {name}'"
 },
 "438": {
  "name": "d",
  "type": "data",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/zfs/posix/attributes/systemattributes.py",
  "lineno": "92",
  "column": "16",
  "slicing": "['logger = logging.getLogger(__name__)\\n', 'def simple_attribute(data, attrs):\\n', '    attr = simple_attribute(data, attrs)\\n', '    logger.info(attr)\\n', '    return attr\\n', 'def eat_remainder(data, attrs):\\n', '    d = data.read()\\n', '    return d\\n', \"    return eat_remainder(data, attrs).decode('utf-8')\\n\", \"    if 'ZPL_DACL_COUNT' not in attrs:\\n\", \"        logger.error('found acl entry but no count!')\\n\", \"    count = attrs['ZPL_DACL_COUNT']\\n\", '    acls = []\\n', '    for x in range(count):\\n', '        acls.append(data.read(8))\\n', \"    logger.debug(f'{data.tell()}/{len(data.getvalue())}')\\n\", '    return acls\\n', 'def no_attrs(f):\\n', '        return f(data)\\n', \"    'ZPL_MODE': no_attrs(Mode),\\n\", \"    'ZPL_ATIME': no_attrs(Timestamp),\\n\", \"    'ZPL_MTIME': no_attrs(Timestamp),\\n\", \"    'ZPL_CTIME': no_attrs(Timestamp),\\n\", \"    'ZPL_CRTIME': no_attrs(Timestamp),\\n\", '        attributes = {}\\n', '        logger.debug(repr(data[:4]))\\n', '        data = BytesIO(data)\\n', \"        attributes['header'] = hdr = SystemAttributeMagic(data)\\n\", '        logger.debug(hdr)\\n', '        for attr in self.dataset.attributes(str(hdr.layout)):\\n', \"            name = attr['name']\\n\", \"            logger.debug(f'processing attr {name}')\\n\", \"            if attr['length'] > 0:\\n\", \"                d = data.read(attr['length'])\\n\", '                d = data\\n', '            if name not in SYSTEM_ATTRIBUTES:\\n', \"                logger.debug('unknown attribute {}'.format(attr))\\n\", '            attributes[name] = SYSTEM_ATTRIBUTES.get(name, eat_remainder)(d, attrs=attributes)\\n', '        return attributes\\n']",
  "context": "attr['length'])\n            else:\n                d = data\n            if name not in SYSTEM_ATTRIBUTES:\n    "
 },
 "439": {
  "name": "mode",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/posix/attributes/__init__.py",
  "lineno": "23",
  "column": "4",
  "slicing": "['    mode = pyndata.uint64()\\n', '    perms = pyndata.BitField(mode, 10)\\n', '    unknown = pyndata.BitField(mode, 2)\\n', '    file_type = pyndata.BitField(mode, 4, enum=PosixType)\\n']",
  "context": "de(pyndata.Struct):\n    __ENDIAN__ = 'little'\n    mode = pyndata.uint64()\n    perms = pyndata.BitField(mode, 10)\n    unknown"
 },
 "440": {
  "name": "perms",
  "type": "pyndata.BitField",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/posix/attributes/__init__.py",
  "lineno": "24",
  "column": "4",
  "slicing": "['    mode = pyndata.uint64()\\n', '    perms = pyndata.BitField(mode, 10)\\n', '    unknown = pyndata.BitField(mode, 2)\\n', '    file_type = pyndata.BitField(mode, 4, enum=PosixType)\\n']",
  "context": "DIAN__ = 'little'\n    mode = pyndata.uint64()\n    perms = pyndata.BitField(mode, 10)\n    unknown = pyndata.BitField(mode, 2)\n    file_t"
 },
 "441": {
  "name": "unknown",
  "type": "pyndata.BitField",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/posix/attributes/__init__.py",
  "lineno": "25",
  "column": "4",
  "slicing": "['    mode = pyndata.uint64()\\n', '    perms = pyndata.BitField(mode, 10)\\n', '    unknown = pyndata.BitField(mode, 2)\\n', '    file_type = pyndata.BitField(mode, 4, enum=PosixType)\\n']",
  "context": "nt64()\n    perms = pyndata.BitField(mode, 10)\n    unknown = pyndata.BitField(mode, 2)\n    file_type = pyndata.BitField(mode, 4, enum=Pos"
 },
 "442": {
  "name": "file_type",
  "type": "pyndata.BitField",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/posix/attributes/__init__.py",
  "lineno": "26",
  "column": "4",
  "slicing": "['    mode = pyndata.uint64()\\n', '    perms = pyndata.BitField(mode, 10)\\n', '    unknown = pyndata.BitField(mode, 2)\\n', '    file_type = pyndata.BitField(mode, 4, enum=PosixType)\\n']",
  "context": ", 10)\n    unknown = pyndata.BitField(mode, 2)\n    file_type = pyndata.BitField(mode, 4, enum=PosixType)\n\n\nclass Timestamp(pyndata.Struct):\n    __ENDIAN__ "
 },
 "443": {
  "name": "seconds",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/posix/attributes/__init__.py",
  "lineno": "31",
  "column": "4",
  "slicing": "['    mode = pyndata.uint64()\\n', '    perms = pyndata.BitField(mode, 10)\\n', '    unknown = pyndata.BitField(mode, 2)\\n', '    file_type = pyndata.BitField(mode, 4, enum=PosixType)\\n', '    seconds = pyndata.uint64()\\n']",
  "context": "mp(pyndata.Struct):\n    __ENDIAN__ = 'little'\n    seconds = pyndata.uint64()\n    nanoseconds = pyndata.uint64()\n\n\nclass ZNodeAC"
 },
 "444": {
  "name": "nanoseconds",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/posix/attributes/__init__.py",
  "lineno": "32",
  "column": "4",
  "slicing": "['    mode = pyndata.uint64()\\n', '    perms = pyndata.BitField(mode, 10)\\n', '    unknown = pyndata.BitField(mode, 2)\\n', '    file_type = pyndata.BitField(mode, 4, enum=PosixType)\\n', '    nanoseconds = pyndata.uint64()\\n']",
  "context": "N__ = 'little'\n    seconds = pyndata.uint64()\n    nanoseconds = pyndata.uint64()\n\n\nclass ZNodeACE(pyndata.Struct):\n    who = pyndat"
 },
 "445": {
  "name": "who",
  "type": "pyndata.uint32",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/posix/attributes/__init__.py",
  "lineno": "36",
  "column": "4",
  "slicing": "['    mode = pyndata.uint64()\\n', '    perms = pyndata.BitField(mode, 10)\\n', '    unknown = pyndata.BitField(mode, 2)\\n', '    file_type = pyndata.BitField(mode, 4, enum=PosixType)\\n', '    who = pyndata.uint32()\\n']",
  "context": "ta.uint64()\n\n\nclass ZNodeACE(pyndata.Struct):\n    who = pyndata.uint32()\n    access_mask = pyndata.uint32()\n    flags = pyn"
 },
 "446": {
  "name": "access_mask",
  "type": "pyndata.uint32",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/posix/attributes/__init__.py",
  "lineno": "37",
  "column": "4",
  "slicing": "['    mode = pyndata.uint64()\\n', '    perms = pyndata.BitField(mode, 10)\\n', '    unknown = pyndata.BitField(mode, 2)\\n', '    file_type = pyndata.BitField(mode, 4, enum=PosixType)\\n', '    access_mask = pyndata.uint32()\\n']",
  "context": "E(pyndata.Struct):\n    who = pyndata.uint32()\n    access_mask = pyndata.uint32()\n    flags = pyndata.uint16()\n    type = pyndata.ui"
 },
 "447": {
  "name": "flags",
  "type": "pyndata.uint16",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/posix/attributes/__init__.py",
  "lineno": "38",
  "column": "4",
  "slicing": "['    mode = pyndata.uint64()\\n', '    perms = pyndata.BitField(mode, 10)\\n', '    unknown = pyndata.BitField(mode, 2)\\n', '    file_type = pyndata.BitField(mode, 4, enum=PosixType)\\n', '    flags = pyndata.uint16()\\n']",
  "context": "a.uint32()\n    access_mask = pyndata.uint32()\n    flags = pyndata.uint16()\n    type = pyndata.uint16()\n\n\nclass ZNodeACL(pynda"
 },
 "448": {
  "name": "type",
  "type": "pyndata.uint16",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/posix/attributes/__init__.py",
  "lineno": "39",
  "column": "4",
  "slicing": "['    mode = pyndata.uint64()\\n', '    perms = pyndata.BitField(mode, 10)\\n', '    unknown = pyndata.BitField(mode, 2)\\n', '    file_type = pyndata.BitField(mode, 4, enum=PosixType)\\n', '    type = pyndata.uint16()\\n']",
  "context": "pyndata.uint32()\n    flags = pyndata.uint16()\n    type = pyndata.uint16()\n\n\nclass ZNodeACL(pyndata.Struct):\n    external_obj"
 },
 "449": {
  "name": "external_object",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/posix/attributes/__init__.py",
  "lineno": "43",
  "column": "4",
  "slicing": "['    mode = pyndata.uint64()\\n', '    perms = pyndata.BitField(mode, 10)\\n', '    unknown = pyndata.BitField(mode, 2)\\n', '    file_type = pyndata.BitField(mode, 4, enum=PosixType)\\n', '    external_object = pyndata.uint64()\\n']",
  "context": "ta.uint16()\n\n\nclass ZNodeACL(pyndata.Struct):\n    external_object = pyndata.uint64()\n    count = pyndata.uint32()\n    version = pyndata"
 },
 "450": {
  "name": "count",
  "type": "pyndata.uint32",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/posix/attributes/__init__.py",
  "lineno": "44",
  "column": "4",
  "slicing": "['    mode = pyndata.uint64()\\n', '    perms = pyndata.BitField(mode, 10)\\n', '    unknown = pyndata.BitField(mode, 2)\\n', '    file_type = pyndata.BitField(mode, 4, enum=PosixType)\\n', '    count = pyndata.uint32()\\n', '    aces = pyndata.array(ZNodeACE, length=count)\\n']",
  "context": "ruct):\n    external_object = pyndata.uint64()\n    count = pyndata.uint32()\n    version = pyndata.uint16()\n    _padding = pynd"
 },
 "451": {
  "name": "version",
  "type": "pyndata.uint16",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/posix/attributes/__init__.py",
  "lineno": "45",
  "column": "4",
  "slicing": "['    mode = pyndata.uint64()\\n', '    perms = pyndata.BitField(mode, 10)\\n', '    unknown = pyndata.BitField(mode, 2)\\n', '    file_type = pyndata.BitField(mode, 4, enum=PosixType)\\n', '    version = pyndata.uint16()\\n']",
  "context": "pyndata.uint64()\n    count = pyndata.uint32()\n    version = pyndata.uint16()\n    _padding = pyndata.padding(length=2)\n    aces "
 },
 "452": {
  "name": "_padding",
  "type": "pyndata.padding",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/posix/attributes/__init__.py",
  "lineno": "46",
  "column": "4",
  "slicing": "['    mode = pyndata.uint64()\\n', '    perms = pyndata.BitField(mode, 10)\\n', '    unknown = pyndata.BitField(mode, 2)\\n', '    file_type = pyndata.BitField(mode, 4, enum=PosixType)\\n', '    _padding = pyndata.padding(length=2)\\n']",
  "context": "ndata.uint32()\n    version = pyndata.uint16()\n    _padding = pyndata.padding(length=2)\n    aces = pyndata.array(ZNodeACE, length=count)\n\n"
 },
 "453": {
  "name": "aces",
  "type": "pyndata.array",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/posix/attributes/__init__.py",
  "lineno": "47",
  "column": "4",
  "slicing": "['    mode = pyndata.uint64()\\n', '    perms = pyndata.BitField(mode, 10)\\n', '    unknown = pyndata.BitField(mode, 2)\\n', '    file_type = pyndata.BitField(mode, 4, enum=PosixType)\\n', '    count = pyndata.uint32()\\n', '    aces = pyndata.array(ZNodeACE, length=count)\\n']",
  "context": "16()\n    _padding = pyndata.padding(length=2)\n    aces = pyndata.array(ZNodeACE, length=count)\n\n\nclass DefaultAttrsV1(pyndata.Struct):\n    __ENDI"
 },
 "454": {
  "name": "ZPL_ATIME",
  "type": "Timestamp",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/posix/attributes/__init__.py",
  "lineno": "52",
  "column": "4",
  "slicing": "['    mode = pyndata.uint64()\\n', '    perms = pyndata.BitField(mode, 10)\\n', '    unknown = pyndata.BitField(mode, 2)\\n', '    file_type = pyndata.BitField(mode, 4, enum=PosixType)\\n', '    count = pyndata.uint32()\\n', '    aces = pyndata.array(ZNodeACE, length=count)\\n', '    ZPL_ATIME = Timestamp()\\n']",
  "context": "V1(pyndata.Struct):\n    __ENDIAN__ = 'little'\n    ZPL_ATIME = Timestamp()\n    ZPL_MTIME = Timestamp()\n    ZPL_CTIME = Timest"
 },
 "455": {
  "name": "ZPL_MTIME",
  "type": "Timestamp",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/posix/attributes/__init__.py",
  "lineno": "53",
  "column": "4",
  "slicing": "['    mode = pyndata.uint64()\\n', '    perms = pyndata.BitField(mode, 10)\\n', '    unknown = pyndata.BitField(mode, 2)\\n', '    file_type = pyndata.BitField(mode, 4, enum=PosixType)\\n', '    count = pyndata.uint32()\\n', '    aces = pyndata.array(ZNodeACE, length=count)\\n', '    ZPL_MTIME = Timestamp()\\n']",
  "context": "DIAN__ = 'little'\n    ZPL_ATIME = Timestamp()\n    ZPL_MTIME = Timestamp()\n    ZPL_CTIME = Timestamp()\n    ZPL_CRTIME = Times"
 },
 "456": {
  "name": "ZPL_CTIME",
  "type": "Timestamp",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/posix/attributes/__init__.py",
  "lineno": "54",
  "column": "4",
  "slicing": "['    mode = pyndata.uint64()\\n', '    perms = pyndata.BitField(mode, 10)\\n', '    unknown = pyndata.BitField(mode, 2)\\n', '    file_type = pyndata.BitField(mode, 4, enum=PosixType)\\n', '    count = pyndata.uint32()\\n', '    aces = pyndata.array(ZNodeACE, length=count)\\n', '    ZPL_CTIME = Timestamp()\\n']",
  "context": "IME = Timestamp()\n    ZPL_MTIME = Timestamp()\n    ZPL_CTIME = Timestamp()\n    ZPL_CRTIME = Timestamp()\n    ZPL_GEN = pyndata"
 },
 "457": {
  "name": "ZPL_CRTIME",
  "type": "Timestamp",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/posix/attributes/__init__.py",
  "lineno": "55",
  "column": "4",
  "slicing": "['    mode = pyndata.uint64()\\n', '    perms = pyndata.BitField(mode, 10)\\n', '    unknown = pyndata.BitField(mode, 2)\\n', '    file_type = pyndata.BitField(mode, 4, enum=PosixType)\\n', '    count = pyndata.uint32()\\n', '    aces = pyndata.array(ZNodeACE, length=count)\\n', '    ZPL_CRTIME = Timestamp()\\n']",
  "context": "IME = Timestamp()\n    ZPL_CTIME = Timestamp()\n    ZPL_CRTIME = Timestamp()\n    ZPL_GEN = pyndata.uint64()\n    ZPL_MODE = Mode"
 },
 "458": {
  "name": "ZPL_GEN",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/posix/attributes/__init__.py",
  "lineno": "56",
  "column": "4",
  "slicing": "['    mode = pyndata.uint64()\\n', '    perms = pyndata.BitField(mode, 10)\\n', '    unknown = pyndata.BitField(mode, 2)\\n', '    file_type = pyndata.BitField(mode, 4, enum=PosixType)\\n', '    count = pyndata.uint32()\\n', '    aces = pyndata.array(ZNodeACE, length=count)\\n', '    ZPL_GEN = pyndata.uint64()\\n']",
  "context": "ME = Timestamp()\n    ZPL_CRTIME = Timestamp()\n    ZPL_GEN = pyndata.uint64()\n    ZPL_MODE = Mode()\n    ZPL_SIZE = pyndata.uint6"
 },
 "459": {
  "name": "ZPL_MODE",
  "type": "Mode",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/posix/attributes/__init__.py",
  "lineno": "57",
  "column": "4",
  "slicing": "['    mode = pyndata.uint64()\\n', '    perms = pyndata.BitField(mode, 10)\\n', '    unknown = pyndata.BitField(mode, 2)\\n', '    file_type = pyndata.BitField(mode, 4, enum=PosixType)\\n', '    count = pyndata.uint32()\\n', '    aces = pyndata.array(ZNodeACE, length=count)\\n', '    ZPL_MODE = Mode()\\n']",
  "context": " = Timestamp()\n    ZPL_GEN = pyndata.uint64()\n    ZPL_MODE = Mode()\n    ZPL_SIZE = pyndata.uint64()\n    ZPL_PARENT = p"
 },
 "460": {
  "name": "ZPL_SIZE",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/posix/attributes/__init__.py",
  "lineno": "58",
  "column": "4",
  "slicing": "['    mode = pyndata.uint64()\\n', '    perms = pyndata.BitField(mode, 10)\\n', '    unknown = pyndata.BitField(mode, 2)\\n', '    file_type = pyndata.BitField(mode, 4, enum=PosixType)\\n', '    count = pyndata.uint32()\\n', '    aces = pyndata.array(ZNodeACE, length=count)\\n', '    ZPL_SIZE = pyndata.uint64()\\n']",
  "context": "_GEN = pyndata.uint64()\n    ZPL_MODE = Mode()\n    ZPL_SIZE = pyndata.uint64()\n    ZPL_PARENT = pyndata.uint64()\n    ZPL_LINKS = "
 },
 "461": {
  "name": "ZPL_PARENT",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/posix/attributes/__init__.py",
  "lineno": "59",
  "column": "4",
  "slicing": "['    mode = pyndata.uint64()\\n', '    perms = pyndata.BitField(mode, 10)\\n', '    unknown = pyndata.BitField(mode, 2)\\n', '    file_type = pyndata.BitField(mode, 4, enum=PosixType)\\n', '    count = pyndata.uint32()\\n', '    aces = pyndata.array(ZNodeACE, length=count)\\n', '    ZPL_PARENT = pyndata.uint64()\\n']",
  "context": "MODE = Mode()\n    ZPL_SIZE = pyndata.uint64()\n    ZPL_PARENT = pyndata.uint64()\n    ZPL_LINKS = pyndata.uint64()\n    ZPL_XATTR = p"
 },
 "462": {
  "name": "ZPL_LINKS",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/posix/attributes/__init__.py",
  "lineno": "60",
  "column": "4",
  "slicing": "['    mode = pyndata.uint64()\\n', '    perms = pyndata.BitField(mode, 10)\\n', '    unknown = pyndata.BitField(mode, 2)\\n', '    file_type = pyndata.BitField(mode, 4, enum=PosixType)\\n', '    count = pyndata.uint32()\\n', '    aces = pyndata.array(ZNodeACE, length=count)\\n', '    ZPL_LINKS = pyndata.uint64()\\n']",
  "context": "ta.uint64()\n    ZPL_PARENT = pyndata.uint64()\n    ZPL_LINKS = pyndata.uint64()\n    ZPL_XATTR = pyndata.uint64()\n    ZPL_RDEV = py"
 },
 "463": {
  "name": "ZPL_XATTR",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/posix/attributes/__init__.py",
  "lineno": "61",
  "column": "4",
  "slicing": "['    mode = pyndata.uint64()\\n', '    perms = pyndata.BitField(mode, 10)\\n', '    unknown = pyndata.BitField(mode, 2)\\n', '    file_type = pyndata.BitField(mode, 4, enum=PosixType)\\n', '    count = pyndata.uint32()\\n', '    aces = pyndata.array(ZNodeACE, length=count)\\n', '    ZPL_XATTR = pyndata.uint64()\\n']",
  "context": "ata.uint64()\n    ZPL_LINKS = pyndata.uint64()\n    ZPL_XATTR = pyndata.uint64()\n    ZPL_RDEV = pyndata.uint64()\n    ZPL_FLAGS = py"
 },
 "464": {
  "name": "ZPL_RDEV",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/posix/attributes/__init__.py",
  "lineno": "62",
  "column": "4",
  "slicing": "['    mode = pyndata.uint64()\\n', '    perms = pyndata.BitField(mode, 10)\\n', '    unknown = pyndata.BitField(mode, 2)\\n', '    file_type = pyndata.BitField(mode, 4, enum=PosixType)\\n', '    count = pyndata.uint32()\\n', '    aces = pyndata.array(ZNodeACE, length=count)\\n', '    ZPL_RDEV = pyndata.uint64()\\n']",
  "context": "ata.uint64()\n    ZPL_XATTR = pyndata.uint64()\n    ZPL_RDEV = pyndata.uint64()\n    ZPL_FLAGS = pyndata.uint64()\n    ZPL_UID = pyn"
 },
 "465": {
  "name": "ZPL_FLAGS",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/posix/attributes/__init__.py",
  "lineno": "63",
  "column": "4",
  "slicing": "['    mode = pyndata.uint64()\\n', '    perms = pyndata.BitField(mode, 10)\\n', '    unknown = pyndata.BitField(mode, 2)\\n', '    file_type = pyndata.BitField(mode, 4, enum=PosixType)\\n', '    count = pyndata.uint32()\\n', '    aces = pyndata.array(ZNodeACE, length=count)\\n', '    ZPL_FLAGS = pyndata.uint64()\\n']",
  "context": "data.uint64()\n    ZPL_RDEV = pyndata.uint64()\n    ZPL_FLAGS = pyndata.uint64()\n    ZPL_UID = pyndata.uint64()\n    ZPL_GID = pynda"
 },
 "466": {
  "name": "ZPL_UID",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/posix/attributes/__init__.py",
  "lineno": "64",
  "column": "4",
  "slicing": "['    mode = pyndata.uint64()\\n', '    perms = pyndata.BitField(mode, 10)\\n', '    unknown = pyndata.BitField(mode, 2)\\n', '    file_type = pyndata.BitField(mode, 4, enum=PosixType)\\n', '    count = pyndata.uint32()\\n', '    aces = pyndata.array(ZNodeACE, length=count)\\n', '    ZPL_UID = pyndata.uint64()\\n']",
  "context": "ata.uint64()\n    ZPL_FLAGS = pyndata.uint64()\n    ZPL_UID = pyndata.uint64()\n    ZPL_GID = pyndata.uint64()\n    padding = pynda"
 },
 "467": {
  "name": "ZPL_GID",
  "type": "pyndata.uint64",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/posix/attributes/__init__.py",
  "lineno": "65",
  "column": "4",
  "slicing": "['    mode = pyndata.uint64()\\n', '    perms = pyndata.BitField(mode, 10)\\n', '    unknown = pyndata.BitField(mode, 2)\\n', '    file_type = pyndata.BitField(mode, 4, enum=PosixType)\\n', '    count = pyndata.uint32()\\n', '    aces = pyndata.array(ZNodeACE, length=count)\\n', '    ZPL_GID = pyndata.uint64()\\n']",
  "context": "ndata.uint64()\n    ZPL_UID = pyndata.uint64()\n    ZPL_GID = pyndata.uint64()\n    padding = pyndata.array(pyndata.uint64(), leng"
 },
 "468": {
  "name": "padding",
  "type": "pyndata.array",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/zfs/posix/attributes/__init__.py",
  "lineno": "66",
  "column": "4",
  "slicing": "['    mode = pyndata.uint64()\\n', '    perms = pyndata.BitField(mode, 10)\\n', '    unknown = pyndata.BitField(mode, 2)\\n', '    file_type = pyndata.BitField(mode, 4, enum=PosixType)\\n', '    count = pyndata.uint32()\\n', '    aces = pyndata.array(ZNodeACE, length=count)\\n', '    padding = pyndata.array(pyndata.uint64(), length=4)\\n']",
  "context": "ndata.uint64()\n    ZPL_GID = pyndata.uint64()\n    padding = pyndata.array(pyndata.uint64(), length=4)\n    acl = ZNodeACL()\n\n\ndef FixedAttributes(data):\n"
 },
 "469": {
  "name": "acl",
  "type": "ZNodeACL",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/posix/attributes/__init__.py",
  "lineno": "67",
  "column": "4",
  "slicing": "['    mode = pyndata.uint64()\\n', '    perms = pyndata.BitField(mode, 10)\\n', '    unknown = pyndata.BitField(mode, 2)\\n', '    file_type = pyndata.BitField(mode, 4, enum=PosixType)\\n', '    count = pyndata.uint32()\\n', '    aces = pyndata.array(ZNodeACE, length=count)\\n', '    acl = ZNodeACL()\\n']",
  "context": "g = pyndata.array(pyndata.uint64(), length=4)\n    acl = ZNodeACL()\n\n\ndef FixedAttributes(data):\n    attrs = DefaultAt"
 },
 "470": {
  "name": "attrs",
  "type": "DefaultAttrsV1",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/zfs/posix/attributes/__init__.py",
  "lineno": "71",
  "column": "4",
  "slicing": "['    mode = pyndata.uint64()\\n', '    perms = pyndata.BitField(mode, 10)\\n', '    unknown = pyndata.BitField(mode, 2)\\n', '    file_type = pyndata.BitField(mode, 4, enum=PosixType)\\n', '    count = pyndata.uint32()\\n', '    aces = pyndata.array(ZNodeACE, length=count)\\n', '    attrs = DefaultAttrsV1(data)\\n', '    return attrs.field_items\\n']",
  "context": "acl = ZNodeACL()\n\n\ndef FixedAttributes(data):\n    attrs = DefaultAttrsV1(data)\n    return attrs.field_items\n\n\ndef POSIXAttrs_for("
 },
 "471": {
  "name": "checksums",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/tests/test_checksums.py",
  "lineno": "6",
  "column": "0",
  "slicing": "['checksums = {\\n', '@pytest.mark.parametrize(\"mode\", checksums)\\n', '    assert zfile.dnode.blkptr[0].checksum_type == checksums[mode]\\n']",
  "context": "omplex_zpool\n\nfrom zfs.constants import Checksum\n\nchecksums = {\n    'fletcher2': Checksum.FLETCHER_2,\n    'fletche"
 },
 "472": {
  "name": "zfile",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/tests/test_checksums.py",
  "lineno": "16",
  "column": "4",
  "slicing": "['    root_dataset = complex_zpool.root_dataset\\n', '    zfile = root_dataset[mode][mode]\\n', '    assert zfile.dnode.blkptr[0].checksum_type == checksums[mode]\\n', '    zfile.read()\\n']",
  "context": "    root_dataset = complex_zpool.root_dataset\n    zfile = root_dataset[mode][mode]\n    assert zfile.dnode.blkptr[0].checksum_type == "
 },
 "473": {
  "name": "c",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/tests/test_posix.py",
  "lineno": "6",
  "column": "4",
  "slicing": "[\"    directory = zpool.open('/d1/d2/d3')\\n\", \"    c = directory['c']\\n\", \"    assert c.attrs['ZPL_UID'] == 123\\n\", \"    assert c.attrs['ZPL_GID'] == 456\\n\", \"    directory = zpool.open('/d1/d2/d3')\\n\", \"    d = directory['d']\\n\", \"    assert d.attrs['ZPL_MODE'].perms == 0o1765\\n\"]",
  "context": "ool):\n    directory = zpool.open('/d1/d2/d3')\n    c = directory['c']\n    assert c.attrs['ZPL_UID'] == 123\n    assert c."
 },
 "474": {
  "name": "d",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/tests/test_posix.py",
  "lineno": "13",
  "column": "4",
  "slicing": "[\"    directory = zpool.open('/d1/d2/d3')\\n\", \"    c = directory['c']\\n\", \"    assert c.attrs['ZPL_UID'] == 123\\n\", \"    assert c.attrs['ZPL_GID'] == 456\\n\", \"    directory = zpool.open('/d1/d2/d3')\\n\", \"    d = directory['d']\\n\", \"    assert d.attrs['ZPL_MODE'].perms == 0o1765\\n\"]",
  "context": "ool):\n    directory = zpool.open('/d1/d2/d3')\n    d = directory['d']\n    assert d.attrs['ZPL_MODE'].perms == 0o1765\n"
 },
 "475": {
  "name": "features",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/tests/test_features.py",
  "lineno": "10",
  "column": "4",
  "slicing": "['    zp = pool.Pool(feature_pools[feature])\\n', \"    features = zp.vdevs[0].best_label[b'features_for_read']\\n\", '    assert feature in features\\n']",
  "context": "):\n    zp = pool.Pool(feature_pools[feature])\n    features = zp.vdevs[0].best_label[b'features_for_read']\n    assert feature in features\n"
 },
 "476": {
  "name": "feature_pools",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/tests/fixtures.py",
  "lineno": "25",
  "column": "0",
  "slicing": "['feature_pools = {\\n', '] + list(feature_pools.values()) + old_version_pools, ids=generate_test_name)\\n']",
  "context": "        return generate_test_name(param[0].devs)\n\nfeature_pools = {\n    b'com.delphix:extensible_dataset':[filedev.Fil"
 },
 "477": {
  "name": "old_version_pools",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/tests/fixtures.py",
  "lineno": "32",
  "column": "0",
  "slicing": "['old_version_pools = []\\n', \"    old_version_pools.append([filedev.FileDev(fixture('versioned/zversion_{}'.format(version)))])\\n\", '] + list(feature_pools.values()) + old_version_pools, ids=generate_test_name)\\n']",
  "context": "dev.FileDev(fixture('feature_large_blocks'))],\n}\n\nold_version_pools = []\nfor version in range(1, 29):\n    old_version_pools"
 },
 "478": {
  "name": "compresion_modes",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/tests/test_compression.py",
  "lineno": "6",
  "column": "0",
  "slicing": "['compresion_modes = {\\n', '@pytest.mark.parametrize(\"mode\", compresion_modes)\\n', '    assert zfile.dnode.blkptr[0].compression == compresion_modes[mode]\\n']",
  "context": "c_fixture\n\nfrom zfs.constants import Compression\n\ncompresion_modes = {\n    'gzip-1': Compression.GZIP_1,\n    'gzip-2': Co"
 },
 "479": {
  "name": "zfile",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/tests/test_compression.py",
  "lineno": "29",
  "column": "4",
  "slicing": "['compresion_modes = {\\n', '@pytest.mark.parametrize(\"mode\", compresion_modes)\\n', '    root_dataset = complex_zpool.root_dataset\\n', '    zfile = root_dataset[mode][mode]\\n', '    assert zfile.dnode.blkptr[0].compression == compresion_modes[mode]\\n', '    result = zfile.read() == file_contents\\n', '    assert result\\n', '    root_dataset = lz4_zpool.root_dataset\\n', \"    mode = 'lz4'\\n\", '    zfile = root_dataset[mode][mode]\\n', '    assert zfile.dnode.blkptr[0].compression == Compression.LZ4\\n', '    result = zfile.read() == file_contents\\n', '    assert result\\n']",
  "context": "    root_dataset = complex_zpool.root_dataset\n    zfile = root_dataset[mode][mode]\n    assert zfile.dnode.blkptr[0].compression == co"
 },
 "480": {
  "name": "result",
  "type": "bool",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "zfsp/tests/test_compression.py",
  "lineno": "31",
  "column": "4",
  "slicing": "['compresion_modes = {\\n', '@pytest.mark.parametrize(\"mode\", compresion_modes)\\n', '    root_dataset = complex_zpool.root_dataset\\n', '    zfile = root_dataset[mode][mode]\\n', '    assert zfile.dnode.blkptr[0].compression == compresion_modes[mode]\\n', '    result = zfile.read() == file_contents\\n', '    assert result\\n', '    root_dataset = lz4_zpool.root_dataset\\n', \"    mode = 'lz4'\\n\", '    zfile = root_dataset[mode][mode]\\n', '    assert zfile.dnode.blkptr[0].compression == Compression.LZ4\\n', '    result = zfile.read() == file_contents\\n', '    assert result\\n']",
  "context": "kptr[0].compression == compresion_modes[mode]\n    result = zfile.read() == file_contents\n    assert result\n\n\ndef test_lz4_compression(lz4_z"
 },
 "481": {
  "name": "zfile",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/tests/test_compression.py",
  "lineno": "38",
  "column": "4",
  "slicing": "['compresion_modes = {\\n', '@pytest.mark.parametrize(\"mode\", compresion_modes)\\n', '    root_dataset = complex_zpool.root_dataset\\n', '    zfile = root_dataset[mode][mode]\\n', '    assert zfile.dnode.blkptr[0].compression == compresion_modes[mode]\\n', '    result = zfile.read() == file_contents\\n', '    assert result\\n', '    root_dataset = lz4_zpool.root_dataset\\n', \"    mode = 'lz4'\\n\", '    zfile = root_dataset[mode][mode]\\n', '    assert zfile.dnode.blkptr[0].compression == Compression.LZ4\\n', '    result = zfile.read() == file_contents\\n', '    assert result\\n']",
  "context": "set = lz4_zpool.root_dataset\n    mode = 'lz4'\n    zfile = root_dataset[mode][mode]\n    assert zfile.dnode.blkptr[0].compression == Co"
 },
 "482": {
  "name": "result",
  "type": "bool",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "zfsp/tests/test_compression.py",
  "lineno": "40",
  "column": "4",
  "slicing": "['compresion_modes = {\\n', '@pytest.mark.parametrize(\"mode\", compresion_modes)\\n', '    root_dataset = complex_zpool.root_dataset\\n', '    zfile = root_dataset[mode][mode]\\n', '    assert zfile.dnode.blkptr[0].compression == compresion_modes[mode]\\n', '    result = zfile.read() == file_contents\\n', '    assert result\\n', '    root_dataset = lz4_zpool.root_dataset\\n', \"    mode = 'lz4'\\n\", '    zfile = root_dataset[mode][mode]\\n', '    assert zfile.dnode.blkptr[0].compression == Compression.LZ4\\n', '    result = zfile.read() == file_contents\\n', '    assert result\\n']",
  "context": "node.blkptr[0].compression == Compression.LZ4\n    result = zfile.read() == file_contents\n    assert result\n"
 },
 "483": {
  "name": "xrange",
  "type": "range",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/array.py",
  "lineno": "7",
  "column": "4",
  "slicing": "['    xrange = range\\n', '        for x in xrange(self.get_length(_struct)):\\n']",
  "context": "ruct\nimport sys\n\nif sys.version_info[0] == 3:\n    xrange = range\n\nfrom .field import Field\nfrom .error import error"
 },
 "484": {
  "name": "kind",
  "type": "structure.StructField",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/array.py",
  "lineno": "35",
  "column": "12",
  "slicing": "['            kind = StructField(kind)\\n', '        self.kind = kind\\n']",
  "context": "   if issubclass(type(kind), Struct):\n            kind = StructField(kind)\n        self.kind = kind\n\n        self.length = le"
 },
 "485": {
  "name": "out",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/array.py",
  "lineno": "46",
  "column": "8",
  "slicing": "['        out = []\\n', '            out.append(self.kind.unpack(reader, _struct))\\n', '        return out\\n']",
  "context": ")\n\n    def unpack(self, reader, _struct):\n        out = []\n        for x in xrange(self.get_length(_struct)):"
 },
 "486": {
  "name": "__DEFAULT__",
  "type": "None",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/field.py",
  "lineno": "27",
  "column": "4",
  "slicing": "['    __DEFAULT__ = None\\n']",
  "context": "he default value for this field.\n    \n    '''\n    __DEFAULT__ = None\n    __SHOW__ = True\n\n    def __init__(self, defaul"
 },
 "487": {
  "name": "__SHOW__",
  "type": "bool",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/field.py",
  "lineno": "28",
  "column": "4",
  "slicing": "['    __SHOW__ = True\\n']",
  "context": "is field.\n    \n    '''\n    __DEFAULT__ = None\n    __SHOW__ = True\n\n    def __init__(self, default=None):\n        sel"
 },
 "488": {
  "name": "__SHOW__",
  "type": "bool",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/bitfield.py",
  "lineno": "24",
  "column": "4",
  "slicing": "['    __SHOW__ = True\\n']",
  "context": "fore returning them.\n\n    '''\n    default = 0\n    __SHOW__ = True\n    def __init__(self, field, size, shift=None, en"
 },
 "489": {
  "name": "field",
  "type": "pyndata.uint16",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/bitfield.py",
  "lineno": "25",
  "column": "23",
  "slicing": "['    def __init__(self, field, size, shift=None, enum=None):\\n']",
  "context": "lt = 0\n    __SHOW__ = True\n    def __init__(self, field, size, shift=None, enum=None):\n        if shift == None:\n            shift = fiel"
 },
 "490": {
  "name": "value",
  "type": "int",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/bitfield.py",
  "lineno": "44",
  "column": "8",
  "slicing": "['            shift = field.current_offset\\n', '        self.mask = ((1 << size)-1) << shift\\n', '        self.shift = shift\\n', '        value = self.field.__get__(obj)\\n', '        value = (value & self.mask) >> self.shift\\n', '            return self.enum(value)\\n', '            return value\\n', '        value = int(value)\\n', '        result |= ((value << self.shift) & self.mask)\\n', '        self.field.__set__(obj, result)\\n']",
  "context": "value\n\n    def __set__(self, obj, value):\n        value = int(value)\n        result = self.field.__get__(obj) & ((~self"
 },
 "491": {
  "name": "__ENDIAN__",
  "type": "None",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/integer.py",
  "lineno": "23",
  "column": "4",
  "slicing": "['    __ENDIAN__ = None\\n']",
  "context": "   '''\n    __TYPE__ = 'b'\n    __DEFAULT__ = 0\n    __ENDIAN__ = None\n\n    def __init__(self, endian=None, enum=None, *a"
 },
 "492": {
  "name": "value",
  "type": "int",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/integer.py",
  "lineno": "39",
  "column": "8",
  "slicing": "['        value = int(value)\\n', '        return struct.pack(self.endian(_struct)+self.__TYPE__, value)\\n', '            return self.enum(value)\\n', '            return value\\n']",
  "context": " '<'\n\n    def pack(self, value, _struct):\n        value = int(value)\n        return struct.pack(self.endian(_struct)+se"
 },
 "493": {
  "name": "value",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/integer.py",
  "lineno": "48",
  "column": "8",
  "slicing": "['        value = int(value)\\n', '        return struct.pack(self.endian(_struct)+self.__TYPE__, value)\\n', '        data = reader.read(self.size)\\n', '        if len(data) != self.size:\\n', '                self.size, repr(data))\\n', '        value = struct.unpack(self.endian(_struct)+self.__TYPE__, data)[0]\\n', '            return self.enum(value)\\n', '            return value\\n']",
  "context": "     self.size, repr(data))\n            )\n        value = struct.unpack(self.endian(_struct)+self.__TYPE__, data)[0]\n        try:\n            return self.enum(value)\n "
 },
 "494": {
  "name": "__all__",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/integer.py",
  "lineno": "64",
  "column": "0",
  "slicing": "['__all__ = [\\n']",
  "context": "PE__ = 'I'\nclass uint64(integer): __TYPE__ = 'Q'\n\n__all__ = [\n    'integer',\n    'int8',\n    'int16',\n    'int32"
 },
 "495": {
  "name": "cls",
  "type": "structure.StructMeta",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/structure.py",
  "lineno": "32",
  "column": "16",
  "slicing": "['    def __new__(cls, cls_name, bases, attrs):\\n']",
  "context": " from a class definition.\n    '''\n    def __new__(cls, cls_name, bases, attrs):\n        fields = []\n        bitfields = []\n       "
 },
 "496": {
  "name": "fields",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/structure.py",
  "lineno": "33",
  "column": "8",
  "slicing": "['        fields = []\\n', '        bitfields = []\\n', '        field_defaults = {}\\n', '        for name, field in attrs.items():\\n', '            if isinstance(field, Struct):\\n', '                field = StructField(field)\\n', '                attrs[name] = field\\n', '            if isinstance(field, Field):\\n', '                field.name = name\\n', \"                if name[0] == '_':\\n\", '                    field.__SHOW__ = False\\n', '                field_defaults[name] = field.default\\n', '                fields.append(field)\\n', '            elif isinstance(field, BitField):\\n', '                field.name = name\\n', \"                if name[0] == '_':\\n\", '                    field.__SHOW__ = False\\n', '                bitfields.append(field)\\n', '        fields.sort(key=lambda x:x.__index__)\\n', '        new_cls = type.__new__(cls, cls_name, bases, attrs)\\n', '        new_cls.field_defaults = field_defaults\\n', '        new_cls.fields = fields\\n', '        new_cls.bitfields = bitfields\\n', '        return new_cls\\n', '        for k, v in kwargs.items():\\n', '            if hasattr(self, k):\\n', '                setattr(self, k, v)\\n', '                raise AttributeError(\"struct {} has no attribute {}\".format(self.__class__.__name__, k))\\n', \"        fields = [field.name+'='+repr(getattr(self, field.name)) for field in self.fields if field.__SHOW__]\\n\", \"        fields.extend(field.name+'='+repr(field.__get__(self)) for field in self.bitfields if field.__SHOW__)\\n\", \"        ret = '{0}({1})'.format(type(self).__name__, ', '.join(fields))\\n\", '        return ret\\n', '            out.append(field.pack(field.__get__(self), self))\\n', '            setattr(self, field.name, field.unpack(reader, self))\\n']",
  "context": "def __new__(cls, cls_name, bases, attrs):\n        fields = []\n        bitfields = []\n        field_defaults = {}"
 },
 "497": {
  "name": "bitfields",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/structure.py",
  "lineno": "34",
  "column": "8",
  "slicing": "['        bitfields = []\\n', '                bitfields.append(field)\\n', '        new_cls.bitfields = bitfields\\n']",
  "context": "_name, bases, attrs):\n        fields = []\n        bitfields = []\n        field_defaults = {}\n        for name, fiel"
 },
 "498": {
  "name": "field_defaults",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/structure.py",
  "lineno": "35",
  "column": "8",
  "slicing": "['        field_defaults = {}\\n', '                field_defaults[name] = field.default\\n', '        new_cls.field_defaults = field_defaults\\n']",
  "context": "       fields = []\n        bitfields = []\n        field_defaults = {}\n        for name, field in attrs.items():\n        "
 },
 "499": {
  "name": "field",
  "type": "structfield.StructField",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/structure.py",
  "lineno": "38",
  "column": "16",
  "slicing": "['        fields = []\\n', '        bitfields = []\\n', '        field_defaults = {}\\n', '        for name, field in attrs.items():\\n', '            if isinstance(field, Struct):\\n', '                field = StructField(field)\\n', '                attrs[name] = field\\n', '            if isinstance(field, Field):\\n', '                field.name = name\\n', \"                if name[0] == '_':\\n\", '                    field.__SHOW__ = False\\n', '                field_defaults[name] = field.default\\n', '                fields.append(field)\\n', '            elif isinstance(field, BitField):\\n', '                field.name = name\\n', \"                if name[0] == '_':\\n\", '                    field.__SHOW__ = False\\n', '                bitfields.append(field)\\n', '        fields.sort(key=lambda x:x.__index__)\\n', '        new_cls = type.__new__(cls, cls_name, bases, attrs)\\n', '        new_cls.field_defaults = field_defaults\\n', '        new_cls.fields = fields\\n', '        new_cls.bitfields = bitfields\\n', '        return new_cls\\n', '        for k, v in kwargs.items():\\n', '            if hasattr(self, k):\\n', '                setattr(self, k, v)\\n', '                raise AttributeError(\"struct {} has no attribute {}\".format(self.__class__.__name__, k))\\n', \"        fields = [field.name+'='+repr(getattr(self, field.name)) for field in self.fields if field.__SHOW__]\\n\", \"        fields.extend(field.name+'='+repr(field.__get__(self)) for field in self.bitfields if field.__SHOW__)\\n\", \"        ret = '{0}({1})'.format(type(self).__name__, ', '.join(fields))\\n\", '        return ret\\n', '            out.append(field.pack(field.__get__(self), self))\\n', '            setattr(self, field.name, field.unpack(reader, self))\\n']",
  "context": "    if isinstance(field, Struct):\n                field = StructField(field)\n                attrs[name] = field\n            if"
 },
 "500": {
  "name": "__metaclass__",
  "type": "structure.StructMeta",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/structure.py",
  "lineno": "66",
  "column": "4",
  "slicing": "['        fields = []\\n', '        bitfields = []\\n', '        field_defaults = {}\\n', '        for name, field in attrs.items():\\n', '            if isinstance(field, Struct):\\n', '                field = StructField(field)\\n', '                attrs[name] = field\\n', '            if isinstance(field, Field):\\n', '                field.name = name\\n', \"                if name[0] == '_':\\n\", '                    field.__SHOW__ = False\\n', '                field_defaults[name] = field.default\\n', '                fields.append(field)\\n', '            elif isinstance(field, BitField):\\n', '                field.name = name\\n', \"                if name[0] == '_':\\n\", '                    field.__SHOW__ = False\\n', '                bitfields.append(field)\\n', '        fields.sort(key=lambda x:x.__index__)\\n', '        new_cls = type.__new__(cls, cls_name, bases, attrs)\\n', '        new_cls.field_defaults = field_defaults\\n', '        new_cls.fields = fields\\n', '        new_cls.bitfields = bitfields\\n', '        return new_cls\\n', '    __metaclass__ = StructMeta\\n', '        for k, v in kwargs.items():\\n', '            if hasattr(self, k):\\n', '                setattr(self, k, v)\\n', '                raise AttributeError(\"struct {} has no attribute {}\".format(self.__class__.__name__, k))\\n', \"        fields = [field.name+'='+repr(getattr(self, field.name)) for field in self.fields if field.__SHOW__]\\n\", \"        fields.extend(field.name+'='+repr(field.__get__(self)) for field in self.bitfields if field.__SHOW__)\\n\", \"        ret = '{0}({1})'.format(type(self).__name__, ', '.join(fields))\\n\", '        return ret\\n', '            out.append(field.pack(field.__get__(self), self))\\n', '            setattr(self, field.name, field.unpack(reader, self))\\n']",
  "context": "r to :meth:`pack` or :meth:`unpack`.\n\n    '''\n    __metaclass__ = StructMeta\n    __ENDIAN__ = 'little'\n\n    def __init__(self, "
 },
 "501": {
  "name": "fields",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/structure.py",
  "lineno": "84",
  "column": "8",
  "slicing": "['        fields = []\\n', '        bitfields = []\\n', '        field_defaults = {}\\n', '        for name, field in attrs.items():\\n', '            if isinstance(field, Struct):\\n', '                field = StructField(field)\\n', '                attrs[name] = field\\n', '            if isinstance(field, Field):\\n', '                field.name = name\\n', \"                if name[0] == '_':\\n\", '                    field.__SHOW__ = False\\n', '                field_defaults[name] = field.default\\n', '                fields.append(field)\\n', '            elif isinstance(field, BitField):\\n', '                field.name = name\\n', \"                if name[0] == '_':\\n\", '                    field.__SHOW__ = False\\n', '                bitfields.append(field)\\n', '        fields.sort(key=lambda x:x.__index__)\\n', '        new_cls = type.__new__(cls, cls_name, bases, attrs)\\n', '        new_cls.field_defaults = field_defaults\\n', '        new_cls.fields = fields\\n', '        new_cls.bitfields = bitfields\\n', '        return new_cls\\n', '        for k, v in kwargs.items():\\n', '            if hasattr(self, k):\\n', '                setattr(self, k, v)\\n', '                raise AttributeError(\"struct {} has no attribute {}\".format(self.__class__.__name__, k))\\n', \"        fields = [field.name+'='+repr(getattr(self, field.name)) for field in self.fields if field.__SHOW__]\\n\", \"        fields.extend(field.name+'='+repr(field.__get__(self)) for field in self.bitfields if field.__SHOW__)\\n\", \"        ret = '{0}({1})'.format(type(self).__name__, ', '.join(fields))\\n\", '        return ret\\n', '            out.append(field.pack(field.__get__(self), self))\\n', '            setattr(self, field.name, field.unpack(reader, self))\\n']",
  "context": ".unpack(initial)\n\n    def __repr__(self):\n        fields = [field.name+'='+repr(getattr(self, field.name)) for field in self.fields if field.__SHOW__]\n        fields.extend(field.name+'='+repr(field.__"
 },
 "502": {
  "name": "out",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/structure.py",
  "lineno": "93",
  "column": "8",
  "slicing": "['        out = []\\n', '            out.append(field.pack(field.__get__(self), self))\\n', \"        return b''.join(out)\\n\"]",
  "context": "s the resulting :class:`str`.\n        '''\n        out = []\n        for field in self.fields:\n            out."
 },
 "503": {
  "name": "reader",
  "type": "StringIO.StringIO",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/structure.py",
  "lineno": "103",
  "column": "12",
  "slicing": "['        fields = []\\n', '        bitfields = []\\n', '        field_defaults = {}\\n', '        for name, field in attrs.items():\\n', '            if isinstance(field, Struct):\\n', '                field = StructField(field)\\n', '                attrs[name] = field\\n', '            if isinstance(field, Field):\\n', '                field.name = name\\n', \"                if name[0] == '_':\\n\", '                    field.__SHOW__ = False\\n', '                field_defaults[name] = field.default\\n', '                fields.append(field)\\n', '            elif isinstance(field, BitField):\\n', '                field.name = name\\n', \"                if name[0] == '_':\\n\", '                    field.__SHOW__ = False\\n', '                bitfields.append(field)\\n', '        fields.sort(key=lambda x:x.__index__)\\n', '        new_cls = type.__new__(cls, cls_name, bases, attrs)\\n', '        new_cls.field_defaults = field_defaults\\n', '        new_cls.fields = fields\\n', '        new_cls.bitfields = bitfields\\n', '        return new_cls\\n', '        for k, v in kwargs.items():\\n', '            if hasattr(self, k):\\n', '                setattr(self, k, v)\\n', '                raise AttributeError(\"struct {} has no attribute {}\".format(self.__class__.__name__, k))\\n', \"        fields = [field.name+'='+repr(getattr(self, field.name)) for field in self.fields if field.__SHOW__]\\n\", \"        fields.extend(field.name+'='+repr(field.__get__(self)) for field in self.bitfields if field.__SHOW__)\\n\", \"        ret = '{0}({1})'.format(type(self).__name__, ', '.join(fields))\\n\", '        return ret\\n', '        out = []\\n', '        for field in self.fields:\\n', '            out.append(field.pack(field.__get__(self), self))\\n', \"        return b''.join(out)\\n\", '            reader = StringIO(reader)\\n', '            setattr(self, field.name, field.unpack(reader, self))\\n']",
  "context": " if isinstance(reader, (str, bytes)):\n            reader = StringIO(reader)\n        for field in self.fields:\n            seta"
 },
 "504": {
  "name": "__all__",
  "type": "list",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/__init__.py",
  "lineno": "21",
  "column": "0",
  "slicing": "['__all__ = [\\n', 'for name in __all__:\\n', '    o = globals()[name]\\n', '    if isinstance(o, type):\\n', \"        o.__module__ = 'pyndata'\\n\"]",
  "context": "truct\nfrom .variablelength import VariableLength\n\n__all__ = [\n    '__nextfield__',\n    'array',\n    'BitField',\n"
 },
 "505": {
  "name": "o",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/__init__.py",
  "lineno": "46",
  "column": "4",
  "slicing": "['__all__ = [\\n', 'for name in __all__:\\n', '    o = globals()[name]\\n', '    if isinstance(o, type):\\n', \"        o.__module__ = 'pyndata'\\n\"]",
  "context": "uint32',\n    'uint64'\n]\n\nfor name in __all__:\n    o = globals()[name]\n    if isinstance(o, type):\n        o.__module__ ="
 },
 "506": {
  "name": "value",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/nullstring.py",
  "lineno": "46",
  "column": "8",
  "slicing": "['                value = value.encode(self.encoding)\\n', '            if len(value) > self.max_length:\\n', '                raise ValueError(\"String length {} exceeds this field\\'s maximum length {}\".format(len(value), self.max_length))\\n', '            if len(value) >= self.max_length:\\n', '                raise ValueError(\"String length {} exceeds this field\\'s maximum length {}\".format(len(value), self.max_length))\\n', \"        value = (value+b'\\\\0')[:self.max_length]\\n\", '            pad = self.max_length - len(value)\\n', \"            value += b'\\\\0'*pad\\n\", '        return value\\n', '            value = reader.read(self.max_length)\\n', \"            value = [b'']\\n\", '            i = 0\\n', '            m = self.max_length + (1 if self.allow_max else 0)\\n', \"            while value[-1] != '\\\\0' and i < m:\\n\", '                value.append(reader.read(1))\\n', '                i += 1\\n', \"            value = b''.join(value)\\n\", '            print(value)\\n', \"        value = value.rstrip(b'\\\\0')\\n\", '            value = value.decode(self.encoding)\\n', '        return value\\n']",
  "context": " {}\".format(len(value), self.max_length))\n        value = (value+b'\\0')[:self.max_length]\n        if self.padded:\n            pad = self.max"
 },
 "507": {
  "name": "pad",
  "type": "int",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/nullstring.py",
  "lineno": "48",
  "column": "12",
  "slicing": "['                value = value.encode(self.encoding)\\n', '            if len(value) > self.max_length:\\n', '                raise ValueError(\"String length {} exceeds this field\\'s maximum length {}\".format(len(value), self.max_length))\\n', '            if len(value) >= self.max_length:\\n', '                raise ValueError(\"String length {} exceeds this field\\'s maximum length {}\".format(len(value), self.max_length))\\n', \"        value = (value+b'\\\\0')[:self.max_length]\\n\", '            pad = self.max_length - len(value)\\n', \"            value += b'\\\\0'*pad\\n\", '        return value\\n', '            value = reader.read(self.max_length)\\n', \"            value = [b'']\\n\", '            i = 0\\n', '            m = self.max_length + (1 if self.allow_max else 0)\\n', \"            while value[-1] != '\\\\0' and i < m:\\n\", '                value.append(reader.read(1))\\n', '                i += 1\\n', \"            value = b''.join(value)\\n\", '            print(value)\\n', \"        value = value.rstrip(b'\\\\0')\\n\", '            value = value.decode(self.encoding)\\n', '        return value\\n']",
  "context": "f.max_length]\n        if self.padded:\n            pad = self.max_length - len(value)\n            value += b'\\0'*pad\n        return valu"
 },
 "508": {
  "name": "value",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/nullstring.py",
  "lineno": "56",
  "column": "12",
  "slicing": "['                value = value.encode(self.encoding)\\n', '            if len(value) > self.max_length:\\n', '                raise ValueError(\"String length {} exceeds this field\\'s maximum length {}\".format(len(value), self.max_length))\\n', '            if len(value) >= self.max_length:\\n', '                raise ValueError(\"String length {} exceeds this field\\'s maximum length {}\".format(len(value), self.max_length))\\n', \"        value = (value+b'\\\\0')[:self.max_length]\\n\", '            pad = self.max_length - len(value)\\n', \"            value += b'\\\\0'*pad\\n\", '        return value\\n', '            value = reader.read(self.max_length)\\n', \"            value = [b'']\\n\", '            i = 0\\n', '            m = self.max_length + (1 if self.allow_max else 0)\\n', \"            while value[-1] != '\\\\0' and i < m:\\n\", '                value.append(reader.read(1))\\n', '                i += 1\\n', \"            value = b''.join(value)\\n\", '            print(value)\\n', \"        value = value.rstrip(b'\\\\0')\\n\", '            value = value.decode(self.encoding)\\n', '        return value\\n']",
  "context": "r.read(self.max_length)\n        else:\n            value = [b'']\n            i = 0\n            m = self.max_length "
 },
 "509": {
  "name": "real_field",
  "type": "structfield.StructField",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/conditional.py",
  "lineno": "12",
  "column": "12",
  "slicing": "['            real_field = StructField(real_field)\\n', '        self.real_field = real_field\\n', '        self.default = real_field.default\\n']",
  "context": "issubclass(type(real_field), Struct):\n            real_field = StructField(real_field)\n\n        self.func = func\n        self.real_field "
 },
 "510": {
  "name": "cf",
  "type": "ConditionalField",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/conditional.py",
  "lineno": "32",
  "column": "8",
  "slicing": "['            real_field = StructField(real_field)\\n', '        self.real_field = real_field\\n', '        self.default = real_field.default\\n', '        cf = ConditionalField(f, field)\\n', '        return cf\\n']",
  "context": "f conditional(field):\n    def wrapper(f):\n        cf = ConditionalField(f, field)\n        return cf\n    return wrapper\n"
 },
 "511": {
  "name": "_a",
  "type": "pyndata.uint8",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/tests/test_struct_repr.py",
  "lineno": "6",
  "column": "4",
  "slicing": "['    _a = pyndata.uint8()\\n']",
  "context": "est\n\nimport pyndata\n\nclass S(pyndata.Struct):\n    _a = pyndata.uint8()\n    b = pyndata.uint8()\n    c = pyndata.BitField(b"
 },
 "512": {
  "name": "b",
  "type": "pyndata.uint8",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/tests/test_struct_repr.py",
  "lineno": "7",
  "column": "4",
  "slicing": "['    b = pyndata.uint8()\\n', '    c = pyndata.BitField(b, 1)\\n', '    _d = pyndata.BitField(b, 1)\\n']",
  "context": "s S(pyndata.Struct):\n    _a = pyndata.uint8()\n    b = pyndata.uint8()\n    c = pyndata.BitField(b, 1)\n    _d = pyndata.Bi"
 },
 "513": {
  "name": "c",
  "type": "bitfield.BitField",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/tests/test_struct_repr.py",
  "lineno": "8",
  "column": "4",
  "slicing": "['    b = pyndata.uint8()\\n', '    c = pyndata.BitField(b, 1)\\n', '    _d = pyndata.BitField(b, 1)\\n']",
  "context": " _a = pyndata.uint8()\n    b = pyndata.uint8()\n    c = pyndata.BitField(b, 1)\n    _d = pyndata.BitField(b, 1)\n\ndef test_default_"
 },
 "514": {
  "name": "_d",
  "type": "bitfield.BitField",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/tests/test_struct_repr.py",
  "lineno": "9",
  "column": "4",
  "slicing": "['    b = pyndata.uint8()\\n', '    c = pyndata.BitField(b, 1)\\n', '    _d = pyndata.BitField(b, 1)\\n']",
  "context": "yndata.uint8()\n    c = pyndata.BitField(b, 1)\n    _d = pyndata.BitField(b, 1)\n\ndef test_default_hidden():\n    x = S()\n    a = re"
 },
 "515": {
  "name": "x",
  "type": "S",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_struct_repr.py",
  "lineno": "12",
  "column": "4",
  "slicing": "['    b = pyndata.uint8()\\n', '    c = pyndata.BitField(b, 1)\\n', '    _d = pyndata.BitField(b, 1)\\n', '    x = S()\\n', '    a = repr(x)\\n', '    assert a == \"S(b=0, c=0)\"\\n']",
  "context": "ta.BitField(b, 1)\n\ndef test_default_hidden():\n    x = S()\n    a = repr(x)\n    assert a == \"S(b=0, c=0)\"\n"
 },
 "516": {
  "name": "a",
  "type": "repr",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_struct_repr.py",
  "lineno": "13",
  "column": "4",
  "slicing": "['    b = pyndata.uint8()\\n', '    c = pyndata.BitField(b, 1)\\n', '    _d = pyndata.BitField(b, 1)\\n', '    x = S()\\n', '    a = repr(x)\\n', '    assert a == \"S(b=0, c=0)\"\\n']",
  "context": "b, 1)\n\ndef test_default_hidden():\n    x = S()\n    a = repr(x)\n    assert a == \"S(b=0, c=0)\"\n"
 },
 "517": {
  "name": "str1",
  "type": "nullstring.nullstring",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/tests/test_nullstring.py",
  "lineno": "8",
  "column": "4",
  "slicing": "['    str1 = pyndata.nullstring(max_length=4)\\n']",
  "context": "ndata\n\nclass NullStringTests(pyndata.Struct):\n    str1 = pyndata.nullstring(max_length=4)\n    str2 = pyndata.nullstring(max_length=4, padded"
 },
 "518": {
  "name": "str2",
  "type": "nullstring.nullstring",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/tests/test_nullstring.py",
  "lineno": "9",
  "column": "4",
  "slicing": "['    str2 = pyndata.nullstring(max_length=4, padded=True)\\n']",
  "context": ":\n    str1 = pyndata.nullstring(max_length=4)\n    str2 = pyndata.nullstring(max_length=4, padded=True)\n    str3 = pyndata.nullstring(max_length=4, allow_"
 },
 "519": {
  "name": "str3",
  "type": "nullstring.nullstring",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/tests/test_nullstring.py",
  "lineno": "10",
  "column": "4",
  "slicing": "['    str3 = pyndata.nullstring(max_length=4, allow_max=True)\\n']",
  "context": "pyndata.nullstring(max_length=4, padded=True)\n    str3 = pyndata.nullstring(max_length=4, allow_max=True)\n\ndef test_null_string_pack():\n    x = NullStringTe"
 },
 "520": {
  "name": "x",
  "type": "NullStringTests",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_nullstring.py",
  "lineno": "13",
  "column": "4",
  "slicing": "['    x = NullStringTests()\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\0\\\\0\\\\0\\\\0\\\\0\\\\0'\\n\", '    x = NullStringTests()\\n', \"    x.str1 = 'asdf'\\n\", '        x.pack()\\n', '    x = NullStringTests()\\n', \"    x.str3 = 'asdfg'\\n\", '        x.pack()\\n', '    x = NullStringTests()\\n', \"    x.unpack(b'asd\\\\x00as\\\\x00\\\\x001234')\\n\", \"    assert x.str1 == 'asd'\\n\", \"    assert x.str2 == 'as'\\n\", \"    assert x.str3 == '1234'\\n\", '    x = NullEncodingTests()\\n', \"    x.s1 = 'asd'\\n\", \"    x.b1 = b'xyz'\\n\", \"    assert x.pack() == b'asd\\\\0xyz\\\\0'\\n\", '    x2 = NullEncodingTests(x.pack())\\n', '    print(type(x2.s1))\\n', '    assert isinstance(x2.s1, strtype)\\n', '    assert isinstance(x2.b1, bytestype)\\n']",
  "context": "allow_max=True)\n\ndef test_null_string_pack():\n    x = NullStringTests()\n    packed = x.pack()\n    assert packed == b'\\0\\0\\"
 },
 "521": {
  "name": "x",
  "type": "NullStringTests",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_nullstring.py",
  "lineno": "18",
  "column": "4",
  "slicing": "['    x = NullStringTests()\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\0\\\\0\\\\0\\\\0\\\\0\\\\0'\\n\", '    x = NullStringTests()\\n', \"    x.str1 = 'asdf'\\n\", '        x.pack()\\n', '    x = NullStringTests()\\n', \"    x.str3 = 'asdfg'\\n\", '        x.pack()\\n', '    x = NullStringTests()\\n', \"    x.unpack(b'asd\\\\x00as\\\\x00\\\\x001234')\\n\", \"    assert x.str1 == 'asd'\\n\", \"    assert x.str2 == 'as'\\n\", \"    assert x.str3 == '1234'\\n\", '    x = NullEncodingTests()\\n', \"    x.s1 = 'asd'\\n\", \"    x.b1 = b'xyz'\\n\", \"    assert x.pack() == b'asd\\\\0xyz\\\\0'\\n\", '    x2 = NullEncodingTests(x.pack())\\n', '    print(type(x2.s1))\\n', '    assert isinstance(x2.s1, strtype)\\n', '    assert isinstance(x2.b1, bytestype)\\n']",
  "context": "0\\0\\0\\0\\0\\0'\n\ndef test_null_string_illegal():\n    x = NullStringTests()\n    x.str1 = 'asdf'\n    with pytest.raises(ValueEr"
 },
 "522": {
  "name": "x",
  "type": "NullStringTests",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_nullstring.py",
  "lineno": "24",
  "column": "4",
  "slicing": "['    x = NullStringTests()\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\0\\\\0\\\\0\\\\0\\\\0\\\\0'\\n\", '    x = NullStringTests()\\n', \"    x.str1 = 'asdf'\\n\", '        x.pack()\\n', '    x = NullStringTests()\\n', \"    x.str3 = 'asdfg'\\n\", '        x.pack()\\n', '    x = NullStringTests()\\n', \"    x.unpack(b'asd\\\\x00as\\\\x00\\\\x001234')\\n\", \"    assert x.str1 == 'asd'\\n\", \"    assert x.str2 == 'as'\\n\", \"    assert x.str3 == '1234'\\n\", '    x = NullEncodingTests()\\n', \"    x.s1 = 'asd'\\n\", \"    x.b1 = b'xyz'\\n\", \"    assert x.pack() == b'asd\\\\0xyz\\\\0'\\n\", '    x2 = NullEncodingTests(x.pack())\\n', '    print(type(x2.s1))\\n', '    assert isinstance(x2.s1, strtype)\\n', '    assert isinstance(x2.b1, bytestype)\\n']",
  "context": "()\n\ndef test_null_string_illegal_allow_max():\n    x = NullStringTests()\n    x.str3 = 'asdfg'\n    with pytest.raises(ValueE"
 },
 "523": {
  "name": "x",
  "type": "NullStringTests",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_nullstring.py",
  "lineno": "30",
  "column": "4",
  "slicing": "['    x = NullStringTests()\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\0\\\\0\\\\0\\\\0\\\\0\\\\0'\\n\", '    x = NullStringTests()\\n', \"    x.str1 = 'asdf'\\n\", '        x.pack()\\n', '    x = NullStringTests()\\n', \"    x.str3 = 'asdfg'\\n\", '        x.pack()\\n', '    x = NullStringTests()\\n', \"    x.unpack(b'asd\\\\x00as\\\\x00\\\\x001234')\\n\", \"    assert x.str1 == 'asd'\\n\", \"    assert x.str2 == 'as'\\n\", \"    assert x.str3 == '1234'\\n\", '    x = NullEncodingTests()\\n', \"    x.s1 = 'asd'\\n\", \"    x.b1 = b'xyz'\\n\", \"    assert x.pack() == b'asd\\\\0xyz\\\\0'\\n\", '    x2 = NullEncodingTests(x.pack())\\n', '    print(type(x2.s1))\\n', '    assert isinstance(x2.s1, strtype)\\n', '    assert isinstance(x2.b1, bytestype)\\n']",
  "context": "     x.pack()\n\ndef test_null_string_unpack():\n    x = NullStringTests()\n    x.unpack(b'asd\\x00as\\x00\\x001234')\n    assert "
 },
 "524": {
  "name": "s1",
  "type": "nullstring.nullstring",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/tests/test_nullstring.py",
  "lineno": "37",
  "column": "4",
  "slicing": "['    x = NullStringTests()\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\0\\\\0\\\\0\\\\0\\\\0\\\\0'\\n\", '    x = NullStringTests()\\n', \"    x.str1 = 'asdf'\\n\", '        x.pack()\\n', '    x = NullStringTests()\\n', \"    x.str3 = 'asdfg'\\n\", '        x.pack()\\n', '    x = NullStringTests()\\n', \"    x.unpack(b'asd\\\\x00as\\\\x00\\\\x001234')\\n\", \"    assert x.str1 == 'asd'\\n\", \"    assert x.str2 == 'as'\\n\", \"    assert x.str3 == '1234'\\n\", \"    s1 = pyndata.nullstring(max_length=4, encoding='utf-8')\\n\", '    x = NullEncodingTests()\\n', \"    x.s1 = 'asd'\\n\", \"    x.b1 = b'xyz'\\n\", \"    assert x.pack() == b'asd\\\\0xyz\\\\0'\\n\", '    x2 = NullEncodingTests(x.pack())\\n', '    print(type(x2.s1))\\n', '    assert isinstance(x2.s1, strtype)\\n', '    assert isinstance(x2.b1, bytestype)\\n']",
  "context": "34'\n\nclass NullEncodingTests(pyndata.Struct):\n    s1 = pyndata.nullstring(max_length=4, encoding='utf-8')\n    b1 = pyndata.nullstring(max_length=4, encoding"
 },
 "525": {
  "name": "b1",
  "type": "nullstring.nullstring",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/tests/test_nullstring.py",
  "lineno": "38",
  "column": "4",
  "slicing": "['    x = NullStringTests()\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\0\\\\0\\\\0\\\\0\\\\0\\\\0'\\n\", '    x = NullStringTests()\\n', \"    x.str1 = 'asdf'\\n\", '        x.pack()\\n', '    x = NullStringTests()\\n', \"    x.str3 = 'asdfg'\\n\", '        x.pack()\\n', '    x = NullStringTests()\\n', \"    x.unpack(b'asd\\\\x00as\\\\x00\\\\x001234')\\n\", \"    assert x.str1 == 'asd'\\n\", \"    assert x.str2 == 'as'\\n\", \"    assert x.str3 == '1234'\\n\", '    b1 = pyndata.nullstring(max_length=4, encoding=None)\\n', '    x = NullEncodingTests()\\n', \"    x.s1 = 'asd'\\n\", \"    x.b1 = b'xyz'\\n\", \"    assert x.pack() == b'asd\\\\0xyz\\\\0'\\n\", '    x2 = NullEncodingTests(x.pack())\\n', '    print(type(x2.s1))\\n', '    assert isinstance(x2.s1, strtype)\\n', '    assert isinstance(x2.b1, bytestype)\\n']",
  "context": "ta.nullstring(max_length=4, encoding='utf-8')\n    b1 = pyndata.nullstring(max_length=4, encoding=None)\n\ndef test_null_string_encoding():\n    x = NullEnco"
 },
 "526": {
  "name": "x",
  "type": "NullEncodingTests",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_nullstring.py",
  "lineno": "41",
  "column": "4",
  "slicing": "['    x = NullStringTests()\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\0\\\\0\\\\0\\\\0\\\\0\\\\0'\\n\", '    x = NullStringTests()\\n', \"    x.str1 = 'asdf'\\n\", '        x.pack()\\n', '    x = NullStringTests()\\n', \"    x.str3 = 'asdfg'\\n\", '        x.pack()\\n', '    x = NullStringTests()\\n', \"    x.unpack(b'asd\\\\x00as\\\\x00\\\\x001234')\\n\", \"    assert x.str1 == 'asd'\\n\", \"    assert x.str2 == 'as'\\n\", \"    assert x.str3 == '1234'\\n\", '    x = NullEncodingTests()\\n', \"    x.s1 = 'asd'\\n\", \"    x.b1 = b'xyz'\\n\", \"    assert x.pack() == b'asd\\\\0xyz\\\\0'\\n\", '    x2 = NullEncodingTests(x.pack())\\n', '    print(type(x2.s1))\\n', '    assert isinstance(x2.s1, strtype)\\n', '    assert isinstance(x2.b1, bytestype)\\n']",
  "context": "oding=None)\n\ndef test_null_string_encoding():\n    x = NullEncodingTests()\n    x.s1 = 'asd'\n    x.b1 = b'xyz'\n    assert x.pa"
 },
 "527": {
  "name": "x2",
  "type": "NullEncodingTests",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_nullstring.py",
  "lineno": "45",
  "column": "4",
  "slicing": "['    x = NullStringTests()\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\0\\\\0\\\\0\\\\0\\\\0\\\\0'\\n\", '    x = NullStringTests()\\n', \"    x.str1 = 'asdf'\\n\", '        x.pack()\\n', '    x = NullStringTests()\\n', \"    x.str3 = 'asdfg'\\n\", '        x.pack()\\n', '    x = NullStringTests()\\n', \"    x.unpack(b'asd\\\\x00as\\\\x00\\\\x001234')\\n\", \"    assert x.str1 == 'asd'\\n\", \"    assert x.str2 == 'as'\\n\", \"    assert x.str3 == '1234'\\n\", '    x = NullEncodingTests()\\n', \"    x.s1 = 'asd'\\n\", \"    x.b1 = b'xyz'\\n\", \"    assert x.pack() == b'asd\\\\0xyz\\\\0'\\n\", '    x2 = NullEncodingTests(x.pack())\\n', '    print(type(x2.s1))\\n', '    assert isinstance(x2.s1, strtype)\\n', '    assert isinstance(x2.b1, bytestype)\\n']",
  "context": "= b'xyz'\n    assert x.pack() == b'asd\\0xyz\\0'\n    x2 = NullEncodingTests(x.pack())\n    print(type(x2.s1))\n    if sys.version_info[0] "
 },
 "528": {
  "name": "strtype",
  "type": "str",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_nullstring.py",
  "lineno": "48",
  "column": "8",
  "slicing": "['    x = NullStringTests()\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\0\\\\0\\\\0\\\\0\\\\0\\\\0'\\n\", '    x = NullStringTests()\\n', \"    x.str1 = 'asdf'\\n\", '        x.pack()\\n', '    x = NullStringTests()\\n', \"    x.str3 = 'asdfg'\\n\", '        x.pack()\\n', '    x = NullStringTests()\\n', \"    x.unpack(b'asd\\\\x00as\\\\x00\\\\x001234')\\n\", \"    assert x.str1 == 'asd'\\n\", \"    assert x.str2 == 'as'\\n\", \"    assert x.str3 == '1234'\\n\", '    x = NullEncodingTests()\\n', \"    x.s1 = 'asd'\\n\", \"    x.b1 = b'xyz'\\n\", \"    assert x.pack() == b'asd\\\\0xyz\\\\0'\\n\", '    x2 = NullEncodingTests(x.pack())\\n', '    print(type(x2.s1))\\n', '        strtype = str\\n', '    assert isinstance(x2.s1, strtype)\\n', '    assert isinstance(x2.b1, bytestype)\\n']",
  "context": "(x2.s1))\n    if sys.version_info[0] == 3:\n        strtype = str\n        bytestype = bytes\n    else:\n        strtyp"
 },
 "529": {
  "name": "bytestype",
  "type": "bytes",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_nullstring.py",
  "lineno": "49",
  "column": "8",
  "slicing": "['    x = NullStringTests()\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\0\\\\0\\\\0\\\\0\\\\0\\\\0'\\n\", '    x = NullStringTests()\\n', \"    x.str1 = 'asdf'\\n\", '        x.pack()\\n', '    x = NullStringTests()\\n', \"    x.str3 = 'asdfg'\\n\", '        x.pack()\\n', '    x = NullStringTests()\\n', \"    x.unpack(b'asd\\\\x00as\\\\x00\\\\x001234')\\n\", \"    assert x.str1 == 'asd'\\n\", \"    assert x.str2 == 'as'\\n\", \"    assert x.str3 == '1234'\\n\", '    x = NullEncodingTests()\\n', \"    x.s1 = 'asd'\\n\", \"    x.b1 = b'xyz'\\n\", \"    assert x.pack() == b'asd\\\\0xyz\\\\0'\\n\", '    x2 = NullEncodingTests(x.pack())\\n', '    print(type(x2.s1))\\n', '        bytestype = bytes\\n', '    assert isinstance(x2.s1, strtype)\\n', '    assert isinstance(x2.b1, bytestype)\\n']",
  "context": "rsion_info[0] == 3:\n        strtype = str\n        bytestype = bytes\n    else:\n        strtype = unicode\n        bytest"
 },
 "530": {
  "name": "strtype",
  "type": "unicode",
  "class": "imported",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_nullstring.py",
  "lineno": "51",
  "column": "8",
  "slicing": "['    x = NullStringTests()\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\0\\\\0\\\\0\\\\0\\\\0\\\\0'\\n\", '    x = NullStringTests()\\n', \"    x.str1 = 'asdf'\\n\", '        x.pack()\\n', '    x = NullStringTests()\\n', \"    x.str3 = 'asdfg'\\n\", '        x.pack()\\n', '    x = NullStringTests()\\n', \"    x.unpack(b'asd\\\\x00as\\\\x00\\\\x001234')\\n\", \"    assert x.str1 == 'asd'\\n\", \"    assert x.str2 == 'as'\\n\", \"    assert x.str3 == '1234'\\n\", '    x = NullEncodingTests()\\n', \"    x.s1 = 'asd'\\n\", \"    x.b1 = b'xyz'\\n\", \"    assert x.pack() == b'asd\\\\0xyz\\\\0'\\n\", '    x2 = NullEncodingTests(x.pack())\\n', '    print(type(x2.s1))\\n', '        strtype = unicode\\n', '    assert isinstance(x2.s1, strtype)\\n', '    assert isinstance(x2.b1, bytestype)\\n']",
  "context": "= str\n        bytestype = bytes\n    else:\n        strtype = unicode\n        bytestype = str\n    assert isinstance(x2.s"
 },
 "531": {
  "name": "bytestype",
  "type": "str",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_nullstring.py",
  "lineno": "52",
  "column": "8",
  "slicing": "['    x = NullStringTests()\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\0\\\\0\\\\0\\\\0\\\\0\\\\0'\\n\", '    x = NullStringTests()\\n', \"    x.str1 = 'asdf'\\n\", '        x.pack()\\n', '    x = NullStringTests()\\n', \"    x.str3 = 'asdfg'\\n\", '        x.pack()\\n', '    x = NullStringTests()\\n', \"    x.unpack(b'asd\\\\x00as\\\\x00\\\\x001234')\\n\", \"    assert x.str1 == 'asd'\\n\", \"    assert x.str2 == 'as'\\n\", \"    assert x.str3 == '1234'\\n\", '    x = NullEncodingTests()\\n', \"    x.s1 = 'asd'\\n\", \"    x.b1 = b'xyz'\\n\", \"    assert x.pack() == b'asd\\\\0xyz\\\\0'\\n\", '    x2 = NullEncodingTests(x.pack())\\n', '    print(type(x2.s1))\\n', '        bytestype = str\\n', '    assert isinstance(x2.s1, strtype)\\n', '    assert isinstance(x2.b1, bytestype)\\n']",
  "context": "bytes\n    else:\n        strtype = unicode\n        bytestype = str\n    assert isinstance(x2.s1, strtype)\n    assert i"
 },
 "532": {
  "name": "a",
  "type": "pyndata.uint8",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/tests/test_struct_keywords.py",
  "lineno": "6",
  "column": "1",
  "slicing": "['\\ta = pyndata.uint8()\\n']",
  "context": "pytest\n\nimport pyndata\n\nclass S(pyndata.Struct):\n\ta = pyndata.uint8()\n\tb = pyndata.uint8()\n\tc = pyndata.uint8()\n\ndef tes"
 },
 "533": {
  "name": "b",
  "type": "pyndata.uint8",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/tests/test_struct_keywords.py",
  "lineno": "7",
  "column": "1",
  "slicing": "['\\tb = pyndata.uint8()\\n']",
  "context": "a\n\nclass S(pyndata.Struct):\n\ta = pyndata.uint8()\n\tb = pyndata.uint8()\n\tc = pyndata.uint8()\n\ndef test_keyword_fields():\n\t"
 },
 "534": {
  "name": "c",
  "type": "pyndata.uint8",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/tests/test_struct_keywords.py",
  "lineno": "8",
  "column": "1",
  "slicing": "['\\tc = pyndata.uint8()\\n']",
  "context": "ruct):\n\ta = pyndata.uint8()\n\tb = pyndata.uint8()\n\tc = pyndata.uint8()\n\ndef test_keyword_fields():\n\tx = S(a=1, b=2, c=3)\n"
 },
 "535": {
  "name": "x",
  "type": "S",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_struct_keywords.py",
  "lineno": "11",
  "column": "1",
  "slicing": "['\\tx = S(a=1, b=2, c=3)\\n', '\\tassert x.a == 1\\n', '\\tassert x.b == 2\\n', '\\tassert x.c == 3\\n']",
  "context": "\tc = pyndata.uint8()\n\ndef test_keyword_fields():\n\tx = S(a=1, b=2, c=3)\n\tassert x.a == 1\n\tassert x.b == 2\n\tassert x.c == 3"
 },
 "536": {
  "name": "x",
  "type": "S",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_struct_keywords.py",
  "lineno": "18",
  "column": "2",
  "slicing": "['\\tx = S(a=1, b=2, c=3)\\n', '\\tassert x.a == 1\\n', '\\tassert x.b == 2\\n', '\\tassert x.c == 3\\n', '\\t\\tx = S(z=1)\\n']",
  "context": "failure():\n\twith pytest.raises(AttributeError):\n\t\tx = S(z=1)\n\n"
 },
 "537": {
  "name": "x",
  "type": "FixedArrayTests",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_array.py",
  "lineno": "9",
  "column": "4",
  "slicing": "['    x = FixedArrayTests()\\n', \"    x.unpack(b'\\\\x01\\\\x02\\\\x03')\\n\", '    assert x.arr == [1,2,3]\\n', '    x = FixedArrayTests()\\n', '    x.arr = [4,5,6]\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\x04\\\\x05\\\\x06'\\n\", '    assert x.c == [0, 1]\\n']",
  "context": "pyndata.uint8(), 3)\n\ndef test_array_unpack():\n    x = FixedArrayTests()\n    x.unpack(b'\\x01\\x02\\x03')\n    assert x.arr == "
 },
 "538": {
  "name": "x",
  "type": "FixedArrayTests",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_array.py",
  "lineno": "14",
  "column": "4",
  "slicing": "['    x = FixedArrayTests()\\n', \"    x.unpack(b'\\\\x01\\\\x02\\\\x03')\\n\", '    assert x.arr == [1,2,3]\\n', '    x = FixedArrayTests()\\n', '    x.arr = [4,5,6]\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\x04\\\\x05\\\\x06'\\n\", '    assert x.c == [0, 1]\\n']",
  "context": "sert x.arr == [1,2,3]\n\ndef test_array_pack():\n    x = FixedArrayTests()\n    x.arr = [4,5,6]\n    packed = x.pack()\n    asse"
 },
 "539": {
  "name": "f",
  "type": "pyndata.uint8",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/tests/test_array.py",
  "lineno": "20",
  "column": "1",
  "slicing": "['    x = FixedArrayTests()\\n', \"    x.unpack(b'\\\\x01\\\\x02\\\\x03')\\n\", '    assert x.arr == [1,2,3]\\n', '    x = FixedArrayTests()\\n', '    x.arr = [4,5,6]\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\x04\\\\x05\\\\x06'\\n\", '\\tf = pyndata.uint8()\\n', '    assert x.c == [0, 1]\\n']",
  "context": "ed == b'\\x04\\x05\\x06'\n\nclass S1(pyndata.Struct):\n\tf = pyndata.uint8()\n\nclass S2(pyndata.Struct):\n\ta = pyndata.array(kind"
 },
 "540": {
  "name": "a",
  "type": "array.array",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/tests/test_array.py",
  "lineno": "23",
  "column": "1",
  "slicing": "['    x = FixedArrayTests()\\n', \"    x.unpack(b'\\\\x01\\\\x02\\\\x03')\\n\", '    assert x.arr == [1,2,3]\\n', '    x = FixedArrayTests()\\n', '    x.arr = [4,5,6]\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\x04\\\\x05\\\\x06'\\n\", '\\ta = pyndata.array(kind=S1(), length=2)\\n', '    l = pyndata.uint8()\\n', '    a = pyndata.array(pyndata.uint8(), length=l)\\n', '    v = VariableArray()\\n', \"    v.unpack(b'\\\\x03\\\\x01\\\\x02\\\\x03')\\n\", '    assert v.l == 3\\n', '    assert v.a == [1, 2, 3]\\n', '    v = VariableArray()\\n', '    v.a = [1, 2, 3]\\n', '    assert v.l == 3\\n', \"    assert v.pack() == b'\\\\x03\\\\x01\\\\x02\\\\x03'\\n\", '    v = VariableArray()\\n', \"        v.unpack(b'\\\\x04\\\\x01\\\\x02\\\\x03')\\n\", '    a = pyndata.uint8()\\n', '    b = pyndata.BitField(a, 8, 0)\\n', '    c = pyndata.array(pyndata.uint8(), length=b)\\n', '    assert x.c == [0, 1]\\n', '        super(ArrayWithFunctionLength, self).__init__(*a, **kw)\\n', '    print(v.fields[0].length)\\n', \"    v.unpack(b'\\\\x01\\\\x02\\\\x03')\\n\", '    assert v.a == [1, 2, 3]\\n', '    v.a = [3, 2, 1]\\n', '    assert v.real_length == 3\\n', \"    assert v.pack() == b'\\\\x03\\\\x02\\\\x01'\\n\"]",
  "context": "\n\tf = pyndata.uint8()\n\nclass S2(pyndata.Struct):\n\ta = pyndata.array(kind=S1(), length=2)\n\nclass VariableArray(pyndata.Struct):\n    l = pynd"
 },
 "541": {
  "name": "l",
  "type": "pyndata.uint8",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/tests/test_array.py",
  "lineno": "26",
  "column": "4",
  "slicing": "['    x = FixedArrayTests()\\n', \"    x.unpack(b'\\\\x01\\\\x02\\\\x03')\\n\", '    assert x.arr == [1,2,3]\\n', '    x = FixedArrayTests()\\n', '    x.arr = [4,5,6]\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\x04\\\\x05\\\\x06'\\n\", '\\ta = pyndata.array(kind=S1(), length=2)\\n', '    l = pyndata.uint8()\\n', '    a = pyndata.array(pyndata.uint8(), length=l)\\n', '    v = VariableArray()\\n', \"    v.unpack(b'\\\\x03\\\\x01\\\\x02\\\\x03')\\n\", '    assert v.l == 3\\n', '    assert v.a == [1, 2, 3]\\n', '    v = VariableArray()\\n', '    v.a = [1, 2, 3]\\n', '    assert v.l == 3\\n', \"    assert v.pack() == b'\\\\x03\\\\x01\\\\x02\\\\x03'\\n\", '    v = VariableArray()\\n', \"        v.unpack(b'\\\\x04\\\\x01\\\\x02\\\\x03')\\n\", '    a = pyndata.uint8()\\n', '    b = pyndata.BitField(a, 8, 0)\\n', '    c = pyndata.array(pyndata.uint8(), length=b)\\n', '    assert x.c == [0, 1]\\n', '        super(ArrayWithFunctionLength, self).__init__(*a, **kw)\\n', '    print(v.fields[0].length)\\n', \"    v.unpack(b'\\\\x01\\\\x02\\\\x03')\\n\", '    assert v.a == [1, 2, 3]\\n', '    v.a = [3, 2, 1]\\n', '    assert v.real_length == 3\\n', \"    assert v.pack() == b'\\\\x03\\\\x02\\\\x01'\\n\"]",
  "context": "ngth=2)\n\nclass VariableArray(pyndata.Struct):\n    l = pyndata.uint8()\n    a = pyndata.array(pyndata.uint8(), length=l)\n\n"
 },
 "542": {
  "name": "v",
  "type": "VariableArray",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_array.py",
  "lineno": "30",
  "column": "4",
  "slicing": "['    x = FixedArrayTests()\\n', \"    x.unpack(b'\\\\x01\\\\x02\\\\x03')\\n\", '    assert x.arr == [1,2,3]\\n', '    x = FixedArrayTests()\\n', '    x.arr = [4,5,6]\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\x04\\\\x05\\\\x06'\\n\", '\\ta = pyndata.array(kind=S1(), length=2)\\n', '    l = pyndata.uint8()\\n', '    a = pyndata.array(pyndata.uint8(), length=l)\\n', '    v = VariableArray()\\n', \"    v.unpack(b'\\\\x03\\\\x01\\\\x02\\\\x03')\\n\", '    assert v.l == 3\\n', '    assert v.a == [1, 2, 3]\\n', '    v = VariableArray()\\n', '    v.a = [1, 2, 3]\\n', '    assert v.l == 3\\n', \"    assert v.pack() == b'\\\\x03\\\\x01\\\\x02\\\\x03'\\n\", '    v = VariableArray()\\n', \"        v.unpack(b'\\\\x04\\\\x01\\\\x02\\\\x03')\\n\", '    a = pyndata.uint8()\\n', '    b = pyndata.BitField(a, 8, 0)\\n', '    c = pyndata.array(pyndata.uint8(), length=b)\\n', '    assert x.c == [0, 1]\\n', '        super(ArrayWithFunctionLength, self).__init__(*a, **kw)\\n', '    print(v.fields[0].length)\\n', \"    v.unpack(b'\\\\x01\\\\x02\\\\x03')\\n\", '    assert v.a == [1, 2, 3]\\n', '    v.a = [3, 2, 1]\\n', '    assert v.real_length == 3\\n', \"    assert v.pack() == b'\\\\x03\\\\x02\\\\x01'\\n\"]",
  "context": "length=l)\n\ndef test_variable_unpack_length():\n    v = VariableArray()\n    v.unpack(b'\\x03\\x01\\x02\\x03')\n    assert v.l ="
 },
 "543": {
  "name": "v",
  "type": "VariableArray",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_array.py",
  "lineno": "36",
  "column": "4",
  "slicing": "['    x = FixedArrayTests()\\n', \"    x.unpack(b'\\\\x01\\\\x02\\\\x03')\\n\", '    assert x.arr == [1,2,3]\\n', '    x = FixedArrayTests()\\n', '    x.arr = [4,5,6]\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\x04\\\\x05\\\\x06'\\n\", '\\ta = pyndata.array(kind=S1(), length=2)\\n', '    l = pyndata.uint8()\\n', '    a = pyndata.array(pyndata.uint8(), length=l)\\n', '    v = VariableArray()\\n', \"    v.unpack(b'\\\\x03\\\\x01\\\\x02\\\\x03')\\n\", '    assert v.l == 3\\n', '    assert v.a == [1, 2, 3]\\n', '    v = VariableArray()\\n', '    v.a = [1, 2, 3]\\n', '    assert v.l == 3\\n', \"    assert v.pack() == b'\\\\x03\\\\x01\\\\x02\\\\x03'\\n\", '    v = VariableArray()\\n', \"        v.unpack(b'\\\\x04\\\\x01\\\\x02\\\\x03')\\n\", '    a = pyndata.uint8()\\n', '    b = pyndata.BitField(a, 8, 0)\\n', '    c = pyndata.array(pyndata.uint8(), length=b)\\n', '    assert x.c == [0, 1]\\n', '        super(ArrayWithFunctionLength, self).__init__(*a, **kw)\\n', '    print(v.fields[0].length)\\n', \"    v.unpack(b'\\\\x01\\\\x02\\\\x03')\\n\", '    assert v.a == [1, 2, 3]\\n', '    v.a = [3, 2, 1]\\n', '    assert v.real_length == 3\\n', \"    assert v.pack() == b'\\\\x03\\\\x02\\\\x01'\\n\"]",
  "context": "t v.a == [1, 2, 3]\n\ndef test_variable_pack():\n    v = VariableArray()\n    v.a = [1, 2, 3]\n    assert v.l == 3\n    assert"
 },
 "544": {
  "name": "v",
  "type": "VariableArray",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_array.py",
  "lineno": "42",
  "column": "4",
  "slicing": "['    x = FixedArrayTests()\\n', \"    x.unpack(b'\\\\x01\\\\x02\\\\x03')\\n\", '    assert x.arr == [1,2,3]\\n', '    x = FixedArrayTests()\\n', '    x.arr = [4,5,6]\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\x04\\\\x05\\\\x06'\\n\", '\\ta = pyndata.array(kind=S1(), length=2)\\n', '    l = pyndata.uint8()\\n', '    a = pyndata.array(pyndata.uint8(), length=l)\\n', '    v = VariableArray()\\n', \"    v.unpack(b'\\\\x03\\\\x01\\\\x02\\\\x03')\\n\", '    assert v.l == 3\\n', '    assert v.a == [1, 2, 3]\\n', '    v = VariableArray()\\n', '    v.a = [1, 2, 3]\\n', '    assert v.l == 3\\n', \"    assert v.pack() == b'\\\\x03\\\\x01\\\\x02\\\\x03'\\n\", '    v = VariableArray()\\n', \"        v.unpack(b'\\\\x04\\\\x01\\\\x02\\\\x03')\\n\", '    a = pyndata.uint8()\\n', '    b = pyndata.BitField(a, 8, 0)\\n', '    c = pyndata.array(pyndata.uint8(), length=b)\\n', '    assert x.c == [0, 1]\\n', '        super(ArrayWithFunctionLength, self).__init__(*a, **kw)\\n', '    print(v.fields[0].length)\\n', \"    v.unpack(b'\\\\x01\\\\x02\\\\x03')\\n\", '    assert v.a == [1, 2, 3]\\n', '    v.a = [3, 2, 1]\\n', '    assert v.real_length == 3\\n', \"    assert v.pack() == b'\\\\x03\\\\x02\\\\x01'\\n\"]",
  "context": "3\\x01\\x02\\x03'\n\ndef test_bad_unpack_length():\n    v = VariableArray()\n    with pytest.raises(pyndata.error):\n        v.u"
 },
 "545": {
  "name": "a",
  "type": "pyndata.uint8",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/tests/test_array.py",
  "lineno": "47",
  "column": "4",
  "slicing": "['    x = FixedArrayTests()\\n', \"    x.unpack(b'\\\\x01\\\\x02\\\\x03')\\n\", '    assert x.arr == [1,2,3]\\n', '    x = FixedArrayTests()\\n', '    x.arr = [4,5,6]\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\x04\\\\x05\\\\x06'\\n\", '\\ta = pyndata.array(kind=S1(), length=2)\\n', '    l = pyndata.uint8()\\n', '    a = pyndata.array(pyndata.uint8(), length=l)\\n', '    v = VariableArray()\\n', \"    v.unpack(b'\\\\x03\\\\x01\\\\x02\\\\x03')\\n\", '    assert v.l == 3\\n', '    assert v.a == [1, 2, 3]\\n', '    v = VariableArray()\\n', '    v.a = [1, 2, 3]\\n', '    assert v.l == 3\\n', \"    assert v.pack() == b'\\\\x03\\\\x01\\\\x02\\\\x03'\\n\", '    v = VariableArray()\\n', \"        v.unpack(b'\\\\x04\\\\x01\\\\x02\\\\x03')\\n\", '    a = pyndata.uint8()\\n', '    b = pyndata.BitField(a, 8, 0)\\n', '    c = pyndata.array(pyndata.uint8(), length=b)\\n', '    assert x.c == [0, 1]\\n', '        super(ArrayWithFunctionLength, self).__init__(*a, **kw)\\n', '    print(v.fields[0].length)\\n', \"    v.unpack(b'\\\\x01\\\\x02\\\\x03')\\n\", '    assert v.a == [1, 2, 3]\\n', '    v.a = [3, 2, 1]\\n', '    assert v.real_length == 3\\n', \"    assert v.pack() == b'\\\\x03\\\\x02\\\\x01'\\n\"]",
  "context": "lass ArrayWithBitfieldLength(pyndata.Struct):\n    a = pyndata.uint8()\n    b = pyndata.BitField(a, 8, 0)\n    c = pyndata."
 },
 "546": {
  "name": "b",
  "type": "bitfield.BitField",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/tests/test_array.py",
  "lineno": "48",
  "column": "4",
  "slicing": "['    x = FixedArrayTests()\\n', \"    x.unpack(b'\\\\x01\\\\x02\\\\x03')\\n\", '    assert x.arr == [1,2,3]\\n', '    x = FixedArrayTests()\\n', '    x.arr = [4,5,6]\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\x04\\\\x05\\\\x06'\\n\", '\\ta = pyndata.array(kind=S1(), length=2)\\n', '    l = pyndata.uint8()\\n', '    a = pyndata.array(pyndata.uint8(), length=l)\\n', '    v = VariableArray()\\n', \"    v.unpack(b'\\\\x03\\\\x01\\\\x02\\\\x03')\\n\", '    assert v.l == 3\\n', '    assert v.a == [1, 2, 3]\\n', '    v = VariableArray()\\n', '    v.a = [1, 2, 3]\\n', '    assert v.l == 3\\n', \"    assert v.pack() == b'\\\\x03\\\\x01\\\\x02\\\\x03'\\n\", '    v = VariableArray()\\n', \"        v.unpack(b'\\\\x04\\\\x01\\\\x02\\\\x03')\\n\", '    a = pyndata.uint8()\\n', '    b = pyndata.BitField(a, 8, 0)\\n', '    c = pyndata.array(pyndata.uint8(), length=b)\\n', '    assert x.c == [0, 1]\\n', '        super(ArrayWithFunctionLength, self).__init__(*a, **kw)\\n', '    print(v.fields[0].length)\\n', \"    v.unpack(b'\\\\x01\\\\x02\\\\x03')\\n\", '    assert v.a == [1, 2, 3]\\n', '    v.a = [3, 2, 1]\\n', '    assert v.real_length == 3\\n', \"    assert v.pack() == b'\\\\x03\\\\x02\\\\x01'\\n\"]",
  "context": "ngth(pyndata.Struct):\n    a = pyndata.uint8()\n    b = pyndata.BitField(a, 8, 0)\n    c = pyndata.array(pyndata.uint8(), length=b)\n\n"
 },
 "547": {
  "name": "x",
  "type": "ArrayWithBitfieldLength",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_array.py",
  "lineno": "52",
  "column": "4",
  "slicing": "['    x = FixedArrayTests()\\n', \"    x.unpack(b'\\\\x01\\\\x02\\\\x03')\\n\", '    assert x.arr == [1,2,3]\\n', '    x = FixedArrayTests()\\n', '    x.arr = [4,5,6]\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\x04\\\\x05\\\\x06'\\n\", '\\ta = pyndata.array(kind=S1(), length=2)\\n', '    l = pyndata.uint8()\\n', '    a = pyndata.array(pyndata.uint8(), length=l)\\n', '    v = VariableArray()\\n', \"    v.unpack(b'\\\\x03\\\\x01\\\\x02\\\\x03')\\n\", '    assert v.l == 3\\n', '    assert v.a == [1, 2, 3]\\n', '    v = VariableArray()\\n', '    v.a = [1, 2, 3]\\n', '    assert v.l == 3\\n', \"    assert v.pack() == b'\\\\x03\\\\x01\\\\x02\\\\x03'\\n\", '    v = VariableArray()\\n', \"        v.unpack(b'\\\\x04\\\\x01\\\\x02\\\\x03')\\n\", '    a = pyndata.uint8()\\n', '    b = pyndata.BitField(a, 8, 0)\\n', '    c = pyndata.array(pyndata.uint8(), length=b)\\n', \"    x = ArrayWithBitfieldLength(b'\\\\x02\\\\x00\\\\x01')\\n\", '    assert x.c == [0, 1]\\n', '        super(ArrayWithFunctionLength, self).__init__(*a, **kw)\\n', '    print(v.fields[0].length)\\n', \"    v.unpack(b'\\\\x01\\\\x02\\\\x03')\\n\", '    assert v.a == [1, 2, 3]\\n', '    v.a = [3, 2, 1]\\n', '    assert v.real_length == 3\\n', \"    assert v.pack() == b'\\\\x03\\\\x02\\\\x01'\\n\"]",
  "context": " length=b)\n\ndef test_array_bitfield_length():\n    x = ArrayWithBitfieldLength(b'\\x02\\x00\\x01')\n    assert x.c == [0, 1]\n    y = ArrayWithBitfield"
 },
 "548": {
  "name": "y",
  "type": "ArrayWithBitfieldLength",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_array.py",
  "lineno": "54",
  "column": "4",
  "slicing": "['    x = FixedArrayTests()\\n', \"    x.unpack(b'\\\\x01\\\\x02\\\\x03')\\n\", '    assert x.arr == [1,2,3]\\n', '    x = FixedArrayTests()\\n', '    x.arr = [4,5,6]\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\x04\\\\x05\\\\x06'\\n\", '\\ta = pyndata.array(kind=S1(), length=2)\\n', '    l = pyndata.uint8()\\n', '    a = pyndata.array(pyndata.uint8(), length=l)\\n', '    v = VariableArray()\\n', \"    v.unpack(b'\\\\x03\\\\x01\\\\x02\\\\x03')\\n\", '    assert v.l == 3\\n', '    assert v.a == [1, 2, 3]\\n', '    v = VariableArray()\\n', '    v.a = [1, 2, 3]\\n', '    assert v.l == 3\\n', \"    assert v.pack() == b'\\\\x03\\\\x01\\\\x02\\\\x03'\\n\", '    v = VariableArray()\\n', \"        v.unpack(b'\\\\x04\\\\x01\\\\x02\\\\x03')\\n\", '    a = pyndata.uint8()\\n', '    b = pyndata.BitField(a, 8, 0)\\n', '    c = pyndata.array(pyndata.uint8(), length=b)\\n', \"    x = ArrayWithBitfieldLength(b'\\\\x02\\\\x00\\\\x01')\\n\", '    assert x.c == [0, 1]\\n', '    y = ArrayWithBitfieldLength()\\n', '    y.b = 2\\n', '    y.c = [0, 1]\\n', \"    assert y.pack() == b'\\\\x02\\\\x00\\\\x01'\\n\", '        super(ArrayWithFunctionLength, self).__init__(*a, **kw)\\n', '    print(v.fields[0].length)\\n', \"    v.unpack(b'\\\\x01\\\\x02\\\\x03')\\n\", '    assert v.a == [1, 2, 3]\\n', '    v.a = [3, 2, 1]\\n', '    assert v.real_length == 3\\n', \"    assert v.pack() == b'\\\\x03\\\\x02\\\\x01'\\n\"]",
  "context": "gth(b'\\x02\\x00\\x01')\n    assert x.c == [0, 1]\n    y = ArrayWithBitfieldLength()\n    y.b = 2\n    y.c = [0, 1]\n    assert y.pack() ="
 },
 "549": {
  "name": "v",
  "type": "ArrayWithFunctionLength",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_array.py",
  "lineno": "75",
  "column": "4",
  "slicing": "['    x = FixedArrayTests()\\n', \"    x.unpack(b'\\\\x01\\\\x02\\\\x03')\\n\", '    assert x.arr == [1,2,3]\\n', '    x = FixedArrayTests()\\n', '    x.arr = [4,5,6]\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\x04\\\\x05\\\\x06'\\n\", '\\ta = pyndata.array(kind=S1(), length=2)\\n', '    l = pyndata.uint8()\\n', '    a = pyndata.array(pyndata.uint8(), length=l)\\n', '    v = VariableArray()\\n', \"    v.unpack(b'\\\\x03\\\\x01\\\\x02\\\\x03')\\n\", '    assert v.l == 3\\n', '    assert v.a == [1, 2, 3]\\n', '    v = VariableArray()\\n', '    v.a = [1, 2, 3]\\n', '    assert v.l == 3\\n', \"    assert v.pack() == b'\\\\x03\\\\x01\\\\x02\\\\x03'\\n\", '    v = VariableArray()\\n', \"        v.unpack(b'\\\\x04\\\\x01\\\\x02\\\\x03')\\n\", '    a = pyndata.uint8()\\n', '    b = pyndata.BitField(a, 8, 0)\\n', '    c = pyndata.array(pyndata.uint8(), length=b)\\n', \"    x = ArrayWithBitfieldLength(b'\\\\x02\\\\x00\\\\x01')\\n\", '    assert x.c == [0, 1]\\n', '    y = ArrayWithBitfieldLength()\\n', '    y.b = 2\\n', '    y.c = [0, 1]\\n', \"    assert y.pack() == b'\\\\x02\\\\x00\\\\x01'\\n\", '        super(ArrayWithFunctionLength, self).__init__(*a, **kw)\\n', '    a = pyndata.array(pyndata.uint8(), length=length)\\n', '    v = ArrayWithFunctionLength()\\n', '    print(v.fields[0].length)\\n', \"    v.unpack(b'\\\\x01\\\\x02\\\\x03')\\n\", '    assert v.a == [1, 2, 3]\\n', '    v.a = [3, 2, 1]\\n', '    assert v.real_length == 3\\n', \"    assert v.pack() == b'\\\\x03\\\\x02\\\\x01'\\n\"]",
  "context": "th)\n\ndef test_array_function_length_unpack():\n    v = ArrayWithFunctionLength()\n    print(v.fields[0].length)\n    v.unpack(b'\\x01\\"
 },
 "550": {
  "name": "v",
  "type": "ArrayWithFunctionLength",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_array.py",
  "lineno": "81",
  "column": "4",
  "slicing": "['    x = FixedArrayTests()\\n', \"    x.unpack(b'\\\\x01\\\\x02\\\\x03')\\n\", '    assert x.arr == [1,2,3]\\n', '    x = FixedArrayTests()\\n', '    x.arr = [4,5,6]\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\x04\\\\x05\\\\x06'\\n\", '\\ta = pyndata.array(kind=S1(), length=2)\\n', '    l = pyndata.uint8()\\n', '    a = pyndata.array(pyndata.uint8(), length=l)\\n', '    v = VariableArray()\\n', \"    v.unpack(b'\\\\x03\\\\x01\\\\x02\\\\x03')\\n\", '    assert v.l == 3\\n', '    assert v.a == [1, 2, 3]\\n', '    v = VariableArray()\\n', '    v.a = [1, 2, 3]\\n', '    assert v.l == 3\\n', \"    assert v.pack() == b'\\\\x03\\\\x01\\\\x02\\\\x03'\\n\", '    v = VariableArray()\\n', \"        v.unpack(b'\\\\x04\\\\x01\\\\x02\\\\x03')\\n\", '    a = pyndata.uint8()\\n', '    b = pyndata.BitField(a, 8, 0)\\n', '    c = pyndata.array(pyndata.uint8(), length=b)\\n', \"    x = ArrayWithBitfieldLength(b'\\\\x02\\\\x00\\\\x01')\\n\", '    assert x.c == [0, 1]\\n', '    y = ArrayWithBitfieldLength()\\n', '    y.b = 2\\n', '    y.c = [0, 1]\\n', \"    assert y.pack() == b'\\\\x02\\\\x00\\\\x01'\\n\", '        super(ArrayWithFunctionLength, self).__init__(*a, **kw)\\n', '    a = pyndata.array(pyndata.uint8(), length=length)\\n', '    v = ArrayWithFunctionLength()\\n', '    print(v.fields[0].length)\\n', \"    v.unpack(b'\\\\x01\\\\x02\\\\x03')\\n\", '    assert v.a == [1, 2, 3]\\n', '    v = ArrayWithFunctionLength()\\n', '    v.a = [3, 2, 1]\\n', '    assert v.real_length == 3\\n', \"    assert v.pack() == b'\\\\x03\\\\x02\\\\x01'\\n\"]",
  "context": "2, 3]\n\ndef test_array_function_length_pack():\n    v = ArrayWithFunctionLength()\n    v.a = [3, 2, 1]\n    assert v.real_length == 3\n"
 },
 "551": {
  "name": "msg_len",
  "type": "pyndata.uint8",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/tests/test_nested_struct.py",
  "lineno": "6",
  "column": "4",
  "slicing": "['    msg_len = pyndata.uint8()\\n']",
  "context": "import pyndata\n\nclass Header(pyndata.Struct):\n    msg_len = pyndata.uint8()\n\nclass Message(pyndata.Struct):\n    hdr = Header()"
 },
 "552": {
  "name": "hdr",
  "type": "Header",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_nested_struct.py",
  "lineno": "9",
  "column": "4",
  "slicing": "['    hdr = Header()\\n', '    s = pyndata.bytestring(length=hdr.msg_len)\\n']",
  "context": "ndata.uint8()\n\nclass Message(pyndata.Struct):\n    hdr = Header()\n    s = pyndata.bytestring(length=hdr.msg_len)\n\n@p"
 },
 "553": {
  "name": "s",
  "type": "bytestring.bytestring",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/tests/test_nested_struct.py",
  "lineno": "10",
  "column": "4",
  "slicing": "['    hdr = Header()\\n', '    s = pyndata.bytestring(length=hdr.msg_len)\\n']",
  "context": "s Message(pyndata.Struct):\n    hdr = Header()\n    s = pyndata.bytestring(length=hdr.msg_len)\n\n@pytest.mark.xfail\ndef test_nested_reference():\n "
 },
 "554": {
  "name": "x",
  "type": "Message",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_nested_struct.py",
  "lineno": "14",
  "column": "4",
  "slicing": "['    hdr = Header()\\n', '    s = pyndata.bytestring(length=hdr.msg_len)\\n', '    x = Message()\\n', \"    x.unpack(b'\\\\x04asdf')\\n\", '    assert x.hdr.msg_len == 4\\n', \"    assert x.s == b'asdf'\\n\"]",
  "context": "ytest.mark.xfail\ndef test_nested_reference():\n    x = Message()\n    x.unpack(b'\\x04asdf')\n    assert x.hdr.msg_len"
 },
 "555": {
  "name": "str1",
  "type": "bytestring.bytestring",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/tests/test_bytestring.py",
  "lineno": "6",
  "column": "4",
  "slicing": "['    str1 = pyndata.bytestring(4)\\n']",
  "context": "ndata\n\nclass BytestringTests(pyndata.Struct):\n    str1 = pyndata.bytestring(4)\n\ndef test_bytestring():\n    t = BytestringTests()\n"
 },
 "556": {
  "name": "t",
  "type": "BytestringTests",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_bytestring.py",
  "lineno": "9",
  "column": "4",
  "slicing": "['    t = BytestringTests()\\n', \"    t.str1 = b'asdf'\\n\", \"    assert t.str1 == b'asdf'\\n\", \"    assert t.pack() == b'asdf'\\n\"]",
  "context": "pyndata.bytestring(4)\n\ndef test_bytestring():\n    t = BytestringTests()\n    t.str1 = b'asdf'\n    assert t.str1 == b'asdf'\n"
 },
 "557": {
  "name": "l",
  "type": "pyndata.uint8",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/tests/test_bytestring.py",
  "lineno": "15",
  "column": "1",
  "slicing": "['    t = BytestringTests()\\n', \"    t.str1 = b'asdf'\\n\", \"    assert t.str1 == b'asdf'\\n\", \"    assert t.pack() == b'asdf'\\n\", '\\tl = pyndata.uint8()\\n', '\\ts = pyndata.bytestring(length=l)\\n']",
  "context": "asdf'\n\nclass VariableBytestring(pyndata.Struct):\n\tl = pyndata.uint8()\n\ts = pyndata.bytestring(length=l)\n\ndef test_variab"
 },
 "558": {
  "name": "s",
  "type": "bytestring.bytestring",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/tests/test_bytestring.py",
  "lineno": "16",
  "column": "1",
  "slicing": "['    t = BytestringTests()\\n', \"    t.str1 = b'asdf'\\n\", \"    assert t.str1 == b'asdf'\\n\", \"    assert t.pack() == b'asdf'\\n\", '\\tl = pyndata.uint8()\\n', '\\ts = pyndata.bytestring(length=l)\\n']",
  "context": "Bytestring(pyndata.Struct):\n\tl = pyndata.uint8()\n\ts = pyndata.bytestring(length=l)\n\ndef test_variable_unpack():\n\tv = VariableBytestri"
 },
 "559": {
  "name": "v",
  "type": "VariableBytestring",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_bytestring.py",
  "lineno": "19",
  "column": "1",
  "slicing": "['    t = BytestringTests()\\n', \"    t.str1 = b'asdf'\\n\", \"    assert t.str1 == b'asdf'\\n\", \"    assert t.pack() == b'asdf'\\n\", '\\tl = pyndata.uint8()\\n', '\\ts = pyndata.bytestring(length=l)\\n', '\\tv = VariableBytestring()\\n', \"\\tv.unpack(b'\\\\x04asdf')\\n\", '\\tassert v.l == 4\\n', \"\\tassert v.s == b'asdf'\\n\", \"    v.s = b'asdf'\\n\", '    assert v.l == 4\\n', \"    assert v.pack() == b'\\\\x04asdf'\\n\", \"        v.unpack(b'\\\\x05a')\\n\"]",
  "context": "ytestring(length=l)\n\ndef test_variable_unpack():\n\tv = VariableBytestring()\n\tv.unpack(b'\\x04asdf')\n\tassert v.l == 4\n\tassert v."
 },
 "560": {
  "name": "v",
  "type": "VariableBytestring",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_bytestring.py",
  "lineno": "25",
  "column": "4",
  "slicing": "['    t = BytestringTests()\\n', \"    t.str1 = b'asdf'\\n\", \"    assert t.str1 == b'asdf'\\n\", \"    assert t.pack() == b'asdf'\\n\", '\\tl = pyndata.uint8()\\n', '\\ts = pyndata.bytestring(length=l)\\n', '\\tv = VariableBytestring()\\n', \"\\tv.unpack(b'\\\\x04asdf')\\n\", '\\tassert v.l == 4\\n', \"\\tassert v.s == b'asdf'\\n\", '    v = VariableBytestring()\\n', \"    v.s = b'asdf'\\n\", '    assert v.l == 4\\n', \"    assert v.pack() == b'\\\\x04asdf'\\n\", \"        v.unpack(b'\\\\x05a')\\n\"]",
  "context": "ert v.s == b'asdf'\n\ndef test_variable_pack():\n    v = VariableBytestring()\n    v.s = b'asdf'\n    assert v.l == 4\n    assert v"
 },
 "561": {
  "name": "v",
  "type": "VariableBytestring",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_bytestring.py",
  "lineno": "31",
  "column": "4",
  "slicing": "['    t = BytestringTests()\\n', \"    t.str1 = b'asdf'\\n\", \"    assert t.str1 == b'asdf'\\n\", \"    assert t.pack() == b'asdf'\\n\", '\\tl = pyndata.uint8()\\n', '\\ts = pyndata.bytestring(length=l)\\n', '\\tv = VariableBytestring()\\n', \"\\tv.unpack(b'\\\\x04asdf')\\n\", '\\tassert v.l == 4\\n', \"\\tassert v.s == b'asdf'\\n\", '    v = VariableBytestring()\\n', \"    v.s = b'asdf'\\n\", '    assert v.l == 4\\n', \"    assert v.pack() == b'\\\\x04asdf'\\n\", '    v = VariableBytestring()\\n', \"        v.unpack(b'\\\\x05a')\\n\"]",
  "context": "== b'\\x04asdf'\n\ndef test_bad_unpack_length():\n    v = VariableBytestring()\n    with pytest.raises(pyndata.error):\n        v.u"
 },
 "562": {
  "name": "x",
  "type": "pyndata.uint8",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/tests/test_substruct.py",
  "lineno": "4",
  "column": "4",
  "slicing": "['    x = pyndata.uint8()\\n']",
  "context": "ort pyndata\n\nclass SubStruct(pyndata.Struct):\n    x = pyndata.uint8()\n\nclass StructWithSubStruct(pyndata.Struct):\n    s1"
 },
 "563": {
  "name": "s1",
  "type": "SubStruct",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_substruct.py",
  "lineno": "7",
  "column": "4",
  "slicing": "['    s1 = SubStruct()\\n']",
  "context": ")\n\nclass StructWithSubStruct(pyndata.Struct):\n    s1 = SubStruct()\n    s2 = SubStruct()\n    _s3 = SubStruct()\n\ndef te"
 },
 "564": {
  "name": "s2",
  "type": "SubStruct",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_substruct.py",
  "lineno": "8",
  "column": "4",
  "slicing": "['    s2 = SubStruct()\\n']",
  "context": "bStruct(pyndata.Struct):\n    s1 = SubStruct()\n    s2 = SubStruct()\n    _s3 = SubStruct()\n\ndef test_sub_struct_unpack("
 },
 "565": {
  "name": "_s3",
  "type": "SubStruct",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_substruct.py",
  "lineno": "9",
  "column": "4",
  "slicing": "['    _s3 = SubStruct()\\n']",
  "context": "t):\n    s1 = SubStruct()\n    s2 = SubStruct()\n    _s3 = SubStruct()\n\ndef test_sub_struct_unpack():\n    t = StructWithS"
 },
 "566": {
  "name": "t",
  "type": "StructWithSubStruct",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_substruct.py",
  "lineno": "12",
  "column": "4",
  "slicing": "[\"    t = StructWithSubStruct(b'\\\\x01\\\\x23\\\\x45')\\n\", '    assert t.s1.x == 0x01\\n', '    assert t.s2.x == 0x23\\n', '    assert t._s3.x == 0x45\\n', '    t = StructWithSubStruct()\\n', '    t.s1.x = 0x20\\n', '    t.s2.x = 0x44\\n', '    t._s3.x = 0x59\\n', '    packed = t.pack()\\n', \"    assert packed == b'\\\\x20\\\\x44\\\\x59'\\n\"]",
  "context": " = SubStruct()\n\ndef test_sub_struct_unpack():\n    t = StructWithSubStruct(b'\\x01\\x23\\x45')\n    assert t.s1.x == 0x01\n    assert t.s2.x == 0x2"
 },
 "567": {
  "name": "t",
  "type": "StructWithSubStruct",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_substruct.py",
  "lineno": "18",
  "column": "4",
  "slicing": "[\"    t = StructWithSubStruct(b'\\\\x01\\\\x23\\\\x45')\\n\", '    assert t.s1.x == 0x01\\n', '    assert t.s2.x == 0x23\\n', '    assert t._s3.x == 0x45\\n', '    t = StructWithSubStruct()\\n', '    t.s1.x = 0x20\\n', '    t.s2.x = 0x44\\n', '    t._s3.x = 0x59\\n', '    packed = t.pack()\\n', \"    assert packed == b'\\\\x20\\\\x44\\\\x59'\\n\"]",
  "context": " t._s3.x == 0x45\n\ndef test_sub_struct_pack():\n    t = StructWithSubStruct()\n    t.s1.x = 0x20\n    t.s2.x = 0x44\n    t._s3.x = "
 },
 "568": {
  "name": "first",
  "type": "pyndata.uint8",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/tests/test_basic.py",
  "lineno": "6",
  "column": "4",
  "slicing": "['    first = pyndata.uint8()\\n']",
  "context": "est\n\nimport pyndata\n\nclass s(pyndata.Struct):\n    first = pyndata.uint8()\n    second = pyndata.uint8(default=5)\n\ndef test_fi"
 },
 "569": {
  "name": "second",
  "type": "pyndata.uint8",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/tests/test_basic.py",
  "lineno": "7",
  "column": "4",
  "slicing": "['    second = pyndata.uint8(default=5)\\n']",
  "context": "(pyndata.Struct):\n    first = pyndata.uint8()\n    second = pyndata.uint8(default=5)\n\ndef test_field_get():\n    x = s()\n    assert x.fi"
 },
 "570": {
  "name": "x",
  "type": "s",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_basic.py",
  "lineno": "10",
  "column": "4",
  "slicing": "['    x = s()\\n', '    assert x.first == 0\\n', '    x = s()\\n', '    assert x.second == 5\\n', '    x = s()\\n', '    x.first = 123\\n', '    assert x.first == 123\\n', '    x = s()\\n', '    y = s()\\n', '    assert id(x.field_items) != id(y.field_items)\\n', '    x = s()\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\0\\\\x05'\\n\", \"    x = s(b'\\\\x20\\\\xff')\\n\", '    assert x.first == 0x20\\n', '    assert x.second == 0xff\\n', '    x = s()\\n', \"    x.unpack(b'\\\\x31\\\\xf0')\\n\", '    assert x.first == 0x31\\n', '    assert x.second == 0xf0\\n', '    x = e()\\n', '    x.normal = 0xf010\\n', '    x.little = 0x1311\\n', '    x.big = 0xf3f2\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\xf0\\\\x10\\\\x11\\\\x13\\\\xf3\\\\xf2'\\n\"]",
  "context": "ndata.uint8(default=5)\n\ndef test_field_get():\n    x = s()\n    assert x.first == 0\n\ndef test_default():\n    x"
 },
 "571": {
  "name": "x",
  "type": "s",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_basic.py",
  "lineno": "14",
  "column": "4",
  "slicing": "['    x = s()\\n', '    assert x.first == 0\\n', '    x = s()\\n', '    assert x.second == 5\\n', '    x = s()\\n', '    x.first = 123\\n', '    assert x.first == 123\\n', '    x = s()\\n', '    y = s()\\n', '    assert id(x.field_items) != id(y.field_items)\\n', '    x = s()\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\0\\\\x05'\\n\", \"    x = s(b'\\\\x20\\\\xff')\\n\", '    assert x.first == 0x20\\n', '    assert x.second == 0xff\\n', '    x = s()\\n', \"    x.unpack(b'\\\\x31\\\\xf0')\\n\", '    assert x.first == 0x31\\n', '    assert x.second == 0xf0\\n', '    x = e()\\n', '    x.normal = 0xf010\\n', '    x.little = 0x1311\\n', '    x.big = 0xf3f2\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\xf0\\\\x10\\\\x11\\\\x13\\\\xf3\\\\xf2'\\n\"]",
  "context": "\n    assert x.first == 0\n\ndef test_default():\n    x = s()\n    assert x.second == 5\n\ndef test_field_set():\n  "
 },
 "572": {
  "name": "x",
  "type": "s",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_basic.py",
  "lineno": "18",
  "column": "4",
  "slicing": "['    x = s()\\n', '    assert x.first == 0\\n', '    x = s()\\n', '    assert x.second == 5\\n', '    x = s()\\n', '    x.first = 123\\n', '    assert x.first == 123\\n', '    x = s()\\n', '    y = s()\\n', '    assert id(x.field_items) != id(y.field_items)\\n', '    x = s()\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\0\\\\x05'\\n\", \"    x = s(b'\\\\x20\\\\xff')\\n\", '    assert x.first == 0x20\\n', '    assert x.second == 0xff\\n', '    x = s()\\n', \"    x.unpack(b'\\\\x31\\\\xf0')\\n\", '    assert x.first == 0x31\\n', '    assert x.second == 0xf0\\n', '    x = e()\\n', '    x.normal = 0xf010\\n', '    x.little = 0x1311\\n', '    x.big = 0xf3f2\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\xf0\\\\x10\\\\x11\\\\x13\\\\xf3\\\\xf2'\\n\"]",
  "context": "  assert x.second == 5\n\ndef test_field_set():\n    x = s()\n    x.first = 123\n    assert x.first == 123\n\ndef t"
 },
 "573": {
  "name": "x",
  "type": "s",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_basic.py",
  "lineno": "23",
  "column": "4",
  "slicing": "['    x = s()\\n', '    assert x.first == 0\\n', '    x = s()\\n', '    assert x.second == 5\\n', '    x = s()\\n', '    x.first = 123\\n', '    assert x.first == 123\\n', '    x = s()\\n', '    y = s()\\n', '    assert id(x.field_items) != id(y.field_items)\\n', '    x = s()\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\0\\\\x05'\\n\", \"    x = s(b'\\\\x20\\\\xff')\\n\", '    assert x.first == 0x20\\n', '    assert x.second == 0xff\\n', '    x = s()\\n', \"    x.unpack(b'\\\\x31\\\\xf0')\\n\", '    assert x.first == 0x31\\n', '    assert x.second == 0xf0\\n', '    x = e()\\n', '    x.normal = 0xf010\\n', '    x.little = 0x1311\\n', '    x.big = 0xf3f2\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\xf0\\\\x10\\\\x11\\\\x13\\\\xf3\\\\xf2'\\n\"]",
  "context": ".first == 123\n\ndef test_unique_field_items():\n    x = s()\n    y = s()\n    assert id(x.field_items) != id(y.f"
 },
 "574": {
  "name": "y",
  "type": "s",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_basic.py",
  "lineno": "24",
  "column": "4",
  "slicing": "['    x = s()\\n', '    assert x.first == 0\\n', '    x = s()\\n', '    assert x.second == 5\\n', '    x = s()\\n', '    x.first = 123\\n', '    assert x.first == 123\\n', '    x = s()\\n', '    y = s()\\n', '    assert id(x.field_items) != id(y.field_items)\\n', '    x = s()\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\0\\\\x05'\\n\", \"    x = s(b'\\\\x20\\\\xff')\\n\", '    assert x.first == 0x20\\n', '    assert x.second == 0xff\\n', '    x = s()\\n', \"    x.unpack(b'\\\\x31\\\\xf0')\\n\", '    assert x.first == 0x31\\n', '    assert x.second == 0xf0\\n', '    x = e()\\n', '    x.normal = 0xf010\\n', '    x.little = 0x1311\\n', '    x.big = 0xf3f2\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\xf0\\\\x10\\\\x11\\\\x13\\\\xf3\\\\xf2'\\n\"]",
  "context": "3\n\ndef test_unique_field_items():\n    x = s()\n    y = s()\n    assert id(x.field_items) != id(y.field_items)\n"
 },
 "575": {
  "name": "x",
  "type": "s",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_basic.py",
  "lineno": "28",
  "column": "4",
  "slicing": "['    x = s()\\n', '    assert x.first == 0\\n', '    x = s()\\n', '    assert x.second == 5\\n', '    x = s()\\n', '    x.first = 123\\n', '    assert x.first == 123\\n', '    x = s()\\n', '    y = s()\\n', '    assert id(x.field_items) != id(y.field_items)\\n', '    x = s()\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\0\\\\x05'\\n\", \"    x = s(b'\\\\x20\\\\xff')\\n\", '    assert x.first == 0x20\\n', '    assert x.second == 0xff\\n', '    x = s()\\n', \"    x.unpack(b'\\\\x31\\\\xf0')\\n\", '    assert x.first == 0x31\\n', '    assert x.second == 0xf0\\n', '    x = e()\\n', '    x.normal = 0xf010\\n', '    x.little = 0x1311\\n', '    x.big = 0xf3f2\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\xf0\\\\x10\\\\x11\\\\x13\\\\xf3\\\\xf2'\\n\"]",
  "context": "items) != id(y.field_items)\n\ndef test_pack():\n    x = s()\n    packed = x.pack()\n    assert packed == b'\\0\\x0"
 },
 "576": {
  "name": "x",
  "type": "s",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_basic.py",
  "lineno": "33",
  "column": "4",
  "slicing": "['    x = s()\\n', '    assert x.first == 0\\n', '    x = s()\\n', '    assert x.second == 5\\n', '    x = s()\\n', '    x.first = 123\\n', '    assert x.first == 123\\n', '    x = s()\\n', '    y = s()\\n', '    assert id(x.field_items) != id(y.field_items)\\n', '    x = s()\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\0\\\\x05'\\n\", \"    x = s(b'\\\\x20\\\\xff')\\n\", '    assert x.first == 0x20\\n', '    assert x.second == 0xff\\n', '    x = s()\\n', \"    x.unpack(b'\\\\x31\\\\xf0')\\n\", '    assert x.first == 0x31\\n', '    assert x.second == 0xf0\\n', '    x = e()\\n', '    x.normal = 0xf010\\n', '    x.little = 0x1311\\n', '    x.big = 0xf3f2\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\xf0\\\\x10\\\\x11\\\\x13\\\\xf3\\\\xf2'\\n\"]",
  "context": "cked == b'\\0\\x05'\n\ndef test_initial_unpack():\n    x = s(b'\\x20\\xff')\n    assert x.first == 0x20\n    assert x.second == "
 },
 "577": {
  "name": "x",
  "type": "s",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_basic.py",
  "lineno": "38",
  "column": "4",
  "slicing": "['    x = s()\\n', '    assert x.first == 0\\n', '    x = s()\\n', '    assert x.second == 5\\n', '    x = s()\\n', '    x.first = 123\\n', '    assert x.first == 123\\n', '    x = s()\\n', '    y = s()\\n', '    assert id(x.field_items) != id(y.field_items)\\n', '    x = s()\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\0\\\\x05'\\n\", \"    x = s(b'\\\\x20\\\\xff')\\n\", '    assert x.first == 0x20\\n', '    assert x.second == 0xff\\n', '    x = s()\\n', \"    x.unpack(b'\\\\x31\\\\xf0')\\n\", '    assert x.first == 0x31\\n', '    assert x.second == 0xf0\\n', '    x = e()\\n', '    x.normal = 0xf010\\n', '    x.little = 0x1311\\n', '    x.big = 0xf3f2\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\xf0\\\\x10\\\\x11\\\\x13\\\\xf3\\\\xf2'\\n\"]",
  "context": "  assert x.second == 0xff\n\ndef test_unpack():\n    x = s()\n    x.unpack(b'\\x31\\xf0')\n    assert x.first == 0x"
 },
 "578": {
  "name": "normal",
  "type": "pyndata.uint16",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/tests/test_basic.py",
  "lineno": "46",
  "column": "4",
  "slicing": "['    x = s()\\n', '    assert x.first == 0\\n', '    x = s()\\n', '    assert x.second == 5\\n', '    x = s()\\n', '    x.first = 123\\n', '    assert x.first == 123\\n', '    x = s()\\n', '    y = s()\\n', '    assert id(x.field_items) != id(y.field_items)\\n', '    x = s()\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\0\\\\x05'\\n\", \"    x = s(b'\\\\x20\\\\xff')\\n\", '    assert x.first == 0x20\\n', '    assert x.second == 0xff\\n', '    x = s()\\n', \"    x.unpack(b'\\\\x31\\\\xf0')\\n\", '    assert x.first == 0x31\\n', '    assert x.second == 0xf0\\n', '    normal = pyndata.uint16()\\n', '    x = e()\\n', '    x.normal = 0xf010\\n', '    x.little = 0x1311\\n', '    x.big = 0xf3f2\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\xf0\\\\x10\\\\x11\\\\x13\\\\xf3\\\\xf2'\\n\"]",
  "context": "ss e(pyndata.Struct):\n    __ENDIAN__ = 'big'\n\n    normal = pyndata.uint16()\n    little = pyndata.uint16(endian='little')\n    b"
 },
 "579": {
  "name": "little",
  "type": "pyndata.uint16",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/tests/test_basic.py",
  "lineno": "47",
  "column": "4",
  "slicing": "['    x = s()\\n', '    assert x.first == 0\\n', '    x = s()\\n', '    assert x.second == 5\\n', '    x = s()\\n', '    x.first = 123\\n', '    assert x.first == 123\\n', '    x = s()\\n', '    y = s()\\n', '    assert id(x.field_items) != id(y.field_items)\\n', '    x = s()\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\0\\\\x05'\\n\", \"    x = s(b'\\\\x20\\\\xff')\\n\", '    assert x.first == 0x20\\n', '    assert x.second == 0xff\\n', '    x = s()\\n', \"    x.unpack(b'\\\\x31\\\\xf0')\\n\", '    assert x.first == 0x31\\n', '    assert x.second == 0xf0\\n', \"    little = pyndata.uint16(endian='little')\\n\", '    x = e()\\n', '    x.normal = 0xf010\\n', '    x.little = 0x1311\\n', '    x.big = 0xf3f2\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\xf0\\\\x10\\\\x11\\\\x13\\\\xf3\\\\xf2'\\n\"]",
  "context": "DIAN__ = 'big'\n\n    normal = pyndata.uint16()\n    little = pyndata.uint16(endian='little')\n    big = pyndata.uint16(endian='big')\n\ndef test_e"
 },
 "580": {
  "name": "big",
  "type": "pyndata.uint16",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/tests/test_basic.py",
  "lineno": "48",
  "column": "4",
  "slicing": "['    x = s()\\n', '    assert x.first == 0\\n', '    x = s()\\n', '    assert x.second == 5\\n', '    x = s()\\n', '    x.first = 123\\n', '    assert x.first == 123\\n', '    x = s()\\n', '    y = s()\\n', '    assert id(x.field_items) != id(y.field_items)\\n', '    x = s()\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\0\\\\x05'\\n\", \"    x = s(b'\\\\x20\\\\xff')\\n\", '    assert x.first == 0x20\\n', '    assert x.second == 0xff\\n', '    x = s()\\n', \"    x.unpack(b'\\\\x31\\\\xf0')\\n\", '    assert x.first == 0x31\\n', '    assert x.second == 0xf0\\n', \"    big = pyndata.uint16(endian='big')\\n\", '    x = e()\\n', '    x.normal = 0xf010\\n', '    x.little = 0x1311\\n', '    x.big = 0xf3f2\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\xf0\\\\x10\\\\x11\\\\x13\\\\xf3\\\\xf2'\\n\"]",
  "context": "\n    little = pyndata.uint16(endian='little')\n    big = pyndata.uint16(endian='big')\n\ndef test_endian():\n    x = e()\n    x.normal = 0xf"
 },
 "581": {
  "name": "x",
  "type": "e",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_basic.py",
  "lineno": "51",
  "column": "4",
  "slicing": "['    x = s()\\n', '    assert x.first == 0\\n', '    x = s()\\n', '    assert x.second == 5\\n', '    x = s()\\n', '    x.first = 123\\n', '    assert x.first == 123\\n', '    x = s()\\n', '    y = s()\\n', '    assert id(x.field_items) != id(y.field_items)\\n', '    x = s()\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\0\\\\x05'\\n\", \"    x = s(b'\\\\x20\\\\xff')\\n\", '    assert x.first == 0x20\\n', '    assert x.second == 0xff\\n', '    x = s()\\n', \"    x.unpack(b'\\\\x31\\\\xf0')\\n\", '    assert x.first == 0x31\\n', '    assert x.second == 0xf0\\n', '    x = e()\\n', '    x.normal = 0xf010\\n', '    x.little = 0x1311\\n', '    x.big = 0xf3f2\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\xf0\\\\x10\\\\x11\\\\x13\\\\xf3\\\\xf2'\\n\"]",
  "context": "data.uint16(endian='big')\n\ndef test_endian():\n    x = e()\n    x.normal = 0xf010\n    x.little = 0x1311\n    x."
 },
 "582": {
  "name": "f",
  "type": "field.Field",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/tests/test_basic.py",
  "lineno": "59",
  "column": "4",
  "slicing": "['    x = s()\\n', '    assert x.first == 0\\n', '    x = s()\\n', '    assert x.second == 5\\n', '    x = s()\\n', '    x.first = 123\\n', '    assert x.first == 123\\n', '    x = s()\\n', '    y = s()\\n', '    assert id(x.field_items) != id(y.field_items)\\n', '    x = s()\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\0\\\\x05'\\n\", \"    x = s(b'\\\\x20\\\\xff')\\n\", '    assert x.first == 0x20\\n', '    assert x.second == 0xff\\n', '    x = s()\\n', \"    x.unpack(b'\\\\x31\\\\xf0')\\n\", '    assert x.first == 0x31\\n', '    assert x.second == 0xf0\\n', '    x = e()\\n', '    x.normal = 0xf010\\n', '    x.little = 0x1311\\n', '    x.big = 0xf3f2\\n', '    packed = x.pack()\\n', \"    assert packed == b'\\\\xf0\\\\x10\\\\x11\\\\x13\\\\xf3\\\\xf2'\\n\", '    f = pyndata.Field()\\n', '        f.pack(None, None)\\n', '        f.unpack(None, None)\\n']",
  "context": "10\\x11\\x13\\xf3\\xf2'\n\ndef test_field_raises():\n    f = pyndata.Field()\n    with pytest.raises(NotImplementedError):\n     "
 },
 "583": {
  "name": "f",
  "type": "pyndata.uint8",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/tests/test_padding.py",
  "lineno": "4",
  "column": "4",
  "slicing": "['    f = pyndata.uint8(default=0xff)\\n']",
  "context": "import pyndata\n\nclass padded(pyndata.Struct):\n    f = pyndata.uint8(default=0xff)\n    pad = pyndata.padding(3)\n\ndef test_padding_unp"
 },
 "584": {
  "name": "pad",
  "type": "padding.padding",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/tests/test_padding.py",
  "lineno": "5",
  "column": "4",
  "slicing": "['    pad = pyndata.padding(3)\\n']",
  "context": ".Struct):\n    f = pyndata.uint8(default=0xff)\n    pad = pyndata.padding(3)\n\ndef test_padding_unpack():\n    x = padded()\n    x"
 },
 "585": {
  "name": "x",
  "type": "padded",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_padding.py",
  "lineno": "8",
  "column": "4",
  "slicing": "['    x = padded()\\n', \"    x.pad = b'\\\\x01\\\\x02\\\\x03'\\n\", \"    assert x.pack() == b'\\\\xff\\\\x01\\\\x02\\\\x03'\\n\", \"    x.unpack(b'\\\\x20\\\\x01\\\\x02\\\\x03')\\n\", \"    assert x.pad == b'\\\\x01\\\\x02\\\\x03'\\n\"]",
  "context": "yndata.padding(3)\n\ndef test_padding_unpack():\n    x = padded()\n    x.pad = b'\\x01\\x02\\x03'\n    assert x.pack() =="
 },
 "586": {
  "name": "x",
  "type": "padded",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_padding.py",
  "lineno": "13",
  "column": "4",
  "slicing": "['    x = padded()\\n', \"    x.pad = b'\\\\x01\\\\x02\\\\x03'\\n\", \"    assert x.pack() == b'\\\\xff\\\\x01\\\\x02\\\\x03'\\n\", '    x = padded()\\n', \"    x.unpack(b'\\\\x20\\\\x01\\\\x02\\\\x03')\\n\", \"    assert x.pad == b'\\\\x01\\\\x02\\\\x03'\\n\"]",
  "context": "b'\\xff\\x01\\x02\\x03'\n\ndef test_padding_pack():\n    x = padded()\n    x.unpack(b'\\x20\\x01\\x02\\x03')\n    assert x.pad"
 },
 "587": {
  "name": "real",
  "type": "pyndata.uint16",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/tests/test_bitfield.py",
  "lineno": "4",
  "column": "4",
  "slicing": "['    real = pyndata.uint16()\\n', '    bit1 = pyndata.BitField(real, 4, shift=0)\\n', '    bit2 = pyndata.BitField(real, 1, shift=4)\\n', '    bit3 = pyndata.BitField(real, 3, shift=5)\\n', '    bit4 = pyndata.BitField(real, 8, shift=8)\\n', '    b = BitFieldTests()\\n', '    b.bit1 = 3\\n', '    b.bit2 = 1\\n', '    b.bit3 = 6\\n', '    b.bit4 = 0b10101010\\n', '    assert b.bit1 == 3\\n', '    assert b.bit2 == 1\\n', '    assert b.bit3 == 6\\n', '    assert b.bit4 == 0b10101010\\n', '    real = pyndata.uint16()\\n', '    bit1 = pyndata.BitField(real, 4)\\n', '    bit2 = pyndata.BitField(real, 1)\\n', '    bit3 = pyndata.BitField(real, 3)\\n', '    bit4 = pyndata.BitField(real, 8)\\n', '    b.bit1 = 3\\n', '    b.bit2 = 1\\n', '    b.bit3 = 6\\n', '    b.bit4 = 0b10101010\\n', '    assert b.bit1 == 3\\n', '    assert b.bit2 == 1\\n', '    assert b.bit3 == 6\\n', '    assert b.bit4 == 0b10101010\\n']",
  "context": "pyndata\n\nclass BitFieldTests(pyndata.Struct):\n    real = pyndata.uint16()\n    bit1 = pyndata.BitField(real, 4, shift=0)\n    "
 },
 "588": {
  "name": "bit1",
  "type": "bitfield.BitField",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/tests/test_bitfield.py",
  "lineno": "5",
  "column": "4",
  "slicing": "['    real = pyndata.uint16()\\n', '    bit1 = pyndata.BitField(real, 4, shift=0)\\n', '    bit2 = pyndata.BitField(real, 1, shift=4)\\n', '    bit3 = pyndata.BitField(real, 3, shift=5)\\n', '    bit4 = pyndata.BitField(real, 8, shift=8)\\n', '    b = BitFieldTests()\\n', '    b.bit1 = 3\\n', '    b.bit2 = 1\\n', '    b.bit3 = 6\\n', '    b.bit4 = 0b10101010\\n', '    assert b.bit1 == 3\\n', '    assert b.bit2 == 1\\n', '    assert b.bit3 == 6\\n', '    assert b.bit4 == 0b10101010\\n', '    real = pyndata.uint16()\\n', '    bit1 = pyndata.BitField(real, 4)\\n', '    bit2 = pyndata.BitField(real, 1)\\n', '    bit3 = pyndata.BitField(real, 3)\\n', '    bit4 = pyndata.BitField(real, 8)\\n', '    b.bit1 = 3\\n', '    b.bit2 = 1\\n', '    b.bit3 = 6\\n', '    b.bit4 = 0b10101010\\n', '    assert b.bit1 == 3\\n', '    assert b.bit2 == 1\\n', '    assert b.bit3 == 6\\n', '    assert b.bit4 == 0b10101010\\n']",
  "context": "(pyndata.Struct):\n    real = pyndata.uint16()\n    bit1 = pyndata.BitField(real, 4, shift=0)\n    bit2 = pyndata.BitField(real, 1, shift=4)\n    "
 },
 "589": {
  "name": "bit2",
  "type": "bitfield.BitField",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/tests/test_bitfield.py",
  "lineno": "6",
  "column": "4",
  "slicing": "['    real = pyndata.uint16()\\n', '    bit1 = pyndata.BitField(real, 4, shift=0)\\n', '    bit2 = pyndata.BitField(real, 1, shift=4)\\n', '    bit3 = pyndata.BitField(real, 3, shift=5)\\n', '    bit4 = pyndata.BitField(real, 8, shift=8)\\n', '    b = BitFieldTests()\\n', '    b.bit1 = 3\\n', '    b.bit2 = 1\\n', '    b.bit3 = 6\\n', '    b.bit4 = 0b10101010\\n', '    assert b.bit1 == 3\\n', '    assert b.bit2 == 1\\n', '    assert b.bit3 == 6\\n', '    assert b.bit4 == 0b10101010\\n', '    real = pyndata.uint16()\\n', '    bit1 = pyndata.BitField(real, 4)\\n', '    bit2 = pyndata.BitField(real, 1)\\n', '    bit3 = pyndata.BitField(real, 3)\\n', '    bit4 = pyndata.BitField(real, 8)\\n', '    b.bit1 = 3\\n', '    b.bit2 = 1\\n', '    b.bit3 = 6\\n', '    b.bit4 = 0b10101010\\n', '    assert b.bit1 == 3\\n', '    assert b.bit2 == 1\\n', '    assert b.bit3 == 6\\n', '    assert b.bit4 == 0b10101010\\n']",
  "context": "    bit1 = pyndata.BitField(real, 4, shift=0)\n    bit2 = pyndata.BitField(real, 1, shift=4)\n    bit3 = pyndata.BitField(real, 3, shift=5)\n    "
 },
 "590": {
  "name": "bit3",
  "type": "bitfield.BitField",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/tests/test_bitfield.py",
  "lineno": "7",
  "column": "4",
  "slicing": "['    real = pyndata.uint16()\\n', '    bit1 = pyndata.BitField(real, 4, shift=0)\\n', '    bit2 = pyndata.BitField(real, 1, shift=4)\\n', '    bit3 = pyndata.BitField(real, 3, shift=5)\\n', '    bit4 = pyndata.BitField(real, 8, shift=8)\\n', '    b = BitFieldTests()\\n', '    b.bit1 = 3\\n', '    b.bit2 = 1\\n', '    b.bit3 = 6\\n', '    b.bit4 = 0b10101010\\n', '    assert b.bit1 == 3\\n', '    assert b.bit2 == 1\\n', '    assert b.bit3 == 6\\n', '    assert b.bit4 == 0b10101010\\n', '    real = pyndata.uint16()\\n', '    bit1 = pyndata.BitField(real, 4)\\n', '    bit2 = pyndata.BitField(real, 1)\\n', '    bit3 = pyndata.BitField(real, 3)\\n', '    bit4 = pyndata.BitField(real, 8)\\n', '    b.bit1 = 3\\n', '    b.bit2 = 1\\n', '    b.bit3 = 6\\n', '    b.bit4 = 0b10101010\\n', '    assert b.bit1 == 3\\n', '    assert b.bit2 == 1\\n', '    assert b.bit3 == 6\\n', '    assert b.bit4 == 0b10101010\\n']",
  "context": "    bit2 = pyndata.BitField(real, 1, shift=4)\n    bit3 = pyndata.BitField(real, 3, shift=5)\n    bit4 = pyndata.BitField(real, 8, shift=8)\n\ndef"
 },
 "591": {
  "name": "bit4",
  "type": "bitfield.BitField",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/tests/test_bitfield.py",
  "lineno": "8",
  "column": "4",
  "slicing": "['    real = pyndata.uint16()\\n', '    bit1 = pyndata.BitField(real, 4, shift=0)\\n', '    bit2 = pyndata.BitField(real, 1, shift=4)\\n', '    bit3 = pyndata.BitField(real, 3, shift=5)\\n', '    bit4 = pyndata.BitField(real, 8, shift=8)\\n', '    b = BitFieldTests()\\n', '    b.bit1 = 3\\n', '    b.bit2 = 1\\n', '    b.bit3 = 6\\n', '    b.bit4 = 0b10101010\\n', '    assert b.bit1 == 3\\n', '    assert b.bit2 == 1\\n', '    assert b.bit3 == 6\\n', '    assert b.bit4 == 0b10101010\\n', '    real = pyndata.uint16()\\n', '    bit1 = pyndata.BitField(real, 4)\\n', '    bit2 = pyndata.BitField(real, 1)\\n', '    bit3 = pyndata.BitField(real, 3)\\n', '    bit4 = pyndata.BitField(real, 8)\\n', '    b.bit1 = 3\\n', '    b.bit2 = 1\\n', '    b.bit3 = 6\\n', '    b.bit4 = 0b10101010\\n', '    assert b.bit1 == 3\\n', '    assert b.bit2 == 1\\n', '    assert b.bit3 == 6\\n', '    assert b.bit4 == 0b10101010\\n']",
  "context": "    bit3 = pyndata.BitField(real, 3, shift=5)\n    bit4 = pyndata.BitField(real, 8, shift=8)\n\ndef test_bitfield():\n    b = BitFieldTests()\n    "
 },
 "592": {
  "name": "b",
  "type": "BitFieldTests",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_bitfield.py",
  "lineno": "11",
  "column": "4",
  "slicing": "['    real = pyndata.uint16()\\n', '    bit1 = pyndata.BitField(real, 4, shift=0)\\n', '    bit2 = pyndata.BitField(real, 1, shift=4)\\n', '    bit3 = pyndata.BitField(real, 3, shift=5)\\n', '    bit4 = pyndata.BitField(real, 8, shift=8)\\n', '    b = BitFieldTests()\\n', '    b.bit1 = 3\\n', '    b.bit2 = 1\\n', '    b.bit3 = 6\\n', '    b.bit4 = 0b10101010\\n', '    assert b.bit1 == 3\\n', '    assert b.bit2 == 1\\n', '    assert b.bit3 == 6\\n', '    assert b.bit4 == 0b10101010\\n', '    real = pyndata.uint16()\\n', '    bit1 = pyndata.BitField(real, 4)\\n', '    bit2 = pyndata.BitField(real, 1)\\n', '    bit3 = pyndata.BitField(real, 3)\\n', '    bit4 = pyndata.BitField(real, 8)\\n', '    b.bit1 = 3\\n', '    b.bit2 = 1\\n', '    b.bit3 = 6\\n', '    b.bit4 = 0b10101010\\n', '    assert b.bit1 == 3\\n', '    assert b.bit2 == 1\\n', '    assert b.bit3 == 6\\n', '    assert b.bit4 == 0b10101010\\n']",
  "context": "Field(real, 8, shift=8)\n\ndef test_bitfield():\n    b = BitFieldTests()\n    b.bit1 = 3\n    b.bit2 = 1\n    b.bit3 = 6\n    b"
 },
 "593": {
  "name": "real",
  "type": "pyndata.uint16",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/tests/test_bitfield.py",
  "lineno": "22",
  "column": "4",
  "slicing": "['    real = pyndata.uint16()\\n', '    bit1 = pyndata.BitField(real, 4, shift=0)\\n', '    bit2 = pyndata.BitField(real, 1, shift=4)\\n', '    bit3 = pyndata.BitField(real, 3, shift=5)\\n', '    bit4 = pyndata.BitField(real, 8, shift=8)\\n', '    b = BitFieldTests()\\n', '    b.bit1 = 3\\n', '    b.bit2 = 1\\n', '    b.bit3 = 6\\n', '    b.bit4 = 0b10101010\\n', '    assert b.bit1 == 3\\n', '    assert b.bit2 == 1\\n', '    assert b.bit3 == 6\\n', '    assert b.bit4 == 0b10101010\\n', '    real = pyndata.uint16()\\n', '    bit1 = pyndata.BitField(real, 4)\\n', '    bit2 = pyndata.BitField(real, 1)\\n', '    bit3 = pyndata.BitField(real, 3)\\n', '    bit4 = pyndata.BitField(real, 8)\\n', '    b.bit1 = 3\\n', '    b.bit2 = 1\\n', '    b.bit3 = 6\\n', '    b.bit4 = 0b10101010\\n', '    assert b.bit1 == 3\\n', '    assert b.bit2 == 1\\n', '    assert b.bit3 == 6\\n', '    assert b.bit4 == 0b10101010\\n']",
  "context": "101010\n\nclass BitField2Tests(pyndata.Struct):\n    real = pyndata.uint16()\n    bit1 = pyndata.BitField(real, 4)\n    bit2 = py"
 },
 "594": {
  "name": "bit1",
  "type": "bitfield.BitField",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/tests/test_bitfield.py",
  "lineno": "23",
  "column": "4",
  "slicing": "['    real = pyndata.uint16()\\n', '    bit1 = pyndata.BitField(real, 4, shift=0)\\n', '    bit2 = pyndata.BitField(real, 1, shift=4)\\n', '    bit3 = pyndata.BitField(real, 3, shift=5)\\n', '    bit4 = pyndata.BitField(real, 8, shift=8)\\n', '    b = BitFieldTests()\\n', '    b.bit1 = 3\\n', '    b.bit2 = 1\\n', '    b.bit3 = 6\\n', '    b.bit4 = 0b10101010\\n', '    assert b.bit1 == 3\\n', '    assert b.bit2 == 1\\n', '    assert b.bit3 == 6\\n', '    assert b.bit4 == 0b10101010\\n', '    real = pyndata.uint16()\\n', '    bit1 = pyndata.BitField(real, 4)\\n', '    bit2 = pyndata.BitField(real, 1)\\n', '    bit3 = pyndata.BitField(real, 3)\\n', '    bit4 = pyndata.BitField(real, 8)\\n', '    b.bit1 = 3\\n', '    b.bit2 = 1\\n', '    b.bit3 = 6\\n', '    b.bit4 = 0b10101010\\n', '    assert b.bit1 == 3\\n', '    assert b.bit2 == 1\\n', '    assert b.bit3 == 6\\n', '    assert b.bit4 == 0b10101010\\n']",
  "context": "(pyndata.Struct):\n    real = pyndata.uint16()\n    bit1 = pyndata.BitField(real, 4)\n    bit2 = pyndata.BitField(real, 1)\n    bit3 = py"
 },
 "595": {
  "name": "bit2",
  "type": "bitfield.BitField",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/tests/test_bitfield.py",
  "lineno": "24",
  "column": "4",
  "slicing": "['    real = pyndata.uint16()\\n', '    bit1 = pyndata.BitField(real, 4, shift=0)\\n', '    bit2 = pyndata.BitField(real, 1, shift=4)\\n', '    bit3 = pyndata.BitField(real, 3, shift=5)\\n', '    bit4 = pyndata.BitField(real, 8, shift=8)\\n', '    b = BitFieldTests()\\n', '    b.bit1 = 3\\n', '    b.bit2 = 1\\n', '    b.bit3 = 6\\n', '    b.bit4 = 0b10101010\\n', '    assert b.bit1 == 3\\n', '    assert b.bit2 == 1\\n', '    assert b.bit3 == 6\\n', '    assert b.bit4 == 0b10101010\\n', '    real = pyndata.uint16()\\n', '    bit1 = pyndata.BitField(real, 4)\\n', '    bit2 = pyndata.BitField(real, 1)\\n', '    bit3 = pyndata.BitField(real, 3)\\n', '    bit4 = pyndata.BitField(real, 8)\\n', '    b.bit1 = 3\\n', '    b.bit2 = 1\\n', '    b.bit3 = 6\\n', '    b.bit4 = 0b10101010\\n', '    assert b.bit1 == 3\\n', '    assert b.bit2 == 1\\n', '    assert b.bit3 == 6\\n', '    assert b.bit4 == 0b10101010\\n']",
  "context": "uint16()\n    bit1 = pyndata.BitField(real, 4)\n    bit2 = pyndata.BitField(real, 1)\n    bit3 = pyndata.BitField(real, 3)\n    bit4 = py"
 },
 "596": {
  "name": "bit3",
  "type": "bitfield.BitField",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/tests/test_bitfield.py",
  "lineno": "25",
  "column": "4",
  "slicing": "['    real = pyndata.uint16()\\n', '    bit1 = pyndata.BitField(real, 4, shift=0)\\n', '    bit2 = pyndata.BitField(real, 1, shift=4)\\n', '    bit3 = pyndata.BitField(real, 3, shift=5)\\n', '    bit4 = pyndata.BitField(real, 8, shift=8)\\n', '    b = BitFieldTests()\\n', '    b.bit1 = 3\\n', '    b.bit2 = 1\\n', '    b.bit3 = 6\\n', '    b.bit4 = 0b10101010\\n', '    assert b.bit1 == 3\\n', '    assert b.bit2 == 1\\n', '    assert b.bit3 == 6\\n', '    assert b.bit4 == 0b10101010\\n', '    real = pyndata.uint16()\\n', '    bit1 = pyndata.BitField(real, 4)\\n', '    bit2 = pyndata.BitField(real, 1)\\n', '    bit3 = pyndata.BitField(real, 3)\\n', '    bit4 = pyndata.BitField(real, 8)\\n', '    b.bit1 = 3\\n', '    b.bit2 = 1\\n', '    b.bit3 = 6\\n', '    b.bit4 = 0b10101010\\n', '    assert b.bit1 == 3\\n', '    assert b.bit2 == 1\\n', '    assert b.bit3 == 6\\n', '    assert b.bit4 == 0b10101010\\n']",
  "context": "real, 4)\n    bit2 = pyndata.BitField(real, 1)\n    bit3 = pyndata.BitField(real, 3)\n    bit4 = pyndata.BitField(real, 8)\n\ndef test_bit"
 },
 "597": {
  "name": "bit4",
  "type": "bitfield.BitField",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "zfsp/pyndata/tests/test_bitfield.py",
  "lineno": "26",
  "column": "4",
  "slicing": "['    real = pyndata.uint16()\\n', '    bit1 = pyndata.BitField(real, 4, shift=0)\\n', '    bit2 = pyndata.BitField(real, 1, shift=4)\\n', '    bit3 = pyndata.BitField(real, 3, shift=5)\\n', '    bit4 = pyndata.BitField(real, 8, shift=8)\\n', '    b = BitFieldTests()\\n', '    b.bit1 = 3\\n', '    b.bit2 = 1\\n', '    b.bit3 = 6\\n', '    b.bit4 = 0b10101010\\n', '    assert b.bit1 == 3\\n', '    assert b.bit2 == 1\\n', '    assert b.bit3 == 6\\n', '    assert b.bit4 == 0b10101010\\n', '    real = pyndata.uint16()\\n', '    bit1 = pyndata.BitField(real, 4)\\n', '    bit2 = pyndata.BitField(real, 1)\\n', '    bit3 = pyndata.BitField(real, 3)\\n', '    bit4 = pyndata.BitField(real, 8)\\n', '    b.bit1 = 3\\n', '    b.bit2 = 1\\n', '    b.bit3 = 6\\n', '    b.bit4 = 0b10101010\\n', '    assert b.bit1 == 3\\n', '    assert b.bit2 == 1\\n', '    assert b.bit3 == 6\\n', '    assert b.bit4 == 0b10101010\\n']",
  "context": "real, 1)\n    bit3 = pyndata.BitField(real, 3)\n    bit4 = pyndata.BitField(real, 8)\n\ndef test_bitfield2():\n    b = BitFieldTests()\n   "
 },
 "598": {
  "name": "b",
  "type": "BitFieldTests",
  "class": "customized",
  "approach": "annotation",
  "file_path": "zfsp/pyndata/tests/test_bitfield.py",
  "lineno": "29",
  "column": "4",
  "slicing": "['    real = pyndata.uint16()\\n', '    bit1 = pyndata.BitField(real, 4, shift=0)\\n', '    bit2 = pyndata.BitField(real, 1, shift=4)\\n', '    bit3 = pyndata.BitField(real, 3, shift=5)\\n', '    bit4 = pyndata.BitField(real, 8, shift=8)\\n', '    b = BitFieldTests()\\n', '    b.bit1 = 3\\n', '    b.bit2 = 1\\n', '    b.bit3 = 6\\n', '    b.bit4 = 0b10101010\\n', '    assert b.bit1 == 3\\n', '    assert b.bit2 == 1\\n', '    assert b.bit3 == 6\\n', '    assert b.bit4 == 0b10101010\\n', '    real = pyndata.uint16()\\n', '    bit1 = pyndata.BitField(real, 4)\\n', '    bit2 = pyndata.BitField(real, 1)\\n', '    bit3 = pyndata.BitField(real, 3)\\n', '    bit4 = pyndata.BitField(real, 8)\\n', '    b = BitFieldTests()\\n', '    b.bit1 = 3\\n', '    b.bit2 = 1\\n', '    b.bit3 = 6\\n', '    b.bit4 = 0b10101010\\n', '    assert b.bit1 == 3\\n', '    assert b.bit2 == 1\\n', '    assert b.bit3 == 6\\n', '    assert b.bit4 == 0b10101010\\n']",
  "context": "data.BitField(real, 8)\n\ndef test_bitfield2():\n    b = BitFieldTests()\n    b.bit1 = 3\n    b.bit2 = 1\n    b.bit3 = 6\n    b"
 }
}