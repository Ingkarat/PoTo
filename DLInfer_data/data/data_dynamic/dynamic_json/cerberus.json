{
 "1": {
  "name": "depth",
  "type": "int",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "311",
  "column": "4",
  "context": "lass:`~cerberus.errors.SchemaErrorTree`. \"\"\"\n\n    depth = 0\n    parent = None\n    path = ()\n\n    def __init__(",
  "context_lines": "        return getattr(error, self.tree_type + '_path')\n\n\nclass ErrorTree(ErrorTreeNode):\n    \"\"\" Base class for :class:`~cerberus.errors.DocumentErrorTree` and\n        :class:`~cerberus.errors.SchemaErrorTree`. \"\"\"\n\n    depth = 0\n    parent = None\n    path = ()\n\n    def __init__(self, errors: Iterable[ValidationError] = ()) -> None:\n        self.tree_root = self\n",
  "slicing": "    depth = 0\n"
 },
 "2": {
  "name": "parent",
  "type": "cerberus.typing.NoneType",
  "class": "imported",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "312",
  "column": "4",
  "context": "s.errors.SchemaErrorTree`. \"\"\"\n\n    depth = 0\n    parent = None\n    path = ()\n\n    def __init__(self, errors: Iter",
  "context_lines": "class ErrorTree(ErrorTreeNode):\n    \"\"\" Base class for :class:`~cerberus.errors.DocumentErrorTree` and\n        :class:`~cerberus.errors.SchemaErrorTree`. \"\"\"\n\n    depth = 0\n    parent = None\n    path = ()\n\n    def __init__(self, errors: Iterable[ValidationError] = ()) -> None:\n        self.tree_root = self\n        self.errors = ErrorList()\n",
  "slicing": "    parent = None\n"
 },
 "3": {
  "name": "tree_type",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "352",
  "column": "4",
  "context": "      structure of a validated document. \"\"\"\n\n    tree_type = 'document'\n\n\nclass SchemaErrorTree(ErrorTree):\n    \"\"\" Implem",
  "context_lines": "        return context\n\n\nclass DocumentErrorTree(ErrorTree):\n    \"\"\" Implements a dict-like class to query errors by indexes following the\n        structure of a validated document. \"\"\"\n\n    tree_type = 'document'\n\n\nclass SchemaErrorTree(ErrorTree):\n    \"\"\" Implements a dict-like class to query errors by indexes following the\n        structure of the used schema. \"\"\"\n\n",
  "slicing": "    tree_type = 'document'\n"
 },
 "4": {
  "name": "tree_type",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "359",
  "column": "4",
  "context": "he\n        structure of the used schema. \"\"\"\n\n    tree_type = 'schema'\n\n\nclass BaseErrorHandler(ABC):\n    \"\"\" Base class ",
  "context_lines": "    tree_type = 'document'\n\n\nclass SchemaErrorTree(ErrorTree):\n    \"\"\" Implements a dict-like class to query errors by indexes following the\n        structure of the used schema. \"\"\"\n\n    tree_type = 'schema'\n\n\nclass BaseErrorHandler(ABC):\n    \"\"\" Base class for all error handlers. \"\"\"\n\n    def __init__(self, *args, **kwargs):\n",
  "slicing": "    tree_type = 'schema'\n"
 },
 "5": {
  "name": "add",
  "type": "function",
  "class": "unknown",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "418",
  "column": "4",
  "context": "timeError('This is not supposed to happen.')\n\n    add = __call__\n\n\nclass BasicErrorHandler(BaseErrorHandler):\n    \"",
  "context_lines": "        pass\n\n\nclass ToyErrorHandler(BaseErrorHandler):\n    def __call__(self, *args, **kwargs):\n        raise RuntimeError('This is not supposed to happen.')\n\n    add = __call__\n\n\nclass BasicErrorHandler(BaseErrorHandler):\n    \"\"\" Models cerberus' legacy. Returns a :class:`dict`. When mangled\n        through :class:`str` a pretty-formatted representation of that\n",
  "slicing": [
   "NORMALIZATION = ErrorDefinition(0x60, None)\n",
   "ERROR_GROUP = ErrorDefinition(0x80, None)\n",
   "LOGICAL = ErrorDefinition(0x90, None)\n",
   "        result = defaultdict(ErrorList)  # type: DefaultDict[int, ErrorList]\n",
   "        for error in self.child_errors:  # type: ignore\n",
   "            i = error.schema_path[len(self.schema_path)]\n",
   "            result[i].append(error)\n",
   "        return result\n",
   "        return bool(self.code & ERROR_GROUP.code)\n",
   "        return bool(self.code & LOGICAL.code - ERROR_GROUP.code)\n",
   "        return bool(self.code & NORMALIZATION.code)\n",
   "        wanted_code = error_definition.code\n",
   "        return any(x.code == wanted_code for x in self)\n",
   "            for error in self.errors:\n",
   "                if item.code == error.code:\n",
   "                    return error\n",
   "        error_path = self._path_of_(error)\n",
   "        key = error_path[self.depth]\n",
   "        if key not in self.descendants:\n",
   "            self[key] = ErrorTreeNode(error_path, self)\n",
   "        node = cast(ErrorTreeNode, self[key])\n",
   "        if len(error_path) == self.depth + 1:\n",
   "            node.errors.append(error)\n",
   "            node.errors.sort()\n",
   "            if error.is_group_error:\n",
   "                for child_error in error.child_errors:  # type: ignore\n",
   "                    self.tree_root.add(child_error)\n",
   "            node.add(error)\n",
   "        return getattr(error, self.tree_type + '_path')\n",
   "    path = ()\n",
   "        for error in errors:\n",
   "            self.add(error)\n",
   "        if not self._path_of_(error):\n",
   "            self.errors.append(error)\n",
   "            super().add(error)\n",
   "        node = self.fetch_node_from(path)\n",
   "        if node is None:\n",
   "            return node.errors\n",
   "        context = self\n",
   "        for key in path:\n",
   "            context = context.get(key, None)\n",
   "            if context is None:\n",
   "        return context\n",
   "        for error in errors:\n",
   "            self.add(error)\n",
   "    add = __call__\n",
   "        pretty = deepcopy(self.tree)\n",
   "        for field in pretty:\n",
   "            self._purge_empty_dicts(pretty[field])\n",
   "        return pretty\n",
   "        error = deepcopy(error)\n",
   "        self._rewrite_error_path(error)\n",
   "        if error.is_logic_error:\n",
   "            self._insert_logic_error(error)\n",
   "        elif error.is_group_error:\n",
   "            self._insert_group_error(error)\n",
   "        elif error.code in self.messages:\n",
   "                error.document_path, self._format_message(error.field, error)\n",
   "        return self.messages[error.code].format(\n",
   "            *error.info, constraint=error.constraint, field=field, value=error.value\n",
   "        field = path[0]\n",
   "        if len(path) == 1:\n",
   "            if field in self.tree:\n",
   "                subtree = self.tree[field].pop()\n",
   "                self.tree[field] += [node, subtree]\n",
   "                self.tree[field] = [node, {}]\n",
   "        elif len(path) >= 1:\n",
   "            if field not in self.tree:\n",
   "                self.tree[field] = [{}]\n",
   "            subtree = self.tree[field][-1]\n",
   "            if subtree:\n",
   "                new = self.__class__(tree=copy(subtree))\n",
   "                new = self.__class__()\n",
   "            new._insert_error(path[1:], node)\n",
   "            subtree.update(new.tree)\n",
   "        for child_error in error.child_errors:\n",
   "            if child_error.is_logic_error:\n",
   "                self._insert_logic_error(child_error)\n",
   "            elif child_error.is_group_error:\n",
   "                self._insert_group_error(child_error)\n",
   "                    child_error.document_path,\n",
   "                    self._format_message(child_error.field, child_error),\n",
   "        field = error.field\n",
   "        self._insert_error(error.document_path, self._format_message(field, error))\n",
   "        for definition_errors in error.definitions_errors.values():\n",
   "            for child_error in definition_errors:\n",
   "                if child_error.is_logic_error:\n",
   "                    self._insert_logic_error(child_error)\n",
   "                elif child_error.is_group_error:\n",
   "                    self._insert_group_error(child_error)\n",
   "                        child_error.document_path,\n",
   "                        self._format_message(field, child_error),\n",
   "        subtree = error_list[-1]\n",
   "            for key in subtree:\n",
   "                self._purge_empty_dicts(subtree[key])\n",
   "        if error.is_logic_error:\n",
   "            self._rewrite_logic_error_path(error, offset)\n",
   "        elif error.is_group_error:\n",
   "            self._rewrite_group_error_path(error, offset)\n",
   "        child_start = len(error.document_path) - offset\n",
   "        for child_error in error.child_errors:\n",
   "            relative_path = child_error.document_path[child_start:]\n",
   "            child_error.document_path = error.document_path + relative_path\n",
   "            self._rewrite_error_path(child_error, offset)\n",
   "        child_start = len(error.document_path) - offset\n",
   "        for i, definition_errors in error.definitions_errors.items():\n",
   "            if not definition_errors:\n",
   "            nodename = '%s definition %s' % (error.rule, i)\n",
   "            path = error.document_path + (nodename,)\n",
   "            for child_error in definition_errors:\n",
   "                rel_path = child_error.document_path[child_start:]\n",
   "                child_error.document_path = path + rel_path\n",
   "                self._rewrite_error_path(child_error, offset + 1)\n"
  ]
 },
 "6": {
  "name": "messages",
  "type": "dict",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/errors.py",
  "lineno": "609",
  "column": "4",
  "context": "\nclass SchemaErrorHandler(BasicErrorHandler):\n    messages = BasicErrorHandler.messages.copy()\n    messages[0x03] = \"unknown rule\"\n",
  "context_lines": "                rel_path = child_error.document_path[child_start:]\n                child_error.document_path = path + rel_path\n\n                self._rewrite_error_path(child_error, offset + 1)\n\n\nclass SchemaErrorHandler(BasicErrorHandler):\n    messages = BasicErrorHandler.messages.copy()\n",
  "slicing": [
   "NORMALIZATION = ErrorDefinition(0x60, None)\n",
   "ERROR_GROUP = ErrorDefinition(0x80, None)\n",
   "LOGICAL = ErrorDefinition(0x90, None)\n",
   "        result = defaultdict(ErrorList)  # type: DefaultDict[int, ErrorList]\n",
   "        for error in self.child_errors:  # type: ignore\n",
   "            i = error.schema_path[len(self.schema_path)]\n",
   "            result[i].append(error)\n",
   "        return result\n",
   "        return bool(self.code & ERROR_GROUP.code)\n",
   "        return bool(self.code & LOGICAL.code - ERROR_GROUP.code)\n",
   "        return bool(self.code & NORMALIZATION.code)\n",
   "        wanted_code = error_definition.code\n",
   "        return any(x.code == wanted_code for x in self)\n",
   "            for error in self.errors:\n",
   "                if item.code == error.code:\n",
   "                    return error\n",
   "        error_path = self._path_of_(error)\n",
   "        key = error_path[self.depth]\n",
   "        if key not in self.descendants:\n",
   "            self[key] = ErrorTreeNode(error_path, self)\n",
   "        node = cast(ErrorTreeNode, self[key])\n",
   "        if len(error_path) == self.depth + 1:\n",
   "            node.errors.append(error)\n",
   "            node.errors.sort()\n",
   "            if error.is_group_error:\n",
   "                for child_error in error.child_errors:  # type: ignore\n",
   "                    self.tree_root.add(child_error)\n",
   "            node.add(error)\n",
   "        return getattr(error, self.tree_type + '_path')\n",
   "    path = ()\n",
   "        for error in errors:\n",
   "            self.add(error)\n",
   "        if not self._path_of_(error):\n",
   "            self.errors.append(error)\n",
   "            super().add(error)\n",
   "        node = self.fetch_node_from(path)\n",
   "        if node is None:\n",
   "            return node.errors\n",
   "        context = self\n",
   "        for key in path:\n",
   "            context = context.get(key, None)\n",
   "            if context is None:\n",
   "        return context\n",
   "        for error in errors:\n",
   "            self.add(error)\n",
   "        pretty = deepcopy(self.tree)\n",
   "        for field in pretty:\n",
   "            self._purge_empty_dicts(pretty[field])\n",
   "        return pretty\n",
   "        error = deepcopy(error)\n",
   "        self._rewrite_error_path(error)\n",
   "        if error.is_logic_error:\n",
   "            self._insert_logic_error(error)\n",
   "        elif error.is_group_error:\n",
   "            self._insert_group_error(error)\n",
   "        elif error.code in self.messages:\n",
   "                error.document_path, self._format_message(error.field, error)\n",
   "        return self.messages[error.code].format(\n",
   "            *error.info, constraint=error.constraint, field=field, value=error.value\n",
   "        field = path[0]\n",
   "        if len(path) == 1:\n",
   "            if field in self.tree:\n",
   "                subtree = self.tree[field].pop()\n",
   "                self.tree[field] += [node, subtree]\n",
   "                self.tree[field] = [node, {}]\n",
   "        elif len(path) >= 1:\n",
   "            if field not in self.tree:\n",
   "                self.tree[field] = [{}]\n",
   "            subtree = self.tree[field][-1]\n",
   "            if subtree:\n",
   "                new = self.__class__(tree=copy(subtree))\n",
   "                new = self.__class__()\n",
   "            new._insert_error(path[1:], node)\n",
   "            subtree.update(new.tree)\n",
   "        for child_error in error.child_errors:\n",
   "            if child_error.is_logic_error:\n",
   "                self._insert_logic_error(child_error)\n",
   "            elif child_error.is_group_error:\n",
   "                self._insert_group_error(child_error)\n",
   "                    child_error.document_path,\n",
   "                    self._format_message(child_error.field, child_error),\n",
   "        field = error.field\n",
   "        self._insert_error(error.document_path, self._format_message(field, error))\n",
   "        for definition_errors in error.definitions_errors.values():\n",
   "            for child_error in definition_errors:\n",
   "                if child_error.is_logic_error:\n",
   "                    self._insert_logic_error(child_error)\n",
   "                elif child_error.is_group_error:\n",
   "                    self._insert_group_error(child_error)\n",
   "                        child_error.document_path,\n",
   "                        self._format_message(field, child_error),\n",
   "        subtree = error_list[-1]\n",
   "            for key in subtree:\n",
   "                self._purge_empty_dicts(subtree[key])\n",
   "        if error.is_logic_error:\n",
   "            self._rewrite_logic_error_path(error, offset)\n",
   "        elif error.is_group_error:\n",
   "            self._rewrite_group_error_path(error, offset)\n",
   "        child_start = len(error.document_path) - offset\n",
   "        for child_error in error.child_errors:\n",
   "            relative_path = child_error.document_path[child_start:]\n",
   "            child_error.document_path = error.document_path + relative_path\n",
   "            self._rewrite_error_path(child_error, offset)\n",
   "        child_start = len(error.document_path) - offset\n",
   "        for i, definition_errors in error.definitions_errors.items():\n",
   "            if not definition_errors:\n",
   "            nodename = '%s definition %s' % (error.rule, i)\n",
   "            path = error.document_path + (nodename,)\n",
   "            for child_error in definition_errors:\n",
   "                rel_path = child_error.document_path[child_start:]\n",
   "                child_error.document_path = path + rel_path\n",
   "                self._rewrite_error_path(child_error, offset + 1)\n",
   "    messages = BasicErrorHandler.messages.copy()\n",
   "    messages[0x03] = \"unknown rule\"\n"
  ]
 },
 "7": {
  "name": "f",
  "type": "function",
  "class": "unknown",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "59",
  "column": "4",
  "context": " in its '\n            'docstring.'\n        )\n\n    f = dummy\n    f.__doc__ = rule_constraints\n    return f\n\n\n# ",
  "context_lines": "            'Dummy method called. Its purpose is to hold just'\n            'validation constraints for a rule in its '\n            'docstring.'\n        )\n\n    f = dummy\n    f.__doc__ = rule_constraints\n    return f\n\n\n# Exceptions\n\n\nclass DocumentError(Exception):\n",
  "slicing": [
   "    f = dummy\n",
   "    f.__doc__ = rule_constraints\n",
   "    return f\n"
  ]
 },
 "8": {
  "name": "_normalize_value",
  "type": "staticmethod",
  "class": "unknown",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "304",
  "column": "4",
  "context": "name, None)\n\n\nclass SchemaRegistry(Registry):\n    _normalize_value = staticmethod(normalize_schema)\n\n\nclass RulesSetRegistry(Registry):\n    _normalize",
  "context_lines": "                      unregistered. \"\"\"\n        for name in names:\n            self._storage.pop(name, None)\n\n\nclass SchemaRegistry(Registry):\n    _normalize_value = staticmethod(normalize_schema)\n\n\nclass RulesSetRegistry(Registry):\n    _normalize_value = staticmethod(normalize_rulesset)\n\n\nschema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\n\n\n",
  "slicing": [
   "RULE_SCHEMA_SEPARATOR = \"The rule's arguments are validated against this schema:\"\n",
   "toy_error_handler = errors.ToyErrorHandler()\n",
   "_ellipsis = typing.Tuple[int, ...].__args__[-1]\n",
   "def dummy_for_rule_validation(rule_constraints: str) -> Callable:\n",
   "    f = dummy\n",
   "    f.__doc__ = rule_constraints\n",
   "    return f\n",
   "_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\n",
   "def normalize_rulesset(rules: RulesSet) -> RulesSet:\n",
   "    _hash = schema_hash(rules)\n",
   "    if _hash in _normalized_rulesset_cache:\n",
   "        return _normalized_rulesset_cache[_hash]\n",
   "    rules = dict(rules)\n",
   "    rules_with_whitespace = [x for x in rules if \" \" in x]\n",
   "    if rules_with_whitespace:\n",
   "        for rule in rules_with_whitespace:\n",
   "            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\n",
   "    if isinstance(rules.get(\"dependencies\"), str):\n",
   "        rules[\"dependencies\"] = (rules[\"dependencies\"],)\n",
   "    if \"excludes\" in rules:\n",
   "        constraint = rules[\"excludes\"]\n",
   "        if isinstance(constraint, str) or not isinstance(constraint, Container):\n",
   "            rules[\"excludes\"] = (constraint,)\n",
   "    if \"type\" in rules:\n",
   "        constraint = rules[\"type\"]\n",
   "        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\n",
   "            rules[\"type\"] = (constraint,)\n",
   "        _expand_generic_type_aliases(rules)\n",
   "    _expand_composed_of_rules(rules)\n",
   "    _normalize_contained_rulessets(rules)\n",
   "    _normalized_rulesset_cache[_hash] = rules\n",
   "    return rules\n",
   "def normalize_schema(schema: Schema) -> Schema:\n",
   "    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\n",
   "    compound_types = []\n",
   "    plain_types = []\n",
   "    is_nullable = False\n",
   "    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\n",
   "        if isinstance(constraint, _GenericAlias):\n",
   "            origin = get_type_origin(constraint)\n",
   "            args = get_type_args(constraint)\n",
   "            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\n",
   "                compound_types.append(\n",
   "                        \"type\": origin,\n",
   "                        \"keysrules\": {\"type\": args[0]},\n",
   "                        \"valuesrules\": {\"type\": args[1]},\n",
   "                issubclass(origin, (abc.MutableSequence, abc.Set))\n",
   "                and not constraint.__parameters__\n",
   "                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\n",
   "            elif issubclass(origin, tuple) and args:\n",
   "                if args[-1] is _ellipsis:\n",
   "                    compound_types.append(\n",
   "                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\n",
   "                    compound_types.append(\n",
   "                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\n",
   "                plain_types.append(origin)\n",
   "        elif constraint is NoneType:  # type: ignore\n",
   "            is_nullable = True\n",
   "        elif isinstance(constraint, ForwardRef):\n",
   "            plain_types.append(constraint.__forward_arg__)\n",
   "            plain_types.append(constraint)\n",
   "    if compound_types or is_nullable:\n",
   "        if \"anyof\" in rules:\n",
   "        if plain_types:\n",
   "            compound_types.append({\"type\": tuple(plain_types)})\n",
   "        if is_nullable:\n",
   "            compound_types.append({\"nullable\": True})\n",
   "        rules[\"anyof\"] = tuple(compound_types)\n",
   "        rules[\"type\"] = tuple(plain_types)\n",
   "    for constraint in type_constraints:\n",
   "        if get_type_origin(constraint) is typing.Union:\n",
   "            yield from _flatten_Union_and_Optional(get_type_args(constraint))\n",
   "            yield constraint\n",
   "    composed_rules = [\n",
   "        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\n",
   "    if not composed_rules:\n",
   "    for composed_rule in composed_rules:\n",
   "        of_rule, rule = composed_rule.split('_', 1)\n",
   "        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\n",
   "    for rule in composed_rules:\n",
   "        rules.pop(rule)\n",
   "    if isinstance(rules.get(\"schema\"), abc.Mapping):\n",
   "        rules['schema'] = normalize_schema(rules['schema'])\n",
   "    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\n",
   "        if rule in rules:\n",
   "            rules[rule] = normalize_rulesset(rules[rule])\n",
   "    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\n",
   "        if not isinstance(rules.get(rule), Sequence):\n",
   "        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\n",
   "        for name, definition in dict(definitions).items():\n",
   "            self.add(name, definition)\n",
   "        return self._storage.get(name, default)\n",
   "        for name in names:\n",
   "            self._storage.pop(name, None)\n",
   "    _normalize_value = staticmethod(normalize_schema)\n",
   "schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\n",
   "TypeDefinition = NamedTuple(\n",
   "        return super().__new__(mcls, name, bases, namespace)\n",
   "        def attributes_with_prefix(prefix):\n",
   "                x[len(prefix) + 2 :]\n",
   "                for x in dir(cls)\n",
   "                if x.startswith('_' + prefix + '_')\n",
   "        super().__init__(name, bases, namespace)\n",
   "        validation_rules = {\n",
   "            for attribute in attributes_with_prefix('validate')\n",
   "        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\n",
   "        x = validation_rules['check_with']['oneof']\n",
   "        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\n",
   "        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\n",
   "            validation_rules[rule]['required'] = True\n",
   "        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\n",
   "        for attribute in attributes_with_prefix('normalize'):\n",
   "            if attribute.startswith('coerce_'):\n",
   "                cls.coercers += (attribute[len('coerce_') :],)\n",
   "            elif attribute.startswith('default_setter_'):\n",
   "                cls.default_setters += (attribute[len('default_setter_') :],)\n",
   "                normalization_rules[attribute] = cls.__get_rule_schema(\n",
   "                    '_normalize_' + attribute\n",
   "        for rule in ('coerce', 'rename_handler'):\n",
   "            x = normalization_rules[rule]['oneof']\n",
   "            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\n",
   "        normalization_rules['default_setter']['oneof'][1][\n",
   "        cls.normalization_rules = normalize_schema(normalization_rules)\n",
   "        cls.validation_rules = normalize_schema(validation_rules)\n",
   "        docstring = getattr(mcls, method_name).__doc__\n",
   "        if docstring is None:\n",
   "            result = {}\n",
   "            if RULE_SCHEMA_SEPARATOR in docstring:\n",
   "                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\n",
   "                result = literal_eval(docstring.strip())\n",
   "                result = {}\n",
   "        if not result and method_name != '_validate_meta':\n",
   "        return result\n",
   "    types_mapping = {\n",
   "        'boolean': TypeDefinition('boolean', (bool,), ()),\n",
   "        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\n",
   "        'bytes': TypeDefinition('bytes', (bytes,), ()),\n",
   "        'complex': TypeDefinition('complex', (complex,), ()),\n",
   "        'date': TypeDefinition('date', (date,), (datetime,)),\n",
   "        'datetime': TypeDefinition('datetime', (datetime,), ()),\n",
   "        'dict': TypeDefinition('dict', (Mapping,), ()),\n",
   "        'float': TypeDefinition('float', (float,), ()),\n",
   "        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\n",
   "        'integer': TypeDefinition('integer', (int,), (bool,)),\n",
   "        'list': TypeDefinition('list', (list,), ()),\n",
   "        'number': TypeDefinition('number', (int, float), (bool,)),\n",
   "        'set': TypeDefinition('set', (set,), ()),\n",
   "        'string': TypeDefinition('string', (str,), ()),\n",
   "        'tuple': TypeDefinition('tuple', (tuple,), ()),\n",
   "        'type': TypeDefinition('type', (type,), ()),\n",
   "    types_mapping.update(\n",
   "        (x, TypeDefinition(x, (getattr(abc, x),), ()))\n",
   "        for x in abc.__all__  # type: ignore\n",
   "    normalization_rules = {}  # type: ClassVar[Schema]\n",
   "    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\n",
   "    validation_rules = {}  # type: ClassVar[Schema]\n",
   "        rules_set_registry: RulesSetRegistry = rules_set_registry,\n",
   "        schema_registry: SchemaRegistry = schema_registry,\n",
   "                \"rules_set_registry\": rules_set_registry,\n",
   "                \"schema_registry\": schema_registry,\n",
   "        self.schema = schema\n",
   "            error_handler, eh_config = config\n",
   "            error_handler, eh_config = config, {}\n",
   "        if isinstance(error_handler, type) and issubclass(\n",
   "            error_handler, errors.BaseErrorHandler\n",
   "            return error_handler(**eh_config)\n",
   "        if len(args) == 1:\n",
   "            self._errors.extend(args[0])\n",
   "            for error in args[0]:\n",
   "                self.document_error_tree.add(error)\n",
   "                self.schema_error_tree.add(error)\n",
   "                self.error_handler.emit(error)\n",
   "        elif len(args) == 2 and isinstance(args[1], str):\n",
   "            self._error(args[0], errors.CUSTOM, args[1])\n",
   "        elif len(args) >= 2:\n",
   "            field = args[0]\n",
   "            code = args[1].code\n",
   "            rule = args[1].rule\n",
   "            info = args[2:]\n",
   "            document_path = self.document_path + (field,)\n",
   "            schema_path = self.schema_path\n",
   "            if code != errors.UNKNOWN_FIELD.code and rule is not None:\n",
   "                schema_path += (field, rule)\n",
   "            if not rule:\n",
   "                constraint = None\n",
   "                field_definitions = self._resolve_rules_set(self.schema[field])\n",
   "                if rule == 'nullable':\n",
   "                    constraint = field_definitions.get(rule, False)\n",
   "                elif rule == 'required':\n",
   "                    constraint = field_definitions.get(rule, self.require_all)\n",
   "                    if rule not in field_definitions:\n",
   "                        schema_path = \"__require_all__\"\n",
   "                    constraint = field_definitions[rule]\n",
   "            value = self.document.get(field)\n",
   "                document_path, schema_path, code, rule, constraint, value, info\n",
   "        child_config = ChainMap(kwargs, self._config)\n",
   "            child_config = child_config.new_child(\n",
   "                    'error_handler': toy_error_handler,\n",
   "        child_validator = self.__class__(**child_config)\n",
   "            child_validator.document_path = self.document_path\n",
   "                document_crumb = (document_crumb,)\n",
   "            child_validator.document_path = self.document_path + document_crumb\n",
   "            child_validator.schema_path = self.schema_path\n",
   "                schema_crumb = (schema_crumb,)\n",
   "            child_validator.schema_path = self.schema_path + schema_crumb\n",
   "        return child_validator\n",
   "        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\n",
   "        result = getattr(self, methodname, None)\n",
   "        if result is None:\n",
   "                \"domain.\".format(rule, domain)\n",
   "        return result\n",
   "        dp_basedepth = len(self.document_path)\n",
   "        sp_basedepth = len(self.schema_path)\n",
   "        for error in _errors:\n",
   "            for i in sorted(dp_items, reverse=True):\n",
   "                error.document_path = drop_item_from_tuple(\n",
   "                    error.document_path, dp_basedepth + i\n",
   "            for i in sorted(sp_items, reverse=True):\n",
   "                error.schema_path = drop_item_from_tuple(\n",
   "                    error.schema_path, sp_basedepth + i\n",
   "            if error.child_errors:\n",
   "                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\n",
   "            path = path[1:]\n",
   "            context = self.document if path.startswith('^') else self.root_document\n",
   "            context = self.document\n",
   "        parts = path.split('.')\n",
   "        for part in parts:\n",
   "            if part not in context:\n",
   "            context = context.get(part, {})\n",
   "        return parts[-1], context\n",
   "        if isinstance(schema, Mapping):\n",
   "            return schema\n",
   "        elif isinstance(schema, str):\n",
   "            return self.schema_registry.get(schema)\n",
   "        if isinstance(value, Mapping):\n",
   "            self._config['allow_unknown'] = normalize_rulesset(value)\n",
   "        elif isinstance(value, bool):\n",
   "            self._config['allow_unknown'] = value\n",
   "        self._config['ignore_none_values'] = value\n",
   "        self._config['_is_normalized'] = value\n",
   "        self._config['purge_unknown'] = value\n",
   "        self._config['purge_readonly'] = value\n",
   "        self._config['require_all'] = value\n",
   "    @rules_set_registry.setter\n",
   "    @schema.setter\n",
   "        if schema is None:\n",
   "            self._schema = schema\n",
   "            self._schema = normalize_schema(schema)\n",
   "    @schema_registry.setter\n",
   "        if schema is not None:\n",
   "            self.schema = schema\n",
   "        if rules:\n",
   "            for rule in (x for x in rules if x in self._remaining_rules):\n",
   "                self._remaining_rules.remove(rule)\n",
   "        self.__init_processing(document, schema)\n",
   "        mapping = mapping.copy()\n",
   "        if isinstance(schema, str):\n",
   "            schema = self._resolve_schema(schema)\n",
   "        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\n",
   "        self.__normalize_rename_fields(mapping, schema)\n",
   "            self._normalize_purge_unknown(mapping, schema)\n",
   "            self.__normalize_purge_readonly(mapping, schema)\n",
   "        self.__validate_readonly_fields(mapping, schema)\n",
   "        self.__normalize_default_fields(mapping, schema)\n",
   "        self._normalize_coerce(mapping, schema)\n",
   "        self.__normalize_containers(mapping, schema)\n",
   "        return mapping\n",
   "        error = errors.COERCION_FAILED\n",
   "        for field in mapping:\n",
   "            if field in schema and 'coerce' in schema[field]:\n",
   "                mapping[field] = self.__normalize_coerce(\n",
   "                    schema[field]['coerce'],\n",
   "                    field,\n",
   "                    mapping[field],\n",
   "                    schema[field].get('nullable', False),\n",
   "                    error,\n",
   "                mapping[field] = self.__normalize_coerce(\n",
   "                    field,\n",
   "                    mapping[field],\n",
   "                    error,\n",
   "            processor = self.__get_rule_handler('normalize_coerce', processor)\n",
   "        elif isinstance(processor, Iterable):\n",
   "            result = value\n",
   "            for p in processor:\n",
   "                result = self.__normalize_coerce(p, field, result, nullable, error)\n",
   "                        self.document_path + (field,)\n",
   "            return result\n",
   "            return processor(value)\n",
   "            if not (nullable and value is None):\n",
   "                self._error(field, error, str(e))\n",
   "            return value\n",
   "        for field in mapping:\n",
   "            rules = set(schema.get(field, ()))\n",
   "            if isinstance(mapping[field], Mapping):\n",
   "                if 'keysrules' in rules:\n",
   "                        field, mapping, schema[field]['keysrules']\n",
   "                if 'valuesrules' in rules:\n",
   "                        field, mapping, schema[field]['valuesrules']\n",
   "                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\n",
   "                    self.__normalize_mapping_per_schema(field, mapping, schema)\n",
   "            elif isinstance(mapping[field], str):\n",
   "            elif isinstance(mapping[field], Sequence):\n",
   "                if 'itemsrules' in rules:\n",
   "                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\n",
   "                elif 'items' in rules:\n",
   "                    self.__normalize_sequence_per_items(field, mapping, schema)\n",
   "        schema = {k: property_rules for k in mapping[field]}\n",
   "        document = {k: k for k in mapping[field]}\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\n",
   "        result = validator.normalized(document, always_return_document=True)\n",
   "        if validator._errors:\n",
   "            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\n",
   "            self._error(validator._errors)\n",
   "        for _in, out in ((k, v) for k, v in result.items() if k != v):\n",
   "            if out in mapping[field]:\n",
   "                        path='.'.join(str(x) for x in self.document_path + (field,)),\n",
   "                        key=_in,\n",
   "                mapping[field][out] = mapping[field][_in]\n",
   "                mapping[field][out] = mapping[field][_in]\n",
   "                del mapping[field][_in]\n",
   "        schema = {k: value_rules for k in mapping[field]}\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\n",
   "        mapping[field] = validator.normalized(\n",
   "            mapping[field], always_return_document=True\n",
   "        if validator._errors:\n",
   "            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\n",
   "            self._error(validator._errors)\n",
   "        rules = schema.get(field, {})\n",
   "        if not rules and isinstance(self.allow_unknown, Mapping):\n",
   "            rules = self.allow_unknown\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field,\n",
   "            schema_crumb=(field, 'schema'),\n",
   "            schema=rules.get('schema', {}),\n",
   "            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\n",
   "            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\n",
   "            require_all=rules.get('require_all', self.require_all),\n",
   "        value_type = type(mapping[field])\n",
   "        result_value = validator.normalized(mapping[field], always_return_document=True)\n",
   "        mapping[field] = value_type(result_value)\n",
   "        if validator._errors:\n",
   "            self._error(validator._errors)\n",
   "        rules, values = schema[field]['items'], mapping[field]\n",
   "        if len(rules) != len(values):\n",
   "        schema = {k: v for k, v in enumerate(rules)}\n",
   "        document = {k: v for k, v in enumerate(values)}\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\n",
   "        value_type = type(mapping[field])\n",
   "        result = validator.normalized(document, always_return_document=True)\n",
   "        mapping[field] = value_type(result.values())\n",
   "        if validator._errors:\n",
   "            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\n",
   "            self._error(validator._errors)\n",
   "        constraint = schema[field]['itemsrules']\n",
   "        schema = {k: constraint for k in range(len(mapping[field]))}\n",
   "        document = {k: v for k, v in enumerate(mapping[field])}\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\n",
   "        value_type = type(mapping[field])\n",
   "        result = validator.normalized(document, always_return_document=True)\n",
   "        mapping[field] = value_type(result.values())\n",
   "        if validator._errors:\n",
   "            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\n",
   "            self._error(validator._errors)\n",
   "        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\n",
   "            mapping.pop(field)\n",
   "        return mapping\n",
   "        for field in [x for x in mapping if x not in schema]:\n",
   "            mapping.pop(field)\n",
   "        return mapping\n",
   "        for field in tuple(mapping):\n",
   "            if field in schema:\n",
   "                self._normalize_rename(mapping, schema, field)\n",
   "                self._normalize_rename_handler(mapping, schema, field)\n",
   "                    mapping, {field: self.allow_unknown}, field\n",
   "        return mapping\n",
   "        if 'rename' in schema[field]:\n",
   "            mapping[schema[field]['rename']] = mapping[field]\n",
   "            del mapping[field]\n",
   "        if 'rename_handler' not in schema[field]:\n",
   "        new_name = self.__normalize_coerce(\n",
   "            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\n",
   "        if new_name != field:\n",
   "            mapping[new_name] = mapping[field]\n",
   "            del mapping[field]\n",
   "        for field in (\n",
   "            x\n",
   "            for x in schema\n",
   "            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\n",
   "            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\n",
   "        empty_fields = [\n",
   "            x\n",
   "            for x in schema\n",
   "            if x not in mapping\n",
   "                mapping[x] is None  # noqa: W503\n",
   "                and not schema[x].get('nullable', False)\n",
   "        for field in (x for x in empty_fields if 'default' in schema[x]):\n",
   "            self._normalize_default(mapping, schema, field)\n",
   "        known_fields_states = set()\n",
   "        fields_with_default_setter = [\n",
   "            x for x in empty_fields if 'default_setter' in schema[x]\n",
   "        while fields_with_default_setter:\n",
   "            field = fields_with_default_setter.pop(0)\n",
   "                self._normalize_default_setter(mapping, schema, field)\n",
   "                fields_with_default_setter.append(field)\n",
   "                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\n",
   "            fields_processing_state = hash(tuple(fields_with_default_setter))\n",
   "            if fields_processing_state in known_fields_states:\n",
   "                for field in fields_with_default_setter:\n",
   "                        field,\n",
   "                known_fields_states.add(fields_processing_state)\n",
   "        mapping[field] = schema[field]['default']\n",
   "        if 'default_setter' in schema[field]:\n",
   "            setter = schema[field]['default_setter']\n",
   "            if isinstance(setter, str):\n",
   "                setter = self.__get_rule_handler('normalize_default_setter', setter)\n",
   "            mapping[field] = setter(mapping)\n",
   "        self.__init_processing(document, schema)\n",
   "        for field in self.document:  # type: ignore\n",
   "            definitions = self.schema.get(field)  # type: ignore\n",
   "            if definitions is not None:\n",
   "                self.__validate_definitions(definitions, field)\n",
   "                self.__validate_unknown_fields(field)\n",
   "            document=document, schema=schema, update=update, normalize=normalize\n",
   "            value = self.document[field]\n",
   "                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\n",
   "                validator = self._get_child_validator(\n",
   "                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\n",
   "                if not validator({field: value}, normalize=False):\n",
   "                    self._error(validator._errors)\n",
   "            self._error(field, errors.UNKNOWN_FIELD)\n",
   "        definitions = self._resolve_rules_set(definitions)\n",
   "        value = self.document[field]\n",
   "        rules_queue = [\n",
   "            x\n",
   "            for x in self.priority_validations\n",
   "            if x in definitions or x in self.mandatory_validations\n",
   "        rules_queue.extend(\n",
   "            x for x in self.mandatory_validations if x not in rules_queue\n",
   "        rules_queue.extend(\n",
   "            x\n",
   "            for x in definitions\n",
   "            if x not in rules_queue\n",
   "            and x not in self.normalization_rules\n",
   "            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\n",
   "        self._remaining_rules = rules_queue\n",
   "            rule = self._remaining_rules.pop(0)\n",
   "            rule_handler = self.__get_rule_handler('validate', rule)\n",
   "            rule_handler(definitions.get(rule, None), field, value)\n",
   "        if isinstance(value, Iterable) and not isinstance(value, str):\n",
   "            unallowed = tuple(x for x in value if x not in allowed_values)\n",
   "            if unallowed:\n",
   "                self._error(field, errors.UNALLOWED_VALUES, unallowed)\n",
   "            if value not in allowed_values:\n",
   "                self._error(field, errors.UNALLOWED_VALUE, value)\n",
   "            value_checker = self.__get_rule_handler('check_with', checks)\n",
   "            value_checker(field, value)\n",
   "            for v in checks:\n",
   "                self._validate_check_with(v, field, value)\n",
   "            checks(field, value, self._error)\n",
   "        if not isinstance(value, Container):\n",
   "            expected_values = set((expected_values,))\n",
   "            expected_values = set(expected_values)\n",
   "        missing_values = expected_values - set(value)\n",
   "        if missing_values:\n",
   "            self._error(field, errors.MISSING_MEMBERS, missing_values)\n",
   "            dependencies = (dependencies,)\n",
   "        if isinstance(dependencies, Sequence):\n",
   "            self.__validate_dependencies_sequence(dependencies, field)\n",
   "        elif isinstance(dependencies, Mapping):\n",
   "            self.__validate_dependencies_mapping(dependencies, field)\n",
   "                self.schema_path + (field, 'dependencies')\n",
   "        validated_dependencies_counter = 0\n",
   "        error_info = {}\n",
   "        for dependency_name, dependency_values in dependencies.items():\n",
   "            if not isinstance(dependency_values, Sequence) or isinstance(\n",
   "                dependency_values, str\n",
   "                dependency_values = [dependency_values]\n",
   "            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\n",
   "            if wanted_field_value in dependency_values:\n",
   "                validated_dependencies_counter += 1\n",
   "                error_info.update({dependency_name: wanted_field_value})\n",
   "        if validated_dependencies_counter != len(dependencies):\n",
   "            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\n",
   "        for dependency in dependencies:\n",
   "            if self._lookup_field(dependency)[0] is None:\n",
   "                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\n",
   "        if isinstance(value, Sized) and len(value) == 0:\n",
   "                self._error(field, errors.EMPTY)\n",
   "            excluded_fields = (excluded_fields,)\n",
   "        if self.schema[field].get('required', self.require_all):\n",
   "            self._unrequired_by_excludes.add(field)\n",
   "        for excluded_field in excluded_fields:\n",
   "            if excluded_field in self.schema and self.schema[field].get(\n",
   "                self._unrequired_by_excludes.add(excluded_field)\n",
   "        if any(excluded_field in self.document for excluded_field in excluded_fields):\n",
   "            exclusion_str = ', '.join(\n",
   "                \"'{0}'\".format(field) for field in excluded_fields\n",
   "            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\n",
   "        if isinstance(value, str):\n",
   "            if value in forbidden_values:\n",
   "                self._error(field, errors.FORBIDDEN_VALUE, value)\n",
   "        elif isinstance(value, Iterable):\n",
   "            forbidden = set(value) & set(forbidden_values)\n",
   "            if forbidden:\n",
   "                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\n",
   "            if value in forbidden_values:\n",
   "                self._error(field, errors.FORBIDDEN_VALUE, value)\n",
   "        if len(items) != len(values):\n",
   "            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\n",
   "            schema = {i: definition for i, definition in enumerate(items)}\n",
   "            validator = self._get_child_validator(\n",
   "                document_crumb=field,\n",
   "                schema_crumb=(field, 'items'),  # noqa: E501\n",
   "                schema=schema,\n",
   "            if not validator(\n",
   "                {i: value for i, value in enumerate(values)},\n",
   "                self._error(field, errors.ITEMS, validator._errors)\n",
   "        if not isinstance(value, Sequence):\n",
   "        schema = {i: rulesset for i in range(len(value))}\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field,\n",
   "            schema_crumb=(field, 'itemsrules'),\n",
   "            schema=schema,\n",
   "        validator(\n",
   "            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\n",
   "        if validator._errors:\n",
   "            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\n",
   "            self._error(field, errors.ITEMSRULES, validator._errors)\n",
   "        valid_counter = 0\n",
   "        _errors = errors.ErrorList()\n",
   "        for i, definition in enumerate(definitions):\n",
   "            schema = {field: definition.copy()}\n",
   "            for rule in ('allow_unknown', 'type'):\n",
   "                if rule not in definition and rule in self.schema[field]:\n",
   "                    schema[field][rule] = self.schema[field][rule]\n",
   "            if 'allow_unknown' not in definition:\n",
   "                schema[field]['allow_unknown'] = self.allow_unknown\n",
   "            validator = self._get_child_validator(\n",
   "                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\n",
   "            if validator(self.document, update=self.update, normalize=False):\n",
   "                valid_counter += 1\n",
   "                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\n",
   "                _errors.extend(validator._errors)\n",
   "        return valid_counter, _errors\n",
   "        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\n",
   "        if valids < 1:\n",
   "            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\n",
   "        valids, _errors = self.__validate_logical('allof', definitions, field, value)\n",
   "        if valids < len(definitions):\n",
   "            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\n",
   "        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\n",
   "        if valids > 0:\n",
   "            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\n",
   "        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\n",
   "        if valids != 1:\n",
   "            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\n",
   "            if value > max_value:\n",
   "                self._error(field, errors.MAX_VALUE)\n",
   "            if value < min_value:\n",
   "                self._error(field, errors.MIN_VALUE)\n",
   "        if isinstance(value, Iterable) and len(value) > max_length:\n",
   "            self._error(field, errors.MAX_LENGTH, len(value))\n",
   "        if isinstance(value, Iterable) and len(value) < min_length:\n",
   "            self._error(field, errors.MIN_LENGTH, len(value))\n",
   "        if value is None:\n",
   "                self._error(field, errors.NULLABLE)\n",
   "        if isinstance(value, Mapping):\n",
   "            validator = self._get_child_validator(\n",
   "                document_crumb=field,\n",
   "                schema_crumb=(field, 'keysrules'),\n",
   "                schema={k: schema for k in value.keys()},\n",
   "            if not validator({k: k for k in value.keys()}, normalize=False):\n",
   "                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\n",
   "                self._error(field, errors.KEYSRULES, validator._errors)\n",
   "                self._error(field, errors.READONLY_FIELD)\n",
   "            has_error = (\n",
   "                    self.document_path + (field,)\n",
   "            if self._is_normalized and has_error:\n",
   "        if not isinstance(value, str):\n",
   "            pattern += '$'\n",
   "        re_obj = re.compile(pattern)\n",
   "        if not re_obj.match(value):\n",
   "            self._error(field, errors.REGEX_MISMATCH)\n",
   "        required = set(\n",
   "            field\n",
   "            for field, definition in self.schema.items()\n",
   "            if self._resolve_rules_set(definition).get('required', self.require_all)\n",
   "        required -= self._unrequired_by_excludes\n",
   "        missing = required - set(\n",
   "            field\n",
   "            for field in document\n",
   "            if document.get(field) is not None or not self.ignore_none_values\n",
   "        for field in missing:\n",
   "            self._error(field, errors.REQUIRED_FIELD)\n",
   "            fields = set(field for field in document if document.get(field) is not None)\n",
   "            if self._unrequired_by_excludes.isdisjoint(fields):\n",
   "                for field in self._unrequired_by_excludes - fields:\n",
   "                    self._error(field, errors.REQUIRED_FIELD)\n",
   "        if not isinstance(value, Mapping):\n",
   "        schema = self._resolve_schema(schema)\n",
   "        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\n",
   "        require_all = self.schema[field].get('require_all', self.require_all)\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field,\n",
   "            schema_crumb=(field, 'schema'),\n",
   "            schema=schema,\n",
   "            allow_unknown=allow_unknown,\n",
   "            require_all=require_all,\n",
   "        if not validator(value, update=self.update, normalize=False):\n",
   "            self._error(field, errors.SCHEMA, validator._errors)\n",
   "        for _type in data_type:\n",
   "            if isinstance(_type, str):\n",
   "                type_definition = self.types_mapping[_type]\n",
   "                if isinstance(value, type_definition.included_types) and not isinstance(\n",
   "                    value, type_definition.excluded_types\n",
   "                if isinstance(value, _type):\n",
   "        self._error(field, errors.TYPE)\n",
   "        if isinstance(value, Mapping):\n",
   "            schema_crumb = (field, 'valuesrules')\n",
   "                document_crumb=field,\n",
   "                schema_crumb=schema_crumb,\n",
   "                schema={k: schema for k in value},\n",
   "            validator(value, update=self.update, normalize=False)\n",
   "            if validator._errors:\n",
   "                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\n",
   "                self._error(field, errors.VALUESRULES, validator._errors)\n"
  ]
 },
 "9": {
  "name": "_normalize_value",
  "type": "staticmethod",
  "class": "unknown",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "308",
  "column": "4",
  "context": "e_schema)\n\n\nclass RulesSetRegistry(Registry):\n    _normalize_value = staticmethod(normalize_rulesset)\n\n\nschema_registry, rules_set_registry = SchemaRegi",
  "context_lines": "            self._storage.pop(name, None)\n\n\nclass SchemaRegistry(Registry):\n    _normalize_value = staticmethod(normalize_schema)\n\n\nclass RulesSetRegistry(Registry):\n    _normalize_value = staticmethod(normalize_rulesset)\n\n\nschema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\n\n\n# Defining types\n\n\nTypeDefinition = NamedTuple(\n",
  "slicing": [
   "RULE_SCHEMA_SEPARATOR = \"The rule's arguments are validated against this schema:\"\n",
   "toy_error_handler = errors.ToyErrorHandler()\n",
   "_ellipsis = typing.Tuple[int, ...].__args__[-1]\n",
   "def dummy_for_rule_validation(rule_constraints: str) -> Callable:\n",
   "    f = dummy\n",
   "    f.__doc__ = rule_constraints\n",
   "    return f\n",
   "_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\n",
   "def normalize_rulesset(rules: RulesSet) -> RulesSet:\n",
   "    _hash = schema_hash(rules)\n",
   "    if _hash in _normalized_rulesset_cache:\n",
   "        return _normalized_rulesset_cache[_hash]\n",
   "    rules = dict(rules)\n",
   "    rules_with_whitespace = [x for x in rules if \" \" in x]\n",
   "    if rules_with_whitespace:\n",
   "        for rule in rules_with_whitespace:\n",
   "            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\n",
   "    if isinstance(rules.get(\"dependencies\"), str):\n",
   "        rules[\"dependencies\"] = (rules[\"dependencies\"],)\n",
   "    if \"excludes\" in rules:\n",
   "        constraint = rules[\"excludes\"]\n",
   "        if isinstance(constraint, str) or not isinstance(constraint, Container):\n",
   "            rules[\"excludes\"] = (constraint,)\n",
   "    if \"type\" in rules:\n",
   "        constraint = rules[\"type\"]\n",
   "        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\n",
   "            rules[\"type\"] = (constraint,)\n",
   "        _expand_generic_type_aliases(rules)\n",
   "    _expand_composed_of_rules(rules)\n",
   "    _normalize_contained_rulessets(rules)\n",
   "    _normalized_rulesset_cache[_hash] = rules\n",
   "    return rules\n",
   "def normalize_schema(schema: Schema) -> Schema:\n",
   "    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\n",
   "    compound_types = []\n",
   "    plain_types = []\n",
   "    is_nullable = False\n",
   "    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\n",
   "        if isinstance(constraint, _GenericAlias):\n",
   "            origin = get_type_origin(constraint)\n",
   "            args = get_type_args(constraint)\n",
   "            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\n",
   "                compound_types.append(\n",
   "                        \"type\": origin,\n",
   "                        \"keysrules\": {\"type\": args[0]},\n",
   "                        \"valuesrules\": {\"type\": args[1]},\n",
   "                issubclass(origin, (abc.MutableSequence, abc.Set))\n",
   "                and not constraint.__parameters__\n",
   "                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\n",
   "            elif issubclass(origin, tuple) and args:\n",
   "                if args[-1] is _ellipsis:\n",
   "                    compound_types.append(\n",
   "                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\n",
   "                    compound_types.append(\n",
   "                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\n",
   "                plain_types.append(origin)\n",
   "        elif constraint is NoneType:  # type: ignore\n",
   "            is_nullable = True\n",
   "        elif isinstance(constraint, ForwardRef):\n",
   "            plain_types.append(constraint.__forward_arg__)\n",
   "            plain_types.append(constraint)\n",
   "    if compound_types or is_nullable:\n",
   "        if \"anyof\" in rules:\n",
   "        if plain_types:\n",
   "            compound_types.append({\"type\": tuple(plain_types)})\n",
   "        if is_nullable:\n",
   "            compound_types.append({\"nullable\": True})\n",
   "        rules[\"anyof\"] = tuple(compound_types)\n",
   "        rules[\"type\"] = tuple(plain_types)\n",
   "    for constraint in type_constraints:\n",
   "        if get_type_origin(constraint) is typing.Union:\n",
   "            yield from _flatten_Union_and_Optional(get_type_args(constraint))\n",
   "            yield constraint\n",
   "    composed_rules = [\n",
   "        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\n",
   "    if not composed_rules:\n",
   "    for composed_rule in composed_rules:\n",
   "        of_rule, rule = composed_rule.split('_', 1)\n",
   "        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\n",
   "    for rule in composed_rules:\n",
   "        rules.pop(rule)\n",
   "    if isinstance(rules.get(\"schema\"), abc.Mapping):\n",
   "        rules['schema'] = normalize_schema(rules['schema'])\n",
   "    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\n",
   "        if rule in rules:\n",
   "            rules[rule] = normalize_rulesset(rules[rule])\n",
   "    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\n",
   "        if not isinstance(rules.get(rule), Sequence):\n",
   "        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\n",
   "        for name, definition in dict(definitions).items():\n",
   "            self.add(name, definition)\n",
   "        return self._storage.get(name, default)\n",
   "        for name in names:\n",
   "            self._storage.pop(name, None)\n",
   "    _normalize_value = staticmethod(normalize_rulesset)\n",
   "schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\n",
   "TypeDefinition = NamedTuple(\n",
   "        return super().__new__(mcls, name, bases, namespace)\n",
   "        def attributes_with_prefix(prefix):\n",
   "                x[len(prefix) + 2 :]\n",
   "                for x in dir(cls)\n",
   "                if x.startswith('_' + prefix + '_')\n",
   "        super().__init__(name, bases, namespace)\n",
   "        validation_rules = {\n",
   "            for attribute in attributes_with_prefix('validate')\n",
   "        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\n",
   "        x = validation_rules['check_with']['oneof']\n",
   "        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\n",
   "        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\n",
   "            validation_rules[rule]['required'] = True\n",
   "        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\n",
   "        for attribute in attributes_with_prefix('normalize'):\n",
   "            if attribute.startswith('coerce_'):\n",
   "                cls.coercers += (attribute[len('coerce_') :],)\n",
   "            elif attribute.startswith('default_setter_'):\n",
   "                cls.default_setters += (attribute[len('default_setter_') :],)\n",
   "                normalization_rules[attribute] = cls.__get_rule_schema(\n",
   "                    '_normalize_' + attribute\n",
   "        for rule in ('coerce', 'rename_handler'):\n",
   "            x = normalization_rules[rule]['oneof']\n",
   "            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\n",
   "        normalization_rules['default_setter']['oneof'][1][\n",
   "        cls.normalization_rules = normalize_schema(normalization_rules)\n",
   "        cls.validation_rules = normalize_schema(validation_rules)\n",
   "        docstring = getattr(mcls, method_name).__doc__\n",
   "        if docstring is None:\n",
   "            result = {}\n",
   "            if RULE_SCHEMA_SEPARATOR in docstring:\n",
   "                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\n",
   "                result = literal_eval(docstring.strip())\n",
   "                result = {}\n",
   "        if not result and method_name != '_validate_meta':\n",
   "        return result\n",
   "    types_mapping = {\n",
   "        'boolean': TypeDefinition('boolean', (bool,), ()),\n",
   "        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\n",
   "        'bytes': TypeDefinition('bytes', (bytes,), ()),\n",
   "        'complex': TypeDefinition('complex', (complex,), ()),\n",
   "        'date': TypeDefinition('date', (date,), (datetime,)),\n",
   "        'datetime': TypeDefinition('datetime', (datetime,), ()),\n",
   "        'dict': TypeDefinition('dict', (Mapping,), ()),\n",
   "        'float': TypeDefinition('float', (float,), ()),\n",
   "        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\n",
   "        'integer': TypeDefinition('integer', (int,), (bool,)),\n",
   "        'list': TypeDefinition('list', (list,), ()),\n",
   "        'number': TypeDefinition('number', (int, float), (bool,)),\n",
   "        'set': TypeDefinition('set', (set,), ()),\n",
   "        'string': TypeDefinition('string', (str,), ()),\n",
   "        'tuple': TypeDefinition('tuple', (tuple,), ()),\n",
   "        'type': TypeDefinition('type', (type,), ()),\n",
   "    types_mapping.update(\n",
   "        (x, TypeDefinition(x, (getattr(abc, x),), ()))\n",
   "        for x in abc.__all__  # type: ignore\n",
   "    normalization_rules = {}  # type: ClassVar[Schema]\n",
   "    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\n",
   "    validation_rules = {}  # type: ClassVar[Schema]\n",
   "        rules_set_registry: RulesSetRegistry = rules_set_registry,\n",
   "        schema_registry: SchemaRegistry = schema_registry,\n",
   "                \"rules_set_registry\": rules_set_registry,\n",
   "                \"schema_registry\": schema_registry,\n",
   "        self.schema = schema\n",
   "            error_handler, eh_config = config\n",
   "            error_handler, eh_config = config, {}\n",
   "        if isinstance(error_handler, type) and issubclass(\n",
   "            error_handler, errors.BaseErrorHandler\n",
   "            return error_handler(**eh_config)\n",
   "        if len(args) == 1:\n",
   "            self._errors.extend(args[0])\n",
   "            for error in args[0]:\n",
   "                self.document_error_tree.add(error)\n",
   "                self.schema_error_tree.add(error)\n",
   "                self.error_handler.emit(error)\n",
   "        elif len(args) == 2 and isinstance(args[1], str):\n",
   "            self._error(args[0], errors.CUSTOM, args[1])\n",
   "        elif len(args) >= 2:\n",
   "            field = args[0]\n",
   "            code = args[1].code\n",
   "            rule = args[1].rule\n",
   "            info = args[2:]\n",
   "            document_path = self.document_path + (field,)\n",
   "            schema_path = self.schema_path\n",
   "            if code != errors.UNKNOWN_FIELD.code and rule is not None:\n",
   "                schema_path += (field, rule)\n",
   "            if not rule:\n",
   "                constraint = None\n",
   "                field_definitions = self._resolve_rules_set(self.schema[field])\n",
   "                if rule == 'nullable':\n",
   "                    constraint = field_definitions.get(rule, False)\n",
   "                elif rule == 'required':\n",
   "                    constraint = field_definitions.get(rule, self.require_all)\n",
   "                    if rule not in field_definitions:\n",
   "                        schema_path = \"__require_all__\"\n",
   "                    constraint = field_definitions[rule]\n",
   "            value = self.document.get(field)\n",
   "                document_path, schema_path, code, rule, constraint, value, info\n",
   "        child_config = ChainMap(kwargs, self._config)\n",
   "            child_config = child_config.new_child(\n",
   "                    'error_handler': toy_error_handler,\n",
   "        child_validator = self.__class__(**child_config)\n",
   "            child_validator.document_path = self.document_path\n",
   "                document_crumb = (document_crumb,)\n",
   "            child_validator.document_path = self.document_path + document_crumb\n",
   "            child_validator.schema_path = self.schema_path\n",
   "                schema_crumb = (schema_crumb,)\n",
   "            child_validator.schema_path = self.schema_path + schema_crumb\n",
   "        return child_validator\n",
   "        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\n",
   "        result = getattr(self, methodname, None)\n",
   "        if result is None:\n",
   "                \"domain.\".format(rule, domain)\n",
   "        return result\n",
   "        dp_basedepth = len(self.document_path)\n",
   "        sp_basedepth = len(self.schema_path)\n",
   "        for error in _errors:\n",
   "            for i in sorted(dp_items, reverse=True):\n",
   "                error.document_path = drop_item_from_tuple(\n",
   "                    error.document_path, dp_basedepth + i\n",
   "            for i in sorted(sp_items, reverse=True):\n",
   "                error.schema_path = drop_item_from_tuple(\n",
   "                    error.schema_path, sp_basedepth + i\n",
   "            if error.child_errors:\n",
   "                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\n",
   "            path = path[1:]\n",
   "            context = self.document if path.startswith('^') else self.root_document\n",
   "            context = self.document\n",
   "        parts = path.split('.')\n",
   "        for part in parts:\n",
   "            if part not in context:\n",
   "            context = context.get(part, {})\n",
   "        return parts[-1], context\n",
   "        if isinstance(schema, Mapping):\n",
   "            return schema\n",
   "        elif isinstance(schema, str):\n",
   "            return self.schema_registry.get(schema)\n",
   "        if isinstance(value, Mapping):\n",
   "            self._config['allow_unknown'] = normalize_rulesset(value)\n",
   "        elif isinstance(value, bool):\n",
   "            self._config['allow_unknown'] = value\n",
   "        self._config['ignore_none_values'] = value\n",
   "        self._config['_is_normalized'] = value\n",
   "        self._config['purge_unknown'] = value\n",
   "        self._config['purge_readonly'] = value\n",
   "        self._config['require_all'] = value\n",
   "    @rules_set_registry.setter\n",
   "    @schema.setter\n",
   "        if schema is None:\n",
   "            self._schema = schema\n",
   "            self._schema = normalize_schema(schema)\n",
   "    @schema_registry.setter\n",
   "        if schema is not None:\n",
   "            self.schema = schema\n",
   "        if rules:\n",
   "            for rule in (x for x in rules if x in self._remaining_rules):\n",
   "                self._remaining_rules.remove(rule)\n",
   "        self.__init_processing(document, schema)\n",
   "        mapping = mapping.copy()\n",
   "        if isinstance(schema, str):\n",
   "            schema = self._resolve_schema(schema)\n",
   "        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\n",
   "        self.__normalize_rename_fields(mapping, schema)\n",
   "            self._normalize_purge_unknown(mapping, schema)\n",
   "            self.__normalize_purge_readonly(mapping, schema)\n",
   "        self.__validate_readonly_fields(mapping, schema)\n",
   "        self.__normalize_default_fields(mapping, schema)\n",
   "        self._normalize_coerce(mapping, schema)\n",
   "        self.__normalize_containers(mapping, schema)\n",
   "        return mapping\n",
   "        error = errors.COERCION_FAILED\n",
   "        for field in mapping:\n",
   "            if field in schema and 'coerce' in schema[field]:\n",
   "                mapping[field] = self.__normalize_coerce(\n",
   "                    schema[field]['coerce'],\n",
   "                    field,\n",
   "                    mapping[field],\n",
   "                    schema[field].get('nullable', False),\n",
   "                    error,\n",
   "                mapping[field] = self.__normalize_coerce(\n",
   "                    field,\n",
   "                    mapping[field],\n",
   "                    error,\n",
   "            processor = self.__get_rule_handler('normalize_coerce', processor)\n",
   "        elif isinstance(processor, Iterable):\n",
   "            result = value\n",
   "            for p in processor:\n",
   "                result = self.__normalize_coerce(p, field, result, nullable, error)\n",
   "                        self.document_path + (field,)\n",
   "            return result\n",
   "            return processor(value)\n",
   "            if not (nullable and value is None):\n",
   "                self._error(field, error, str(e))\n",
   "            return value\n",
   "        for field in mapping:\n",
   "            rules = set(schema.get(field, ()))\n",
   "            if isinstance(mapping[field], Mapping):\n",
   "                if 'keysrules' in rules:\n",
   "                        field, mapping, schema[field]['keysrules']\n",
   "                if 'valuesrules' in rules:\n",
   "                        field, mapping, schema[field]['valuesrules']\n",
   "                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\n",
   "                    self.__normalize_mapping_per_schema(field, mapping, schema)\n",
   "            elif isinstance(mapping[field], str):\n",
   "            elif isinstance(mapping[field], Sequence):\n",
   "                if 'itemsrules' in rules:\n",
   "                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\n",
   "                elif 'items' in rules:\n",
   "                    self.__normalize_sequence_per_items(field, mapping, schema)\n",
   "        schema = {k: property_rules for k in mapping[field]}\n",
   "        document = {k: k for k in mapping[field]}\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\n",
   "        result = validator.normalized(document, always_return_document=True)\n",
   "        if validator._errors:\n",
   "            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\n",
   "            self._error(validator._errors)\n",
   "        for _in, out in ((k, v) for k, v in result.items() if k != v):\n",
   "            if out in mapping[field]:\n",
   "                        path='.'.join(str(x) for x in self.document_path + (field,)),\n",
   "                        key=_in,\n",
   "                mapping[field][out] = mapping[field][_in]\n",
   "                mapping[field][out] = mapping[field][_in]\n",
   "                del mapping[field][_in]\n",
   "        schema = {k: value_rules for k in mapping[field]}\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\n",
   "        mapping[field] = validator.normalized(\n",
   "            mapping[field], always_return_document=True\n",
   "        if validator._errors:\n",
   "            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\n",
   "            self._error(validator._errors)\n",
   "        rules = schema.get(field, {})\n",
   "        if not rules and isinstance(self.allow_unknown, Mapping):\n",
   "            rules = self.allow_unknown\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field,\n",
   "            schema_crumb=(field, 'schema'),\n",
   "            schema=rules.get('schema', {}),\n",
   "            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\n",
   "            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\n",
   "            require_all=rules.get('require_all', self.require_all),\n",
   "        value_type = type(mapping[field])\n",
   "        result_value = validator.normalized(mapping[field], always_return_document=True)\n",
   "        mapping[field] = value_type(result_value)\n",
   "        if validator._errors:\n",
   "            self._error(validator._errors)\n",
   "        rules, values = schema[field]['items'], mapping[field]\n",
   "        if len(rules) != len(values):\n",
   "        schema = {k: v for k, v in enumerate(rules)}\n",
   "        document = {k: v for k, v in enumerate(values)}\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\n",
   "        value_type = type(mapping[field])\n",
   "        result = validator.normalized(document, always_return_document=True)\n",
   "        mapping[field] = value_type(result.values())\n",
   "        if validator._errors:\n",
   "            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\n",
   "            self._error(validator._errors)\n",
   "        constraint = schema[field]['itemsrules']\n",
   "        schema = {k: constraint for k in range(len(mapping[field]))}\n",
   "        document = {k: v for k, v in enumerate(mapping[field])}\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\n",
   "        value_type = type(mapping[field])\n",
   "        result = validator.normalized(document, always_return_document=True)\n",
   "        mapping[field] = value_type(result.values())\n",
   "        if validator._errors:\n",
   "            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\n",
   "            self._error(validator._errors)\n",
   "        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\n",
   "            mapping.pop(field)\n",
   "        return mapping\n",
   "        for field in [x for x in mapping if x not in schema]:\n",
   "            mapping.pop(field)\n",
   "        return mapping\n",
   "        for field in tuple(mapping):\n",
   "            if field in schema:\n",
   "                self._normalize_rename(mapping, schema, field)\n",
   "                self._normalize_rename_handler(mapping, schema, field)\n",
   "                    mapping, {field: self.allow_unknown}, field\n",
   "        return mapping\n",
   "        if 'rename' in schema[field]:\n",
   "            mapping[schema[field]['rename']] = mapping[field]\n",
   "            del mapping[field]\n",
   "        if 'rename_handler' not in schema[field]:\n",
   "        new_name = self.__normalize_coerce(\n",
   "            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\n",
   "        if new_name != field:\n",
   "            mapping[new_name] = mapping[field]\n",
   "            del mapping[field]\n",
   "        for field in (\n",
   "            x\n",
   "            for x in schema\n",
   "            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\n",
   "            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\n",
   "        empty_fields = [\n",
   "            x\n",
   "            for x in schema\n",
   "            if x not in mapping\n",
   "                mapping[x] is None  # noqa: W503\n",
   "                and not schema[x].get('nullable', False)\n",
   "        for field in (x for x in empty_fields if 'default' in schema[x]):\n",
   "            self._normalize_default(mapping, schema, field)\n",
   "        known_fields_states = set()\n",
   "        fields_with_default_setter = [\n",
   "            x for x in empty_fields if 'default_setter' in schema[x]\n",
   "        while fields_with_default_setter:\n",
   "            field = fields_with_default_setter.pop(0)\n",
   "                self._normalize_default_setter(mapping, schema, field)\n",
   "                fields_with_default_setter.append(field)\n",
   "                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\n",
   "            fields_processing_state = hash(tuple(fields_with_default_setter))\n",
   "            if fields_processing_state in known_fields_states:\n",
   "                for field in fields_with_default_setter:\n",
   "                        field,\n",
   "                known_fields_states.add(fields_processing_state)\n",
   "        mapping[field] = schema[field]['default']\n",
   "        if 'default_setter' in schema[field]:\n",
   "            setter = schema[field]['default_setter']\n",
   "            if isinstance(setter, str):\n",
   "                setter = self.__get_rule_handler('normalize_default_setter', setter)\n",
   "            mapping[field] = setter(mapping)\n",
   "        self.__init_processing(document, schema)\n",
   "        for field in self.document:  # type: ignore\n",
   "            definitions = self.schema.get(field)  # type: ignore\n",
   "            if definitions is not None:\n",
   "                self.__validate_definitions(definitions, field)\n",
   "                self.__validate_unknown_fields(field)\n",
   "            document=document, schema=schema, update=update, normalize=normalize\n",
   "            value = self.document[field]\n",
   "                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\n",
   "                validator = self._get_child_validator(\n",
   "                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\n",
   "                if not validator({field: value}, normalize=False):\n",
   "                    self._error(validator._errors)\n",
   "            self._error(field, errors.UNKNOWN_FIELD)\n",
   "        definitions = self._resolve_rules_set(definitions)\n",
   "        value = self.document[field]\n",
   "        rules_queue = [\n",
   "            x\n",
   "            for x in self.priority_validations\n",
   "            if x in definitions or x in self.mandatory_validations\n",
   "        rules_queue.extend(\n",
   "            x for x in self.mandatory_validations if x not in rules_queue\n",
   "        rules_queue.extend(\n",
   "            x\n",
   "            for x in definitions\n",
   "            if x not in rules_queue\n",
   "            and x not in self.normalization_rules\n",
   "            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\n",
   "        self._remaining_rules = rules_queue\n",
   "            rule = self._remaining_rules.pop(0)\n",
   "            rule_handler = self.__get_rule_handler('validate', rule)\n",
   "            rule_handler(definitions.get(rule, None), field, value)\n",
   "        if isinstance(value, Iterable) and not isinstance(value, str):\n",
   "            unallowed = tuple(x for x in value if x not in allowed_values)\n",
   "            if unallowed:\n",
   "                self._error(field, errors.UNALLOWED_VALUES, unallowed)\n",
   "            if value not in allowed_values:\n",
   "                self._error(field, errors.UNALLOWED_VALUE, value)\n",
   "            value_checker = self.__get_rule_handler('check_with', checks)\n",
   "            value_checker(field, value)\n",
   "            for v in checks:\n",
   "                self._validate_check_with(v, field, value)\n",
   "            checks(field, value, self._error)\n",
   "        if not isinstance(value, Container):\n",
   "            expected_values = set((expected_values,))\n",
   "            expected_values = set(expected_values)\n",
   "        missing_values = expected_values - set(value)\n",
   "        if missing_values:\n",
   "            self._error(field, errors.MISSING_MEMBERS, missing_values)\n",
   "            dependencies = (dependencies,)\n",
   "        if isinstance(dependencies, Sequence):\n",
   "            self.__validate_dependencies_sequence(dependencies, field)\n",
   "        elif isinstance(dependencies, Mapping):\n",
   "            self.__validate_dependencies_mapping(dependencies, field)\n",
   "                self.schema_path + (field, 'dependencies')\n",
   "        validated_dependencies_counter = 0\n",
   "        error_info = {}\n",
   "        for dependency_name, dependency_values in dependencies.items():\n",
   "            if not isinstance(dependency_values, Sequence) or isinstance(\n",
   "                dependency_values, str\n",
   "                dependency_values = [dependency_values]\n",
   "            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\n",
   "            if wanted_field_value in dependency_values:\n",
   "                validated_dependencies_counter += 1\n",
   "                error_info.update({dependency_name: wanted_field_value})\n",
   "        if validated_dependencies_counter != len(dependencies):\n",
   "            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\n",
   "        for dependency in dependencies:\n",
   "            if self._lookup_field(dependency)[0] is None:\n",
   "                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\n",
   "        if isinstance(value, Sized) and len(value) == 0:\n",
   "                self._error(field, errors.EMPTY)\n",
   "            excluded_fields = (excluded_fields,)\n",
   "        if self.schema[field].get('required', self.require_all):\n",
   "            self._unrequired_by_excludes.add(field)\n",
   "        for excluded_field in excluded_fields:\n",
   "            if excluded_field in self.schema and self.schema[field].get(\n",
   "                self._unrequired_by_excludes.add(excluded_field)\n",
   "        if any(excluded_field in self.document for excluded_field in excluded_fields):\n",
   "            exclusion_str = ', '.join(\n",
   "                \"'{0}'\".format(field) for field in excluded_fields\n",
   "            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\n",
   "        if isinstance(value, str):\n",
   "            if value in forbidden_values:\n",
   "                self._error(field, errors.FORBIDDEN_VALUE, value)\n",
   "        elif isinstance(value, Iterable):\n",
   "            forbidden = set(value) & set(forbidden_values)\n",
   "            if forbidden:\n",
   "                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\n",
   "            if value in forbidden_values:\n",
   "                self._error(field, errors.FORBIDDEN_VALUE, value)\n",
   "        if len(items) != len(values):\n",
   "            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\n",
   "            schema = {i: definition for i, definition in enumerate(items)}\n",
   "            validator = self._get_child_validator(\n",
   "                document_crumb=field,\n",
   "                schema_crumb=(field, 'items'),  # noqa: E501\n",
   "                schema=schema,\n",
   "            if not validator(\n",
   "                {i: value for i, value in enumerate(values)},\n",
   "                self._error(field, errors.ITEMS, validator._errors)\n",
   "        if not isinstance(value, Sequence):\n",
   "        schema = {i: rulesset for i in range(len(value))}\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field,\n",
   "            schema_crumb=(field, 'itemsrules'),\n",
   "            schema=schema,\n",
   "        validator(\n",
   "            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\n",
   "        if validator._errors:\n",
   "            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\n",
   "            self._error(field, errors.ITEMSRULES, validator._errors)\n",
   "        valid_counter = 0\n",
   "        _errors = errors.ErrorList()\n",
   "        for i, definition in enumerate(definitions):\n",
   "            schema = {field: definition.copy()}\n",
   "            for rule in ('allow_unknown', 'type'):\n",
   "                if rule not in definition and rule in self.schema[field]:\n",
   "                    schema[field][rule] = self.schema[field][rule]\n",
   "            if 'allow_unknown' not in definition:\n",
   "                schema[field]['allow_unknown'] = self.allow_unknown\n",
   "            validator = self._get_child_validator(\n",
   "                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\n",
   "            if validator(self.document, update=self.update, normalize=False):\n",
   "                valid_counter += 1\n",
   "                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\n",
   "                _errors.extend(validator._errors)\n",
   "        return valid_counter, _errors\n",
   "        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\n",
   "        if valids < 1:\n",
   "            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\n",
   "        valids, _errors = self.__validate_logical('allof', definitions, field, value)\n",
   "        if valids < len(definitions):\n",
   "            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\n",
   "        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\n",
   "        if valids > 0:\n",
   "            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\n",
   "        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\n",
   "        if valids != 1:\n",
   "            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\n",
   "            if value > max_value:\n",
   "                self._error(field, errors.MAX_VALUE)\n",
   "            if value < min_value:\n",
   "                self._error(field, errors.MIN_VALUE)\n",
   "        if isinstance(value, Iterable) and len(value) > max_length:\n",
   "            self._error(field, errors.MAX_LENGTH, len(value))\n",
   "        if isinstance(value, Iterable) and len(value) < min_length:\n",
   "            self._error(field, errors.MIN_LENGTH, len(value))\n",
   "        if value is None:\n",
   "                self._error(field, errors.NULLABLE)\n",
   "        if isinstance(value, Mapping):\n",
   "            validator = self._get_child_validator(\n",
   "                document_crumb=field,\n",
   "                schema_crumb=(field, 'keysrules'),\n",
   "                schema={k: schema for k in value.keys()},\n",
   "            if not validator({k: k for k in value.keys()}, normalize=False):\n",
   "                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\n",
   "                self._error(field, errors.KEYSRULES, validator._errors)\n",
   "                self._error(field, errors.READONLY_FIELD)\n",
   "            has_error = (\n",
   "                    self.document_path + (field,)\n",
   "            if self._is_normalized and has_error:\n",
   "        if not isinstance(value, str):\n",
   "            pattern += '$'\n",
   "        re_obj = re.compile(pattern)\n",
   "        if not re_obj.match(value):\n",
   "            self._error(field, errors.REGEX_MISMATCH)\n",
   "        required = set(\n",
   "            field\n",
   "            for field, definition in self.schema.items()\n",
   "            if self._resolve_rules_set(definition).get('required', self.require_all)\n",
   "        required -= self._unrequired_by_excludes\n",
   "        missing = required - set(\n",
   "            field\n",
   "            for field in document\n",
   "            if document.get(field) is not None or not self.ignore_none_values\n",
   "        for field in missing:\n",
   "            self._error(field, errors.REQUIRED_FIELD)\n",
   "            fields = set(field for field in document if document.get(field) is not None)\n",
   "            if self._unrequired_by_excludes.isdisjoint(fields):\n",
   "                for field in self._unrequired_by_excludes - fields:\n",
   "                    self._error(field, errors.REQUIRED_FIELD)\n",
   "        if not isinstance(value, Mapping):\n",
   "        schema = self._resolve_schema(schema)\n",
   "        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\n",
   "        require_all = self.schema[field].get('require_all', self.require_all)\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field,\n",
   "            schema_crumb=(field, 'schema'),\n",
   "            schema=schema,\n",
   "            allow_unknown=allow_unknown,\n",
   "            require_all=require_all,\n",
   "        if not validator(value, update=self.update, normalize=False):\n",
   "            self._error(field, errors.SCHEMA, validator._errors)\n",
   "        for _type in data_type:\n",
   "            if isinstance(_type, str):\n",
   "                type_definition = self.types_mapping[_type]\n",
   "                if isinstance(value, type_definition.included_types) and not isinstance(\n",
   "                    value, type_definition.excluded_types\n",
   "                if isinstance(value, _type):\n",
   "        self._error(field, errors.TYPE)\n",
   "        if isinstance(value, Mapping):\n",
   "            schema_crumb = (field, 'valuesrules')\n",
   "                document_crumb=field,\n",
   "                schema_crumb=schema_crumb,\n",
   "                schema={k: schema for k in value},\n",
   "            validator(value, update=self.update, normalize=False)\n",
   "            if validator._errors:\n",
   "                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\n",
   "                self._error(field, errors.VALUESRULES, validator._errors)\n"
  ]
 },
 "10": {
  "name": "docstring",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "392",
  "column": "8",
  "context": "def __get_rule_schema(mcls, method_name):\n        docstring = getattr(mcls, method_name).__doc__\n        if docstring is None:\n            result =",
  "context_lines": "        cls.normalization_rules = normalize_schema(normalization_rules)\n        cls.validation_rules = normalize_schema(validation_rules)\n        cls.rules = ChainMap(cls.normalization_rules, cls.validation_rules)\n\n    def __get_rule_schema(mcls, method_name):\n        docstring = getattr(mcls, method_name).__doc__\n        if docstring is None:\n            result = {}\n        else:\n            if RULE_SCHEMA_SEPARATOR in docstring:\n",
  "slicing": [
   "RULE_SCHEMA_SEPARATOR = \"The rule's arguments are validated against this schema:\"\n",
   "toy_error_handler = errors.ToyErrorHandler()\n",
   "_ellipsis = typing.Tuple[int, ...].__args__[-1]\n",
   "def dummy_for_rule_validation(rule_constraints: str) -> Callable:\n",
   "    f = dummy\n",
   "    f.__doc__ = rule_constraints\n",
   "    return f\n",
   "_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\n",
   "def normalize_rulesset(rules: RulesSet) -> RulesSet:\n",
   "    _hash = schema_hash(rules)\n",
   "    if _hash in _normalized_rulesset_cache:\n",
   "        return _normalized_rulesset_cache[_hash]\n",
   "    rules = dict(rules)\n",
   "    rules_with_whitespace = [x for x in rules if \" \" in x]\n",
   "    if rules_with_whitespace:\n",
   "        for rule in rules_with_whitespace:\n",
   "            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\n",
   "    if isinstance(rules.get(\"dependencies\"), str):\n",
   "        rules[\"dependencies\"] = (rules[\"dependencies\"],)\n",
   "    if \"excludes\" in rules:\n",
   "        constraint = rules[\"excludes\"]\n",
   "        if isinstance(constraint, str) or not isinstance(constraint, Container):\n",
   "            rules[\"excludes\"] = (constraint,)\n",
   "    if \"type\" in rules:\n",
   "        constraint = rules[\"type\"]\n",
   "        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\n",
   "            rules[\"type\"] = (constraint,)\n",
   "        _expand_generic_type_aliases(rules)\n",
   "    _expand_composed_of_rules(rules)\n",
   "    _normalize_contained_rulessets(rules)\n",
   "    _normalized_rulesset_cache[_hash] = rules\n",
   "    return rules\n",
   "def normalize_schema(schema: Schema) -> Schema:\n",
   "    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\n",
   "    compound_types = []\n",
   "    plain_types = []\n",
   "    is_nullable = False\n",
   "    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\n",
   "        if isinstance(constraint, _GenericAlias):\n",
   "            origin = get_type_origin(constraint)\n",
   "            args = get_type_args(constraint)\n",
   "            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\n",
   "                compound_types.append(\n",
   "                        \"type\": origin,\n",
   "                        \"keysrules\": {\"type\": args[0]},\n",
   "                        \"valuesrules\": {\"type\": args[1]},\n",
   "                issubclass(origin, (abc.MutableSequence, abc.Set))\n",
   "                and not constraint.__parameters__\n",
   "                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\n",
   "            elif issubclass(origin, tuple) and args:\n",
   "                if args[-1] is _ellipsis:\n",
   "                    compound_types.append(\n",
   "                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\n",
   "                    compound_types.append(\n",
   "                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\n",
   "                plain_types.append(origin)\n",
   "        elif constraint is NoneType:  # type: ignore\n",
   "            is_nullable = True\n",
   "        elif isinstance(constraint, ForwardRef):\n",
   "            plain_types.append(constraint.__forward_arg__)\n",
   "            plain_types.append(constraint)\n",
   "    if compound_types or is_nullable:\n",
   "        if \"anyof\" in rules:\n",
   "        if plain_types:\n",
   "            compound_types.append({\"type\": tuple(plain_types)})\n",
   "        if is_nullable:\n",
   "            compound_types.append({\"nullable\": True})\n",
   "        rules[\"anyof\"] = tuple(compound_types)\n",
   "        rules[\"type\"] = tuple(plain_types)\n",
   "    for constraint in type_constraints:\n",
   "        if get_type_origin(constraint) is typing.Union:\n",
   "            yield from _flatten_Union_and_Optional(get_type_args(constraint))\n",
   "            yield constraint\n",
   "    composed_rules = [\n",
   "        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\n",
   "    if not composed_rules:\n",
   "    for composed_rule in composed_rules:\n",
   "        of_rule, rule = composed_rule.split('_', 1)\n",
   "        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\n",
   "    for rule in composed_rules:\n",
   "        rules.pop(rule)\n",
   "    if isinstance(rules.get(\"schema\"), abc.Mapping):\n",
   "        rules['schema'] = normalize_schema(rules['schema'])\n",
   "    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\n",
   "        if rule in rules:\n",
   "            rules[rule] = normalize_rulesset(rules[rule])\n",
   "    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\n",
   "        if not isinstance(rules.get(rule), Sequence):\n",
   "        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\n",
   "        for name, definition in dict(definitions).items():\n",
   "            self.add(name, definition)\n",
   "        return self._storage.get(name, default)\n",
   "        for name in names:\n",
   "            self._storage.pop(name, None)\n",
   "schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\n",
   "TypeDefinition = NamedTuple(\n",
   "        return super().__new__(mcls, name, bases, namespace)\n",
   "        def attributes_with_prefix(prefix):\n",
   "                x[len(prefix) + 2 :]\n",
   "                for x in dir(cls)\n",
   "                if x.startswith('_' + prefix + '_')\n",
   "        super().__init__(name, bases, namespace)\n",
   "        validation_rules = {\n",
   "            for attribute in attributes_with_prefix('validate')\n",
   "        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\n",
   "        x = validation_rules['check_with']['oneof']\n",
   "        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\n",
   "        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\n",
   "            validation_rules[rule]['required'] = True\n",
   "        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\n",
   "        for attribute in attributes_with_prefix('normalize'):\n",
   "            if attribute.startswith('coerce_'):\n",
   "                cls.coercers += (attribute[len('coerce_') :],)\n",
   "            elif attribute.startswith('default_setter_'):\n",
   "                cls.default_setters += (attribute[len('default_setter_') :],)\n",
   "                normalization_rules[attribute] = cls.__get_rule_schema(\n",
   "                    '_normalize_' + attribute\n",
   "        for rule in ('coerce', 'rename_handler'):\n",
   "            x = normalization_rules[rule]['oneof']\n",
   "            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\n",
   "        normalization_rules['default_setter']['oneof'][1][\n",
   "        cls.normalization_rules = normalize_schema(normalization_rules)\n",
   "        cls.validation_rules = normalize_schema(validation_rules)\n",
   "        docstring = getattr(mcls, method_name).__doc__\n",
   "        if docstring is None:\n",
   "            result = {}\n",
   "            if RULE_SCHEMA_SEPARATOR in docstring:\n",
   "                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\n",
   "                result = literal_eval(docstring.strip())\n",
   "                result = {}\n",
   "        if not result and method_name != '_validate_meta':\n",
   "        return result\n",
   "    types_mapping = {\n",
   "        'boolean': TypeDefinition('boolean', (bool,), ()),\n",
   "        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\n",
   "        'bytes': TypeDefinition('bytes', (bytes,), ()),\n",
   "        'complex': TypeDefinition('complex', (complex,), ()),\n",
   "        'date': TypeDefinition('date', (date,), (datetime,)),\n",
   "        'datetime': TypeDefinition('datetime', (datetime,), ()),\n",
   "        'dict': TypeDefinition('dict', (Mapping,), ()),\n",
   "        'float': TypeDefinition('float', (float,), ()),\n",
   "        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\n",
   "        'integer': TypeDefinition('integer', (int,), (bool,)),\n",
   "        'list': TypeDefinition('list', (list,), ()),\n",
   "        'number': TypeDefinition('number', (int, float), (bool,)),\n",
   "        'set': TypeDefinition('set', (set,), ()),\n",
   "        'string': TypeDefinition('string', (str,), ()),\n",
   "        'tuple': TypeDefinition('tuple', (tuple,), ()),\n",
   "        'type': TypeDefinition('type', (type,), ()),\n",
   "    types_mapping.update(\n",
   "        (x, TypeDefinition(x, (getattr(abc, x),), ()))\n",
   "        for x in abc.__all__  # type: ignore\n",
   "    normalization_rules = {}  # type: ClassVar[Schema]\n",
   "    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\n",
   "    validation_rules = {}  # type: ClassVar[Schema]\n",
   "        rules_set_registry: RulesSetRegistry = rules_set_registry,\n",
   "        schema_registry: SchemaRegistry = schema_registry,\n",
   "                \"rules_set_registry\": rules_set_registry,\n",
   "                \"schema_registry\": schema_registry,\n",
   "        self.schema = schema\n",
   "            error_handler, eh_config = config\n",
   "            error_handler, eh_config = config, {}\n",
   "        if isinstance(error_handler, type) and issubclass(\n",
   "            error_handler, errors.BaseErrorHandler\n",
   "            return error_handler(**eh_config)\n",
   "        if len(args) == 1:\n",
   "            self._errors.extend(args[0])\n",
   "            for error in args[0]:\n",
   "                self.document_error_tree.add(error)\n",
   "                self.schema_error_tree.add(error)\n",
   "                self.error_handler.emit(error)\n",
   "        elif len(args) == 2 and isinstance(args[1], str):\n",
   "            self._error(args[0], errors.CUSTOM, args[1])\n",
   "        elif len(args) >= 2:\n",
   "            field = args[0]\n",
   "            code = args[1].code\n",
   "            rule = args[1].rule\n",
   "            info = args[2:]\n",
   "            document_path = self.document_path + (field,)\n",
   "            schema_path = self.schema_path\n",
   "            if code != errors.UNKNOWN_FIELD.code and rule is not None:\n",
   "                schema_path += (field, rule)\n",
   "            if not rule:\n",
   "                constraint = None\n",
   "                field_definitions = self._resolve_rules_set(self.schema[field])\n",
   "                if rule == 'nullable':\n",
   "                    constraint = field_definitions.get(rule, False)\n",
   "                elif rule == 'required':\n",
   "                    constraint = field_definitions.get(rule, self.require_all)\n",
   "                    if rule not in field_definitions:\n",
   "                        schema_path = \"__require_all__\"\n",
   "                    constraint = field_definitions[rule]\n",
   "            value = self.document.get(field)\n",
   "                document_path, schema_path, code, rule, constraint, value, info\n",
   "        child_config = ChainMap(kwargs, self._config)\n",
   "            child_config = child_config.new_child(\n",
   "                    'error_handler': toy_error_handler,\n",
   "        child_validator = self.__class__(**child_config)\n",
   "            child_validator.document_path = self.document_path\n",
   "                document_crumb = (document_crumb,)\n",
   "            child_validator.document_path = self.document_path + document_crumb\n",
   "            child_validator.schema_path = self.schema_path\n",
   "                schema_crumb = (schema_crumb,)\n",
   "            child_validator.schema_path = self.schema_path + schema_crumb\n",
   "        return child_validator\n",
   "        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\n",
   "        result = getattr(self, methodname, None)\n",
   "        if result is None:\n",
   "                \"domain.\".format(rule, domain)\n",
   "        return result\n",
   "        dp_basedepth = len(self.document_path)\n",
   "        sp_basedepth = len(self.schema_path)\n",
   "        for error in _errors:\n",
   "            for i in sorted(dp_items, reverse=True):\n",
   "                error.document_path = drop_item_from_tuple(\n",
   "                    error.document_path, dp_basedepth + i\n",
   "            for i in sorted(sp_items, reverse=True):\n",
   "                error.schema_path = drop_item_from_tuple(\n",
   "                    error.schema_path, sp_basedepth + i\n",
   "            if error.child_errors:\n",
   "                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\n",
   "            path = path[1:]\n",
   "            context = self.document if path.startswith('^') else self.root_document\n",
   "            context = self.document\n",
   "        parts = path.split('.')\n",
   "        for part in parts:\n",
   "            if part not in context:\n",
   "            context = context.get(part, {})\n",
   "        return parts[-1], context\n",
   "        if isinstance(schema, Mapping):\n",
   "            return schema\n",
   "        elif isinstance(schema, str):\n",
   "            return self.schema_registry.get(schema)\n",
   "        if isinstance(value, Mapping):\n",
   "            self._config['allow_unknown'] = normalize_rulesset(value)\n",
   "        elif isinstance(value, bool):\n",
   "            self._config['allow_unknown'] = value\n",
   "        self._config['ignore_none_values'] = value\n",
   "        self._config['_is_normalized'] = value\n",
   "        self._config['purge_unknown'] = value\n",
   "        self._config['purge_readonly'] = value\n",
   "        self._config['require_all'] = value\n",
   "    @rules_set_registry.setter\n",
   "    @schema.setter\n",
   "        if schema is None:\n",
   "            self._schema = schema\n",
   "            self._schema = normalize_schema(schema)\n",
   "    @schema_registry.setter\n",
   "        if schema is not None:\n",
   "            self.schema = schema\n",
   "        if rules:\n",
   "            for rule in (x for x in rules if x in self._remaining_rules):\n",
   "                self._remaining_rules.remove(rule)\n",
   "        self.__init_processing(document, schema)\n",
   "        mapping = mapping.copy()\n",
   "        if isinstance(schema, str):\n",
   "            schema = self._resolve_schema(schema)\n",
   "        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\n",
   "        self.__normalize_rename_fields(mapping, schema)\n",
   "            self._normalize_purge_unknown(mapping, schema)\n",
   "            self.__normalize_purge_readonly(mapping, schema)\n",
   "        self.__validate_readonly_fields(mapping, schema)\n",
   "        self.__normalize_default_fields(mapping, schema)\n",
   "        self._normalize_coerce(mapping, schema)\n",
   "        self.__normalize_containers(mapping, schema)\n",
   "        return mapping\n",
   "        error = errors.COERCION_FAILED\n",
   "        for field in mapping:\n",
   "            if field in schema and 'coerce' in schema[field]:\n",
   "                mapping[field] = self.__normalize_coerce(\n",
   "                    schema[field]['coerce'],\n",
   "                    field,\n",
   "                    mapping[field],\n",
   "                    schema[field].get('nullable', False),\n",
   "                    error,\n",
   "                mapping[field] = self.__normalize_coerce(\n",
   "                    field,\n",
   "                    mapping[field],\n",
   "                    error,\n",
   "            processor = self.__get_rule_handler('normalize_coerce', processor)\n",
   "        elif isinstance(processor, Iterable):\n",
   "            result = value\n",
   "            for p in processor:\n",
   "                result = self.__normalize_coerce(p, field, result, nullable, error)\n",
   "                        self.document_path + (field,)\n",
   "            return result\n",
   "            return processor(value)\n",
   "            if not (nullable and value is None):\n",
   "                self._error(field, error, str(e))\n",
   "            return value\n",
   "        for field in mapping:\n",
   "            rules = set(schema.get(field, ()))\n",
   "            if isinstance(mapping[field], Mapping):\n",
   "                if 'keysrules' in rules:\n",
   "                        field, mapping, schema[field]['keysrules']\n",
   "                if 'valuesrules' in rules:\n",
   "                        field, mapping, schema[field]['valuesrules']\n",
   "                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\n",
   "                    self.__normalize_mapping_per_schema(field, mapping, schema)\n",
   "            elif isinstance(mapping[field], str):\n",
   "            elif isinstance(mapping[field], Sequence):\n",
   "                if 'itemsrules' in rules:\n",
   "                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\n",
   "                elif 'items' in rules:\n",
   "                    self.__normalize_sequence_per_items(field, mapping, schema)\n",
   "        schema = {k: property_rules for k in mapping[field]}\n",
   "        document = {k: k for k in mapping[field]}\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\n",
   "        result = validator.normalized(document, always_return_document=True)\n",
   "        if validator._errors:\n",
   "            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\n",
   "            self._error(validator._errors)\n",
   "        for _in, out in ((k, v) for k, v in result.items() if k != v):\n",
   "            if out in mapping[field]:\n",
   "                        path='.'.join(str(x) for x in self.document_path + (field,)),\n",
   "                        key=_in,\n",
   "                mapping[field][out] = mapping[field][_in]\n",
   "                mapping[field][out] = mapping[field][_in]\n",
   "                del mapping[field][_in]\n",
   "        schema = {k: value_rules for k in mapping[field]}\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\n",
   "        mapping[field] = validator.normalized(\n",
   "            mapping[field], always_return_document=True\n",
   "        if validator._errors:\n",
   "            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\n",
   "            self._error(validator._errors)\n",
   "        rules = schema.get(field, {})\n",
   "        if not rules and isinstance(self.allow_unknown, Mapping):\n",
   "            rules = self.allow_unknown\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field,\n",
   "            schema_crumb=(field, 'schema'),\n",
   "            schema=rules.get('schema', {}),\n",
   "            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\n",
   "            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\n",
   "            require_all=rules.get('require_all', self.require_all),\n",
   "        value_type = type(mapping[field])\n",
   "        result_value = validator.normalized(mapping[field], always_return_document=True)\n",
   "        mapping[field] = value_type(result_value)\n",
   "        if validator._errors:\n",
   "            self._error(validator._errors)\n",
   "        rules, values = schema[field]['items'], mapping[field]\n",
   "        if len(rules) != len(values):\n",
   "        schema = {k: v for k, v in enumerate(rules)}\n",
   "        document = {k: v for k, v in enumerate(values)}\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\n",
   "        value_type = type(mapping[field])\n",
   "        result = validator.normalized(document, always_return_document=True)\n",
   "        mapping[field] = value_type(result.values())\n",
   "        if validator._errors:\n",
   "            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\n",
   "            self._error(validator._errors)\n",
   "        constraint = schema[field]['itemsrules']\n",
   "        schema = {k: constraint for k in range(len(mapping[field]))}\n",
   "        document = {k: v for k, v in enumerate(mapping[field])}\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\n",
   "        value_type = type(mapping[field])\n",
   "        result = validator.normalized(document, always_return_document=True)\n",
   "        mapping[field] = value_type(result.values())\n",
   "        if validator._errors:\n",
   "            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\n",
   "            self._error(validator._errors)\n",
   "        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\n",
   "            mapping.pop(field)\n",
   "        return mapping\n",
   "        for field in [x for x in mapping if x not in schema]:\n",
   "            mapping.pop(field)\n",
   "        return mapping\n",
   "        for field in tuple(mapping):\n",
   "            if field in schema:\n",
   "                self._normalize_rename(mapping, schema, field)\n",
   "                self._normalize_rename_handler(mapping, schema, field)\n",
   "                    mapping, {field: self.allow_unknown}, field\n",
   "        return mapping\n",
   "        if 'rename' in schema[field]:\n",
   "            mapping[schema[field]['rename']] = mapping[field]\n",
   "            del mapping[field]\n",
   "        if 'rename_handler' not in schema[field]:\n",
   "        new_name = self.__normalize_coerce(\n",
   "            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\n",
   "        if new_name != field:\n",
   "            mapping[new_name] = mapping[field]\n",
   "            del mapping[field]\n",
   "        for field in (\n",
   "            x\n",
   "            for x in schema\n",
   "            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\n",
   "            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\n",
   "        empty_fields = [\n",
   "            x\n",
   "            for x in schema\n",
   "            if x not in mapping\n",
   "                mapping[x] is None  # noqa: W503\n",
   "                and not schema[x].get('nullable', False)\n",
   "        for field in (x for x in empty_fields if 'default' in schema[x]):\n",
   "            self._normalize_default(mapping, schema, field)\n",
   "        known_fields_states = set()\n",
   "        fields_with_default_setter = [\n",
   "            x for x in empty_fields if 'default_setter' in schema[x]\n",
   "        while fields_with_default_setter:\n",
   "            field = fields_with_default_setter.pop(0)\n",
   "                self._normalize_default_setter(mapping, schema, field)\n",
   "                fields_with_default_setter.append(field)\n",
   "                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\n",
   "            fields_processing_state = hash(tuple(fields_with_default_setter))\n",
   "            if fields_processing_state in known_fields_states:\n",
   "                for field in fields_with_default_setter:\n",
   "                        field,\n",
   "                known_fields_states.add(fields_processing_state)\n",
   "        mapping[field] = schema[field]['default']\n",
   "        if 'default_setter' in schema[field]:\n",
   "            setter = schema[field]['default_setter']\n",
   "            if isinstance(setter, str):\n",
   "                setter = self.__get_rule_handler('normalize_default_setter', setter)\n",
   "            mapping[field] = setter(mapping)\n",
   "        self.__init_processing(document, schema)\n",
   "        for field in self.document:  # type: ignore\n",
   "            definitions = self.schema.get(field)  # type: ignore\n",
   "            if definitions is not None:\n",
   "                self.__validate_definitions(definitions, field)\n",
   "                self.__validate_unknown_fields(field)\n",
   "            document=document, schema=schema, update=update, normalize=normalize\n",
   "            value = self.document[field]\n",
   "                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\n",
   "                validator = self._get_child_validator(\n",
   "                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\n",
   "                if not validator({field: value}, normalize=False):\n",
   "                    self._error(validator._errors)\n",
   "            self._error(field, errors.UNKNOWN_FIELD)\n",
   "        definitions = self._resolve_rules_set(definitions)\n",
   "        value = self.document[field]\n",
   "        rules_queue = [\n",
   "            x\n",
   "            for x in self.priority_validations\n",
   "            if x in definitions or x in self.mandatory_validations\n",
   "        rules_queue.extend(\n",
   "            x for x in self.mandatory_validations if x not in rules_queue\n",
   "        rules_queue.extend(\n",
   "            x\n",
   "            for x in definitions\n",
   "            if x not in rules_queue\n",
   "            and x not in self.normalization_rules\n",
   "            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\n",
   "        self._remaining_rules = rules_queue\n",
   "            rule = self._remaining_rules.pop(0)\n",
   "            rule_handler = self.__get_rule_handler('validate', rule)\n",
   "            rule_handler(definitions.get(rule, None), field, value)\n",
   "        if isinstance(value, Iterable) and not isinstance(value, str):\n",
   "            unallowed = tuple(x for x in value if x not in allowed_values)\n",
   "            if unallowed:\n",
   "                self._error(field, errors.UNALLOWED_VALUES, unallowed)\n",
   "            if value not in allowed_values:\n",
   "                self._error(field, errors.UNALLOWED_VALUE, value)\n",
   "            value_checker = self.__get_rule_handler('check_with', checks)\n",
   "            value_checker(field, value)\n",
   "            for v in checks:\n",
   "                self._validate_check_with(v, field, value)\n",
   "            checks(field, value, self._error)\n",
   "        if not isinstance(value, Container):\n",
   "            expected_values = set((expected_values,))\n",
   "            expected_values = set(expected_values)\n",
   "        missing_values = expected_values - set(value)\n",
   "        if missing_values:\n",
   "            self._error(field, errors.MISSING_MEMBERS, missing_values)\n",
   "            dependencies = (dependencies,)\n",
   "        if isinstance(dependencies, Sequence):\n",
   "            self.__validate_dependencies_sequence(dependencies, field)\n",
   "        elif isinstance(dependencies, Mapping):\n",
   "            self.__validate_dependencies_mapping(dependencies, field)\n",
   "                self.schema_path + (field, 'dependencies')\n",
   "        validated_dependencies_counter = 0\n",
   "        error_info = {}\n",
   "        for dependency_name, dependency_values in dependencies.items():\n",
   "            if not isinstance(dependency_values, Sequence) or isinstance(\n",
   "                dependency_values, str\n",
   "                dependency_values = [dependency_values]\n",
   "            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\n",
   "            if wanted_field_value in dependency_values:\n",
   "                validated_dependencies_counter += 1\n",
   "                error_info.update({dependency_name: wanted_field_value})\n",
   "        if validated_dependencies_counter != len(dependencies):\n",
   "            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\n",
   "        for dependency in dependencies:\n",
   "            if self._lookup_field(dependency)[0] is None:\n",
   "                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\n",
   "        if isinstance(value, Sized) and len(value) == 0:\n",
   "                self._error(field, errors.EMPTY)\n",
   "            excluded_fields = (excluded_fields,)\n",
   "        if self.schema[field].get('required', self.require_all):\n",
   "            self._unrequired_by_excludes.add(field)\n",
   "        for excluded_field in excluded_fields:\n",
   "            if excluded_field in self.schema and self.schema[field].get(\n",
   "                self._unrequired_by_excludes.add(excluded_field)\n",
   "        if any(excluded_field in self.document for excluded_field in excluded_fields):\n",
   "            exclusion_str = ', '.join(\n",
   "                \"'{0}'\".format(field) for field in excluded_fields\n",
   "            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\n",
   "        if isinstance(value, str):\n",
   "            if value in forbidden_values:\n",
   "                self._error(field, errors.FORBIDDEN_VALUE, value)\n",
   "        elif isinstance(value, Iterable):\n",
   "            forbidden = set(value) & set(forbidden_values)\n",
   "            if forbidden:\n",
   "                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\n",
   "            if value in forbidden_values:\n",
   "                self._error(field, errors.FORBIDDEN_VALUE, value)\n",
   "        if len(items) != len(values):\n",
   "            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\n",
   "            schema = {i: definition for i, definition in enumerate(items)}\n",
   "            validator = self._get_child_validator(\n",
   "                document_crumb=field,\n",
   "                schema_crumb=(field, 'items'),  # noqa: E501\n",
   "                schema=schema,\n",
   "            if not validator(\n",
   "                {i: value for i, value in enumerate(values)},\n",
   "                self._error(field, errors.ITEMS, validator._errors)\n",
   "        if not isinstance(value, Sequence):\n",
   "        schema = {i: rulesset for i in range(len(value))}\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field,\n",
   "            schema_crumb=(field, 'itemsrules'),\n",
   "            schema=schema,\n",
   "        validator(\n",
   "            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\n",
   "        if validator._errors:\n",
   "            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\n",
   "            self._error(field, errors.ITEMSRULES, validator._errors)\n",
   "        valid_counter = 0\n",
   "        _errors = errors.ErrorList()\n",
   "        for i, definition in enumerate(definitions):\n",
   "            schema = {field: definition.copy()}\n",
   "            for rule in ('allow_unknown', 'type'):\n",
   "                if rule not in definition and rule in self.schema[field]:\n",
   "                    schema[field][rule] = self.schema[field][rule]\n",
   "            if 'allow_unknown' not in definition:\n",
   "                schema[field]['allow_unknown'] = self.allow_unknown\n",
   "            validator = self._get_child_validator(\n",
   "                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\n",
   "            if validator(self.document, update=self.update, normalize=False):\n",
   "                valid_counter += 1\n",
   "                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\n",
   "                _errors.extend(validator._errors)\n",
   "        return valid_counter, _errors\n",
   "        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\n",
   "        if valids < 1:\n",
   "            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\n",
   "        valids, _errors = self.__validate_logical('allof', definitions, field, value)\n",
   "        if valids < len(definitions):\n",
   "            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\n",
   "        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\n",
   "        if valids > 0:\n",
   "            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\n",
   "        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\n",
   "        if valids != 1:\n",
   "            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\n",
   "            if value > max_value:\n",
   "                self._error(field, errors.MAX_VALUE)\n",
   "            if value < min_value:\n",
   "                self._error(field, errors.MIN_VALUE)\n",
   "        if isinstance(value, Iterable) and len(value) > max_length:\n",
   "            self._error(field, errors.MAX_LENGTH, len(value))\n",
   "        if isinstance(value, Iterable) and len(value) < min_length:\n",
   "            self._error(field, errors.MIN_LENGTH, len(value))\n",
   "        if value is None:\n",
   "                self._error(field, errors.NULLABLE)\n",
   "        if isinstance(value, Mapping):\n",
   "            validator = self._get_child_validator(\n",
   "                document_crumb=field,\n",
   "                schema_crumb=(field, 'keysrules'),\n",
   "                schema={k: schema for k in value.keys()},\n",
   "            if not validator({k: k for k in value.keys()}, normalize=False):\n",
   "                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\n",
   "                self._error(field, errors.KEYSRULES, validator._errors)\n",
   "                self._error(field, errors.READONLY_FIELD)\n",
   "            has_error = (\n",
   "                    self.document_path + (field,)\n",
   "            if self._is_normalized and has_error:\n",
   "        if not isinstance(value, str):\n",
   "            pattern += '$'\n",
   "        re_obj = re.compile(pattern)\n",
   "        if not re_obj.match(value):\n",
   "            self._error(field, errors.REGEX_MISMATCH)\n",
   "        required = set(\n",
   "            field\n",
   "            for field, definition in self.schema.items()\n",
   "            if self._resolve_rules_set(definition).get('required', self.require_all)\n",
   "        required -= self._unrequired_by_excludes\n",
   "        missing = required - set(\n",
   "            field\n",
   "            for field in document\n",
   "            if document.get(field) is not None or not self.ignore_none_values\n",
   "        for field in missing:\n",
   "            self._error(field, errors.REQUIRED_FIELD)\n",
   "            fields = set(field for field in document if document.get(field) is not None)\n",
   "            if self._unrequired_by_excludes.isdisjoint(fields):\n",
   "                for field in self._unrequired_by_excludes - fields:\n",
   "                    self._error(field, errors.REQUIRED_FIELD)\n",
   "        if not isinstance(value, Mapping):\n",
   "        schema = self._resolve_schema(schema)\n",
   "        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\n",
   "        require_all = self.schema[field].get('require_all', self.require_all)\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field,\n",
   "            schema_crumb=(field, 'schema'),\n",
   "            schema=schema,\n",
   "            allow_unknown=allow_unknown,\n",
   "            require_all=require_all,\n",
   "        if not validator(value, update=self.update, normalize=False):\n",
   "            self._error(field, errors.SCHEMA, validator._errors)\n",
   "        for _type in data_type:\n",
   "            if isinstance(_type, str):\n",
   "                type_definition = self.types_mapping[_type]\n",
   "                if isinstance(value, type_definition.included_types) and not isinstance(\n",
   "                    value, type_definition.excluded_types\n",
   "                if isinstance(value, _type):\n",
   "        self._error(field, errors.TYPE)\n",
   "        if isinstance(value, Mapping):\n",
   "            schema_crumb = (field, 'valuesrules')\n",
   "                document_crumb=field,\n",
   "                schema_crumb=schema_crumb,\n",
   "                schema={k: schema for k in value},\n",
   "            validator(value, update=self.update, normalize=False)\n",
   "            if validator._errors:\n",
   "                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\n",
   "                self._error(field, errors.VALUESRULES, validator._errors)\n"
  ]
 },
 "11": {
  "name": "__call__",
  "type": "function",
  "class": "unknown",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1357",
  "column": "4",
  "context": "ort()\n\n        return not bool(self._errors)\n\n    __call__ = validate\n\n    def validated(\n        self,\n        document",
  "context_lines": "            self.__validate_required_fields(self.document)\n\n        self.error_handler.end(self)\n        self._errors.sort()\n\n        return not bool(self._errors)\n\n    __call__ = validate\n\n    def validated(\n        self,\n        document: Document,\n",
  "slicing": [
   "RULE_SCHEMA_SEPARATOR = \"The rule's arguments are validated against this schema:\"\n",
   "toy_error_handler = errors.ToyErrorHandler()\n",
   "_ellipsis = typing.Tuple[int, ...].__args__[-1]\n",
   "def dummy_for_rule_validation(rule_constraints: str) -> Callable:\n",
   "    f = dummy\n",
   "    f.__doc__ = rule_constraints\n",
   "    return f\n",
   "_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\n",
   "def normalize_rulesset(rules: RulesSet) -> RulesSet:\n",
   "    _hash = schema_hash(rules)\n",
   "    if _hash in _normalized_rulesset_cache:\n",
   "        return _normalized_rulesset_cache[_hash]\n",
   "    rules = dict(rules)\n",
   "    rules_with_whitespace = [x for x in rules if \" \" in x]\n",
   "    if rules_with_whitespace:\n",
   "        for rule in rules_with_whitespace:\n",
   "            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\n",
   "    if isinstance(rules.get(\"dependencies\"), str):\n",
   "        rules[\"dependencies\"] = (rules[\"dependencies\"],)\n",
   "    if \"excludes\" in rules:\n",
   "        constraint = rules[\"excludes\"]\n",
   "        if isinstance(constraint, str) or not isinstance(constraint, Container):\n",
   "            rules[\"excludes\"] = (constraint,)\n",
   "    if \"type\" in rules:\n",
   "        constraint = rules[\"type\"]\n",
   "        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\n",
   "            rules[\"type\"] = (constraint,)\n",
   "        _expand_generic_type_aliases(rules)\n",
   "    _expand_composed_of_rules(rules)\n",
   "    _normalize_contained_rulessets(rules)\n",
   "    _normalized_rulesset_cache[_hash] = rules\n",
   "    return rules\n",
   "def normalize_schema(schema: Schema) -> Schema:\n",
   "    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\n",
   "    compound_types = []\n",
   "    plain_types = []\n",
   "    is_nullable = False\n",
   "    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\n",
   "        if isinstance(constraint, _GenericAlias):\n",
   "            origin = get_type_origin(constraint)\n",
   "            args = get_type_args(constraint)\n",
   "            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\n",
   "                compound_types.append(\n",
   "                        \"type\": origin,\n",
   "                        \"keysrules\": {\"type\": args[0]},\n",
   "                        \"valuesrules\": {\"type\": args[1]},\n",
   "                issubclass(origin, (abc.MutableSequence, abc.Set))\n",
   "                and not constraint.__parameters__\n",
   "                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\n",
   "            elif issubclass(origin, tuple) and args:\n",
   "                if args[-1] is _ellipsis:\n",
   "                    compound_types.append(\n",
   "                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\n",
   "                    compound_types.append(\n",
   "                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\n",
   "                plain_types.append(origin)\n",
   "        elif constraint is NoneType:  # type: ignore\n",
   "            is_nullable = True\n",
   "        elif isinstance(constraint, ForwardRef):\n",
   "            plain_types.append(constraint.__forward_arg__)\n",
   "            plain_types.append(constraint)\n",
   "    if compound_types or is_nullable:\n",
   "        if \"anyof\" in rules:\n",
   "        if plain_types:\n",
   "            compound_types.append({\"type\": tuple(plain_types)})\n",
   "        if is_nullable:\n",
   "            compound_types.append({\"nullable\": True})\n",
   "        rules[\"anyof\"] = tuple(compound_types)\n",
   "        rules[\"type\"] = tuple(plain_types)\n",
   "    for constraint in type_constraints:\n",
   "        if get_type_origin(constraint) is typing.Union:\n",
   "            yield from _flatten_Union_and_Optional(get_type_args(constraint))\n",
   "            yield constraint\n",
   "    composed_rules = [\n",
   "        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\n",
   "    if not composed_rules:\n",
   "    for composed_rule in composed_rules:\n",
   "        of_rule, rule = composed_rule.split('_', 1)\n",
   "        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\n",
   "    for rule in composed_rules:\n",
   "        rules.pop(rule)\n",
   "    if isinstance(rules.get(\"schema\"), abc.Mapping):\n",
   "        rules['schema'] = normalize_schema(rules['schema'])\n",
   "    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\n",
   "        if rule in rules:\n",
   "            rules[rule] = normalize_rulesset(rules[rule])\n",
   "    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\n",
   "        if not isinstance(rules.get(rule), Sequence):\n",
   "        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\n",
   "        for name, definition in dict(definitions).items():\n",
   "            self.add(name, definition)\n",
   "        return self._storage.get(name, default)\n",
   "        for name in names:\n",
   "            self._storage.pop(name, None)\n",
   "schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\n",
   "TypeDefinition = NamedTuple(\n",
   "        return super().__new__(mcls, name, bases, namespace)\n",
   "        def attributes_with_prefix(prefix):\n",
   "                x[len(prefix) + 2 :]\n",
   "                for x in dir(cls)\n",
   "                if x.startswith('_' + prefix + '_')\n",
   "        super().__init__(name, bases, namespace)\n",
   "        validation_rules = {\n",
   "            for attribute in attributes_with_prefix('validate')\n",
   "        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\n",
   "        x = validation_rules['check_with']['oneof']\n",
   "        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\n",
   "        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\n",
   "            validation_rules[rule]['required'] = True\n",
   "        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\n",
   "        for attribute in attributes_with_prefix('normalize'):\n",
   "            if attribute.startswith('coerce_'):\n",
   "                cls.coercers += (attribute[len('coerce_') :],)\n",
   "            elif attribute.startswith('default_setter_'):\n",
   "                cls.default_setters += (attribute[len('default_setter_') :],)\n",
   "                normalization_rules[attribute] = cls.__get_rule_schema(\n",
   "                    '_normalize_' + attribute\n",
   "        for rule in ('coerce', 'rename_handler'):\n",
   "            x = normalization_rules[rule]['oneof']\n",
   "            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\n",
   "        normalization_rules['default_setter']['oneof'][1][\n",
   "        cls.normalization_rules = normalize_schema(normalization_rules)\n",
   "        cls.validation_rules = normalize_schema(validation_rules)\n",
   "        docstring = getattr(mcls, method_name).__doc__\n",
   "        if docstring is None:\n",
   "            result = {}\n",
   "            if RULE_SCHEMA_SEPARATOR in docstring:\n",
   "                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\n",
   "                result = literal_eval(docstring.strip())\n",
   "                result = {}\n",
   "        if not result and method_name != '_validate_meta':\n",
   "        return result\n",
   "    types_mapping = {\n",
   "        'boolean': TypeDefinition('boolean', (bool,), ()),\n",
   "        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\n",
   "        'bytes': TypeDefinition('bytes', (bytes,), ()),\n",
   "        'complex': TypeDefinition('complex', (complex,), ()),\n",
   "        'date': TypeDefinition('date', (date,), (datetime,)),\n",
   "        'datetime': TypeDefinition('datetime', (datetime,), ()),\n",
   "        'dict': TypeDefinition('dict', (Mapping,), ()),\n",
   "        'float': TypeDefinition('float', (float,), ()),\n",
   "        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\n",
   "        'integer': TypeDefinition('integer', (int,), (bool,)),\n",
   "        'list': TypeDefinition('list', (list,), ()),\n",
   "        'number': TypeDefinition('number', (int, float), (bool,)),\n",
   "        'set': TypeDefinition('set', (set,), ()),\n",
   "        'string': TypeDefinition('string', (str,), ()),\n",
   "        'tuple': TypeDefinition('tuple', (tuple,), ()),\n",
   "        'type': TypeDefinition('type', (type,), ()),\n",
   "    types_mapping.update(\n",
   "        (x, TypeDefinition(x, (getattr(abc, x),), ()))\n",
   "        for x in abc.__all__  # type: ignore\n",
   "    normalization_rules = {}  # type: ClassVar[Schema]\n",
   "    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\n",
   "    validation_rules = {}  # type: ClassVar[Schema]\n",
   "        rules_set_registry: RulesSetRegistry = rules_set_registry,\n",
   "        schema_registry: SchemaRegistry = schema_registry,\n",
   "                \"rules_set_registry\": rules_set_registry,\n",
   "                \"schema_registry\": schema_registry,\n",
   "        self.schema = schema\n",
   "            error_handler, eh_config = config\n",
   "            error_handler, eh_config = config, {}\n",
   "        if isinstance(error_handler, type) and issubclass(\n",
   "            error_handler, errors.BaseErrorHandler\n",
   "            return error_handler(**eh_config)\n",
   "        if len(args) == 1:\n",
   "            self._errors.extend(args[0])\n",
   "            for error in args[0]:\n",
   "                self.document_error_tree.add(error)\n",
   "                self.schema_error_tree.add(error)\n",
   "                self.error_handler.emit(error)\n",
   "        elif len(args) == 2 and isinstance(args[1], str):\n",
   "            self._error(args[0], errors.CUSTOM, args[1])\n",
   "        elif len(args) >= 2:\n",
   "            field = args[0]\n",
   "            code = args[1].code\n",
   "            rule = args[1].rule\n",
   "            info = args[2:]\n",
   "            document_path = self.document_path + (field,)\n",
   "            schema_path = self.schema_path\n",
   "            if code != errors.UNKNOWN_FIELD.code and rule is not None:\n",
   "                schema_path += (field, rule)\n",
   "            if not rule:\n",
   "                constraint = None\n",
   "                field_definitions = self._resolve_rules_set(self.schema[field])\n",
   "                if rule == 'nullable':\n",
   "                    constraint = field_definitions.get(rule, False)\n",
   "                elif rule == 'required':\n",
   "                    constraint = field_definitions.get(rule, self.require_all)\n",
   "                    if rule not in field_definitions:\n",
   "                        schema_path = \"__require_all__\"\n",
   "                    constraint = field_definitions[rule]\n",
   "            value = self.document.get(field)\n",
   "                document_path, schema_path, code, rule, constraint, value, info\n",
   "        child_config = ChainMap(kwargs, self._config)\n",
   "            child_config = child_config.new_child(\n",
   "                    'error_handler': toy_error_handler,\n",
   "        child_validator = self.__class__(**child_config)\n",
   "            child_validator.document_path = self.document_path\n",
   "                document_crumb = (document_crumb,)\n",
   "            child_validator.document_path = self.document_path + document_crumb\n",
   "            child_validator.schema_path = self.schema_path\n",
   "                schema_crumb = (schema_crumb,)\n",
   "            child_validator.schema_path = self.schema_path + schema_crumb\n",
   "        return child_validator\n",
   "        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\n",
   "        result = getattr(self, methodname, None)\n",
   "        if result is None:\n",
   "                \"domain.\".format(rule, domain)\n",
   "        return result\n",
   "        dp_basedepth = len(self.document_path)\n",
   "        sp_basedepth = len(self.schema_path)\n",
   "        for error in _errors:\n",
   "            for i in sorted(dp_items, reverse=True):\n",
   "                error.document_path = drop_item_from_tuple(\n",
   "                    error.document_path, dp_basedepth + i\n",
   "            for i in sorted(sp_items, reverse=True):\n",
   "                error.schema_path = drop_item_from_tuple(\n",
   "                    error.schema_path, sp_basedepth + i\n",
   "            if error.child_errors:\n",
   "                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\n",
   "            path = path[1:]\n",
   "            context = self.document if path.startswith('^') else self.root_document\n",
   "            context = self.document\n",
   "        parts = path.split('.')\n",
   "        for part in parts:\n",
   "            if part not in context:\n",
   "            context = context.get(part, {})\n",
   "        return parts[-1], context\n",
   "        if isinstance(schema, Mapping):\n",
   "            return schema\n",
   "        elif isinstance(schema, str):\n",
   "            return self.schema_registry.get(schema)\n",
   "        if isinstance(value, Mapping):\n",
   "            self._config['allow_unknown'] = normalize_rulesset(value)\n",
   "        elif isinstance(value, bool):\n",
   "            self._config['allow_unknown'] = value\n",
   "        self._config['ignore_none_values'] = value\n",
   "        self._config['_is_normalized'] = value\n",
   "        self._config['purge_unknown'] = value\n",
   "        self._config['purge_readonly'] = value\n",
   "        self._config['require_all'] = value\n",
   "    @rules_set_registry.setter\n",
   "    @schema.setter\n",
   "        if schema is None:\n",
   "            self._schema = schema\n",
   "            self._schema = normalize_schema(schema)\n",
   "    @schema_registry.setter\n",
   "        if schema is not None:\n",
   "            self.schema = schema\n",
   "        if rules:\n",
   "            for rule in (x for x in rules if x in self._remaining_rules):\n",
   "                self._remaining_rules.remove(rule)\n",
   "        self.__init_processing(document, schema)\n",
   "        mapping = mapping.copy()\n",
   "        if isinstance(schema, str):\n",
   "            schema = self._resolve_schema(schema)\n",
   "        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\n",
   "        self.__normalize_rename_fields(mapping, schema)\n",
   "            self._normalize_purge_unknown(mapping, schema)\n",
   "            self.__normalize_purge_readonly(mapping, schema)\n",
   "        self.__validate_readonly_fields(mapping, schema)\n",
   "        self.__normalize_default_fields(mapping, schema)\n",
   "        self._normalize_coerce(mapping, schema)\n",
   "        self.__normalize_containers(mapping, schema)\n",
   "        return mapping\n",
   "        error = errors.COERCION_FAILED\n",
   "        for field in mapping:\n",
   "            if field in schema and 'coerce' in schema[field]:\n",
   "                mapping[field] = self.__normalize_coerce(\n",
   "                    schema[field]['coerce'],\n",
   "                    field,\n",
   "                    mapping[field],\n",
   "                    schema[field].get('nullable', False),\n",
   "                    error,\n",
   "                mapping[field] = self.__normalize_coerce(\n",
   "                    field,\n",
   "                    mapping[field],\n",
   "                    error,\n",
   "            processor = self.__get_rule_handler('normalize_coerce', processor)\n",
   "        elif isinstance(processor, Iterable):\n",
   "            result = value\n",
   "            for p in processor:\n",
   "                result = self.__normalize_coerce(p, field, result, nullable, error)\n",
   "                        self.document_path + (field,)\n",
   "            return result\n",
   "            return processor(value)\n",
   "            if not (nullable and value is None):\n",
   "                self._error(field, error, str(e))\n",
   "            return value\n",
   "        for field in mapping:\n",
   "            rules = set(schema.get(field, ()))\n",
   "            if isinstance(mapping[field], Mapping):\n",
   "                if 'keysrules' in rules:\n",
   "                        field, mapping, schema[field]['keysrules']\n",
   "                if 'valuesrules' in rules:\n",
   "                        field, mapping, schema[field]['valuesrules']\n",
   "                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\n",
   "                    self.__normalize_mapping_per_schema(field, mapping, schema)\n",
   "            elif isinstance(mapping[field], str):\n",
   "            elif isinstance(mapping[field], Sequence):\n",
   "                if 'itemsrules' in rules:\n",
   "                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\n",
   "                elif 'items' in rules:\n",
   "                    self.__normalize_sequence_per_items(field, mapping, schema)\n",
   "        schema = {k: property_rules for k in mapping[field]}\n",
   "        document = {k: k for k in mapping[field]}\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\n",
   "        result = validator.normalized(document, always_return_document=True)\n",
   "        if validator._errors:\n",
   "            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\n",
   "            self._error(validator._errors)\n",
   "        for _in, out in ((k, v) for k, v in result.items() if k != v):\n",
   "            if out in mapping[field]:\n",
   "                        path='.'.join(str(x) for x in self.document_path + (field,)),\n",
   "                        key=_in,\n",
   "                mapping[field][out] = mapping[field][_in]\n",
   "                mapping[field][out] = mapping[field][_in]\n",
   "                del mapping[field][_in]\n",
   "        schema = {k: value_rules for k in mapping[field]}\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\n",
   "        mapping[field] = validator.normalized(\n",
   "            mapping[field], always_return_document=True\n",
   "        if validator._errors:\n",
   "            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\n",
   "            self._error(validator._errors)\n",
   "        rules = schema.get(field, {})\n",
   "        if not rules and isinstance(self.allow_unknown, Mapping):\n",
   "            rules = self.allow_unknown\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field,\n",
   "            schema_crumb=(field, 'schema'),\n",
   "            schema=rules.get('schema', {}),\n",
   "            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\n",
   "            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\n",
   "            require_all=rules.get('require_all', self.require_all),\n",
   "        value_type = type(mapping[field])\n",
   "        result_value = validator.normalized(mapping[field], always_return_document=True)\n",
   "        mapping[field] = value_type(result_value)\n",
   "        if validator._errors:\n",
   "            self._error(validator._errors)\n",
   "        rules, values = schema[field]['items'], mapping[field]\n",
   "        if len(rules) != len(values):\n",
   "        schema = {k: v for k, v in enumerate(rules)}\n",
   "        document = {k: v for k, v in enumerate(values)}\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\n",
   "        value_type = type(mapping[field])\n",
   "        result = validator.normalized(document, always_return_document=True)\n",
   "        mapping[field] = value_type(result.values())\n",
   "        if validator._errors:\n",
   "            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\n",
   "            self._error(validator._errors)\n",
   "        constraint = schema[field]['itemsrules']\n",
   "        schema = {k: constraint for k in range(len(mapping[field]))}\n",
   "        document = {k: v for k, v in enumerate(mapping[field])}\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\n",
   "        value_type = type(mapping[field])\n",
   "        result = validator.normalized(document, always_return_document=True)\n",
   "        mapping[field] = value_type(result.values())\n",
   "        if validator._errors:\n",
   "            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\n",
   "            self._error(validator._errors)\n",
   "        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\n",
   "            mapping.pop(field)\n",
   "        return mapping\n",
   "        for field in [x for x in mapping if x not in schema]:\n",
   "            mapping.pop(field)\n",
   "        return mapping\n",
   "        for field in tuple(mapping):\n",
   "            if field in schema:\n",
   "                self._normalize_rename(mapping, schema, field)\n",
   "                self._normalize_rename_handler(mapping, schema, field)\n",
   "                    mapping, {field: self.allow_unknown}, field\n",
   "        return mapping\n",
   "        if 'rename' in schema[field]:\n",
   "            mapping[schema[field]['rename']] = mapping[field]\n",
   "            del mapping[field]\n",
   "        if 'rename_handler' not in schema[field]:\n",
   "        new_name = self.__normalize_coerce(\n",
   "            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\n",
   "        if new_name != field:\n",
   "            mapping[new_name] = mapping[field]\n",
   "            del mapping[field]\n",
   "        for field in (\n",
   "            x\n",
   "            for x in schema\n",
   "            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\n",
   "            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\n",
   "        empty_fields = [\n",
   "            x\n",
   "            for x in schema\n",
   "            if x not in mapping\n",
   "                mapping[x] is None  # noqa: W503\n",
   "                and not schema[x].get('nullable', False)\n",
   "        for field in (x for x in empty_fields if 'default' in schema[x]):\n",
   "            self._normalize_default(mapping, schema, field)\n",
   "        known_fields_states = set()\n",
   "        fields_with_default_setter = [\n",
   "            x for x in empty_fields if 'default_setter' in schema[x]\n",
   "        while fields_with_default_setter:\n",
   "            field = fields_with_default_setter.pop(0)\n",
   "                self._normalize_default_setter(mapping, schema, field)\n",
   "                fields_with_default_setter.append(field)\n",
   "                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\n",
   "            fields_processing_state = hash(tuple(fields_with_default_setter))\n",
   "            if fields_processing_state in known_fields_states:\n",
   "                for field in fields_with_default_setter:\n",
   "                        field,\n",
   "                known_fields_states.add(fields_processing_state)\n",
   "        mapping[field] = schema[field]['default']\n",
   "        if 'default_setter' in schema[field]:\n",
   "            setter = schema[field]['default_setter']\n",
   "            if isinstance(setter, str):\n",
   "                setter = self.__get_rule_handler('normalize_default_setter', setter)\n",
   "            mapping[field] = setter(mapping)\n",
   "        self.__init_processing(document, schema)\n",
   "        for field in self.document:  # type: ignore\n",
   "            definitions = self.schema.get(field)  # type: ignore\n",
   "            if definitions is not None:\n",
   "                self.__validate_definitions(definitions, field)\n",
   "                self.__validate_unknown_fields(field)\n",
   "    __call__ = validate\n",
   "            document=document, schema=schema, update=update, normalize=normalize\n",
   "            value = self.document[field]\n",
   "                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\n",
   "                validator = self._get_child_validator(\n",
   "                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\n",
   "                if not validator({field: value}, normalize=False):\n",
   "                    self._error(validator._errors)\n",
   "            self._error(field, errors.UNKNOWN_FIELD)\n",
   "        definitions = self._resolve_rules_set(definitions)\n",
   "        value = self.document[field]\n",
   "        rules_queue = [\n",
   "            x\n",
   "            for x in self.priority_validations\n",
   "            if x in definitions or x in self.mandatory_validations\n",
   "        rules_queue.extend(\n",
   "            x for x in self.mandatory_validations if x not in rules_queue\n",
   "        rules_queue.extend(\n",
   "            x\n",
   "            for x in definitions\n",
   "            if x not in rules_queue\n",
   "            and x not in self.normalization_rules\n",
   "            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\n",
   "        self._remaining_rules = rules_queue\n",
   "            rule = self._remaining_rules.pop(0)\n",
   "            rule_handler = self.__get_rule_handler('validate', rule)\n",
   "            rule_handler(definitions.get(rule, None), field, value)\n",
   "        if isinstance(value, Iterable) and not isinstance(value, str):\n",
   "            unallowed = tuple(x for x in value if x not in allowed_values)\n",
   "            if unallowed:\n",
   "                self._error(field, errors.UNALLOWED_VALUES, unallowed)\n",
   "            if value not in allowed_values:\n",
   "                self._error(field, errors.UNALLOWED_VALUE, value)\n",
   "            value_checker = self.__get_rule_handler('check_with', checks)\n",
   "            value_checker(field, value)\n",
   "            for v in checks:\n",
   "                self._validate_check_with(v, field, value)\n",
   "            checks(field, value, self._error)\n",
   "        if not isinstance(value, Container):\n",
   "            expected_values = set((expected_values,))\n",
   "            expected_values = set(expected_values)\n",
   "        missing_values = expected_values - set(value)\n",
   "        if missing_values:\n",
   "            self._error(field, errors.MISSING_MEMBERS, missing_values)\n",
   "            dependencies = (dependencies,)\n",
   "        if isinstance(dependencies, Sequence):\n",
   "            self.__validate_dependencies_sequence(dependencies, field)\n",
   "        elif isinstance(dependencies, Mapping):\n",
   "            self.__validate_dependencies_mapping(dependencies, field)\n",
   "                self.schema_path + (field, 'dependencies')\n",
   "        validated_dependencies_counter = 0\n",
   "        error_info = {}\n",
   "        for dependency_name, dependency_values in dependencies.items():\n",
   "            if not isinstance(dependency_values, Sequence) or isinstance(\n",
   "                dependency_values, str\n",
   "                dependency_values = [dependency_values]\n",
   "            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\n",
   "            if wanted_field_value in dependency_values:\n",
   "                validated_dependencies_counter += 1\n",
   "                error_info.update({dependency_name: wanted_field_value})\n",
   "        if validated_dependencies_counter != len(dependencies):\n",
   "            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\n",
   "        for dependency in dependencies:\n",
   "            if self._lookup_field(dependency)[0] is None:\n",
   "                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\n",
   "        if isinstance(value, Sized) and len(value) == 0:\n",
   "                self._error(field, errors.EMPTY)\n",
   "            excluded_fields = (excluded_fields,)\n",
   "        if self.schema[field].get('required', self.require_all):\n",
   "            self._unrequired_by_excludes.add(field)\n",
   "        for excluded_field in excluded_fields:\n",
   "            if excluded_field in self.schema and self.schema[field].get(\n",
   "                self._unrequired_by_excludes.add(excluded_field)\n",
   "        if any(excluded_field in self.document for excluded_field in excluded_fields):\n",
   "            exclusion_str = ', '.join(\n",
   "                \"'{0}'\".format(field) for field in excluded_fields\n",
   "            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\n",
   "        if isinstance(value, str):\n",
   "            if value in forbidden_values:\n",
   "                self._error(field, errors.FORBIDDEN_VALUE, value)\n",
   "        elif isinstance(value, Iterable):\n",
   "            forbidden = set(value) & set(forbidden_values)\n",
   "            if forbidden:\n",
   "                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\n",
   "            if value in forbidden_values:\n",
   "                self._error(field, errors.FORBIDDEN_VALUE, value)\n",
   "        if len(items) != len(values):\n",
   "            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\n",
   "            schema = {i: definition for i, definition in enumerate(items)}\n",
   "            validator = self._get_child_validator(\n",
   "                document_crumb=field,\n",
   "                schema_crumb=(field, 'items'),  # noqa: E501\n",
   "                schema=schema,\n",
   "            if not validator(\n",
   "                {i: value for i, value in enumerate(values)},\n",
   "                self._error(field, errors.ITEMS, validator._errors)\n",
   "        if not isinstance(value, Sequence):\n",
   "        schema = {i: rulesset for i in range(len(value))}\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field,\n",
   "            schema_crumb=(field, 'itemsrules'),\n",
   "            schema=schema,\n",
   "        validator(\n",
   "            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\n",
   "        if validator._errors:\n",
   "            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\n",
   "            self._error(field, errors.ITEMSRULES, validator._errors)\n",
   "        valid_counter = 0\n",
   "        _errors = errors.ErrorList()\n",
   "        for i, definition in enumerate(definitions):\n",
   "            schema = {field: definition.copy()}\n",
   "            for rule in ('allow_unknown', 'type'):\n",
   "                if rule not in definition and rule in self.schema[field]:\n",
   "                    schema[field][rule] = self.schema[field][rule]\n",
   "            if 'allow_unknown' not in definition:\n",
   "                schema[field]['allow_unknown'] = self.allow_unknown\n",
   "            validator = self._get_child_validator(\n",
   "                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\n",
   "            if validator(self.document, update=self.update, normalize=False):\n",
   "                valid_counter += 1\n",
   "                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\n",
   "                _errors.extend(validator._errors)\n",
   "        return valid_counter, _errors\n",
   "        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\n",
   "        if valids < 1:\n",
   "            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\n",
   "        valids, _errors = self.__validate_logical('allof', definitions, field, value)\n",
   "        if valids < len(definitions):\n",
   "            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\n",
   "        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\n",
   "        if valids > 0:\n",
   "            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\n",
   "        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\n",
   "        if valids != 1:\n",
   "            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\n",
   "            if value > max_value:\n",
   "                self._error(field, errors.MAX_VALUE)\n",
   "            if value < min_value:\n",
   "                self._error(field, errors.MIN_VALUE)\n",
   "        if isinstance(value, Iterable) and len(value) > max_length:\n",
   "            self._error(field, errors.MAX_LENGTH, len(value))\n",
   "        if isinstance(value, Iterable) and len(value) < min_length:\n",
   "            self._error(field, errors.MIN_LENGTH, len(value))\n",
   "        if value is None:\n",
   "                self._error(field, errors.NULLABLE)\n",
   "        if isinstance(value, Mapping):\n",
   "            validator = self._get_child_validator(\n",
   "                document_crumb=field,\n",
   "                schema_crumb=(field, 'keysrules'),\n",
   "                schema={k: schema for k in value.keys()},\n",
   "            if not validator({k: k for k in value.keys()}, normalize=False):\n",
   "                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\n",
   "                self._error(field, errors.KEYSRULES, validator._errors)\n",
   "                self._error(field, errors.READONLY_FIELD)\n",
   "            has_error = (\n",
   "                    self.document_path + (field,)\n",
   "            if self._is_normalized and has_error:\n",
   "        if not isinstance(value, str):\n",
   "            pattern += '$'\n",
   "        re_obj = re.compile(pattern)\n",
   "        if not re_obj.match(value):\n",
   "            self._error(field, errors.REGEX_MISMATCH)\n",
   "        required = set(\n",
   "            field\n",
   "            for field, definition in self.schema.items()\n",
   "            if self._resolve_rules_set(definition).get('required', self.require_all)\n",
   "        required -= self._unrequired_by_excludes\n",
   "        missing = required - set(\n",
   "            field\n",
   "            for field in document\n",
   "            if document.get(field) is not None or not self.ignore_none_values\n",
   "        for field in missing:\n",
   "            self._error(field, errors.REQUIRED_FIELD)\n",
   "            fields = set(field for field in document if document.get(field) is not None)\n",
   "            if self._unrequired_by_excludes.isdisjoint(fields):\n",
   "                for field in self._unrequired_by_excludes - fields:\n",
   "                    self._error(field, errors.REQUIRED_FIELD)\n",
   "        if not isinstance(value, Mapping):\n",
   "        schema = self._resolve_schema(schema)\n",
   "        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\n",
   "        require_all = self.schema[field].get('require_all', self.require_all)\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field,\n",
   "            schema_crumb=(field, 'schema'),\n",
   "            schema=schema,\n",
   "            allow_unknown=allow_unknown,\n",
   "            require_all=require_all,\n",
   "        if not validator(value, update=self.update, normalize=False):\n",
   "            self._error(field, errors.SCHEMA, validator._errors)\n",
   "        for _type in data_type:\n",
   "            if isinstance(_type, str):\n",
   "                type_definition = self.types_mapping[_type]\n",
   "                if isinstance(value, type_definition.included_types) and not isinstance(\n",
   "                    value, type_definition.excluded_types\n",
   "                if isinstance(value, _type):\n",
   "        self._error(field, errors.TYPE)\n",
   "        if isinstance(value, Mapping):\n",
   "            schema_crumb = (field, 'valuesrules')\n",
   "                document_crumb=field,\n",
   "                schema_crumb=schema_crumb,\n",
   "                schema={k: schema for k in value},\n",
   "            validator(value, update=self.update, normalize=False)\n",
   "            if validator._errors:\n",
   "                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\n",
   "                self._error(field, errors.VALUESRULES, validator._errors)\n"
  ]
 },
 "12": {
  "name": "_validate_allow_unknown",
  "type": "function",
  "class": "unknown",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1425",
  "column": "4",
  "context": " below this line\n    # sorted alphabetically\n\n    _validate_allow_unknown = dummy_for_rule_validation(\n        \"\"\" {'oneof': [{'type': 'boolean'},\n      ",
  "context_lines": "            rule_handler = self.__get_rule_handler('validate', rule)\n            rule_handler(definitions.get(rule, None), field, value)\n\n    # Remember to keep the validation methods below this line\n    # sorted alphabetically\n\n    _validate_allow_unknown = dummy_for_rule_validation(\n        \"\"\" {'oneof': [{'type': 'boolean'},\n                       {'type': ['dict', 'string'],\n                        'check_with': 'rulesset'}]} \"\"\"\n    )\n\n",
  "slicing": [
   "RULE_SCHEMA_SEPARATOR = \"The rule's arguments are validated against this schema:\"\n",
   "toy_error_handler = errors.ToyErrorHandler()\n",
   "_ellipsis = typing.Tuple[int, ...].__args__[-1]\n",
   "def dummy_for_rule_validation(rule_constraints: str) -> Callable:\n",
   "    f = dummy\n",
   "    f.__doc__ = rule_constraints\n",
   "    return f\n",
   "_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\n",
   "def normalize_rulesset(rules: RulesSet) -> RulesSet:\n",
   "    _hash = schema_hash(rules)\n",
   "    if _hash in _normalized_rulesset_cache:\n",
   "        return _normalized_rulesset_cache[_hash]\n",
   "    rules = dict(rules)\n",
   "    rules_with_whitespace = [x for x in rules if \" \" in x]\n",
   "    if rules_with_whitespace:\n",
   "        for rule in rules_with_whitespace:\n",
   "            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\n",
   "    if isinstance(rules.get(\"dependencies\"), str):\n",
   "        rules[\"dependencies\"] = (rules[\"dependencies\"],)\n",
   "    if \"excludes\" in rules:\n",
   "        constraint = rules[\"excludes\"]\n",
   "        if isinstance(constraint, str) or not isinstance(constraint, Container):\n",
   "            rules[\"excludes\"] = (constraint,)\n",
   "    if \"type\" in rules:\n",
   "        constraint = rules[\"type\"]\n",
   "        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\n",
   "            rules[\"type\"] = (constraint,)\n",
   "        _expand_generic_type_aliases(rules)\n",
   "    _expand_composed_of_rules(rules)\n",
   "    _normalize_contained_rulessets(rules)\n",
   "    _normalized_rulesset_cache[_hash] = rules\n",
   "    return rules\n",
   "def normalize_schema(schema: Schema) -> Schema:\n",
   "    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\n",
   "    compound_types = []\n",
   "    plain_types = []\n",
   "    is_nullable = False\n",
   "    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\n",
   "        if isinstance(constraint, _GenericAlias):\n",
   "            origin = get_type_origin(constraint)\n",
   "            args = get_type_args(constraint)\n",
   "            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\n",
   "                compound_types.append(\n",
   "                        \"type\": origin,\n",
   "                        \"keysrules\": {\"type\": args[0]},\n",
   "                        \"valuesrules\": {\"type\": args[1]},\n",
   "                issubclass(origin, (abc.MutableSequence, abc.Set))\n",
   "                and not constraint.__parameters__\n",
   "                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\n",
   "            elif issubclass(origin, tuple) and args:\n",
   "                if args[-1] is _ellipsis:\n",
   "                    compound_types.append(\n",
   "                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\n",
   "                    compound_types.append(\n",
   "                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\n",
   "                plain_types.append(origin)\n",
   "        elif constraint is NoneType:  # type: ignore\n",
   "            is_nullable = True\n",
   "        elif isinstance(constraint, ForwardRef):\n",
   "            plain_types.append(constraint.__forward_arg__)\n",
   "            plain_types.append(constraint)\n",
   "    if compound_types or is_nullable:\n",
   "        if \"anyof\" in rules:\n",
   "        if plain_types:\n",
   "            compound_types.append({\"type\": tuple(plain_types)})\n",
   "        if is_nullable:\n",
   "            compound_types.append({\"nullable\": True})\n",
   "        rules[\"anyof\"] = tuple(compound_types)\n",
   "        rules[\"type\"] = tuple(plain_types)\n",
   "    for constraint in type_constraints:\n",
   "        if get_type_origin(constraint) is typing.Union:\n",
   "            yield from _flatten_Union_and_Optional(get_type_args(constraint))\n",
   "            yield constraint\n",
   "    composed_rules = [\n",
   "        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\n",
   "    if not composed_rules:\n",
   "    for composed_rule in composed_rules:\n",
   "        of_rule, rule = composed_rule.split('_', 1)\n",
   "        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\n",
   "    for rule in composed_rules:\n",
   "        rules.pop(rule)\n",
   "    if isinstance(rules.get(\"schema\"), abc.Mapping):\n",
   "        rules['schema'] = normalize_schema(rules['schema'])\n",
   "    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\n",
   "        if rule in rules:\n",
   "            rules[rule] = normalize_rulesset(rules[rule])\n",
   "    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\n",
   "        if not isinstance(rules.get(rule), Sequence):\n",
   "        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\n",
   "        for name, definition in dict(definitions).items():\n",
   "            self.add(name, definition)\n",
   "        return self._storage.get(name, default)\n",
   "        for name in names:\n",
   "            self._storage.pop(name, None)\n",
   "schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\n",
   "TypeDefinition = NamedTuple(\n",
   "        return super().__new__(mcls, name, bases, namespace)\n",
   "        def attributes_with_prefix(prefix):\n",
   "                x[len(prefix) + 2 :]\n",
   "                for x in dir(cls)\n",
   "                if x.startswith('_' + prefix + '_')\n",
   "        super().__init__(name, bases, namespace)\n",
   "        validation_rules = {\n",
   "            for attribute in attributes_with_prefix('validate')\n",
   "        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\n",
   "        x = validation_rules['check_with']['oneof']\n",
   "        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\n",
   "        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\n",
   "            validation_rules[rule]['required'] = True\n",
   "        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\n",
   "        for attribute in attributes_with_prefix('normalize'):\n",
   "            if attribute.startswith('coerce_'):\n",
   "                cls.coercers += (attribute[len('coerce_') :],)\n",
   "            elif attribute.startswith('default_setter_'):\n",
   "                cls.default_setters += (attribute[len('default_setter_') :],)\n",
   "                normalization_rules[attribute] = cls.__get_rule_schema(\n",
   "                    '_normalize_' + attribute\n",
   "        for rule in ('coerce', 'rename_handler'):\n",
   "            x = normalization_rules[rule]['oneof']\n",
   "            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\n",
   "        normalization_rules['default_setter']['oneof'][1][\n",
   "        cls.normalization_rules = normalize_schema(normalization_rules)\n",
   "        cls.validation_rules = normalize_schema(validation_rules)\n",
   "        docstring = getattr(mcls, method_name).__doc__\n",
   "        if docstring is None:\n",
   "            result = {}\n",
   "            if RULE_SCHEMA_SEPARATOR in docstring:\n",
   "                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\n",
   "                result = literal_eval(docstring.strip())\n",
   "                result = {}\n",
   "        if not result and method_name != '_validate_meta':\n",
   "        return result\n",
   "    types_mapping = {\n",
   "        'boolean': TypeDefinition('boolean', (bool,), ()),\n",
   "        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\n",
   "        'bytes': TypeDefinition('bytes', (bytes,), ()),\n",
   "        'complex': TypeDefinition('complex', (complex,), ()),\n",
   "        'date': TypeDefinition('date', (date,), (datetime,)),\n",
   "        'datetime': TypeDefinition('datetime', (datetime,), ()),\n",
   "        'dict': TypeDefinition('dict', (Mapping,), ()),\n",
   "        'float': TypeDefinition('float', (float,), ()),\n",
   "        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\n",
   "        'integer': TypeDefinition('integer', (int,), (bool,)),\n",
   "        'list': TypeDefinition('list', (list,), ()),\n",
   "        'number': TypeDefinition('number', (int, float), (bool,)),\n",
   "        'set': TypeDefinition('set', (set,), ()),\n",
   "        'string': TypeDefinition('string', (str,), ()),\n",
   "        'tuple': TypeDefinition('tuple', (tuple,), ()),\n",
   "        'type': TypeDefinition('type', (type,), ()),\n",
   "    types_mapping.update(\n",
   "        (x, TypeDefinition(x, (getattr(abc, x),), ()))\n",
   "        for x in abc.__all__  # type: ignore\n",
   "    normalization_rules = {}  # type: ClassVar[Schema]\n",
   "    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\n",
   "    validation_rules = {}  # type: ClassVar[Schema]\n",
   "        rules_set_registry: RulesSetRegistry = rules_set_registry,\n",
   "        schema_registry: SchemaRegistry = schema_registry,\n",
   "                \"rules_set_registry\": rules_set_registry,\n",
   "                \"schema_registry\": schema_registry,\n",
   "        self.schema = schema\n",
   "            error_handler, eh_config = config\n",
   "            error_handler, eh_config = config, {}\n",
   "        if isinstance(error_handler, type) and issubclass(\n",
   "            error_handler, errors.BaseErrorHandler\n",
   "            return error_handler(**eh_config)\n",
   "        if len(args) == 1:\n",
   "            self._errors.extend(args[0])\n",
   "            for error in args[0]:\n",
   "                self.document_error_tree.add(error)\n",
   "                self.schema_error_tree.add(error)\n",
   "                self.error_handler.emit(error)\n",
   "        elif len(args) == 2 and isinstance(args[1], str):\n",
   "            self._error(args[0], errors.CUSTOM, args[1])\n",
   "        elif len(args) >= 2:\n",
   "            field = args[0]\n",
   "            code = args[1].code\n",
   "            rule = args[1].rule\n",
   "            info = args[2:]\n",
   "            document_path = self.document_path + (field,)\n",
   "            schema_path = self.schema_path\n",
   "            if code != errors.UNKNOWN_FIELD.code and rule is not None:\n",
   "                schema_path += (field, rule)\n",
   "            if not rule:\n",
   "                constraint = None\n",
   "                field_definitions = self._resolve_rules_set(self.schema[field])\n",
   "                if rule == 'nullable':\n",
   "                    constraint = field_definitions.get(rule, False)\n",
   "                elif rule == 'required':\n",
   "                    constraint = field_definitions.get(rule, self.require_all)\n",
   "                    if rule not in field_definitions:\n",
   "                        schema_path = \"__require_all__\"\n",
   "                    constraint = field_definitions[rule]\n",
   "            value = self.document.get(field)\n",
   "                document_path, schema_path, code, rule, constraint, value, info\n",
   "        child_config = ChainMap(kwargs, self._config)\n",
   "            child_config = child_config.new_child(\n",
   "                    'error_handler': toy_error_handler,\n",
   "        child_validator = self.__class__(**child_config)\n",
   "            child_validator.document_path = self.document_path\n",
   "                document_crumb = (document_crumb,)\n",
   "            child_validator.document_path = self.document_path + document_crumb\n",
   "            child_validator.schema_path = self.schema_path\n",
   "                schema_crumb = (schema_crumb,)\n",
   "            child_validator.schema_path = self.schema_path + schema_crumb\n",
   "        return child_validator\n",
   "        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\n",
   "        result = getattr(self, methodname, None)\n",
   "        if result is None:\n",
   "                \"domain.\".format(rule, domain)\n",
   "        return result\n",
   "        dp_basedepth = len(self.document_path)\n",
   "        sp_basedepth = len(self.schema_path)\n",
   "        for error in _errors:\n",
   "            for i in sorted(dp_items, reverse=True):\n",
   "                error.document_path = drop_item_from_tuple(\n",
   "                    error.document_path, dp_basedepth + i\n",
   "            for i in sorted(sp_items, reverse=True):\n",
   "                error.schema_path = drop_item_from_tuple(\n",
   "                    error.schema_path, sp_basedepth + i\n",
   "            if error.child_errors:\n",
   "                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\n",
   "            path = path[1:]\n",
   "            context = self.document if path.startswith('^') else self.root_document\n",
   "            context = self.document\n",
   "        parts = path.split('.')\n",
   "        for part in parts:\n",
   "            if part not in context:\n",
   "            context = context.get(part, {})\n",
   "        return parts[-1], context\n",
   "        if isinstance(schema, Mapping):\n",
   "            return schema\n",
   "        elif isinstance(schema, str):\n",
   "            return self.schema_registry.get(schema)\n",
   "        if isinstance(value, Mapping):\n",
   "            self._config['allow_unknown'] = normalize_rulesset(value)\n",
   "        elif isinstance(value, bool):\n",
   "            self._config['allow_unknown'] = value\n",
   "        self._config['ignore_none_values'] = value\n",
   "        self._config['_is_normalized'] = value\n",
   "        self._config['purge_unknown'] = value\n",
   "        self._config['purge_readonly'] = value\n",
   "        self._config['require_all'] = value\n",
   "    @rules_set_registry.setter\n",
   "    @schema.setter\n",
   "        if schema is None:\n",
   "            self._schema = schema\n",
   "            self._schema = normalize_schema(schema)\n",
   "    @schema_registry.setter\n",
   "        if schema is not None:\n",
   "            self.schema = schema\n",
   "        if rules:\n",
   "            for rule in (x for x in rules if x in self._remaining_rules):\n",
   "                self._remaining_rules.remove(rule)\n",
   "        self.__init_processing(document, schema)\n",
   "        mapping = mapping.copy()\n",
   "        if isinstance(schema, str):\n",
   "            schema = self._resolve_schema(schema)\n",
   "        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\n",
   "        self.__normalize_rename_fields(mapping, schema)\n",
   "            self._normalize_purge_unknown(mapping, schema)\n",
   "            self.__normalize_purge_readonly(mapping, schema)\n",
   "        self.__validate_readonly_fields(mapping, schema)\n",
   "        self.__normalize_default_fields(mapping, schema)\n",
   "        self._normalize_coerce(mapping, schema)\n",
   "        self.__normalize_containers(mapping, schema)\n",
   "        return mapping\n",
   "        error = errors.COERCION_FAILED\n",
   "        for field in mapping:\n",
   "            if field in schema and 'coerce' in schema[field]:\n",
   "                mapping[field] = self.__normalize_coerce(\n",
   "                    schema[field]['coerce'],\n",
   "                    field,\n",
   "                    mapping[field],\n",
   "                    schema[field].get('nullable', False),\n",
   "                    error,\n",
   "                mapping[field] = self.__normalize_coerce(\n",
   "                    field,\n",
   "                    mapping[field],\n",
   "                    error,\n",
   "            processor = self.__get_rule_handler('normalize_coerce', processor)\n",
   "        elif isinstance(processor, Iterable):\n",
   "            result = value\n",
   "            for p in processor:\n",
   "                result = self.__normalize_coerce(p, field, result, nullable, error)\n",
   "                        self.document_path + (field,)\n",
   "            return result\n",
   "            return processor(value)\n",
   "            if not (nullable and value is None):\n",
   "                self._error(field, error, str(e))\n",
   "            return value\n",
   "        for field in mapping:\n",
   "            rules = set(schema.get(field, ()))\n",
   "            if isinstance(mapping[field], Mapping):\n",
   "                if 'keysrules' in rules:\n",
   "                        field, mapping, schema[field]['keysrules']\n",
   "                if 'valuesrules' in rules:\n",
   "                        field, mapping, schema[field]['valuesrules']\n",
   "                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\n",
   "                    self.__normalize_mapping_per_schema(field, mapping, schema)\n",
   "            elif isinstance(mapping[field], str):\n",
   "            elif isinstance(mapping[field], Sequence):\n",
   "                if 'itemsrules' in rules:\n",
   "                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\n",
   "                elif 'items' in rules:\n",
   "                    self.__normalize_sequence_per_items(field, mapping, schema)\n",
   "        schema = {k: property_rules for k in mapping[field]}\n",
   "        document = {k: k for k in mapping[field]}\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\n",
   "        result = validator.normalized(document, always_return_document=True)\n",
   "        if validator._errors:\n",
   "            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\n",
   "            self._error(validator._errors)\n",
   "        for _in, out in ((k, v) for k, v in result.items() if k != v):\n",
   "            if out in mapping[field]:\n",
   "                        path='.'.join(str(x) for x in self.document_path + (field,)),\n",
   "                        key=_in,\n",
   "                mapping[field][out] = mapping[field][_in]\n",
   "                mapping[field][out] = mapping[field][_in]\n",
   "                del mapping[field][_in]\n",
   "        schema = {k: value_rules for k in mapping[field]}\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\n",
   "        mapping[field] = validator.normalized(\n",
   "            mapping[field], always_return_document=True\n",
   "        if validator._errors:\n",
   "            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\n",
   "            self._error(validator._errors)\n",
   "        rules = schema.get(field, {})\n",
   "        if not rules and isinstance(self.allow_unknown, Mapping):\n",
   "            rules = self.allow_unknown\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field,\n",
   "            schema_crumb=(field, 'schema'),\n",
   "            schema=rules.get('schema', {}),\n",
   "            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\n",
   "            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\n",
   "            require_all=rules.get('require_all', self.require_all),\n",
   "        value_type = type(mapping[field])\n",
   "        result_value = validator.normalized(mapping[field], always_return_document=True)\n",
   "        mapping[field] = value_type(result_value)\n",
   "        if validator._errors:\n",
   "            self._error(validator._errors)\n",
   "        rules, values = schema[field]['items'], mapping[field]\n",
   "        if len(rules) != len(values):\n",
   "        schema = {k: v for k, v in enumerate(rules)}\n",
   "        document = {k: v for k, v in enumerate(values)}\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\n",
   "        value_type = type(mapping[field])\n",
   "        result = validator.normalized(document, always_return_document=True)\n",
   "        mapping[field] = value_type(result.values())\n",
   "        if validator._errors:\n",
   "            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\n",
   "            self._error(validator._errors)\n",
   "        constraint = schema[field]['itemsrules']\n",
   "        schema = {k: constraint for k in range(len(mapping[field]))}\n",
   "        document = {k: v for k, v in enumerate(mapping[field])}\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\n",
   "        value_type = type(mapping[field])\n",
   "        result = validator.normalized(document, always_return_document=True)\n",
   "        mapping[field] = value_type(result.values())\n",
   "        if validator._errors:\n",
   "            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\n",
   "            self._error(validator._errors)\n",
   "        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\n",
   "            mapping.pop(field)\n",
   "        return mapping\n",
   "        for field in [x for x in mapping if x not in schema]:\n",
   "            mapping.pop(field)\n",
   "        return mapping\n",
   "        for field in tuple(mapping):\n",
   "            if field in schema:\n",
   "                self._normalize_rename(mapping, schema, field)\n",
   "                self._normalize_rename_handler(mapping, schema, field)\n",
   "                    mapping, {field: self.allow_unknown}, field\n",
   "        return mapping\n",
   "        if 'rename' in schema[field]:\n",
   "            mapping[schema[field]['rename']] = mapping[field]\n",
   "            del mapping[field]\n",
   "        if 'rename_handler' not in schema[field]:\n",
   "        new_name = self.__normalize_coerce(\n",
   "            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\n",
   "        if new_name != field:\n",
   "            mapping[new_name] = mapping[field]\n",
   "            del mapping[field]\n",
   "        for field in (\n",
   "            x\n",
   "            for x in schema\n",
   "            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\n",
   "            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\n",
   "        empty_fields = [\n",
   "            x\n",
   "            for x in schema\n",
   "            if x not in mapping\n",
   "                mapping[x] is None  # noqa: W503\n",
   "                and not schema[x].get('nullable', False)\n",
   "        for field in (x for x in empty_fields if 'default' in schema[x]):\n",
   "            self._normalize_default(mapping, schema, field)\n",
   "        known_fields_states = set()\n",
   "        fields_with_default_setter = [\n",
   "            x for x in empty_fields if 'default_setter' in schema[x]\n",
   "        while fields_with_default_setter:\n",
   "            field = fields_with_default_setter.pop(0)\n",
   "                self._normalize_default_setter(mapping, schema, field)\n",
   "                fields_with_default_setter.append(field)\n",
   "                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\n",
   "            fields_processing_state = hash(tuple(fields_with_default_setter))\n",
   "            if fields_processing_state in known_fields_states:\n",
   "                for field in fields_with_default_setter:\n",
   "                        field,\n",
   "                known_fields_states.add(fields_processing_state)\n",
   "        mapping[field] = schema[field]['default']\n",
   "        if 'default_setter' in schema[field]:\n",
   "            setter = schema[field]['default_setter']\n",
   "            if isinstance(setter, str):\n",
   "                setter = self.__get_rule_handler('normalize_default_setter', setter)\n",
   "            mapping[field] = setter(mapping)\n",
   "        self.__init_processing(document, schema)\n",
   "        for field in self.document:  # type: ignore\n",
   "            definitions = self.schema.get(field)  # type: ignore\n",
   "            if definitions is not None:\n",
   "                self.__validate_definitions(definitions, field)\n",
   "                self.__validate_unknown_fields(field)\n",
   "            document=document, schema=schema, update=update, normalize=normalize\n",
   "            value = self.document[field]\n",
   "                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\n",
   "                validator = self._get_child_validator(\n",
   "                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\n",
   "                if not validator({field: value}, normalize=False):\n",
   "                    self._error(validator._errors)\n",
   "            self._error(field, errors.UNKNOWN_FIELD)\n",
   "        definitions = self._resolve_rules_set(definitions)\n",
   "        value = self.document[field]\n",
   "        rules_queue = [\n",
   "            x\n",
   "            for x in self.priority_validations\n",
   "            if x in definitions or x in self.mandatory_validations\n",
   "        rules_queue.extend(\n",
   "            x for x in self.mandatory_validations if x not in rules_queue\n",
   "        rules_queue.extend(\n",
   "            x\n",
   "            for x in definitions\n",
   "            if x not in rules_queue\n",
   "            and x not in self.normalization_rules\n",
   "            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\n",
   "        self._remaining_rules = rules_queue\n",
   "            rule = self._remaining_rules.pop(0)\n",
   "            rule_handler = self.__get_rule_handler('validate', rule)\n",
   "            rule_handler(definitions.get(rule, None), field, value)\n",
   "    _validate_allow_unknown = dummy_for_rule_validation(\n",
   "        if isinstance(value, Iterable) and not isinstance(value, str):\n",
   "            unallowed = tuple(x for x in value if x not in allowed_values)\n",
   "            if unallowed:\n",
   "                self._error(field, errors.UNALLOWED_VALUES, unallowed)\n",
   "            if value not in allowed_values:\n",
   "                self._error(field, errors.UNALLOWED_VALUE, value)\n",
   "            value_checker = self.__get_rule_handler('check_with', checks)\n",
   "            value_checker(field, value)\n",
   "            for v in checks:\n",
   "                self._validate_check_with(v, field, value)\n",
   "            checks(field, value, self._error)\n",
   "        if not isinstance(value, Container):\n",
   "            expected_values = set((expected_values,))\n",
   "            expected_values = set(expected_values)\n",
   "        missing_values = expected_values - set(value)\n",
   "        if missing_values:\n",
   "            self._error(field, errors.MISSING_MEMBERS, missing_values)\n",
   "            dependencies = (dependencies,)\n",
   "        if isinstance(dependencies, Sequence):\n",
   "            self.__validate_dependencies_sequence(dependencies, field)\n",
   "        elif isinstance(dependencies, Mapping):\n",
   "            self.__validate_dependencies_mapping(dependencies, field)\n",
   "                self.schema_path + (field, 'dependencies')\n",
   "        validated_dependencies_counter = 0\n",
   "        error_info = {}\n",
   "        for dependency_name, dependency_values in dependencies.items():\n",
   "            if not isinstance(dependency_values, Sequence) or isinstance(\n",
   "                dependency_values, str\n",
   "                dependency_values = [dependency_values]\n",
   "            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\n",
   "            if wanted_field_value in dependency_values:\n",
   "                validated_dependencies_counter += 1\n",
   "                error_info.update({dependency_name: wanted_field_value})\n",
   "        if validated_dependencies_counter != len(dependencies):\n",
   "            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\n",
   "        for dependency in dependencies:\n",
   "            if self._lookup_field(dependency)[0] is None:\n",
   "                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\n",
   "        if isinstance(value, Sized) and len(value) == 0:\n",
   "                self._error(field, errors.EMPTY)\n",
   "            excluded_fields = (excluded_fields,)\n",
   "        if self.schema[field].get('required', self.require_all):\n",
   "            self._unrequired_by_excludes.add(field)\n",
   "        for excluded_field in excluded_fields:\n",
   "            if excluded_field in self.schema and self.schema[field].get(\n",
   "                self._unrequired_by_excludes.add(excluded_field)\n",
   "        if any(excluded_field in self.document for excluded_field in excluded_fields):\n",
   "            exclusion_str = ', '.join(\n",
   "                \"'{0}'\".format(field) for field in excluded_fields\n",
   "            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\n",
   "        if isinstance(value, str):\n",
   "            if value in forbidden_values:\n",
   "                self._error(field, errors.FORBIDDEN_VALUE, value)\n",
   "        elif isinstance(value, Iterable):\n",
   "            forbidden = set(value) & set(forbidden_values)\n",
   "            if forbidden:\n",
   "                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\n",
   "            if value in forbidden_values:\n",
   "                self._error(field, errors.FORBIDDEN_VALUE, value)\n",
   "        if len(items) != len(values):\n",
   "            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\n",
   "            schema = {i: definition for i, definition in enumerate(items)}\n",
   "            validator = self._get_child_validator(\n",
   "                document_crumb=field,\n",
   "                schema_crumb=(field, 'items'),  # noqa: E501\n",
   "                schema=schema,\n",
   "            if not validator(\n",
   "                {i: value for i, value in enumerate(values)},\n",
   "                self._error(field, errors.ITEMS, validator._errors)\n",
   "        if not isinstance(value, Sequence):\n",
   "        schema = {i: rulesset for i in range(len(value))}\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field,\n",
   "            schema_crumb=(field, 'itemsrules'),\n",
   "            schema=schema,\n",
   "        validator(\n",
   "            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\n",
   "        if validator._errors:\n",
   "            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\n",
   "            self._error(field, errors.ITEMSRULES, validator._errors)\n",
   "        valid_counter = 0\n",
   "        _errors = errors.ErrorList()\n",
   "        for i, definition in enumerate(definitions):\n",
   "            schema = {field: definition.copy()}\n",
   "            for rule in ('allow_unknown', 'type'):\n",
   "                if rule not in definition and rule in self.schema[field]:\n",
   "                    schema[field][rule] = self.schema[field][rule]\n",
   "            if 'allow_unknown' not in definition:\n",
   "                schema[field]['allow_unknown'] = self.allow_unknown\n",
   "            validator = self._get_child_validator(\n",
   "                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\n",
   "            if validator(self.document, update=self.update, normalize=False):\n",
   "                valid_counter += 1\n",
   "                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\n",
   "                _errors.extend(validator._errors)\n",
   "        return valid_counter, _errors\n",
   "        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\n",
   "        if valids < 1:\n",
   "            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\n",
   "        valids, _errors = self.__validate_logical('allof', definitions, field, value)\n",
   "        if valids < len(definitions):\n",
   "            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\n",
   "        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\n",
   "        if valids > 0:\n",
   "            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\n",
   "        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\n",
   "        if valids != 1:\n",
   "            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\n",
   "            if value > max_value:\n",
   "                self._error(field, errors.MAX_VALUE)\n",
   "            if value < min_value:\n",
   "                self._error(field, errors.MIN_VALUE)\n",
   "        if isinstance(value, Iterable) and len(value) > max_length:\n",
   "            self._error(field, errors.MAX_LENGTH, len(value))\n",
   "        if isinstance(value, Iterable) and len(value) < min_length:\n",
   "            self._error(field, errors.MIN_LENGTH, len(value))\n",
   "        if value is None:\n",
   "                self._error(field, errors.NULLABLE)\n",
   "        if isinstance(value, Mapping):\n",
   "            validator = self._get_child_validator(\n",
   "                document_crumb=field,\n",
   "                schema_crumb=(field, 'keysrules'),\n",
   "                schema={k: schema for k in value.keys()},\n",
   "            if not validator({k: k for k in value.keys()}, normalize=False):\n",
   "                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\n",
   "                self._error(field, errors.KEYSRULES, validator._errors)\n",
   "                self._error(field, errors.READONLY_FIELD)\n",
   "            has_error = (\n",
   "                    self.document_path + (field,)\n",
   "            if self._is_normalized and has_error:\n",
   "        if not isinstance(value, str):\n",
   "            pattern += '$'\n",
   "        re_obj = re.compile(pattern)\n",
   "        if not re_obj.match(value):\n",
   "            self._error(field, errors.REGEX_MISMATCH)\n",
   "        required = set(\n",
   "            field\n",
   "            for field, definition in self.schema.items()\n",
   "            if self._resolve_rules_set(definition).get('required', self.require_all)\n",
   "        required -= self._unrequired_by_excludes\n",
   "        missing = required - set(\n",
   "            field\n",
   "            for field in document\n",
   "            if document.get(field) is not None or not self.ignore_none_values\n",
   "        for field in missing:\n",
   "            self._error(field, errors.REQUIRED_FIELD)\n",
   "            fields = set(field for field in document if document.get(field) is not None)\n",
   "            if self._unrequired_by_excludes.isdisjoint(fields):\n",
   "                for field in self._unrequired_by_excludes - fields:\n",
   "                    self._error(field, errors.REQUIRED_FIELD)\n",
   "        if not isinstance(value, Mapping):\n",
   "        schema = self._resolve_schema(schema)\n",
   "        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\n",
   "        require_all = self.schema[field].get('require_all', self.require_all)\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field,\n",
   "            schema_crumb=(field, 'schema'),\n",
   "            schema=schema,\n",
   "            allow_unknown=allow_unknown,\n",
   "            require_all=require_all,\n",
   "        if not validator(value, update=self.update, normalize=False):\n",
   "            self._error(field, errors.SCHEMA, validator._errors)\n",
   "        for _type in data_type:\n",
   "            if isinstance(_type, str):\n",
   "                type_definition = self.types_mapping[_type]\n",
   "                if isinstance(value, type_definition.included_types) and not isinstance(\n",
   "                    value, type_definition.excluded_types\n",
   "                if isinstance(value, _type):\n",
   "        self._error(field, errors.TYPE)\n",
   "        if isinstance(value, Mapping):\n",
   "            schema_crumb = (field, 'valuesrules')\n",
   "                document_crumb=field,\n",
   "                schema_crumb=schema_crumb,\n",
   "                schema={k: schema for k in value},\n",
   "            validator(value, update=self.update, normalize=False)\n",
   "            if validator._errors:\n",
   "                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\n",
   "                self._error(field, errors.VALUESRULES, validator._errors)\n"
  ]
 },
 "13": {
  "name": "_validate_meta",
  "type": "function",
  "class": "unknown",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1683",
  "column": "4",
  "context": "_error(field, errors.MAX_LENGTH, len(value))\n\n    _validate_meta = dummy_for_rule_validation('')\n\n    def _validate_minlength(self, min_length, fie",
  "context_lines": "    def _validate_maxlength(self, max_length, field, value):\n        \"\"\" {'type': 'integer'} \"\"\"\n        if isinstance(value, Iterable) and len(value) > max_length:\n            self._error(field, errors.MAX_LENGTH, len(value))\n\n    _validate_meta = dummy_for_rule_validation('')\n\n    def _validate_minlength(self, min_length, field, value):\n        \"\"\" {'type': 'integer'} \"\"\"\n        if isinstance(value, Iterable) and len(value) < min_length:\n",
  "slicing": [
   "RULE_SCHEMA_SEPARATOR = \"The rule's arguments are validated against this schema:\"\n",
   "toy_error_handler = errors.ToyErrorHandler()\n",
   "_ellipsis = typing.Tuple[int, ...].__args__[-1]\n",
   "def dummy_for_rule_validation(rule_constraints: str) -> Callable:\n",
   "    f = dummy\n",
   "    f.__doc__ = rule_constraints\n",
   "    return f\n",
   "_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\n",
   "def normalize_rulesset(rules: RulesSet) -> RulesSet:\n",
   "    _hash = schema_hash(rules)\n",
   "    if _hash in _normalized_rulesset_cache:\n",
   "        return _normalized_rulesset_cache[_hash]\n",
   "    rules = dict(rules)\n",
   "    rules_with_whitespace = [x for x in rules if \" \" in x]\n",
   "    if rules_with_whitespace:\n",
   "        for rule in rules_with_whitespace:\n",
   "            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\n",
   "    if isinstance(rules.get(\"dependencies\"), str):\n",
   "        rules[\"dependencies\"] = (rules[\"dependencies\"],)\n",
   "    if \"excludes\" in rules:\n",
   "        constraint = rules[\"excludes\"]\n",
   "        if isinstance(constraint, str) or not isinstance(constraint, Container):\n",
   "            rules[\"excludes\"] = (constraint,)\n",
   "    if \"type\" in rules:\n",
   "        constraint = rules[\"type\"]\n",
   "        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\n",
   "            rules[\"type\"] = (constraint,)\n",
   "        _expand_generic_type_aliases(rules)\n",
   "    _expand_composed_of_rules(rules)\n",
   "    _normalize_contained_rulessets(rules)\n",
   "    _normalized_rulesset_cache[_hash] = rules\n",
   "    return rules\n",
   "def normalize_schema(schema: Schema) -> Schema:\n",
   "    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\n",
   "    compound_types = []\n",
   "    plain_types = []\n",
   "    is_nullable = False\n",
   "    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\n",
   "        if isinstance(constraint, _GenericAlias):\n",
   "            origin = get_type_origin(constraint)\n",
   "            args = get_type_args(constraint)\n",
   "            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\n",
   "                compound_types.append(\n",
   "                        \"type\": origin,\n",
   "                        \"keysrules\": {\"type\": args[0]},\n",
   "                        \"valuesrules\": {\"type\": args[1]},\n",
   "                issubclass(origin, (abc.MutableSequence, abc.Set))\n",
   "                and not constraint.__parameters__\n",
   "                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\n",
   "            elif issubclass(origin, tuple) and args:\n",
   "                if args[-1] is _ellipsis:\n",
   "                    compound_types.append(\n",
   "                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\n",
   "                    compound_types.append(\n",
   "                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\n",
   "                plain_types.append(origin)\n",
   "        elif constraint is NoneType:  # type: ignore\n",
   "            is_nullable = True\n",
   "        elif isinstance(constraint, ForwardRef):\n",
   "            plain_types.append(constraint.__forward_arg__)\n",
   "            plain_types.append(constraint)\n",
   "    if compound_types or is_nullable:\n",
   "        if \"anyof\" in rules:\n",
   "        if plain_types:\n",
   "            compound_types.append({\"type\": tuple(plain_types)})\n",
   "        if is_nullable:\n",
   "            compound_types.append({\"nullable\": True})\n",
   "        rules[\"anyof\"] = tuple(compound_types)\n",
   "        rules[\"type\"] = tuple(plain_types)\n",
   "    for constraint in type_constraints:\n",
   "        if get_type_origin(constraint) is typing.Union:\n",
   "            yield from _flatten_Union_and_Optional(get_type_args(constraint))\n",
   "            yield constraint\n",
   "    composed_rules = [\n",
   "        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\n",
   "    if not composed_rules:\n",
   "    for composed_rule in composed_rules:\n",
   "        of_rule, rule = composed_rule.split('_', 1)\n",
   "        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\n",
   "    for rule in composed_rules:\n",
   "        rules.pop(rule)\n",
   "    if isinstance(rules.get(\"schema\"), abc.Mapping):\n",
   "        rules['schema'] = normalize_schema(rules['schema'])\n",
   "    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\n",
   "        if rule in rules:\n",
   "            rules[rule] = normalize_rulesset(rules[rule])\n",
   "    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\n",
   "        if not isinstance(rules.get(rule), Sequence):\n",
   "        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\n",
   "        for name, definition in dict(definitions).items():\n",
   "            self.add(name, definition)\n",
   "        return self._storage.get(name, default)\n",
   "        for name in names:\n",
   "            self._storage.pop(name, None)\n",
   "schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\n",
   "TypeDefinition = NamedTuple(\n",
   "        return super().__new__(mcls, name, bases, namespace)\n",
   "        def attributes_with_prefix(prefix):\n",
   "                x[len(prefix) + 2 :]\n",
   "                for x in dir(cls)\n",
   "                if x.startswith('_' + prefix + '_')\n",
   "        super().__init__(name, bases, namespace)\n",
   "        validation_rules = {\n",
   "            for attribute in attributes_with_prefix('validate')\n",
   "        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\n",
   "        x = validation_rules['check_with']['oneof']\n",
   "        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\n",
   "        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\n",
   "            validation_rules[rule]['required'] = True\n",
   "        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\n",
   "        for attribute in attributes_with_prefix('normalize'):\n",
   "            if attribute.startswith('coerce_'):\n",
   "                cls.coercers += (attribute[len('coerce_') :],)\n",
   "            elif attribute.startswith('default_setter_'):\n",
   "                cls.default_setters += (attribute[len('default_setter_') :],)\n",
   "                normalization_rules[attribute] = cls.__get_rule_schema(\n",
   "                    '_normalize_' + attribute\n",
   "        for rule in ('coerce', 'rename_handler'):\n",
   "            x = normalization_rules[rule]['oneof']\n",
   "            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\n",
   "        normalization_rules['default_setter']['oneof'][1][\n",
   "        cls.normalization_rules = normalize_schema(normalization_rules)\n",
   "        cls.validation_rules = normalize_schema(validation_rules)\n",
   "        docstring = getattr(mcls, method_name).__doc__\n",
   "        if docstring is None:\n",
   "            result = {}\n",
   "            if RULE_SCHEMA_SEPARATOR in docstring:\n",
   "                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\n",
   "                result = literal_eval(docstring.strip())\n",
   "                result = {}\n",
   "        if not result and method_name != '_validate_meta':\n",
   "        return result\n",
   "    types_mapping = {\n",
   "        'boolean': TypeDefinition('boolean', (bool,), ()),\n",
   "        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\n",
   "        'bytes': TypeDefinition('bytes', (bytes,), ()),\n",
   "        'complex': TypeDefinition('complex', (complex,), ()),\n",
   "        'date': TypeDefinition('date', (date,), (datetime,)),\n",
   "        'datetime': TypeDefinition('datetime', (datetime,), ()),\n",
   "        'dict': TypeDefinition('dict', (Mapping,), ()),\n",
   "        'float': TypeDefinition('float', (float,), ()),\n",
   "        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\n",
   "        'integer': TypeDefinition('integer', (int,), (bool,)),\n",
   "        'list': TypeDefinition('list', (list,), ()),\n",
   "        'number': TypeDefinition('number', (int, float), (bool,)),\n",
   "        'set': TypeDefinition('set', (set,), ()),\n",
   "        'string': TypeDefinition('string', (str,), ()),\n",
   "        'tuple': TypeDefinition('tuple', (tuple,), ()),\n",
   "        'type': TypeDefinition('type', (type,), ()),\n",
   "    types_mapping.update(\n",
   "        (x, TypeDefinition(x, (getattr(abc, x),), ()))\n",
   "        for x in abc.__all__  # type: ignore\n",
   "    normalization_rules = {}  # type: ClassVar[Schema]\n",
   "    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\n",
   "    validation_rules = {}  # type: ClassVar[Schema]\n",
   "        rules_set_registry: RulesSetRegistry = rules_set_registry,\n",
   "        schema_registry: SchemaRegistry = schema_registry,\n",
   "                \"rules_set_registry\": rules_set_registry,\n",
   "                \"schema_registry\": schema_registry,\n",
   "        self.schema = schema\n",
   "            error_handler, eh_config = config\n",
   "            error_handler, eh_config = config, {}\n",
   "        if isinstance(error_handler, type) and issubclass(\n",
   "            error_handler, errors.BaseErrorHandler\n",
   "            return error_handler(**eh_config)\n",
   "        if len(args) == 1:\n",
   "            self._errors.extend(args[0])\n",
   "            for error in args[0]:\n",
   "                self.document_error_tree.add(error)\n",
   "                self.schema_error_tree.add(error)\n",
   "                self.error_handler.emit(error)\n",
   "        elif len(args) == 2 and isinstance(args[1], str):\n",
   "            self._error(args[0], errors.CUSTOM, args[1])\n",
   "        elif len(args) >= 2:\n",
   "            field = args[0]\n",
   "            code = args[1].code\n",
   "            rule = args[1].rule\n",
   "            info = args[2:]\n",
   "            document_path = self.document_path + (field,)\n",
   "            schema_path = self.schema_path\n",
   "            if code != errors.UNKNOWN_FIELD.code and rule is not None:\n",
   "                schema_path += (field, rule)\n",
   "            if not rule:\n",
   "                constraint = None\n",
   "                field_definitions = self._resolve_rules_set(self.schema[field])\n",
   "                if rule == 'nullable':\n",
   "                    constraint = field_definitions.get(rule, False)\n",
   "                elif rule == 'required':\n",
   "                    constraint = field_definitions.get(rule, self.require_all)\n",
   "                    if rule not in field_definitions:\n",
   "                        schema_path = \"__require_all__\"\n",
   "                    constraint = field_definitions[rule]\n",
   "            value = self.document.get(field)\n",
   "                document_path, schema_path, code, rule, constraint, value, info\n",
   "        child_config = ChainMap(kwargs, self._config)\n",
   "            child_config = child_config.new_child(\n",
   "                    'error_handler': toy_error_handler,\n",
   "        child_validator = self.__class__(**child_config)\n",
   "            child_validator.document_path = self.document_path\n",
   "                document_crumb = (document_crumb,)\n",
   "            child_validator.document_path = self.document_path + document_crumb\n",
   "            child_validator.schema_path = self.schema_path\n",
   "                schema_crumb = (schema_crumb,)\n",
   "            child_validator.schema_path = self.schema_path + schema_crumb\n",
   "        return child_validator\n",
   "        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\n",
   "        result = getattr(self, methodname, None)\n",
   "        if result is None:\n",
   "                \"domain.\".format(rule, domain)\n",
   "        return result\n",
   "        dp_basedepth = len(self.document_path)\n",
   "        sp_basedepth = len(self.schema_path)\n",
   "        for error in _errors:\n",
   "            for i in sorted(dp_items, reverse=True):\n",
   "                error.document_path = drop_item_from_tuple(\n",
   "                    error.document_path, dp_basedepth + i\n",
   "            for i in sorted(sp_items, reverse=True):\n",
   "                error.schema_path = drop_item_from_tuple(\n",
   "                    error.schema_path, sp_basedepth + i\n",
   "            if error.child_errors:\n",
   "                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\n",
   "            path = path[1:]\n",
   "            context = self.document if path.startswith('^') else self.root_document\n",
   "            context = self.document\n",
   "        parts = path.split('.')\n",
   "        for part in parts:\n",
   "            if part not in context:\n",
   "            context = context.get(part, {})\n",
   "        return parts[-1], context\n",
   "        if isinstance(schema, Mapping):\n",
   "            return schema\n",
   "        elif isinstance(schema, str):\n",
   "            return self.schema_registry.get(schema)\n",
   "        if isinstance(value, Mapping):\n",
   "            self._config['allow_unknown'] = normalize_rulesset(value)\n",
   "        elif isinstance(value, bool):\n",
   "            self._config['allow_unknown'] = value\n",
   "        self._config['ignore_none_values'] = value\n",
   "        self._config['_is_normalized'] = value\n",
   "        self._config['purge_unknown'] = value\n",
   "        self._config['purge_readonly'] = value\n",
   "        self._config['require_all'] = value\n",
   "    @rules_set_registry.setter\n",
   "    @schema.setter\n",
   "        if schema is None:\n",
   "            self._schema = schema\n",
   "            self._schema = normalize_schema(schema)\n",
   "    @schema_registry.setter\n",
   "        if schema is not None:\n",
   "            self.schema = schema\n",
   "        if rules:\n",
   "            for rule in (x for x in rules if x in self._remaining_rules):\n",
   "                self._remaining_rules.remove(rule)\n",
   "        self.__init_processing(document, schema)\n",
   "        mapping = mapping.copy()\n",
   "        if isinstance(schema, str):\n",
   "            schema = self._resolve_schema(schema)\n",
   "        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\n",
   "        self.__normalize_rename_fields(mapping, schema)\n",
   "            self._normalize_purge_unknown(mapping, schema)\n",
   "            self.__normalize_purge_readonly(mapping, schema)\n",
   "        self.__validate_readonly_fields(mapping, schema)\n",
   "        self.__normalize_default_fields(mapping, schema)\n",
   "        self._normalize_coerce(mapping, schema)\n",
   "        self.__normalize_containers(mapping, schema)\n",
   "        return mapping\n",
   "        error = errors.COERCION_FAILED\n",
   "        for field in mapping:\n",
   "            if field in schema and 'coerce' in schema[field]:\n",
   "                mapping[field] = self.__normalize_coerce(\n",
   "                    schema[field]['coerce'],\n",
   "                    field,\n",
   "                    mapping[field],\n",
   "                    schema[field].get('nullable', False),\n",
   "                    error,\n",
   "                mapping[field] = self.__normalize_coerce(\n",
   "                    field,\n",
   "                    mapping[field],\n",
   "                    error,\n",
   "            processor = self.__get_rule_handler('normalize_coerce', processor)\n",
   "        elif isinstance(processor, Iterable):\n",
   "            result = value\n",
   "            for p in processor:\n",
   "                result = self.__normalize_coerce(p, field, result, nullable, error)\n",
   "                        self.document_path + (field,)\n",
   "            return result\n",
   "            return processor(value)\n",
   "            if not (nullable and value is None):\n",
   "                self._error(field, error, str(e))\n",
   "            return value\n",
   "        for field in mapping:\n",
   "            rules = set(schema.get(field, ()))\n",
   "            if isinstance(mapping[field], Mapping):\n",
   "                if 'keysrules' in rules:\n",
   "                        field, mapping, schema[field]['keysrules']\n",
   "                if 'valuesrules' in rules:\n",
   "                        field, mapping, schema[field]['valuesrules']\n",
   "                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\n",
   "                    self.__normalize_mapping_per_schema(field, mapping, schema)\n",
   "            elif isinstance(mapping[field], str):\n",
   "            elif isinstance(mapping[field], Sequence):\n",
   "                if 'itemsrules' in rules:\n",
   "                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\n",
   "                elif 'items' in rules:\n",
   "                    self.__normalize_sequence_per_items(field, mapping, schema)\n",
   "        schema = {k: property_rules for k in mapping[field]}\n",
   "        document = {k: k for k in mapping[field]}\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\n",
   "        result = validator.normalized(document, always_return_document=True)\n",
   "        if validator._errors:\n",
   "            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\n",
   "            self._error(validator._errors)\n",
   "        for _in, out in ((k, v) for k, v in result.items() if k != v):\n",
   "            if out in mapping[field]:\n",
   "                        path='.'.join(str(x) for x in self.document_path + (field,)),\n",
   "                        key=_in,\n",
   "                mapping[field][out] = mapping[field][_in]\n",
   "                mapping[field][out] = mapping[field][_in]\n",
   "                del mapping[field][_in]\n",
   "        schema = {k: value_rules for k in mapping[field]}\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\n",
   "        mapping[field] = validator.normalized(\n",
   "            mapping[field], always_return_document=True\n",
   "        if validator._errors:\n",
   "            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\n",
   "            self._error(validator._errors)\n",
   "        rules = schema.get(field, {})\n",
   "        if not rules and isinstance(self.allow_unknown, Mapping):\n",
   "            rules = self.allow_unknown\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field,\n",
   "            schema_crumb=(field, 'schema'),\n",
   "            schema=rules.get('schema', {}),\n",
   "            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\n",
   "            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\n",
   "            require_all=rules.get('require_all', self.require_all),\n",
   "        value_type = type(mapping[field])\n",
   "        result_value = validator.normalized(mapping[field], always_return_document=True)\n",
   "        mapping[field] = value_type(result_value)\n",
   "        if validator._errors:\n",
   "            self._error(validator._errors)\n",
   "        rules, values = schema[field]['items'], mapping[field]\n",
   "        if len(rules) != len(values):\n",
   "        schema = {k: v for k, v in enumerate(rules)}\n",
   "        document = {k: v for k, v in enumerate(values)}\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\n",
   "        value_type = type(mapping[field])\n",
   "        result = validator.normalized(document, always_return_document=True)\n",
   "        mapping[field] = value_type(result.values())\n",
   "        if validator._errors:\n",
   "            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\n",
   "            self._error(validator._errors)\n",
   "        constraint = schema[field]['itemsrules']\n",
   "        schema = {k: constraint for k in range(len(mapping[field]))}\n",
   "        document = {k: v for k, v in enumerate(mapping[field])}\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\n",
   "        value_type = type(mapping[field])\n",
   "        result = validator.normalized(document, always_return_document=True)\n",
   "        mapping[field] = value_type(result.values())\n",
   "        if validator._errors:\n",
   "            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\n",
   "            self._error(validator._errors)\n",
   "        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\n",
   "            mapping.pop(field)\n",
   "        return mapping\n",
   "        for field in [x for x in mapping if x not in schema]:\n",
   "            mapping.pop(field)\n",
   "        return mapping\n",
   "        for field in tuple(mapping):\n",
   "            if field in schema:\n",
   "                self._normalize_rename(mapping, schema, field)\n",
   "                self._normalize_rename_handler(mapping, schema, field)\n",
   "                    mapping, {field: self.allow_unknown}, field\n",
   "        return mapping\n",
   "        if 'rename' in schema[field]:\n",
   "            mapping[schema[field]['rename']] = mapping[field]\n",
   "            del mapping[field]\n",
   "        if 'rename_handler' not in schema[field]:\n",
   "        new_name = self.__normalize_coerce(\n",
   "            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\n",
   "        if new_name != field:\n",
   "            mapping[new_name] = mapping[field]\n",
   "            del mapping[field]\n",
   "        for field in (\n",
   "            x\n",
   "            for x in schema\n",
   "            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\n",
   "            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\n",
   "        empty_fields = [\n",
   "            x\n",
   "            for x in schema\n",
   "            if x not in mapping\n",
   "                mapping[x] is None  # noqa: W503\n",
   "                and not schema[x].get('nullable', False)\n",
   "        for field in (x for x in empty_fields if 'default' in schema[x]):\n",
   "            self._normalize_default(mapping, schema, field)\n",
   "        known_fields_states = set()\n",
   "        fields_with_default_setter = [\n",
   "            x for x in empty_fields if 'default_setter' in schema[x]\n",
   "        while fields_with_default_setter:\n",
   "            field = fields_with_default_setter.pop(0)\n",
   "                self._normalize_default_setter(mapping, schema, field)\n",
   "                fields_with_default_setter.append(field)\n",
   "                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\n",
   "            fields_processing_state = hash(tuple(fields_with_default_setter))\n",
   "            if fields_processing_state in known_fields_states:\n",
   "                for field in fields_with_default_setter:\n",
   "                        field,\n",
   "                known_fields_states.add(fields_processing_state)\n",
   "        mapping[field] = schema[field]['default']\n",
   "        if 'default_setter' in schema[field]:\n",
   "            setter = schema[field]['default_setter']\n",
   "            if isinstance(setter, str):\n",
   "                setter = self.__get_rule_handler('normalize_default_setter', setter)\n",
   "            mapping[field] = setter(mapping)\n",
   "        self.__init_processing(document, schema)\n",
   "        for field in self.document:  # type: ignore\n",
   "            definitions = self.schema.get(field)  # type: ignore\n",
   "            if definitions is not None:\n",
   "                self.__validate_definitions(definitions, field)\n",
   "                self.__validate_unknown_fields(field)\n",
   "            document=document, schema=schema, update=update, normalize=normalize\n",
   "            value = self.document[field]\n",
   "                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\n",
   "                validator = self._get_child_validator(\n",
   "                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\n",
   "                if not validator({field: value}, normalize=False):\n",
   "                    self._error(validator._errors)\n",
   "            self._error(field, errors.UNKNOWN_FIELD)\n",
   "        definitions = self._resolve_rules_set(definitions)\n",
   "        value = self.document[field]\n",
   "        rules_queue = [\n",
   "            x\n",
   "            for x in self.priority_validations\n",
   "            if x in definitions or x in self.mandatory_validations\n",
   "        rules_queue.extend(\n",
   "            x for x in self.mandatory_validations if x not in rules_queue\n",
   "        rules_queue.extend(\n",
   "            x\n",
   "            for x in definitions\n",
   "            if x not in rules_queue\n",
   "            and x not in self.normalization_rules\n",
   "            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\n",
   "        self._remaining_rules = rules_queue\n",
   "            rule = self._remaining_rules.pop(0)\n",
   "            rule_handler = self.__get_rule_handler('validate', rule)\n",
   "            rule_handler(definitions.get(rule, None), field, value)\n",
   "        if isinstance(value, Iterable) and not isinstance(value, str):\n",
   "            unallowed = tuple(x for x in value if x not in allowed_values)\n",
   "            if unallowed:\n",
   "                self._error(field, errors.UNALLOWED_VALUES, unallowed)\n",
   "            if value not in allowed_values:\n",
   "                self._error(field, errors.UNALLOWED_VALUE, value)\n",
   "            value_checker = self.__get_rule_handler('check_with', checks)\n",
   "            value_checker(field, value)\n",
   "            for v in checks:\n",
   "                self._validate_check_with(v, field, value)\n",
   "            checks(field, value, self._error)\n",
   "        if not isinstance(value, Container):\n",
   "            expected_values = set((expected_values,))\n",
   "            expected_values = set(expected_values)\n",
   "        missing_values = expected_values - set(value)\n",
   "        if missing_values:\n",
   "            self._error(field, errors.MISSING_MEMBERS, missing_values)\n",
   "            dependencies = (dependencies,)\n",
   "        if isinstance(dependencies, Sequence):\n",
   "            self.__validate_dependencies_sequence(dependencies, field)\n",
   "        elif isinstance(dependencies, Mapping):\n",
   "            self.__validate_dependencies_mapping(dependencies, field)\n",
   "                self.schema_path + (field, 'dependencies')\n",
   "        validated_dependencies_counter = 0\n",
   "        error_info = {}\n",
   "        for dependency_name, dependency_values in dependencies.items():\n",
   "            if not isinstance(dependency_values, Sequence) or isinstance(\n",
   "                dependency_values, str\n",
   "                dependency_values = [dependency_values]\n",
   "            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\n",
   "            if wanted_field_value in dependency_values:\n",
   "                validated_dependencies_counter += 1\n",
   "                error_info.update({dependency_name: wanted_field_value})\n",
   "        if validated_dependencies_counter != len(dependencies):\n",
   "            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\n",
   "        for dependency in dependencies:\n",
   "            if self._lookup_field(dependency)[0] is None:\n",
   "                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\n",
   "        if isinstance(value, Sized) and len(value) == 0:\n",
   "                self._error(field, errors.EMPTY)\n",
   "            excluded_fields = (excluded_fields,)\n",
   "        if self.schema[field].get('required', self.require_all):\n",
   "            self._unrequired_by_excludes.add(field)\n",
   "        for excluded_field in excluded_fields:\n",
   "            if excluded_field in self.schema and self.schema[field].get(\n",
   "                self._unrequired_by_excludes.add(excluded_field)\n",
   "        if any(excluded_field in self.document for excluded_field in excluded_fields):\n",
   "            exclusion_str = ', '.join(\n",
   "                \"'{0}'\".format(field) for field in excluded_fields\n",
   "            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\n",
   "        if isinstance(value, str):\n",
   "            if value in forbidden_values:\n",
   "                self._error(field, errors.FORBIDDEN_VALUE, value)\n",
   "        elif isinstance(value, Iterable):\n",
   "            forbidden = set(value) & set(forbidden_values)\n",
   "            if forbidden:\n",
   "                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\n",
   "            if value in forbidden_values:\n",
   "                self._error(field, errors.FORBIDDEN_VALUE, value)\n",
   "        if len(items) != len(values):\n",
   "            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\n",
   "            schema = {i: definition for i, definition in enumerate(items)}\n",
   "            validator = self._get_child_validator(\n",
   "                document_crumb=field,\n",
   "                schema_crumb=(field, 'items'),  # noqa: E501\n",
   "                schema=schema,\n",
   "            if not validator(\n",
   "                {i: value for i, value in enumerate(values)},\n",
   "                self._error(field, errors.ITEMS, validator._errors)\n",
   "        if not isinstance(value, Sequence):\n",
   "        schema = {i: rulesset for i in range(len(value))}\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field,\n",
   "            schema_crumb=(field, 'itemsrules'),\n",
   "            schema=schema,\n",
   "        validator(\n",
   "            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\n",
   "        if validator._errors:\n",
   "            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\n",
   "            self._error(field, errors.ITEMSRULES, validator._errors)\n",
   "        valid_counter = 0\n",
   "        _errors = errors.ErrorList()\n",
   "        for i, definition in enumerate(definitions):\n",
   "            schema = {field: definition.copy()}\n",
   "            for rule in ('allow_unknown', 'type'):\n",
   "                if rule not in definition and rule in self.schema[field]:\n",
   "                    schema[field][rule] = self.schema[field][rule]\n",
   "            if 'allow_unknown' not in definition:\n",
   "                schema[field]['allow_unknown'] = self.allow_unknown\n",
   "            validator = self._get_child_validator(\n",
   "                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\n",
   "            if validator(self.document, update=self.update, normalize=False):\n",
   "                valid_counter += 1\n",
   "                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\n",
   "                _errors.extend(validator._errors)\n",
   "        return valid_counter, _errors\n",
   "        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\n",
   "        if valids < 1:\n",
   "            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\n",
   "        valids, _errors = self.__validate_logical('allof', definitions, field, value)\n",
   "        if valids < len(definitions):\n",
   "            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\n",
   "        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\n",
   "        if valids > 0:\n",
   "            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\n",
   "        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\n",
   "        if valids != 1:\n",
   "            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\n",
   "            if value > max_value:\n",
   "                self._error(field, errors.MAX_VALUE)\n",
   "            if value < min_value:\n",
   "                self._error(field, errors.MIN_VALUE)\n",
   "        if isinstance(value, Iterable) and len(value) > max_length:\n",
   "            self._error(field, errors.MAX_LENGTH, len(value))\n",
   "    _validate_meta = dummy_for_rule_validation('')\n",
   "        if isinstance(value, Iterable) and len(value) < min_length:\n",
   "            self._error(field, errors.MIN_LENGTH, len(value))\n",
   "        if value is None:\n",
   "                self._error(field, errors.NULLABLE)\n",
   "        if isinstance(value, Mapping):\n",
   "            validator = self._get_child_validator(\n",
   "                document_crumb=field,\n",
   "                schema_crumb=(field, 'keysrules'),\n",
   "                schema={k: schema for k in value.keys()},\n",
   "            if not validator({k: k for k in value.keys()}, normalize=False):\n",
   "                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\n",
   "                self._error(field, errors.KEYSRULES, validator._errors)\n",
   "                self._error(field, errors.READONLY_FIELD)\n",
   "            has_error = (\n",
   "                    self.document_path + (field,)\n",
   "            if self._is_normalized and has_error:\n",
   "        if not isinstance(value, str):\n",
   "            pattern += '$'\n",
   "        re_obj = re.compile(pattern)\n",
   "        if not re_obj.match(value):\n",
   "            self._error(field, errors.REGEX_MISMATCH)\n",
   "        required = set(\n",
   "            field\n",
   "            for field, definition in self.schema.items()\n",
   "            if self._resolve_rules_set(definition).get('required', self.require_all)\n",
   "        required -= self._unrequired_by_excludes\n",
   "        missing = required - set(\n",
   "            field\n",
   "            for field in document\n",
   "            if document.get(field) is not None or not self.ignore_none_values\n",
   "        for field in missing:\n",
   "            self._error(field, errors.REQUIRED_FIELD)\n",
   "            fields = set(field for field in document if document.get(field) is not None)\n",
   "            if self._unrequired_by_excludes.isdisjoint(fields):\n",
   "                for field in self._unrequired_by_excludes - fields:\n",
   "                    self._error(field, errors.REQUIRED_FIELD)\n",
   "        if not isinstance(value, Mapping):\n",
   "        schema = self._resolve_schema(schema)\n",
   "        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\n",
   "        require_all = self.schema[field].get('require_all', self.require_all)\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field,\n",
   "            schema_crumb=(field, 'schema'),\n",
   "            schema=schema,\n",
   "            allow_unknown=allow_unknown,\n",
   "            require_all=require_all,\n",
   "        if not validator(value, update=self.update, normalize=False):\n",
   "            self._error(field, errors.SCHEMA, validator._errors)\n",
   "        for _type in data_type:\n",
   "            if isinstance(_type, str):\n",
   "                type_definition = self.types_mapping[_type]\n",
   "                if isinstance(value, type_definition.included_types) and not isinstance(\n",
   "                    value, type_definition.excluded_types\n",
   "                if isinstance(value, _type):\n",
   "        self._error(field, errors.TYPE)\n",
   "        if isinstance(value, Mapping):\n",
   "            schema_crumb = (field, 'valuesrules')\n",
   "                document_crumb=field,\n",
   "                schema_crumb=schema_crumb,\n",
   "                schema={k: schema for k in value},\n",
   "            validator(value, update=self.update, normalize=False)\n",
   "            if validator._errors:\n",
   "                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\n",
   "                self._error(field, errors.VALUESRULES, validator._errors)\n"
  ]
 },
 "14": {
  "name": "_validate_required",
  "type": "function",
  "class": "unknown",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1751",
  "column": "4",
  "context": "   self._error(field, errors.REGEX_MISMATCH)\n\n    _validate_required = dummy_for_rule_validation(\"\"\" {'type': 'boolean'} \"\"\")\n\n    _validate_require_all = dummy_for_rule_valida",
  "context_lines": "            pattern += '$'\n        re_obj = re.compile(pattern)\n        if not re_obj.match(value):\n            self._error(field, errors.REGEX_MISMATCH)\n\n    _validate_required = dummy_for_rule_validation(\"\"\" {'type': 'boolean'} \"\"\")\n\n    _validate_require_all = dummy_for_rule_validation(\"\"\" {'type': 'boolean'} \"\"\")\n\n    def __validate_required_fields(self, document):\n        \"\"\" Validates that required fields are not missing.\n\n",
  "slicing": [
   "RULE_SCHEMA_SEPARATOR = \"The rule's arguments are validated against this schema:\"\n",
   "toy_error_handler = errors.ToyErrorHandler()\n",
   "_ellipsis = typing.Tuple[int, ...].__args__[-1]\n",
   "def dummy_for_rule_validation(rule_constraints: str) -> Callable:\n",
   "    f = dummy\n",
   "    f.__doc__ = rule_constraints\n",
   "    return f\n",
   "_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\n",
   "def normalize_rulesset(rules: RulesSet) -> RulesSet:\n",
   "    _hash = schema_hash(rules)\n",
   "    if _hash in _normalized_rulesset_cache:\n",
   "        return _normalized_rulesset_cache[_hash]\n",
   "    rules = dict(rules)\n",
   "    rules_with_whitespace = [x for x in rules if \" \" in x]\n",
   "    if rules_with_whitespace:\n",
   "        for rule in rules_with_whitespace:\n",
   "            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\n",
   "    if isinstance(rules.get(\"dependencies\"), str):\n",
   "        rules[\"dependencies\"] = (rules[\"dependencies\"],)\n",
   "    if \"excludes\" in rules:\n",
   "        constraint = rules[\"excludes\"]\n",
   "        if isinstance(constraint, str) or not isinstance(constraint, Container):\n",
   "            rules[\"excludes\"] = (constraint,)\n",
   "    if \"type\" in rules:\n",
   "        constraint = rules[\"type\"]\n",
   "        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\n",
   "            rules[\"type\"] = (constraint,)\n",
   "        _expand_generic_type_aliases(rules)\n",
   "    _expand_composed_of_rules(rules)\n",
   "    _normalize_contained_rulessets(rules)\n",
   "    _normalized_rulesset_cache[_hash] = rules\n",
   "    return rules\n",
   "def normalize_schema(schema: Schema) -> Schema:\n",
   "    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\n",
   "    compound_types = []\n",
   "    plain_types = []\n",
   "    is_nullable = False\n",
   "    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\n",
   "        if isinstance(constraint, _GenericAlias):\n",
   "            origin = get_type_origin(constraint)\n",
   "            args = get_type_args(constraint)\n",
   "            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\n",
   "                compound_types.append(\n",
   "                        \"type\": origin,\n",
   "                        \"keysrules\": {\"type\": args[0]},\n",
   "                        \"valuesrules\": {\"type\": args[1]},\n",
   "                issubclass(origin, (abc.MutableSequence, abc.Set))\n",
   "                and not constraint.__parameters__\n",
   "                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\n",
   "            elif issubclass(origin, tuple) and args:\n",
   "                if args[-1] is _ellipsis:\n",
   "                    compound_types.append(\n",
   "                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\n",
   "                    compound_types.append(\n",
   "                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\n",
   "                plain_types.append(origin)\n",
   "        elif constraint is NoneType:  # type: ignore\n",
   "            is_nullable = True\n",
   "        elif isinstance(constraint, ForwardRef):\n",
   "            plain_types.append(constraint.__forward_arg__)\n",
   "            plain_types.append(constraint)\n",
   "    if compound_types or is_nullable:\n",
   "        if \"anyof\" in rules:\n",
   "        if plain_types:\n",
   "            compound_types.append({\"type\": tuple(plain_types)})\n",
   "        if is_nullable:\n",
   "            compound_types.append({\"nullable\": True})\n",
   "        rules[\"anyof\"] = tuple(compound_types)\n",
   "        rules[\"type\"] = tuple(plain_types)\n",
   "    for constraint in type_constraints:\n",
   "        if get_type_origin(constraint) is typing.Union:\n",
   "            yield from _flatten_Union_and_Optional(get_type_args(constraint))\n",
   "            yield constraint\n",
   "    composed_rules = [\n",
   "        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\n",
   "    if not composed_rules:\n",
   "    for composed_rule in composed_rules:\n",
   "        of_rule, rule = composed_rule.split('_', 1)\n",
   "        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\n",
   "    for rule in composed_rules:\n",
   "        rules.pop(rule)\n",
   "    if isinstance(rules.get(\"schema\"), abc.Mapping):\n",
   "        rules['schema'] = normalize_schema(rules['schema'])\n",
   "    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\n",
   "        if rule in rules:\n",
   "            rules[rule] = normalize_rulesset(rules[rule])\n",
   "    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\n",
   "        if not isinstance(rules.get(rule), Sequence):\n",
   "        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\n",
   "        for name, definition in dict(definitions).items():\n",
   "            self.add(name, definition)\n",
   "        return self._storage.get(name, default)\n",
   "        for name in names:\n",
   "            self._storage.pop(name, None)\n",
   "schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\n",
   "TypeDefinition = NamedTuple(\n",
   "        return super().__new__(mcls, name, bases, namespace)\n",
   "        def attributes_with_prefix(prefix):\n",
   "                x[len(prefix) + 2 :]\n",
   "                for x in dir(cls)\n",
   "                if x.startswith('_' + prefix + '_')\n",
   "        super().__init__(name, bases, namespace)\n",
   "        validation_rules = {\n",
   "            for attribute in attributes_with_prefix('validate')\n",
   "        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\n",
   "        x = validation_rules['check_with']['oneof']\n",
   "        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\n",
   "        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\n",
   "            validation_rules[rule]['required'] = True\n",
   "        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\n",
   "        for attribute in attributes_with_prefix('normalize'):\n",
   "            if attribute.startswith('coerce_'):\n",
   "                cls.coercers += (attribute[len('coerce_') :],)\n",
   "            elif attribute.startswith('default_setter_'):\n",
   "                cls.default_setters += (attribute[len('default_setter_') :],)\n",
   "                normalization_rules[attribute] = cls.__get_rule_schema(\n",
   "                    '_normalize_' + attribute\n",
   "        for rule in ('coerce', 'rename_handler'):\n",
   "            x = normalization_rules[rule]['oneof']\n",
   "            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\n",
   "        normalization_rules['default_setter']['oneof'][1][\n",
   "        cls.normalization_rules = normalize_schema(normalization_rules)\n",
   "        cls.validation_rules = normalize_schema(validation_rules)\n",
   "        docstring = getattr(mcls, method_name).__doc__\n",
   "        if docstring is None:\n",
   "            result = {}\n",
   "            if RULE_SCHEMA_SEPARATOR in docstring:\n",
   "                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\n",
   "                result = literal_eval(docstring.strip())\n",
   "                result = {}\n",
   "        if not result and method_name != '_validate_meta':\n",
   "        return result\n",
   "    types_mapping = {\n",
   "        'boolean': TypeDefinition('boolean', (bool,), ()),\n",
   "        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\n",
   "        'bytes': TypeDefinition('bytes', (bytes,), ()),\n",
   "        'complex': TypeDefinition('complex', (complex,), ()),\n",
   "        'date': TypeDefinition('date', (date,), (datetime,)),\n",
   "        'datetime': TypeDefinition('datetime', (datetime,), ()),\n",
   "        'dict': TypeDefinition('dict', (Mapping,), ()),\n",
   "        'float': TypeDefinition('float', (float,), ()),\n",
   "        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\n",
   "        'integer': TypeDefinition('integer', (int,), (bool,)),\n",
   "        'list': TypeDefinition('list', (list,), ()),\n",
   "        'number': TypeDefinition('number', (int, float), (bool,)),\n",
   "        'set': TypeDefinition('set', (set,), ()),\n",
   "        'string': TypeDefinition('string', (str,), ()),\n",
   "        'tuple': TypeDefinition('tuple', (tuple,), ()),\n",
   "        'type': TypeDefinition('type', (type,), ()),\n",
   "    types_mapping.update(\n",
   "        (x, TypeDefinition(x, (getattr(abc, x),), ()))\n",
   "        for x in abc.__all__  # type: ignore\n",
   "    normalization_rules = {}  # type: ClassVar[Schema]\n",
   "    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\n",
   "    validation_rules = {}  # type: ClassVar[Schema]\n",
   "        rules_set_registry: RulesSetRegistry = rules_set_registry,\n",
   "        schema_registry: SchemaRegistry = schema_registry,\n",
   "                \"rules_set_registry\": rules_set_registry,\n",
   "                \"schema_registry\": schema_registry,\n",
   "        self.schema = schema\n",
   "            error_handler, eh_config = config\n",
   "            error_handler, eh_config = config, {}\n",
   "        if isinstance(error_handler, type) and issubclass(\n",
   "            error_handler, errors.BaseErrorHandler\n",
   "            return error_handler(**eh_config)\n",
   "        if len(args) == 1:\n",
   "            self._errors.extend(args[0])\n",
   "            for error in args[0]:\n",
   "                self.document_error_tree.add(error)\n",
   "                self.schema_error_tree.add(error)\n",
   "                self.error_handler.emit(error)\n",
   "        elif len(args) == 2 and isinstance(args[1], str):\n",
   "            self._error(args[0], errors.CUSTOM, args[1])\n",
   "        elif len(args) >= 2:\n",
   "            field = args[0]\n",
   "            code = args[1].code\n",
   "            rule = args[1].rule\n",
   "            info = args[2:]\n",
   "            document_path = self.document_path + (field,)\n",
   "            schema_path = self.schema_path\n",
   "            if code != errors.UNKNOWN_FIELD.code and rule is not None:\n",
   "                schema_path += (field, rule)\n",
   "            if not rule:\n",
   "                constraint = None\n",
   "                field_definitions = self._resolve_rules_set(self.schema[field])\n",
   "                if rule == 'nullable':\n",
   "                    constraint = field_definitions.get(rule, False)\n",
   "                elif rule == 'required':\n",
   "                    constraint = field_definitions.get(rule, self.require_all)\n",
   "                    if rule not in field_definitions:\n",
   "                        schema_path = \"__require_all__\"\n",
   "                    constraint = field_definitions[rule]\n",
   "            value = self.document.get(field)\n",
   "                document_path, schema_path, code, rule, constraint, value, info\n",
   "        child_config = ChainMap(kwargs, self._config)\n",
   "            child_config = child_config.new_child(\n",
   "                    'error_handler': toy_error_handler,\n",
   "        child_validator = self.__class__(**child_config)\n",
   "            child_validator.document_path = self.document_path\n",
   "                document_crumb = (document_crumb,)\n",
   "            child_validator.document_path = self.document_path + document_crumb\n",
   "            child_validator.schema_path = self.schema_path\n",
   "                schema_crumb = (schema_crumb,)\n",
   "            child_validator.schema_path = self.schema_path + schema_crumb\n",
   "        return child_validator\n",
   "        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\n",
   "        result = getattr(self, methodname, None)\n",
   "        if result is None:\n",
   "                \"domain.\".format(rule, domain)\n",
   "        return result\n",
   "        dp_basedepth = len(self.document_path)\n",
   "        sp_basedepth = len(self.schema_path)\n",
   "        for error in _errors:\n",
   "            for i in sorted(dp_items, reverse=True):\n",
   "                error.document_path = drop_item_from_tuple(\n",
   "                    error.document_path, dp_basedepth + i\n",
   "            for i in sorted(sp_items, reverse=True):\n",
   "                error.schema_path = drop_item_from_tuple(\n",
   "                    error.schema_path, sp_basedepth + i\n",
   "            if error.child_errors:\n",
   "                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\n",
   "            path = path[1:]\n",
   "            context = self.document if path.startswith('^') else self.root_document\n",
   "            context = self.document\n",
   "        parts = path.split('.')\n",
   "        for part in parts:\n",
   "            if part not in context:\n",
   "            context = context.get(part, {})\n",
   "        return parts[-1], context\n",
   "        if isinstance(schema, Mapping):\n",
   "            return schema\n",
   "        elif isinstance(schema, str):\n",
   "            return self.schema_registry.get(schema)\n",
   "        if isinstance(value, Mapping):\n",
   "            self._config['allow_unknown'] = normalize_rulesset(value)\n",
   "        elif isinstance(value, bool):\n",
   "            self._config['allow_unknown'] = value\n",
   "        self._config['ignore_none_values'] = value\n",
   "        self._config['_is_normalized'] = value\n",
   "        self._config['purge_unknown'] = value\n",
   "        self._config['purge_readonly'] = value\n",
   "        self._config['require_all'] = value\n",
   "    @rules_set_registry.setter\n",
   "    @schema.setter\n",
   "        if schema is None:\n",
   "            self._schema = schema\n",
   "            self._schema = normalize_schema(schema)\n",
   "    @schema_registry.setter\n",
   "        if schema is not None:\n",
   "            self.schema = schema\n",
   "        if rules:\n",
   "            for rule in (x for x in rules if x in self._remaining_rules):\n",
   "                self._remaining_rules.remove(rule)\n",
   "        self.__init_processing(document, schema)\n",
   "        mapping = mapping.copy()\n",
   "        if isinstance(schema, str):\n",
   "            schema = self._resolve_schema(schema)\n",
   "        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\n",
   "        self.__normalize_rename_fields(mapping, schema)\n",
   "            self._normalize_purge_unknown(mapping, schema)\n",
   "            self.__normalize_purge_readonly(mapping, schema)\n",
   "        self.__validate_readonly_fields(mapping, schema)\n",
   "        self.__normalize_default_fields(mapping, schema)\n",
   "        self._normalize_coerce(mapping, schema)\n",
   "        self.__normalize_containers(mapping, schema)\n",
   "        return mapping\n",
   "        error = errors.COERCION_FAILED\n",
   "        for field in mapping:\n",
   "            if field in schema and 'coerce' in schema[field]:\n",
   "                mapping[field] = self.__normalize_coerce(\n",
   "                    schema[field]['coerce'],\n",
   "                    field,\n",
   "                    mapping[field],\n",
   "                    schema[field].get('nullable', False),\n",
   "                    error,\n",
   "                mapping[field] = self.__normalize_coerce(\n",
   "                    field,\n",
   "                    mapping[field],\n",
   "                    error,\n",
   "            processor = self.__get_rule_handler('normalize_coerce', processor)\n",
   "        elif isinstance(processor, Iterable):\n",
   "            result = value\n",
   "            for p in processor:\n",
   "                result = self.__normalize_coerce(p, field, result, nullable, error)\n",
   "                        self.document_path + (field,)\n",
   "            return result\n",
   "            return processor(value)\n",
   "            if not (nullable and value is None):\n",
   "                self._error(field, error, str(e))\n",
   "            return value\n",
   "        for field in mapping:\n",
   "            rules = set(schema.get(field, ()))\n",
   "            if isinstance(mapping[field], Mapping):\n",
   "                if 'keysrules' in rules:\n",
   "                        field, mapping, schema[field]['keysrules']\n",
   "                if 'valuesrules' in rules:\n",
   "                        field, mapping, schema[field]['valuesrules']\n",
   "                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\n",
   "                    self.__normalize_mapping_per_schema(field, mapping, schema)\n",
   "            elif isinstance(mapping[field], str):\n",
   "            elif isinstance(mapping[field], Sequence):\n",
   "                if 'itemsrules' in rules:\n",
   "                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\n",
   "                elif 'items' in rules:\n",
   "                    self.__normalize_sequence_per_items(field, mapping, schema)\n",
   "        schema = {k: property_rules for k in mapping[field]}\n",
   "        document = {k: k for k in mapping[field]}\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\n",
   "        result = validator.normalized(document, always_return_document=True)\n",
   "        if validator._errors:\n",
   "            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\n",
   "            self._error(validator._errors)\n",
   "        for _in, out in ((k, v) for k, v in result.items() if k != v):\n",
   "            if out in mapping[field]:\n",
   "                        path='.'.join(str(x) for x in self.document_path + (field,)),\n",
   "                        key=_in,\n",
   "                mapping[field][out] = mapping[field][_in]\n",
   "                mapping[field][out] = mapping[field][_in]\n",
   "                del mapping[field][_in]\n",
   "        schema = {k: value_rules for k in mapping[field]}\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\n",
   "        mapping[field] = validator.normalized(\n",
   "            mapping[field], always_return_document=True\n",
   "        if validator._errors:\n",
   "            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\n",
   "            self._error(validator._errors)\n",
   "        rules = schema.get(field, {})\n",
   "        if not rules and isinstance(self.allow_unknown, Mapping):\n",
   "            rules = self.allow_unknown\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field,\n",
   "            schema_crumb=(field, 'schema'),\n",
   "            schema=rules.get('schema', {}),\n",
   "            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\n",
   "            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\n",
   "            require_all=rules.get('require_all', self.require_all),\n",
   "        value_type = type(mapping[field])\n",
   "        result_value = validator.normalized(mapping[field], always_return_document=True)\n",
   "        mapping[field] = value_type(result_value)\n",
   "        if validator._errors:\n",
   "            self._error(validator._errors)\n",
   "        rules, values = schema[field]['items'], mapping[field]\n",
   "        if len(rules) != len(values):\n",
   "        schema = {k: v for k, v in enumerate(rules)}\n",
   "        document = {k: v for k, v in enumerate(values)}\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\n",
   "        value_type = type(mapping[field])\n",
   "        result = validator.normalized(document, always_return_document=True)\n",
   "        mapping[field] = value_type(result.values())\n",
   "        if validator._errors:\n",
   "            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\n",
   "            self._error(validator._errors)\n",
   "        constraint = schema[field]['itemsrules']\n",
   "        schema = {k: constraint for k in range(len(mapping[field]))}\n",
   "        document = {k: v for k, v in enumerate(mapping[field])}\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\n",
   "        value_type = type(mapping[field])\n",
   "        result = validator.normalized(document, always_return_document=True)\n",
   "        mapping[field] = value_type(result.values())\n",
   "        if validator._errors:\n",
   "            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\n",
   "            self._error(validator._errors)\n",
   "        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\n",
   "            mapping.pop(field)\n",
   "        return mapping\n",
   "        for field in [x for x in mapping if x not in schema]:\n",
   "            mapping.pop(field)\n",
   "        return mapping\n",
   "        for field in tuple(mapping):\n",
   "            if field in schema:\n",
   "                self._normalize_rename(mapping, schema, field)\n",
   "                self._normalize_rename_handler(mapping, schema, field)\n",
   "                    mapping, {field: self.allow_unknown}, field\n",
   "        return mapping\n",
   "        if 'rename' in schema[field]:\n",
   "            mapping[schema[field]['rename']] = mapping[field]\n",
   "            del mapping[field]\n",
   "        if 'rename_handler' not in schema[field]:\n",
   "        new_name = self.__normalize_coerce(\n",
   "            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\n",
   "        if new_name != field:\n",
   "            mapping[new_name] = mapping[field]\n",
   "            del mapping[field]\n",
   "        for field in (\n",
   "            x\n",
   "            for x in schema\n",
   "            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\n",
   "            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\n",
   "        empty_fields = [\n",
   "            x\n",
   "            for x in schema\n",
   "            if x not in mapping\n",
   "                mapping[x] is None  # noqa: W503\n",
   "                and not schema[x].get('nullable', False)\n",
   "        for field in (x for x in empty_fields if 'default' in schema[x]):\n",
   "            self._normalize_default(mapping, schema, field)\n",
   "        known_fields_states = set()\n",
   "        fields_with_default_setter = [\n",
   "            x for x in empty_fields if 'default_setter' in schema[x]\n",
   "        while fields_with_default_setter:\n",
   "            field = fields_with_default_setter.pop(0)\n",
   "                self._normalize_default_setter(mapping, schema, field)\n",
   "                fields_with_default_setter.append(field)\n",
   "                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\n",
   "            fields_processing_state = hash(tuple(fields_with_default_setter))\n",
   "            if fields_processing_state in known_fields_states:\n",
   "                for field in fields_with_default_setter:\n",
   "                        field,\n",
   "                known_fields_states.add(fields_processing_state)\n",
   "        mapping[field] = schema[field]['default']\n",
   "        if 'default_setter' in schema[field]:\n",
   "            setter = schema[field]['default_setter']\n",
   "            if isinstance(setter, str):\n",
   "                setter = self.__get_rule_handler('normalize_default_setter', setter)\n",
   "            mapping[field] = setter(mapping)\n",
   "        self.__init_processing(document, schema)\n",
   "        for field in self.document:  # type: ignore\n",
   "            definitions = self.schema.get(field)  # type: ignore\n",
   "            if definitions is not None:\n",
   "                self.__validate_definitions(definitions, field)\n",
   "                self.__validate_unknown_fields(field)\n",
   "            document=document, schema=schema, update=update, normalize=normalize\n",
   "            value = self.document[field]\n",
   "                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\n",
   "                validator = self._get_child_validator(\n",
   "                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\n",
   "                if not validator({field: value}, normalize=False):\n",
   "                    self._error(validator._errors)\n",
   "            self._error(field, errors.UNKNOWN_FIELD)\n",
   "        definitions = self._resolve_rules_set(definitions)\n",
   "        value = self.document[field]\n",
   "        rules_queue = [\n",
   "            x\n",
   "            for x in self.priority_validations\n",
   "            if x in definitions or x in self.mandatory_validations\n",
   "        rules_queue.extend(\n",
   "            x for x in self.mandatory_validations if x not in rules_queue\n",
   "        rules_queue.extend(\n",
   "            x\n",
   "            for x in definitions\n",
   "            if x not in rules_queue\n",
   "            and x not in self.normalization_rules\n",
   "            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\n",
   "        self._remaining_rules = rules_queue\n",
   "            rule = self._remaining_rules.pop(0)\n",
   "            rule_handler = self.__get_rule_handler('validate', rule)\n",
   "            rule_handler(definitions.get(rule, None), field, value)\n",
   "        if isinstance(value, Iterable) and not isinstance(value, str):\n",
   "            unallowed = tuple(x for x in value if x not in allowed_values)\n",
   "            if unallowed:\n",
   "                self._error(field, errors.UNALLOWED_VALUES, unallowed)\n",
   "            if value not in allowed_values:\n",
   "                self._error(field, errors.UNALLOWED_VALUE, value)\n",
   "            value_checker = self.__get_rule_handler('check_with', checks)\n",
   "            value_checker(field, value)\n",
   "            for v in checks:\n",
   "                self._validate_check_with(v, field, value)\n",
   "            checks(field, value, self._error)\n",
   "        if not isinstance(value, Container):\n",
   "            expected_values = set((expected_values,))\n",
   "            expected_values = set(expected_values)\n",
   "        missing_values = expected_values - set(value)\n",
   "        if missing_values:\n",
   "            self._error(field, errors.MISSING_MEMBERS, missing_values)\n",
   "            dependencies = (dependencies,)\n",
   "        if isinstance(dependencies, Sequence):\n",
   "            self.__validate_dependencies_sequence(dependencies, field)\n",
   "        elif isinstance(dependencies, Mapping):\n",
   "            self.__validate_dependencies_mapping(dependencies, field)\n",
   "                self.schema_path + (field, 'dependencies')\n",
   "        validated_dependencies_counter = 0\n",
   "        error_info = {}\n",
   "        for dependency_name, dependency_values in dependencies.items():\n",
   "            if not isinstance(dependency_values, Sequence) or isinstance(\n",
   "                dependency_values, str\n",
   "                dependency_values = [dependency_values]\n",
   "            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\n",
   "            if wanted_field_value in dependency_values:\n",
   "                validated_dependencies_counter += 1\n",
   "                error_info.update({dependency_name: wanted_field_value})\n",
   "        if validated_dependencies_counter != len(dependencies):\n",
   "            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\n",
   "        for dependency in dependencies:\n",
   "            if self._lookup_field(dependency)[0] is None:\n",
   "                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\n",
   "        if isinstance(value, Sized) and len(value) == 0:\n",
   "                self._error(field, errors.EMPTY)\n",
   "            excluded_fields = (excluded_fields,)\n",
   "        if self.schema[field].get('required', self.require_all):\n",
   "            self._unrequired_by_excludes.add(field)\n",
   "        for excluded_field in excluded_fields:\n",
   "            if excluded_field in self.schema and self.schema[field].get(\n",
   "                self._unrequired_by_excludes.add(excluded_field)\n",
   "        if any(excluded_field in self.document for excluded_field in excluded_fields):\n",
   "            exclusion_str = ', '.join(\n",
   "                \"'{0}'\".format(field) for field in excluded_fields\n",
   "            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\n",
   "        if isinstance(value, str):\n",
   "            if value in forbidden_values:\n",
   "                self._error(field, errors.FORBIDDEN_VALUE, value)\n",
   "        elif isinstance(value, Iterable):\n",
   "            forbidden = set(value) & set(forbidden_values)\n",
   "            if forbidden:\n",
   "                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\n",
   "            if value in forbidden_values:\n",
   "                self._error(field, errors.FORBIDDEN_VALUE, value)\n",
   "        if len(items) != len(values):\n",
   "            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\n",
   "            schema = {i: definition for i, definition in enumerate(items)}\n",
   "            validator = self._get_child_validator(\n",
   "                document_crumb=field,\n",
   "                schema_crumb=(field, 'items'),  # noqa: E501\n",
   "                schema=schema,\n",
   "            if not validator(\n",
   "                {i: value for i, value in enumerate(values)},\n",
   "                self._error(field, errors.ITEMS, validator._errors)\n",
   "        if not isinstance(value, Sequence):\n",
   "        schema = {i: rulesset for i in range(len(value))}\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field,\n",
   "            schema_crumb=(field, 'itemsrules'),\n",
   "            schema=schema,\n",
   "        validator(\n",
   "            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\n",
   "        if validator._errors:\n",
   "            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\n",
   "            self._error(field, errors.ITEMSRULES, validator._errors)\n",
   "        valid_counter = 0\n",
   "        _errors = errors.ErrorList()\n",
   "        for i, definition in enumerate(definitions):\n",
   "            schema = {field: definition.copy()}\n",
   "            for rule in ('allow_unknown', 'type'):\n",
   "                if rule not in definition and rule in self.schema[field]:\n",
   "                    schema[field][rule] = self.schema[field][rule]\n",
   "            if 'allow_unknown' not in definition:\n",
   "                schema[field]['allow_unknown'] = self.allow_unknown\n",
   "            validator = self._get_child_validator(\n",
   "                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\n",
   "            if validator(self.document, update=self.update, normalize=False):\n",
   "                valid_counter += 1\n",
   "                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\n",
   "                _errors.extend(validator._errors)\n",
   "        return valid_counter, _errors\n",
   "        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\n",
   "        if valids < 1:\n",
   "            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\n",
   "        valids, _errors = self.__validate_logical('allof', definitions, field, value)\n",
   "        if valids < len(definitions):\n",
   "            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\n",
   "        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\n",
   "        if valids > 0:\n",
   "            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\n",
   "        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\n",
   "        if valids != 1:\n",
   "            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\n",
   "            if value > max_value:\n",
   "                self._error(field, errors.MAX_VALUE)\n",
   "            if value < min_value:\n",
   "                self._error(field, errors.MIN_VALUE)\n",
   "        if isinstance(value, Iterable) and len(value) > max_length:\n",
   "            self._error(field, errors.MAX_LENGTH, len(value))\n",
   "        if isinstance(value, Iterable) and len(value) < min_length:\n",
   "            self._error(field, errors.MIN_LENGTH, len(value))\n",
   "        if value is None:\n",
   "                self._error(field, errors.NULLABLE)\n",
   "        if isinstance(value, Mapping):\n",
   "            validator = self._get_child_validator(\n",
   "                document_crumb=field,\n",
   "                schema_crumb=(field, 'keysrules'),\n",
   "                schema={k: schema for k in value.keys()},\n",
   "            if not validator({k: k for k in value.keys()}, normalize=False):\n",
   "                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\n",
   "                self._error(field, errors.KEYSRULES, validator._errors)\n",
   "                self._error(field, errors.READONLY_FIELD)\n",
   "            has_error = (\n",
   "                    self.document_path + (field,)\n",
   "            if self._is_normalized and has_error:\n",
   "        if not isinstance(value, str):\n",
   "            pattern += '$'\n",
   "        re_obj = re.compile(pattern)\n",
   "        if not re_obj.match(value):\n",
   "            self._error(field, errors.REGEX_MISMATCH)\n",
   "    _validate_required = dummy_for_rule_validation(\"\"\" {'type': 'boolean'} \"\"\")\n",
   "        required = set(\n",
   "            field\n",
   "            for field, definition in self.schema.items()\n",
   "            if self._resolve_rules_set(definition).get('required', self.require_all)\n",
   "        required -= self._unrequired_by_excludes\n",
   "        missing = required - set(\n",
   "            field\n",
   "            for field in document\n",
   "            if document.get(field) is not None or not self.ignore_none_values\n",
   "        for field in missing:\n",
   "            self._error(field, errors.REQUIRED_FIELD)\n",
   "            fields = set(field for field in document if document.get(field) is not None)\n",
   "            if self._unrequired_by_excludes.isdisjoint(fields):\n",
   "                for field in self._unrequired_by_excludes - fields:\n",
   "                    self._error(field, errors.REQUIRED_FIELD)\n",
   "        if not isinstance(value, Mapping):\n",
   "        schema = self._resolve_schema(schema)\n",
   "        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\n",
   "        require_all = self.schema[field].get('require_all', self.require_all)\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field,\n",
   "            schema_crumb=(field, 'schema'),\n",
   "            schema=schema,\n",
   "            allow_unknown=allow_unknown,\n",
   "            require_all=require_all,\n",
   "        if not validator(value, update=self.update, normalize=False):\n",
   "            self._error(field, errors.SCHEMA, validator._errors)\n",
   "        for _type in data_type:\n",
   "            if isinstance(_type, str):\n",
   "                type_definition = self.types_mapping[_type]\n",
   "                if isinstance(value, type_definition.included_types) and not isinstance(\n",
   "                    value, type_definition.excluded_types\n",
   "                if isinstance(value, _type):\n",
   "        self._error(field, errors.TYPE)\n",
   "        if isinstance(value, Mapping):\n",
   "            schema_crumb = (field, 'valuesrules')\n",
   "                document_crumb=field,\n",
   "                schema_crumb=schema_crumb,\n",
   "                schema={k: schema for k in value},\n",
   "            validator(value, update=self.update, normalize=False)\n",
   "            if validator._errors:\n",
   "                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\n",
   "                self._error(field, errors.VALUESRULES, validator._errors)\n"
  ]
 },
 "15": {
  "name": "_validate_require_all",
  "type": "function",
  "class": "unknown",
  "approach": "annotation",
  "file_path": "cerberus/cerberus/base.py",
  "lineno": "1753",
  "column": "4",
  "context": "rule_validation(\"\"\" {'type': 'boolean'} \"\"\")\n\n    _validate_require_all = dummy_for_rule_validation(\"\"\" {'type': 'boolean'} \"\"\")\n\n    def __validate_required_fields(self, document",
  "context_lines": "        re_obj = re.compile(pattern)\n        if not re_obj.match(value):\n            self._error(field, errors.REGEX_MISMATCH)\n\n    _validate_required = dummy_for_rule_validation(\"\"\" {'type': 'boolean'} \"\"\")\n\n    _validate_require_all = dummy_for_rule_validation(\"\"\" {'type': 'boolean'} \"\"\")\n\n    def __validate_required_fields(self, document):\n        \"\"\" Validates that required fields are not missing.\n\n        :param document: The document being validated.\n",
  "slicing": [
   "RULE_SCHEMA_SEPARATOR = \"The rule's arguments are validated against this schema:\"\n",
   "toy_error_handler = errors.ToyErrorHandler()\n",
   "_ellipsis = typing.Tuple[int, ...].__args__[-1]\n",
   "def dummy_for_rule_validation(rule_constraints: str) -> Callable:\n",
   "    f = dummy\n",
   "    f.__doc__ = rule_constraints\n",
   "    return f\n",
   "_normalized_rulesset_cache = {}  # type: Dict[int, Dict[str, Any]]\n",
   "def normalize_rulesset(rules: RulesSet) -> RulesSet:\n",
   "    _hash = schema_hash(rules)\n",
   "    if _hash in _normalized_rulesset_cache:\n",
   "        return _normalized_rulesset_cache[_hash]\n",
   "    rules = dict(rules)\n",
   "    rules_with_whitespace = [x for x in rules if \" \" in x]\n",
   "    if rules_with_whitespace:\n",
   "        for rule in rules_with_whitespace:\n",
   "            rules[rule.replace(\" \", \"_\")] = rules.pop(rule)\n",
   "    if isinstance(rules.get(\"dependencies\"), str):\n",
   "        rules[\"dependencies\"] = (rules[\"dependencies\"],)\n",
   "    if \"excludes\" in rules:\n",
   "        constraint = rules[\"excludes\"]\n",
   "        if isinstance(constraint, str) or not isinstance(constraint, Container):\n",
   "            rules[\"excludes\"] = (constraint,)\n",
   "    if \"type\" in rules:\n",
   "        constraint = rules[\"type\"]\n",
   "        if not (isinstance(constraint, Iterable) and not isinstance(constraint, str)):\n",
   "            rules[\"type\"] = (constraint,)\n",
   "        _expand_generic_type_aliases(rules)\n",
   "    _expand_composed_of_rules(rules)\n",
   "    _normalize_contained_rulessets(rules)\n",
   "    _normalized_rulesset_cache[_hash] = rules\n",
   "    return rules\n",
   "def normalize_schema(schema: Schema) -> Schema:\n",
   "    return {field: normalize_rulesset(rules) for field, rules in schema.items()}\n",
   "    compound_types = []\n",
   "    plain_types = []\n",
   "    is_nullable = False\n",
   "    for constraint in _flatten_Union_and_Optional(rules.pop(\"type\")):\n",
   "        if isinstance(constraint, _GenericAlias):\n",
   "            origin = get_type_origin(constraint)\n",
   "            args = get_type_args(constraint)\n",
   "            if issubclass(origin, abc.Mapping) and not constraint.__parameters__:\n",
   "                compound_types.append(\n",
   "                        \"type\": origin,\n",
   "                        \"keysrules\": {\"type\": args[0]},\n",
   "                        \"valuesrules\": {\"type\": args[1]},\n",
   "                issubclass(origin, (abc.MutableSequence, abc.Set))\n",
   "                and not constraint.__parameters__\n",
   "                compound_types.append({\"type\": origin, \"itemsrules\": {\"type\": args[0]}})\n",
   "            elif issubclass(origin, tuple) and args:\n",
   "                if args[-1] is _ellipsis:\n",
   "                    compound_types.append(\n",
   "                        {\"type\": origin, \"itemsrules\": {\"type\": args[0]}}\n",
   "                    compound_types.append(\n",
   "                        {\"type\": origin, \"items\": tuple({\"type\": x} for x in args)}\n",
   "                plain_types.append(origin)\n",
   "        elif constraint is NoneType:  # type: ignore\n",
   "            is_nullable = True\n",
   "        elif isinstance(constraint, ForwardRef):\n",
   "            plain_types.append(constraint.__forward_arg__)\n",
   "            plain_types.append(constraint)\n",
   "    if compound_types or is_nullable:\n",
   "        if \"anyof\" in rules:\n",
   "        if plain_types:\n",
   "            compound_types.append({\"type\": tuple(plain_types)})\n",
   "        if is_nullable:\n",
   "            compound_types.append({\"nullable\": True})\n",
   "        rules[\"anyof\"] = tuple(compound_types)\n",
   "        rules[\"type\"] = tuple(plain_types)\n",
   "    for constraint in type_constraints:\n",
   "        if get_type_origin(constraint) is typing.Union:\n",
   "            yield from _flatten_Union_and_Optional(get_type_args(constraint))\n",
   "            yield constraint\n",
   "    composed_rules = [\n",
   "        x for x in rules if x.startswith(('allof_', 'anyof_', 'noneof_', 'oneof_'))\n",
   "    if not composed_rules:\n",
   "    for composed_rule in composed_rules:\n",
   "        of_rule, rule = composed_rule.split('_', 1)\n",
   "        rules[of_rule] = tuple({rule: x} for x in rules[composed_rule])\n",
   "    for rule in composed_rules:\n",
   "        rules.pop(rule)\n",
   "    if isinstance(rules.get(\"schema\"), abc.Mapping):\n",
   "        rules['schema'] = normalize_schema(rules['schema'])\n",
   "    for rule in (\"allow_unknown\", \"itemsrules\", \"keysrules\", \"valuesrules\"):\n",
   "        if rule in rules:\n",
   "            rules[rule] = normalize_rulesset(rules[rule])\n",
   "    for rule in ('allof', 'anyof', 'items', 'noneof', 'oneof'):\n",
   "        if not isinstance(rules.get(rule), Sequence):\n",
   "        rules[rule] = tuple(normalize_rulesset(x) for x in rules[rule])\n",
   "        for name, definition in dict(definitions).items():\n",
   "            self.add(name, definition)\n",
   "        return self._storage.get(name, default)\n",
   "        for name in names:\n",
   "            self._storage.pop(name, None)\n",
   "schema_registry, rules_set_registry = SchemaRegistry(), RulesSetRegistry()\n",
   "TypeDefinition = NamedTuple(\n",
   "        return super().__new__(mcls, name, bases, namespace)\n",
   "        def attributes_with_prefix(prefix):\n",
   "                x[len(prefix) + 2 :]\n",
   "                for x in dir(cls)\n",
   "                if x.startswith('_' + prefix + '_')\n",
   "        super().__init__(name, bases, namespace)\n",
   "        validation_rules = {\n",
   "            for attribute in attributes_with_prefix('validate')\n",
   "        cls.checkers = tuple(x for x in attributes_with_prefix('check_with'))\n",
   "        x = validation_rules['check_with']['oneof']\n",
   "        x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.checkers\n",
   "        for rule in (x for x in cls.mandatory_validations if x != 'nullable'):\n",
   "            validation_rules[rule]['required'] = True\n",
   "        cls.coercers, cls.default_setters, normalization_rules = (), (), {}\n",
   "        for attribute in attributes_with_prefix('normalize'):\n",
   "            if attribute.startswith('coerce_'):\n",
   "                cls.coercers += (attribute[len('coerce_') :],)\n",
   "            elif attribute.startswith('default_setter_'):\n",
   "                cls.default_setters += (attribute[len('default_setter_') :],)\n",
   "                normalization_rules[attribute] = cls.__get_rule_schema(\n",
   "                    '_normalize_' + attribute\n",
   "        for rule in ('coerce', 'rename_handler'):\n",
   "            x = normalization_rules[rule]['oneof']\n",
   "            x[1]['itemsrules']['oneof'][1]['allowed'] = x[2]['allowed'] = cls.coercers\n",
   "        normalization_rules['default_setter']['oneof'][1][\n",
   "        cls.normalization_rules = normalize_schema(normalization_rules)\n",
   "        cls.validation_rules = normalize_schema(validation_rules)\n",
   "        docstring = getattr(mcls, method_name).__doc__\n",
   "        if docstring is None:\n",
   "            result = {}\n",
   "            if RULE_SCHEMA_SEPARATOR in docstring:\n",
   "                docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1]\n",
   "                result = literal_eval(docstring.strip())\n",
   "                result = {}\n",
   "        if not result and method_name != '_validate_meta':\n",
   "        return result\n",
   "    types_mapping = {\n",
   "        'boolean': TypeDefinition('boolean', (bool,), ()),\n",
   "        'bytearray': TypeDefinition('bytearray', (bytearray,), ()),\n",
   "        'bytes': TypeDefinition('bytes', (bytes,), ()),\n",
   "        'complex': TypeDefinition('complex', (complex,), ()),\n",
   "        'date': TypeDefinition('date', (date,), (datetime,)),\n",
   "        'datetime': TypeDefinition('datetime', (datetime,), ()),\n",
   "        'dict': TypeDefinition('dict', (Mapping,), ()),\n",
   "        'float': TypeDefinition('float', (float,), ()),\n",
   "        'frozenset': TypeDefinition('frozenset', (frozenset,), ()),\n",
   "        'integer': TypeDefinition('integer', (int,), (bool,)),\n",
   "        'list': TypeDefinition('list', (list,), ()),\n",
   "        'number': TypeDefinition('number', (int, float), (bool,)),\n",
   "        'set': TypeDefinition('set', (set,), ()),\n",
   "        'string': TypeDefinition('string', (str,), ()),\n",
   "        'tuple': TypeDefinition('tuple', (tuple,), ()),\n",
   "        'type': TypeDefinition('type', (type,), ()),\n",
   "    types_mapping.update(\n",
   "        (x, TypeDefinition(x, (getattr(abc, x),), ()))\n",
   "        for x in abc.__all__  # type: ignore\n",
   "    normalization_rules = {}  # type: ClassVar[Schema]\n",
   "    rules = {}  # type: ClassVar[Dict[str, RulesSet]]\n",
   "    validation_rules = {}  # type: ClassVar[Schema]\n",
   "        rules_set_registry: RulesSetRegistry = rules_set_registry,\n",
   "        schema_registry: SchemaRegistry = schema_registry,\n",
   "                \"rules_set_registry\": rules_set_registry,\n",
   "                \"schema_registry\": schema_registry,\n",
   "        self.schema = schema\n",
   "            error_handler, eh_config = config\n",
   "            error_handler, eh_config = config, {}\n",
   "        if isinstance(error_handler, type) and issubclass(\n",
   "            error_handler, errors.BaseErrorHandler\n",
   "            return error_handler(**eh_config)\n",
   "        if len(args) == 1:\n",
   "            self._errors.extend(args[0])\n",
   "            for error in args[0]:\n",
   "                self.document_error_tree.add(error)\n",
   "                self.schema_error_tree.add(error)\n",
   "                self.error_handler.emit(error)\n",
   "        elif len(args) == 2 and isinstance(args[1], str):\n",
   "            self._error(args[0], errors.CUSTOM, args[1])\n",
   "        elif len(args) >= 2:\n",
   "            field = args[0]\n",
   "            code = args[1].code\n",
   "            rule = args[1].rule\n",
   "            info = args[2:]\n",
   "            document_path = self.document_path + (field,)\n",
   "            schema_path = self.schema_path\n",
   "            if code != errors.UNKNOWN_FIELD.code and rule is not None:\n",
   "                schema_path += (field, rule)\n",
   "            if not rule:\n",
   "                constraint = None\n",
   "                field_definitions = self._resolve_rules_set(self.schema[field])\n",
   "                if rule == 'nullable':\n",
   "                    constraint = field_definitions.get(rule, False)\n",
   "                elif rule == 'required':\n",
   "                    constraint = field_definitions.get(rule, self.require_all)\n",
   "                    if rule not in field_definitions:\n",
   "                        schema_path = \"__require_all__\"\n",
   "                    constraint = field_definitions[rule]\n",
   "            value = self.document.get(field)\n",
   "                document_path, schema_path, code, rule, constraint, value, info\n",
   "        child_config = ChainMap(kwargs, self._config)\n",
   "            child_config = child_config.new_child(\n",
   "                    'error_handler': toy_error_handler,\n",
   "        child_validator = self.__class__(**child_config)\n",
   "            child_validator.document_path = self.document_path\n",
   "                document_crumb = (document_crumb,)\n",
   "            child_validator.document_path = self.document_path + document_crumb\n",
   "            child_validator.schema_path = self.schema_path\n",
   "                schema_crumb = (schema_crumb,)\n",
   "            child_validator.schema_path = self.schema_path + schema_crumb\n",
   "        return child_validator\n",
   "        methodname = '_{0}_{1}'.format(domain, rule.replace(' ', '_'))\n",
   "        result = getattr(self, methodname, None)\n",
   "        if result is None:\n",
   "                \"domain.\".format(rule, domain)\n",
   "        return result\n",
   "        dp_basedepth = len(self.document_path)\n",
   "        sp_basedepth = len(self.schema_path)\n",
   "        for error in _errors:\n",
   "            for i in sorted(dp_items, reverse=True):\n",
   "                error.document_path = drop_item_from_tuple(\n",
   "                    error.document_path, dp_basedepth + i\n",
   "            for i in sorted(sp_items, reverse=True):\n",
   "                error.schema_path = drop_item_from_tuple(\n",
   "                    error.schema_path, sp_basedepth + i\n",
   "            if error.child_errors:\n",
   "                self._drop_nodes_from_errorpaths(error.child_errors, dp_items, sp_items)\n",
   "            path = path[1:]\n",
   "            context = self.document if path.startswith('^') else self.root_document\n",
   "            context = self.document\n",
   "        parts = path.split('.')\n",
   "        for part in parts:\n",
   "            if part not in context:\n",
   "            context = context.get(part, {})\n",
   "        return parts[-1], context\n",
   "        if isinstance(schema, Mapping):\n",
   "            return schema\n",
   "        elif isinstance(schema, str):\n",
   "            return self.schema_registry.get(schema)\n",
   "        if isinstance(value, Mapping):\n",
   "            self._config['allow_unknown'] = normalize_rulesset(value)\n",
   "        elif isinstance(value, bool):\n",
   "            self._config['allow_unknown'] = value\n",
   "        self._config['ignore_none_values'] = value\n",
   "        self._config['_is_normalized'] = value\n",
   "        self._config['purge_unknown'] = value\n",
   "        self._config['purge_readonly'] = value\n",
   "        self._config['require_all'] = value\n",
   "    @rules_set_registry.setter\n",
   "    @schema.setter\n",
   "        if schema is None:\n",
   "            self._schema = schema\n",
   "            self._schema = normalize_schema(schema)\n",
   "    @schema_registry.setter\n",
   "        if schema is not None:\n",
   "            self.schema = schema\n",
   "        if rules:\n",
   "            for rule in (x for x in rules if x in self._remaining_rules):\n",
   "                self._remaining_rules.remove(rule)\n",
   "        self.__init_processing(document, schema)\n",
   "        mapping = mapping.copy()\n",
   "        if isinstance(schema, str):\n",
   "            schema = self._resolve_schema(schema)\n",
   "        schema = {k: self._resolve_rules_set(v) for k, v in schema.items()}\n",
   "        self.__normalize_rename_fields(mapping, schema)\n",
   "            self._normalize_purge_unknown(mapping, schema)\n",
   "            self.__normalize_purge_readonly(mapping, schema)\n",
   "        self.__validate_readonly_fields(mapping, schema)\n",
   "        self.__normalize_default_fields(mapping, schema)\n",
   "        self._normalize_coerce(mapping, schema)\n",
   "        self.__normalize_containers(mapping, schema)\n",
   "        return mapping\n",
   "        error = errors.COERCION_FAILED\n",
   "        for field in mapping:\n",
   "            if field in schema and 'coerce' in schema[field]:\n",
   "                mapping[field] = self.__normalize_coerce(\n",
   "                    schema[field]['coerce'],\n",
   "                    field,\n",
   "                    mapping[field],\n",
   "                    schema[field].get('nullable', False),\n",
   "                    error,\n",
   "                mapping[field] = self.__normalize_coerce(\n",
   "                    field,\n",
   "                    mapping[field],\n",
   "                    error,\n",
   "            processor = self.__get_rule_handler('normalize_coerce', processor)\n",
   "        elif isinstance(processor, Iterable):\n",
   "            result = value\n",
   "            for p in processor:\n",
   "                result = self.__normalize_coerce(p, field, result, nullable, error)\n",
   "                        self.document_path + (field,)\n",
   "            return result\n",
   "            return processor(value)\n",
   "            if not (nullable and value is None):\n",
   "                self._error(field, error, str(e))\n",
   "            return value\n",
   "        for field in mapping:\n",
   "            rules = set(schema.get(field, ()))\n",
   "            if isinstance(mapping[field], Mapping):\n",
   "                if 'keysrules' in rules:\n",
   "                        field, mapping, schema[field]['keysrules']\n",
   "                if 'valuesrules' in rules:\n",
   "                        field, mapping, schema[field]['valuesrules']\n",
   "                    x in rules for x in ('allow_unknown', 'purge_unknown', 'schema')\n",
   "                    self.__normalize_mapping_per_schema(field, mapping, schema)\n",
   "            elif isinstance(mapping[field], str):\n",
   "            elif isinstance(mapping[field], Sequence):\n",
   "                if 'itemsrules' in rules:\n",
   "                    self.__normalize_sequence_per_itemsrules(field, mapping, schema)\n",
   "                elif 'items' in rules:\n",
   "                    self.__normalize_sequence_per_items(field, mapping, schema)\n",
   "        schema = {k: property_rules for k in mapping[field]}\n",
   "        document = {k: k for k in mapping[field]}\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field, schema_crumb=(field, 'keysrules'), schema=schema\n",
   "        result = validator.normalized(document, always_return_document=True)\n",
   "        if validator._errors:\n",
   "            self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\n",
   "            self._error(validator._errors)\n",
   "        for _in, out in ((k, v) for k, v in result.items() if k != v):\n",
   "            if out in mapping[field]:\n",
   "                        path='.'.join(str(x) for x in self.document_path + (field,)),\n",
   "                        key=_in,\n",
   "                mapping[field][out] = mapping[field][_in]\n",
   "                mapping[field][out] = mapping[field][_in]\n",
   "                del mapping[field][_in]\n",
   "        schema = {k: value_rules for k in mapping[field]}\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field, schema_crumb=(field, 'valuesrules'), schema=schema\n",
   "        mapping[field] = validator.normalized(\n",
   "            mapping[field], always_return_document=True\n",
   "        if validator._errors:\n",
   "            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\n",
   "            self._error(validator._errors)\n",
   "        rules = schema.get(field, {})\n",
   "        if not rules and isinstance(self.allow_unknown, Mapping):\n",
   "            rules = self.allow_unknown\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field,\n",
   "            schema_crumb=(field, 'schema'),\n",
   "            schema=rules.get('schema', {}),\n",
   "            allow_unknown=rules.get('allow_unknown', self.allow_unknown),  # noqa: E501\n",
   "            purge_unknown=rules.get('purge_unknown', self.purge_unknown),\n",
   "            require_all=rules.get('require_all', self.require_all),\n",
   "        value_type = type(mapping[field])\n",
   "        result_value = validator.normalized(mapping[field], always_return_document=True)\n",
   "        mapping[field] = value_type(result_value)\n",
   "        if validator._errors:\n",
   "            self._error(validator._errors)\n",
   "        rules, values = schema[field]['items'], mapping[field]\n",
   "        if len(rules) != len(values):\n",
   "        schema = {k: v for k, v in enumerate(rules)}\n",
   "        document = {k: v for k, v in enumerate(values)}\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field, schema_crumb=(field, 'items'), schema=schema\n",
   "        value_type = type(mapping[field])\n",
   "        result = validator.normalized(document, always_return_document=True)\n",
   "        mapping[field] = value_type(result.values())\n",
   "        if validator._errors:\n",
   "            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\n",
   "            self._error(validator._errors)\n",
   "        constraint = schema[field]['itemsrules']\n",
   "        schema = {k: constraint for k in range(len(mapping[field]))}\n",
   "        document = {k: v for k, v in enumerate(mapping[field])}\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field, schema_crumb=(field, 'itemsrules'), schema=schema\n",
   "        value_type = type(mapping[field])\n",
   "        result = validator.normalized(document, always_return_document=True)\n",
   "        mapping[field] = value_type(result.values())\n",
   "        if validator._errors:\n",
   "            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\n",
   "            self._error(validator._errors)\n",
   "        for field in [x for x in mapping if schema.get(x, {}).get('readonly', False)]:\n",
   "            mapping.pop(field)\n",
   "        return mapping\n",
   "        for field in [x for x in mapping if x not in schema]:\n",
   "            mapping.pop(field)\n",
   "        return mapping\n",
   "        for field in tuple(mapping):\n",
   "            if field in schema:\n",
   "                self._normalize_rename(mapping, schema, field)\n",
   "                self._normalize_rename_handler(mapping, schema, field)\n",
   "                    mapping, {field: self.allow_unknown}, field\n",
   "        return mapping\n",
   "        if 'rename' in schema[field]:\n",
   "            mapping[schema[field]['rename']] = mapping[field]\n",
   "            del mapping[field]\n",
   "        if 'rename_handler' not in schema[field]:\n",
   "        new_name = self.__normalize_coerce(\n",
   "            schema[field]['rename_handler'], field, field, False, errors.RENAMING_FAILED\n",
   "        if new_name != field:\n",
   "            mapping[new_name] = mapping[field]\n",
   "            del mapping[field]\n",
   "        for field in (\n",
   "            x\n",
   "            for x in schema\n",
   "            if x in mapping and self._resolve_rules_set(schema[x]).get('readonly')\n",
   "            self._validate_readonly(schema[field]['readonly'], field, mapping[field])\n",
   "        empty_fields = [\n",
   "            x\n",
   "            for x in schema\n",
   "            if x not in mapping\n",
   "                mapping[x] is None  # noqa: W503\n",
   "                and not schema[x].get('nullable', False)\n",
   "        for field in (x for x in empty_fields if 'default' in schema[x]):\n",
   "            self._normalize_default(mapping, schema, field)\n",
   "        known_fields_states = set()\n",
   "        fields_with_default_setter = [\n",
   "            x for x in empty_fields if 'default_setter' in schema[x]\n",
   "        while fields_with_default_setter:\n",
   "            field = fields_with_default_setter.pop(0)\n",
   "                self._normalize_default_setter(mapping, schema, field)\n",
   "                fields_with_default_setter.append(field)\n",
   "                self._error(field, errors.SETTING_DEFAULT_FAILED, str(e))\n",
   "            fields_processing_state = hash(tuple(fields_with_default_setter))\n",
   "            if fields_processing_state in known_fields_states:\n",
   "                for field in fields_with_default_setter:\n",
   "                        field,\n",
   "                known_fields_states.add(fields_processing_state)\n",
   "        mapping[field] = schema[field]['default']\n",
   "        if 'default_setter' in schema[field]:\n",
   "            setter = schema[field]['default_setter']\n",
   "            if isinstance(setter, str):\n",
   "                setter = self.__get_rule_handler('normalize_default_setter', setter)\n",
   "            mapping[field] = setter(mapping)\n",
   "        self.__init_processing(document, schema)\n",
   "        for field in self.document:  # type: ignore\n",
   "            definitions = self.schema.get(field)  # type: ignore\n",
   "            if definitions is not None:\n",
   "                self.__validate_definitions(definitions, field)\n",
   "                self.__validate_unknown_fields(field)\n",
   "            document=document, schema=schema, update=update, normalize=normalize\n",
   "            value = self.document[field]\n",
   "                schema_crumb = 'allow_unknown' if self.is_child else '__allow_unknown__'\n",
   "                validator = self._get_child_validator(\n",
   "                    schema_crumb=schema_crumb, schema={field: self.allow_unknown}\n",
   "                if not validator({field: value}, normalize=False):\n",
   "                    self._error(validator._errors)\n",
   "            self._error(field, errors.UNKNOWN_FIELD)\n",
   "        definitions = self._resolve_rules_set(definitions)\n",
   "        value = self.document[field]\n",
   "        rules_queue = [\n",
   "            x\n",
   "            for x in self.priority_validations\n",
   "            if x in definitions or x in self.mandatory_validations\n",
   "        rules_queue.extend(\n",
   "            x for x in self.mandatory_validations if x not in rules_queue\n",
   "        rules_queue.extend(\n",
   "            x\n",
   "            for x in definitions\n",
   "            if x not in rules_queue\n",
   "            and x not in self.normalization_rules\n",
   "            and x not in ('allow_unknown', 'require_all', 'meta', 'required')\n",
   "        self._remaining_rules = rules_queue\n",
   "            rule = self._remaining_rules.pop(0)\n",
   "            rule_handler = self.__get_rule_handler('validate', rule)\n",
   "            rule_handler(definitions.get(rule, None), field, value)\n",
   "        if isinstance(value, Iterable) and not isinstance(value, str):\n",
   "            unallowed = tuple(x for x in value if x not in allowed_values)\n",
   "            if unallowed:\n",
   "                self._error(field, errors.UNALLOWED_VALUES, unallowed)\n",
   "            if value not in allowed_values:\n",
   "                self._error(field, errors.UNALLOWED_VALUE, value)\n",
   "            value_checker = self.__get_rule_handler('check_with', checks)\n",
   "            value_checker(field, value)\n",
   "            for v in checks:\n",
   "                self._validate_check_with(v, field, value)\n",
   "            checks(field, value, self._error)\n",
   "        if not isinstance(value, Container):\n",
   "            expected_values = set((expected_values,))\n",
   "            expected_values = set(expected_values)\n",
   "        missing_values = expected_values - set(value)\n",
   "        if missing_values:\n",
   "            self._error(field, errors.MISSING_MEMBERS, missing_values)\n",
   "            dependencies = (dependencies,)\n",
   "        if isinstance(dependencies, Sequence):\n",
   "            self.__validate_dependencies_sequence(dependencies, field)\n",
   "        elif isinstance(dependencies, Mapping):\n",
   "            self.__validate_dependencies_mapping(dependencies, field)\n",
   "                self.schema_path + (field, 'dependencies')\n",
   "        validated_dependencies_counter = 0\n",
   "        error_info = {}\n",
   "        for dependency_name, dependency_values in dependencies.items():\n",
   "            if not isinstance(dependency_values, Sequence) or isinstance(\n",
   "                dependency_values, str\n",
   "                dependency_values = [dependency_values]\n",
   "            wanted_field, wanted_field_value = self._lookup_field(dependency_name)\n",
   "            if wanted_field_value in dependency_values:\n",
   "                validated_dependencies_counter += 1\n",
   "                error_info.update({dependency_name: wanted_field_value})\n",
   "        if validated_dependencies_counter != len(dependencies):\n",
   "            self._error(field, errors.DEPENDENCIES_FIELD_VALUE, error_info)\n",
   "        for dependency in dependencies:\n",
   "            if self._lookup_field(dependency)[0] is None:\n",
   "                self._error(field, errors.DEPENDENCIES_FIELD, dependency)\n",
   "        if isinstance(value, Sized) and len(value) == 0:\n",
   "                self._error(field, errors.EMPTY)\n",
   "            excluded_fields = (excluded_fields,)\n",
   "        if self.schema[field].get('required', self.require_all):\n",
   "            self._unrequired_by_excludes.add(field)\n",
   "        for excluded_field in excluded_fields:\n",
   "            if excluded_field in self.schema and self.schema[field].get(\n",
   "                self._unrequired_by_excludes.add(excluded_field)\n",
   "        if any(excluded_field in self.document for excluded_field in excluded_fields):\n",
   "            exclusion_str = ', '.join(\n",
   "                \"'{0}'\".format(field) for field in excluded_fields\n",
   "            self._error(field, errors.EXCLUDES_FIELD, exclusion_str)\n",
   "        if isinstance(value, str):\n",
   "            if value in forbidden_values:\n",
   "                self._error(field, errors.FORBIDDEN_VALUE, value)\n",
   "        elif isinstance(value, Iterable):\n",
   "            forbidden = set(value) & set(forbidden_values)\n",
   "            if forbidden:\n",
   "                self._error(field, errors.FORBIDDEN_VALUES, list(forbidden))\n",
   "            if value in forbidden_values:\n",
   "                self._error(field, errors.FORBIDDEN_VALUE, value)\n",
   "        if len(items) != len(values):\n",
   "            self._error(field, errors.ITEMS_LENGTH, len(items), len(values))\n",
   "            schema = {i: definition for i, definition in enumerate(items)}\n",
   "            validator = self._get_child_validator(\n",
   "                document_crumb=field,\n",
   "                schema_crumb=(field, 'items'),  # noqa: E501\n",
   "                schema=schema,\n",
   "            if not validator(\n",
   "                {i: value for i, value in enumerate(values)},\n",
   "                self._error(field, errors.ITEMS, validator._errors)\n",
   "        if not isinstance(value, Sequence):\n",
   "        schema = {i: rulesset for i in range(len(value))}\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field,\n",
   "            schema_crumb=(field, 'itemsrules'),\n",
   "            schema=schema,\n",
   "        validator(\n",
   "            {i: v for i, v in enumerate(value)}, update=self.update, normalize=False\n",
   "        if validator._errors:\n",
   "            self._drop_nodes_from_errorpaths(validator._errors, [], [2])\n",
   "            self._error(field, errors.ITEMSRULES, validator._errors)\n",
   "        valid_counter = 0\n",
   "        _errors = errors.ErrorList()\n",
   "        for i, definition in enumerate(definitions):\n",
   "            schema = {field: definition.copy()}\n",
   "            for rule in ('allow_unknown', 'type'):\n",
   "                if rule not in definition and rule in self.schema[field]:\n",
   "                    schema[field][rule] = self.schema[field][rule]\n",
   "            if 'allow_unknown' not in definition:\n",
   "                schema[field]['allow_unknown'] = self.allow_unknown\n",
   "            validator = self._get_child_validator(\n",
   "                schema_crumb=(field, operator, i), schema=schema, allow_unknown=True\n",
   "            if validator(self.document, update=self.update, normalize=False):\n",
   "                valid_counter += 1\n",
   "                self._drop_nodes_from_errorpaths(validator._errors, [], [3])\n",
   "                _errors.extend(validator._errors)\n",
   "        return valid_counter, _errors\n",
   "        valids, _errors = self.__validate_logical('anyof', definitions, field, value)\n",
   "        if valids < 1:\n",
   "            self._error(field, errors.ANYOF, _errors, valids, len(definitions))\n",
   "        valids, _errors = self.__validate_logical('allof', definitions, field, value)\n",
   "        if valids < len(definitions):\n",
   "            self._error(field, errors.ALLOF, _errors, valids, len(definitions))\n",
   "        valids, _errors = self.__validate_logical('noneof', definitions, field, value)\n",
   "        if valids > 0:\n",
   "            self._error(field, errors.NONEOF, _errors, valids, len(definitions))\n",
   "        valids, _errors = self.__validate_logical('oneof', definitions, field, value)\n",
   "        if valids != 1:\n",
   "            self._error(field, errors.ONEOF, _errors, valids, len(definitions))\n",
   "            if value > max_value:\n",
   "                self._error(field, errors.MAX_VALUE)\n",
   "            if value < min_value:\n",
   "                self._error(field, errors.MIN_VALUE)\n",
   "        if isinstance(value, Iterable) and len(value) > max_length:\n",
   "            self._error(field, errors.MAX_LENGTH, len(value))\n",
   "        if isinstance(value, Iterable) and len(value) < min_length:\n",
   "            self._error(field, errors.MIN_LENGTH, len(value))\n",
   "        if value is None:\n",
   "                self._error(field, errors.NULLABLE)\n",
   "        if isinstance(value, Mapping):\n",
   "            validator = self._get_child_validator(\n",
   "                document_crumb=field,\n",
   "                schema_crumb=(field, 'keysrules'),\n",
   "                schema={k: schema for k in value.keys()},\n",
   "            if not validator({k: k for k in value.keys()}, normalize=False):\n",
   "                self._drop_nodes_from_errorpaths(validator._errors, [], [2, 4])\n",
   "                self._error(field, errors.KEYSRULES, validator._errors)\n",
   "                self._error(field, errors.READONLY_FIELD)\n",
   "            has_error = (\n",
   "                    self.document_path + (field,)\n",
   "            if self._is_normalized and has_error:\n",
   "        if not isinstance(value, str):\n",
   "            pattern += '$'\n",
   "        re_obj = re.compile(pattern)\n",
   "        if not re_obj.match(value):\n",
   "            self._error(field, errors.REGEX_MISMATCH)\n",
   "    _validate_require_all = dummy_for_rule_validation(\"\"\" {'type': 'boolean'} \"\"\")\n",
   "        required = set(\n",
   "            field\n",
   "            for field, definition in self.schema.items()\n",
   "            if self._resolve_rules_set(definition).get('required', self.require_all)\n",
   "        required -= self._unrequired_by_excludes\n",
   "        missing = required - set(\n",
   "            field\n",
   "            for field in document\n",
   "            if document.get(field) is not None or not self.ignore_none_values\n",
   "        for field in missing:\n",
   "            self._error(field, errors.REQUIRED_FIELD)\n",
   "            fields = set(field for field in document if document.get(field) is not None)\n",
   "            if self._unrequired_by_excludes.isdisjoint(fields):\n",
   "                for field in self._unrequired_by_excludes - fields:\n",
   "                    self._error(field, errors.REQUIRED_FIELD)\n",
   "        if not isinstance(value, Mapping):\n",
   "        schema = self._resolve_schema(schema)\n",
   "        allow_unknown = self.schema[field].get('allow_unknown', self.allow_unknown)\n",
   "        require_all = self.schema[field].get('require_all', self.require_all)\n",
   "        validator = self._get_child_validator(\n",
   "            document_crumb=field,\n",
   "            schema_crumb=(field, 'schema'),\n",
   "            schema=schema,\n",
   "            allow_unknown=allow_unknown,\n",
   "            require_all=require_all,\n",
   "        if not validator(value, update=self.update, normalize=False):\n",
   "            self._error(field, errors.SCHEMA, validator._errors)\n",
   "        for _type in data_type:\n",
   "            if isinstance(_type, str):\n",
   "                type_definition = self.types_mapping[_type]\n",
   "                if isinstance(value, type_definition.included_types) and not isinstance(\n",
   "                    value, type_definition.excluded_types\n",
   "                if isinstance(value, _type):\n",
   "        self._error(field, errors.TYPE)\n",
   "        if isinstance(value, Mapping):\n",
   "            schema_crumb = (field, 'valuesrules')\n",
   "                document_crumb=field,\n",
   "                schema_crumb=schema_crumb,\n",
   "                schema={k: schema for k in value},\n",
   "            validator(value, update=self.update, normalize=False)\n",
   "            if validator._errors:\n",
   "                self._drop_nodes_from_errorpaths(validator._errors, [], [2])\n",
   "                self._error(field, errors.VALUESRULES, validator._errors)\n"
  ]
 },
 "16": {
  "name": "types_mapping",
  "type": "dict",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "cerberus/cerberus/schema.py",
  "lineno": "22",
  "column": "4",
  "context": " passed to a Cerberus\n        validator. \"\"\"\n\n    types_mapping = UnconcernedValidator.types_mapping.copy()\n    types_mapping.update(\n        {\n            \"c",
  "context_lines": "from cerberus.utils import schema_hash\n\n\nclass SchemaValidator(UnconcernedValidator):\n    \"\"\" This validator provides mechanics to validate schemas passed to a Cerberus\n        validator. \"\"\"\n\n    types_mapping = UnconcernedValidator.types_mapping.copy()\n    types_mapping.update(\n        {\n            \"container_but_not_string\": TypeDefinition(\n                \"container_but_not_string\", (abc.Container,), (str,)\n",
  "slicing": [
   "    types_mapping = UnconcernedValidator.types_mapping.copy()\n",
   "    types_mapping.update(\n"
  ]
 },
 "17": {
  "name": "module_spec",
  "type": "_frozen_importlib.ModuleSpec",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "cerberus/docs/includes/generate.py",
  "lineno": "16",
  "column": "4",
  "context": "berus'\n\n\ndef load_module_members(name, path):\n    module_spec = importlib.util.spec_from_file_location(name, path)\n    _module = importlib.util.module_from_spec(modu",
  "context_lines": "from types import SimpleNamespace\n\n\nINCLUDES_DIR = Path(__file__).parent.resolve()\nCERBERUS_DIR = INCLUDES_DIR.parent.parent / 'cerberus'\n\n\ndef load_module_members(name, path):\n    module_spec = importlib.util.spec_from_file_location(name, path)\n    _module = importlib.util.module_from_spec(module_spec)\n    module_spec.loader.exec_module(_module)\n    return vars(_module)\n\n\nerrors_module = load_module_members('errors', CERBERUS_DIR / 'errors.py')\n",
  "slicing": [
   "INCLUDES_DIR = Path(__file__).parent.resolve()\n",
   "CERBERUS_DIR = INCLUDES_DIR.parent.parent / 'cerberus'\n",
   "def load_module_members(name, path):\n",
   "    module_spec = importlib.util.spec_from_file_location(name, path)\n",
   "    _module = importlib.util.module_from_spec(module_spec)\n",
   "    module_spec.loader.exec_module(_module)\n",
   "    return vars(_module)\n",
   "errors_module = load_module_members('errors', CERBERUS_DIR / 'errors.py')\n",
   "error_type = errors_module['ErrorDefinition']\n",
   "error_definitions = []\n",
   "for name, member in errors_module.items():\n",
   "    if not isinstance(member, error_type):\n",
   "    error_definition = SimpleNamespace(code=member.code, rule=member.rule)\n",
   "    error_definition.name = name\n",
   "    error_definitions.append(error_definition)\n",
   "error_definitions.sort(key=attrgetter('code'))\n",
   "with (INCLUDES_DIR / 'error-codes.rst').open('wt') as f:\n",
   "        file=f,\n",
   "    for error_definition in error_definitions:\n",
   "   * - {error_definition.code}\n",
   "     - {hex(error_definition.code)}\n",
   "     - {error_definition.name}\n",
   "     - {error_definition.rule}\"\"\".lstrip(\n",
   "            file=f,\n",
   "validator_module = load_module_members('validator', CERBERUS_DIR / 'validator.py')\n",
   "validator = validator_module['Validator']()\n",
   "    validator.rules, width=68\n",
   "with (INCLUDES_DIR / 'schema-validation-schema.rst').open('wt') as f:\n",
   "        '.. code-block:: python\\n\\n', indent(schema_validation_schema, '    '), file=f\n"
  ]
 },
 "18": {
  "name": "_module",
  "type": "module",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "cerberus/docs/includes/generate.py",
  "lineno": "17",
  "column": "4",
  "context": "tlib.util.spec_from_file_location(name, path)\n    _module = importlib.util.module_from_spec(module_spec)\n    module_spec.loader.exec_module(_module)\n    re",
  "context_lines": "INCLUDES_DIR = Path(__file__).parent.resolve()\nCERBERUS_DIR = INCLUDES_DIR.parent.parent / 'cerberus'\n\n\ndef load_module_members(name, path):\n    module_spec = importlib.util.spec_from_file_location(name, path)\n    _module = importlib.util.module_from_spec(module_spec)\n    module_spec.loader.exec_module(_module)\n    return vars(_module)\n\n\nerrors_module = load_module_members('errors', CERBERUS_DIR / 'errors.py')\nerror_type = errors_module['ErrorDefinition']\n",
  "slicing": [
   "INCLUDES_DIR = Path(__file__).parent.resolve()\n",
   "CERBERUS_DIR = INCLUDES_DIR.parent.parent / 'cerberus'\n",
   "def load_module_members(name, path):\n",
   "    module_spec = importlib.util.spec_from_file_location(name, path)\n",
   "    _module = importlib.util.module_from_spec(module_spec)\n",
   "    module_spec.loader.exec_module(_module)\n",
   "    return vars(_module)\n",
   "errors_module = load_module_members('errors', CERBERUS_DIR / 'errors.py')\n",
   "error_type = errors_module['ErrorDefinition']\n",
   "error_definitions = []\n",
   "for name, member in errors_module.items():\n",
   "    if not isinstance(member, error_type):\n",
   "    error_definition = SimpleNamespace(code=member.code, rule=member.rule)\n",
   "    error_definition.name = name\n",
   "    error_definitions.append(error_definition)\n",
   "error_definitions.sort(key=attrgetter('code'))\n",
   "with (INCLUDES_DIR / 'error-codes.rst').open('wt') as f:\n",
   "        file=f,\n",
   "    for error_definition in error_definitions:\n",
   "   * - {error_definition.code}\n",
   "     - {hex(error_definition.code)}\n",
   "     - {error_definition.name}\n",
   "     - {error_definition.rule}\"\"\".lstrip(\n",
   "            file=f,\n",
   "validator_module = load_module_members('validator', CERBERUS_DIR / 'validator.py')\n",
   "validator = validator_module['Validator']()\n",
   "    validator.rules, width=68\n",
   "with (INCLUDES_DIR / 'schema-validation-schema.rst').open('wt') as f:\n",
   "        '.. code-block:: python\\n\\n', indent(schema_validation_schema, '    '), file=f\n"
  ]
 }
}