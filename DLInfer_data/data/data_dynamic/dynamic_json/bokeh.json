{
 "1": {
  "name": "event_name",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/events.py",
  "lineno": "180",
  "column": "4",
  "context": "ounce when a Document is fully idle.\n\n    '''\n    event_name = 'document_ready'\n\n\nclass ModelEvent(Event):\n    ''' Base class for ",
  "context_lines": "    '''\n\n\nclass DocumentReady(DocumentEvent):\n    ''' Announce when a Document is fully idle.\n\n    '''\n    event_name = 'document_ready'\n\n\nclass ModelEvent(Event):\n    ''' Base class for all Bokeh Model events.\n\n    This base class is not typically useful to instantiate on its own.\n\n",
  "slicing": "    event_name = 'document_ready'\n"
 },
 "2": {
  "name": "event_name",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/events.py",
  "lineno": "207",
  "column": "4",
  "context": "lick event on a Bokeh button widget.\n\n    '''\n    event_name = 'button_click'\n\n    def __init__(self, model):\n        from .mode",
  "context_lines": "            self._model_id = model.id\n\n\nclass ButtonClick(ModelEvent):\n    ''' Announce a button click event on a Bokeh button widget.\n\n    '''\n    event_name = 'button_click'\n\n    def __init__(self, model):\n        from .models.widgets import AbstractButton\n        if model is not None and not isinstance(model, AbstractButton):\n",
  "slicing": "    event_name = 'button_click'\n"
 },
 "3": {
  "name": "event_name",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/events.py",
  "lineno": "220",
  "column": "4",
  "context": "on click event on a Bokeh menu item.\n\n    '''\n    event_name = 'menu_item_click'\n\n    def __init__(self, model, item=None):\n       ",
  "context_lines": "        super().__init__(model=model)\n\nclass MenuItemClick(ModelEvent):\n    ''' Announce a button click event on a Bokeh menu item.\n\n    '''\n    event_name = 'menu_item_click'\n\n    def __init__(self, model, item=None):\n        self.item = item\n        super().__init__(model=model)\n\n",
  "slicing": "    event_name = 'menu_item_click'\n"
 },
 "4": {
  "name": "event_name",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/events.py",
  "lineno": "246",
  "column": "4",
  "context": "never a LOD mode\n    has just begun.\n\n    '''\n    event_name = 'lodstart'\n\nclass LODEnd(PlotEvent):\n    ''' Announce the end",
  "context_lines": "    maintain high interactive rates. This is referred to as interactive\n    Level-of-Detail (LOD) mode. This event fires whenever a LOD mode\n    has just begun.\n\n    '''\n    event_name = 'lodstart'\n\nclass LODEnd(PlotEvent):\n    ''' Announce the end of \"interactive level-of-detail\" mode on a plot.\n\n    During interactive actions such as panning or zooming, Bokeh can\n",
  "slicing": "    event_name = 'lodstart'\n"
 },
 "5": {
  "name": "event_name",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/events.py",
  "lineno": "258",
  "column": "4",
  "context": "never a LOD mode\n    has just ended.\n\n    '''\n    event_name = 'lodend'\n\nclass SelectionGeometry(PlotEvent):\n    ''' Annou",
  "context_lines": "    maintain high interactive rates. This is referred to as interactive\n    Level-of-Detail (LOD) mode. This event fires whenever a LOD mode\n    has just ended.\n\n    '''\n    event_name = 'lodend'\n\nclass SelectionGeometry(PlotEvent):\n    ''' Announce the coordinates of a selection event on a plot.\n\n    Attributes:\n",
  "slicing": "    event_name = 'lodend'\n"
 },
 "6": {
  "name": "event_name",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/events.py",
  "lineno": "270",
  "column": "4",
  "context": "se of selections on every mousemove.\n\n    '''\n    event_name = \"selectiongeometry\"\n\n    def __init__(self, model, geometry=None, fina",
  "context_lines": "            selection event.\n        final (bool) : whether the selection event is the last selection event\n            in the case of selections on every mousemove.\n\n    '''\n    event_name = \"selectiongeometry\"\n\n    def __init__(self, model, geometry=None, final=True):\n        self.geometry = geometry\n        self.final = final\n",
  "slicing": "    event_name = \"selectiongeometry\"\n"
 },
 "7": {
  "name": "event_name",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/events.py",
  "lineno": "281",
  "column": "4",
  "context": "click event on a plot ``ResetTool``.\n\n    '''\n    event_name = \"reset\"\n\n    def __init__(self, model):\n        super().__",
  "context_lines": "        super().__init__(model=model)\n\nclass Reset(PlotEvent):\n    ''' Announce a button click event on a plot ``ResetTool``.\n\n    '''\n    event_name = \"reset\"\n\n    def __init__(self, model):\n        super().__init__(model=model)\n\nclass PointEvent(PlotEvent):\n",
  "slicing": "    event_name = \"reset\"\n"
 },
 "8": {
  "name": "event_name",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/events.py",
  "lineno": "317",
  "column": "4",
  "context": "rdinate of the event in *data* space\n\n    '''\n    event_name = 'tap'\n\nclass DoubleTap(PointEvent):\n    ''' Announce a d",
  "context_lines": "        sy (float) : y-coordinate of the event in *screen* space\n        x (float) : x-coordinate of the event in *data* space\n        y (float) : y-coordinate of the event in *data* space\n\n    '''\n    event_name = 'tap'\n\nclass DoubleTap(PointEvent):\n    ''' Announce a double-tap or double-click event on a Bokeh plot.\n\n    Attributes:\n",
  "slicing": "    event_name = 'tap'\n"
 },
 "9": {
  "name": "event_name",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/events.py",
  "lineno": "329",
  "column": "4",
  "context": "rdinate of the event in *data* space\n\n    '''\n    event_name = 'doubletap'\n\nclass Press(PointEvent):\n    ''' Announce a press",
  "context_lines": "        sy (float) : y-coordinate of the event in *screen* space\n        x (float) : x-coordinate of the event in *data* space\n        y (float) : y-coordinate of the event in *data* space\n\n    '''\n    event_name = 'doubletap'\n\nclass Press(PointEvent):\n    ''' Announce a press event on a Bokeh plot.\n\n    Attributes:\n",
  "slicing": "    event_name = 'doubletap'\n"
 },
 "10": {
  "name": "event_name",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/events.py",
  "lineno": "341",
  "column": "4",
  "context": "rdinate of the event in *data* space\n\n    '''\n    event_name = 'press'\n\nclass PressUp(PointEvent):\n    ''' Announce a pre",
  "context_lines": "        sy (float) : y-coordinate of the event in *screen* space\n        x (float) : x-coordinate of the event in *data* space\n        y (float) : y-coordinate of the event in *data* space\n\n    '''\n    event_name = 'press'\n\nclass PressUp(PointEvent):\n    ''' Announce a pressup event on a Bokeh plot.\n\n    Attributes:\n",
  "slicing": "    event_name = 'press'\n"
 },
 "11": {
  "name": "event_name",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/events.py",
  "lineno": "353",
  "column": "4",
  "context": "rdinate of the event in *data* space\n\n    '''\n    event_name = 'pressup'\n\nclass MouseEnter(PointEvent):\n    ''' Announce a ",
  "context_lines": "        sy (float) : y-coordinate of the event in *screen* space\n        x (float) : x-coordinate of the event in *data* space\n        y (float) : y-coordinate of the event in *data* space\n\n    '''\n    event_name = 'pressup'\n\nclass MouseEnter(PointEvent):\n    ''' Announce a mouse enter event onto a Bokeh plot.\n\n    Attributes:\n",
  "slicing": "    event_name = 'pressup'\n"
 },
 "12": {
  "name": "event_name",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/events.py",
  "lineno": "369",
  "column": "4",
  "context": "dding and space for axes or legends.\n\n    '''\n    event_name = 'mouseenter'\n\nclass MouseLeave(PointEvent):\n    ''' Announce a ",
  "context_lines": "    .. note::\n        The enter event is generated when the mouse leaves the entire Plot\n        canvas, including any border padding and space for axes or legends.\n\n    '''\n    event_name = 'mouseenter'\n\nclass MouseLeave(PointEvent):\n    ''' Announce a mouse leave event from a Bokeh plot.\n\n    Attributes:\n",
  "slicing": "    event_name = 'mouseenter'\n"
 },
 "13": {
  "name": "event_name",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/events.py",
  "lineno": "385",
  "column": "4",
  "context": "dding and space for axes or legends.\n\n    '''\n    event_name = 'mouseleave'\n\nclass MouseMove(PointEvent):\n    ''' Announce a m",
  "context_lines": "    .. note::\n        The leave event is generated when the mouse leaves the entire Plot\n        canvas, including any border padding and space for axes or legends.\n\n    '''\n    event_name = 'mouseleave'\n\nclass MouseMove(PointEvent):\n    ''' Announce a mouse movement event over a Bokeh plot.\n\n    Attributes:\n",
  "slicing": "    event_name = 'mouseleave'\n"
 },
 "14": {
  "name": "event_name",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/events.py",
  "lineno": "401",
  "column": "4",
  "context": "network\n        traffic or CPU load.\n\n    '''\n    event_name = 'mousemove'\n\nclass MouseWheel(PointEvent):\n    ''' Announce a ",
  "context_lines": "    .. note::\n        This event can fire at a very high rate, potentially increasing network\n        traffic or CPU load.\n\n    '''\n    event_name = 'mousemove'\n\nclass MouseWheel(PointEvent):\n    ''' Announce a mouse wheel event on a Bokeh plot.\n\n    Attributes:\n",
  "slicing": "    event_name = 'mousemove'\n"
 },
 "15": {
  "name": "event_name",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/events.py",
  "lineno": "420",
  "column": "4",
  "context": "y change in\n        future releases.\n\n    '''\n    event_name = 'wheel'\n\n    def __init__(self, model, delta=None, **kwarg",
  "context_lines": "        By default, Bokeh plots do not prevent default scroll events unless a\n        ``WheelZoomTool`` or ``WheelPanTool`` is active. This may change in\n        future releases.\n\n    '''\n    event_name = 'wheel'\n\n    def __init__(self, model, delta=None, **kwargs):\n        self.delta = delta\n        super().__init__(model, **kwargs)\n\n",
  "slicing": "    event_name = 'wheel'\n"
 },
 "16": {
  "name": "event_name",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/events.py",
  "lineno": "439",
  "column": "4",
  "context": "rdinate of the event in *data* space\n\n    '''\n    event_name = 'pan'\n\n    def __init__(self, model, delta_x=None, delta",
  "context_lines": "        sy (float) : y-coordinate of the event in *screen* space\n        x (float) : x-coordinate of the event in *data* space\n        y (float) : y-coordinate of the event in *data* space\n\n    '''\n    event_name = 'pan'\n\n    def __init__(self, model, delta_x=None, delta_y=None, direction=None, **kwargs):\n        self.delta_x = delta_x\n        self.delta_y = delta_y\n",
  "slicing": "    event_name = 'pan'\n"
 },
 "17": {
  "name": "event_name",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/events.py",
  "lineno": "457",
  "column": "4",
  "context": "rdinate of the event in *data* space\n\n    '''\n    event_name = 'panend'\n\nclass PanStart(PointEvent):\n    ''' Announce the ",
  "context_lines": "        sy (float) : y-coordinate of the event in *screen* space\n        x (float) : x-coordinate of the event in *data* space\n        y (float) : y-coordinate of the event in *data* space\n\n    '''\n    event_name = 'panend'\n\nclass PanStart(PointEvent):\n    ''' Announce the start of a pan event on a Bokeh plot.\n\n    Attributes:\n",
  "slicing": "    event_name = 'panend'\n"
 },
 "18": {
  "name": "event_name",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/events.py",
  "lineno": "469",
  "column": "4",
  "context": "rdinate of the event in *data* space\n\n    '''\n    event_name = 'panstart'\n\nclass Pinch(PointEvent):\n    ''' Announce a pinch",
  "context_lines": "        sy (float) : y-coordinate of the event in *screen* space\n        x (float) : x-coordinate of the event in *data* space\n        y (float) : y-coordinate of the event in *data* space\n\n    '''\n    event_name = 'panstart'\n\nclass Pinch(PointEvent):\n    ''' Announce a pinch event on a Bokeh plot.\n\n    Attributes:\n",
  "slicing": "    event_name = 'panstart'\n"
 },
 "19": {
  "name": "event_name",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/events.py",
  "lineno": "485",
  "column": "4",
  "context": "pplicable for touch-enabled devices.\n\n    '''\n    event_name = 'pinch'\n\n    def __init__(self, model, scale=None, **kwarg",
  "context_lines": "        y (float) : y-coordinate of the event in *data* space\n\n    .. note::\n        This event is only applicable for touch-enabled devices.\n\n    '''\n    event_name = 'pinch'\n\n    def __init__(self, model, scale=None, **kwargs):\n        self.scale = scale\n        super().__init__(model, **kwargs)\n\n",
  "slicing": "    event_name = 'pinch'\n"
 },
 "20": {
  "name": "event_name",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/events.py",
  "lineno": "504",
  "column": "4",
  "context": "pplicable for touch-enabled devices.\n\n    '''\n    event_name = 'pinchend'\n\nclass PinchStart(PointEvent):\n    ''' Announce th",
  "context_lines": "        y (float) : y-coordinate of the event in *data* space\n\n    .. note::\n        This event is only applicable for touch-enabled devices.\n\n    '''\n    event_name = 'pinchend'\n\nclass PinchStart(PointEvent):\n    ''' Announce the start of a pinch event on a Bokeh plot.\n\n    Attributes:\n",
  "slicing": "    event_name = 'pinchend'\n"
 },
 "21": {
  "name": "event_name",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/events.py",
  "lineno": "519",
  "column": "4",
  "context": "pplicable for touch-enabled devices.\n\n    '''\n    event_name = 'pinchstart'\n\nclass Rotate(PointEvent):\n    ''' Announce a rota",
  "context_lines": "        y (float) : y-coordinate of the event in *data* space\n\n    .. note::\n        This event is only applicable for touch-enabled devices.\n\n    '''\n    event_name = 'pinchstart'\n\nclass Rotate(PointEvent):\n    ''' Announce a rotate event on a Bokeh plot.\n\n    Attributes:\n",
  "slicing": "    event_name = 'pinchstart'\n"
 },
 "22": {
  "name": "event_name",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/events.py",
  "lineno": "535",
  "column": "4",
  "context": "pplicable for touch-enabled devices.\n\n    '''\n    event_name = 'rotate'\n\n    def __init__(self, model, rotation=None, **kw",
  "context_lines": "        y (float) : y-coordinate of the event in *data* space\n\n    .. note::\n        This event is only applicable for touch-enabled devices.\n\n    '''\n    event_name = 'rotate'\n\n    def __init__(self, model, rotation=None, **kwargs):\n        self.rotation = rotation\n        super().__init__(model, **kwargs)\n\n",
  "slicing": "    event_name = 'rotate'\n"
 },
 "23": {
  "name": "event_name",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/events.py",
  "lineno": "554",
  "column": "4",
  "context": "pplicable for touch-enabled devices.\n\n    '''\n    event_name = 'rotateend'\n\nclass RotateStart(PointEvent):\n    ''' Announce t",
  "context_lines": "        y (float) : y-coordinate of the event in *data* space\n\n    .. note::\n        This event is only applicable for touch-enabled devices.\n\n    '''\n    event_name = 'rotateend'\n\nclass RotateStart(PointEvent):\n    ''' Announce the start of a rotate event on a Bokeh plot.\n\n    Attributes:\n",
  "slicing": "    event_name = 'rotateend'\n"
 },
 "24": {
  "name": "event_name",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/events.py",
  "lineno": "569",
  "column": "4",
  "context": "pplicable for touch-enabled devices.\n\n    '''\n    event_name = 'rotatestart'\n\n#------------------------------------------------",
  "context_lines": "        y (float) : y-coordinate of the event in *data* space\n\n    .. note::\n        This event is only applicable for touch-enabled devices.\n\n    '''\n    event_name = 'rotatestart'\n\n#-----------------------------------------------------------------------------\n# Dev API\n#-----------------------------------------------------------------------------\n\n",
  "slicing": "    event_name = 'rotatestart'\n"
 },
 "25": {
  "name": "obj",
  "type": "LinearAxis",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/model.py",
  "lineno": "88",
  "column": "8",
  "context": "nces(value, queue_one)\n\n    while queued:\n        obj = queued.pop(0)\n        if obj.id not in ids:\n            ids.add(",
  "context_lines": "            queued.append(obj)\n\n    for value in input_values:\n        _visit_value_and_its_immediate_references(value, queue_one)\n\n    while queued:\n        obj = queued.pop(0)\n        if obj.id not in ids:\n            ids.add(obj.id)\n            collected.append(obj)\n            _visit_immediate_value_references(obj, queue_one)\n\n",
  "slicing": [
   "def collect_filtered_models(discard, *input_values):\n",
   "    ids = set()\n",
   "    collected = []\n",
   "    queued = []\n",
   "        if obj.id not in ids and not (callable(discard) and discard(obj)):\n",
   "            queued.append(obj)\n",
   "    for value in input_values:\n",
   "        _visit_value_and_its_immediate_references(value, queue_one)\n",
   "    while queued:\n",
   "        obj = queued.pop(0)\n",
   "        if obj.id not in ids:\n",
   "            ids.add(obj.id)\n",
   "            collected.append(obj)\n",
   "            _visit_immediate_value_references(obj, queue_one)\n",
   "    return collected\n",
   "def collect_models(*input_values):\n",
   "    return collect_filtered_models(None, *input_values)\n",
   "    d = Model.model_class_reverse_map\n",
   "    if view_model_name in d:\n",
   "        return d[view_model_name]\n",
   "_HTML_REPR = \"\"\"\n",
   "        module = cls.__view_module__\n",
   "        model = cls.__dict__.get(\"__subtype__\", cls.__view_model__)\n",
   "        impl = cls.__dict__.get(\"__implementation__\", None)\n",
   "        head = module.split(\".\")[0]\n",
   "        if head == \"bokeh\" or head == \"__main__\" or impl is not None:\n",
   "            qualified = model\n",
   "            qualified = module + \".\" + model\n",
   "        cls.__qualified_model__ = qualified\n",
   "        previous = cls.model_class_reverse_map.get(qualified, None)\n",
   "        if previous is not None and not hasattr(cls, \"__implementation__\"):\n",
   "            raise Warning(f\"Duplicate qualified model declaration of '{qualified}'. Previous definition: {previous}\")\n",
   "        cls.model_class_reverse_map[qualified] = cls\n",
   "        obj =  super().__new__(cls)\n",
   "        obj._id = kwargs.pop(\"id\", make_id())\n",
   "        obj._document = None\n",
   "        obj._temp_document = None\n",
   "        return obj\n",
   "    name = String(help=\"\"\"\n",
   "        this = {\n",
   "            parts = this[\"type\"].split(\".\")\n",
   "            parts[-1] = self.__view_model__\n",
   "            this[\"type\"] = \".\".join(parts)\n",
   "            this[\"subtype\"] = self.__subtype__\n",
   "        return this\n",
   "            event = event.event_name\n",
   "        old_callbacks = self.js_event_callbacks.get(\"event\", [])\n",
   "        new_callbacks = [ callback for callback in callbacks if callback not in old_callbacks ]\n",
   "        self.js_event_callbacks[event] = old_callbacks + new_callbacks\n",
   "        selector = f\"[{attr_selector!r}]\" if attr_selector is not None else \"\"\n",
   "        cb = CustomJS(args=dict(other=other), code=f\"other.{other_attr} = this.{attr}{selector}\")\n",
   "        self.js_on_change(attr, cb)\n",
   "        if not all(isinstance(x, CustomJS) for x in callbacks):\n",
   "        if event in self.properties():\n",
   "            event = \"change:%s\" % event\n",
   "        old = {k: [cb for cb in cbs] for k, cbs in self.js_property_callbacks.items()}\n",
   "        if event not in self.js_property_callbacks:\n",
   "            self.js_property_callbacks[event] = []\n",
   "        for callback in callbacks:\n",
   "            if callback in self.js_property_callbacks[event]:\n",
   "            self.js_property_callbacks[event].append(callback)\n",
   "        self.trigger('js_property_callbacks', old, self.js_property_callbacks)\n",
   "        return set(collect_models(self))\n",
   "        return find(self.references(), selector)\n",
   "        result = list(self.select(selector))\n",
   "        if len(result) > 1:\n",
   "            raise ValueError(\"Found more than one object matching %s: %r\" % (selector, result))\n",
   "        if len(result) == 0:\n",
   "        return result[0]\n",
   "        if isclass(selector) and issubclass(selector, Model):\n",
   "            selector = dict(type=selector)\n",
   "        for obj in self.select(selector):\n",
   "            for key, val in updates.items():\n",
   "                setattr(obj, key, val)\n",
   "        json_like = self._to_json_like(include_defaults=include_defaults)\n",
   "        json_like['id'] = self.id\n",
   "        return serialize_json(json_like)\n",
   "            dirty = { 'count' : 0 }\n",
   "                dirty['count'] += 1\n",
   "                _visit_value_and_its_immediate_references(old, mark_dirty)\n",
   "                if dirty['count'] > 0:\n",
   "        super().trigger(attr, old, new, hint=hint, setter=setter)\n",
   "            k: v for k, v in Model.model_class_reverse_map.items()\n",
   "            if getattr(v, \"__implementation__\", None) is None\n",
   "                and getattr(v, \"__javascript__\", None) is None\n",
   "                and getattr(v, \"__css__\", None) is None\n",
   "        all_attrs = self.properties_with_values(include_defaults=include_defaults)\n",
   "        subtype = getattr(self.__class__, \"__subtype__\", None)\n",
   "        if subtype is not None and subtype != self.__class__.__view_model__:\n",
   "            attrs = {}\n",
   "            for attr, value in all_attrs.items():\n",
   "                if attr in self.__class__.__dict__:\n",
   "                    attrs[attr] = value\n",
   "            attrs = all_attrs\n",
   "        for (k, v) in attrs.items():\n",
   "            if isinstance(v, float) and v == float('inf'):\n",
   "                attrs[k] = None\n",
   "        return attrs\n",
   "        module = self.__class__.__module__\n",
   "        name = self.__class__.__name__\n",
   "        _id = getattr(self, \"_id\", None)\n",
   "        cls_name = make_id()\n",
   "        def row(c):\n",
   "        def hidden_row(c):\n",
   "            return '<div class=\"%s\" style=\"display: none;\">%s</div>' % (cls_name, c)\n",
   "        def cell(c):\n",
   "            return '<div style=\"display: table-cell;\">' + c + '</div>'\n",
   "        html = ''\n",
   "        html += '<div style=\"display: table;\">'\n",
   "        ellipsis_id = make_id()\n",
   "        ellipsis = '<span id=\"%s\" style=\"cursor: pointer;\">&hellip;)</span>' % ellipsis_id\n",
   "        prefix = cell('<b title=\"%s.%s\">%s</b>(' % (module, name, name))\n",
   "        html += row(prefix + cell('id' + '&nbsp;=&nbsp;' + repr(_id) + ', ' + ellipsis))\n",
   "        props = self.properties_with_values().items()\n",
   "        sorted_props = sorted(props, key=itemgetter(0))\n",
   "        all_props = sorted_props\n",
   "        for i, (prop, value) in enumerate(all_props):\n",
   "            end = ')' if i == len(all_props)-1 else ','\n",
   "            html += hidden_row(cell(\"\") + cell(prop + '&nbsp;=&nbsp;' + repr(value) + end))\n",
   "        html += '</div>'\n",
   "        html += _HTML_REPR % dict(ellipsis_id=ellipsis_id, cls_name=cls_name)\n",
   "        return html\n",
   "    if isinstance(value, HasProps):\n",
   "        for attr in value.properties_with_refs():\n",
   "            child = getattr(value, attr)\n",
   "            _visit_value_and_its_immediate_references(child, visitor)\n",
   "        _visit_value_and_its_immediate_references(value, visitor)\n",
   "    typ = type(obj)\n",
   "    if typ in _common_types:  # short circuit on common base types\n",
   "    if typ is list or issubclass(typ, (list, tuple)):  # check common containers\n",
   "        for item in obj:\n",
   "            _visit_value_and_its_immediate_references(item, visitor)\n",
   "    elif issubclass(typ, dict):\n",
   "        for key, value in obj.items():\n",
   "            _visit_value_and_its_immediate_references(key, visitor)\n",
   "            _visit_value_and_its_immediate_references(value, visitor)\n",
   "    elif issubclass(typ, HasProps):\n",
   "        if issubclass(typ, Model):\n",
   "            visitor(obj)\n",
   "            _visit_immediate_value_references(obj, visitor)\n"
  ]
 },
 "26": {
  "name": "model",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/model.py",
  "lineno": "190",
  "column": "8",
  "context": "e__\n\n        module = cls.__view_module__\n        model = cls.__dict__.get(\"__subtype__\", cls.__view_model__)\n        impl = cls.__dict__.get(\"__implementation_",
  "context_lines": "            cls.__view_model__ = cls.__name__\n        if \"__view_module__\" not in cls.__dict__:\n            cls.__view_module__ = cls.__module__\n\n        module = cls.__view_module__\n        model = cls.__dict__.get(\"__subtype__\", cls.__view_model__)\n        impl = cls.__dict__.get(\"__implementation__\", None)\n\n        head = module.split(\".\")[0]\n        if head == \"bokeh\" or head == \"__main__\" or impl is not None:\n            qualified = model\n",
  "slicing": [
   "def collect_filtered_models(discard, *input_values):\n",
   "    ids = set()\n",
   "    collected = []\n",
   "    queued = []\n",
   "        if obj.id not in ids and not (callable(discard) and discard(obj)):\n",
   "            queued.append(obj)\n",
   "    for value in input_values:\n",
   "        _visit_value_and_its_immediate_references(value, queue_one)\n",
   "    while queued:\n",
   "        obj = queued.pop(0)\n",
   "        if obj.id not in ids:\n",
   "            ids.add(obj.id)\n",
   "            collected.append(obj)\n",
   "            _visit_immediate_value_references(obj, queue_one)\n",
   "    return collected\n",
   "def collect_models(*input_values):\n",
   "    return collect_filtered_models(None, *input_values)\n",
   "    d = Model.model_class_reverse_map\n",
   "    if view_model_name in d:\n",
   "        return d[view_model_name]\n",
   "_HTML_REPR = \"\"\"\n",
   "        module = cls.__view_module__\n",
   "        model = cls.__dict__.get(\"__subtype__\", cls.__view_model__)\n",
   "        impl = cls.__dict__.get(\"__implementation__\", None)\n",
   "        head = module.split(\".\")[0]\n",
   "        if head == \"bokeh\" or head == \"__main__\" or impl is not None:\n",
   "            qualified = model\n",
   "            qualified = module + \".\" + model\n",
   "        cls.__qualified_model__ = qualified\n",
   "        previous = cls.model_class_reverse_map.get(qualified, None)\n",
   "        if previous is not None and not hasattr(cls, \"__implementation__\"):\n",
   "            raise Warning(f\"Duplicate qualified model declaration of '{qualified}'. Previous definition: {previous}\")\n",
   "        cls.model_class_reverse_map[qualified] = cls\n",
   "        obj =  super().__new__(cls)\n",
   "        obj._id = kwargs.pop(\"id\", make_id())\n",
   "        obj._document = None\n",
   "        obj._temp_document = None\n",
   "        return obj\n",
   "    name = String(help=\"\"\"\n",
   "        this = {\n",
   "            parts = this[\"type\"].split(\".\")\n",
   "            parts[-1] = self.__view_model__\n",
   "            this[\"type\"] = \".\".join(parts)\n",
   "            this[\"subtype\"] = self.__subtype__\n",
   "        return this\n",
   "            event = event.event_name\n",
   "        old_callbacks = self.js_event_callbacks.get(\"event\", [])\n",
   "        new_callbacks = [ callback for callback in callbacks if callback not in old_callbacks ]\n",
   "        self.js_event_callbacks[event] = old_callbacks + new_callbacks\n",
   "        selector = f\"[{attr_selector!r}]\" if attr_selector is not None else \"\"\n",
   "        cb = CustomJS(args=dict(other=other), code=f\"other.{other_attr} = this.{attr}{selector}\")\n",
   "        self.js_on_change(attr, cb)\n",
   "        if not all(isinstance(x, CustomJS) for x in callbacks):\n",
   "        if event in self.properties():\n",
   "            event = \"change:%s\" % event\n",
   "        old = {k: [cb for cb in cbs] for k, cbs in self.js_property_callbacks.items()}\n",
   "        if event not in self.js_property_callbacks:\n",
   "            self.js_property_callbacks[event] = []\n",
   "        for callback in callbacks:\n",
   "            if callback in self.js_property_callbacks[event]:\n",
   "            self.js_property_callbacks[event].append(callback)\n",
   "        self.trigger('js_property_callbacks', old, self.js_property_callbacks)\n",
   "        return set(collect_models(self))\n",
   "        return find(self.references(), selector)\n",
   "        result = list(self.select(selector))\n",
   "        if len(result) > 1:\n",
   "            raise ValueError(\"Found more than one object matching %s: %r\" % (selector, result))\n",
   "        if len(result) == 0:\n",
   "        return result[0]\n",
   "        if isclass(selector) and issubclass(selector, Model):\n",
   "            selector = dict(type=selector)\n",
   "        for obj in self.select(selector):\n",
   "            for key, val in updates.items():\n",
   "                setattr(obj, key, val)\n",
   "        json_like = self._to_json_like(include_defaults=include_defaults)\n",
   "        json_like['id'] = self.id\n",
   "        return serialize_json(json_like)\n",
   "            dirty = { 'count' : 0 }\n",
   "                dirty['count'] += 1\n",
   "                _visit_value_and_its_immediate_references(old, mark_dirty)\n",
   "                if dirty['count'] > 0:\n",
   "        super().trigger(attr, old, new, hint=hint, setter=setter)\n",
   "            k: v for k, v in Model.model_class_reverse_map.items()\n",
   "            if getattr(v, \"__implementation__\", None) is None\n",
   "                and getattr(v, \"__javascript__\", None) is None\n",
   "                and getattr(v, \"__css__\", None) is None\n",
   "        all_attrs = self.properties_with_values(include_defaults=include_defaults)\n",
   "        subtype = getattr(self.__class__, \"__subtype__\", None)\n",
   "        if subtype is not None and subtype != self.__class__.__view_model__:\n",
   "            attrs = {}\n",
   "            for attr, value in all_attrs.items():\n",
   "                if attr in self.__class__.__dict__:\n",
   "                    attrs[attr] = value\n",
   "            attrs = all_attrs\n",
   "        for (k, v) in attrs.items():\n",
   "            if isinstance(v, float) and v == float('inf'):\n",
   "                attrs[k] = None\n",
   "        return attrs\n",
   "        module = self.__class__.__module__\n",
   "        name = self.__class__.__name__\n",
   "        _id = getattr(self, \"_id\", None)\n",
   "        cls_name = make_id()\n",
   "        def row(c):\n",
   "        def hidden_row(c):\n",
   "            return '<div class=\"%s\" style=\"display: none;\">%s</div>' % (cls_name, c)\n",
   "        def cell(c):\n",
   "            return '<div style=\"display: table-cell;\">' + c + '</div>'\n",
   "        html = ''\n",
   "        html += '<div style=\"display: table;\">'\n",
   "        ellipsis_id = make_id()\n",
   "        ellipsis = '<span id=\"%s\" style=\"cursor: pointer;\">&hellip;)</span>' % ellipsis_id\n",
   "        prefix = cell('<b title=\"%s.%s\">%s</b>(' % (module, name, name))\n",
   "        html += row(prefix + cell('id' + '&nbsp;=&nbsp;' + repr(_id) + ', ' + ellipsis))\n",
   "        props = self.properties_with_values().items()\n",
   "        sorted_props = sorted(props, key=itemgetter(0))\n",
   "        all_props = sorted_props\n",
   "        for i, (prop, value) in enumerate(all_props):\n",
   "            end = ')' if i == len(all_props)-1 else ','\n",
   "            html += hidden_row(cell(\"\") + cell(prop + '&nbsp;=&nbsp;' + repr(value) + end))\n",
   "        html += '</div>'\n",
   "        html += _HTML_REPR % dict(ellipsis_id=ellipsis_id, cls_name=cls_name)\n",
   "        return html\n",
   "    if isinstance(value, HasProps):\n",
   "        for attr in value.properties_with_refs():\n",
   "            child = getattr(value, attr)\n",
   "            _visit_value_and_its_immediate_references(child, visitor)\n",
   "        _visit_value_and_its_immediate_references(value, visitor)\n",
   "    typ = type(obj)\n",
   "    if typ in _common_types:  # short circuit on common base types\n",
   "    if typ is list or issubclass(typ, (list, tuple)):  # check common containers\n",
   "        for item in obj:\n",
   "            _visit_value_and_its_immediate_references(item, visitor)\n",
   "    elif issubclass(typ, dict):\n",
   "        for key, value in obj.items():\n",
   "            _visit_value_and_its_immediate_references(key, visitor)\n",
   "            _visit_value_and_its_immediate_references(value, visitor)\n",
   "    elif issubclass(typ, HasProps):\n",
   "        if issubclass(typ, Model):\n",
   "            visitor(obj)\n",
   "            _visit_immediate_value_references(obj, visitor)\n"
  ]
 },
 "27": {
  "name": "impl",
  "type": "NoneType",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/model.py",
  "lineno": "191",
  "column": "8",
  "context": "__.get(\"__subtype__\", cls.__view_model__)\n        impl = cls.__dict__.get(\"__implementation__\", None)\n\n        head = module.split(\".\")[0]\n        if he",
  "context_lines": "        if \"__view_module__\" not in cls.__dict__:\n            cls.__view_module__ = cls.__module__\n\n        module = cls.__view_module__\n        model = cls.__dict__.get(\"__subtype__\", cls.__view_model__)\n        impl = cls.__dict__.get(\"__implementation__\", None)\n\n        head = module.split(\".\")[0]\n        if head == \"bokeh\" or head == \"__main__\" or impl is not None:\n            qualified = model\n",
  "slicing": [
   "def collect_filtered_models(discard, *input_values):\n",
   "    ids = set()\n",
   "    collected = []\n",
   "    queued = []\n",
   "        if obj.id not in ids and not (callable(discard) and discard(obj)):\n",
   "            queued.append(obj)\n",
   "    for value in input_values:\n",
   "        _visit_value_and_its_immediate_references(value, queue_one)\n",
   "    while queued:\n",
   "        obj = queued.pop(0)\n",
   "        if obj.id not in ids:\n",
   "            ids.add(obj.id)\n",
   "            collected.append(obj)\n",
   "            _visit_immediate_value_references(obj, queue_one)\n",
   "    return collected\n",
   "def collect_models(*input_values):\n",
   "    return collect_filtered_models(None, *input_values)\n",
   "    d = Model.model_class_reverse_map\n",
   "    if view_model_name in d:\n",
   "        return d[view_model_name]\n",
   "_HTML_REPR = \"\"\"\n",
   "        module = cls.__view_module__\n",
   "        model = cls.__dict__.get(\"__subtype__\", cls.__view_model__)\n",
   "        impl = cls.__dict__.get(\"__implementation__\", None)\n",
   "        head = module.split(\".\")[0]\n",
   "        if head == \"bokeh\" or head == \"__main__\" or impl is not None:\n",
   "            qualified = model\n",
   "            qualified = module + \".\" + model\n",
   "        cls.__qualified_model__ = qualified\n",
   "        previous = cls.model_class_reverse_map.get(qualified, None)\n",
   "        if previous is not None and not hasattr(cls, \"__implementation__\"):\n",
   "            raise Warning(f\"Duplicate qualified model declaration of '{qualified}'. Previous definition: {previous}\")\n",
   "        cls.model_class_reverse_map[qualified] = cls\n",
   "        obj =  super().__new__(cls)\n",
   "        obj._id = kwargs.pop(\"id\", make_id())\n",
   "        obj._document = None\n",
   "        obj._temp_document = None\n",
   "        return obj\n",
   "    name = String(help=\"\"\"\n",
   "        this = {\n",
   "            parts = this[\"type\"].split(\".\")\n",
   "            parts[-1] = self.__view_model__\n",
   "            this[\"type\"] = \".\".join(parts)\n",
   "            this[\"subtype\"] = self.__subtype__\n",
   "        return this\n",
   "            event = event.event_name\n",
   "        old_callbacks = self.js_event_callbacks.get(\"event\", [])\n",
   "        new_callbacks = [ callback for callback in callbacks if callback not in old_callbacks ]\n",
   "        self.js_event_callbacks[event] = old_callbacks + new_callbacks\n",
   "        selector = f\"[{attr_selector!r}]\" if attr_selector is not None else \"\"\n",
   "        cb = CustomJS(args=dict(other=other), code=f\"other.{other_attr} = this.{attr}{selector}\")\n",
   "        self.js_on_change(attr, cb)\n",
   "        if not all(isinstance(x, CustomJS) for x in callbacks):\n",
   "        if event in self.properties():\n",
   "            event = \"change:%s\" % event\n",
   "        old = {k: [cb for cb in cbs] for k, cbs in self.js_property_callbacks.items()}\n",
   "        if event not in self.js_property_callbacks:\n",
   "            self.js_property_callbacks[event] = []\n",
   "        for callback in callbacks:\n",
   "            if callback in self.js_property_callbacks[event]:\n",
   "            self.js_property_callbacks[event].append(callback)\n",
   "        self.trigger('js_property_callbacks', old, self.js_property_callbacks)\n",
   "        return set(collect_models(self))\n",
   "        return find(self.references(), selector)\n",
   "        result = list(self.select(selector))\n",
   "        if len(result) > 1:\n",
   "            raise ValueError(\"Found more than one object matching %s: %r\" % (selector, result))\n",
   "        if len(result) == 0:\n",
   "        return result[0]\n",
   "        if isclass(selector) and issubclass(selector, Model):\n",
   "            selector = dict(type=selector)\n",
   "        for obj in self.select(selector):\n",
   "            for key, val in updates.items():\n",
   "                setattr(obj, key, val)\n",
   "        json_like = self._to_json_like(include_defaults=include_defaults)\n",
   "        json_like['id'] = self.id\n",
   "        return serialize_json(json_like)\n",
   "            dirty = { 'count' : 0 }\n",
   "                dirty['count'] += 1\n",
   "                _visit_value_and_its_immediate_references(old, mark_dirty)\n",
   "                if dirty['count'] > 0:\n",
   "        super().trigger(attr, old, new, hint=hint, setter=setter)\n",
   "            k: v for k, v in Model.model_class_reverse_map.items()\n",
   "            if getattr(v, \"__implementation__\", None) is None\n",
   "                and getattr(v, \"__javascript__\", None) is None\n",
   "                and getattr(v, \"__css__\", None) is None\n",
   "        all_attrs = self.properties_with_values(include_defaults=include_defaults)\n",
   "        subtype = getattr(self.__class__, \"__subtype__\", None)\n",
   "        if subtype is not None and subtype != self.__class__.__view_model__:\n",
   "            attrs = {}\n",
   "            for attr, value in all_attrs.items():\n",
   "                if attr in self.__class__.__dict__:\n",
   "                    attrs[attr] = value\n",
   "            attrs = all_attrs\n",
   "        for (k, v) in attrs.items():\n",
   "            if isinstance(v, float) and v == float('inf'):\n",
   "                attrs[k] = None\n",
   "        return attrs\n",
   "        module = self.__class__.__module__\n",
   "        name = self.__class__.__name__\n",
   "        _id = getattr(self, \"_id\", None)\n",
   "        cls_name = make_id()\n",
   "        def row(c):\n",
   "        def hidden_row(c):\n",
   "            return '<div class=\"%s\" style=\"display: none;\">%s</div>' % (cls_name, c)\n",
   "        def cell(c):\n",
   "            return '<div style=\"display: table-cell;\">' + c + '</div>'\n",
   "        html = ''\n",
   "        html += '<div style=\"display: table;\">'\n",
   "        ellipsis_id = make_id()\n",
   "        ellipsis = '<span id=\"%s\" style=\"cursor: pointer;\">&hellip;)</span>' % ellipsis_id\n",
   "        prefix = cell('<b title=\"%s.%s\">%s</b>(' % (module, name, name))\n",
   "        html += row(prefix + cell('id' + '&nbsp;=&nbsp;' + repr(_id) + ', ' + ellipsis))\n",
   "        props = self.properties_with_values().items()\n",
   "        sorted_props = sorted(props, key=itemgetter(0))\n",
   "        all_props = sorted_props\n",
   "        for i, (prop, value) in enumerate(all_props):\n",
   "            end = ')' if i == len(all_props)-1 else ','\n",
   "            html += hidden_row(cell(\"\") + cell(prop + '&nbsp;=&nbsp;' + repr(value) + end))\n",
   "        html += '</div>'\n",
   "        html += _HTML_REPR % dict(ellipsis_id=ellipsis_id, cls_name=cls_name)\n",
   "        return html\n",
   "    if isinstance(value, HasProps):\n",
   "        for attr in value.properties_with_refs():\n",
   "            child = getattr(value, attr)\n",
   "            _visit_value_and_its_immediate_references(child, visitor)\n",
   "        _visit_value_and_its_immediate_references(value, visitor)\n",
   "    typ = type(obj)\n",
   "    if typ in _common_types:  # short circuit on common base types\n",
   "    if typ is list or issubclass(typ, (list, tuple)):  # check common containers\n",
   "        for item in obj:\n",
   "            _visit_value_and_its_immediate_references(item, visitor)\n",
   "    elif issubclass(typ, dict):\n",
   "        for key, value in obj.items():\n",
   "            _visit_value_and_its_immediate_references(key, visitor)\n",
   "            _visit_value_and_its_immediate_references(value, visitor)\n",
   "    elif issubclass(typ, HasProps):\n",
   "        if issubclass(typ, Model):\n",
   "            visitor(obj)\n",
   "            _visit_immediate_value_references(obj, visitor)\n"
  ]
 },
 "28": {
  "name": "qualified",
  "type": "str",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/model.py",
  "lineno": "195",
  "column": "12",
  "context": "ad == \"__main__\" or impl is not None:\n            qualified = model\n        else:\n            qualified = module + \".\"",
  "context_lines": "        model = cls.__dict__.get(\"__subtype__\", cls.__view_model__)\n        impl = cls.__dict__.get(\"__implementation__\", None)\n\n        head = module.split(\".\")[0]\n        if head == \"bokeh\" or head == \"__main__\" or impl is not None:\n            qualified = model\n        else:\n            qualified = module + \".\" + model\n\n        cls.__qualified_model__ = qualified\n\n        # update the mapping of view model names to classes, checking for any duplicates\n",
  "slicing": [
   "def collect_filtered_models(discard, *input_values):\n",
   "    ids = set()\n",
   "    collected = []\n",
   "    queued = []\n",
   "        if obj.id not in ids and not (callable(discard) and discard(obj)):\n",
   "            queued.append(obj)\n",
   "    for value in input_values:\n",
   "        _visit_value_and_its_immediate_references(value, queue_one)\n",
   "    while queued:\n",
   "        obj = queued.pop(0)\n",
   "        if obj.id not in ids:\n",
   "            ids.add(obj.id)\n",
   "            collected.append(obj)\n",
   "            _visit_immediate_value_references(obj, queue_one)\n",
   "    return collected\n",
   "def collect_models(*input_values):\n",
   "    return collect_filtered_models(None, *input_values)\n",
   "    d = Model.model_class_reverse_map\n",
   "    if view_model_name in d:\n",
   "        return d[view_model_name]\n",
   "_HTML_REPR = \"\"\"\n",
   "        module = cls.__view_module__\n",
   "        model = cls.__dict__.get(\"__subtype__\", cls.__view_model__)\n",
   "        impl = cls.__dict__.get(\"__implementation__\", None)\n",
   "        head = module.split(\".\")[0]\n",
   "        if head == \"bokeh\" or head == \"__main__\" or impl is not None:\n",
   "            qualified = model\n",
   "            qualified = module + \".\" + model\n",
   "        cls.__qualified_model__ = qualified\n",
   "        previous = cls.model_class_reverse_map.get(qualified, None)\n",
   "        if previous is not None and not hasattr(cls, \"__implementation__\"):\n",
   "            raise Warning(f\"Duplicate qualified model declaration of '{qualified}'. Previous definition: {previous}\")\n",
   "        cls.model_class_reverse_map[qualified] = cls\n",
   "        obj =  super().__new__(cls)\n",
   "        obj._id = kwargs.pop(\"id\", make_id())\n",
   "        obj._document = None\n",
   "        obj._temp_document = None\n",
   "        return obj\n",
   "    name = String(help=\"\"\"\n",
   "        this = {\n",
   "            parts = this[\"type\"].split(\".\")\n",
   "            parts[-1] = self.__view_model__\n",
   "            this[\"type\"] = \".\".join(parts)\n",
   "            this[\"subtype\"] = self.__subtype__\n",
   "        return this\n",
   "            event = event.event_name\n",
   "        old_callbacks = self.js_event_callbacks.get(\"event\", [])\n",
   "        new_callbacks = [ callback for callback in callbacks if callback not in old_callbacks ]\n",
   "        self.js_event_callbacks[event] = old_callbacks + new_callbacks\n",
   "        selector = f\"[{attr_selector!r}]\" if attr_selector is not None else \"\"\n",
   "        cb = CustomJS(args=dict(other=other), code=f\"other.{other_attr} = this.{attr}{selector}\")\n",
   "        self.js_on_change(attr, cb)\n",
   "        if not all(isinstance(x, CustomJS) for x in callbacks):\n",
   "        if event in self.properties():\n",
   "            event = \"change:%s\" % event\n",
   "        old = {k: [cb for cb in cbs] for k, cbs in self.js_property_callbacks.items()}\n",
   "        if event not in self.js_property_callbacks:\n",
   "            self.js_property_callbacks[event] = []\n",
   "        for callback in callbacks:\n",
   "            if callback in self.js_property_callbacks[event]:\n",
   "            self.js_property_callbacks[event].append(callback)\n",
   "        self.trigger('js_property_callbacks', old, self.js_property_callbacks)\n",
   "        return set(collect_models(self))\n",
   "        return find(self.references(), selector)\n",
   "        result = list(self.select(selector))\n",
   "        if len(result) > 1:\n",
   "            raise ValueError(\"Found more than one object matching %s: %r\" % (selector, result))\n",
   "        if len(result) == 0:\n",
   "        return result[0]\n",
   "        if isclass(selector) and issubclass(selector, Model):\n",
   "            selector = dict(type=selector)\n",
   "        for obj in self.select(selector):\n",
   "            for key, val in updates.items():\n",
   "                setattr(obj, key, val)\n",
   "        json_like = self._to_json_like(include_defaults=include_defaults)\n",
   "        json_like['id'] = self.id\n",
   "        return serialize_json(json_like)\n",
   "            dirty = { 'count' : 0 }\n",
   "                dirty['count'] += 1\n",
   "                _visit_value_and_its_immediate_references(old, mark_dirty)\n",
   "                if dirty['count'] > 0:\n",
   "        super().trigger(attr, old, new, hint=hint, setter=setter)\n",
   "            k: v for k, v in Model.model_class_reverse_map.items()\n",
   "            if getattr(v, \"__implementation__\", None) is None\n",
   "                and getattr(v, \"__javascript__\", None) is None\n",
   "                and getattr(v, \"__css__\", None) is None\n",
   "        all_attrs = self.properties_with_values(include_defaults=include_defaults)\n",
   "        subtype = getattr(self.__class__, \"__subtype__\", None)\n",
   "        if subtype is not None and subtype != self.__class__.__view_model__:\n",
   "            attrs = {}\n",
   "            for attr, value in all_attrs.items():\n",
   "                if attr in self.__class__.__dict__:\n",
   "                    attrs[attr] = value\n",
   "            attrs = all_attrs\n",
   "        for (k, v) in attrs.items():\n",
   "            if isinstance(v, float) and v == float('inf'):\n",
   "                attrs[k] = None\n",
   "        return attrs\n",
   "        module = self.__class__.__module__\n",
   "        name = self.__class__.__name__\n",
   "        _id = getattr(self, \"_id\", None)\n",
   "        cls_name = make_id()\n",
   "        def row(c):\n",
   "        def hidden_row(c):\n",
   "            return '<div class=\"%s\" style=\"display: none;\">%s</div>' % (cls_name, c)\n",
   "        def cell(c):\n",
   "            return '<div style=\"display: table-cell;\">' + c + '</div>'\n",
   "        html = ''\n",
   "        html += '<div style=\"display: table;\">'\n",
   "        ellipsis_id = make_id()\n",
   "        ellipsis = '<span id=\"%s\" style=\"cursor: pointer;\">&hellip;)</span>' % ellipsis_id\n",
   "        prefix = cell('<b title=\"%s.%s\">%s</b>(' % (module, name, name))\n",
   "        html += row(prefix + cell('id' + '&nbsp;=&nbsp;' + repr(_id) + ', ' + ellipsis))\n",
   "        props = self.properties_with_values().items()\n",
   "        sorted_props = sorted(props, key=itemgetter(0))\n",
   "        all_props = sorted_props\n",
   "        for i, (prop, value) in enumerate(all_props):\n",
   "            end = ')' if i == len(all_props)-1 else ','\n",
   "            html += hidden_row(cell(\"\") + cell(prop + '&nbsp;=&nbsp;' + repr(value) + end))\n",
   "        html += '</div>'\n",
   "        html += _HTML_REPR % dict(ellipsis_id=ellipsis_id, cls_name=cls_name)\n",
   "        return html\n",
   "    if isinstance(value, HasProps):\n",
   "        for attr in value.properties_with_refs():\n",
   "            child = getattr(value, attr)\n",
   "            _visit_value_and_its_immediate_references(child, visitor)\n",
   "        _visit_value_and_its_immediate_references(value, visitor)\n",
   "    typ = type(obj)\n",
   "    if typ in _common_types:  # short circuit on common base types\n",
   "    if typ is list or issubclass(typ, (list, tuple)):  # check common containers\n",
   "        for item in obj:\n",
   "            _visit_value_and_its_immediate_references(item, visitor)\n",
   "    elif issubclass(typ, dict):\n",
   "        for key, value in obj.items():\n",
   "            _visit_value_and_its_immediate_references(key, visitor)\n",
   "            _visit_value_and_its_immediate_references(value, visitor)\n",
   "    elif issubclass(typ, HasProps):\n",
   "        if issubclass(typ, Model):\n",
   "            visitor(obj)\n",
   "            _visit_immediate_value_references(obj, visitor)\n"
  ]
 },
 "29": {
  "name": "previous",
  "type": "NoneType",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/model.py",
  "lineno": "203",
  "column": "8",
  "context": "e relationships or custom implementations\n        previous = cls.model_class_reverse_map.get(qualified, None)\n        if previous is not None and not hasattr(cl",
  "context_lines": "            qualified = module + \".\" + model\n\n        cls.__qualified_model__ = qualified\n\n        # update the mapping of view model names to classes, checking for any duplicates\n        # and handling any subtype relationships or custom implementations\n        previous = cls.model_class_reverse_map.get(qualified, None)\n        if previous is not None and not hasattr(cls, \"__implementation__\"):\n            raise Warning(f\"Duplicate qualified model declaration of '{qualified}'. Previous definition: {previous}\")\n        cls.model_class_reverse_map[qualified] = cls\n\n    def __new__(cls, *args, **kwargs):\n",
  "slicing": [
   "def collect_filtered_models(discard, *input_values):\n",
   "    ids = set()\n",
   "    collected = []\n",
   "    queued = []\n",
   "        if obj.id not in ids and not (callable(discard) and discard(obj)):\n",
   "            queued.append(obj)\n",
   "    for value in input_values:\n",
   "        _visit_value_and_its_immediate_references(value, queue_one)\n",
   "    while queued:\n",
   "        obj = queued.pop(0)\n",
   "        if obj.id not in ids:\n",
   "            ids.add(obj.id)\n",
   "            collected.append(obj)\n",
   "            _visit_immediate_value_references(obj, queue_one)\n",
   "    return collected\n",
   "def collect_models(*input_values):\n",
   "    return collect_filtered_models(None, *input_values)\n",
   "    d = Model.model_class_reverse_map\n",
   "    if view_model_name in d:\n",
   "        return d[view_model_name]\n",
   "_HTML_REPR = \"\"\"\n",
   "        module = cls.__view_module__\n",
   "        model = cls.__dict__.get(\"__subtype__\", cls.__view_model__)\n",
   "        impl = cls.__dict__.get(\"__implementation__\", None)\n",
   "        head = module.split(\".\")[0]\n",
   "        if head == \"bokeh\" or head == \"__main__\" or impl is not None:\n",
   "            qualified = model\n",
   "            qualified = module + \".\" + model\n",
   "        cls.__qualified_model__ = qualified\n",
   "        previous = cls.model_class_reverse_map.get(qualified, None)\n",
   "        if previous is not None and not hasattr(cls, \"__implementation__\"):\n",
   "            raise Warning(f\"Duplicate qualified model declaration of '{qualified}'. Previous definition: {previous}\")\n",
   "        cls.model_class_reverse_map[qualified] = cls\n",
   "        obj =  super().__new__(cls)\n",
   "        obj._id = kwargs.pop(\"id\", make_id())\n",
   "        obj._document = None\n",
   "        obj._temp_document = None\n",
   "        return obj\n",
   "    name = String(help=\"\"\"\n",
   "        this = {\n",
   "            parts = this[\"type\"].split(\".\")\n",
   "            parts[-1] = self.__view_model__\n",
   "            this[\"type\"] = \".\".join(parts)\n",
   "            this[\"subtype\"] = self.__subtype__\n",
   "        return this\n",
   "            event = event.event_name\n",
   "        old_callbacks = self.js_event_callbacks.get(\"event\", [])\n",
   "        new_callbacks = [ callback for callback in callbacks if callback not in old_callbacks ]\n",
   "        self.js_event_callbacks[event] = old_callbacks + new_callbacks\n",
   "        selector = f\"[{attr_selector!r}]\" if attr_selector is not None else \"\"\n",
   "        cb = CustomJS(args=dict(other=other), code=f\"other.{other_attr} = this.{attr}{selector}\")\n",
   "        self.js_on_change(attr, cb)\n",
   "        if not all(isinstance(x, CustomJS) for x in callbacks):\n",
   "        if event in self.properties():\n",
   "            event = \"change:%s\" % event\n",
   "        old = {k: [cb for cb in cbs] for k, cbs in self.js_property_callbacks.items()}\n",
   "        if event not in self.js_property_callbacks:\n",
   "            self.js_property_callbacks[event] = []\n",
   "        for callback in callbacks:\n",
   "            if callback in self.js_property_callbacks[event]:\n",
   "            self.js_property_callbacks[event].append(callback)\n",
   "        self.trigger('js_property_callbacks', old, self.js_property_callbacks)\n",
   "        return set(collect_models(self))\n",
   "        return find(self.references(), selector)\n",
   "        result = list(self.select(selector))\n",
   "        if len(result) > 1:\n",
   "            raise ValueError(\"Found more than one object matching %s: %r\" % (selector, result))\n",
   "        if len(result) == 0:\n",
   "        return result[0]\n",
   "        if isclass(selector) and issubclass(selector, Model):\n",
   "            selector = dict(type=selector)\n",
   "        for obj in self.select(selector):\n",
   "            for key, val in updates.items():\n",
   "                setattr(obj, key, val)\n",
   "        json_like = self._to_json_like(include_defaults=include_defaults)\n",
   "        json_like['id'] = self.id\n",
   "        return serialize_json(json_like)\n",
   "            dirty = { 'count' : 0 }\n",
   "                dirty['count'] += 1\n",
   "                _visit_value_and_its_immediate_references(old, mark_dirty)\n",
   "                if dirty['count'] > 0:\n",
   "        super().trigger(attr, old, new, hint=hint, setter=setter)\n",
   "            k: v for k, v in Model.model_class_reverse_map.items()\n",
   "            if getattr(v, \"__implementation__\", None) is None\n",
   "                and getattr(v, \"__javascript__\", None) is None\n",
   "                and getattr(v, \"__css__\", None) is None\n",
   "        all_attrs = self.properties_with_values(include_defaults=include_defaults)\n",
   "        subtype = getattr(self.__class__, \"__subtype__\", None)\n",
   "        if subtype is not None and subtype != self.__class__.__view_model__:\n",
   "            attrs = {}\n",
   "            for attr, value in all_attrs.items():\n",
   "                if attr in self.__class__.__dict__:\n",
   "                    attrs[attr] = value\n",
   "            attrs = all_attrs\n",
   "        for (k, v) in attrs.items():\n",
   "            if isinstance(v, float) and v == float('inf'):\n",
   "                attrs[k] = None\n",
   "        return attrs\n",
   "        module = self.__class__.__module__\n",
   "        name = self.__class__.__name__\n",
   "        _id = getattr(self, \"_id\", None)\n",
   "        cls_name = make_id()\n",
   "        def row(c):\n",
   "        def hidden_row(c):\n",
   "            return '<div class=\"%s\" style=\"display: none;\">%s</div>' % (cls_name, c)\n",
   "        def cell(c):\n",
   "            return '<div style=\"display: table-cell;\">' + c + '</div>'\n",
   "        html = ''\n",
   "        html += '<div style=\"display: table;\">'\n",
   "        ellipsis_id = make_id()\n",
   "        ellipsis = '<span id=\"%s\" style=\"cursor: pointer;\">&hellip;)</span>' % ellipsis_id\n",
   "        prefix = cell('<b title=\"%s.%s\">%s</b>(' % (module, name, name))\n",
   "        html += row(prefix + cell('id' + '&nbsp;=&nbsp;' + repr(_id) + ', ' + ellipsis))\n",
   "        props = self.properties_with_values().items()\n",
   "        sorted_props = sorted(props, key=itemgetter(0))\n",
   "        all_props = sorted_props\n",
   "        for i, (prop, value) in enumerate(all_props):\n",
   "            end = ')' if i == len(all_props)-1 else ','\n",
   "            html += hidden_row(cell(\"\") + cell(prop + '&nbsp;=&nbsp;' + repr(value) + end))\n",
   "        html += '</div>'\n",
   "        html += _HTML_REPR % dict(ellipsis_id=ellipsis_id, cls_name=cls_name)\n",
   "        return html\n",
   "    if isinstance(value, HasProps):\n",
   "        for attr in value.properties_with_refs():\n",
   "            child = getattr(value, attr)\n",
   "            _visit_value_and_its_immediate_references(child, visitor)\n",
   "        _visit_value_and_its_immediate_references(value, visitor)\n",
   "    typ = type(obj)\n",
   "    if typ in _common_types:  # short circuit on common base types\n",
   "    if typ is list or issubclass(typ, (list, tuple)):  # check common containers\n",
   "        for item in obj:\n",
   "            _visit_value_and_its_immediate_references(item, visitor)\n",
   "    elif issubclass(typ, dict):\n",
   "        for key, value in obj.items():\n",
   "            _visit_value_and_its_immediate_references(key, visitor)\n",
   "            _visit_value_and_its_immediate_references(value, visitor)\n",
   "    elif issubclass(typ, HasProps):\n",
   "        if issubclass(typ, Model):\n",
   "            visitor(obj)\n",
   "            _visit_immediate_value_references(obj, visitor)\n"
  ]
 },
 "30": {
  "name": "qualified",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/model.py",
  "lineno": "197",
  "column": "12",
  "context": "      qualified = model\n        else:\n            qualified = module + \".\" + model\n\n        cls.__qualified_model__ = qualified\n\n    ",
  "context_lines": "        head = module.split(\".\")[0]\n        if head == \"bokeh\" or head == \"__main__\" or impl is not None:\n            qualified = model\n        else:\n            qualified = module + \".\" + model\n\n        cls.__qualified_model__ = qualified\n\n        # update the mapping of view model names to classes, checking for any duplicates\n        # and handling any subtype relationships or custom implementations\n",
  "slicing": [
   "def collect_filtered_models(discard, *input_values):\n",
   "    ids = set()\n",
   "    collected = []\n",
   "    queued = []\n",
   "        if obj.id not in ids and not (callable(discard) and discard(obj)):\n",
   "            queued.append(obj)\n",
   "    for value in input_values:\n",
   "        _visit_value_and_its_immediate_references(value, queue_one)\n",
   "    while queued:\n",
   "        obj = queued.pop(0)\n",
   "        if obj.id not in ids:\n",
   "            ids.add(obj.id)\n",
   "            collected.append(obj)\n",
   "            _visit_immediate_value_references(obj, queue_one)\n",
   "    return collected\n",
   "def collect_models(*input_values):\n",
   "    return collect_filtered_models(None, *input_values)\n",
   "    d = Model.model_class_reverse_map\n",
   "    if view_model_name in d:\n",
   "        return d[view_model_name]\n",
   "_HTML_REPR = \"\"\"\n",
   "        module = cls.__view_module__\n",
   "        model = cls.__dict__.get(\"__subtype__\", cls.__view_model__)\n",
   "        impl = cls.__dict__.get(\"__implementation__\", None)\n",
   "        head = module.split(\".\")[0]\n",
   "        if head == \"bokeh\" or head == \"__main__\" or impl is not None:\n",
   "            qualified = model\n",
   "            qualified = module + \".\" + model\n",
   "        cls.__qualified_model__ = qualified\n",
   "        previous = cls.model_class_reverse_map.get(qualified, None)\n",
   "        if previous is not None and not hasattr(cls, \"__implementation__\"):\n",
   "            raise Warning(f\"Duplicate qualified model declaration of '{qualified}'. Previous definition: {previous}\")\n",
   "        cls.model_class_reverse_map[qualified] = cls\n",
   "        obj =  super().__new__(cls)\n",
   "        obj._id = kwargs.pop(\"id\", make_id())\n",
   "        obj._document = None\n",
   "        obj._temp_document = None\n",
   "        return obj\n",
   "    name = String(help=\"\"\"\n",
   "        this = {\n",
   "            parts = this[\"type\"].split(\".\")\n",
   "            parts[-1] = self.__view_model__\n",
   "            this[\"type\"] = \".\".join(parts)\n",
   "            this[\"subtype\"] = self.__subtype__\n",
   "        return this\n",
   "            event = event.event_name\n",
   "        old_callbacks = self.js_event_callbacks.get(\"event\", [])\n",
   "        new_callbacks = [ callback for callback in callbacks if callback not in old_callbacks ]\n",
   "        self.js_event_callbacks[event] = old_callbacks + new_callbacks\n",
   "        selector = f\"[{attr_selector!r}]\" if attr_selector is not None else \"\"\n",
   "        cb = CustomJS(args=dict(other=other), code=f\"other.{other_attr} = this.{attr}{selector}\")\n",
   "        self.js_on_change(attr, cb)\n",
   "        if not all(isinstance(x, CustomJS) for x in callbacks):\n",
   "        if event in self.properties():\n",
   "            event = \"change:%s\" % event\n",
   "        old = {k: [cb for cb in cbs] for k, cbs in self.js_property_callbacks.items()}\n",
   "        if event not in self.js_property_callbacks:\n",
   "            self.js_property_callbacks[event] = []\n",
   "        for callback in callbacks:\n",
   "            if callback in self.js_property_callbacks[event]:\n",
   "            self.js_property_callbacks[event].append(callback)\n",
   "        self.trigger('js_property_callbacks', old, self.js_property_callbacks)\n",
   "        return set(collect_models(self))\n",
   "        return find(self.references(), selector)\n",
   "        result = list(self.select(selector))\n",
   "        if len(result) > 1:\n",
   "            raise ValueError(\"Found more than one object matching %s: %r\" % (selector, result))\n",
   "        if len(result) == 0:\n",
   "        return result[0]\n",
   "        if isclass(selector) and issubclass(selector, Model):\n",
   "            selector = dict(type=selector)\n",
   "        for obj in self.select(selector):\n",
   "            for key, val in updates.items():\n",
   "                setattr(obj, key, val)\n",
   "        json_like = self._to_json_like(include_defaults=include_defaults)\n",
   "        json_like['id'] = self.id\n",
   "        return serialize_json(json_like)\n",
   "            dirty = { 'count' : 0 }\n",
   "                dirty['count'] += 1\n",
   "                _visit_value_and_its_immediate_references(old, mark_dirty)\n",
   "                if dirty['count'] > 0:\n",
   "        super().trigger(attr, old, new, hint=hint, setter=setter)\n",
   "            k: v for k, v in Model.model_class_reverse_map.items()\n",
   "            if getattr(v, \"__implementation__\", None) is None\n",
   "                and getattr(v, \"__javascript__\", None) is None\n",
   "                and getattr(v, \"__css__\", None) is None\n",
   "        all_attrs = self.properties_with_values(include_defaults=include_defaults)\n",
   "        subtype = getattr(self.__class__, \"__subtype__\", None)\n",
   "        if subtype is not None and subtype != self.__class__.__view_model__:\n",
   "            attrs = {}\n",
   "            for attr, value in all_attrs.items():\n",
   "                if attr in self.__class__.__dict__:\n",
   "                    attrs[attr] = value\n",
   "            attrs = all_attrs\n",
   "        for (k, v) in attrs.items():\n",
   "            if isinstance(v, float) and v == float('inf'):\n",
   "                attrs[k] = None\n",
   "        return attrs\n",
   "        module = self.__class__.__module__\n",
   "        name = self.__class__.__name__\n",
   "        _id = getattr(self, \"_id\", None)\n",
   "        cls_name = make_id()\n",
   "        def row(c):\n",
   "        def hidden_row(c):\n",
   "            return '<div class=\"%s\" style=\"display: none;\">%s</div>' % (cls_name, c)\n",
   "        def cell(c):\n",
   "            return '<div style=\"display: table-cell;\">' + c + '</div>'\n",
   "        html = ''\n",
   "        html += '<div style=\"display: table;\">'\n",
   "        ellipsis_id = make_id()\n",
   "        ellipsis = '<span id=\"%s\" style=\"cursor: pointer;\">&hellip;)</span>' % ellipsis_id\n",
   "        prefix = cell('<b title=\"%s.%s\">%s</b>(' % (module, name, name))\n",
   "        html += row(prefix + cell('id' + '&nbsp;=&nbsp;' + repr(_id) + ', ' + ellipsis))\n",
   "        props = self.properties_with_values().items()\n",
   "        sorted_props = sorted(props, key=itemgetter(0))\n",
   "        all_props = sorted_props\n",
   "        for i, (prop, value) in enumerate(all_props):\n",
   "            end = ')' if i == len(all_props)-1 else ','\n",
   "            html += hidden_row(cell(\"\") + cell(prop + '&nbsp;=&nbsp;' + repr(value) + end))\n",
   "        html += '</div>'\n",
   "        html += _HTML_REPR % dict(ellipsis_id=ellipsis_id, cls_name=cls_name)\n",
   "        return html\n",
   "    if isinstance(value, HasProps):\n",
   "        for attr in value.properties_with_refs():\n",
   "            child = getattr(value, attr)\n",
   "            _visit_value_and_its_immediate_references(child, visitor)\n",
   "        _visit_value_and_its_immediate_references(value, visitor)\n",
   "    typ = type(obj)\n",
   "    if typ in _common_types:  # short circuit on common base types\n",
   "    if typ is list or issubclass(typ, (list, tuple)):  # check common containers\n",
   "        for item in obj:\n",
   "            _visit_value_and_its_immediate_references(item, visitor)\n",
   "    elif issubclass(typ, dict):\n",
   "        for key, value in obj.items():\n",
   "            _visit_value_and_its_immediate_references(key, visitor)\n",
   "            _visit_value_and_its_immediate_references(value, visitor)\n",
   "    elif issubclass(typ, HasProps):\n",
   "        if issubclass(typ, Model):\n",
   "            visitor(obj)\n",
   "            _visit_immediate_value_references(obj, visitor)\n"
  ]
 },
 "31": {
  "name": "obj",
  "type": "LinearAxis",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/model.py",
  "lineno": "209",
  "column": "8",
  "context": "s\n\n    def __new__(cls, *args, **kwargs):\n        obj =  super().__new__(cls)\n        obj._id = kwargs.pop(\"id\", make_id())\n    ",
  "context_lines": "        if previous is not None and not hasattr(cls, \"__implementation__\"):\n            raise Warning(f\"Duplicate qualified model declaration of '{qualified}'. Previous definition: {previous}\")\n        cls.model_class_reverse_map[qualified] = cls\n\n    def __new__(cls, *args, **kwargs):\n        obj =  super().__new__(cls)\n        obj._id = kwargs.pop(\"id\", make_id())\n        obj._document = None\n        obj._temp_document = None\n        return obj\n\n",
  "slicing": [
   "def collect_filtered_models(discard, *input_values):\n",
   "    ids = set()\n",
   "    collected = []\n",
   "    queued = []\n",
   "        if obj.id not in ids and not (callable(discard) and discard(obj)):\n",
   "            queued.append(obj)\n",
   "    for value in input_values:\n",
   "        _visit_value_and_its_immediate_references(value, queue_one)\n",
   "    while queued:\n",
   "        obj = queued.pop(0)\n",
   "        if obj.id not in ids:\n",
   "            ids.add(obj.id)\n",
   "            collected.append(obj)\n",
   "            _visit_immediate_value_references(obj, queue_one)\n",
   "    return collected\n",
   "def collect_models(*input_values):\n",
   "    return collect_filtered_models(None, *input_values)\n",
   "    d = Model.model_class_reverse_map\n",
   "    if view_model_name in d:\n",
   "        return d[view_model_name]\n",
   "_HTML_REPR = \"\"\"\n",
   "        module = cls.__view_module__\n",
   "        model = cls.__dict__.get(\"__subtype__\", cls.__view_model__)\n",
   "        impl = cls.__dict__.get(\"__implementation__\", None)\n",
   "        head = module.split(\".\")[0]\n",
   "        if head == \"bokeh\" or head == \"__main__\" or impl is not None:\n",
   "            qualified = model\n",
   "            qualified = module + \".\" + model\n",
   "        cls.__qualified_model__ = qualified\n",
   "        previous = cls.model_class_reverse_map.get(qualified, None)\n",
   "        if previous is not None and not hasattr(cls, \"__implementation__\"):\n",
   "            raise Warning(f\"Duplicate qualified model declaration of '{qualified}'. Previous definition: {previous}\")\n",
   "        cls.model_class_reverse_map[qualified] = cls\n",
   "        obj =  super().__new__(cls)\n",
   "        obj._id = kwargs.pop(\"id\", make_id())\n",
   "        obj._document = None\n",
   "        obj._temp_document = None\n",
   "        return obj\n",
   "    name = String(help=\"\"\"\n",
   "        this = {\n",
   "            parts = this[\"type\"].split(\".\")\n",
   "            parts[-1] = self.__view_model__\n",
   "            this[\"type\"] = \".\".join(parts)\n",
   "            this[\"subtype\"] = self.__subtype__\n",
   "        return this\n",
   "            event = event.event_name\n",
   "        old_callbacks = self.js_event_callbacks.get(\"event\", [])\n",
   "        new_callbacks = [ callback for callback in callbacks if callback not in old_callbacks ]\n",
   "        self.js_event_callbacks[event] = old_callbacks + new_callbacks\n",
   "        selector = f\"[{attr_selector!r}]\" if attr_selector is not None else \"\"\n",
   "        cb = CustomJS(args=dict(other=other), code=f\"other.{other_attr} = this.{attr}{selector}\")\n",
   "        self.js_on_change(attr, cb)\n",
   "        if not all(isinstance(x, CustomJS) for x in callbacks):\n",
   "        if event in self.properties():\n",
   "            event = \"change:%s\" % event\n",
   "        old = {k: [cb for cb in cbs] for k, cbs in self.js_property_callbacks.items()}\n",
   "        if event not in self.js_property_callbacks:\n",
   "            self.js_property_callbacks[event] = []\n",
   "        for callback in callbacks:\n",
   "            if callback in self.js_property_callbacks[event]:\n",
   "            self.js_property_callbacks[event].append(callback)\n",
   "        self.trigger('js_property_callbacks', old, self.js_property_callbacks)\n",
   "        return set(collect_models(self))\n",
   "        return find(self.references(), selector)\n",
   "        result = list(self.select(selector))\n",
   "        if len(result) > 1:\n",
   "            raise ValueError(\"Found more than one object matching %s: %r\" % (selector, result))\n",
   "        if len(result) == 0:\n",
   "        return result[0]\n",
   "        if isclass(selector) and issubclass(selector, Model):\n",
   "            selector = dict(type=selector)\n",
   "        for obj in self.select(selector):\n",
   "            for key, val in updates.items():\n",
   "                setattr(obj, key, val)\n",
   "        json_like = self._to_json_like(include_defaults=include_defaults)\n",
   "        json_like['id'] = self.id\n",
   "        return serialize_json(json_like)\n",
   "            dirty = { 'count' : 0 }\n",
   "                dirty['count'] += 1\n",
   "                _visit_value_and_its_immediate_references(old, mark_dirty)\n",
   "                if dirty['count'] > 0:\n",
   "        super().trigger(attr, old, new, hint=hint, setter=setter)\n",
   "            k: v for k, v in Model.model_class_reverse_map.items()\n",
   "            if getattr(v, \"__implementation__\", None) is None\n",
   "                and getattr(v, \"__javascript__\", None) is None\n",
   "                and getattr(v, \"__css__\", None) is None\n",
   "        all_attrs = self.properties_with_values(include_defaults=include_defaults)\n",
   "        subtype = getattr(self.__class__, \"__subtype__\", None)\n",
   "        if subtype is not None and subtype != self.__class__.__view_model__:\n",
   "            attrs = {}\n",
   "            for attr, value in all_attrs.items():\n",
   "                if attr in self.__class__.__dict__:\n",
   "                    attrs[attr] = value\n",
   "            attrs = all_attrs\n",
   "        for (k, v) in attrs.items():\n",
   "            if isinstance(v, float) and v == float('inf'):\n",
   "                attrs[k] = None\n",
   "        return attrs\n",
   "        module = self.__class__.__module__\n",
   "        name = self.__class__.__name__\n",
   "        _id = getattr(self, \"_id\", None)\n",
   "        cls_name = make_id()\n",
   "        def row(c):\n",
   "        def hidden_row(c):\n",
   "            return '<div class=\"%s\" style=\"display: none;\">%s</div>' % (cls_name, c)\n",
   "        def cell(c):\n",
   "            return '<div style=\"display: table-cell;\">' + c + '</div>'\n",
   "        html = ''\n",
   "        html += '<div style=\"display: table;\">'\n",
   "        ellipsis_id = make_id()\n",
   "        ellipsis = '<span id=\"%s\" style=\"cursor: pointer;\">&hellip;)</span>' % ellipsis_id\n",
   "        prefix = cell('<b title=\"%s.%s\">%s</b>(' % (module, name, name))\n",
   "        html += row(prefix + cell('id' + '&nbsp;=&nbsp;' + repr(_id) + ', ' + ellipsis))\n",
   "        props = self.properties_with_values().items()\n",
   "        sorted_props = sorted(props, key=itemgetter(0))\n",
   "        all_props = sorted_props\n",
   "        for i, (prop, value) in enumerate(all_props):\n",
   "            end = ')' if i == len(all_props)-1 else ','\n",
   "            html += hidden_row(cell(\"\") + cell(prop + '&nbsp;=&nbsp;' + repr(value) + end))\n",
   "        html += '</div>'\n",
   "        html += _HTML_REPR % dict(ellipsis_id=ellipsis_id, cls_name=cls_name)\n",
   "        return html\n",
   "    if isinstance(value, HasProps):\n",
   "        for attr in value.properties_with_refs():\n",
   "            child = getattr(value, attr)\n",
   "            _visit_value_and_its_immediate_references(child, visitor)\n",
   "        _visit_value_and_its_immediate_references(value, visitor)\n",
   "    typ = type(obj)\n",
   "    if typ in _common_types:  # short circuit on common base types\n",
   "    if typ is list or issubclass(typ, (list, tuple)):  # check common containers\n",
   "        for item in obj:\n",
   "            _visit_value_and_its_immediate_references(item, visitor)\n",
   "    elif issubclass(typ, dict):\n",
   "        for key, value in obj.items():\n",
   "            _visit_value_and_its_immediate_references(key, visitor)\n",
   "            _visit_value_and_its_immediate_references(value, visitor)\n",
   "    elif issubclass(typ, HasProps):\n",
   "        if issubclass(typ, Model):\n",
   "            visitor(obj)\n",
   "            _visit_immediate_value_references(obj, visitor)\n"
  ]
 },
 "32": {
  "name": "__repr__",
  "type": "function",
  "class": "unknown",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/model.py",
  "lineno": "240",
  "column": "4",
  "context": "class__.__name__, getattr(self, \"id\", None))\n\n    __repr__ = __str__\n\n    @property\n    def id(self):\n        return se",
  "context_lines": "        super().__init__(**kwargs)\n        default_theme.apply_to_model(self)\n\n    def __str__(self):\n        return \"%s(id=%r, ...)\" % (self.__class__.__name__, getattr(self, \"id\", None))\n\n    __repr__ = __str__\n\n    @property\n    def id(self):\n        return self._id\n\n",
  "slicing": [
   "def collect_filtered_models(discard, *input_values):\n",
   "    ids = set()\n",
   "    collected = []\n",
   "    queued = []\n",
   "        if obj.id not in ids and not (callable(discard) and discard(obj)):\n",
   "            queued.append(obj)\n",
   "    for value in input_values:\n",
   "        _visit_value_and_its_immediate_references(value, queue_one)\n",
   "    while queued:\n",
   "        obj = queued.pop(0)\n",
   "        if obj.id not in ids:\n",
   "            ids.add(obj.id)\n",
   "            collected.append(obj)\n",
   "            _visit_immediate_value_references(obj, queue_one)\n",
   "    return collected\n",
   "def collect_models(*input_values):\n",
   "    return collect_filtered_models(None, *input_values)\n",
   "    d = Model.model_class_reverse_map\n",
   "    if view_model_name in d:\n",
   "        return d[view_model_name]\n",
   "_HTML_REPR = \"\"\"\n",
   "        module = cls.__view_module__\n",
   "        model = cls.__dict__.get(\"__subtype__\", cls.__view_model__)\n",
   "        impl = cls.__dict__.get(\"__implementation__\", None)\n",
   "        head = module.split(\".\")[0]\n",
   "        if head == \"bokeh\" or head == \"__main__\" or impl is not None:\n",
   "            qualified = model\n",
   "            qualified = module + \".\" + model\n",
   "        cls.__qualified_model__ = qualified\n",
   "        previous = cls.model_class_reverse_map.get(qualified, None)\n",
   "        if previous is not None and not hasattr(cls, \"__implementation__\"):\n",
   "            raise Warning(f\"Duplicate qualified model declaration of '{qualified}'. Previous definition: {previous}\")\n",
   "        cls.model_class_reverse_map[qualified] = cls\n",
   "        obj =  super().__new__(cls)\n",
   "        obj._id = kwargs.pop(\"id\", make_id())\n",
   "        obj._document = None\n",
   "        obj._temp_document = None\n",
   "        return obj\n",
   "    __repr__ = __str__\n",
   "    name = String(help=\"\"\"\n",
   "        this = {\n",
   "            parts = this[\"type\"].split(\".\")\n",
   "            parts[-1] = self.__view_model__\n",
   "            this[\"type\"] = \".\".join(parts)\n",
   "            this[\"subtype\"] = self.__subtype__\n",
   "        return this\n",
   "            event = event.event_name\n",
   "        old_callbacks = self.js_event_callbacks.get(\"event\", [])\n",
   "        new_callbacks = [ callback for callback in callbacks if callback not in old_callbacks ]\n",
   "        self.js_event_callbacks[event] = old_callbacks + new_callbacks\n",
   "        selector = f\"[{attr_selector!r}]\" if attr_selector is not None else \"\"\n",
   "        cb = CustomJS(args=dict(other=other), code=f\"other.{other_attr} = this.{attr}{selector}\")\n",
   "        self.js_on_change(attr, cb)\n",
   "        if not all(isinstance(x, CustomJS) for x in callbacks):\n",
   "        if event in self.properties():\n",
   "            event = \"change:%s\" % event\n",
   "        old = {k: [cb for cb in cbs] for k, cbs in self.js_property_callbacks.items()}\n",
   "        if event not in self.js_property_callbacks:\n",
   "            self.js_property_callbacks[event] = []\n",
   "        for callback in callbacks:\n",
   "            if callback in self.js_property_callbacks[event]:\n",
   "            self.js_property_callbacks[event].append(callback)\n",
   "        self.trigger('js_property_callbacks', old, self.js_property_callbacks)\n",
   "        return set(collect_models(self))\n",
   "        return find(self.references(), selector)\n",
   "        result = list(self.select(selector))\n",
   "        if len(result) > 1:\n",
   "            raise ValueError(\"Found more than one object matching %s: %r\" % (selector, result))\n",
   "        if len(result) == 0:\n",
   "        return result[0]\n",
   "        if isclass(selector) and issubclass(selector, Model):\n",
   "            selector = dict(type=selector)\n",
   "        for obj in self.select(selector):\n",
   "            for key, val in updates.items():\n",
   "                setattr(obj, key, val)\n",
   "        json_like = self._to_json_like(include_defaults=include_defaults)\n",
   "        json_like['id'] = self.id\n",
   "        return serialize_json(json_like)\n",
   "            dirty = { 'count' : 0 }\n",
   "                dirty['count'] += 1\n",
   "                _visit_value_and_its_immediate_references(old, mark_dirty)\n",
   "                if dirty['count'] > 0:\n",
   "        super().trigger(attr, old, new, hint=hint, setter=setter)\n",
   "            k: v for k, v in Model.model_class_reverse_map.items()\n",
   "            if getattr(v, \"__implementation__\", None) is None\n",
   "                and getattr(v, \"__javascript__\", None) is None\n",
   "                and getattr(v, \"__css__\", None) is None\n",
   "        all_attrs = self.properties_with_values(include_defaults=include_defaults)\n",
   "        subtype = getattr(self.__class__, \"__subtype__\", None)\n",
   "        if subtype is not None and subtype != self.__class__.__view_model__:\n",
   "            attrs = {}\n",
   "            for attr, value in all_attrs.items():\n",
   "                if attr in self.__class__.__dict__:\n",
   "                    attrs[attr] = value\n",
   "            attrs = all_attrs\n",
   "        for (k, v) in attrs.items():\n",
   "            if isinstance(v, float) and v == float('inf'):\n",
   "                attrs[k] = None\n",
   "        return attrs\n",
   "        module = self.__class__.__module__\n",
   "        name = self.__class__.__name__\n",
   "        _id = getattr(self, \"_id\", None)\n",
   "        cls_name = make_id()\n",
   "        def row(c):\n",
   "        def hidden_row(c):\n",
   "            return '<div class=\"%s\" style=\"display: none;\">%s</div>' % (cls_name, c)\n",
   "        def cell(c):\n",
   "            return '<div style=\"display: table-cell;\">' + c + '</div>'\n",
   "        html = ''\n",
   "        html += '<div style=\"display: table;\">'\n",
   "        ellipsis_id = make_id()\n",
   "        ellipsis = '<span id=\"%s\" style=\"cursor: pointer;\">&hellip;)</span>' % ellipsis_id\n",
   "        prefix = cell('<b title=\"%s.%s\">%s</b>(' % (module, name, name))\n",
   "        html += row(prefix + cell('id' + '&nbsp;=&nbsp;' + repr(_id) + ', ' + ellipsis))\n",
   "        props = self.properties_with_values().items()\n",
   "        sorted_props = sorted(props, key=itemgetter(0))\n",
   "        all_props = sorted_props\n",
   "        for i, (prop, value) in enumerate(all_props):\n",
   "            end = ')' if i == len(all_props)-1 else ','\n",
   "            html += hidden_row(cell(\"\") + cell(prop + '&nbsp;=&nbsp;' + repr(value) + end))\n",
   "        html += '</div>'\n",
   "        html += _HTML_REPR % dict(ellipsis_id=ellipsis_id, cls_name=cls_name)\n",
   "        return html\n",
   "    if isinstance(value, HasProps):\n",
   "        for attr in value.properties_with_refs():\n",
   "            child = getattr(value, attr)\n",
   "            _visit_value_and_its_immediate_references(child, visitor)\n",
   "        _visit_value_and_its_immediate_references(value, visitor)\n",
   "    typ = type(obj)\n",
   "    if typ in _common_types:  # short circuit on common base types\n",
   "    if typ is list or issubclass(typ, (list, tuple)):  # check common containers\n",
   "        for item in obj:\n",
   "            _visit_value_and_its_immediate_references(item, visitor)\n",
   "    elif issubclass(typ, dict):\n",
   "        for key, value in obj.items():\n",
   "            _visit_value_and_its_immediate_references(key, visitor)\n",
   "            _visit_value_and_its_immediate_references(value, visitor)\n",
   "    elif issubclass(typ, HasProps):\n",
   "        if issubclass(typ, Model):\n",
   "            visitor(obj)\n",
   "            _visit_immediate_value_references(obj, visitor)\n"
  ]
 },
 "33": {
  "name": "child",
  "type": "LinearAxis",
  "class": "customized",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/model.py",
  "lineno": "786",
  "column": "12",
  "context": "attr in value.properties_with_refs():\n            child = getattr(value, attr)\n            _visit_value_and_its_immediate_referen",
  "context_lines": "    it's referenced more than once. Does not visit the passed-in value.\n\n    '''\n    if isinstance(value, HasProps):\n        for attr in value.properties_with_refs():\n            child = getattr(value, attr)\n            _visit_value_and_its_immediate_references(child, visitor)\n    else:\n        _visit_value_and_its_immediate_references(value, visitor)\n\n\n_common_types = {int, float, str}\n\n",
  "slicing": [
   "def collect_filtered_models(discard, *input_values):\n",
   "    ids = set()\n",
   "    collected = []\n",
   "    queued = []\n",
   "        if obj.id not in ids and not (callable(discard) and discard(obj)):\n",
   "            queued.append(obj)\n",
   "    for value in input_values:\n",
   "        _visit_value_and_its_immediate_references(value, queue_one)\n",
   "    while queued:\n",
   "        obj = queued.pop(0)\n",
   "        if obj.id not in ids:\n",
   "            ids.add(obj.id)\n",
   "            collected.append(obj)\n",
   "            _visit_immediate_value_references(obj, queue_one)\n",
   "    return collected\n",
   "def collect_models(*input_values):\n",
   "    return collect_filtered_models(None, *input_values)\n",
   "    d = Model.model_class_reverse_map\n",
   "    if view_model_name in d:\n",
   "        return d[view_model_name]\n",
   "_HTML_REPR = \"\"\"\n",
   "        module = cls.__view_module__\n",
   "        model = cls.__dict__.get(\"__subtype__\", cls.__view_model__)\n",
   "        impl = cls.__dict__.get(\"__implementation__\", None)\n",
   "        head = module.split(\".\")[0]\n",
   "        if head == \"bokeh\" or head == \"__main__\" or impl is not None:\n",
   "            qualified = model\n",
   "            qualified = module + \".\" + model\n",
   "        cls.__qualified_model__ = qualified\n",
   "        previous = cls.model_class_reverse_map.get(qualified, None)\n",
   "        if previous is not None and not hasattr(cls, \"__implementation__\"):\n",
   "            raise Warning(f\"Duplicate qualified model declaration of '{qualified}'. Previous definition: {previous}\")\n",
   "        cls.model_class_reverse_map[qualified] = cls\n",
   "        obj =  super().__new__(cls)\n",
   "        obj._id = kwargs.pop(\"id\", make_id())\n",
   "        obj._document = None\n",
   "        obj._temp_document = None\n",
   "        return obj\n",
   "    name = String(help=\"\"\"\n",
   "        this = {\n",
   "            parts = this[\"type\"].split(\".\")\n",
   "            parts[-1] = self.__view_model__\n",
   "            this[\"type\"] = \".\".join(parts)\n",
   "            this[\"subtype\"] = self.__subtype__\n",
   "        return this\n",
   "            event = event.event_name\n",
   "        old_callbacks = self.js_event_callbacks.get(\"event\", [])\n",
   "        new_callbacks = [ callback for callback in callbacks if callback not in old_callbacks ]\n",
   "        self.js_event_callbacks[event] = old_callbacks + new_callbacks\n",
   "        selector = f\"[{attr_selector!r}]\" if attr_selector is not None else \"\"\n",
   "        cb = CustomJS(args=dict(other=other), code=f\"other.{other_attr} = this.{attr}{selector}\")\n",
   "        self.js_on_change(attr, cb)\n",
   "        if not all(isinstance(x, CustomJS) for x in callbacks):\n",
   "        if event in self.properties():\n",
   "            event = \"change:%s\" % event\n",
   "        old = {k: [cb for cb in cbs] for k, cbs in self.js_property_callbacks.items()}\n",
   "        if event not in self.js_property_callbacks:\n",
   "            self.js_property_callbacks[event] = []\n",
   "        for callback in callbacks:\n",
   "            if callback in self.js_property_callbacks[event]:\n",
   "            self.js_property_callbacks[event].append(callback)\n",
   "        self.trigger('js_property_callbacks', old, self.js_property_callbacks)\n",
   "        return set(collect_models(self))\n",
   "        return find(self.references(), selector)\n",
   "        result = list(self.select(selector))\n",
   "        if len(result) > 1:\n",
   "            raise ValueError(\"Found more than one object matching %s: %r\" % (selector, result))\n",
   "        if len(result) == 0:\n",
   "        return result[0]\n",
   "        if isclass(selector) and issubclass(selector, Model):\n",
   "            selector = dict(type=selector)\n",
   "        for obj in self.select(selector):\n",
   "            for key, val in updates.items():\n",
   "                setattr(obj, key, val)\n",
   "        json_like = self._to_json_like(include_defaults=include_defaults)\n",
   "        json_like['id'] = self.id\n",
   "        return serialize_json(json_like)\n",
   "            dirty = { 'count' : 0 }\n",
   "                dirty['count'] += 1\n",
   "                _visit_value_and_its_immediate_references(old, mark_dirty)\n",
   "                if dirty['count'] > 0:\n",
   "        super().trigger(attr, old, new, hint=hint, setter=setter)\n",
   "            k: v for k, v in Model.model_class_reverse_map.items()\n",
   "            if getattr(v, \"__implementation__\", None) is None\n",
   "                and getattr(v, \"__javascript__\", None) is None\n",
   "                and getattr(v, \"__css__\", None) is None\n",
   "        all_attrs = self.properties_with_values(include_defaults=include_defaults)\n",
   "        subtype = getattr(self.__class__, \"__subtype__\", None)\n",
   "        if subtype is not None and subtype != self.__class__.__view_model__:\n",
   "            attrs = {}\n",
   "            for attr, value in all_attrs.items():\n",
   "                if attr in self.__class__.__dict__:\n",
   "                    attrs[attr] = value\n",
   "            attrs = all_attrs\n",
   "        for (k, v) in attrs.items():\n",
   "            if isinstance(v, float) and v == float('inf'):\n",
   "                attrs[k] = None\n",
   "        return attrs\n",
   "        module = self.__class__.__module__\n",
   "        name = self.__class__.__name__\n",
   "        _id = getattr(self, \"_id\", None)\n",
   "        cls_name = make_id()\n",
   "        def row(c):\n",
   "        def hidden_row(c):\n",
   "            return '<div class=\"%s\" style=\"display: none;\">%s</div>' % (cls_name, c)\n",
   "        def cell(c):\n",
   "            return '<div style=\"display: table-cell;\">' + c + '</div>'\n",
   "        html = ''\n",
   "        html += '<div style=\"display: table;\">'\n",
   "        ellipsis_id = make_id()\n",
   "        ellipsis = '<span id=\"%s\" style=\"cursor: pointer;\">&hellip;)</span>' % ellipsis_id\n",
   "        prefix = cell('<b title=\"%s.%s\">%s</b>(' % (module, name, name))\n",
   "        html += row(prefix + cell('id' + '&nbsp;=&nbsp;' + repr(_id) + ', ' + ellipsis))\n",
   "        props = self.properties_with_values().items()\n",
   "        sorted_props = sorted(props, key=itemgetter(0))\n",
   "        all_props = sorted_props\n",
   "        for i, (prop, value) in enumerate(all_props):\n",
   "            end = ')' if i == len(all_props)-1 else ','\n",
   "            html += hidden_row(cell(\"\") + cell(prop + '&nbsp;=&nbsp;' + repr(value) + end))\n",
   "        html += '</div>'\n",
   "        html += _HTML_REPR % dict(ellipsis_id=ellipsis_id, cls_name=cls_name)\n",
   "        return html\n",
   "    if isinstance(value, HasProps):\n",
   "        for attr in value.properties_with_refs():\n",
   "            child = getattr(value, attr)\n",
   "            _visit_value_and_its_immediate_references(child, visitor)\n",
   "        _visit_value_and_its_immediate_references(value, visitor)\n",
   "    typ = type(obj)\n",
   "    if typ in _common_types:  # short circuit on common base types\n",
   "    if typ is list or issubclass(typ, (list, tuple)):  # check common containers\n",
   "        for item in obj:\n",
   "            _visit_value_and_its_immediate_references(item, visitor)\n",
   "    elif issubclass(typ, dict):\n",
   "        for key, value in obj.items():\n",
   "            _visit_value_and_its_immediate_references(key, visitor)\n",
   "            _visit_value_and_its_immediate_references(value, visitor)\n",
   "    elif issubclass(typ, HasProps):\n",
   "        if issubclass(typ, Model):\n",
   "            visitor(obj)\n",
   "            _visit_immediate_value_references(obj, visitor)\n"
  ]
 },
 "34": {
  "name": "typ",
  "type": "bokeh",
  "class": "imported",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/model.py",
  "lineno": "802",
  "column": "4",
  "context": "ecause isinstance checks can be slow.\n    '''\n    typ = type(obj)\n    if typ in _common_types:  # short circuit on c",
  "context_lines": "    most comomn types (int, float, str) first so that we can quickly return in\n    the common case.  We avoid isinstance and issubclass checks in a couple\n    places with `type` checks because isinstance checks can be slow.\n    '''\n    typ = type(obj)\n    if typ in _common_types:  # short circuit on common base types\n        return\n    if typ is list or issubclass(typ, (list, tuple)):  # check common containers\n        for item in obj:\n",
  "slicing": [
   "def collect_filtered_models(discard, *input_values):\n",
   "    ids = set()\n",
   "    collected = []\n",
   "    queued = []\n",
   "        if obj.id not in ids and not (callable(discard) and discard(obj)):\n",
   "            queued.append(obj)\n",
   "    for value in input_values:\n",
   "        _visit_value_and_its_immediate_references(value, queue_one)\n",
   "    while queued:\n",
   "        obj = queued.pop(0)\n",
   "        if obj.id not in ids:\n",
   "            ids.add(obj.id)\n",
   "            collected.append(obj)\n",
   "            _visit_immediate_value_references(obj, queue_one)\n",
   "    return collected\n",
   "def collect_models(*input_values):\n",
   "    return collect_filtered_models(None, *input_values)\n",
   "    d = Model.model_class_reverse_map\n",
   "    if view_model_name in d:\n",
   "        return d[view_model_name]\n",
   "_HTML_REPR = \"\"\"\n",
   "        module = cls.__view_module__\n",
   "        model = cls.__dict__.get(\"__subtype__\", cls.__view_model__)\n",
   "        impl = cls.__dict__.get(\"__implementation__\", None)\n",
   "        head = module.split(\".\")[0]\n",
   "        if head == \"bokeh\" or head == \"__main__\" or impl is not None:\n",
   "            qualified = model\n",
   "            qualified = module + \".\" + model\n",
   "        cls.__qualified_model__ = qualified\n",
   "        previous = cls.model_class_reverse_map.get(qualified, None)\n",
   "        if previous is not None and not hasattr(cls, \"__implementation__\"):\n",
   "            raise Warning(f\"Duplicate qualified model declaration of '{qualified}'. Previous definition: {previous}\")\n",
   "        cls.model_class_reverse_map[qualified] = cls\n",
   "        obj =  super().__new__(cls)\n",
   "        obj._id = kwargs.pop(\"id\", make_id())\n",
   "        obj._document = None\n",
   "        obj._temp_document = None\n",
   "        return obj\n",
   "    name = String(help=\"\"\"\n",
   "        this = {\n",
   "            parts = this[\"type\"].split(\".\")\n",
   "            parts[-1] = self.__view_model__\n",
   "            this[\"type\"] = \".\".join(parts)\n",
   "            this[\"subtype\"] = self.__subtype__\n",
   "        return this\n",
   "            event = event.event_name\n",
   "        old_callbacks = self.js_event_callbacks.get(\"event\", [])\n",
   "        new_callbacks = [ callback for callback in callbacks if callback not in old_callbacks ]\n",
   "        self.js_event_callbacks[event] = old_callbacks + new_callbacks\n",
   "        selector = f\"[{attr_selector!r}]\" if attr_selector is not None else \"\"\n",
   "        cb = CustomJS(args=dict(other=other), code=f\"other.{other_attr} = this.{attr}{selector}\")\n",
   "        self.js_on_change(attr, cb)\n",
   "        if not all(isinstance(x, CustomJS) for x in callbacks):\n",
   "        if event in self.properties():\n",
   "            event = \"change:%s\" % event\n",
   "        old = {k: [cb for cb in cbs] for k, cbs in self.js_property_callbacks.items()}\n",
   "        if event not in self.js_property_callbacks:\n",
   "            self.js_property_callbacks[event] = []\n",
   "        for callback in callbacks:\n",
   "            if callback in self.js_property_callbacks[event]:\n",
   "            self.js_property_callbacks[event].append(callback)\n",
   "        self.trigger('js_property_callbacks', old, self.js_property_callbacks)\n",
   "        return set(collect_models(self))\n",
   "        return find(self.references(), selector)\n",
   "        result = list(self.select(selector))\n",
   "        if len(result) > 1:\n",
   "            raise ValueError(\"Found more than one object matching %s: %r\" % (selector, result))\n",
   "        if len(result) == 0:\n",
   "        return result[0]\n",
   "        if isclass(selector) and issubclass(selector, Model):\n",
   "            selector = dict(type=selector)\n",
   "        for obj in self.select(selector):\n",
   "            for key, val in updates.items():\n",
   "                setattr(obj, key, val)\n",
   "        json_like = self._to_json_like(include_defaults=include_defaults)\n",
   "        json_like['id'] = self.id\n",
   "        return serialize_json(json_like)\n",
   "            dirty = { 'count' : 0 }\n",
   "                dirty['count'] += 1\n",
   "                _visit_value_and_its_immediate_references(old, mark_dirty)\n",
   "                if dirty['count'] > 0:\n",
   "        super().trigger(attr, old, new, hint=hint, setter=setter)\n",
   "            k: v for k, v in Model.model_class_reverse_map.items()\n",
   "            if getattr(v, \"__implementation__\", None) is None\n",
   "                and getattr(v, \"__javascript__\", None) is None\n",
   "                and getattr(v, \"__css__\", None) is None\n",
   "        all_attrs = self.properties_with_values(include_defaults=include_defaults)\n",
   "        subtype = getattr(self.__class__, \"__subtype__\", None)\n",
   "        if subtype is not None and subtype != self.__class__.__view_model__:\n",
   "            attrs = {}\n",
   "            for attr, value in all_attrs.items():\n",
   "                if attr in self.__class__.__dict__:\n",
   "                    attrs[attr] = value\n",
   "            attrs = all_attrs\n",
   "        for (k, v) in attrs.items():\n",
   "            if isinstance(v, float) and v == float('inf'):\n",
   "                attrs[k] = None\n",
   "        return attrs\n",
   "        module = self.__class__.__module__\n",
   "        name = self.__class__.__name__\n",
   "        _id = getattr(self, \"_id\", None)\n",
   "        cls_name = make_id()\n",
   "        def row(c):\n",
   "        def hidden_row(c):\n",
   "            return '<div class=\"%s\" style=\"display: none;\">%s</div>' % (cls_name, c)\n",
   "        def cell(c):\n",
   "            return '<div style=\"display: table-cell;\">' + c + '</div>'\n",
   "        html = ''\n",
   "        html += '<div style=\"display: table;\">'\n",
   "        ellipsis_id = make_id()\n",
   "        ellipsis = '<span id=\"%s\" style=\"cursor: pointer;\">&hellip;)</span>' % ellipsis_id\n",
   "        prefix = cell('<b title=\"%s.%s\">%s</b>(' % (module, name, name))\n",
   "        html += row(prefix + cell('id' + '&nbsp;=&nbsp;' + repr(_id) + ', ' + ellipsis))\n",
   "        props = self.properties_with_values().items()\n",
   "        sorted_props = sorted(props, key=itemgetter(0))\n",
   "        all_props = sorted_props\n",
   "        for i, (prop, value) in enumerate(all_props):\n",
   "            end = ')' if i == len(all_props)-1 else ','\n",
   "            html += hidden_row(cell(\"\") + cell(prop + '&nbsp;=&nbsp;' + repr(value) + end))\n",
   "        html += '</div>'\n",
   "        html += _HTML_REPR % dict(ellipsis_id=ellipsis_id, cls_name=cls_name)\n",
   "        return html\n",
   "    if isinstance(value, HasProps):\n",
   "        for attr in value.properties_with_refs():\n",
   "            child = getattr(value, attr)\n",
   "            _visit_value_and_its_immediate_references(child, visitor)\n",
   "        _visit_value_and_its_immediate_references(value, visitor)\n",
   "    typ = type(obj)\n",
   "    if typ in _common_types:  # short circuit on common base types\n",
   "    if typ is list or issubclass(typ, (list, tuple)):  # check common containers\n",
   "        for item in obj:\n",
   "            _visit_value_and_its_immediate_references(item, visitor)\n",
   "    elif issubclass(typ, dict):\n",
   "        for key, value in obj.items():\n",
   "            _visit_value_and_its_immediate_references(key, visitor)\n",
   "            _visit_value_and_its_immediate_references(value, visitor)\n",
   "    elif issubclass(typ, HasProps):\n",
   "        if issubclass(typ, Model):\n",
   "            visitor(obj)\n",
   "            _visit_immediate_value_references(obj, visitor)\n"
  ]
 },
 "35": {
  "name": "sizing_mode",
  "type": "NoneType",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/layouts.py",
  "lineno": "78",
  "column": "4",
  "context": ", plot], sizing_mode='stretch_both')\n    \"\"\"\n\n    sizing_mode = kwargs.pop('sizing_mode', None)\n    children = kwargs.pop('children', None)\n\n    c",
  "context_lines": "    Examples:\n\n        >>> row(plot1, plot2)\n        >>> row(children=[widgets, plot], sizing_mode='stretch_both')\n    \"\"\"\n\n    sizing_mode = kwargs.pop('sizing_mode', None)\n    children = kwargs.pop('children', None)\n\n    children = _parse_children_arg(*args, children=children)\n\n    _handle_child_sizing(children, sizing_mode, widget=\"row\")\n\n    return Row(children=children, sizing_mode=sizing_mode, **kwargs)\n\n\n",
  "slicing": [
   "    sizing_mode = kwargs.pop('sizing_mode', None)\n",
   "    _handle_child_sizing(children, sizing_mode, widget=\"row\")\n",
   "    return Row(children=children, sizing_mode=sizing_mode, **kwargs)\n",
   "    _handle_child_sizing(children, sizing_mode, widget=\"column\")\n",
   "    return Column(children=children, sizing_mode=sizing_mode, **kwargs)\n",
   "    _handle_child_sizing(children, sizing_mode, widget=\"widget box\")\n",
   "    return WidgetBox(children=children, sizing_mode=sizing_mode, **kwargs)\n",
   "    return _create_grid(children, sizing_mode, **kwargs)\n",
   "                if sizing_mode is not None and _has_auto_sizing(item):\n",
   "                    item.sizing_mode = sizing_mode\n",
   "        return GridBox(children=items, sizing_mode=sizing_mode)\n",
   "        return Column(children=[toolbar, grid], sizing_mode=sizing_mode)\n",
   "        return Column(children=[grid, toolbar], sizing_mode=sizing_mode)\n",
   "        return Row(children=[toolbar, grid], sizing_mode=sizing_mode)\n",
   "        return Row(children=[grid, toolbar], sizing_mode=sizing_mode)\n",
   "    if sizing_mode is not None:\n",
   "        grid.sizing_mode = sizing_mode\n",
   "                layout.sizing_mode = sizing_mode\n",
   "        if sizing_mode is not None and _has_auto_sizing(item):\n",
   "            item.sizing_mode = sizing_mode\n",
   "            return_list.append(_create_grid(item, sizing_mode, layer+1))\n",
   "            if sizing_mode is not None and _has_auto_sizing(item):\n",
   "                item.sizing_mode = sizing_mode\n",
   "        return column(children=return_list, sizing_mode=sizing_mode, **kwargs)\n",
   "    return row(children=return_list, sizing_mode=sizing_mode, **kwargs)\n"
  ]
 },
 "36": {
  "name": "children",
  "type": "NoneType",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/layouts.py",
  "lineno": "79",
  "column": "4",
  "context": "sizing_mode = kwargs.pop('sizing_mode', None)\n    children = kwargs.pop('children', None)\n\n    children = _parse_children_arg(*args, childre",
  "context_lines": "        >>> row(plot1, plot2)\n        >>> row(children=[widgets, plot], sizing_mode='stretch_both')\n    \"\"\"\n\n    sizing_mode = kwargs.pop('sizing_mode', None)\n    children = kwargs.pop('children', None)\n\n    children = _parse_children_arg(*args, children=children)\n\n    _handle_child_sizing(children, sizing_mode, widget=\"row\")\n\n    return Row(children=children, sizing_mode=sizing_mode, **kwargs)\n\n\n",
  "slicing": [
   "def row(*args, **kwargs):\n",
   "    sizing_mode = kwargs.pop('sizing_mode', None)\n",
   "    children = kwargs.pop('children', None)\n",
   "    children = _parse_children_arg(*args, children=children)\n",
   "    _handle_child_sizing(children, sizing_mode, widget=\"row\")\n",
   "    return Row(children=children, sizing_mode=sizing_mode, **kwargs)\n",
   "    sizing_mode = kwargs.pop('sizing_mode', None)\n",
   "    children = kwargs.pop('children', None)\n",
   "    children = _parse_children_arg(*args, children=children)\n",
   "    _handle_child_sizing(children, sizing_mode, widget=\"column\")\n",
   "    return Column(children=children, sizing_mode=sizing_mode, **kwargs)\n",
   "    sizing_mode = kwargs.pop('sizing_mode', None)\n",
   "    children = kwargs.pop('children', None)\n",
   "    children = _parse_children_arg(*args, children=children)\n",
   "    _handle_child_sizing(children, sizing_mode, widget=\"widget box\")\n",
   "    return WidgetBox(children=children, sizing_mode=sizing_mode, **kwargs)\n",
   "    sizing_mode = kwargs.pop('sizing_mode', None)\n",
   "    children = kwargs.pop('children', None)\n",
   "    children = _parse_children_arg(*args, children=children)\n",
   "    return _create_grid(children, sizing_mode, **kwargs)\n",
   "        toolbar_options = {}\n",
   "    children = _parse_children_arg(children=children)\n",
   "        if any(isinstance(child, list) for child in children):\n",
   "        children = list(_chunks(children, ncols))\n",
   "    if not children:\n",
   "        children = []\n",
   "    toolbars = []\n",
   "    items = []\n",
   "    for y, row in enumerate(children):\n",
   "        for x, item in enumerate(row):\n",
   "            if item is None:\n",
   "            elif isinstance(item, LayoutDOM):\n",
   "                    for plot in item.select(dict(type=Plot)):\n",
   "                        toolbars.append(plot.toolbar)\n",
   "                        plot.toolbar_location = None\n",
   "                if isinstance(item, Plot):\n",
   "                        item.plot_width = plot_width\n",
   "                        item.plot_height = plot_height\n",
   "                if sizing_mode is not None and _has_auto_sizing(item):\n",
   "                    item.sizing_mode = sizing_mode\n",
   "                items.append((item, y, x))\n",
   "        return GridBox(children=items, sizing_mode=sizing_mode)\n",
   "    grid = GridBox(children=items)\n",
   "    tools = sum([ toolbar.tools for toolbar in toolbars ], [])\n",
   "    proxy = ProxyToolbar(toolbars=toolbars, tools=tools, **toolbar_options)\n",
   "    toolbar = ToolbarBox(toolbar=proxy, toolbar_location=toolbar_location)\n",
   "        return Column(children=[toolbar, grid], sizing_mode=sizing_mode)\n",
   "        return Column(children=[grid, toolbar], sizing_mode=sizing_mode)\n",
   "        return Row(children=[toolbar, grid], sizing_mode=sizing_mode)\n",
   "        return Row(children=[grid, toolbar], sizing_mode=sizing_mode)\n",
   "    row = namedtuple(\"row\", [\"children\"])\n",
   "    col = namedtuple(\"col\", [\"children\"])\n",
   "    def flatten(layout):\n",
   "        Item = namedtuple(\"Item\", [\"layout\", \"r0\", \"c0\", \"r1\", \"c1\"])\n",
   "        Grid = namedtuple(\"Grid\", [\"nrows\", \"ncols\", \"items\"])\n",
   "        def gcd(a, b):\n",
   "            a, b = abs(a), abs(b)\n",
   "            while b != 0:\n",
   "                a, b = b, a % b\n",
   "            return a\n",
   "        def lcm(a, *rest):\n",
   "            for b in rest:\n",
   "                a = (a*b) // gcd(a, b)\n",
   "            return a\n",
   "        nonempty = lambda child: child.nrows != 0 and child.ncols != 0\n",
   "        def _flatten(layout):\n",
   "            if isinstance(layout, row):\n",
   "                children = list(filter(nonempty, map(_flatten, layout.children)))\n",
   "                if not children:\n",
   "                    return Grid(0, 0, [])\n",
   "                nrows = lcm(*[ child.nrows for child in children ])\n",
   "                ncols = sum(child.ncols for child in children)\n",
   "                items = []\n",
   "                offset = 0\n",
   "                for child in children:\n",
   "                    factor = nrows//child.nrows\n",
   "                    for (layout, r0, c0, r1, c1) in child.items:\n",
   "                        items.append((layout, factor*r0, c0 + offset, factor*r1, c1 + offset))\n",
   "                    offset += child.ncols\n",
   "                return Grid(nrows, ncols, items)\n",
   "            elif isinstance(layout, col):\n",
   "                children = list(filter(nonempty, map(_flatten, layout.children)))\n",
   "                if not children:\n",
   "                    return Grid(0, 0, [])\n",
   "                nrows = sum(child.nrows for child in children)\n",
   "                ncols = lcm(*[ child.ncols for child in children ])\n",
   "                items = []\n",
   "                offset = 0\n",
   "                for child in children:\n",
   "                    factor = ncols//child.ncols\n",
   "                    for (layout, r0, c0, r1, c1) in child.items:\n",
   "                        items.append((layout, r0 + offset, factor*c0, r1 + offset, factor*c1))\n",
   "                    offset += child.nrows\n",
   "                return Grid(nrows, ncols, items)\n",
   "                return Grid(1, 1, [Item(layout, 0, 0, 1, 1)])\n",
   "        grid = _flatten(layout)\n",
   "        children = []\n",
   "        for (layout, r0, c0, r1, c1) in grid.items:\n",
   "            if layout is not None:\n",
   "                children.append((layout, r0, c0, r1 - r0, c1 - c0))\n",
   "        return GridBox(children=children)\n",
   "    if isinstance(children, list):\n",
   "        if nrows is not None or ncols is not None:\n",
   "            N = len(children)\n",
   "            if ncols is None:\n",
   "                ncols = math.ceil(N/nrows)\n",
   "            layout = col([ row(children[i:i+ncols]) for i in range(0, N, ncols) ])\n",
   "            def traverse(children, level=0):\n",
   "                if isinstance(children, list):\n",
   "                    container = col if level % 2 == 0 else row\n",
   "                    return container([ traverse(child, level+1) for child in children ])\n",
   "                    return children\n",
   "            layout = traverse(children)\n",
   "    elif isinstance(children, LayoutDOM):\n",
   "        def is_usable(child):\n",
   "            return _has_auto_sizing(child) and child.spacing == 0\n",
   "        def traverse(item, top_level=False):\n",
   "            if isinstance(item, Box) and (top_level or is_usable(item)):\n",
   "                container = col if isinstance(item, Column) else row\n",
   "                return container(list(map(traverse, item.children)))\n",
   "                return item\n",
   "        layout = traverse(children, top_level=True)\n",
   "    elif isinstance(children, str):\n",
   "    grid = flatten(layout)\n",
   "    if sizing_mode is not None:\n",
   "        grid.sizing_mode = sizing_mode\n",
   "        for child in grid.children:\n",
   "            layout = child[0]\n",
   "            if _has_auto_sizing(layout):\n",
   "                layout.sizing_mode = sizing_mode\n",
   "    return grid\n",
   "        self.nrows = nrows\n",
   "        self.ncols = ncols\n",
   "        k1, k2 = key\n",
   "        if isinstance(k1, slice):\n",
   "            row1, row2, _ = k1.indices(self.nrows)\n",
   "            if k1 < 0:\n",
   "                k1 += self.nrows\n",
   "            if k1 >= self.nrows or k1 < 0:\n",
   "            row1, row2 = k1, None\n",
   "        if isinstance(k2, slice):\n",
   "            col1, col2, _ = k2.indices(self.ncols)\n",
   "            if k2 < 0:\n",
   "                k2 += self.ncols\n",
   "            if k2 >= self.ncols or k2 < 0:\n",
   "            col1, col2 = k2, None\n",
   "        def get_or_else(fn, default):\n",
   "                return fn()\n",
   "                return default\n",
   "        if row2 is None and col2 is None:\n",
   "            self._arrangement[row1, col1] = obj\n",
   "        elif row2 is None:\n",
   "            for col in range(col1, col2):\n",
   "                self._arrangement[row1, col] = get_or_else(lambda: obj[col-col1], None) # lgtm [py/loop-variable-capture]\n",
   "        elif col2 is None:\n",
   "            for row in range(row1, row2):\n",
   "                self._arrangement[row, col1] = get_or_else(lambda: obj[row-row1], None) # lgtm [py/loop-variable-capture]\n",
   "            for row, col in zip(range(row1, row2), range(col1, col2)):\n",
   "                self._arrangement[row, col] = get_or_else(lambda: obj[row-row1][col-col1], None) # lgtm [py/loop-variable-capture]\n",
   "        array = [ [ None ]*self.ncols for _ in range(0, self.nrows) ]\n",
   "        for (row, col), obj in self._arrangement.items():\n",
   "            array[row][col] = obj\n",
   "        return iter(array)\n",
   "    return item.sizing_mode is None and item.width_policy == \"auto\" and item.height_policy == \"auto\"\n",
   "    children = kwargs.get('children')\n",
   "    if len(args) > 0 and children is not None:\n",
   "    if not children:\n",
   "    return children\n",
   "    for item in children:\n",
   "        if not isinstance(item, LayoutDOM):\n",
   "            raise ValueError(f\"Only LayoutDOM items can be inserted into a {widget}. Tried to insert: {item} of type {type(item)}\")\n",
   "        if sizing_mode is not None and _has_auto_sizing(item):\n",
   "            item.sizing_mode = sizing_mode\n",
   "        if isinstance(item, list):\n",
   "            return_list.append(_create_grid(item, sizing_mode, layer+1))\n",
   "        elif isinstance(item, LayoutDOM):\n",
   "            if sizing_mode is not None and _has_auto_sizing(item):\n",
   "                item.sizing_mode = sizing_mode\n",
   "            return_list.append(item)\n",
   "                Tried to insert: %s of type %s\"\"\" % (item, type(item))\n",
   "        return column(children=return_list, sizing_mode=sizing_mode, **kwargs)\n",
   "    return row(children=return_list, sizing_mode=sizing_mode, **kwargs)\n",
   "    assert isinstance(ncols, int), \"ncols must be an integer\"\n",
   "    for i in range(0, len(l), ncols):\n",
   "        yield l[i: i+ncols]\n"
  ]
 },
 "37": {
  "name": "children",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/layouts.py",
  "lineno": "81",
  "column": "4",
  "context": "\n    children = kwargs.pop('children', None)\n\n    children = _parse_children_arg(*args, children=children)\n\n    _handle_child_sizing(children, sizing_mode, w",
  "context_lines": "        >>> row(children=[widgets, plot], sizing_mode='stretch_both')\n    \"\"\"\n\n    sizing_mode = kwargs.pop('sizing_mode', None)\n    children = kwargs.pop('children', None)\n\n    children = _parse_children_arg(*args, children=children)\n\n    _handle_child_sizing(children, sizing_mode, widget=\"row\")\n\n    return Row(children=children, sizing_mode=sizing_mode, **kwargs)\n\n\ndef column(*args, **kwargs):\n",
  "slicing": [
   "def row(*args, **kwargs):\n",
   "    sizing_mode = kwargs.pop('sizing_mode', None)\n",
   "    children = kwargs.pop('children', None)\n",
   "    children = _parse_children_arg(*args, children=children)\n",
   "    _handle_child_sizing(children, sizing_mode, widget=\"row\")\n",
   "    return Row(children=children, sizing_mode=sizing_mode, **kwargs)\n",
   "    sizing_mode = kwargs.pop('sizing_mode', None)\n",
   "    children = kwargs.pop('children', None)\n",
   "    children = _parse_children_arg(*args, children=children)\n",
   "    _handle_child_sizing(children, sizing_mode, widget=\"column\")\n",
   "    return Column(children=children, sizing_mode=sizing_mode, **kwargs)\n",
   "    sizing_mode = kwargs.pop('sizing_mode', None)\n",
   "    children = kwargs.pop('children', None)\n",
   "    children = _parse_children_arg(*args, children=children)\n",
   "    _handle_child_sizing(children, sizing_mode, widget=\"widget box\")\n",
   "    return WidgetBox(children=children, sizing_mode=sizing_mode, **kwargs)\n",
   "    sizing_mode = kwargs.pop('sizing_mode', None)\n",
   "    children = kwargs.pop('children', None)\n",
   "    children = _parse_children_arg(*args, children=children)\n",
   "    return _create_grid(children, sizing_mode, **kwargs)\n",
   "        toolbar_options = {}\n",
   "    children = _parse_children_arg(children=children)\n",
   "        if any(isinstance(child, list) for child in children):\n",
   "        children = list(_chunks(children, ncols))\n",
   "    if not children:\n",
   "        children = []\n",
   "    toolbars = []\n",
   "    items = []\n",
   "    for y, row in enumerate(children):\n",
   "        for x, item in enumerate(row):\n",
   "            if item is None:\n",
   "            elif isinstance(item, LayoutDOM):\n",
   "                    for plot in item.select(dict(type=Plot)):\n",
   "                        toolbars.append(plot.toolbar)\n",
   "                        plot.toolbar_location = None\n",
   "                if isinstance(item, Plot):\n",
   "                        item.plot_width = plot_width\n",
   "                        item.plot_height = plot_height\n",
   "                if sizing_mode is not None and _has_auto_sizing(item):\n",
   "                    item.sizing_mode = sizing_mode\n",
   "                items.append((item, y, x))\n",
   "        return GridBox(children=items, sizing_mode=sizing_mode)\n",
   "    grid = GridBox(children=items)\n",
   "    tools = sum([ toolbar.tools for toolbar in toolbars ], [])\n",
   "    proxy = ProxyToolbar(toolbars=toolbars, tools=tools, **toolbar_options)\n",
   "    toolbar = ToolbarBox(toolbar=proxy, toolbar_location=toolbar_location)\n",
   "        return Column(children=[toolbar, grid], sizing_mode=sizing_mode)\n",
   "        return Column(children=[grid, toolbar], sizing_mode=sizing_mode)\n",
   "        return Row(children=[toolbar, grid], sizing_mode=sizing_mode)\n",
   "        return Row(children=[grid, toolbar], sizing_mode=sizing_mode)\n",
   "    row = namedtuple(\"row\", [\"children\"])\n",
   "    col = namedtuple(\"col\", [\"children\"])\n",
   "    def flatten(layout):\n",
   "        Item = namedtuple(\"Item\", [\"layout\", \"r0\", \"c0\", \"r1\", \"c1\"])\n",
   "        Grid = namedtuple(\"Grid\", [\"nrows\", \"ncols\", \"items\"])\n",
   "        def gcd(a, b):\n",
   "            a, b = abs(a), abs(b)\n",
   "            while b != 0:\n",
   "                a, b = b, a % b\n",
   "            return a\n",
   "        def lcm(a, *rest):\n",
   "            for b in rest:\n",
   "                a = (a*b) // gcd(a, b)\n",
   "            return a\n",
   "        nonempty = lambda child: child.nrows != 0 and child.ncols != 0\n",
   "        def _flatten(layout):\n",
   "            if isinstance(layout, row):\n",
   "                children = list(filter(nonempty, map(_flatten, layout.children)))\n",
   "                if not children:\n",
   "                    return Grid(0, 0, [])\n",
   "                nrows = lcm(*[ child.nrows for child in children ])\n",
   "                ncols = sum(child.ncols for child in children)\n",
   "                items = []\n",
   "                offset = 0\n",
   "                for child in children:\n",
   "                    factor = nrows//child.nrows\n",
   "                    for (layout, r0, c0, r1, c1) in child.items:\n",
   "                        items.append((layout, factor*r0, c0 + offset, factor*r1, c1 + offset))\n",
   "                    offset += child.ncols\n",
   "                return Grid(nrows, ncols, items)\n",
   "            elif isinstance(layout, col):\n",
   "                children = list(filter(nonempty, map(_flatten, layout.children)))\n",
   "                if not children:\n",
   "                    return Grid(0, 0, [])\n",
   "                nrows = sum(child.nrows for child in children)\n",
   "                ncols = lcm(*[ child.ncols for child in children ])\n",
   "                items = []\n",
   "                offset = 0\n",
   "                for child in children:\n",
   "                    factor = ncols//child.ncols\n",
   "                    for (layout, r0, c0, r1, c1) in child.items:\n",
   "                        items.append((layout, r0 + offset, factor*c0, r1 + offset, factor*c1))\n",
   "                    offset += child.nrows\n",
   "                return Grid(nrows, ncols, items)\n",
   "                return Grid(1, 1, [Item(layout, 0, 0, 1, 1)])\n",
   "        grid = _flatten(layout)\n",
   "        children = []\n",
   "        for (layout, r0, c0, r1, c1) in grid.items:\n",
   "            if layout is not None:\n",
   "                children.append((layout, r0, c0, r1 - r0, c1 - c0))\n",
   "        return GridBox(children=children)\n",
   "    if isinstance(children, list):\n",
   "        if nrows is not None or ncols is not None:\n",
   "            N = len(children)\n",
   "            if ncols is None:\n",
   "                ncols = math.ceil(N/nrows)\n",
   "            layout = col([ row(children[i:i+ncols]) for i in range(0, N, ncols) ])\n",
   "            def traverse(children, level=0):\n",
   "                if isinstance(children, list):\n",
   "                    container = col if level % 2 == 0 else row\n",
   "                    return container([ traverse(child, level+1) for child in children ])\n",
   "                    return children\n",
   "            layout = traverse(children)\n",
   "    elif isinstance(children, LayoutDOM):\n",
   "        def is_usable(child):\n",
   "            return _has_auto_sizing(child) and child.spacing == 0\n",
   "        def traverse(item, top_level=False):\n",
   "            if isinstance(item, Box) and (top_level or is_usable(item)):\n",
   "                container = col if isinstance(item, Column) else row\n",
   "                return container(list(map(traverse, item.children)))\n",
   "                return item\n",
   "        layout = traverse(children, top_level=True)\n",
   "    elif isinstance(children, str):\n",
   "    grid = flatten(layout)\n",
   "    if sizing_mode is not None:\n",
   "        grid.sizing_mode = sizing_mode\n",
   "        for child in grid.children:\n",
   "            layout = child[0]\n",
   "            if _has_auto_sizing(layout):\n",
   "                layout.sizing_mode = sizing_mode\n",
   "    return grid\n",
   "        self.nrows = nrows\n",
   "        self.ncols = ncols\n",
   "        k1, k2 = key\n",
   "        if isinstance(k1, slice):\n",
   "            row1, row2, _ = k1.indices(self.nrows)\n",
   "            if k1 < 0:\n",
   "                k1 += self.nrows\n",
   "            if k1 >= self.nrows or k1 < 0:\n",
   "            row1, row2 = k1, None\n",
   "        if isinstance(k2, slice):\n",
   "            col1, col2, _ = k2.indices(self.ncols)\n",
   "            if k2 < 0:\n",
   "                k2 += self.ncols\n",
   "            if k2 >= self.ncols or k2 < 0:\n",
   "            col1, col2 = k2, None\n",
   "        def get_or_else(fn, default):\n",
   "                return fn()\n",
   "                return default\n",
   "        if row2 is None and col2 is None:\n",
   "            self._arrangement[row1, col1] = obj\n",
   "        elif row2 is None:\n",
   "            for col in range(col1, col2):\n",
   "                self._arrangement[row1, col] = get_or_else(lambda: obj[col-col1], None) # lgtm [py/loop-variable-capture]\n",
   "        elif col2 is None:\n",
   "            for row in range(row1, row2):\n",
   "                self._arrangement[row, col1] = get_or_else(lambda: obj[row-row1], None) # lgtm [py/loop-variable-capture]\n",
   "            for row, col in zip(range(row1, row2), range(col1, col2)):\n",
   "                self._arrangement[row, col] = get_or_else(lambda: obj[row-row1][col-col1], None) # lgtm [py/loop-variable-capture]\n",
   "        array = [ [ None ]*self.ncols for _ in range(0, self.nrows) ]\n",
   "        for (row, col), obj in self._arrangement.items():\n",
   "            array[row][col] = obj\n",
   "        return iter(array)\n",
   "    return item.sizing_mode is None and item.width_policy == \"auto\" and item.height_policy == \"auto\"\n",
   "    children = kwargs.get('children')\n",
   "    if len(args) > 0 and children is not None:\n",
   "    if not children:\n",
   "    return children\n",
   "    for item in children:\n",
   "        if not isinstance(item, LayoutDOM):\n",
   "            raise ValueError(f\"Only LayoutDOM items can be inserted into a {widget}. Tried to insert: {item} of type {type(item)}\")\n",
   "        if sizing_mode is not None and _has_auto_sizing(item):\n",
   "            item.sizing_mode = sizing_mode\n",
   "        if isinstance(item, list):\n",
   "            return_list.append(_create_grid(item, sizing_mode, layer+1))\n",
   "        elif isinstance(item, LayoutDOM):\n",
   "            if sizing_mode is not None and _has_auto_sizing(item):\n",
   "                item.sizing_mode = sizing_mode\n",
   "            return_list.append(item)\n",
   "                Tried to insert: %s of type %s\"\"\" % (item, type(item))\n",
   "        return column(children=return_list, sizing_mode=sizing_mode, **kwargs)\n",
   "    return row(children=return_list, sizing_mode=sizing_mode, **kwargs)\n",
   "    assert isinstance(ncols, int), \"ncols must be an integer\"\n",
   "    for i in range(0, len(l), ncols):\n",
   "        yield l[i: i+ncols]\n"
  ]
 },
 "38": {
  "name": "children",
  "type": "NoneType",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/layouts.py",
  "lineno": "555",
  "column": "4",
  "context": "o\"\n\ndef _parse_children_arg(*args, **kwargs):\n    children = kwargs.get('children')\n\n    # Set-up Children from args or kwargs\n    if ",
  "context_lines": "#-----------------------------------------------------------------------------\n\ndef _has_auto_sizing(item):\n    return item.sizing_mode is None and item.width_policy == \"auto\" and item.height_policy == \"auto\"\n\ndef _parse_children_arg(*args, **kwargs):\n    children = kwargs.get('children')\n\n    # Set-up Children from args or kwargs\n    if len(args) > 0 and children is not None:\n        raise ValueError(\"'children' keyword cannot be used with positional arguments\")\n\n",
  "slicing": [
   "def row(*args, **kwargs):\n",
   "    sizing_mode = kwargs.pop('sizing_mode', None)\n",
   "    children = kwargs.pop('children', None)\n",
   "    children = _parse_children_arg(*args, children=children)\n",
   "    _handle_child_sizing(children, sizing_mode, widget=\"row\")\n",
   "    return Row(children=children, sizing_mode=sizing_mode, **kwargs)\n",
   "    sizing_mode = kwargs.pop('sizing_mode', None)\n",
   "    children = kwargs.pop('children', None)\n",
   "    children = _parse_children_arg(*args, children=children)\n",
   "    _handle_child_sizing(children, sizing_mode, widget=\"column\")\n",
   "    return Column(children=children, sizing_mode=sizing_mode, **kwargs)\n",
   "    sizing_mode = kwargs.pop('sizing_mode', None)\n",
   "    children = kwargs.pop('children', None)\n",
   "    children = _parse_children_arg(*args, children=children)\n",
   "    _handle_child_sizing(children, sizing_mode, widget=\"widget box\")\n",
   "    return WidgetBox(children=children, sizing_mode=sizing_mode, **kwargs)\n",
   "    sizing_mode = kwargs.pop('sizing_mode', None)\n",
   "    children = kwargs.pop('children', None)\n",
   "    children = _parse_children_arg(*args, children=children)\n",
   "    return _create_grid(children, sizing_mode, **kwargs)\n",
   "        toolbar_options = {}\n",
   "    children = _parse_children_arg(children=children)\n",
   "        if any(isinstance(child, list) for child in children):\n",
   "        children = list(_chunks(children, ncols))\n",
   "    if not children:\n",
   "        children = []\n",
   "    toolbars = []\n",
   "    items = []\n",
   "    for y, row in enumerate(children):\n",
   "        for x, item in enumerate(row):\n",
   "            if item is None:\n",
   "            elif isinstance(item, LayoutDOM):\n",
   "                    for plot in item.select(dict(type=Plot)):\n",
   "                        toolbars.append(plot.toolbar)\n",
   "                        plot.toolbar_location = None\n",
   "                if isinstance(item, Plot):\n",
   "                        item.plot_width = plot_width\n",
   "                        item.plot_height = plot_height\n",
   "                if sizing_mode is not None and _has_auto_sizing(item):\n",
   "                    item.sizing_mode = sizing_mode\n",
   "                items.append((item, y, x))\n",
   "        return GridBox(children=items, sizing_mode=sizing_mode)\n",
   "    grid = GridBox(children=items)\n",
   "    tools = sum([ toolbar.tools for toolbar in toolbars ], [])\n",
   "    proxy = ProxyToolbar(toolbars=toolbars, tools=tools, **toolbar_options)\n",
   "    toolbar = ToolbarBox(toolbar=proxy, toolbar_location=toolbar_location)\n",
   "        return Column(children=[toolbar, grid], sizing_mode=sizing_mode)\n",
   "        return Column(children=[grid, toolbar], sizing_mode=sizing_mode)\n",
   "        return Row(children=[toolbar, grid], sizing_mode=sizing_mode)\n",
   "        return Row(children=[grid, toolbar], sizing_mode=sizing_mode)\n",
   "    row = namedtuple(\"row\", [\"children\"])\n",
   "    col = namedtuple(\"col\", [\"children\"])\n",
   "    def flatten(layout):\n",
   "        Item = namedtuple(\"Item\", [\"layout\", \"r0\", \"c0\", \"r1\", \"c1\"])\n",
   "        Grid = namedtuple(\"Grid\", [\"nrows\", \"ncols\", \"items\"])\n",
   "        def gcd(a, b):\n",
   "            a, b = abs(a), abs(b)\n",
   "            while b != 0:\n",
   "                a, b = b, a % b\n",
   "            return a\n",
   "        def lcm(a, *rest):\n",
   "            for b in rest:\n",
   "                a = (a*b) // gcd(a, b)\n",
   "            return a\n",
   "        nonempty = lambda child: child.nrows != 0 and child.ncols != 0\n",
   "        def _flatten(layout):\n",
   "            if isinstance(layout, row):\n",
   "                children = list(filter(nonempty, map(_flatten, layout.children)))\n",
   "                if not children:\n",
   "                    return Grid(0, 0, [])\n",
   "                nrows = lcm(*[ child.nrows for child in children ])\n",
   "                ncols = sum(child.ncols for child in children)\n",
   "                items = []\n",
   "                offset = 0\n",
   "                for child in children:\n",
   "                    factor = nrows//child.nrows\n",
   "                    for (layout, r0, c0, r1, c1) in child.items:\n",
   "                        items.append((layout, factor*r0, c0 + offset, factor*r1, c1 + offset))\n",
   "                    offset += child.ncols\n",
   "                return Grid(nrows, ncols, items)\n",
   "            elif isinstance(layout, col):\n",
   "                children = list(filter(nonempty, map(_flatten, layout.children)))\n",
   "                if not children:\n",
   "                    return Grid(0, 0, [])\n",
   "                nrows = sum(child.nrows for child in children)\n",
   "                ncols = lcm(*[ child.ncols for child in children ])\n",
   "                items = []\n",
   "                offset = 0\n",
   "                for child in children:\n",
   "                    factor = ncols//child.ncols\n",
   "                    for (layout, r0, c0, r1, c1) in child.items:\n",
   "                        items.append((layout, r0 + offset, factor*c0, r1 + offset, factor*c1))\n",
   "                    offset += child.nrows\n",
   "                return Grid(nrows, ncols, items)\n",
   "                return Grid(1, 1, [Item(layout, 0, 0, 1, 1)])\n",
   "        grid = _flatten(layout)\n",
   "        children = []\n",
   "        for (layout, r0, c0, r1, c1) in grid.items:\n",
   "            if layout is not None:\n",
   "                children.append((layout, r0, c0, r1 - r0, c1 - c0))\n",
   "        return GridBox(children=children)\n",
   "    if isinstance(children, list):\n",
   "        if nrows is not None or ncols is not None:\n",
   "            N = len(children)\n",
   "            if ncols is None:\n",
   "                ncols = math.ceil(N/nrows)\n",
   "            layout = col([ row(children[i:i+ncols]) for i in range(0, N, ncols) ])\n",
   "            def traverse(children, level=0):\n",
   "                if isinstance(children, list):\n",
   "                    container = col if level % 2 == 0 else row\n",
   "                    return container([ traverse(child, level+1) for child in children ])\n",
   "                    return children\n",
   "            layout = traverse(children)\n",
   "    elif isinstance(children, LayoutDOM):\n",
   "        def is_usable(child):\n",
   "            return _has_auto_sizing(child) and child.spacing == 0\n",
   "        def traverse(item, top_level=False):\n",
   "            if isinstance(item, Box) and (top_level or is_usable(item)):\n",
   "                container = col if isinstance(item, Column) else row\n",
   "                return container(list(map(traverse, item.children)))\n",
   "                return item\n",
   "        layout = traverse(children, top_level=True)\n",
   "    elif isinstance(children, str):\n",
   "    grid = flatten(layout)\n",
   "    if sizing_mode is not None:\n",
   "        grid.sizing_mode = sizing_mode\n",
   "        for child in grid.children:\n",
   "            layout = child[0]\n",
   "            if _has_auto_sizing(layout):\n",
   "                layout.sizing_mode = sizing_mode\n",
   "    return grid\n",
   "        self.nrows = nrows\n",
   "        self.ncols = ncols\n",
   "        k1, k2 = key\n",
   "        if isinstance(k1, slice):\n",
   "            row1, row2, _ = k1.indices(self.nrows)\n",
   "            if k1 < 0:\n",
   "                k1 += self.nrows\n",
   "            if k1 >= self.nrows or k1 < 0:\n",
   "            row1, row2 = k1, None\n",
   "        if isinstance(k2, slice):\n",
   "            col1, col2, _ = k2.indices(self.ncols)\n",
   "            if k2 < 0:\n",
   "                k2 += self.ncols\n",
   "            if k2 >= self.ncols or k2 < 0:\n",
   "            col1, col2 = k2, None\n",
   "        def get_or_else(fn, default):\n",
   "                return fn()\n",
   "                return default\n",
   "        if row2 is None and col2 is None:\n",
   "            self._arrangement[row1, col1] = obj\n",
   "        elif row2 is None:\n",
   "            for col in range(col1, col2):\n",
   "                self._arrangement[row1, col] = get_or_else(lambda: obj[col-col1], None) # lgtm [py/loop-variable-capture]\n",
   "        elif col2 is None:\n",
   "            for row in range(row1, row2):\n",
   "                self._arrangement[row, col1] = get_or_else(lambda: obj[row-row1], None) # lgtm [py/loop-variable-capture]\n",
   "            for row, col in zip(range(row1, row2), range(col1, col2)):\n",
   "                self._arrangement[row, col] = get_or_else(lambda: obj[row-row1][col-col1], None) # lgtm [py/loop-variable-capture]\n",
   "        array = [ [ None ]*self.ncols for _ in range(0, self.nrows) ]\n",
   "        for (row, col), obj in self._arrangement.items():\n",
   "            array[row][col] = obj\n",
   "        return iter(array)\n",
   "    return item.sizing_mode is None and item.width_policy == \"auto\" and item.height_policy == \"auto\"\n",
   "    children = kwargs.get('children')\n",
   "    if len(args) > 0 and children is not None:\n",
   "    if not children:\n",
   "    return children\n",
   "    for item in children:\n",
   "        if not isinstance(item, LayoutDOM):\n",
   "            raise ValueError(f\"Only LayoutDOM items can be inserted into a {widget}. Tried to insert: {item} of type {type(item)}\")\n",
   "        if sizing_mode is not None and _has_auto_sizing(item):\n",
   "            item.sizing_mode = sizing_mode\n",
   "        if isinstance(item, list):\n",
   "            return_list.append(_create_grid(item, sizing_mode, layer+1))\n",
   "        elif isinstance(item, LayoutDOM):\n",
   "            if sizing_mode is not None and _has_auto_sizing(item):\n",
   "                item.sizing_mode = sizing_mode\n",
   "            return_list.append(item)\n",
   "                Tried to insert: %s of type %s\"\"\" % (item, type(item))\n",
   "        return column(children=return_list, sizing_mode=sizing_mode, **kwargs)\n",
   "    return row(children=return_list, sizing_mode=sizing_mode, **kwargs)\n",
   "    assert isinstance(ncols, int), \"ncols must be an integer\"\n",
   "    for i in range(0, len(l), ncols):\n",
   "        yield l[i: i+ncols]\n"
  ]
 },
 "39": {
  "name": "_CARTO_ATTRIBUTION",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/tile_providers.py",
  "lineno": "154",
  "column": "4",
  "context": "class _TileProvidersModule(types.ModuleType):\n    _CARTO_ATTRIBUTION = (\n        '&copy; <a href=\"https://www.openstreetmap",
  "context_lines": "#-----------------------------------------------------------------------------\n# Private API\n#-----------------------------------------------------------------------------\n\nclass _TileProvidersModule(types.ModuleType):\n    _CARTO_ATTRIBUTION = (\n        '&copy; <a href=\"https://www.openstreetmap.org/copyright\">OpenStreetMap</a> contributors,'\n        '&copy; <a href=\"https://cartodb.com/attributions\">CartoDB</a>'\n    )\n\n    _STAMEN_ATTRIBUTION = (\n",
  "slicing": "    _CARTO_ATTRIBUTION = (\n"
 },
 "40": {
  "name": "_STAMEN_ATTRIBUTION",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/tile_providers.py",
  "lineno": "159",
  "column": "4",
  "context": "cartodb.com/attributions\">CartoDB</a>'\n    )\n\n    _STAMEN_ATTRIBUTION = (\n        'Map tiles by <a href=\"https://stamen.com\"",
  "context_lines": "    _CARTO_ATTRIBUTION = (\n        '&copy; <a href=\"https://www.openstreetmap.org/copyright\">OpenStreetMap</a> contributors,'\n        '&copy; <a href=\"https://cartodb.com/attributions\">CartoDB</a>'\n    )\n\n    _STAMEN_ATTRIBUTION = (\n        'Map tiles by <a href=\"https://stamen.com\">Stamen Design</a>, '\n        'under <a href=\"https://creativecommons.org/licenses/by/3.0\">CC BY 3.0</a>. '\n        'Data by <a href=\"https://openstreetmap.org\">OpenStreetMap</a>, '\n        'under %s.'\n",
  "slicing": "    _STAMEN_ATTRIBUTION = (\n"
 },
 "41": {
  "name": "_OSM_ATTRIBTION",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/tile_providers.py",
  "lineno": "166",
  "column": "4",
  "context": "enStreetMap</a>, '\n        'under %s.'\n    )\n\n    _OSM_ATTRIBTION = (\n        '&copy; <a href=\"https://www.openstreetmap",
  "context_lines": "        'under <a href=\"https://creativecommons.org/licenses/by/3.0\">CC BY 3.0</a>. '\n        'Data by <a href=\"https://openstreetmap.org\">OpenStreetMap</a>, '\n        'under %s.'\n    )\n\n    _OSM_ATTRIBTION = (\n        '&copy; <a href=\"https://www.openstreetmap.org/copyright\">OpenStreetMap</a> contributors'\n    )\n\n    _WIKIMEDIA_ATTRIBUTION = (\n        '&copy; <a href=\"https://foundation.wikimedia.org/wiki/Maps_Terms_of_Use\">Wikimedia Maps</a> contributors'\n",
  "slicing": "    _OSM_ATTRIBTION = (\n"
 },
 "42": {
  "name": "_WIKIMEDIA_ATTRIBUTION",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/tile_providers.py",
  "lineno": "170",
  "column": "4",
  "context": "right\">OpenStreetMap</a> contributors'\n    )\n\n    _WIKIMEDIA_ATTRIBUTION = (\n        '&copy; <a href=\"https://foundation.wikime",
  "context_lines": "    )\n\n    _OSM_ATTRIBTION = (\n        '&copy; <a href=\"https://www.openstreetmap.org/copyright\">OpenStreetMap</a> contributors'\n    )\n\n    _WIKIMEDIA_ATTRIBUTION = (\n        '&copy; <a href=\"https://foundation.wikimedia.org/wiki/Maps_Terms_of_Use\">Wikimedia Maps</a> contributors'\n    )\n\n    _ESRI_IMAGERY_ATTRIBUTION = (\n        '&copy; <a href=\"http://downloads.esri.com/ArcGISOnline/docs/tou_summary.pdf\">Esri</a>, '\n",
  "slicing": "    _WIKIMEDIA_ATTRIBUTION = (\n"
 },
 "43": {
  "name": "_ESRI_IMAGERY_ATTRIBUTION",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/tile_providers.py",
  "lineno": "174",
  "column": "4",
  "context": "_Use\">Wikimedia Maps</a> contributors'\n    )\n\n    _ESRI_IMAGERY_ATTRIBUTION = (\n        '&copy; <a href=\"http://downloads.esri.com",
  "context_lines": "    )\n\n    _WIKIMEDIA_ATTRIBUTION = (\n        '&copy; <a href=\"https://foundation.wikimedia.org/wiki/Maps_Terms_of_Use\">Wikimedia Maps</a> contributors'\n    )\n\n    _ESRI_IMAGERY_ATTRIBUTION = (\n        '&copy; <a href=\"http://downloads.esri.com/ArcGISOnline/docs/tou_summary.pdf\">Esri</a>, '\n        'Earthstar Geographics'\n    )\n\n    _SERVICE_URLS = dict(\n",
  "slicing": "    _ESRI_IMAGERY_ATTRIBUTION = (\n"
 },
 "44": {
  "name": "CARTODBPOSITRON",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/tile_providers.py",
  "lineno": "236",
  "column": "4",
  "context": "--------------------------------------------\n\n    CARTODBPOSITRON = Vendors.CARTODBPOSITRON\n    CARTODBPOSITRON_RETINA = Vendors.CARTODBPOSITR",
  "context_lines": "        else:\n\n            raise RuntimeError('Can not retrieve attribution for %s' % selected_provider)\n        return WMTSTileSource(url=url, attribution=attribution)\n\n    # Properties --------------------------------------------------------------\n\n    CARTODBPOSITRON = Vendors.CARTODBPOSITRON\n    CARTODBPOSITRON_RETINA = Vendors.CARTODBPOSITRON_RETINA\n    STAMEN_TERRAIN = Vendors.STAMEN_TERRAIN\n    STAMEN_TERRAIN_RETINA = Vendors.STAMEN_TERRAIN_RETINA\n    STAMEN_TONER = Vendors.STAMEN_TONER\n",
  "slicing": [
   "    Vendors = enumeration('CARTODBPOSITRON', 'CARTODBPOSITRON_RETINA',\n",
   "        selected_provider = provider_name.upper()\n",
   "        if selected_provider not in self.Vendors:\n",
   "        url = self._SERVICE_URLS[selected_provider]\n",
   "        if selected_provider.startswith('CARTO'):\n",
   "            attribution = self._CARTO_ATTRIBUTION\n",
   "        elif selected_provider.startswith('STAMEN'):\n",
   "            attribution = self._STAMEN_ATTRIBUTION % self._STAMEN_ATTRIBUTION_URLS[selected_provider]\n",
   "        elif selected_provider.startswith('OSM'):\n",
   "            attribution = self._OSM_ATTRIBTION\n",
   "        elif selected_provider.startswith('WIKIMEDIA'):\n",
   "            attribution = self._WIKIMEDIA_ATTRIBUTION\n",
   "        elif selected_provider.startswith('ESRI_IMAGERY'):\n",
   "            attribution = self._ESRI_IMAGERY_ATTRIBUTION\n",
   "            raise RuntimeError('Can not retrieve attribution for %s' % selected_provider)\n",
   "        return WMTSTileSource(url=url, attribution=attribution)\n",
   "    CARTODBPOSITRON = Vendors.CARTODBPOSITRON\n",
   "    CARTODBPOSITRON_RETINA = Vendors.CARTODBPOSITRON_RETINA\n",
   "    STAMEN_TERRAIN = Vendors.STAMEN_TERRAIN\n",
   "    STAMEN_TERRAIN_RETINA = Vendors.STAMEN_TERRAIN_RETINA\n",
   "    STAMEN_TONER = Vendors.STAMEN_TONER\n",
   "    STAMEN_TONER_BACKGROUND = Vendors.STAMEN_TONER_BACKGROUND\n",
   "    STAMEN_TONER_LABELS = Vendors.STAMEN_TONER_LABELS\n",
   "    OSM = Vendors.OSM\n",
   "    WIKIMEDIA = Vendors.WIKIMEDIA\n",
   "    ESRI_IMAGERY = Vendors.ESRI_IMAGERY\n"
  ]
 },
 "45": {
  "name": "CARTODBPOSITRON_RETINA",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/tile_providers.py",
  "lineno": "237",
  "column": "4",
  "context": "    CARTODBPOSITRON = Vendors.CARTODBPOSITRON\n    CARTODBPOSITRON_RETINA = Vendors.CARTODBPOSITRON_RETINA\n    STAMEN_TERRAIN = Vendors.STAMEN_TERRAIN\n    ST",
  "context_lines": "            raise RuntimeError('Can not retrieve attribution for %s' % selected_provider)\n        return WMTSTileSource(url=url, attribution=attribution)\n\n    # Properties --------------------------------------------------------------\n\n    CARTODBPOSITRON = Vendors.CARTODBPOSITRON\n    CARTODBPOSITRON_RETINA = Vendors.CARTODBPOSITRON_RETINA\n    STAMEN_TERRAIN = Vendors.STAMEN_TERRAIN\n    STAMEN_TERRAIN_RETINA = Vendors.STAMEN_TERRAIN_RETINA\n    STAMEN_TONER = Vendors.STAMEN_TONER\n    STAMEN_TONER_BACKGROUND = Vendors.STAMEN_TONER_BACKGROUND\n",
  "slicing": [
   "    Vendors = enumeration('CARTODBPOSITRON', 'CARTODBPOSITRON_RETINA',\n",
   "        selected_provider = provider_name.upper()\n",
   "        if selected_provider not in self.Vendors:\n",
   "        url = self._SERVICE_URLS[selected_provider]\n",
   "        if selected_provider.startswith('CARTO'):\n",
   "            attribution = self._CARTO_ATTRIBUTION\n",
   "        elif selected_provider.startswith('STAMEN'):\n",
   "            attribution = self._STAMEN_ATTRIBUTION % self._STAMEN_ATTRIBUTION_URLS[selected_provider]\n",
   "        elif selected_provider.startswith('OSM'):\n",
   "            attribution = self._OSM_ATTRIBTION\n",
   "        elif selected_provider.startswith('WIKIMEDIA'):\n",
   "            attribution = self._WIKIMEDIA_ATTRIBUTION\n",
   "        elif selected_provider.startswith('ESRI_IMAGERY'):\n",
   "            attribution = self._ESRI_IMAGERY_ATTRIBUTION\n",
   "            raise RuntimeError('Can not retrieve attribution for %s' % selected_provider)\n",
   "        return WMTSTileSource(url=url, attribution=attribution)\n",
   "    CARTODBPOSITRON = Vendors.CARTODBPOSITRON\n",
   "    CARTODBPOSITRON_RETINA = Vendors.CARTODBPOSITRON_RETINA\n",
   "    STAMEN_TERRAIN = Vendors.STAMEN_TERRAIN\n",
   "    STAMEN_TERRAIN_RETINA = Vendors.STAMEN_TERRAIN_RETINA\n",
   "    STAMEN_TONER = Vendors.STAMEN_TONER\n",
   "    STAMEN_TONER_BACKGROUND = Vendors.STAMEN_TONER_BACKGROUND\n",
   "    STAMEN_TONER_LABELS = Vendors.STAMEN_TONER_LABELS\n",
   "    OSM = Vendors.OSM\n",
   "    WIKIMEDIA = Vendors.WIKIMEDIA\n",
   "    ESRI_IMAGERY = Vendors.ESRI_IMAGERY\n"
  ]
 },
 "46": {
  "name": "STAMEN_TERRAIN",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/tile_providers.py",
  "lineno": "238",
  "column": "4",
  "context": "ITRON_RETINA = Vendors.CARTODBPOSITRON_RETINA\n    STAMEN_TERRAIN = Vendors.STAMEN_TERRAIN\n    STAMEN_TERRAIN_RETINA = Vendors.STAMEN_TERRAIN",
  "context_lines": "        return WMTSTileSource(url=url, attribution=attribution)\n\n    # Properties --------------------------------------------------------------\n\n    CARTODBPOSITRON = Vendors.CARTODBPOSITRON\n    CARTODBPOSITRON_RETINA = Vendors.CARTODBPOSITRON_RETINA\n    STAMEN_TERRAIN = Vendors.STAMEN_TERRAIN\n    STAMEN_TERRAIN_RETINA = Vendors.STAMEN_TERRAIN_RETINA\n    STAMEN_TONER = Vendors.STAMEN_TONER\n    STAMEN_TONER_BACKGROUND = Vendors.STAMEN_TONER_BACKGROUND\n    STAMEN_TONER_LABELS = Vendors.STAMEN_TONER_LABELS\n",
  "slicing": [
   "    Vendors = enumeration('CARTODBPOSITRON', 'CARTODBPOSITRON_RETINA',\n",
   "        selected_provider = provider_name.upper()\n",
   "        if selected_provider not in self.Vendors:\n",
   "        url = self._SERVICE_URLS[selected_provider]\n",
   "        if selected_provider.startswith('CARTO'):\n",
   "            attribution = self._CARTO_ATTRIBUTION\n",
   "        elif selected_provider.startswith('STAMEN'):\n",
   "            attribution = self._STAMEN_ATTRIBUTION % self._STAMEN_ATTRIBUTION_URLS[selected_provider]\n",
   "        elif selected_provider.startswith('OSM'):\n",
   "            attribution = self._OSM_ATTRIBTION\n",
   "        elif selected_provider.startswith('WIKIMEDIA'):\n",
   "            attribution = self._WIKIMEDIA_ATTRIBUTION\n",
   "        elif selected_provider.startswith('ESRI_IMAGERY'):\n",
   "            attribution = self._ESRI_IMAGERY_ATTRIBUTION\n",
   "            raise RuntimeError('Can not retrieve attribution for %s' % selected_provider)\n",
   "        return WMTSTileSource(url=url, attribution=attribution)\n",
   "    CARTODBPOSITRON = Vendors.CARTODBPOSITRON\n",
   "    CARTODBPOSITRON_RETINA = Vendors.CARTODBPOSITRON_RETINA\n",
   "    STAMEN_TERRAIN = Vendors.STAMEN_TERRAIN\n",
   "    STAMEN_TERRAIN_RETINA = Vendors.STAMEN_TERRAIN_RETINA\n",
   "    STAMEN_TONER = Vendors.STAMEN_TONER\n",
   "    STAMEN_TONER_BACKGROUND = Vendors.STAMEN_TONER_BACKGROUND\n",
   "    STAMEN_TONER_LABELS = Vendors.STAMEN_TONER_LABELS\n",
   "    OSM = Vendors.OSM\n",
   "    WIKIMEDIA = Vendors.WIKIMEDIA\n",
   "    ESRI_IMAGERY = Vendors.ESRI_IMAGERY\n"
  ]
 },
 "47": {
  "name": "STAMEN_TERRAIN_RETINA",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/tile_providers.py",
  "lineno": "239",
  "column": "4",
  "context": "A\n    STAMEN_TERRAIN = Vendors.STAMEN_TERRAIN\n    STAMEN_TERRAIN_RETINA = Vendors.STAMEN_TERRAIN_RETINA\n    STAMEN_TONER = Vendors.STAMEN_TONER\n    STAMEN",
  "context_lines": "    # Properties --------------------------------------------------------------\n\n    CARTODBPOSITRON = Vendors.CARTODBPOSITRON\n    CARTODBPOSITRON_RETINA = Vendors.CARTODBPOSITRON_RETINA\n    STAMEN_TERRAIN = Vendors.STAMEN_TERRAIN\n    STAMEN_TERRAIN_RETINA = Vendors.STAMEN_TERRAIN_RETINA\n    STAMEN_TONER = Vendors.STAMEN_TONER\n    STAMEN_TONER_BACKGROUND = Vendors.STAMEN_TONER_BACKGROUND\n    STAMEN_TONER_LABELS = Vendors.STAMEN_TONER_LABELS\n    OSM = Vendors.OSM\n",
  "slicing": [
   "    Vendors = enumeration('CARTODBPOSITRON', 'CARTODBPOSITRON_RETINA',\n",
   "        selected_provider = provider_name.upper()\n",
   "        if selected_provider not in self.Vendors:\n",
   "        url = self._SERVICE_URLS[selected_provider]\n",
   "        if selected_provider.startswith('CARTO'):\n",
   "            attribution = self._CARTO_ATTRIBUTION\n",
   "        elif selected_provider.startswith('STAMEN'):\n",
   "            attribution = self._STAMEN_ATTRIBUTION % self._STAMEN_ATTRIBUTION_URLS[selected_provider]\n",
   "        elif selected_provider.startswith('OSM'):\n",
   "            attribution = self._OSM_ATTRIBTION\n",
   "        elif selected_provider.startswith('WIKIMEDIA'):\n",
   "            attribution = self._WIKIMEDIA_ATTRIBUTION\n",
   "        elif selected_provider.startswith('ESRI_IMAGERY'):\n",
   "            attribution = self._ESRI_IMAGERY_ATTRIBUTION\n",
   "            raise RuntimeError('Can not retrieve attribution for %s' % selected_provider)\n",
   "        return WMTSTileSource(url=url, attribution=attribution)\n",
   "    CARTODBPOSITRON = Vendors.CARTODBPOSITRON\n",
   "    CARTODBPOSITRON_RETINA = Vendors.CARTODBPOSITRON_RETINA\n",
   "    STAMEN_TERRAIN = Vendors.STAMEN_TERRAIN\n",
   "    STAMEN_TERRAIN_RETINA = Vendors.STAMEN_TERRAIN_RETINA\n",
   "    STAMEN_TONER = Vendors.STAMEN_TONER\n",
   "    STAMEN_TONER_BACKGROUND = Vendors.STAMEN_TONER_BACKGROUND\n",
   "    STAMEN_TONER_LABELS = Vendors.STAMEN_TONER_LABELS\n",
   "    OSM = Vendors.OSM\n",
   "    WIKIMEDIA = Vendors.WIKIMEDIA\n",
   "    ESRI_IMAGERY = Vendors.ESRI_IMAGERY\n"
  ]
 },
 "48": {
  "name": "STAMEN_TONER",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/tile_providers.py",
  "lineno": "240",
  "column": "4",
  "context": "ERRAIN_RETINA = Vendors.STAMEN_TERRAIN_RETINA\n    STAMEN_TONER = Vendors.STAMEN_TONER\n    STAMEN_TONER_BACKGROUND = Vendors.STAMEN_TONER",
  "context_lines": "    CARTODBPOSITRON = Vendors.CARTODBPOSITRON\n    CARTODBPOSITRON_RETINA = Vendors.CARTODBPOSITRON_RETINA\n    STAMEN_TERRAIN = Vendors.STAMEN_TERRAIN\n    STAMEN_TERRAIN_RETINA = Vendors.STAMEN_TERRAIN_RETINA\n    STAMEN_TONER = Vendors.STAMEN_TONER\n    STAMEN_TONER_BACKGROUND = Vendors.STAMEN_TONER_BACKGROUND\n    STAMEN_TONER_LABELS = Vendors.STAMEN_TONER_LABELS\n    OSM = Vendors.OSM\n    WIKIMEDIA = Vendors.WIKIMEDIA\n",
  "slicing": [
   "    Vendors = enumeration('CARTODBPOSITRON', 'CARTODBPOSITRON_RETINA',\n",
   "        selected_provider = provider_name.upper()\n",
   "        if selected_provider not in self.Vendors:\n",
   "        url = self._SERVICE_URLS[selected_provider]\n",
   "        if selected_provider.startswith('CARTO'):\n",
   "            attribution = self._CARTO_ATTRIBUTION\n",
   "        elif selected_provider.startswith('STAMEN'):\n",
   "            attribution = self._STAMEN_ATTRIBUTION % self._STAMEN_ATTRIBUTION_URLS[selected_provider]\n",
   "        elif selected_provider.startswith('OSM'):\n",
   "            attribution = self._OSM_ATTRIBTION\n",
   "        elif selected_provider.startswith('WIKIMEDIA'):\n",
   "            attribution = self._WIKIMEDIA_ATTRIBUTION\n",
   "        elif selected_provider.startswith('ESRI_IMAGERY'):\n",
   "            attribution = self._ESRI_IMAGERY_ATTRIBUTION\n",
   "            raise RuntimeError('Can not retrieve attribution for %s' % selected_provider)\n",
   "        return WMTSTileSource(url=url, attribution=attribution)\n",
   "    CARTODBPOSITRON = Vendors.CARTODBPOSITRON\n",
   "    CARTODBPOSITRON_RETINA = Vendors.CARTODBPOSITRON_RETINA\n",
   "    STAMEN_TERRAIN = Vendors.STAMEN_TERRAIN\n",
   "    STAMEN_TERRAIN_RETINA = Vendors.STAMEN_TERRAIN_RETINA\n",
   "    STAMEN_TONER = Vendors.STAMEN_TONER\n",
   "    STAMEN_TONER_BACKGROUND = Vendors.STAMEN_TONER_BACKGROUND\n",
   "    STAMEN_TONER_LABELS = Vendors.STAMEN_TONER_LABELS\n",
   "    OSM = Vendors.OSM\n",
   "    WIKIMEDIA = Vendors.WIKIMEDIA\n",
   "    ESRI_IMAGERY = Vendors.ESRI_IMAGERY\n"
  ]
 },
 "49": {
  "name": "STAMEN_TONER_BACKGROUND",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/tile_providers.py",
  "lineno": "241",
  "column": "4",
  "context": "ETINA\n    STAMEN_TONER = Vendors.STAMEN_TONER\n    STAMEN_TONER_BACKGROUND = Vendors.STAMEN_TONER_BACKGROUND\n    STAMEN_TONER_LABELS = Vendors.STAMEN_TONER_LAB",
  "context_lines": "    CARTODBPOSITRON_RETINA = Vendors.CARTODBPOSITRON_RETINA\n    STAMEN_TERRAIN = Vendors.STAMEN_TERRAIN\n    STAMEN_TERRAIN_RETINA = Vendors.STAMEN_TERRAIN_RETINA\n    STAMEN_TONER = Vendors.STAMEN_TONER\n    STAMEN_TONER_BACKGROUND = Vendors.STAMEN_TONER_BACKGROUND\n    STAMEN_TONER_LABELS = Vendors.STAMEN_TONER_LABELS\n    OSM = Vendors.OSM\n    WIKIMEDIA = Vendors.WIKIMEDIA\n    ESRI_IMAGERY = Vendors.ESRI_IMAGERY\n\n",
  "slicing": [
   "    Vendors = enumeration('CARTODBPOSITRON', 'CARTODBPOSITRON_RETINA',\n",
   "        selected_provider = provider_name.upper()\n",
   "        if selected_provider not in self.Vendors:\n",
   "        url = self._SERVICE_URLS[selected_provider]\n",
   "        if selected_provider.startswith('CARTO'):\n",
   "            attribution = self._CARTO_ATTRIBUTION\n",
   "        elif selected_provider.startswith('STAMEN'):\n",
   "            attribution = self._STAMEN_ATTRIBUTION % self._STAMEN_ATTRIBUTION_URLS[selected_provider]\n",
   "        elif selected_provider.startswith('OSM'):\n",
   "            attribution = self._OSM_ATTRIBTION\n",
   "        elif selected_provider.startswith('WIKIMEDIA'):\n",
   "            attribution = self._WIKIMEDIA_ATTRIBUTION\n",
   "        elif selected_provider.startswith('ESRI_IMAGERY'):\n",
   "            attribution = self._ESRI_IMAGERY_ATTRIBUTION\n",
   "            raise RuntimeError('Can not retrieve attribution for %s' % selected_provider)\n",
   "        return WMTSTileSource(url=url, attribution=attribution)\n",
   "    CARTODBPOSITRON = Vendors.CARTODBPOSITRON\n",
   "    CARTODBPOSITRON_RETINA = Vendors.CARTODBPOSITRON_RETINA\n",
   "    STAMEN_TERRAIN = Vendors.STAMEN_TERRAIN\n",
   "    STAMEN_TERRAIN_RETINA = Vendors.STAMEN_TERRAIN_RETINA\n",
   "    STAMEN_TONER = Vendors.STAMEN_TONER\n",
   "    STAMEN_TONER_BACKGROUND = Vendors.STAMEN_TONER_BACKGROUND\n",
   "    STAMEN_TONER_LABELS = Vendors.STAMEN_TONER_LABELS\n",
   "    OSM = Vendors.OSM\n",
   "    WIKIMEDIA = Vendors.WIKIMEDIA\n",
   "    ESRI_IMAGERY = Vendors.ESRI_IMAGERY\n"
  ]
 },
 "50": {
  "name": "STAMEN_TONER_LABELS",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/tile_providers.py",
  "lineno": "242",
  "column": "4",
  "context": "_BACKGROUND = Vendors.STAMEN_TONER_BACKGROUND\n    STAMEN_TONER_LABELS = Vendors.STAMEN_TONER_LABELS\n    OSM = Vendors.OSM\n    WIKIMEDIA = Vendors.WIKI",
  "context_lines": "    STAMEN_TERRAIN = Vendors.STAMEN_TERRAIN\n    STAMEN_TERRAIN_RETINA = Vendors.STAMEN_TERRAIN_RETINA\n    STAMEN_TONER = Vendors.STAMEN_TONER\n    STAMEN_TONER_BACKGROUND = Vendors.STAMEN_TONER_BACKGROUND\n    STAMEN_TONER_LABELS = Vendors.STAMEN_TONER_LABELS\n    OSM = Vendors.OSM\n    WIKIMEDIA = Vendors.WIKIMEDIA\n    ESRI_IMAGERY = Vendors.ESRI_IMAGERY\n\n#-----------------------------------------------------------------------------\n",
  "slicing": [
   "    Vendors = enumeration('CARTODBPOSITRON', 'CARTODBPOSITRON_RETINA',\n",
   "        selected_provider = provider_name.upper()\n",
   "        if selected_provider not in self.Vendors:\n",
   "        url = self._SERVICE_URLS[selected_provider]\n",
   "        if selected_provider.startswith('CARTO'):\n",
   "            attribution = self._CARTO_ATTRIBUTION\n",
   "        elif selected_provider.startswith('STAMEN'):\n",
   "            attribution = self._STAMEN_ATTRIBUTION % self._STAMEN_ATTRIBUTION_URLS[selected_provider]\n",
   "        elif selected_provider.startswith('OSM'):\n",
   "            attribution = self._OSM_ATTRIBTION\n",
   "        elif selected_provider.startswith('WIKIMEDIA'):\n",
   "            attribution = self._WIKIMEDIA_ATTRIBUTION\n",
   "        elif selected_provider.startswith('ESRI_IMAGERY'):\n",
   "            attribution = self._ESRI_IMAGERY_ATTRIBUTION\n",
   "            raise RuntimeError('Can not retrieve attribution for %s' % selected_provider)\n",
   "        return WMTSTileSource(url=url, attribution=attribution)\n",
   "    CARTODBPOSITRON = Vendors.CARTODBPOSITRON\n",
   "    CARTODBPOSITRON_RETINA = Vendors.CARTODBPOSITRON_RETINA\n",
   "    STAMEN_TERRAIN = Vendors.STAMEN_TERRAIN\n",
   "    STAMEN_TERRAIN_RETINA = Vendors.STAMEN_TERRAIN_RETINA\n",
   "    STAMEN_TONER = Vendors.STAMEN_TONER\n",
   "    STAMEN_TONER_BACKGROUND = Vendors.STAMEN_TONER_BACKGROUND\n",
   "    STAMEN_TONER_LABELS = Vendors.STAMEN_TONER_LABELS\n",
   "    OSM = Vendors.OSM\n",
   "    WIKIMEDIA = Vendors.WIKIMEDIA\n",
   "    ESRI_IMAGERY = Vendors.ESRI_IMAGERY\n"
  ]
 },
 "51": {
  "name": "OSM",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/tile_providers.py",
  "lineno": "243",
  "column": "4",
  "context": "EN_TONER_LABELS = Vendors.STAMEN_TONER_LABELS\n    OSM = Vendors.OSM\n    WIKIMEDIA = Vendors.WIKIMEDIA\n    ESRI_IMAGERY",
  "context_lines": "    STAMEN_TERRAIN_RETINA = Vendors.STAMEN_TERRAIN_RETINA\n    STAMEN_TONER = Vendors.STAMEN_TONER\n    STAMEN_TONER_BACKGROUND = Vendors.STAMEN_TONER_BACKGROUND\n    STAMEN_TONER_LABELS = Vendors.STAMEN_TONER_LABELS\n    OSM = Vendors.OSM\n    WIKIMEDIA = Vendors.WIKIMEDIA\n    ESRI_IMAGERY = Vendors.ESRI_IMAGERY\n\n#-----------------------------------------------------------------------------\n# Code\n",
  "slicing": [
   "    Vendors = enumeration('CARTODBPOSITRON', 'CARTODBPOSITRON_RETINA',\n",
   "        selected_provider = provider_name.upper()\n",
   "        if selected_provider not in self.Vendors:\n",
   "        url = self._SERVICE_URLS[selected_provider]\n",
   "        if selected_provider.startswith('CARTO'):\n",
   "            attribution = self._CARTO_ATTRIBUTION\n",
   "        elif selected_provider.startswith('STAMEN'):\n",
   "            attribution = self._STAMEN_ATTRIBUTION % self._STAMEN_ATTRIBUTION_URLS[selected_provider]\n",
   "        elif selected_provider.startswith('OSM'):\n",
   "            attribution = self._OSM_ATTRIBTION\n",
   "        elif selected_provider.startswith('WIKIMEDIA'):\n",
   "            attribution = self._WIKIMEDIA_ATTRIBUTION\n",
   "        elif selected_provider.startswith('ESRI_IMAGERY'):\n",
   "            attribution = self._ESRI_IMAGERY_ATTRIBUTION\n",
   "            raise RuntimeError('Can not retrieve attribution for %s' % selected_provider)\n",
   "        return WMTSTileSource(url=url, attribution=attribution)\n",
   "    CARTODBPOSITRON = Vendors.CARTODBPOSITRON\n",
   "    CARTODBPOSITRON_RETINA = Vendors.CARTODBPOSITRON_RETINA\n",
   "    STAMEN_TERRAIN = Vendors.STAMEN_TERRAIN\n",
   "    STAMEN_TERRAIN_RETINA = Vendors.STAMEN_TERRAIN_RETINA\n",
   "    STAMEN_TONER = Vendors.STAMEN_TONER\n",
   "    STAMEN_TONER_BACKGROUND = Vendors.STAMEN_TONER_BACKGROUND\n",
   "    STAMEN_TONER_LABELS = Vendors.STAMEN_TONER_LABELS\n",
   "    OSM = Vendors.OSM\n",
   "    WIKIMEDIA = Vendors.WIKIMEDIA\n",
   "    ESRI_IMAGERY = Vendors.ESRI_IMAGERY\n"
  ]
 },
 "52": {
  "name": "WIKIMEDIA",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/tile_providers.py",
  "lineno": "244",
  "column": "4",
  "context": "ors.STAMEN_TONER_LABELS\n    OSM = Vendors.OSM\n    WIKIMEDIA = Vendors.WIKIMEDIA\n    ESRI_IMAGERY = Vendors.ESRI_IMAGERY\n\n#--------",
  "context_lines": "    STAMEN_TONER = Vendors.STAMEN_TONER\n    STAMEN_TONER_BACKGROUND = Vendors.STAMEN_TONER_BACKGROUND\n    STAMEN_TONER_LABELS = Vendors.STAMEN_TONER_LABELS\n    OSM = Vendors.OSM\n    WIKIMEDIA = Vendors.WIKIMEDIA\n    ESRI_IMAGERY = Vendors.ESRI_IMAGERY\n\n#-----------------------------------------------------------------------------\n# Code\n#-----------------------------------------------------------------------------\n\n",
  "slicing": [
   "    Vendors = enumeration('CARTODBPOSITRON', 'CARTODBPOSITRON_RETINA',\n",
   "        selected_provider = provider_name.upper()\n",
   "        if selected_provider not in self.Vendors:\n",
   "        url = self._SERVICE_URLS[selected_provider]\n",
   "        if selected_provider.startswith('CARTO'):\n",
   "            attribution = self._CARTO_ATTRIBUTION\n",
   "        elif selected_provider.startswith('STAMEN'):\n",
   "            attribution = self._STAMEN_ATTRIBUTION % self._STAMEN_ATTRIBUTION_URLS[selected_provider]\n",
   "        elif selected_provider.startswith('OSM'):\n",
   "            attribution = self._OSM_ATTRIBTION\n",
   "        elif selected_provider.startswith('WIKIMEDIA'):\n",
   "            attribution = self._WIKIMEDIA_ATTRIBUTION\n",
   "        elif selected_provider.startswith('ESRI_IMAGERY'):\n",
   "            attribution = self._ESRI_IMAGERY_ATTRIBUTION\n",
   "            raise RuntimeError('Can not retrieve attribution for %s' % selected_provider)\n",
   "        return WMTSTileSource(url=url, attribution=attribution)\n",
   "    CARTODBPOSITRON = Vendors.CARTODBPOSITRON\n",
   "    CARTODBPOSITRON_RETINA = Vendors.CARTODBPOSITRON_RETINA\n",
   "    STAMEN_TERRAIN = Vendors.STAMEN_TERRAIN\n",
   "    STAMEN_TERRAIN_RETINA = Vendors.STAMEN_TERRAIN_RETINA\n",
   "    STAMEN_TONER = Vendors.STAMEN_TONER\n",
   "    STAMEN_TONER_BACKGROUND = Vendors.STAMEN_TONER_BACKGROUND\n",
   "    STAMEN_TONER_LABELS = Vendors.STAMEN_TONER_LABELS\n",
   "    OSM = Vendors.OSM\n",
   "    WIKIMEDIA = Vendors.WIKIMEDIA\n",
   "    ESRI_IMAGERY = Vendors.ESRI_IMAGERY\n"
  ]
 },
 "53": {
  "name": "ESRI_IMAGERY",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/tile_providers.py",
  "lineno": "245",
  "column": "4",
  "context": "Vendors.OSM\n    WIKIMEDIA = Vendors.WIKIMEDIA\n    ESRI_IMAGERY = Vendors.ESRI_IMAGERY\n\n#------------------------------------------------",
  "context_lines": "    STAMEN_TONER_BACKGROUND = Vendors.STAMEN_TONER_BACKGROUND\n    STAMEN_TONER_LABELS = Vendors.STAMEN_TONER_LABELS\n    OSM = Vendors.OSM\n    WIKIMEDIA = Vendors.WIKIMEDIA\n    ESRI_IMAGERY = Vendors.ESRI_IMAGERY\n\n#-----------------------------------------------------------------------------\n# Code\n#-----------------------------------------------------------------------------\n\n",
  "slicing": [
   "    Vendors = enumeration('CARTODBPOSITRON', 'CARTODBPOSITRON_RETINA',\n",
   "        selected_provider = provider_name.upper()\n",
   "        if selected_provider not in self.Vendors:\n",
   "        url = self._SERVICE_URLS[selected_provider]\n",
   "        if selected_provider.startswith('CARTO'):\n",
   "            attribution = self._CARTO_ATTRIBUTION\n",
   "        elif selected_provider.startswith('STAMEN'):\n",
   "            attribution = self._STAMEN_ATTRIBUTION % self._STAMEN_ATTRIBUTION_URLS[selected_provider]\n",
   "        elif selected_provider.startswith('OSM'):\n",
   "            attribution = self._OSM_ATTRIBTION\n",
   "        elif selected_provider.startswith('WIKIMEDIA'):\n",
   "            attribution = self._WIKIMEDIA_ATTRIBUTION\n",
   "        elif selected_provider.startswith('ESRI_IMAGERY'):\n",
   "            attribution = self._ESRI_IMAGERY_ATTRIBUTION\n",
   "            raise RuntimeError('Can not retrieve attribution for %s' % selected_provider)\n",
   "        return WMTSTileSource(url=url, attribution=attribution)\n",
   "    CARTODBPOSITRON = Vendors.CARTODBPOSITRON\n",
   "    CARTODBPOSITRON_RETINA = Vendors.CARTODBPOSITRON_RETINA\n",
   "    STAMEN_TERRAIN = Vendors.STAMEN_TERRAIN\n",
   "    STAMEN_TERRAIN_RETINA = Vendors.STAMEN_TERRAIN_RETINA\n",
   "    STAMEN_TONER = Vendors.STAMEN_TONER\n",
   "    STAMEN_TONER_BACKGROUND = Vendors.STAMEN_TONER_BACKGROUND\n",
   "    STAMEN_TONER_LABELS = Vendors.STAMEN_TONER_LABELS\n",
   "    OSM = Vendors.OSM\n",
   "    WIKIMEDIA = Vendors.WIKIMEDIA\n",
   "    ESRI_IMAGERY = Vendors.ESRI_IMAGERY\n"
  ]
 },
 "54": {
  "name": "_default_root_dir",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/resources.py",
  "lineno": "204",
  "column": "4",
  "context": " the package: {bad!r}\")\n\nclass BaseResources:\n    _default_root_dir = \".\"\n    _default_root_url = DEFAULT_SERVER_HTTP_URL\n\n ",
  "context_lines": "            bad.append(path)\n\n    if bad:\n        raise RuntimeError(f\"SRI Hash mismatches in the package: {bad!r}\")\n\nclass BaseResources:\n    _default_root_dir = \".\"\n    _default_root_url = DEFAULT_SERVER_HTTP_URL\n\n    def __init__(\n        self,\n        mode=None,\n",
  "slicing": "    _default_root_dir = \".\"\n"
 },
 "55": {
  "name": "_default_root_url",
  "type": "str",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/resources.py",
  "lineno": "205",
  "column": "4",
  "context": "ss BaseResources:\n    _default_root_dir = \".\"\n    _default_root_url = DEFAULT_SERVER_HTTP_URL\n\n    def __init__(\n        self,\n        mode=None",
  "context_lines": "    if bad:\n        raise RuntimeError(f\"SRI Hash mismatches in the package: {bad!r}\")\n\nclass BaseResources:\n    _default_root_dir = \".\"\n    _default_root_url = DEFAULT_SERVER_HTTP_URL\n\n    def __init__(\n        self,\n        mode=None,\n",
  "slicing": [
   "DEFAULT_SERVER_HOST = \"localhost\"\n",
   "DEFAULT_SERVER_PORT = 5006\n",
   "DEFAULT_SERVER_HTTP_URL = \"http://%s:%d/\" % (DEFAULT_SERVER_HOST, DEFAULT_SERVER_PORT)\n",
   "_SRI_HASHES = None\n",
   "    if not _SRI_HASHES:\n",
   "        with open(join(ROOT_DIR, \"_sri.json\")) as f:\n",
   "            _SRI_HASHES = json.load(f)\n",
   "    return dict(_SRI_HASHES)\n",
   "def get_sri_hashes_for_version(version):\n",
   "    hashes = get_all_sri_hashes()\n",
   "    return hashes[version]\n",
   "    paths = glob(join(bokehjsdir(), \"js/bokeh*.js\"))\n",
   "    hashes = get_sri_hashes_for_version(__version__)\n",
   "    if len(hashes) < len(paths):\n",
   "    if len(hashes) > len(paths):\n",
   "    bad = []\n",
   "    for path in paths:\n",
   "        name, suffix = basename(path).split(\".\", 1)\n",
   "        filename = f\"{name}-{__version__}.{suffix}\"\n",
   "        sri_hash = _compute_single_hash(path)\n",
   "        if hashes[filename] != sri_hash:\n",
   "            bad.append(path)\n",
   "    if bad:\n",
   "        raise RuntimeError(f\"SRI Hash mismatches in the package: {bad!r}\")\n",
   "    _default_root_url = DEFAULT_SERVER_HTTP_URL\n",
   "        if version and not self.mode.startswith(\"cdn\"):\n",
   "        self.version = settings.cdn_version(version)\n",
   "            root_url = root_url + \"/\"\n",
   "        self._root_url = root_url\n",
   "            cdn = self._cdn_urls()\n",
   "            self.messages.extend(cdn[\"messages\"])\n",
   "            server = self._server_urls()\n",
   "            self.messages.extend(server[\"messages\"])\n",
   "        valid_levels = [\"trace\", \"debug\", \"info\", \"warn\", \"error\", \"fatal\"]\n",
   "        if not (level is None or level in valid_levels):\n",
   "            raise ValueError(\"Unknown log level '{}', valid levels are: {}\".format(level, str(valid_levels)))\n",
   "        components = self.js_components if kind == \"js\" else self.css_components\n",
   "            components = [c for c in components if c in self._components]\n",
   "        return components\n",
   "        minified = \".min\" if not self.dev and self.minified else \"\"\n",
   "        files = [\"%s%s.%s\" % (component, minified, kind) for component in self.components(kind)]\n",
   "        paths = [join(self.base_dir, kind, file) for file in files]\n",
   "        return paths\n",
   "        external_resources = []\n",
   "        for _, cls in sorted(Model.model_class_reverse_map.items(), key=lambda arg: arg[0]):\n",
   "            external = getattr(cls, resource_attr, None)\n",
   "            if isinstance(external, str):\n",
   "                if external not in external_resources:\n",
   "                    external_resources.append(external)\n",
   "            elif isinstance(external, list):\n",
   "                for e in external:\n",
   "                    if e not in external_resources:\n",
   "                        external_resources.append(e)\n",
   "        return external_resources\n",
   "        paths = self._file_paths(kind)\n",
   "        files, raw = [], []\n",
   "        hashes = {}\n",
   "            raw = [self._inline(path) for path in paths]\n",
   "            root_dir = self.root_dir or self._default_root_dir\n",
   "            files = [relpath(path, root_dir) for path in paths]\n",
   "            files = list(paths)\n",
   "            cdn = self._cdn_urls()\n",
   "            files = list(cdn[\"urls\"](self.components(kind), kind))\n",
   "            if cdn[\"hashes\"]:\n",
   "                hashes = cdn[\"hashes\"](self.components(kind), kind)\n",
   "            server = self._server_urls()\n",
   "            files = list(server[\"urls\"](self.components(kind), kind))\n",
   "        return (files, raw, hashes)\n",
   "        begin = \"/* BEGIN %s */\" % basename(path)\n",
   "        with open(path, \"rb\") as f:\n",
   "            middle = f.read().decode(\"utf-8\")\n",
   "        end = \"/* END %s */\" % basename(path)\n",
   "        return \"%s\\n%s\\n%s\" % (begin, middle, end)\n",
   "        files, _, __ = self._resolve(\"js\")\n",
   "        external_resources = self._collect_external_resources(\"__javascript__\")\n",
   "        return external_resources + files\n",
   "        _, raw, __ = self._resolve(\"js\")\n",
   "            raw.append('Bokeh.set_log_level(\"%s\");' % self.log_level)\n",
   "            raw.append(\"Bokeh.settings.dev = true\")\n",
   "        return raw\n",
   "        _, __, hashes = self._resolve(\"js\")\n",
   "        return hashes\n",
   "        files, _, __ = self._resolve(\"css\")\n",
   "        external_resources = self._collect_external_resources(\"__css__\")\n",
   "        return external_resources + files\n",
   "        _, raw, __ = self._resolve(\"css\")\n",
   "        return raw\n",
   "        return [json.dumps(css) for css in self.css_raw]\n",
   "        self._url = kwargs.get(\"url\", DEFAULT_SERVER_HTTP_URL)\n",
   "            self._url = DEFAULT_SERVER_HTTP_URL\n",
   "_DEV_PAT = re.compile(r\"^(\\d)+\\.(\\d)+\\.(\\d)+(dev|rc)\")\n",
   "    if version is None:\n",
   "            version = settings.docs_cdn()\n",
   "            version = __version__.split(\"-\")[0]\n",
   "    _minified = \".min\" if minified else \"\"\n",
   "    _legacy = \".legacy\" if legacy else \"\"\n",
   "    base_url = _cdn_base_url()\n",
   "    dev_container = \"bokeh/dev\"\n",
   "    rel_container = \"bokeh/release\"\n",
   "    container = dev_container if _DEV_PAT.match(version) else rel_container\n",
   "    def mk_filename(comp, kind):\n",
   "        return f\"{comp}-{version}{_legacy}{_minified}.{kind}\"\n",
   "    def mk_url(comp, kind):\n",
   "        return f\"{base_url}/{container}/\" + mk_filename(comp, kind)\n",
   "    result = {\n",
   "        \"urls\": lambda components, kind: [mk_url(component, kind) for component in components],\n",
   "        result[\"messages\"].append(\n",
   "                    \"This configuration is unsupported and may not work!\" % (version, __version__)\n",
   "    if is_full_release(version):\n",
   "        sri_hashes = get_sri_hashes_for_version(version)\n",
   "        result['hashes'] = lambda components, kind: {mk_url(component, kind): sri_hashes[mk_filename(component, kind)] for component in components}\n",
   "    return result\n",
   "    _minified = \".min\" if minified else \"\"\n",
   "    _legacy = \".legacy\" if legacy else \"\"\n",
   "    def mk_url(comp, kind):\n",
   "        path = f\"{kind}/{comp}{_legacy}{_minified}.{kind}\"\n",
   "            path = path_versioner(path)\n",
   "        return f\"{root_url}static/{path}\"\n",
   "    return {\"urls\": lambda components, kind: [mk_url(component, kind) for component in components], \"messages\": []}\n",
   "    assert path.endswith(\".js\")\n",
   "    digest = f\"openssl dgst -sha384 -binary {path}\".split()\n",
   "    p1 = Popen(digest, stdout=PIPE)\n",
   "    b64 = \"openssl base64 -A\".split()\n",
   "    p2 = Popen(b64, stdin=p1.stdout, stdout=PIPE)\n",
   "    out, _ = p2.communicate()\n",
   "    return out.decode(\"utf-8\").strip()\n"
  ]
 },
 "56": {
  "name": "_minified",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/resources.py",
  "lineno": "647",
  "column": "4",
  "context": "]\n\n    # check if we want minified js and css\n    _minified = \".min\" if minified else \"\"\n    _legacy = \".legacy\" if legacy else \"\"\n\n    bas",
  "context_lines": "            version = settings.docs_cdn()\n        else:\n            version = __version__.split(\"-\")[0]\n\n    # check if we want minified js and css\n    _minified = \".min\" if minified else \"\"\n    _legacy = \".legacy\" if legacy else \"\"\n\n    base_url = _cdn_base_url()\n    dev_container = \"bokeh/dev\"\n    rel_container = \"bokeh/release\"\n\n",
  "slicing": [
   "DEFAULT_SERVER_HOST = \"localhost\"\n",
   "DEFAULT_SERVER_PORT = 5006\n",
   "DEFAULT_SERVER_HTTP_URL = \"http://%s:%d/\" % (DEFAULT_SERVER_HOST, DEFAULT_SERVER_PORT)\n",
   "_SRI_HASHES = None\n",
   "    if not _SRI_HASHES:\n",
   "        with open(join(ROOT_DIR, \"_sri.json\")) as f:\n",
   "            _SRI_HASHES = json.load(f)\n",
   "    return dict(_SRI_HASHES)\n",
   "def get_sri_hashes_for_version(version):\n",
   "    hashes = get_all_sri_hashes()\n",
   "    return hashes[version]\n",
   "    paths = glob(join(bokehjsdir(), \"js/bokeh*.js\"))\n",
   "    hashes = get_sri_hashes_for_version(__version__)\n",
   "    if len(hashes) < len(paths):\n",
   "    if len(hashes) > len(paths):\n",
   "    bad = []\n",
   "    for path in paths:\n",
   "        name, suffix = basename(path).split(\".\", 1)\n",
   "        filename = f\"{name}-{__version__}.{suffix}\"\n",
   "        sri_hash = _compute_single_hash(path)\n",
   "        if hashes[filename] != sri_hash:\n",
   "            bad.append(path)\n",
   "    if bad:\n",
   "        raise RuntimeError(f\"SRI Hash mismatches in the package: {bad!r}\")\n",
   "    _default_root_url = DEFAULT_SERVER_HTTP_URL\n",
   "        if version and not self.mode.startswith(\"cdn\"):\n",
   "        self.version = settings.cdn_version(version)\n",
   "            root_url = root_url + \"/\"\n",
   "        self._root_url = root_url\n",
   "            cdn = self._cdn_urls()\n",
   "            self.messages.extend(cdn[\"messages\"])\n",
   "            server = self._server_urls()\n",
   "            self.messages.extend(server[\"messages\"])\n",
   "        valid_levels = [\"trace\", \"debug\", \"info\", \"warn\", \"error\", \"fatal\"]\n",
   "        if not (level is None or level in valid_levels):\n",
   "            raise ValueError(\"Unknown log level '{}', valid levels are: {}\".format(level, str(valid_levels)))\n",
   "        components = self.js_components if kind == \"js\" else self.css_components\n",
   "            components = [c for c in components if c in self._components]\n",
   "        return components\n",
   "        minified = \".min\" if not self.dev and self.minified else \"\"\n",
   "        files = [\"%s%s.%s\" % (component, minified, kind) for component in self.components(kind)]\n",
   "        paths = [join(self.base_dir, kind, file) for file in files]\n",
   "        return paths\n",
   "        external_resources = []\n",
   "        for _, cls in sorted(Model.model_class_reverse_map.items(), key=lambda arg: arg[0]):\n",
   "            external = getattr(cls, resource_attr, None)\n",
   "            if isinstance(external, str):\n",
   "                if external not in external_resources:\n",
   "                    external_resources.append(external)\n",
   "            elif isinstance(external, list):\n",
   "                for e in external:\n",
   "                    if e not in external_resources:\n",
   "                        external_resources.append(e)\n",
   "        return external_resources\n",
   "        paths = self._file_paths(kind)\n",
   "        files, raw = [], []\n",
   "        hashes = {}\n",
   "            raw = [self._inline(path) for path in paths]\n",
   "            root_dir = self.root_dir or self._default_root_dir\n",
   "            files = [relpath(path, root_dir) for path in paths]\n",
   "            files = list(paths)\n",
   "            cdn = self._cdn_urls()\n",
   "            files = list(cdn[\"urls\"](self.components(kind), kind))\n",
   "            if cdn[\"hashes\"]:\n",
   "                hashes = cdn[\"hashes\"](self.components(kind), kind)\n",
   "            server = self._server_urls()\n",
   "            files = list(server[\"urls\"](self.components(kind), kind))\n",
   "        return (files, raw, hashes)\n",
   "        begin = \"/* BEGIN %s */\" % basename(path)\n",
   "        with open(path, \"rb\") as f:\n",
   "            middle = f.read().decode(\"utf-8\")\n",
   "        end = \"/* END %s */\" % basename(path)\n",
   "        return \"%s\\n%s\\n%s\" % (begin, middle, end)\n",
   "        files, _, __ = self._resolve(\"js\")\n",
   "        external_resources = self._collect_external_resources(\"__javascript__\")\n",
   "        return external_resources + files\n",
   "        _, raw, __ = self._resolve(\"js\")\n",
   "            raw.append('Bokeh.set_log_level(\"%s\");' % self.log_level)\n",
   "            raw.append(\"Bokeh.settings.dev = true\")\n",
   "        return raw\n",
   "        _, __, hashes = self._resolve(\"js\")\n",
   "        return hashes\n",
   "        files, _, __ = self._resolve(\"css\")\n",
   "        external_resources = self._collect_external_resources(\"__css__\")\n",
   "        return external_resources + files\n",
   "        _, raw, __ = self._resolve(\"css\")\n",
   "        return raw\n",
   "        return [json.dumps(css) for css in self.css_raw]\n",
   "        self._url = kwargs.get(\"url\", DEFAULT_SERVER_HTTP_URL)\n",
   "            self._url = DEFAULT_SERVER_HTTP_URL\n",
   "_DEV_PAT = re.compile(r\"^(\\d)+\\.(\\d)+\\.(\\d)+(dev|rc)\")\n",
   "    if version is None:\n",
   "            version = settings.docs_cdn()\n",
   "            version = __version__.split(\"-\")[0]\n",
   "    _minified = \".min\" if minified else \"\"\n",
   "    _legacy = \".legacy\" if legacy else \"\"\n",
   "    base_url = _cdn_base_url()\n",
   "    dev_container = \"bokeh/dev\"\n",
   "    rel_container = \"bokeh/release\"\n",
   "    container = dev_container if _DEV_PAT.match(version) else rel_container\n",
   "    def mk_filename(comp, kind):\n",
   "        return f\"{comp}-{version}{_legacy}{_minified}.{kind}\"\n",
   "    def mk_url(comp, kind):\n",
   "        return f\"{base_url}/{container}/\" + mk_filename(comp, kind)\n",
   "    result = {\n",
   "        \"urls\": lambda components, kind: [mk_url(component, kind) for component in components],\n",
   "        result[\"messages\"].append(\n",
   "                    \"This configuration is unsupported and may not work!\" % (version, __version__)\n",
   "    if is_full_release(version):\n",
   "        sri_hashes = get_sri_hashes_for_version(version)\n",
   "        result['hashes'] = lambda components, kind: {mk_url(component, kind): sri_hashes[mk_filename(component, kind)] for component in components}\n",
   "    return result\n",
   "    _minified = \".min\" if minified else \"\"\n",
   "    _legacy = \".legacy\" if legacy else \"\"\n",
   "    def mk_url(comp, kind):\n",
   "        path = f\"{kind}/{comp}{_legacy}{_minified}.{kind}\"\n",
   "            path = path_versioner(path)\n",
   "        return f\"{root_url}static/{path}\"\n",
   "    return {\"urls\": lambda components, kind: [mk_url(component, kind) for component in components], \"messages\": []}\n",
   "    assert path.endswith(\".js\")\n",
   "    digest = f\"openssl dgst -sha384 -binary {path}\".split()\n",
   "    p1 = Popen(digest, stdout=PIPE)\n",
   "    b64 = \"openssl base64 -A\".split()\n",
   "    p2 = Popen(b64, stdin=p1.stdout, stdout=PIPE)\n",
   "    out, _ = p2.communicate()\n",
   "    return out.decode(\"utf-8\").strip()\n"
  ]
 },
 "57": {
  "name": "_legacy",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/resources.py",
  "lineno": "648",
  "column": "4",
  "context": "ss\n    _minified = \".min\" if minified else \"\"\n    _legacy = \".legacy\" if legacy else \"\"\n\n    base_url = _cdn_base_url()\n    dev_container ",
  "context_lines": "        else:\n            version = __version__.split(\"-\")[0]\n\n    # check if we want minified js and css\n    _minified = \".min\" if minified else \"\"\n    _legacy = \".legacy\" if legacy else \"\"\n\n    base_url = _cdn_base_url()\n    dev_container = \"bokeh/dev\"\n    rel_container = \"bokeh/release\"\n\n",
  "slicing": [
   "DEFAULT_SERVER_HOST = \"localhost\"\n",
   "DEFAULT_SERVER_PORT = 5006\n",
   "DEFAULT_SERVER_HTTP_URL = \"http://%s:%d/\" % (DEFAULT_SERVER_HOST, DEFAULT_SERVER_PORT)\n",
   "_SRI_HASHES = None\n",
   "    if not _SRI_HASHES:\n",
   "        with open(join(ROOT_DIR, \"_sri.json\")) as f:\n",
   "            _SRI_HASHES = json.load(f)\n",
   "    return dict(_SRI_HASHES)\n",
   "def get_sri_hashes_for_version(version):\n",
   "    hashes = get_all_sri_hashes()\n",
   "    return hashes[version]\n",
   "    paths = glob(join(bokehjsdir(), \"js/bokeh*.js\"))\n",
   "    hashes = get_sri_hashes_for_version(__version__)\n",
   "    if len(hashes) < len(paths):\n",
   "    if len(hashes) > len(paths):\n",
   "    bad = []\n",
   "    for path in paths:\n",
   "        name, suffix = basename(path).split(\".\", 1)\n",
   "        filename = f\"{name}-{__version__}.{suffix}\"\n",
   "        sri_hash = _compute_single_hash(path)\n",
   "        if hashes[filename] != sri_hash:\n",
   "            bad.append(path)\n",
   "    if bad:\n",
   "        raise RuntimeError(f\"SRI Hash mismatches in the package: {bad!r}\")\n",
   "    _default_root_url = DEFAULT_SERVER_HTTP_URL\n",
   "        if version and not self.mode.startswith(\"cdn\"):\n",
   "        self.version = settings.cdn_version(version)\n",
   "            root_url = root_url + \"/\"\n",
   "        self._root_url = root_url\n",
   "            cdn = self._cdn_urls()\n",
   "            self.messages.extend(cdn[\"messages\"])\n",
   "            server = self._server_urls()\n",
   "            self.messages.extend(server[\"messages\"])\n",
   "        valid_levels = [\"trace\", \"debug\", \"info\", \"warn\", \"error\", \"fatal\"]\n",
   "        if not (level is None or level in valid_levels):\n",
   "            raise ValueError(\"Unknown log level '{}', valid levels are: {}\".format(level, str(valid_levels)))\n",
   "        components = self.js_components if kind == \"js\" else self.css_components\n",
   "            components = [c for c in components if c in self._components]\n",
   "        return components\n",
   "        minified = \".min\" if not self.dev and self.minified else \"\"\n",
   "        files = [\"%s%s.%s\" % (component, minified, kind) for component in self.components(kind)]\n",
   "        paths = [join(self.base_dir, kind, file) for file in files]\n",
   "        return paths\n",
   "        external_resources = []\n",
   "        for _, cls in sorted(Model.model_class_reverse_map.items(), key=lambda arg: arg[0]):\n",
   "            external = getattr(cls, resource_attr, None)\n",
   "            if isinstance(external, str):\n",
   "                if external not in external_resources:\n",
   "                    external_resources.append(external)\n",
   "            elif isinstance(external, list):\n",
   "                for e in external:\n",
   "                    if e not in external_resources:\n",
   "                        external_resources.append(e)\n",
   "        return external_resources\n",
   "        paths = self._file_paths(kind)\n",
   "        files, raw = [], []\n",
   "        hashes = {}\n",
   "            raw = [self._inline(path) for path in paths]\n",
   "            root_dir = self.root_dir or self._default_root_dir\n",
   "            files = [relpath(path, root_dir) for path in paths]\n",
   "            files = list(paths)\n",
   "            cdn = self._cdn_urls()\n",
   "            files = list(cdn[\"urls\"](self.components(kind), kind))\n",
   "            if cdn[\"hashes\"]:\n",
   "                hashes = cdn[\"hashes\"](self.components(kind), kind)\n",
   "            server = self._server_urls()\n",
   "            files = list(server[\"urls\"](self.components(kind), kind))\n",
   "        return (files, raw, hashes)\n",
   "        begin = \"/* BEGIN %s */\" % basename(path)\n",
   "        with open(path, \"rb\") as f:\n",
   "            middle = f.read().decode(\"utf-8\")\n",
   "        end = \"/* END %s */\" % basename(path)\n",
   "        return \"%s\\n%s\\n%s\" % (begin, middle, end)\n",
   "        files, _, __ = self._resolve(\"js\")\n",
   "        external_resources = self._collect_external_resources(\"__javascript__\")\n",
   "        return external_resources + files\n",
   "        _, raw, __ = self._resolve(\"js\")\n",
   "            raw.append('Bokeh.set_log_level(\"%s\");' % self.log_level)\n",
   "            raw.append(\"Bokeh.settings.dev = true\")\n",
   "        return raw\n",
   "        _, __, hashes = self._resolve(\"js\")\n",
   "        return hashes\n",
   "        files, _, __ = self._resolve(\"css\")\n",
   "        external_resources = self._collect_external_resources(\"__css__\")\n",
   "        return external_resources + files\n",
   "        _, raw, __ = self._resolve(\"css\")\n",
   "        return raw\n",
   "        return [json.dumps(css) for css in self.css_raw]\n",
   "        self._url = kwargs.get(\"url\", DEFAULT_SERVER_HTTP_URL)\n",
   "            self._url = DEFAULT_SERVER_HTTP_URL\n",
   "_DEV_PAT = re.compile(r\"^(\\d)+\\.(\\d)+\\.(\\d)+(dev|rc)\")\n",
   "    if version is None:\n",
   "            version = settings.docs_cdn()\n",
   "            version = __version__.split(\"-\")[0]\n",
   "    _minified = \".min\" if minified else \"\"\n",
   "    _legacy = \".legacy\" if legacy else \"\"\n",
   "    base_url = _cdn_base_url()\n",
   "    dev_container = \"bokeh/dev\"\n",
   "    rel_container = \"bokeh/release\"\n",
   "    container = dev_container if _DEV_PAT.match(version) else rel_container\n",
   "    def mk_filename(comp, kind):\n",
   "        return f\"{comp}-{version}{_legacy}{_minified}.{kind}\"\n",
   "    def mk_url(comp, kind):\n",
   "        return f\"{base_url}/{container}/\" + mk_filename(comp, kind)\n",
   "    result = {\n",
   "        \"urls\": lambda components, kind: [mk_url(component, kind) for component in components],\n",
   "        result[\"messages\"].append(\n",
   "                    \"This configuration is unsupported and may not work!\" % (version, __version__)\n",
   "    if is_full_release(version):\n",
   "        sri_hashes = get_sri_hashes_for_version(version)\n",
   "        result['hashes'] = lambda components, kind: {mk_url(component, kind): sri_hashes[mk_filename(component, kind)] for component in components}\n",
   "    return result\n",
   "    _minified = \".min\" if minified else \"\"\n",
   "    _legacy = \".legacy\" if legacy else \"\"\n",
   "    def mk_url(comp, kind):\n",
   "        path = f\"{kind}/{comp}{_legacy}{_minified}.{kind}\"\n",
   "            path = path_versioner(path)\n",
   "        return f\"{root_url}static/{path}\"\n",
   "    return {\"urls\": lambda components, kind: [mk_url(component, kind) for component in components], \"messages\": []}\n",
   "    assert path.endswith(\".js\")\n",
   "    digest = f\"openssl dgst -sha384 -binary {path}\".split()\n",
   "    p1 = Popen(digest, stdout=PIPE)\n",
   "    b64 = \"openssl base64 -A\".split()\n",
   "    p2 = Popen(b64, stdin=p1.stdout, stdout=PIPE)\n",
   "    out, _ = p2.communicate()\n",
   "    return out.decode(\"utf-8\").strip()\n"
  ]
 },
 "58": {
  "name": "base_url",
  "type": "str",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/resources.py",
  "lineno": "650",
  "column": "4",
  "context": "\"\"\n    _legacy = \".legacy\" if legacy else \"\"\n\n    base_url = _cdn_base_url()\n    dev_container = \"bokeh/dev\"\n    rel_container ",
  "context_lines": "            version = __version__.split(\"-\")[0]\n\n    # check if we want minified js and css\n    _minified = \".min\" if minified else \"\"\n    _legacy = \".legacy\" if legacy else \"\"\n\n    base_url = _cdn_base_url()\n    dev_container = \"bokeh/dev\"\n    rel_container = \"bokeh/release\"\n\n    # check the 'dev' fingerprint\n    container = dev_container if _DEV_PAT.match(version) else rel_container\n\n",
  "slicing": [
   "DEFAULT_SERVER_HOST = \"localhost\"\n",
   "DEFAULT_SERVER_PORT = 5006\n",
   "DEFAULT_SERVER_HTTP_URL = \"http://%s:%d/\" % (DEFAULT_SERVER_HOST, DEFAULT_SERVER_PORT)\n",
   "_SRI_HASHES = None\n",
   "    if not _SRI_HASHES:\n",
   "        with open(join(ROOT_DIR, \"_sri.json\")) as f:\n",
   "            _SRI_HASHES = json.load(f)\n",
   "    return dict(_SRI_HASHES)\n",
   "def get_sri_hashes_for_version(version):\n",
   "    hashes = get_all_sri_hashes()\n",
   "    return hashes[version]\n",
   "    paths = glob(join(bokehjsdir(), \"js/bokeh*.js\"))\n",
   "    hashes = get_sri_hashes_for_version(__version__)\n",
   "    if len(hashes) < len(paths):\n",
   "    if len(hashes) > len(paths):\n",
   "    bad = []\n",
   "    for path in paths:\n",
   "        name, suffix = basename(path).split(\".\", 1)\n",
   "        filename = f\"{name}-{__version__}.{suffix}\"\n",
   "        sri_hash = _compute_single_hash(path)\n",
   "        if hashes[filename] != sri_hash:\n",
   "            bad.append(path)\n",
   "    if bad:\n",
   "        raise RuntimeError(f\"SRI Hash mismatches in the package: {bad!r}\")\n",
   "    _default_root_url = DEFAULT_SERVER_HTTP_URL\n",
   "        if version and not self.mode.startswith(\"cdn\"):\n",
   "        self.version = settings.cdn_version(version)\n",
   "            root_url = root_url + \"/\"\n",
   "        self._root_url = root_url\n",
   "            cdn = self._cdn_urls()\n",
   "            self.messages.extend(cdn[\"messages\"])\n",
   "            server = self._server_urls()\n",
   "            self.messages.extend(server[\"messages\"])\n",
   "        valid_levels = [\"trace\", \"debug\", \"info\", \"warn\", \"error\", \"fatal\"]\n",
   "        if not (level is None or level in valid_levels):\n",
   "            raise ValueError(\"Unknown log level '{}', valid levels are: {}\".format(level, str(valid_levels)))\n",
   "        components = self.js_components if kind == \"js\" else self.css_components\n",
   "            components = [c for c in components if c in self._components]\n",
   "        return components\n",
   "        minified = \".min\" if not self.dev and self.minified else \"\"\n",
   "        files = [\"%s%s.%s\" % (component, minified, kind) for component in self.components(kind)]\n",
   "        paths = [join(self.base_dir, kind, file) for file in files]\n",
   "        return paths\n",
   "        external_resources = []\n",
   "        for _, cls in sorted(Model.model_class_reverse_map.items(), key=lambda arg: arg[0]):\n",
   "            external = getattr(cls, resource_attr, None)\n",
   "            if isinstance(external, str):\n",
   "                if external not in external_resources:\n",
   "                    external_resources.append(external)\n",
   "            elif isinstance(external, list):\n",
   "                for e in external:\n",
   "                    if e not in external_resources:\n",
   "                        external_resources.append(e)\n",
   "        return external_resources\n",
   "        paths = self._file_paths(kind)\n",
   "        files, raw = [], []\n",
   "        hashes = {}\n",
   "            raw = [self._inline(path) for path in paths]\n",
   "            root_dir = self.root_dir or self._default_root_dir\n",
   "            files = [relpath(path, root_dir) for path in paths]\n",
   "            files = list(paths)\n",
   "            cdn = self._cdn_urls()\n",
   "            files = list(cdn[\"urls\"](self.components(kind), kind))\n",
   "            if cdn[\"hashes\"]:\n",
   "                hashes = cdn[\"hashes\"](self.components(kind), kind)\n",
   "            server = self._server_urls()\n",
   "            files = list(server[\"urls\"](self.components(kind), kind))\n",
   "        return (files, raw, hashes)\n",
   "        begin = \"/* BEGIN %s */\" % basename(path)\n",
   "        with open(path, \"rb\") as f:\n",
   "            middle = f.read().decode(\"utf-8\")\n",
   "        end = \"/* END %s */\" % basename(path)\n",
   "        return \"%s\\n%s\\n%s\" % (begin, middle, end)\n",
   "        files, _, __ = self._resolve(\"js\")\n",
   "        external_resources = self._collect_external_resources(\"__javascript__\")\n",
   "        return external_resources + files\n",
   "        _, raw, __ = self._resolve(\"js\")\n",
   "            raw.append('Bokeh.set_log_level(\"%s\");' % self.log_level)\n",
   "            raw.append(\"Bokeh.settings.dev = true\")\n",
   "        return raw\n",
   "        _, __, hashes = self._resolve(\"js\")\n",
   "        return hashes\n",
   "        files, _, __ = self._resolve(\"css\")\n",
   "        external_resources = self._collect_external_resources(\"__css__\")\n",
   "        return external_resources + files\n",
   "        _, raw, __ = self._resolve(\"css\")\n",
   "        return raw\n",
   "        return [json.dumps(css) for css in self.css_raw]\n",
   "        self._url = kwargs.get(\"url\", DEFAULT_SERVER_HTTP_URL)\n",
   "            self._url = DEFAULT_SERVER_HTTP_URL\n",
   "_DEV_PAT = re.compile(r\"^(\\d)+\\.(\\d)+\\.(\\d)+(dev|rc)\")\n",
   "    if version is None:\n",
   "            version = settings.docs_cdn()\n",
   "            version = __version__.split(\"-\")[0]\n",
   "    _minified = \".min\" if minified else \"\"\n",
   "    _legacy = \".legacy\" if legacy else \"\"\n",
   "    base_url = _cdn_base_url()\n",
   "    dev_container = \"bokeh/dev\"\n",
   "    rel_container = \"bokeh/release\"\n",
   "    container = dev_container if _DEV_PAT.match(version) else rel_container\n",
   "    def mk_filename(comp, kind):\n",
   "        return f\"{comp}-{version}{_legacy}{_minified}.{kind}\"\n",
   "    def mk_url(comp, kind):\n",
   "        return f\"{base_url}/{container}/\" + mk_filename(comp, kind)\n",
   "    result = {\n",
   "        \"urls\": lambda components, kind: [mk_url(component, kind) for component in components],\n",
   "        result[\"messages\"].append(\n",
   "                    \"This configuration is unsupported and may not work!\" % (version, __version__)\n",
   "    if is_full_release(version):\n",
   "        sri_hashes = get_sri_hashes_for_version(version)\n",
   "        result['hashes'] = lambda components, kind: {mk_url(component, kind): sri_hashes[mk_filename(component, kind)] for component in components}\n",
   "    return result\n",
   "    _minified = \".min\" if minified else \"\"\n",
   "    _legacy = \".legacy\" if legacy else \"\"\n",
   "    def mk_url(comp, kind):\n",
   "        path = f\"{kind}/{comp}{_legacy}{_minified}.{kind}\"\n",
   "            path = path_versioner(path)\n",
   "        return f\"{root_url}static/{path}\"\n",
   "    return {\"urls\": lambda components, kind: [mk_url(component, kind) for component in components], \"messages\": []}\n",
   "    assert path.endswith(\".js\")\n",
   "    digest = f\"openssl dgst -sha384 -binary {path}\".split()\n",
   "    p1 = Popen(digest, stdout=PIPE)\n",
   "    b64 = \"openssl base64 -A\".split()\n",
   "    p2 = Popen(b64, stdin=p1.stdout, stdout=PIPE)\n",
   "    out, _ = p2.communicate()\n",
   "    return out.decode(\"utf-8\").strip()\n"
  ]
 },
 "59": {
  "name": "dev_container",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/resources.py",
  "lineno": "651",
  "column": "4",
  "context": "egacy else \"\"\n\n    base_url = _cdn_base_url()\n    dev_container = \"bokeh/dev\"\n    rel_container = \"bokeh/release\"\n\n    # check t",
  "context_lines": "    # check if we want minified js and css\n    _minified = \".min\" if minified else \"\"\n    _legacy = \".legacy\" if legacy else \"\"\n\n    base_url = _cdn_base_url()\n    dev_container = \"bokeh/dev\"\n    rel_container = \"bokeh/release\"\n\n    # check the 'dev' fingerprint\n    container = dev_container if _DEV_PAT.match(version) else rel_container\n\n    def mk_filename(comp, kind):\n",
  "slicing": [
   "DEFAULT_SERVER_HOST = \"localhost\"\n",
   "DEFAULT_SERVER_PORT = 5006\n",
   "DEFAULT_SERVER_HTTP_URL = \"http://%s:%d/\" % (DEFAULT_SERVER_HOST, DEFAULT_SERVER_PORT)\n",
   "_SRI_HASHES = None\n",
   "    if not _SRI_HASHES:\n",
   "        with open(join(ROOT_DIR, \"_sri.json\")) as f:\n",
   "            _SRI_HASHES = json.load(f)\n",
   "    return dict(_SRI_HASHES)\n",
   "def get_sri_hashes_for_version(version):\n",
   "    hashes = get_all_sri_hashes()\n",
   "    return hashes[version]\n",
   "    paths = glob(join(bokehjsdir(), \"js/bokeh*.js\"))\n",
   "    hashes = get_sri_hashes_for_version(__version__)\n",
   "    if len(hashes) < len(paths):\n",
   "    if len(hashes) > len(paths):\n",
   "    bad = []\n",
   "    for path in paths:\n",
   "        name, suffix = basename(path).split(\".\", 1)\n",
   "        filename = f\"{name}-{__version__}.{suffix}\"\n",
   "        sri_hash = _compute_single_hash(path)\n",
   "        if hashes[filename] != sri_hash:\n",
   "            bad.append(path)\n",
   "    if bad:\n",
   "        raise RuntimeError(f\"SRI Hash mismatches in the package: {bad!r}\")\n",
   "    _default_root_url = DEFAULT_SERVER_HTTP_URL\n",
   "        if version and not self.mode.startswith(\"cdn\"):\n",
   "        self.version = settings.cdn_version(version)\n",
   "            root_url = root_url + \"/\"\n",
   "        self._root_url = root_url\n",
   "            cdn = self._cdn_urls()\n",
   "            self.messages.extend(cdn[\"messages\"])\n",
   "            server = self._server_urls()\n",
   "            self.messages.extend(server[\"messages\"])\n",
   "        valid_levels = [\"trace\", \"debug\", \"info\", \"warn\", \"error\", \"fatal\"]\n",
   "        if not (level is None or level in valid_levels):\n",
   "            raise ValueError(\"Unknown log level '{}', valid levels are: {}\".format(level, str(valid_levels)))\n",
   "        components = self.js_components if kind == \"js\" else self.css_components\n",
   "            components = [c for c in components if c in self._components]\n",
   "        return components\n",
   "        minified = \".min\" if not self.dev and self.minified else \"\"\n",
   "        files = [\"%s%s.%s\" % (component, minified, kind) for component in self.components(kind)]\n",
   "        paths = [join(self.base_dir, kind, file) for file in files]\n",
   "        return paths\n",
   "        external_resources = []\n",
   "        for _, cls in sorted(Model.model_class_reverse_map.items(), key=lambda arg: arg[0]):\n",
   "            external = getattr(cls, resource_attr, None)\n",
   "            if isinstance(external, str):\n",
   "                if external not in external_resources:\n",
   "                    external_resources.append(external)\n",
   "            elif isinstance(external, list):\n",
   "                for e in external:\n",
   "                    if e not in external_resources:\n",
   "                        external_resources.append(e)\n",
   "        return external_resources\n",
   "        paths = self._file_paths(kind)\n",
   "        files, raw = [], []\n",
   "        hashes = {}\n",
   "            raw = [self._inline(path) for path in paths]\n",
   "            root_dir = self.root_dir or self._default_root_dir\n",
   "            files = [relpath(path, root_dir) for path in paths]\n",
   "            files = list(paths)\n",
   "            cdn = self._cdn_urls()\n",
   "            files = list(cdn[\"urls\"](self.components(kind), kind))\n",
   "            if cdn[\"hashes\"]:\n",
   "                hashes = cdn[\"hashes\"](self.components(kind), kind)\n",
   "            server = self._server_urls()\n",
   "            files = list(server[\"urls\"](self.components(kind), kind))\n",
   "        return (files, raw, hashes)\n",
   "        begin = \"/* BEGIN %s */\" % basename(path)\n",
   "        with open(path, \"rb\") as f:\n",
   "            middle = f.read().decode(\"utf-8\")\n",
   "        end = \"/* END %s */\" % basename(path)\n",
   "        return \"%s\\n%s\\n%s\" % (begin, middle, end)\n",
   "        files, _, __ = self._resolve(\"js\")\n",
   "        external_resources = self._collect_external_resources(\"__javascript__\")\n",
   "        return external_resources + files\n",
   "        _, raw, __ = self._resolve(\"js\")\n",
   "            raw.append('Bokeh.set_log_level(\"%s\");' % self.log_level)\n",
   "            raw.append(\"Bokeh.settings.dev = true\")\n",
   "        return raw\n",
   "        _, __, hashes = self._resolve(\"js\")\n",
   "        return hashes\n",
   "        files, _, __ = self._resolve(\"css\")\n",
   "        external_resources = self._collect_external_resources(\"__css__\")\n",
   "        return external_resources + files\n",
   "        _, raw, __ = self._resolve(\"css\")\n",
   "        return raw\n",
   "        return [json.dumps(css) for css in self.css_raw]\n",
   "        self._url = kwargs.get(\"url\", DEFAULT_SERVER_HTTP_URL)\n",
   "            self._url = DEFAULT_SERVER_HTTP_URL\n",
   "_DEV_PAT = re.compile(r\"^(\\d)+\\.(\\d)+\\.(\\d)+(dev|rc)\")\n",
   "    if version is None:\n",
   "            version = settings.docs_cdn()\n",
   "            version = __version__.split(\"-\")[0]\n",
   "    _minified = \".min\" if minified else \"\"\n",
   "    _legacy = \".legacy\" if legacy else \"\"\n",
   "    base_url = _cdn_base_url()\n",
   "    dev_container = \"bokeh/dev\"\n",
   "    rel_container = \"bokeh/release\"\n",
   "    container = dev_container if _DEV_PAT.match(version) else rel_container\n",
   "    def mk_filename(comp, kind):\n",
   "        return f\"{comp}-{version}{_legacy}{_minified}.{kind}\"\n",
   "    def mk_url(comp, kind):\n",
   "        return f\"{base_url}/{container}/\" + mk_filename(comp, kind)\n",
   "    result = {\n",
   "        \"urls\": lambda components, kind: [mk_url(component, kind) for component in components],\n",
   "        result[\"messages\"].append(\n",
   "                    \"This configuration is unsupported and may not work!\" % (version, __version__)\n",
   "    if is_full_release(version):\n",
   "        sri_hashes = get_sri_hashes_for_version(version)\n",
   "        result['hashes'] = lambda components, kind: {mk_url(component, kind): sri_hashes[mk_filename(component, kind)] for component in components}\n",
   "    return result\n",
   "    _minified = \".min\" if minified else \"\"\n",
   "    _legacy = \".legacy\" if legacy else \"\"\n",
   "    def mk_url(comp, kind):\n",
   "        path = f\"{kind}/{comp}{_legacy}{_minified}.{kind}\"\n",
   "            path = path_versioner(path)\n",
   "        return f\"{root_url}static/{path}\"\n",
   "    return {\"urls\": lambda components, kind: [mk_url(component, kind) for component in components], \"messages\": []}\n",
   "    assert path.endswith(\".js\")\n",
   "    digest = f\"openssl dgst -sha384 -binary {path}\".split()\n",
   "    p1 = Popen(digest, stdout=PIPE)\n",
   "    b64 = \"openssl base64 -A\".split()\n",
   "    p2 = Popen(b64, stdin=p1.stdout, stdout=PIPE)\n",
   "    out, _ = p2.communicate()\n",
   "    return out.decode(\"utf-8\").strip()\n"
  ]
 },
 "60": {
  "name": "rel_container",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/resources.py",
  "lineno": "652",
  "column": "4",
  "context": "dn_base_url()\n    dev_container = \"bokeh/dev\"\n    rel_container = \"bokeh/release\"\n\n    # check the 'dev' fingerprint\n    container =",
  "context_lines": "    _minified = \".min\" if minified else \"\"\n    _legacy = \".legacy\" if legacy else \"\"\n\n    base_url = _cdn_base_url()\n    dev_container = \"bokeh/dev\"\n    rel_container = \"bokeh/release\"\n\n    # check the 'dev' fingerprint\n    container = dev_container if _DEV_PAT.match(version) else rel_container\n\n    def mk_filename(comp, kind):\n",
  "slicing": [
   "DEFAULT_SERVER_HOST = \"localhost\"\n",
   "DEFAULT_SERVER_PORT = 5006\n",
   "DEFAULT_SERVER_HTTP_URL = \"http://%s:%d/\" % (DEFAULT_SERVER_HOST, DEFAULT_SERVER_PORT)\n",
   "_SRI_HASHES = None\n",
   "    if not _SRI_HASHES:\n",
   "        with open(join(ROOT_DIR, \"_sri.json\")) as f:\n",
   "            _SRI_HASHES = json.load(f)\n",
   "    return dict(_SRI_HASHES)\n",
   "def get_sri_hashes_for_version(version):\n",
   "    hashes = get_all_sri_hashes()\n",
   "    return hashes[version]\n",
   "    paths = glob(join(bokehjsdir(), \"js/bokeh*.js\"))\n",
   "    hashes = get_sri_hashes_for_version(__version__)\n",
   "    if len(hashes) < len(paths):\n",
   "    if len(hashes) > len(paths):\n",
   "    bad = []\n",
   "    for path in paths:\n",
   "        name, suffix = basename(path).split(\".\", 1)\n",
   "        filename = f\"{name}-{__version__}.{suffix}\"\n",
   "        sri_hash = _compute_single_hash(path)\n",
   "        if hashes[filename] != sri_hash:\n",
   "            bad.append(path)\n",
   "    if bad:\n",
   "        raise RuntimeError(f\"SRI Hash mismatches in the package: {bad!r}\")\n",
   "    _default_root_url = DEFAULT_SERVER_HTTP_URL\n",
   "        if version and not self.mode.startswith(\"cdn\"):\n",
   "        self.version = settings.cdn_version(version)\n",
   "            root_url = root_url + \"/\"\n",
   "        self._root_url = root_url\n",
   "            cdn = self._cdn_urls()\n",
   "            self.messages.extend(cdn[\"messages\"])\n",
   "            server = self._server_urls()\n",
   "            self.messages.extend(server[\"messages\"])\n",
   "        valid_levels = [\"trace\", \"debug\", \"info\", \"warn\", \"error\", \"fatal\"]\n",
   "        if not (level is None or level in valid_levels):\n",
   "            raise ValueError(\"Unknown log level '{}', valid levels are: {}\".format(level, str(valid_levels)))\n",
   "        components = self.js_components if kind == \"js\" else self.css_components\n",
   "            components = [c for c in components if c in self._components]\n",
   "        return components\n",
   "        minified = \".min\" if not self.dev and self.minified else \"\"\n",
   "        files = [\"%s%s.%s\" % (component, minified, kind) for component in self.components(kind)]\n",
   "        paths = [join(self.base_dir, kind, file) for file in files]\n",
   "        return paths\n",
   "        external_resources = []\n",
   "        for _, cls in sorted(Model.model_class_reverse_map.items(), key=lambda arg: arg[0]):\n",
   "            external = getattr(cls, resource_attr, None)\n",
   "            if isinstance(external, str):\n",
   "                if external not in external_resources:\n",
   "                    external_resources.append(external)\n",
   "            elif isinstance(external, list):\n",
   "                for e in external:\n",
   "                    if e not in external_resources:\n",
   "                        external_resources.append(e)\n",
   "        return external_resources\n",
   "        paths = self._file_paths(kind)\n",
   "        files, raw = [], []\n",
   "        hashes = {}\n",
   "            raw = [self._inline(path) for path in paths]\n",
   "            root_dir = self.root_dir or self._default_root_dir\n",
   "            files = [relpath(path, root_dir) for path in paths]\n",
   "            files = list(paths)\n",
   "            cdn = self._cdn_urls()\n",
   "            files = list(cdn[\"urls\"](self.components(kind), kind))\n",
   "            if cdn[\"hashes\"]:\n",
   "                hashes = cdn[\"hashes\"](self.components(kind), kind)\n",
   "            server = self._server_urls()\n",
   "            files = list(server[\"urls\"](self.components(kind), kind))\n",
   "        return (files, raw, hashes)\n",
   "        begin = \"/* BEGIN %s */\" % basename(path)\n",
   "        with open(path, \"rb\") as f:\n",
   "            middle = f.read().decode(\"utf-8\")\n",
   "        end = \"/* END %s */\" % basename(path)\n",
   "        return \"%s\\n%s\\n%s\" % (begin, middle, end)\n",
   "        files, _, __ = self._resolve(\"js\")\n",
   "        external_resources = self._collect_external_resources(\"__javascript__\")\n",
   "        return external_resources + files\n",
   "        _, raw, __ = self._resolve(\"js\")\n",
   "            raw.append('Bokeh.set_log_level(\"%s\");' % self.log_level)\n",
   "            raw.append(\"Bokeh.settings.dev = true\")\n",
   "        return raw\n",
   "        _, __, hashes = self._resolve(\"js\")\n",
   "        return hashes\n",
   "        files, _, __ = self._resolve(\"css\")\n",
   "        external_resources = self._collect_external_resources(\"__css__\")\n",
   "        return external_resources + files\n",
   "        _, raw, __ = self._resolve(\"css\")\n",
   "        return raw\n",
   "        return [json.dumps(css) for css in self.css_raw]\n",
   "        self._url = kwargs.get(\"url\", DEFAULT_SERVER_HTTP_URL)\n",
   "            self._url = DEFAULT_SERVER_HTTP_URL\n",
   "_DEV_PAT = re.compile(r\"^(\\d)+\\.(\\d)+\\.(\\d)+(dev|rc)\")\n",
   "    if version is None:\n",
   "            version = settings.docs_cdn()\n",
   "            version = __version__.split(\"-\")[0]\n",
   "    _minified = \".min\" if minified else \"\"\n",
   "    _legacy = \".legacy\" if legacy else \"\"\n",
   "    base_url = _cdn_base_url()\n",
   "    dev_container = \"bokeh/dev\"\n",
   "    rel_container = \"bokeh/release\"\n",
   "    container = dev_container if _DEV_PAT.match(version) else rel_container\n",
   "    def mk_filename(comp, kind):\n",
   "        return f\"{comp}-{version}{_legacy}{_minified}.{kind}\"\n",
   "    def mk_url(comp, kind):\n",
   "        return f\"{base_url}/{container}/\" + mk_filename(comp, kind)\n",
   "    result = {\n",
   "        \"urls\": lambda components, kind: [mk_url(component, kind) for component in components],\n",
   "        result[\"messages\"].append(\n",
   "                    \"This configuration is unsupported and may not work!\" % (version, __version__)\n",
   "    if is_full_release(version):\n",
   "        sri_hashes = get_sri_hashes_for_version(version)\n",
   "        result['hashes'] = lambda components, kind: {mk_url(component, kind): sri_hashes[mk_filename(component, kind)] for component in components}\n",
   "    return result\n",
   "    _minified = \".min\" if minified else \"\"\n",
   "    _legacy = \".legacy\" if legacy else \"\"\n",
   "    def mk_url(comp, kind):\n",
   "        path = f\"{kind}/{comp}{_legacy}{_minified}.{kind}\"\n",
   "            path = path_versioner(path)\n",
   "        return f\"{root_url}static/{path}\"\n",
   "    return {\"urls\": lambda components, kind: [mk_url(component, kind) for component in components], \"messages\": []}\n",
   "    assert path.endswith(\".js\")\n",
   "    digest = f\"openssl dgst -sha384 -binary {path}\".split()\n",
   "    p1 = Popen(digest, stdout=PIPE)\n",
   "    b64 = \"openssl base64 -A\".split()\n",
   "    p2 = Popen(b64, stdin=p1.stdout, stdout=PIPE)\n",
   "    out, _ = p2.communicate()\n",
   "    return out.decode(\"utf-8\").strip()\n"
  ]
 },
 "61": {
  "name": "container",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/resources.py",
  "lineno": "655",
  "column": "4",
  "context": "h/release\"\n\n    # check the 'dev' fingerprint\n    container = dev_container if _DEV_PAT.match(version) else rel_container\n\n    def mk_filename(comp, kind):\n        return f",
  "context_lines": "    base_url = _cdn_base_url()\n    dev_container = \"bokeh/dev\"\n    rel_container = \"bokeh/release\"\n\n    # check the 'dev' fingerprint\n    container = dev_container if _DEV_PAT.match(version) else rel_container\n\n    def mk_filename(comp, kind):\n        return f\"{comp}-{version}{_legacy}{_minified}.{kind}\"\n\n    def mk_url(comp, kind):\n",
  "slicing": [
   "DEFAULT_SERVER_HOST = \"localhost\"\n",
   "DEFAULT_SERVER_PORT = 5006\n",
   "DEFAULT_SERVER_HTTP_URL = \"http://%s:%d/\" % (DEFAULT_SERVER_HOST, DEFAULT_SERVER_PORT)\n",
   "_SRI_HASHES = None\n",
   "    if not _SRI_HASHES:\n",
   "        with open(join(ROOT_DIR, \"_sri.json\")) as f:\n",
   "            _SRI_HASHES = json.load(f)\n",
   "    return dict(_SRI_HASHES)\n",
   "def get_sri_hashes_for_version(version):\n",
   "    hashes = get_all_sri_hashes()\n",
   "    return hashes[version]\n",
   "    paths = glob(join(bokehjsdir(), \"js/bokeh*.js\"))\n",
   "    hashes = get_sri_hashes_for_version(__version__)\n",
   "    if len(hashes) < len(paths):\n",
   "    if len(hashes) > len(paths):\n",
   "    bad = []\n",
   "    for path in paths:\n",
   "        name, suffix = basename(path).split(\".\", 1)\n",
   "        filename = f\"{name}-{__version__}.{suffix}\"\n",
   "        sri_hash = _compute_single_hash(path)\n",
   "        if hashes[filename] != sri_hash:\n",
   "            bad.append(path)\n",
   "    if bad:\n",
   "        raise RuntimeError(f\"SRI Hash mismatches in the package: {bad!r}\")\n",
   "    _default_root_url = DEFAULT_SERVER_HTTP_URL\n",
   "        if version and not self.mode.startswith(\"cdn\"):\n",
   "        self.version = settings.cdn_version(version)\n",
   "            root_url = root_url + \"/\"\n",
   "        self._root_url = root_url\n",
   "            cdn = self._cdn_urls()\n",
   "            self.messages.extend(cdn[\"messages\"])\n",
   "            server = self._server_urls()\n",
   "            self.messages.extend(server[\"messages\"])\n",
   "        valid_levels = [\"trace\", \"debug\", \"info\", \"warn\", \"error\", \"fatal\"]\n",
   "        if not (level is None or level in valid_levels):\n",
   "            raise ValueError(\"Unknown log level '{}', valid levels are: {}\".format(level, str(valid_levels)))\n",
   "        components = self.js_components if kind == \"js\" else self.css_components\n",
   "            components = [c for c in components if c in self._components]\n",
   "        return components\n",
   "        minified = \".min\" if not self.dev and self.minified else \"\"\n",
   "        files = [\"%s%s.%s\" % (component, minified, kind) for component in self.components(kind)]\n",
   "        paths = [join(self.base_dir, kind, file) for file in files]\n",
   "        return paths\n",
   "        external_resources = []\n",
   "        for _, cls in sorted(Model.model_class_reverse_map.items(), key=lambda arg: arg[0]):\n",
   "            external = getattr(cls, resource_attr, None)\n",
   "            if isinstance(external, str):\n",
   "                if external not in external_resources:\n",
   "                    external_resources.append(external)\n",
   "            elif isinstance(external, list):\n",
   "                for e in external:\n",
   "                    if e not in external_resources:\n",
   "                        external_resources.append(e)\n",
   "        return external_resources\n",
   "        paths = self._file_paths(kind)\n",
   "        files, raw = [], []\n",
   "        hashes = {}\n",
   "            raw = [self._inline(path) for path in paths]\n",
   "            root_dir = self.root_dir or self._default_root_dir\n",
   "            files = [relpath(path, root_dir) for path in paths]\n",
   "            files = list(paths)\n",
   "            cdn = self._cdn_urls()\n",
   "            files = list(cdn[\"urls\"](self.components(kind), kind))\n",
   "            if cdn[\"hashes\"]:\n",
   "                hashes = cdn[\"hashes\"](self.components(kind), kind)\n",
   "            server = self._server_urls()\n",
   "            files = list(server[\"urls\"](self.components(kind), kind))\n",
   "        return (files, raw, hashes)\n",
   "        begin = \"/* BEGIN %s */\" % basename(path)\n",
   "        with open(path, \"rb\") as f:\n",
   "            middle = f.read().decode(\"utf-8\")\n",
   "        end = \"/* END %s */\" % basename(path)\n",
   "        return \"%s\\n%s\\n%s\" % (begin, middle, end)\n",
   "        files, _, __ = self._resolve(\"js\")\n",
   "        external_resources = self._collect_external_resources(\"__javascript__\")\n",
   "        return external_resources + files\n",
   "        _, raw, __ = self._resolve(\"js\")\n",
   "            raw.append('Bokeh.set_log_level(\"%s\");' % self.log_level)\n",
   "            raw.append(\"Bokeh.settings.dev = true\")\n",
   "        return raw\n",
   "        _, __, hashes = self._resolve(\"js\")\n",
   "        return hashes\n",
   "        files, _, __ = self._resolve(\"css\")\n",
   "        external_resources = self._collect_external_resources(\"__css__\")\n",
   "        return external_resources + files\n",
   "        _, raw, __ = self._resolve(\"css\")\n",
   "        return raw\n",
   "        return [json.dumps(css) for css in self.css_raw]\n",
   "        self._url = kwargs.get(\"url\", DEFAULT_SERVER_HTTP_URL)\n",
   "            self._url = DEFAULT_SERVER_HTTP_URL\n",
   "_DEV_PAT = re.compile(r\"^(\\d)+\\.(\\d)+\\.(\\d)+(dev|rc)\")\n",
   "    if version is None:\n",
   "            version = settings.docs_cdn()\n",
   "            version = __version__.split(\"-\")[0]\n",
   "    _minified = \".min\" if minified else \"\"\n",
   "    _legacy = \".legacy\" if legacy else \"\"\n",
   "    base_url = _cdn_base_url()\n",
   "    dev_container = \"bokeh/dev\"\n",
   "    rel_container = \"bokeh/release\"\n",
   "    container = dev_container if _DEV_PAT.match(version) else rel_container\n",
   "    def mk_filename(comp, kind):\n",
   "        return f\"{comp}-{version}{_legacy}{_minified}.{kind}\"\n",
   "    def mk_url(comp, kind):\n",
   "        return f\"{base_url}/{container}/\" + mk_filename(comp, kind)\n",
   "    result = {\n",
   "        \"urls\": lambda components, kind: [mk_url(component, kind) for component in components],\n",
   "        result[\"messages\"].append(\n",
   "                    \"This configuration is unsupported and may not work!\" % (version, __version__)\n",
   "    if is_full_release(version):\n",
   "        sri_hashes = get_sri_hashes_for_version(version)\n",
   "        result['hashes'] = lambda components, kind: {mk_url(component, kind): sri_hashes[mk_filename(component, kind)] for component in components}\n",
   "    return result\n",
   "    _minified = \".min\" if minified else \"\"\n",
   "    _legacy = \".legacy\" if legacy else \"\"\n",
   "    def mk_url(comp, kind):\n",
   "        path = f\"{kind}/{comp}{_legacy}{_minified}.{kind}\"\n",
   "            path = path_versioner(path)\n",
   "        return f\"{root_url}static/{path}\"\n",
   "    return {\"urls\": lambda components, kind: [mk_url(component, kind) for component in components], \"messages\": []}\n",
   "    assert path.endswith(\".js\")\n",
   "    digest = f\"openssl dgst -sha384 -binary {path}\".split()\n",
   "    p1 = Popen(digest, stdout=PIPE)\n",
   "    b64 = \"openssl base64 -A\".split()\n",
   "    p2 = Popen(b64, stdin=p1.stdout, stdout=PIPE)\n",
   "    out, _ = p2.communicate()\n",
   "    return out.decode(\"utf-8\").strip()\n"
  ]
 },
 "62": {
  "name": "git_refnames",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/_version.py",
  "lineno": "26",
  "column": "4",
  "context": "rsion.py will just call\n    # get_keywords().\n    git_refnames = \" (HEAD -> branch-2.2)\"\n    git_full = \"fc5e37c2f7a0ca002e3ec4df7bdd65be0a",
  "context_lines": "    # these strings will be replaced by git during git-archive.\n    # setup.py/versioneer.py will grep for the variable names, so they must\n    # each be defined on a line of their own. _version.py will just call\n    # get_keywords().\n    git_refnames = \" (HEAD -> branch-2.2)\"\n    git_full = \"fc5e37c2f7a0ca002e3ec4df7bdd65be0adfcac1\"\n    git_date = \"2020-08-13 16:24:36 -0700\"\n    keywords = {\"refnames\": git_refnames, \"full\": git_full, \"date\": git_date}\n    return keywords\n\n\n",
  "slicing": [
   "    git_refnames = \" (HEAD -> branch-2.2)\"\n",
   "    git_full = \"fc5e37c2f7a0ca002e3ec4df7bdd65be0adfcac1\"\n",
   "    git_date = \"2020-08-13 16:24:36 -0700\"\n",
   "    keywords = {\"refnames\": git_refnames, \"full\": git_full, \"date\": git_date}\n",
   "    return keywords\n",
   "    cfg = VersioneerConfig()\n",
   "    cfg.VCS = \"git\"\n",
   "    cfg.style = \"git-describe\"\n",
   "    cfg.tag_prefix = \"\"\n",
   "    cfg.parentdir_prefix = \"Bokeh-\"\n",
   "    cfg.versionfile_source = \"bokeh/_version.py\"\n",
   "    cfg.verbose = False\n",
   "    return cfg\n",
   "HANDLERS = {}\n",
   "def register_vcs_handler(vcs, method):  # decorator\n",
   "        if vcs not in HANDLERS:\n",
   "            HANDLERS[vcs] = {}\n",
   "        HANDLERS[vcs][method] = f\n",
   "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False,\n",
   "    p = None\n",
   "    for c in commands:\n",
   "            dispcmd = str([c] + args)\n",
   "            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n",
   "            e = sys.exc_info()[1]\n",
   "            if e.errno == errno.ENOENT:\n",
   "                print(\"unable to run %s\" % dispcmd)\n",
   "                print(e)\n",
   "            print(\"unable to find command, tried %s\" % (commands,))\n",
   "    stdout = p.communicate()[0].strip()\n",
   "        stdout = stdout.decode()\n",
   "    if p.returncode != 0:\n",
   "            print(\"unable to run %s (error)\" % dispcmd)\n",
   "            print(\"stdout was %s\" % stdout)\n",
   "        return None, p.returncode\n",
   "    return stdout, p.returncode\n",
   "    rootdirs = []\n",
   "        dirname = os.path.basename(root)\n",
   "        if dirname.startswith(parentdir_prefix):\n",
   "            return {\"version\": dirname[len(parentdir_prefix):],\n",
   "            rootdirs.append(root)\n",
   "            root = os.path.dirname(root)  # up a level\n",
   "              (str(rootdirs), parentdir_prefix))\n",
   "    keywords = {}\n",
   "        with open(versionfile_abs) as f:\n",
   "            for line in f.readlines():\n",
   "                if line.strip().startswith(\"git_refnames =\"):\n",
   "                    mo = re.search(r'=\\s*\"(.*)\"', line)\n",
   "                    if mo:\n",
   "                        keywords[\"refnames\"] = mo.group(1)\n",
   "                if line.strip().startswith(\"git_full =\"):\n",
   "                    mo = re.search(r'=\\s*\"(.*)\"', line)\n",
   "                    if mo:\n",
   "                        keywords[\"full\"] = mo.group(1)\n",
   "                if line.strip().startswith(\"git_date =\"):\n",
   "                    mo = re.search(r'=\\s*\"(.*)\"', line)\n",
   "                    if mo:\n",
   "                        keywords[\"date\"] = mo.group(1)\n",
   "    return keywords\n",
   "def git_versions_from_keywords(keywords, tag_prefix, verbose):\n",
   "    if not keywords:\n",
   "    date = keywords.get(\"date\")\n",
   "    if date is not None:\n",
   "        date = date.strip().replace(\" \", \"T\", 1).replace(\" \", \"\", 1)\n",
   "    refnames = keywords[\"refnames\"].strip()\n",
   "    if refnames.startswith(\"$Format\"):\n",
   "    refs = {r.strip() for r in refnames.strip(\"()\").split(\",\")}\n",
   "    TAG = \"tag: \"\n",
   "    tags = {r[len(TAG):] for r in refs if r.startswith(TAG)}\n",
   "    if not tags:\n",
   "        tags = {r for r in refs if re.search(r\"\\d\", r)}\n",
   "            print(\"discarding '%s', no digits\" % \",\".join(refs - tags))\n",
   "        print(\"likely tags: %s\" % \",\".join(sorted(tags)))\n",
   "    for ref in sorted(tags):\n",
   "        if ref.startswith(tag_prefix):\n",
   "            r = ref[len(tag_prefix):]\n",
   "                print(\"picking %s\" % r)\n",
   "            return {\"version\": r,\n",
   "                    \"full-revisionid\": keywords[\"full\"].strip(),\n",
   "                    \"date\": date}\n",
   "            \"full-revisionid\": keywords[\"full\"].strip(),\n",
   "def git_pieces_from_vcs(tag_prefix, root, verbose, run_command=run_command):\n",
   "    GITS = [\"git\"]\n",
   "        GITS = [\"git.cmd\", \"git.exe\"]\n",
   "    out, rc = run_command(GITS, [\"rev-parse\", \"--git-dir\"], cwd=root,\n",
   "    if rc != 0:\n",
   "            print(\"Directory %s not under git control\" % root)\n",
   "    describe_out, rc = run_command(GITS, [\"describe\", \"--tags\", \"--dirty\",\n",
   "                                   cwd=root)\n",
   "    if describe_out is None:\n",
   "    describe_out = describe_out.strip()\n",
   "    full_out, rc = run_command(GITS, [\"rev-parse\", \"HEAD\"], cwd=root)\n",
   "    if full_out is None:\n",
   "    full_out = full_out.strip()\n",
   "    pieces = {}\n",
   "    pieces[\"long\"] = full_out\n",
   "    pieces[\"short\"] = full_out[:7]  # maybe improved later\n",
   "    pieces[\"error\"] = None\n",
   "    git_describe = describe_out\n",
   "    dirty = git_describe.endswith(\"-dirty\")\n",
   "    pieces[\"dirty\"] = dirty\n",
   "    if dirty:\n",
   "        git_describe = git_describe[:git_describe.rindex(\"-dirty\")]\n",
   "    if \"-\" in git_describe:\n",
   "        mo = re.search(r'^(.+)-(\\d+)-g([0-9a-f]+)$', git_describe)\n",
   "        if not mo:\n",
   "            pieces[\"error\"] = (\"unable to parse git-describe output: '%s'\"\n",
   "                               % describe_out)\n",
   "            return pieces\n",
   "        full_tag = mo.group(1)\n",
   "        if not full_tag.startswith(tag_prefix):\n",
   "                fmt = \"tag '%s' doesn't start with prefix '%s'\"\n",
   "                print(fmt % (full_tag, tag_prefix))\n",
   "            pieces[\"error\"] = (\"tag '%s' doesn't start with prefix '%s'\"\n",
   "                               % (full_tag, tag_prefix))\n",
   "            return pieces\n",
   "        pieces[\"closest-tag\"] = full_tag[len(tag_prefix):]\n",
   "        pieces[\"distance\"] = int(mo.group(2))\n",
   "        pieces[\"short\"] = mo.group(3)\n",
   "        pieces[\"closest-tag\"] = None\n",
   "        count_out, rc = run_command(GITS, [\"rev-list\", \"HEAD\", \"--count\"],\n",
   "                                    cwd=root)\n",
   "        pieces[\"distance\"] = int(count_out)  # total number of commits\n",
   "    date = run_command(GITS, [\"show\", \"-s\", \"--format=%ci\", \"HEAD\"],\n",
   "                       cwd=root)[0].strip()\n",
   "    pieces[\"date\"] = date.strip().replace(\" \", \"T\", 1).replace(\" \", \"\", 1)\n",
   "    return pieces\n",
   "def plus_or_dot(pieces):\n",
   "    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n",
   "def render_pep440(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"] or pieces[\"dirty\"]:\n",
   "            rendered += plus_or_dot(pieces)\n",
   "            rendered += \"%d.g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n",
   "            if pieces[\"dirty\"]:\n",
   "                rendered += \".dirty\"\n",
   "        rendered = \"0+untagged.%d.g%s\" % (pieces[\"distance\"],\n",
   "                                          pieces[\"short\"])\n",
   "        if pieces[\"dirty\"]:\n",
   "            rendered += \".dirty\"\n",
   "    return rendered\n",
   "def render_pep440_pre(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"]:\n",
   "            rendered += \".post.dev%d\" % pieces[\"distance\"]\n",
   "        rendered = \"0.post.dev%d\" % pieces[\"distance\"]\n",
   "    return rendered\n",
   "def render_pep440_post(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"] or pieces[\"dirty\"]:\n",
   "            rendered += \".post%d\" % pieces[\"distance\"]\n",
   "            if pieces[\"dirty\"]:\n",
   "                rendered += \".dev0\"\n",
   "            rendered += plus_or_dot(pieces)\n",
   "            rendered += \"g%s\" % pieces[\"short\"]\n",
   "        rendered = \"0.post%d\" % pieces[\"distance\"]\n",
   "        if pieces[\"dirty\"]:\n",
   "            rendered += \".dev0\"\n",
   "        rendered += \"+g%s\" % pieces[\"short\"]\n",
   "    return rendered\n",
   "def render_pep440_old(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"] or pieces[\"dirty\"]:\n",
   "            rendered += \".post%d\" % pieces[\"distance\"]\n",
   "            if pieces[\"dirty\"]:\n",
   "                rendered += \".dev0\"\n",
   "        rendered = \"0.post%d\" % pieces[\"distance\"]\n",
   "        if pieces[\"dirty\"]:\n",
   "            rendered += \".dev0\"\n",
   "    return rendered\n",
   "def render_git_describe(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"]:\n",
   "            rendered += \"-%d-g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n",
   "        rendered = pieces[\"short\"]\n",
   "    if pieces[\"dirty\"]:\n",
   "        rendered += \"-dirty\"\n",
   "    return rendered\n",
   "def render_git_describe_long(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        rendered += \"-%d-g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n",
   "        rendered = pieces[\"short\"]\n",
   "    if pieces[\"dirty\"]:\n",
   "        rendered += \"-dirty\"\n",
   "    return rendered\n",
   "    if pieces[\"error\"]:\n",
   "                \"full-revisionid\": pieces.get(\"long\"),\n",
   "                \"error\": pieces[\"error\"],\n",
   "        style = \"pep440\"  # the default\n",
   "    if style == \"pep440\":\n",
   "        rendered = render_pep440(pieces)\n",
   "    elif style == \"pep440-pre\":\n",
   "        rendered = render_pep440_pre(pieces)\n",
   "    elif style == \"pep440-post\":\n",
   "        rendered = render_pep440_post(pieces)\n",
   "    elif style == \"pep440-old\":\n",
   "        rendered = render_pep440_old(pieces)\n",
   "    elif style == \"git-describe\":\n",
   "        rendered = render_git_describe(pieces)\n",
   "    elif style == \"git-describe-long\":\n",
   "        rendered = render_git_describe_long(pieces)\n",
   "        raise ValueError(\"unknown style '%s'\" % style)\n",
   "    return {\"version\": rendered, \"full-revisionid\": pieces[\"long\"],\n",
   "            \"dirty\": pieces[\"dirty\"], \"error\": None,\n",
   "            \"date\": pieces.get(\"date\")}\n",
   "    cfg = get_config()\n",
   "    verbose = cfg.verbose\n",
   "        return git_versions_from_keywords(get_keywords(), cfg.tag_prefix,\n",
   "                                          verbose)\n",
   "        root = os.path.realpath(__file__)\n",
   "        for _ in cfg.versionfile_source.split('/'):\n",
   "            root = os.path.dirname(root)\n",
   "        pieces = git_pieces_from_vcs(cfg.tag_prefix, root, verbose)\n",
   "        return render(pieces, cfg.style)\n",
   "        if cfg.parentdir_prefix:\n",
   "            return versions_from_parentdir(cfg.parentdir_prefix, root, verbose)\n"
  ]
 },
 "63": {
  "name": "git_full",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/_version.py",
  "lineno": "27",
  "column": "4",
  "context": ").\n    git_refnames = \" (HEAD -> branch-2.2)\"\n    git_full = \"fc5e37c2f7a0ca002e3ec4df7bdd65be0adfcac1\"\n    git_date = \"2020-08-13 16:24:36 -0700\"\n    key",
  "context_lines": "    # setup.py/versioneer.py will grep for the variable names, so they must\n    # each be defined on a line of their own. _version.py will just call\n    # get_keywords().\n    git_refnames = \" (HEAD -> branch-2.2)\"\n    git_full = \"fc5e37c2f7a0ca002e3ec4df7bdd65be0adfcac1\"\n    git_date = \"2020-08-13 16:24:36 -0700\"\n    keywords = {\"refnames\": git_refnames, \"full\": git_full, \"date\": git_date}\n    return keywords\n\n\nclass VersioneerConfig:\n",
  "slicing": [
   "    git_refnames = \" (HEAD -> branch-2.2)\"\n",
   "    git_full = \"fc5e37c2f7a0ca002e3ec4df7bdd65be0adfcac1\"\n",
   "    git_date = \"2020-08-13 16:24:36 -0700\"\n",
   "    keywords = {\"refnames\": git_refnames, \"full\": git_full, \"date\": git_date}\n",
   "    return keywords\n",
   "    cfg = VersioneerConfig()\n",
   "    cfg.VCS = \"git\"\n",
   "    cfg.style = \"git-describe\"\n",
   "    cfg.tag_prefix = \"\"\n",
   "    cfg.parentdir_prefix = \"Bokeh-\"\n",
   "    cfg.versionfile_source = \"bokeh/_version.py\"\n",
   "    cfg.verbose = False\n",
   "    return cfg\n",
   "HANDLERS = {}\n",
   "def register_vcs_handler(vcs, method):  # decorator\n",
   "        if vcs not in HANDLERS:\n",
   "            HANDLERS[vcs] = {}\n",
   "        HANDLERS[vcs][method] = f\n",
   "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False,\n",
   "    p = None\n",
   "    for c in commands:\n",
   "            dispcmd = str([c] + args)\n",
   "            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n",
   "            e = sys.exc_info()[1]\n",
   "            if e.errno == errno.ENOENT:\n",
   "                print(\"unable to run %s\" % dispcmd)\n",
   "                print(e)\n",
   "            print(\"unable to find command, tried %s\" % (commands,))\n",
   "    stdout = p.communicate()[0].strip()\n",
   "        stdout = stdout.decode()\n",
   "    if p.returncode != 0:\n",
   "            print(\"unable to run %s (error)\" % dispcmd)\n",
   "            print(\"stdout was %s\" % stdout)\n",
   "        return None, p.returncode\n",
   "    return stdout, p.returncode\n",
   "    rootdirs = []\n",
   "        dirname = os.path.basename(root)\n",
   "        if dirname.startswith(parentdir_prefix):\n",
   "            return {\"version\": dirname[len(parentdir_prefix):],\n",
   "            rootdirs.append(root)\n",
   "            root = os.path.dirname(root)  # up a level\n",
   "              (str(rootdirs), parentdir_prefix))\n",
   "    keywords = {}\n",
   "        with open(versionfile_abs) as f:\n",
   "            for line in f.readlines():\n",
   "                if line.strip().startswith(\"git_refnames =\"):\n",
   "                    mo = re.search(r'=\\s*\"(.*)\"', line)\n",
   "                    if mo:\n",
   "                        keywords[\"refnames\"] = mo.group(1)\n",
   "                if line.strip().startswith(\"git_full =\"):\n",
   "                    mo = re.search(r'=\\s*\"(.*)\"', line)\n",
   "                    if mo:\n",
   "                        keywords[\"full\"] = mo.group(1)\n",
   "                if line.strip().startswith(\"git_date =\"):\n",
   "                    mo = re.search(r'=\\s*\"(.*)\"', line)\n",
   "                    if mo:\n",
   "                        keywords[\"date\"] = mo.group(1)\n",
   "    return keywords\n",
   "def git_versions_from_keywords(keywords, tag_prefix, verbose):\n",
   "    if not keywords:\n",
   "    date = keywords.get(\"date\")\n",
   "    if date is not None:\n",
   "        date = date.strip().replace(\" \", \"T\", 1).replace(\" \", \"\", 1)\n",
   "    refnames = keywords[\"refnames\"].strip()\n",
   "    if refnames.startswith(\"$Format\"):\n",
   "    refs = {r.strip() for r in refnames.strip(\"()\").split(\",\")}\n",
   "    TAG = \"tag: \"\n",
   "    tags = {r[len(TAG):] for r in refs if r.startswith(TAG)}\n",
   "    if not tags:\n",
   "        tags = {r for r in refs if re.search(r\"\\d\", r)}\n",
   "            print(\"discarding '%s', no digits\" % \",\".join(refs - tags))\n",
   "        print(\"likely tags: %s\" % \",\".join(sorted(tags)))\n",
   "    for ref in sorted(tags):\n",
   "        if ref.startswith(tag_prefix):\n",
   "            r = ref[len(tag_prefix):]\n",
   "                print(\"picking %s\" % r)\n",
   "            return {\"version\": r,\n",
   "                    \"full-revisionid\": keywords[\"full\"].strip(),\n",
   "                    \"date\": date}\n",
   "            \"full-revisionid\": keywords[\"full\"].strip(),\n",
   "def git_pieces_from_vcs(tag_prefix, root, verbose, run_command=run_command):\n",
   "    GITS = [\"git\"]\n",
   "        GITS = [\"git.cmd\", \"git.exe\"]\n",
   "    out, rc = run_command(GITS, [\"rev-parse\", \"--git-dir\"], cwd=root,\n",
   "    if rc != 0:\n",
   "            print(\"Directory %s not under git control\" % root)\n",
   "    describe_out, rc = run_command(GITS, [\"describe\", \"--tags\", \"--dirty\",\n",
   "                                   cwd=root)\n",
   "    if describe_out is None:\n",
   "    describe_out = describe_out.strip()\n",
   "    full_out, rc = run_command(GITS, [\"rev-parse\", \"HEAD\"], cwd=root)\n",
   "    if full_out is None:\n",
   "    full_out = full_out.strip()\n",
   "    pieces = {}\n",
   "    pieces[\"long\"] = full_out\n",
   "    pieces[\"short\"] = full_out[:7]  # maybe improved later\n",
   "    pieces[\"error\"] = None\n",
   "    git_describe = describe_out\n",
   "    dirty = git_describe.endswith(\"-dirty\")\n",
   "    pieces[\"dirty\"] = dirty\n",
   "    if dirty:\n",
   "        git_describe = git_describe[:git_describe.rindex(\"-dirty\")]\n",
   "    if \"-\" in git_describe:\n",
   "        mo = re.search(r'^(.+)-(\\d+)-g([0-9a-f]+)$', git_describe)\n",
   "        if not mo:\n",
   "            pieces[\"error\"] = (\"unable to parse git-describe output: '%s'\"\n",
   "                               % describe_out)\n",
   "            return pieces\n",
   "        full_tag = mo.group(1)\n",
   "        if not full_tag.startswith(tag_prefix):\n",
   "                fmt = \"tag '%s' doesn't start with prefix '%s'\"\n",
   "                print(fmt % (full_tag, tag_prefix))\n",
   "            pieces[\"error\"] = (\"tag '%s' doesn't start with prefix '%s'\"\n",
   "                               % (full_tag, tag_prefix))\n",
   "            return pieces\n",
   "        pieces[\"closest-tag\"] = full_tag[len(tag_prefix):]\n",
   "        pieces[\"distance\"] = int(mo.group(2))\n",
   "        pieces[\"short\"] = mo.group(3)\n",
   "        pieces[\"closest-tag\"] = None\n",
   "        count_out, rc = run_command(GITS, [\"rev-list\", \"HEAD\", \"--count\"],\n",
   "                                    cwd=root)\n",
   "        pieces[\"distance\"] = int(count_out)  # total number of commits\n",
   "    date = run_command(GITS, [\"show\", \"-s\", \"--format=%ci\", \"HEAD\"],\n",
   "                       cwd=root)[0].strip()\n",
   "    pieces[\"date\"] = date.strip().replace(\" \", \"T\", 1).replace(\" \", \"\", 1)\n",
   "    return pieces\n",
   "def plus_or_dot(pieces):\n",
   "    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n",
   "def render_pep440(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"] or pieces[\"dirty\"]:\n",
   "            rendered += plus_or_dot(pieces)\n",
   "            rendered += \"%d.g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n",
   "            if pieces[\"dirty\"]:\n",
   "                rendered += \".dirty\"\n",
   "        rendered = \"0+untagged.%d.g%s\" % (pieces[\"distance\"],\n",
   "                                          pieces[\"short\"])\n",
   "        if pieces[\"dirty\"]:\n",
   "            rendered += \".dirty\"\n",
   "    return rendered\n",
   "def render_pep440_pre(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"]:\n",
   "            rendered += \".post.dev%d\" % pieces[\"distance\"]\n",
   "        rendered = \"0.post.dev%d\" % pieces[\"distance\"]\n",
   "    return rendered\n",
   "def render_pep440_post(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"] or pieces[\"dirty\"]:\n",
   "            rendered += \".post%d\" % pieces[\"distance\"]\n",
   "            if pieces[\"dirty\"]:\n",
   "                rendered += \".dev0\"\n",
   "            rendered += plus_or_dot(pieces)\n",
   "            rendered += \"g%s\" % pieces[\"short\"]\n",
   "        rendered = \"0.post%d\" % pieces[\"distance\"]\n",
   "        if pieces[\"dirty\"]:\n",
   "            rendered += \".dev0\"\n",
   "        rendered += \"+g%s\" % pieces[\"short\"]\n",
   "    return rendered\n",
   "def render_pep440_old(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"] or pieces[\"dirty\"]:\n",
   "            rendered += \".post%d\" % pieces[\"distance\"]\n",
   "            if pieces[\"dirty\"]:\n",
   "                rendered += \".dev0\"\n",
   "        rendered = \"0.post%d\" % pieces[\"distance\"]\n",
   "        if pieces[\"dirty\"]:\n",
   "            rendered += \".dev0\"\n",
   "    return rendered\n",
   "def render_git_describe(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"]:\n",
   "            rendered += \"-%d-g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n",
   "        rendered = pieces[\"short\"]\n",
   "    if pieces[\"dirty\"]:\n",
   "        rendered += \"-dirty\"\n",
   "    return rendered\n",
   "def render_git_describe_long(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        rendered += \"-%d-g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n",
   "        rendered = pieces[\"short\"]\n",
   "    if pieces[\"dirty\"]:\n",
   "        rendered += \"-dirty\"\n",
   "    return rendered\n",
   "    if pieces[\"error\"]:\n",
   "                \"full-revisionid\": pieces.get(\"long\"),\n",
   "                \"error\": pieces[\"error\"],\n",
   "        style = \"pep440\"  # the default\n",
   "    if style == \"pep440\":\n",
   "        rendered = render_pep440(pieces)\n",
   "    elif style == \"pep440-pre\":\n",
   "        rendered = render_pep440_pre(pieces)\n",
   "    elif style == \"pep440-post\":\n",
   "        rendered = render_pep440_post(pieces)\n",
   "    elif style == \"pep440-old\":\n",
   "        rendered = render_pep440_old(pieces)\n",
   "    elif style == \"git-describe\":\n",
   "        rendered = render_git_describe(pieces)\n",
   "    elif style == \"git-describe-long\":\n",
   "        rendered = render_git_describe_long(pieces)\n",
   "        raise ValueError(\"unknown style '%s'\" % style)\n",
   "    return {\"version\": rendered, \"full-revisionid\": pieces[\"long\"],\n",
   "            \"dirty\": pieces[\"dirty\"], \"error\": None,\n",
   "            \"date\": pieces.get(\"date\")}\n",
   "    cfg = get_config()\n",
   "    verbose = cfg.verbose\n",
   "        return git_versions_from_keywords(get_keywords(), cfg.tag_prefix,\n",
   "                                          verbose)\n",
   "        root = os.path.realpath(__file__)\n",
   "        for _ in cfg.versionfile_source.split('/'):\n",
   "            root = os.path.dirname(root)\n",
   "        pieces = git_pieces_from_vcs(cfg.tag_prefix, root, verbose)\n",
   "        return render(pieces, cfg.style)\n",
   "        if cfg.parentdir_prefix:\n",
   "            return versions_from_parentdir(cfg.parentdir_prefix, root, verbose)\n"
  ]
 },
 "64": {
  "name": "git_date",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/_version.py",
  "lineno": "28",
  "column": "4",
  "context": " = \"fc5e37c2f7a0ca002e3ec4df7bdd65be0adfcac1\"\n    git_date = \"2020-08-13 16:24:36 -0700\"\n    keywords = {\"refnames\": git_refnames, \"full\": ",
  "context_lines": "    # each be defined on a line of their own. _version.py will just call\n    # get_keywords().\n    git_refnames = \" (HEAD -> branch-2.2)\"\n    git_full = \"fc5e37c2f7a0ca002e3ec4df7bdd65be0adfcac1\"\n    git_date = \"2020-08-13 16:24:36 -0700\"\n    keywords = {\"refnames\": git_refnames, \"full\": git_full, \"date\": git_date}\n    return keywords\n\n\nclass VersioneerConfig:\n    \"\"\"Container for Versioneer configuration parameters.\"\"\"\n\n\n",
  "slicing": [
   "    git_refnames = \" (HEAD -> branch-2.2)\"\n",
   "    git_full = \"fc5e37c2f7a0ca002e3ec4df7bdd65be0adfcac1\"\n",
   "    git_date = \"2020-08-13 16:24:36 -0700\"\n",
   "    keywords = {\"refnames\": git_refnames, \"full\": git_full, \"date\": git_date}\n",
   "    return keywords\n",
   "    cfg = VersioneerConfig()\n",
   "    cfg.VCS = \"git\"\n",
   "    cfg.style = \"git-describe\"\n",
   "    cfg.tag_prefix = \"\"\n",
   "    cfg.parentdir_prefix = \"Bokeh-\"\n",
   "    cfg.versionfile_source = \"bokeh/_version.py\"\n",
   "    cfg.verbose = False\n",
   "    return cfg\n",
   "HANDLERS = {}\n",
   "def register_vcs_handler(vcs, method):  # decorator\n",
   "        if vcs not in HANDLERS:\n",
   "            HANDLERS[vcs] = {}\n",
   "        HANDLERS[vcs][method] = f\n",
   "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False,\n",
   "    p = None\n",
   "    for c in commands:\n",
   "            dispcmd = str([c] + args)\n",
   "            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n",
   "            e = sys.exc_info()[1]\n",
   "            if e.errno == errno.ENOENT:\n",
   "                print(\"unable to run %s\" % dispcmd)\n",
   "                print(e)\n",
   "            print(\"unable to find command, tried %s\" % (commands,))\n",
   "    stdout = p.communicate()[0].strip()\n",
   "        stdout = stdout.decode()\n",
   "    if p.returncode != 0:\n",
   "            print(\"unable to run %s (error)\" % dispcmd)\n",
   "            print(\"stdout was %s\" % stdout)\n",
   "        return None, p.returncode\n",
   "    return stdout, p.returncode\n",
   "    rootdirs = []\n",
   "        dirname = os.path.basename(root)\n",
   "        if dirname.startswith(parentdir_prefix):\n",
   "            return {\"version\": dirname[len(parentdir_prefix):],\n",
   "            rootdirs.append(root)\n",
   "            root = os.path.dirname(root)  # up a level\n",
   "              (str(rootdirs), parentdir_prefix))\n",
   "    keywords = {}\n",
   "        with open(versionfile_abs) as f:\n",
   "            for line in f.readlines():\n",
   "                if line.strip().startswith(\"git_refnames =\"):\n",
   "                    mo = re.search(r'=\\s*\"(.*)\"', line)\n",
   "                    if mo:\n",
   "                        keywords[\"refnames\"] = mo.group(1)\n",
   "                if line.strip().startswith(\"git_full =\"):\n",
   "                    mo = re.search(r'=\\s*\"(.*)\"', line)\n",
   "                    if mo:\n",
   "                        keywords[\"full\"] = mo.group(1)\n",
   "                if line.strip().startswith(\"git_date =\"):\n",
   "                    mo = re.search(r'=\\s*\"(.*)\"', line)\n",
   "                    if mo:\n",
   "                        keywords[\"date\"] = mo.group(1)\n",
   "    return keywords\n",
   "def git_versions_from_keywords(keywords, tag_prefix, verbose):\n",
   "    if not keywords:\n",
   "    date = keywords.get(\"date\")\n",
   "    if date is not None:\n",
   "        date = date.strip().replace(\" \", \"T\", 1).replace(\" \", \"\", 1)\n",
   "    refnames = keywords[\"refnames\"].strip()\n",
   "    if refnames.startswith(\"$Format\"):\n",
   "    refs = {r.strip() for r in refnames.strip(\"()\").split(\",\")}\n",
   "    TAG = \"tag: \"\n",
   "    tags = {r[len(TAG):] for r in refs if r.startswith(TAG)}\n",
   "    if not tags:\n",
   "        tags = {r for r in refs if re.search(r\"\\d\", r)}\n",
   "            print(\"discarding '%s', no digits\" % \",\".join(refs - tags))\n",
   "        print(\"likely tags: %s\" % \",\".join(sorted(tags)))\n",
   "    for ref in sorted(tags):\n",
   "        if ref.startswith(tag_prefix):\n",
   "            r = ref[len(tag_prefix):]\n",
   "                print(\"picking %s\" % r)\n",
   "            return {\"version\": r,\n",
   "                    \"full-revisionid\": keywords[\"full\"].strip(),\n",
   "                    \"date\": date}\n",
   "            \"full-revisionid\": keywords[\"full\"].strip(),\n",
   "def git_pieces_from_vcs(tag_prefix, root, verbose, run_command=run_command):\n",
   "    GITS = [\"git\"]\n",
   "        GITS = [\"git.cmd\", \"git.exe\"]\n",
   "    out, rc = run_command(GITS, [\"rev-parse\", \"--git-dir\"], cwd=root,\n",
   "    if rc != 0:\n",
   "            print(\"Directory %s not under git control\" % root)\n",
   "    describe_out, rc = run_command(GITS, [\"describe\", \"--tags\", \"--dirty\",\n",
   "                                   cwd=root)\n",
   "    if describe_out is None:\n",
   "    describe_out = describe_out.strip()\n",
   "    full_out, rc = run_command(GITS, [\"rev-parse\", \"HEAD\"], cwd=root)\n",
   "    if full_out is None:\n",
   "    full_out = full_out.strip()\n",
   "    pieces = {}\n",
   "    pieces[\"long\"] = full_out\n",
   "    pieces[\"short\"] = full_out[:7]  # maybe improved later\n",
   "    pieces[\"error\"] = None\n",
   "    git_describe = describe_out\n",
   "    dirty = git_describe.endswith(\"-dirty\")\n",
   "    pieces[\"dirty\"] = dirty\n",
   "    if dirty:\n",
   "        git_describe = git_describe[:git_describe.rindex(\"-dirty\")]\n",
   "    if \"-\" in git_describe:\n",
   "        mo = re.search(r'^(.+)-(\\d+)-g([0-9a-f]+)$', git_describe)\n",
   "        if not mo:\n",
   "            pieces[\"error\"] = (\"unable to parse git-describe output: '%s'\"\n",
   "                               % describe_out)\n",
   "            return pieces\n",
   "        full_tag = mo.group(1)\n",
   "        if not full_tag.startswith(tag_prefix):\n",
   "                fmt = \"tag '%s' doesn't start with prefix '%s'\"\n",
   "                print(fmt % (full_tag, tag_prefix))\n",
   "            pieces[\"error\"] = (\"tag '%s' doesn't start with prefix '%s'\"\n",
   "                               % (full_tag, tag_prefix))\n",
   "            return pieces\n",
   "        pieces[\"closest-tag\"] = full_tag[len(tag_prefix):]\n",
   "        pieces[\"distance\"] = int(mo.group(2))\n",
   "        pieces[\"short\"] = mo.group(3)\n",
   "        pieces[\"closest-tag\"] = None\n",
   "        count_out, rc = run_command(GITS, [\"rev-list\", \"HEAD\", \"--count\"],\n",
   "                                    cwd=root)\n",
   "        pieces[\"distance\"] = int(count_out)  # total number of commits\n",
   "    date = run_command(GITS, [\"show\", \"-s\", \"--format=%ci\", \"HEAD\"],\n",
   "                       cwd=root)[0].strip()\n",
   "    pieces[\"date\"] = date.strip().replace(\" \", \"T\", 1).replace(\" \", \"\", 1)\n",
   "    return pieces\n",
   "def plus_or_dot(pieces):\n",
   "    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n",
   "def render_pep440(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"] or pieces[\"dirty\"]:\n",
   "            rendered += plus_or_dot(pieces)\n",
   "            rendered += \"%d.g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n",
   "            if pieces[\"dirty\"]:\n",
   "                rendered += \".dirty\"\n",
   "        rendered = \"0+untagged.%d.g%s\" % (pieces[\"distance\"],\n",
   "                                          pieces[\"short\"])\n",
   "        if pieces[\"dirty\"]:\n",
   "            rendered += \".dirty\"\n",
   "    return rendered\n",
   "def render_pep440_pre(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"]:\n",
   "            rendered += \".post.dev%d\" % pieces[\"distance\"]\n",
   "        rendered = \"0.post.dev%d\" % pieces[\"distance\"]\n",
   "    return rendered\n",
   "def render_pep440_post(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"] or pieces[\"dirty\"]:\n",
   "            rendered += \".post%d\" % pieces[\"distance\"]\n",
   "            if pieces[\"dirty\"]:\n",
   "                rendered += \".dev0\"\n",
   "            rendered += plus_or_dot(pieces)\n",
   "            rendered += \"g%s\" % pieces[\"short\"]\n",
   "        rendered = \"0.post%d\" % pieces[\"distance\"]\n",
   "        if pieces[\"dirty\"]:\n",
   "            rendered += \".dev0\"\n",
   "        rendered += \"+g%s\" % pieces[\"short\"]\n",
   "    return rendered\n",
   "def render_pep440_old(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"] or pieces[\"dirty\"]:\n",
   "            rendered += \".post%d\" % pieces[\"distance\"]\n",
   "            if pieces[\"dirty\"]:\n",
   "                rendered += \".dev0\"\n",
   "        rendered = \"0.post%d\" % pieces[\"distance\"]\n",
   "        if pieces[\"dirty\"]:\n",
   "            rendered += \".dev0\"\n",
   "    return rendered\n",
   "def render_git_describe(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"]:\n",
   "            rendered += \"-%d-g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n",
   "        rendered = pieces[\"short\"]\n",
   "    if pieces[\"dirty\"]:\n",
   "        rendered += \"-dirty\"\n",
   "    return rendered\n",
   "def render_git_describe_long(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        rendered += \"-%d-g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n",
   "        rendered = pieces[\"short\"]\n",
   "    if pieces[\"dirty\"]:\n",
   "        rendered += \"-dirty\"\n",
   "    return rendered\n",
   "    if pieces[\"error\"]:\n",
   "                \"full-revisionid\": pieces.get(\"long\"),\n",
   "                \"error\": pieces[\"error\"],\n",
   "        style = \"pep440\"  # the default\n",
   "    if style == \"pep440\":\n",
   "        rendered = render_pep440(pieces)\n",
   "    elif style == \"pep440-pre\":\n",
   "        rendered = render_pep440_pre(pieces)\n",
   "    elif style == \"pep440-post\":\n",
   "        rendered = render_pep440_post(pieces)\n",
   "    elif style == \"pep440-old\":\n",
   "        rendered = render_pep440_old(pieces)\n",
   "    elif style == \"git-describe\":\n",
   "        rendered = render_git_describe(pieces)\n",
   "    elif style == \"git-describe-long\":\n",
   "        rendered = render_git_describe_long(pieces)\n",
   "        raise ValueError(\"unknown style '%s'\" % style)\n",
   "    return {\"version\": rendered, \"full-revisionid\": pieces[\"long\"],\n",
   "            \"dirty\": pieces[\"dirty\"], \"error\": None,\n",
   "            \"date\": pieces.get(\"date\")}\n",
   "    cfg = get_config()\n",
   "    verbose = cfg.verbose\n",
   "        return git_versions_from_keywords(get_keywords(), cfg.tag_prefix,\n",
   "                                          verbose)\n",
   "        root = os.path.realpath(__file__)\n",
   "        for _ in cfg.versionfile_source.split('/'):\n",
   "            root = os.path.dirname(root)\n",
   "        pieces = git_pieces_from_vcs(cfg.tag_prefix, root, verbose)\n",
   "        return render(pieces, cfg.style)\n",
   "        if cfg.parentdir_prefix:\n",
   "            return versions_from_parentdir(cfg.parentdir_prefix, root, verbose)\n"
  ]
 },
 "65": {
  "name": "date",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/_version.py",
  "lineno": "165",
  "column": "4",
  "context": "se NotThisMethod(\"no keywords at all, weird\")\n    date = keywords.get(\"date\")\n    if date is not None:\n        # git-2.2.0 added",
  "context_lines": "def git_versions_from_keywords(keywords, tag_prefix, verbose):\n    \"\"\"Get version information from git keywords.\"\"\"\n    if not keywords:\n        raise NotThisMethod(\"no keywords at all, weird\")\n    date = keywords.get(\"date\")\n    if date is not None:\n        # git-2.2.0 added \"%cI\", which expands to an ISO-8601 -compliant\n        # datestamp. However we prefer \"%ci\" (which expands to an \"ISO-8601\n        # -like\" string, which we must then edit to make compliant), because\n",
  "slicing": [
   "    git_refnames = \" (HEAD -> branch-2.2)\"\n",
   "    git_full = \"fc5e37c2f7a0ca002e3ec4df7bdd65be0adfcac1\"\n",
   "    git_date = \"2020-08-13 16:24:36 -0700\"\n",
   "    keywords = {\"refnames\": git_refnames, \"full\": git_full, \"date\": git_date}\n",
   "    return keywords\n",
   "    cfg = VersioneerConfig()\n",
   "    cfg.VCS = \"git\"\n",
   "    cfg.style = \"git-describe\"\n",
   "    cfg.tag_prefix = \"\"\n",
   "    cfg.parentdir_prefix = \"Bokeh-\"\n",
   "    cfg.versionfile_source = \"bokeh/_version.py\"\n",
   "    cfg.verbose = False\n",
   "    return cfg\n",
   "HANDLERS = {}\n",
   "def register_vcs_handler(vcs, method):  # decorator\n",
   "        if vcs not in HANDLERS:\n",
   "            HANDLERS[vcs] = {}\n",
   "        HANDLERS[vcs][method] = f\n",
   "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False,\n",
   "    p = None\n",
   "    for c in commands:\n",
   "            dispcmd = str([c] + args)\n",
   "            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n",
   "            e = sys.exc_info()[1]\n",
   "            if e.errno == errno.ENOENT:\n",
   "                print(\"unable to run %s\" % dispcmd)\n",
   "                print(e)\n",
   "            print(\"unable to find command, tried %s\" % (commands,))\n",
   "    stdout = p.communicate()[0].strip()\n",
   "        stdout = stdout.decode()\n",
   "    if p.returncode != 0:\n",
   "            print(\"unable to run %s (error)\" % dispcmd)\n",
   "            print(\"stdout was %s\" % stdout)\n",
   "        return None, p.returncode\n",
   "    return stdout, p.returncode\n",
   "    rootdirs = []\n",
   "        dirname = os.path.basename(root)\n",
   "        if dirname.startswith(parentdir_prefix):\n",
   "            return {\"version\": dirname[len(parentdir_prefix):],\n",
   "            rootdirs.append(root)\n",
   "            root = os.path.dirname(root)  # up a level\n",
   "              (str(rootdirs), parentdir_prefix))\n",
   "    keywords = {}\n",
   "        with open(versionfile_abs) as f:\n",
   "            for line in f.readlines():\n",
   "                if line.strip().startswith(\"git_refnames =\"):\n",
   "                    mo = re.search(r'=\\s*\"(.*)\"', line)\n",
   "                    if mo:\n",
   "                        keywords[\"refnames\"] = mo.group(1)\n",
   "                if line.strip().startswith(\"git_full =\"):\n",
   "                    mo = re.search(r'=\\s*\"(.*)\"', line)\n",
   "                    if mo:\n",
   "                        keywords[\"full\"] = mo.group(1)\n",
   "                if line.strip().startswith(\"git_date =\"):\n",
   "                    mo = re.search(r'=\\s*\"(.*)\"', line)\n",
   "                    if mo:\n",
   "                        keywords[\"date\"] = mo.group(1)\n",
   "    return keywords\n",
   "def git_versions_from_keywords(keywords, tag_prefix, verbose):\n",
   "    if not keywords:\n",
   "    date = keywords.get(\"date\")\n",
   "    if date is not None:\n",
   "        date = date.strip().replace(\" \", \"T\", 1).replace(\" \", \"\", 1)\n",
   "    refnames = keywords[\"refnames\"].strip()\n",
   "    if refnames.startswith(\"$Format\"):\n",
   "    refs = {r.strip() for r in refnames.strip(\"()\").split(\",\")}\n",
   "    TAG = \"tag: \"\n",
   "    tags = {r[len(TAG):] for r in refs if r.startswith(TAG)}\n",
   "    if not tags:\n",
   "        tags = {r for r in refs if re.search(r\"\\d\", r)}\n",
   "            print(\"discarding '%s', no digits\" % \",\".join(refs - tags))\n",
   "        print(\"likely tags: %s\" % \",\".join(sorted(tags)))\n",
   "    for ref in sorted(tags):\n",
   "        if ref.startswith(tag_prefix):\n",
   "            r = ref[len(tag_prefix):]\n",
   "                print(\"picking %s\" % r)\n",
   "            return {\"version\": r,\n",
   "                    \"full-revisionid\": keywords[\"full\"].strip(),\n",
   "                    \"date\": date}\n",
   "            \"full-revisionid\": keywords[\"full\"].strip(),\n",
   "def git_pieces_from_vcs(tag_prefix, root, verbose, run_command=run_command):\n",
   "    GITS = [\"git\"]\n",
   "        GITS = [\"git.cmd\", \"git.exe\"]\n",
   "    out, rc = run_command(GITS, [\"rev-parse\", \"--git-dir\"], cwd=root,\n",
   "    if rc != 0:\n",
   "            print(\"Directory %s not under git control\" % root)\n",
   "    describe_out, rc = run_command(GITS, [\"describe\", \"--tags\", \"--dirty\",\n",
   "                                   cwd=root)\n",
   "    if describe_out is None:\n",
   "    describe_out = describe_out.strip()\n",
   "    full_out, rc = run_command(GITS, [\"rev-parse\", \"HEAD\"], cwd=root)\n",
   "    if full_out is None:\n",
   "    full_out = full_out.strip()\n",
   "    pieces = {}\n",
   "    pieces[\"long\"] = full_out\n",
   "    pieces[\"short\"] = full_out[:7]  # maybe improved later\n",
   "    pieces[\"error\"] = None\n",
   "    git_describe = describe_out\n",
   "    dirty = git_describe.endswith(\"-dirty\")\n",
   "    pieces[\"dirty\"] = dirty\n",
   "    if dirty:\n",
   "        git_describe = git_describe[:git_describe.rindex(\"-dirty\")]\n",
   "    if \"-\" in git_describe:\n",
   "        mo = re.search(r'^(.+)-(\\d+)-g([0-9a-f]+)$', git_describe)\n",
   "        if not mo:\n",
   "            pieces[\"error\"] = (\"unable to parse git-describe output: '%s'\"\n",
   "                               % describe_out)\n",
   "            return pieces\n",
   "        full_tag = mo.group(1)\n",
   "        if not full_tag.startswith(tag_prefix):\n",
   "                fmt = \"tag '%s' doesn't start with prefix '%s'\"\n",
   "                print(fmt % (full_tag, tag_prefix))\n",
   "            pieces[\"error\"] = (\"tag '%s' doesn't start with prefix '%s'\"\n",
   "                               % (full_tag, tag_prefix))\n",
   "            return pieces\n",
   "        pieces[\"closest-tag\"] = full_tag[len(tag_prefix):]\n",
   "        pieces[\"distance\"] = int(mo.group(2))\n",
   "        pieces[\"short\"] = mo.group(3)\n",
   "        pieces[\"closest-tag\"] = None\n",
   "        count_out, rc = run_command(GITS, [\"rev-list\", \"HEAD\", \"--count\"],\n",
   "                                    cwd=root)\n",
   "        pieces[\"distance\"] = int(count_out)  # total number of commits\n",
   "    date = run_command(GITS, [\"show\", \"-s\", \"--format=%ci\", \"HEAD\"],\n",
   "                       cwd=root)[0].strip()\n",
   "    pieces[\"date\"] = date.strip().replace(\" \", \"T\", 1).replace(\" \", \"\", 1)\n",
   "    return pieces\n",
   "def plus_or_dot(pieces):\n",
   "    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n",
   "def render_pep440(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"] or pieces[\"dirty\"]:\n",
   "            rendered += plus_or_dot(pieces)\n",
   "            rendered += \"%d.g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n",
   "            if pieces[\"dirty\"]:\n",
   "                rendered += \".dirty\"\n",
   "        rendered = \"0+untagged.%d.g%s\" % (pieces[\"distance\"],\n",
   "                                          pieces[\"short\"])\n",
   "        if pieces[\"dirty\"]:\n",
   "            rendered += \".dirty\"\n",
   "    return rendered\n",
   "def render_pep440_pre(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"]:\n",
   "            rendered += \".post.dev%d\" % pieces[\"distance\"]\n",
   "        rendered = \"0.post.dev%d\" % pieces[\"distance\"]\n",
   "    return rendered\n",
   "def render_pep440_post(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"] or pieces[\"dirty\"]:\n",
   "            rendered += \".post%d\" % pieces[\"distance\"]\n",
   "            if pieces[\"dirty\"]:\n",
   "                rendered += \".dev0\"\n",
   "            rendered += plus_or_dot(pieces)\n",
   "            rendered += \"g%s\" % pieces[\"short\"]\n",
   "        rendered = \"0.post%d\" % pieces[\"distance\"]\n",
   "        if pieces[\"dirty\"]:\n",
   "            rendered += \".dev0\"\n",
   "        rendered += \"+g%s\" % pieces[\"short\"]\n",
   "    return rendered\n",
   "def render_pep440_old(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"] or pieces[\"dirty\"]:\n",
   "            rendered += \".post%d\" % pieces[\"distance\"]\n",
   "            if pieces[\"dirty\"]:\n",
   "                rendered += \".dev0\"\n",
   "        rendered = \"0.post%d\" % pieces[\"distance\"]\n",
   "        if pieces[\"dirty\"]:\n",
   "            rendered += \".dev0\"\n",
   "    return rendered\n",
   "def render_git_describe(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"]:\n",
   "            rendered += \"-%d-g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n",
   "        rendered = pieces[\"short\"]\n",
   "    if pieces[\"dirty\"]:\n",
   "        rendered += \"-dirty\"\n",
   "    return rendered\n",
   "def render_git_describe_long(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        rendered += \"-%d-g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n",
   "        rendered = pieces[\"short\"]\n",
   "    if pieces[\"dirty\"]:\n",
   "        rendered += \"-dirty\"\n",
   "    return rendered\n",
   "    if pieces[\"error\"]:\n",
   "                \"full-revisionid\": pieces.get(\"long\"),\n",
   "                \"error\": pieces[\"error\"],\n",
   "        style = \"pep440\"  # the default\n",
   "    if style == \"pep440\":\n",
   "        rendered = render_pep440(pieces)\n",
   "    elif style == \"pep440-pre\":\n",
   "        rendered = render_pep440_pre(pieces)\n",
   "    elif style == \"pep440-post\":\n",
   "        rendered = render_pep440_post(pieces)\n",
   "    elif style == \"pep440-old\":\n",
   "        rendered = render_pep440_old(pieces)\n",
   "    elif style == \"git-describe\":\n",
   "        rendered = render_git_describe(pieces)\n",
   "    elif style == \"git-describe-long\":\n",
   "        rendered = render_git_describe_long(pieces)\n",
   "        raise ValueError(\"unknown style '%s'\" % style)\n",
   "    return {\"version\": rendered, \"full-revisionid\": pieces[\"long\"],\n",
   "            \"dirty\": pieces[\"dirty\"], \"error\": None,\n",
   "            \"date\": pieces.get(\"date\")}\n",
   "    cfg = get_config()\n",
   "    verbose = cfg.verbose\n",
   "        return git_versions_from_keywords(get_keywords(), cfg.tag_prefix,\n",
   "                                          verbose)\n",
   "        root = os.path.realpath(__file__)\n",
   "        for _ in cfg.versionfile_source.split('/'):\n",
   "            root = os.path.dirname(root)\n",
   "        pieces = git_pieces_from_vcs(cfg.tag_prefix, root, verbose)\n",
   "        return render(pieces, cfg.style)\n",
   "        if cfg.parentdir_prefix:\n",
   "            return versions_from_parentdir(cfg.parentdir_prefix, root, verbose)\n"
  ]
 },
 "66": {
  "name": "date",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/_version.py",
  "lineno": "173",
  "column": "8",
  "context": "work around using an\n        # older one.\n        date = date.strip().replace(\" \", \"T\", 1).replace(\" \", \"\", 1)\n    refnames = keywords[\"refnames\"].strip()\n    if",
  "context_lines": "        # -like\" string, which we must then edit to make compliant), because\n        # it's been around since git-1.5.3, and it's too difficult to\n        # discover which version we're using, or to work around using an\n        # older one.\n        date = date.strip().replace(\" \", \"T\", 1).replace(\" \", \"\", 1)\n    refnames = keywords[\"refnames\"].strip()\n    if refnames.startswith(\"$Format\"):\n        if verbose:\n            print(\"keywords are unexpanded, not using\")\n",
  "slicing": [
   "    git_refnames = \" (HEAD -> branch-2.2)\"\n",
   "    git_full = \"fc5e37c2f7a0ca002e3ec4df7bdd65be0adfcac1\"\n",
   "    git_date = \"2020-08-13 16:24:36 -0700\"\n",
   "    keywords = {\"refnames\": git_refnames, \"full\": git_full, \"date\": git_date}\n",
   "    return keywords\n",
   "    cfg = VersioneerConfig()\n",
   "    cfg.VCS = \"git\"\n",
   "    cfg.style = \"git-describe\"\n",
   "    cfg.tag_prefix = \"\"\n",
   "    cfg.parentdir_prefix = \"Bokeh-\"\n",
   "    cfg.versionfile_source = \"bokeh/_version.py\"\n",
   "    cfg.verbose = False\n",
   "    return cfg\n",
   "HANDLERS = {}\n",
   "def register_vcs_handler(vcs, method):  # decorator\n",
   "        if vcs not in HANDLERS:\n",
   "            HANDLERS[vcs] = {}\n",
   "        HANDLERS[vcs][method] = f\n",
   "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False,\n",
   "    p = None\n",
   "    for c in commands:\n",
   "            dispcmd = str([c] + args)\n",
   "            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n",
   "            e = sys.exc_info()[1]\n",
   "            if e.errno == errno.ENOENT:\n",
   "                print(\"unable to run %s\" % dispcmd)\n",
   "                print(e)\n",
   "            print(\"unable to find command, tried %s\" % (commands,))\n",
   "    stdout = p.communicate()[0].strip()\n",
   "        stdout = stdout.decode()\n",
   "    if p.returncode != 0:\n",
   "            print(\"unable to run %s (error)\" % dispcmd)\n",
   "            print(\"stdout was %s\" % stdout)\n",
   "        return None, p.returncode\n",
   "    return stdout, p.returncode\n",
   "    rootdirs = []\n",
   "        dirname = os.path.basename(root)\n",
   "        if dirname.startswith(parentdir_prefix):\n",
   "            return {\"version\": dirname[len(parentdir_prefix):],\n",
   "            rootdirs.append(root)\n",
   "            root = os.path.dirname(root)  # up a level\n",
   "              (str(rootdirs), parentdir_prefix))\n",
   "    keywords = {}\n",
   "        with open(versionfile_abs) as f:\n",
   "            for line in f.readlines():\n",
   "                if line.strip().startswith(\"git_refnames =\"):\n",
   "                    mo = re.search(r'=\\s*\"(.*)\"', line)\n",
   "                    if mo:\n",
   "                        keywords[\"refnames\"] = mo.group(1)\n",
   "                if line.strip().startswith(\"git_full =\"):\n",
   "                    mo = re.search(r'=\\s*\"(.*)\"', line)\n",
   "                    if mo:\n",
   "                        keywords[\"full\"] = mo.group(1)\n",
   "                if line.strip().startswith(\"git_date =\"):\n",
   "                    mo = re.search(r'=\\s*\"(.*)\"', line)\n",
   "                    if mo:\n",
   "                        keywords[\"date\"] = mo.group(1)\n",
   "    return keywords\n",
   "def git_versions_from_keywords(keywords, tag_prefix, verbose):\n",
   "    if not keywords:\n",
   "    date = keywords.get(\"date\")\n",
   "    if date is not None:\n",
   "        date = date.strip().replace(\" \", \"T\", 1).replace(\" \", \"\", 1)\n",
   "    refnames = keywords[\"refnames\"].strip()\n",
   "    if refnames.startswith(\"$Format\"):\n",
   "    refs = {r.strip() for r in refnames.strip(\"()\").split(\",\")}\n",
   "    TAG = \"tag: \"\n",
   "    tags = {r[len(TAG):] for r in refs if r.startswith(TAG)}\n",
   "    if not tags:\n",
   "        tags = {r for r in refs if re.search(r\"\\d\", r)}\n",
   "            print(\"discarding '%s', no digits\" % \",\".join(refs - tags))\n",
   "        print(\"likely tags: %s\" % \",\".join(sorted(tags)))\n",
   "    for ref in sorted(tags):\n",
   "        if ref.startswith(tag_prefix):\n",
   "            r = ref[len(tag_prefix):]\n",
   "                print(\"picking %s\" % r)\n",
   "            return {\"version\": r,\n",
   "                    \"full-revisionid\": keywords[\"full\"].strip(),\n",
   "                    \"date\": date}\n",
   "            \"full-revisionid\": keywords[\"full\"].strip(),\n",
   "def git_pieces_from_vcs(tag_prefix, root, verbose, run_command=run_command):\n",
   "    GITS = [\"git\"]\n",
   "        GITS = [\"git.cmd\", \"git.exe\"]\n",
   "    out, rc = run_command(GITS, [\"rev-parse\", \"--git-dir\"], cwd=root,\n",
   "    if rc != 0:\n",
   "            print(\"Directory %s not under git control\" % root)\n",
   "    describe_out, rc = run_command(GITS, [\"describe\", \"--tags\", \"--dirty\",\n",
   "                                   cwd=root)\n",
   "    if describe_out is None:\n",
   "    describe_out = describe_out.strip()\n",
   "    full_out, rc = run_command(GITS, [\"rev-parse\", \"HEAD\"], cwd=root)\n",
   "    if full_out is None:\n",
   "    full_out = full_out.strip()\n",
   "    pieces = {}\n",
   "    pieces[\"long\"] = full_out\n",
   "    pieces[\"short\"] = full_out[:7]  # maybe improved later\n",
   "    pieces[\"error\"] = None\n",
   "    git_describe = describe_out\n",
   "    dirty = git_describe.endswith(\"-dirty\")\n",
   "    pieces[\"dirty\"] = dirty\n",
   "    if dirty:\n",
   "        git_describe = git_describe[:git_describe.rindex(\"-dirty\")]\n",
   "    if \"-\" in git_describe:\n",
   "        mo = re.search(r'^(.+)-(\\d+)-g([0-9a-f]+)$', git_describe)\n",
   "        if not mo:\n",
   "            pieces[\"error\"] = (\"unable to parse git-describe output: '%s'\"\n",
   "                               % describe_out)\n",
   "            return pieces\n",
   "        full_tag = mo.group(1)\n",
   "        if not full_tag.startswith(tag_prefix):\n",
   "                fmt = \"tag '%s' doesn't start with prefix '%s'\"\n",
   "                print(fmt % (full_tag, tag_prefix))\n",
   "            pieces[\"error\"] = (\"tag '%s' doesn't start with prefix '%s'\"\n",
   "                               % (full_tag, tag_prefix))\n",
   "            return pieces\n",
   "        pieces[\"closest-tag\"] = full_tag[len(tag_prefix):]\n",
   "        pieces[\"distance\"] = int(mo.group(2))\n",
   "        pieces[\"short\"] = mo.group(3)\n",
   "        pieces[\"closest-tag\"] = None\n",
   "        count_out, rc = run_command(GITS, [\"rev-list\", \"HEAD\", \"--count\"],\n",
   "                                    cwd=root)\n",
   "        pieces[\"distance\"] = int(count_out)  # total number of commits\n",
   "    date = run_command(GITS, [\"show\", \"-s\", \"--format=%ci\", \"HEAD\"],\n",
   "                       cwd=root)[0].strip()\n",
   "    pieces[\"date\"] = date.strip().replace(\" \", \"T\", 1).replace(\" \", \"\", 1)\n",
   "    return pieces\n",
   "def plus_or_dot(pieces):\n",
   "    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n",
   "def render_pep440(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"] or pieces[\"dirty\"]:\n",
   "            rendered += plus_or_dot(pieces)\n",
   "            rendered += \"%d.g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n",
   "            if pieces[\"dirty\"]:\n",
   "                rendered += \".dirty\"\n",
   "        rendered = \"0+untagged.%d.g%s\" % (pieces[\"distance\"],\n",
   "                                          pieces[\"short\"])\n",
   "        if pieces[\"dirty\"]:\n",
   "            rendered += \".dirty\"\n",
   "    return rendered\n",
   "def render_pep440_pre(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"]:\n",
   "            rendered += \".post.dev%d\" % pieces[\"distance\"]\n",
   "        rendered = \"0.post.dev%d\" % pieces[\"distance\"]\n",
   "    return rendered\n",
   "def render_pep440_post(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"] or pieces[\"dirty\"]:\n",
   "            rendered += \".post%d\" % pieces[\"distance\"]\n",
   "            if pieces[\"dirty\"]:\n",
   "                rendered += \".dev0\"\n",
   "            rendered += plus_or_dot(pieces)\n",
   "            rendered += \"g%s\" % pieces[\"short\"]\n",
   "        rendered = \"0.post%d\" % pieces[\"distance\"]\n",
   "        if pieces[\"dirty\"]:\n",
   "            rendered += \".dev0\"\n",
   "        rendered += \"+g%s\" % pieces[\"short\"]\n",
   "    return rendered\n",
   "def render_pep440_old(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"] or pieces[\"dirty\"]:\n",
   "            rendered += \".post%d\" % pieces[\"distance\"]\n",
   "            if pieces[\"dirty\"]:\n",
   "                rendered += \".dev0\"\n",
   "        rendered = \"0.post%d\" % pieces[\"distance\"]\n",
   "        if pieces[\"dirty\"]:\n",
   "            rendered += \".dev0\"\n",
   "    return rendered\n",
   "def render_git_describe(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"]:\n",
   "            rendered += \"-%d-g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n",
   "        rendered = pieces[\"short\"]\n",
   "    if pieces[\"dirty\"]:\n",
   "        rendered += \"-dirty\"\n",
   "    return rendered\n",
   "def render_git_describe_long(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        rendered += \"-%d-g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n",
   "        rendered = pieces[\"short\"]\n",
   "    if pieces[\"dirty\"]:\n",
   "        rendered += \"-dirty\"\n",
   "    return rendered\n",
   "    if pieces[\"error\"]:\n",
   "                \"full-revisionid\": pieces.get(\"long\"),\n",
   "                \"error\": pieces[\"error\"],\n",
   "        style = \"pep440\"  # the default\n",
   "    if style == \"pep440\":\n",
   "        rendered = render_pep440(pieces)\n",
   "    elif style == \"pep440-pre\":\n",
   "        rendered = render_pep440_pre(pieces)\n",
   "    elif style == \"pep440-post\":\n",
   "        rendered = render_pep440_post(pieces)\n",
   "    elif style == \"pep440-old\":\n",
   "        rendered = render_pep440_old(pieces)\n",
   "    elif style == \"git-describe\":\n",
   "        rendered = render_git_describe(pieces)\n",
   "    elif style == \"git-describe-long\":\n",
   "        rendered = render_git_describe_long(pieces)\n",
   "        raise ValueError(\"unknown style '%s'\" % style)\n",
   "    return {\"version\": rendered, \"full-revisionid\": pieces[\"long\"],\n",
   "            \"dirty\": pieces[\"dirty\"], \"error\": None,\n",
   "            \"date\": pieces.get(\"date\")}\n",
   "    cfg = get_config()\n",
   "    verbose = cfg.verbose\n",
   "        return git_versions_from_keywords(get_keywords(), cfg.tag_prefix,\n",
   "                                          verbose)\n",
   "        root = os.path.realpath(__file__)\n",
   "        for _ in cfg.versionfile_source.split('/'):\n",
   "            root = os.path.dirname(root)\n",
   "        pieces = git_pieces_from_vcs(cfg.tag_prefix, root, verbose)\n",
   "        return render(pieces, cfg.style)\n",
   "        if cfg.parentdir_prefix:\n",
   "            return versions_from_parentdir(cfg.parentdir_prefix, root, verbose)\n"
  ]
 },
 "67": {
  "name": "refnames",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/_version.py",
  "lineno": "174",
  "column": "4",
  "context": "ip().replace(\" \", \"T\", 1).replace(\" \", \"\", 1)\n    refnames = keywords[\"refnames\"].strip()\n    if refnames.startswith(\"$Format\"):\n        if ",
  "context_lines": "        # it's been around since git-1.5.3, and it's too difficult to\n        # discover which version we're using, or to work around using an\n        # older one.\n        date = date.strip().replace(\" \", \"T\", 1).replace(\" \", \"\", 1)\n    refnames = keywords[\"refnames\"].strip()\n    if refnames.startswith(\"$Format\"):\n        if verbose:\n            print(\"keywords are unexpanded, not using\")\n        raise NotThisMethod(\"unexpanded keywords, not a git-archive tarball\")\n",
  "slicing": [
   "    git_refnames = \" (HEAD -> branch-2.2)\"\n",
   "    git_full = \"fc5e37c2f7a0ca002e3ec4df7bdd65be0adfcac1\"\n",
   "    git_date = \"2020-08-13 16:24:36 -0700\"\n",
   "    keywords = {\"refnames\": git_refnames, \"full\": git_full, \"date\": git_date}\n",
   "    return keywords\n",
   "    cfg = VersioneerConfig()\n",
   "    cfg.VCS = \"git\"\n",
   "    cfg.style = \"git-describe\"\n",
   "    cfg.tag_prefix = \"\"\n",
   "    cfg.parentdir_prefix = \"Bokeh-\"\n",
   "    cfg.versionfile_source = \"bokeh/_version.py\"\n",
   "    cfg.verbose = False\n",
   "    return cfg\n",
   "HANDLERS = {}\n",
   "def register_vcs_handler(vcs, method):  # decorator\n",
   "        if vcs not in HANDLERS:\n",
   "            HANDLERS[vcs] = {}\n",
   "        HANDLERS[vcs][method] = f\n",
   "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False,\n",
   "    p = None\n",
   "    for c in commands:\n",
   "            dispcmd = str([c] + args)\n",
   "            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n",
   "            e = sys.exc_info()[1]\n",
   "            if e.errno == errno.ENOENT:\n",
   "                print(\"unable to run %s\" % dispcmd)\n",
   "                print(e)\n",
   "            print(\"unable to find command, tried %s\" % (commands,))\n",
   "    stdout = p.communicate()[0].strip()\n",
   "        stdout = stdout.decode()\n",
   "    if p.returncode != 0:\n",
   "            print(\"unable to run %s (error)\" % dispcmd)\n",
   "            print(\"stdout was %s\" % stdout)\n",
   "        return None, p.returncode\n",
   "    return stdout, p.returncode\n",
   "    rootdirs = []\n",
   "        dirname = os.path.basename(root)\n",
   "        if dirname.startswith(parentdir_prefix):\n",
   "            return {\"version\": dirname[len(parentdir_prefix):],\n",
   "            rootdirs.append(root)\n",
   "            root = os.path.dirname(root)  # up a level\n",
   "              (str(rootdirs), parentdir_prefix))\n",
   "    keywords = {}\n",
   "        with open(versionfile_abs) as f:\n",
   "            for line in f.readlines():\n",
   "                if line.strip().startswith(\"git_refnames =\"):\n",
   "                    mo = re.search(r'=\\s*\"(.*)\"', line)\n",
   "                    if mo:\n",
   "                        keywords[\"refnames\"] = mo.group(1)\n",
   "                if line.strip().startswith(\"git_full =\"):\n",
   "                    mo = re.search(r'=\\s*\"(.*)\"', line)\n",
   "                    if mo:\n",
   "                        keywords[\"full\"] = mo.group(1)\n",
   "                if line.strip().startswith(\"git_date =\"):\n",
   "                    mo = re.search(r'=\\s*\"(.*)\"', line)\n",
   "                    if mo:\n",
   "                        keywords[\"date\"] = mo.group(1)\n",
   "    return keywords\n",
   "def git_versions_from_keywords(keywords, tag_prefix, verbose):\n",
   "    if not keywords:\n",
   "    date = keywords.get(\"date\")\n",
   "    if date is not None:\n",
   "        date = date.strip().replace(\" \", \"T\", 1).replace(\" \", \"\", 1)\n",
   "    refnames = keywords[\"refnames\"].strip()\n",
   "    if refnames.startswith(\"$Format\"):\n",
   "    refs = {r.strip() for r in refnames.strip(\"()\").split(\",\")}\n",
   "    TAG = \"tag: \"\n",
   "    tags = {r[len(TAG):] for r in refs if r.startswith(TAG)}\n",
   "    if not tags:\n",
   "        tags = {r for r in refs if re.search(r\"\\d\", r)}\n",
   "            print(\"discarding '%s', no digits\" % \",\".join(refs - tags))\n",
   "        print(\"likely tags: %s\" % \",\".join(sorted(tags)))\n",
   "    for ref in sorted(tags):\n",
   "        if ref.startswith(tag_prefix):\n",
   "            r = ref[len(tag_prefix):]\n",
   "                print(\"picking %s\" % r)\n",
   "            return {\"version\": r,\n",
   "                    \"full-revisionid\": keywords[\"full\"].strip(),\n",
   "                    \"date\": date}\n",
   "            \"full-revisionid\": keywords[\"full\"].strip(),\n",
   "def git_pieces_from_vcs(tag_prefix, root, verbose, run_command=run_command):\n",
   "    GITS = [\"git\"]\n",
   "        GITS = [\"git.cmd\", \"git.exe\"]\n",
   "    out, rc = run_command(GITS, [\"rev-parse\", \"--git-dir\"], cwd=root,\n",
   "    if rc != 0:\n",
   "            print(\"Directory %s not under git control\" % root)\n",
   "    describe_out, rc = run_command(GITS, [\"describe\", \"--tags\", \"--dirty\",\n",
   "                                   cwd=root)\n",
   "    if describe_out is None:\n",
   "    describe_out = describe_out.strip()\n",
   "    full_out, rc = run_command(GITS, [\"rev-parse\", \"HEAD\"], cwd=root)\n",
   "    if full_out is None:\n",
   "    full_out = full_out.strip()\n",
   "    pieces = {}\n",
   "    pieces[\"long\"] = full_out\n",
   "    pieces[\"short\"] = full_out[:7]  # maybe improved later\n",
   "    pieces[\"error\"] = None\n",
   "    git_describe = describe_out\n",
   "    dirty = git_describe.endswith(\"-dirty\")\n",
   "    pieces[\"dirty\"] = dirty\n",
   "    if dirty:\n",
   "        git_describe = git_describe[:git_describe.rindex(\"-dirty\")]\n",
   "    if \"-\" in git_describe:\n",
   "        mo = re.search(r'^(.+)-(\\d+)-g([0-9a-f]+)$', git_describe)\n",
   "        if not mo:\n",
   "            pieces[\"error\"] = (\"unable to parse git-describe output: '%s'\"\n",
   "                               % describe_out)\n",
   "            return pieces\n",
   "        full_tag = mo.group(1)\n",
   "        if not full_tag.startswith(tag_prefix):\n",
   "                fmt = \"tag '%s' doesn't start with prefix '%s'\"\n",
   "                print(fmt % (full_tag, tag_prefix))\n",
   "            pieces[\"error\"] = (\"tag '%s' doesn't start with prefix '%s'\"\n",
   "                               % (full_tag, tag_prefix))\n",
   "            return pieces\n",
   "        pieces[\"closest-tag\"] = full_tag[len(tag_prefix):]\n",
   "        pieces[\"distance\"] = int(mo.group(2))\n",
   "        pieces[\"short\"] = mo.group(3)\n",
   "        pieces[\"closest-tag\"] = None\n",
   "        count_out, rc = run_command(GITS, [\"rev-list\", \"HEAD\", \"--count\"],\n",
   "                                    cwd=root)\n",
   "        pieces[\"distance\"] = int(count_out)  # total number of commits\n",
   "    date = run_command(GITS, [\"show\", \"-s\", \"--format=%ci\", \"HEAD\"],\n",
   "                       cwd=root)[0].strip()\n",
   "    pieces[\"date\"] = date.strip().replace(\" \", \"T\", 1).replace(\" \", \"\", 1)\n",
   "    return pieces\n",
   "def plus_or_dot(pieces):\n",
   "    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n",
   "def render_pep440(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"] or pieces[\"dirty\"]:\n",
   "            rendered += plus_or_dot(pieces)\n",
   "            rendered += \"%d.g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n",
   "            if pieces[\"dirty\"]:\n",
   "                rendered += \".dirty\"\n",
   "        rendered = \"0+untagged.%d.g%s\" % (pieces[\"distance\"],\n",
   "                                          pieces[\"short\"])\n",
   "        if pieces[\"dirty\"]:\n",
   "            rendered += \".dirty\"\n",
   "    return rendered\n",
   "def render_pep440_pre(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"]:\n",
   "            rendered += \".post.dev%d\" % pieces[\"distance\"]\n",
   "        rendered = \"0.post.dev%d\" % pieces[\"distance\"]\n",
   "    return rendered\n",
   "def render_pep440_post(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"] or pieces[\"dirty\"]:\n",
   "            rendered += \".post%d\" % pieces[\"distance\"]\n",
   "            if pieces[\"dirty\"]:\n",
   "                rendered += \".dev0\"\n",
   "            rendered += plus_or_dot(pieces)\n",
   "            rendered += \"g%s\" % pieces[\"short\"]\n",
   "        rendered = \"0.post%d\" % pieces[\"distance\"]\n",
   "        if pieces[\"dirty\"]:\n",
   "            rendered += \".dev0\"\n",
   "        rendered += \"+g%s\" % pieces[\"short\"]\n",
   "    return rendered\n",
   "def render_pep440_old(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"] or pieces[\"dirty\"]:\n",
   "            rendered += \".post%d\" % pieces[\"distance\"]\n",
   "            if pieces[\"dirty\"]:\n",
   "                rendered += \".dev0\"\n",
   "        rendered = \"0.post%d\" % pieces[\"distance\"]\n",
   "        if pieces[\"dirty\"]:\n",
   "            rendered += \".dev0\"\n",
   "    return rendered\n",
   "def render_git_describe(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"]:\n",
   "            rendered += \"-%d-g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n",
   "        rendered = pieces[\"short\"]\n",
   "    if pieces[\"dirty\"]:\n",
   "        rendered += \"-dirty\"\n",
   "    return rendered\n",
   "def render_git_describe_long(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        rendered += \"-%d-g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n",
   "        rendered = pieces[\"short\"]\n",
   "    if pieces[\"dirty\"]:\n",
   "        rendered += \"-dirty\"\n",
   "    return rendered\n",
   "    if pieces[\"error\"]:\n",
   "                \"full-revisionid\": pieces.get(\"long\"),\n",
   "                \"error\": pieces[\"error\"],\n",
   "        style = \"pep440\"  # the default\n",
   "    if style == \"pep440\":\n",
   "        rendered = render_pep440(pieces)\n",
   "    elif style == \"pep440-pre\":\n",
   "        rendered = render_pep440_pre(pieces)\n",
   "    elif style == \"pep440-post\":\n",
   "        rendered = render_pep440_post(pieces)\n",
   "    elif style == \"pep440-old\":\n",
   "        rendered = render_pep440_old(pieces)\n",
   "    elif style == \"git-describe\":\n",
   "        rendered = render_git_describe(pieces)\n",
   "    elif style == \"git-describe-long\":\n",
   "        rendered = render_git_describe_long(pieces)\n",
   "        raise ValueError(\"unknown style '%s'\" % style)\n",
   "    return {\"version\": rendered, \"full-revisionid\": pieces[\"long\"],\n",
   "            \"dirty\": pieces[\"dirty\"], \"error\": None,\n",
   "            \"date\": pieces.get(\"date\")}\n",
   "    cfg = get_config()\n",
   "    verbose = cfg.verbose\n",
   "        return git_versions_from_keywords(get_keywords(), cfg.tag_prefix,\n",
   "                                          verbose)\n",
   "        root = os.path.realpath(__file__)\n",
   "        for _ in cfg.versionfile_source.split('/'):\n",
   "            root = os.path.dirname(root)\n",
   "        pieces = git_pieces_from_vcs(cfg.tag_prefix, root, verbose)\n",
   "        return render(pieces, cfg.style)\n",
   "        if cfg.parentdir_prefix:\n",
   "            return versions_from_parentdir(cfg.parentdir_prefix, root, verbose)\n"
  ]
 },
 "68": {
  "name": "TAG",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/_version.py",
  "lineno": "182",
  "column": "4",
  "context": "0\". If we see a \"tag: \" prefix, prefer those.\n    TAG = \"tag: \"\n    tags = {r[len(TAG):] for r in refs if r.starts",
  "context_lines": "        raise NotThisMethod(\"unexpanded keywords, not a git-archive tarball\")\n    refs = {r.strip() for r in refnames.strip(\"()\").split(\",\")}\n    # starting in git-1.8.3, tags are listed as \"tag: foo-1.0\" instead of\n    # just \"foo-1.0\". If we see a \"tag: \" prefix, prefer those.\n    TAG = \"tag: \"\n    tags = {r[len(TAG):] for r in refs if r.startswith(TAG)}\n    if not tags:\n        # Either we're using git < 1.8.3, or there really are no tags. We use\n        # a heuristic: assume all version tags have a digit. The old git %d\n",
  "slicing": [
   "    git_refnames = \" (HEAD -> branch-2.2)\"\n",
   "    git_full = \"fc5e37c2f7a0ca002e3ec4df7bdd65be0adfcac1\"\n",
   "    git_date = \"2020-08-13 16:24:36 -0700\"\n",
   "    keywords = {\"refnames\": git_refnames, \"full\": git_full, \"date\": git_date}\n",
   "    return keywords\n",
   "    cfg = VersioneerConfig()\n",
   "    cfg.VCS = \"git\"\n",
   "    cfg.style = \"git-describe\"\n",
   "    cfg.tag_prefix = \"\"\n",
   "    cfg.parentdir_prefix = \"Bokeh-\"\n",
   "    cfg.versionfile_source = \"bokeh/_version.py\"\n",
   "    cfg.verbose = False\n",
   "    return cfg\n",
   "HANDLERS = {}\n",
   "def register_vcs_handler(vcs, method):  # decorator\n",
   "        if vcs not in HANDLERS:\n",
   "            HANDLERS[vcs] = {}\n",
   "        HANDLERS[vcs][method] = f\n",
   "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False,\n",
   "    p = None\n",
   "    for c in commands:\n",
   "            dispcmd = str([c] + args)\n",
   "            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n",
   "            e = sys.exc_info()[1]\n",
   "            if e.errno == errno.ENOENT:\n",
   "                print(\"unable to run %s\" % dispcmd)\n",
   "                print(e)\n",
   "            print(\"unable to find command, tried %s\" % (commands,))\n",
   "    stdout = p.communicate()[0].strip()\n",
   "        stdout = stdout.decode()\n",
   "    if p.returncode != 0:\n",
   "            print(\"unable to run %s (error)\" % dispcmd)\n",
   "            print(\"stdout was %s\" % stdout)\n",
   "        return None, p.returncode\n",
   "    return stdout, p.returncode\n",
   "    rootdirs = []\n",
   "        dirname = os.path.basename(root)\n",
   "        if dirname.startswith(parentdir_prefix):\n",
   "            return {\"version\": dirname[len(parentdir_prefix):],\n",
   "            rootdirs.append(root)\n",
   "            root = os.path.dirname(root)  # up a level\n",
   "              (str(rootdirs), parentdir_prefix))\n",
   "    keywords = {}\n",
   "        with open(versionfile_abs) as f:\n",
   "            for line in f.readlines():\n",
   "                if line.strip().startswith(\"git_refnames =\"):\n",
   "                    mo = re.search(r'=\\s*\"(.*)\"', line)\n",
   "                    if mo:\n",
   "                        keywords[\"refnames\"] = mo.group(1)\n",
   "                if line.strip().startswith(\"git_full =\"):\n",
   "                    mo = re.search(r'=\\s*\"(.*)\"', line)\n",
   "                    if mo:\n",
   "                        keywords[\"full\"] = mo.group(1)\n",
   "                if line.strip().startswith(\"git_date =\"):\n",
   "                    mo = re.search(r'=\\s*\"(.*)\"', line)\n",
   "                    if mo:\n",
   "                        keywords[\"date\"] = mo.group(1)\n",
   "    return keywords\n",
   "def git_versions_from_keywords(keywords, tag_prefix, verbose):\n",
   "    if not keywords:\n",
   "    date = keywords.get(\"date\")\n",
   "    if date is not None:\n",
   "        date = date.strip().replace(\" \", \"T\", 1).replace(\" \", \"\", 1)\n",
   "    refnames = keywords[\"refnames\"].strip()\n",
   "    if refnames.startswith(\"$Format\"):\n",
   "    refs = {r.strip() for r in refnames.strip(\"()\").split(\",\")}\n",
   "    TAG = \"tag: \"\n",
   "    tags = {r[len(TAG):] for r in refs if r.startswith(TAG)}\n",
   "    if not tags:\n",
   "        tags = {r for r in refs if re.search(r\"\\d\", r)}\n",
   "            print(\"discarding '%s', no digits\" % \",\".join(refs - tags))\n",
   "        print(\"likely tags: %s\" % \",\".join(sorted(tags)))\n",
   "    for ref in sorted(tags):\n",
   "        if ref.startswith(tag_prefix):\n",
   "            r = ref[len(tag_prefix):]\n",
   "                print(\"picking %s\" % r)\n",
   "            return {\"version\": r,\n",
   "                    \"full-revisionid\": keywords[\"full\"].strip(),\n",
   "                    \"date\": date}\n",
   "            \"full-revisionid\": keywords[\"full\"].strip(),\n",
   "def git_pieces_from_vcs(tag_prefix, root, verbose, run_command=run_command):\n",
   "    GITS = [\"git\"]\n",
   "        GITS = [\"git.cmd\", \"git.exe\"]\n",
   "    out, rc = run_command(GITS, [\"rev-parse\", \"--git-dir\"], cwd=root,\n",
   "    if rc != 0:\n",
   "            print(\"Directory %s not under git control\" % root)\n",
   "    describe_out, rc = run_command(GITS, [\"describe\", \"--tags\", \"--dirty\",\n",
   "                                   cwd=root)\n",
   "    if describe_out is None:\n",
   "    describe_out = describe_out.strip()\n",
   "    full_out, rc = run_command(GITS, [\"rev-parse\", \"HEAD\"], cwd=root)\n",
   "    if full_out is None:\n",
   "    full_out = full_out.strip()\n",
   "    pieces = {}\n",
   "    pieces[\"long\"] = full_out\n",
   "    pieces[\"short\"] = full_out[:7]  # maybe improved later\n",
   "    pieces[\"error\"] = None\n",
   "    git_describe = describe_out\n",
   "    dirty = git_describe.endswith(\"-dirty\")\n",
   "    pieces[\"dirty\"] = dirty\n",
   "    if dirty:\n",
   "        git_describe = git_describe[:git_describe.rindex(\"-dirty\")]\n",
   "    if \"-\" in git_describe:\n",
   "        mo = re.search(r'^(.+)-(\\d+)-g([0-9a-f]+)$', git_describe)\n",
   "        if not mo:\n",
   "            pieces[\"error\"] = (\"unable to parse git-describe output: '%s'\"\n",
   "                               % describe_out)\n",
   "            return pieces\n",
   "        full_tag = mo.group(1)\n",
   "        if not full_tag.startswith(tag_prefix):\n",
   "                fmt = \"tag '%s' doesn't start with prefix '%s'\"\n",
   "                print(fmt % (full_tag, tag_prefix))\n",
   "            pieces[\"error\"] = (\"tag '%s' doesn't start with prefix '%s'\"\n",
   "                               % (full_tag, tag_prefix))\n",
   "            return pieces\n",
   "        pieces[\"closest-tag\"] = full_tag[len(tag_prefix):]\n",
   "        pieces[\"distance\"] = int(mo.group(2))\n",
   "        pieces[\"short\"] = mo.group(3)\n",
   "        pieces[\"closest-tag\"] = None\n",
   "        count_out, rc = run_command(GITS, [\"rev-list\", \"HEAD\", \"--count\"],\n",
   "                                    cwd=root)\n",
   "        pieces[\"distance\"] = int(count_out)  # total number of commits\n",
   "    date = run_command(GITS, [\"show\", \"-s\", \"--format=%ci\", \"HEAD\"],\n",
   "                       cwd=root)[0].strip()\n",
   "    pieces[\"date\"] = date.strip().replace(\" \", \"T\", 1).replace(\" \", \"\", 1)\n",
   "    return pieces\n",
   "def plus_or_dot(pieces):\n",
   "    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n",
   "def render_pep440(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"] or pieces[\"dirty\"]:\n",
   "            rendered += plus_or_dot(pieces)\n",
   "            rendered += \"%d.g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n",
   "            if pieces[\"dirty\"]:\n",
   "                rendered += \".dirty\"\n",
   "        rendered = \"0+untagged.%d.g%s\" % (pieces[\"distance\"],\n",
   "                                          pieces[\"short\"])\n",
   "        if pieces[\"dirty\"]:\n",
   "            rendered += \".dirty\"\n",
   "    return rendered\n",
   "def render_pep440_pre(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"]:\n",
   "            rendered += \".post.dev%d\" % pieces[\"distance\"]\n",
   "        rendered = \"0.post.dev%d\" % pieces[\"distance\"]\n",
   "    return rendered\n",
   "def render_pep440_post(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"] or pieces[\"dirty\"]:\n",
   "            rendered += \".post%d\" % pieces[\"distance\"]\n",
   "            if pieces[\"dirty\"]:\n",
   "                rendered += \".dev0\"\n",
   "            rendered += plus_or_dot(pieces)\n",
   "            rendered += \"g%s\" % pieces[\"short\"]\n",
   "        rendered = \"0.post%d\" % pieces[\"distance\"]\n",
   "        if pieces[\"dirty\"]:\n",
   "            rendered += \".dev0\"\n",
   "        rendered += \"+g%s\" % pieces[\"short\"]\n",
   "    return rendered\n",
   "def render_pep440_old(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"] or pieces[\"dirty\"]:\n",
   "            rendered += \".post%d\" % pieces[\"distance\"]\n",
   "            if pieces[\"dirty\"]:\n",
   "                rendered += \".dev0\"\n",
   "        rendered = \"0.post%d\" % pieces[\"distance\"]\n",
   "        if pieces[\"dirty\"]:\n",
   "            rendered += \".dev0\"\n",
   "    return rendered\n",
   "def render_git_describe(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"]:\n",
   "            rendered += \"-%d-g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n",
   "        rendered = pieces[\"short\"]\n",
   "    if pieces[\"dirty\"]:\n",
   "        rendered += \"-dirty\"\n",
   "    return rendered\n",
   "def render_git_describe_long(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        rendered += \"-%d-g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n",
   "        rendered = pieces[\"short\"]\n",
   "    if pieces[\"dirty\"]:\n",
   "        rendered += \"-dirty\"\n",
   "    return rendered\n",
   "    if pieces[\"error\"]:\n",
   "                \"full-revisionid\": pieces.get(\"long\"),\n",
   "                \"error\": pieces[\"error\"],\n",
   "        style = \"pep440\"  # the default\n",
   "    if style == \"pep440\":\n",
   "        rendered = render_pep440(pieces)\n",
   "    elif style == \"pep440-pre\":\n",
   "        rendered = render_pep440_pre(pieces)\n",
   "    elif style == \"pep440-post\":\n",
   "        rendered = render_pep440_post(pieces)\n",
   "    elif style == \"pep440-old\":\n",
   "        rendered = render_pep440_old(pieces)\n",
   "    elif style == \"git-describe\":\n",
   "        rendered = render_git_describe(pieces)\n",
   "    elif style == \"git-describe-long\":\n",
   "        rendered = render_git_describe_long(pieces)\n",
   "        raise ValueError(\"unknown style '%s'\" % style)\n",
   "    return {\"version\": rendered, \"full-revisionid\": pieces[\"long\"],\n",
   "            \"dirty\": pieces[\"dirty\"], \"error\": None,\n",
   "            \"date\": pieces.get(\"date\")}\n",
   "    cfg = get_config()\n",
   "    verbose = cfg.verbose\n",
   "        return git_versions_from_keywords(get_keywords(), cfg.tag_prefix,\n",
   "                                          verbose)\n",
   "        root = os.path.realpath(__file__)\n",
   "        for _ in cfg.versionfile_source.split('/'):\n",
   "            root = os.path.dirname(root)\n",
   "        pieces = git_pieces_from_vcs(cfg.tag_prefix, root, verbose)\n",
   "        return render(pieces, cfg.style)\n",
   "        if cfg.parentdir_prefix:\n",
   "            return versions_from_parentdir(cfg.parentdir_prefix, root, verbose)\n"
  ]
 },
 "69": {
  "name": "cfg",
  "type": "VersioneerConfig",
  "class": "customized",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/_version.py",
  "lineno": "483",
  "column": "4",
  "context": "   # case we can only use expanded keywords.\n\n    cfg = get_config()\n    verbose = cfg.verbose\n\n    try:\n        return",
  "context_lines": "    # I am in _version.py, which lives at ROOT/VERSIONFILE_SOURCE. If we have\n    # __file__, we can work backwards from there to the root. Some\n    # py2exe/bbfreeze/non-CPython implementations don't do __file__, in which\n    # case we can only use expanded keywords.\n\n    cfg = get_config()\n    verbose = cfg.verbose\n\n    try:\n        return git_versions_from_keywords(get_keywords(), cfg.tag_prefix,\n                                          verbose)\n",
  "slicing": [
   "    git_refnames = \" (HEAD -> branch-2.2)\"\n",
   "    git_full = \"fc5e37c2f7a0ca002e3ec4df7bdd65be0adfcac1\"\n",
   "    git_date = \"2020-08-13 16:24:36 -0700\"\n",
   "    keywords = {\"refnames\": git_refnames, \"full\": git_full, \"date\": git_date}\n",
   "    return keywords\n",
   "    cfg = VersioneerConfig()\n",
   "    cfg.VCS = \"git\"\n",
   "    cfg.style = \"git-describe\"\n",
   "    cfg.tag_prefix = \"\"\n",
   "    cfg.parentdir_prefix = \"Bokeh-\"\n",
   "    cfg.versionfile_source = \"bokeh/_version.py\"\n",
   "    cfg.verbose = False\n",
   "    return cfg\n",
   "HANDLERS = {}\n",
   "def register_vcs_handler(vcs, method):  # decorator\n",
   "        if vcs not in HANDLERS:\n",
   "            HANDLERS[vcs] = {}\n",
   "        HANDLERS[vcs][method] = f\n",
   "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False,\n",
   "    p = None\n",
   "    for c in commands:\n",
   "            dispcmd = str([c] + args)\n",
   "            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n",
   "            e = sys.exc_info()[1]\n",
   "            if e.errno == errno.ENOENT:\n",
   "                print(\"unable to run %s\" % dispcmd)\n",
   "                print(e)\n",
   "            print(\"unable to find command, tried %s\" % (commands,))\n",
   "    stdout = p.communicate()[0].strip()\n",
   "        stdout = stdout.decode()\n",
   "    if p.returncode != 0:\n",
   "            print(\"unable to run %s (error)\" % dispcmd)\n",
   "            print(\"stdout was %s\" % stdout)\n",
   "        return None, p.returncode\n",
   "    return stdout, p.returncode\n",
   "    rootdirs = []\n",
   "        dirname = os.path.basename(root)\n",
   "        if dirname.startswith(parentdir_prefix):\n",
   "            return {\"version\": dirname[len(parentdir_prefix):],\n",
   "            rootdirs.append(root)\n",
   "            root = os.path.dirname(root)  # up a level\n",
   "              (str(rootdirs), parentdir_prefix))\n",
   "    keywords = {}\n",
   "        with open(versionfile_abs) as f:\n",
   "            for line in f.readlines():\n",
   "                if line.strip().startswith(\"git_refnames =\"):\n",
   "                    mo = re.search(r'=\\s*\"(.*)\"', line)\n",
   "                    if mo:\n",
   "                        keywords[\"refnames\"] = mo.group(1)\n",
   "                if line.strip().startswith(\"git_full =\"):\n",
   "                    mo = re.search(r'=\\s*\"(.*)\"', line)\n",
   "                    if mo:\n",
   "                        keywords[\"full\"] = mo.group(1)\n",
   "                if line.strip().startswith(\"git_date =\"):\n",
   "                    mo = re.search(r'=\\s*\"(.*)\"', line)\n",
   "                    if mo:\n",
   "                        keywords[\"date\"] = mo.group(1)\n",
   "    return keywords\n",
   "def git_versions_from_keywords(keywords, tag_prefix, verbose):\n",
   "    if not keywords:\n",
   "    date = keywords.get(\"date\")\n",
   "    if date is not None:\n",
   "        date = date.strip().replace(\" \", \"T\", 1).replace(\" \", \"\", 1)\n",
   "    refnames = keywords[\"refnames\"].strip()\n",
   "    if refnames.startswith(\"$Format\"):\n",
   "    refs = {r.strip() for r in refnames.strip(\"()\").split(\",\")}\n",
   "    TAG = \"tag: \"\n",
   "    tags = {r[len(TAG):] for r in refs if r.startswith(TAG)}\n",
   "    if not tags:\n",
   "        tags = {r for r in refs if re.search(r\"\\d\", r)}\n",
   "            print(\"discarding '%s', no digits\" % \",\".join(refs - tags))\n",
   "        print(\"likely tags: %s\" % \",\".join(sorted(tags)))\n",
   "    for ref in sorted(tags):\n",
   "        if ref.startswith(tag_prefix):\n",
   "            r = ref[len(tag_prefix):]\n",
   "                print(\"picking %s\" % r)\n",
   "            return {\"version\": r,\n",
   "                    \"full-revisionid\": keywords[\"full\"].strip(),\n",
   "                    \"date\": date}\n",
   "            \"full-revisionid\": keywords[\"full\"].strip(),\n",
   "def git_pieces_from_vcs(tag_prefix, root, verbose, run_command=run_command):\n",
   "    GITS = [\"git\"]\n",
   "        GITS = [\"git.cmd\", \"git.exe\"]\n",
   "    out, rc = run_command(GITS, [\"rev-parse\", \"--git-dir\"], cwd=root,\n",
   "    if rc != 0:\n",
   "            print(\"Directory %s not under git control\" % root)\n",
   "    describe_out, rc = run_command(GITS, [\"describe\", \"--tags\", \"--dirty\",\n",
   "                                   cwd=root)\n",
   "    if describe_out is None:\n",
   "    describe_out = describe_out.strip()\n",
   "    full_out, rc = run_command(GITS, [\"rev-parse\", \"HEAD\"], cwd=root)\n",
   "    if full_out is None:\n",
   "    full_out = full_out.strip()\n",
   "    pieces = {}\n",
   "    pieces[\"long\"] = full_out\n",
   "    pieces[\"short\"] = full_out[:7]  # maybe improved later\n",
   "    pieces[\"error\"] = None\n",
   "    git_describe = describe_out\n",
   "    dirty = git_describe.endswith(\"-dirty\")\n",
   "    pieces[\"dirty\"] = dirty\n",
   "    if dirty:\n",
   "        git_describe = git_describe[:git_describe.rindex(\"-dirty\")]\n",
   "    if \"-\" in git_describe:\n",
   "        mo = re.search(r'^(.+)-(\\d+)-g([0-9a-f]+)$', git_describe)\n",
   "        if not mo:\n",
   "            pieces[\"error\"] = (\"unable to parse git-describe output: '%s'\"\n",
   "                               % describe_out)\n",
   "            return pieces\n",
   "        full_tag = mo.group(1)\n",
   "        if not full_tag.startswith(tag_prefix):\n",
   "                fmt = \"tag '%s' doesn't start with prefix '%s'\"\n",
   "                print(fmt % (full_tag, tag_prefix))\n",
   "            pieces[\"error\"] = (\"tag '%s' doesn't start with prefix '%s'\"\n",
   "                               % (full_tag, tag_prefix))\n",
   "            return pieces\n",
   "        pieces[\"closest-tag\"] = full_tag[len(tag_prefix):]\n",
   "        pieces[\"distance\"] = int(mo.group(2))\n",
   "        pieces[\"short\"] = mo.group(3)\n",
   "        pieces[\"closest-tag\"] = None\n",
   "        count_out, rc = run_command(GITS, [\"rev-list\", \"HEAD\", \"--count\"],\n",
   "                                    cwd=root)\n",
   "        pieces[\"distance\"] = int(count_out)  # total number of commits\n",
   "    date = run_command(GITS, [\"show\", \"-s\", \"--format=%ci\", \"HEAD\"],\n",
   "                       cwd=root)[0].strip()\n",
   "    pieces[\"date\"] = date.strip().replace(\" \", \"T\", 1).replace(\" \", \"\", 1)\n",
   "    return pieces\n",
   "def plus_or_dot(pieces):\n",
   "    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n",
   "def render_pep440(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"] or pieces[\"dirty\"]:\n",
   "            rendered += plus_or_dot(pieces)\n",
   "            rendered += \"%d.g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n",
   "            if pieces[\"dirty\"]:\n",
   "                rendered += \".dirty\"\n",
   "        rendered = \"0+untagged.%d.g%s\" % (pieces[\"distance\"],\n",
   "                                          pieces[\"short\"])\n",
   "        if pieces[\"dirty\"]:\n",
   "            rendered += \".dirty\"\n",
   "    return rendered\n",
   "def render_pep440_pre(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"]:\n",
   "            rendered += \".post.dev%d\" % pieces[\"distance\"]\n",
   "        rendered = \"0.post.dev%d\" % pieces[\"distance\"]\n",
   "    return rendered\n",
   "def render_pep440_post(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"] or pieces[\"dirty\"]:\n",
   "            rendered += \".post%d\" % pieces[\"distance\"]\n",
   "            if pieces[\"dirty\"]:\n",
   "                rendered += \".dev0\"\n",
   "            rendered += plus_or_dot(pieces)\n",
   "            rendered += \"g%s\" % pieces[\"short\"]\n",
   "        rendered = \"0.post%d\" % pieces[\"distance\"]\n",
   "        if pieces[\"dirty\"]:\n",
   "            rendered += \".dev0\"\n",
   "        rendered += \"+g%s\" % pieces[\"short\"]\n",
   "    return rendered\n",
   "def render_pep440_old(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"] or pieces[\"dirty\"]:\n",
   "            rendered += \".post%d\" % pieces[\"distance\"]\n",
   "            if pieces[\"dirty\"]:\n",
   "                rendered += \".dev0\"\n",
   "        rendered = \"0.post%d\" % pieces[\"distance\"]\n",
   "        if pieces[\"dirty\"]:\n",
   "            rendered += \".dev0\"\n",
   "    return rendered\n",
   "def render_git_describe(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"]:\n",
   "            rendered += \"-%d-g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n",
   "        rendered = pieces[\"short\"]\n",
   "    if pieces[\"dirty\"]:\n",
   "        rendered += \"-dirty\"\n",
   "    return rendered\n",
   "def render_git_describe_long(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        rendered += \"-%d-g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n",
   "        rendered = pieces[\"short\"]\n",
   "    if pieces[\"dirty\"]:\n",
   "        rendered += \"-dirty\"\n",
   "    return rendered\n",
   "    if pieces[\"error\"]:\n",
   "                \"full-revisionid\": pieces.get(\"long\"),\n",
   "                \"error\": pieces[\"error\"],\n",
   "        style = \"pep440\"  # the default\n",
   "    if style == \"pep440\":\n",
   "        rendered = render_pep440(pieces)\n",
   "    elif style == \"pep440-pre\":\n",
   "        rendered = render_pep440_pre(pieces)\n",
   "    elif style == \"pep440-post\":\n",
   "        rendered = render_pep440_post(pieces)\n",
   "    elif style == \"pep440-old\":\n",
   "        rendered = render_pep440_old(pieces)\n",
   "    elif style == \"git-describe\":\n",
   "        rendered = render_git_describe(pieces)\n",
   "    elif style == \"git-describe-long\":\n",
   "        rendered = render_git_describe_long(pieces)\n",
   "        raise ValueError(\"unknown style '%s'\" % style)\n",
   "    return {\"version\": rendered, \"full-revisionid\": pieces[\"long\"],\n",
   "            \"dirty\": pieces[\"dirty\"], \"error\": None,\n",
   "            \"date\": pieces.get(\"date\")}\n",
   "    cfg = get_config()\n",
   "    verbose = cfg.verbose\n",
   "        return git_versions_from_keywords(get_keywords(), cfg.tag_prefix,\n",
   "                                          verbose)\n",
   "        root = os.path.realpath(__file__)\n",
   "        for _ in cfg.versionfile_source.split('/'):\n",
   "            root = os.path.dirname(root)\n",
   "        pieces = git_pieces_from_vcs(cfg.tag_prefix, root, verbose)\n",
   "        return render(pieces, cfg.style)\n",
   "        if cfg.parentdir_prefix:\n",
   "            return versions_from_parentdir(cfg.parentdir_prefix, root, verbose)\n"
  ]
 },
 "70": {
  "name": "verbose",
  "type": "bool",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/_version.py",
  "lineno": "484",
  "column": "4",
  "context": "se expanded keywords.\n\n    cfg = get_config()\n    verbose = cfg.verbose\n\n    try:\n        return git_versions_from_keyword",
  "context_lines": "    # __file__, we can work backwards from there to the root. Some\n    # py2exe/bbfreeze/non-CPython implementations don't do __file__, in which\n    # case we can only use expanded keywords.\n\n    cfg = get_config()\n    verbose = cfg.verbose\n\n    try:\n        return git_versions_from_keywords(get_keywords(), cfg.tag_prefix,\n                                          verbose)\n",
  "slicing": [
   "    git_refnames = \" (HEAD -> branch-2.2)\"\n",
   "    git_full = \"fc5e37c2f7a0ca002e3ec4df7bdd65be0adfcac1\"\n",
   "    git_date = \"2020-08-13 16:24:36 -0700\"\n",
   "    keywords = {\"refnames\": git_refnames, \"full\": git_full, \"date\": git_date}\n",
   "    return keywords\n",
   "    cfg = VersioneerConfig()\n",
   "    cfg.VCS = \"git\"\n",
   "    cfg.style = \"git-describe\"\n",
   "    cfg.tag_prefix = \"\"\n",
   "    cfg.parentdir_prefix = \"Bokeh-\"\n",
   "    cfg.versionfile_source = \"bokeh/_version.py\"\n",
   "    cfg.verbose = False\n",
   "    return cfg\n",
   "HANDLERS = {}\n",
   "def register_vcs_handler(vcs, method):  # decorator\n",
   "        if vcs not in HANDLERS:\n",
   "            HANDLERS[vcs] = {}\n",
   "        HANDLERS[vcs][method] = f\n",
   "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False,\n",
   "    p = None\n",
   "    for c in commands:\n",
   "            dispcmd = str([c] + args)\n",
   "            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n",
   "            e = sys.exc_info()[1]\n",
   "            if e.errno == errno.ENOENT:\n",
   "                print(\"unable to run %s\" % dispcmd)\n",
   "                print(e)\n",
   "            print(\"unable to find command, tried %s\" % (commands,))\n",
   "    stdout = p.communicate()[0].strip()\n",
   "        stdout = stdout.decode()\n",
   "    if p.returncode != 0:\n",
   "            print(\"unable to run %s (error)\" % dispcmd)\n",
   "            print(\"stdout was %s\" % stdout)\n",
   "        return None, p.returncode\n",
   "    return stdout, p.returncode\n",
   "    rootdirs = []\n",
   "        dirname = os.path.basename(root)\n",
   "        if dirname.startswith(parentdir_prefix):\n",
   "            return {\"version\": dirname[len(parentdir_prefix):],\n",
   "            rootdirs.append(root)\n",
   "            root = os.path.dirname(root)  # up a level\n",
   "              (str(rootdirs), parentdir_prefix))\n",
   "    keywords = {}\n",
   "        with open(versionfile_abs) as f:\n",
   "            for line in f.readlines():\n",
   "                if line.strip().startswith(\"git_refnames =\"):\n",
   "                    mo = re.search(r'=\\s*\"(.*)\"', line)\n",
   "                    if mo:\n",
   "                        keywords[\"refnames\"] = mo.group(1)\n",
   "                if line.strip().startswith(\"git_full =\"):\n",
   "                    mo = re.search(r'=\\s*\"(.*)\"', line)\n",
   "                    if mo:\n",
   "                        keywords[\"full\"] = mo.group(1)\n",
   "                if line.strip().startswith(\"git_date =\"):\n",
   "                    mo = re.search(r'=\\s*\"(.*)\"', line)\n",
   "                    if mo:\n",
   "                        keywords[\"date\"] = mo.group(1)\n",
   "    return keywords\n",
   "def git_versions_from_keywords(keywords, tag_prefix, verbose):\n",
   "    if not keywords:\n",
   "    date = keywords.get(\"date\")\n",
   "    if date is not None:\n",
   "        date = date.strip().replace(\" \", \"T\", 1).replace(\" \", \"\", 1)\n",
   "    refnames = keywords[\"refnames\"].strip()\n",
   "    if refnames.startswith(\"$Format\"):\n",
   "    refs = {r.strip() for r in refnames.strip(\"()\").split(\",\")}\n",
   "    TAG = \"tag: \"\n",
   "    tags = {r[len(TAG):] for r in refs if r.startswith(TAG)}\n",
   "    if not tags:\n",
   "        tags = {r for r in refs if re.search(r\"\\d\", r)}\n",
   "            print(\"discarding '%s', no digits\" % \",\".join(refs - tags))\n",
   "        print(\"likely tags: %s\" % \",\".join(sorted(tags)))\n",
   "    for ref in sorted(tags):\n",
   "        if ref.startswith(tag_prefix):\n",
   "            r = ref[len(tag_prefix):]\n",
   "                print(\"picking %s\" % r)\n",
   "            return {\"version\": r,\n",
   "                    \"full-revisionid\": keywords[\"full\"].strip(),\n",
   "                    \"date\": date}\n",
   "            \"full-revisionid\": keywords[\"full\"].strip(),\n",
   "def git_pieces_from_vcs(tag_prefix, root, verbose, run_command=run_command):\n",
   "    GITS = [\"git\"]\n",
   "        GITS = [\"git.cmd\", \"git.exe\"]\n",
   "    out, rc = run_command(GITS, [\"rev-parse\", \"--git-dir\"], cwd=root,\n",
   "    if rc != 0:\n",
   "            print(\"Directory %s not under git control\" % root)\n",
   "    describe_out, rc = run_command(GITS, [\"describe\", \"--tags\", \"--dirty\",\n",
   "                                   cwd=root)\n",
   "    if describe_out is None:\n",
   "    describe_out = describe_out.strip()\n",
   "    full_out, rc = run_command(GITS, [\"rev-parse\", \"HEAD\"], cwd=root)\n",
   "    if full_out is None:\n",
   "    full_out = full_out.strip()\n",
   "    pieces = {}\n",
   "    pieces[\"long\"] = full_out\n",
   "    pieces[\"short\"] = full_out[:7]  # maybe improved later\n",
   "    pieces[\"error\"] = None\n",
   "    git_describe = describe_out\n",
   "    dirty = git_describe.endswith(\"-dirty\")\n",
   "    pieces[\"dirty\"] = dirty\n",
   "    if dirty:\n",
   "        git_describe = git_describe[:git_describe.rindex(\"-dirty\")]\n",
   "    if \"-\" in git_describe:\n",
   "        mo = re.search(r'^(.+)-(\\d+)-g([0-9a-f]+)$', git_describe)\n",
   "        if not mo:\n",
   "            pieces[\"error\"] = (\"unable to parse git-describe output: '%s'\"\n",
   "                               % describe_out)\n",
   "            return pieces\n",
   "        full_tag = mo.group(1)\n",
   "        if not full_tag.startswith(tag_prefix):\n",
   "                fmt = \"tag '%s' doesn't start with prefix '%s'\"\n",
   "                print(fmt % (full_tag, tag_prefix))\n",
   "            pieces[\"error\"] = (\"tag '%s' doesn't start with prefix '%s'\"\n",
   "                               % (full_tag, tag_prefix))\n",
   "            return pieces\n",
   "        pieces[\"closest-tag\"] = full_tag[len(tag_prefix):]\n",
   "        pieces[\"distance\"] = int(mo.group(2))\n",
   "        pieces[\"short\"] = mo.group(3)\n",
   "        pieces[\"closest-tag\"] = None\n",
   "        count_out, rc = run_command(GITS, [\"rev-list\", \"HEAD\", \"--count\"],\n",
   "                                    cwd=root)\n",
   "        pieces[\"distance\"] = int(count_out)  # total number of commits\n",
   "    date = run_command(GITS, [\"show\", \"-s\", \"--format=%ci\", \"HEAD\"],\n",
   "                       cwd=root)[0].strip()\n",
   "    pieces[\"date\"] = date.strip().replace(\" \", \"T\", 1).replace(\" \", \"\", 1)\n",
   "    return pieces\n",
   "def plus_or_dot(pieces):\n",
   "    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n",
   "def render_pep440(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"] or pieces[\"dirty\"]:\n",
   "            rendered += plus_or_dot(pieces)\n",
   "            rendered += \"%d.g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n",
   "            if pieces[\"dirty\"]:\n",
   "                rendered += \".dirty\"\n",
   "        rendered = \"0+untagged.%d.g%s\" % (pieces[\"distance\"],\n",
   "                                          pieces[\"short\"])\n",
   "        if pieces[\"dirty\"]:\n",
   "            rendered += \".dirty\"\n",
   "    return rendered\n",
   "def render_pep440_pre(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"]:\n",
   "            rendered += \".post.dev%d\" % pieces[\"distance\"]\n",
   "        rendered = \"0.post.dev%d\" % pieces[\"distance\"]\n",
   "    return rendered\n",
   "def render_pep440_post(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"] or pieces[\"dirty\"]:\n",
   "            rendered += \".post%d\" % pieces[\"distance\"]\n",
   "            if pieces[\"dirty\"]:\n",
   "                rendered += \".dev0\"\n",
   "            rendered += plus_or_dot(pieces)\n",
   "            rendered += \"g%s\" % pieces[\"short\"]\n",
   "        rendered = \"0.post%d\" % pieces[\"distance\"]\n",
   "        if pieces[\"dirty\"]:\n",
   "            rendered += \".dev0\"\n",
   "        rendered += \"+g%s\" % pieces[\"short\"]\n",
   "    return rendered\n",
   "def render_pep440_old(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"] or pieces[\"dirty\"]:\n",
   "            rendered += \".post%d\" % pieces[\"distance\"]\n",
   "            if pieces[\"dirty\"]:\n",
   "                rendered += \".dev0\"\n",
   "        rendered = \"0.post%d\" % pieces[\"distance\"]\n",
   "        if pieces[\"dirty\"]:\n",
   "            rendered += \".dev0\"\n",
   "    return rendered\n",
   "def render_git_describe(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        if pieces[\"distance\"]:\n",
   "            rendered += \"-%d-g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n",
   "        rendered = pieces[\"short\"]\n",
   "    if pieces[\"dirty\"]:\n",
   "        rendered += \"-dirty\"\n",
   "    return rendered\n",
   "def render_git_describe_long(pieces):\n",
   "    if pieces[\"closest-tag\"]:\n",
   "        rendered = pieces[\"closest-tag\"]\n",
   "        rendered += \"-%d-g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n",
   "        rendered = pieces[\"short\"]\n",
   "    if pieces[\"dirty\"]:\n",
   "        rendered += \"-dirty\"\n",
   "    return rendered\n",
   "    if pieces[\"error\"]:\n",
   "                \"full-revisionid\": pieces.get(\"long\"),\n",
   "                \"error\": pieces[\"error\"],\n",
   "        style = \"pep440\"  # the default\n",
   "    if style == \"pep440\":\n",
   "        rendered = render_pep440(pieces)\n",
   "    elif style == \"pep440-pre\":\n",
   "        rendered = render_pep440_pre(pieces)\n",
   "    elif style == \"pep440-post\":\n",
   "        rendered = render_pep440_post(pieces)\n",
   "    elif style == \"pep440-old\":\n",
   "        rendered = render_pep440_old(pieces)\n",
   "    elif style == \"git-describe\":\n",
   "        rendered = render_git_describe(pieces)\n",
   "    elif style == \"git-describe-long\":\n",
   "        rendered = render_git_describe_long(pieces)\n",
   "        raise ValueError(\"unknown style '%s'\" % style)\n",
   "    return {\"version\": rendered, \"full-revisionid\": pieces[\"long\"],\n",
   "            \"dirty\": pieces[\"dirty\"], \"error\": None,\n",
   "            \"date\": pieces.get(\"date\")}\n",
   "    cfg = get_config()\n",
   "    verbose = cfg.verbose\n",
   "        return git_versions_from_keywords(get_keywords(), cfg.tag_prefix,\n",
   "                                          verbose)\n",
   "        root = os.path.realpath(__file__)\n",
   "        for _ in cfg.versionfile_source.split('/'):\n",
   "            root = os.path.dirname(root)\n",
   "        pieces = git_pieces_from_vcs(cfg.tag_prefix, root, verbose)\n",
   "        return render(pieces, cfg.style)\n",
   "        if cfg.parentdir_prefix:\n",
   "            return versions_from_parentdir(cfg.parentdir_prefix, root, verbose)\n"
  ]
 },
 "71": {
  "name": "value",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/settings.py",
  "lineno": "240",
  "column": "4",
  "context": "(_log_levels.values()):\n        return value\n\n    value = value.upper()\n    if value in _log_levels:\n        return _log_l",
  "context_lines": "        ValueError\n\n    '''\n    if value in set(_log_levels.values()):\n        return value\n\n    value = value.upper()\n    if value in _log_levels:\n        return _log_levels[value]\n\n    raise ValueError(\"Cannot convert {} to log level, valid values are: {}\".format(value, \", \".join(_log_levels)))\n\nclass _Unset: pass\n\n",
  "slicing": [
   "    val = value.lower()\n",
   "    if val in [\"yes\", \"1\", \"on\", \"true\", \"True\"]:\n",
   "    if val in [\"no\", \"0\", \"off\", \"false\", \"False\"]:\n",
   "_log_levels = {\n",
   "    if value in set(_log_levels.values()):\n",
   "    value = value.upper()\n",
   "    if value in _log_levels:\n",
   "        return _log_levels[value]\n",
   "    raise ValueError(\"Cannot convert {} to log level, valid values are: {}\".format(value, \", \".join(_log_levels)))\n",
   "        if value is not None:\n",
   "            return self._convert(value)\n",
   "        self.set_value(value)\n",
   "        self._user_value = value  # lgtm [py/mutable-descriptor]\n"
  ]
 },
 "72": {
  "name": "key",
  "type": "NoneType",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/settings.py",
  "lineno": "667",
  "column": "12",
  "context": "t hasattr(self, '_secret_key_bytes'):\n            key = self.secret_key()\n            if key is None:\n                self._",
  "context_lines": "    def secret_key_bytes(self) -> Optional[bytes]:\n        ''' Return the secret_key, converted to bytes and cached.\n\n        '''\n        if not hasattr(self, '_secret_key_bytes'):\n            key = self.secret_key()\n            if key is None:\n                self._secret_key_bytes = None\n            else:\n                self._secret_key_bytes = codecs.encode(key, \"utf-8\")\n",
  "slicing": [
   "def convert_bool(value):\n",
   "    val = value.lower()\n",
   "    if val in [\"yes\", \"1\", \"on\", \"true\", \"True\"]:\n",
   "    if val in [\"no\", \"0\", \"off\", \"false\", \"False\"]:\n",
   "_log_levels = {\n",
   "    if value in set(_log_levels.values()):\n",
   "    value = value.upper()\n",
   "    if value in _log_levels:\n",
   "        return _log_levels[value]\n",
   "    raise ValueError(\"Cannot convert {} to log level, valid values are: {}\".format(value, \", \".join(_log_levels)))\n",
   "        if value is not None:\n",
   "            return self._convert(value)\n",
   "        self.set_value(value)\n",
   "        self._user_value = value  # lgtm [py/mutable-descriptor]\n",
   "_config_user_locations = (\n",
   "        self._config_user = self._try_load_config(_config_user_locations)\n",
   "        for x in self.__class__.__dict__.values():\n",
   "            if isinstance(x, PrioritizedSetting):\n",
   "                x._parent = self\n",
   "        js_files = []\n",
   "        for root, dirnames, files in os.walk(self.bokehjsdir()):\n",
   "            for fname in files:\n",
   "                if fname.endswith(\".css\"):\n",
   "                    js_files.append(join(root, fname))\n",
   "        return js_files\n",
   "        js_files = []\n",
   "        for root, dirnames, files in os.walk(self.bokehjsdir()):\n",
   "            for fname in files:\n",
   "                if fname.endswith(\".js\"):\n",
   "                    js_files.append(join(root, fname))\n",
   "        return js_files\n",
   "            key = self.secret_key()\n",
   "            if key is None:\n",
   "                self._secret_key_bytes = codecs.encode(key, \"utf-8\")\n"
  ]
 },
 "73": {
  "name": "msgtype",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/protocol/messages/server_info_req.py",
  "lineno": "45",
  "column": "4",
  "context": "gment of for this message is empty.\n\n    '''\n\n    msgtype   = 'SERVER-INFO-REQ'\n\n    @classmethod\n    def create(cls, **metadata):",
  "context_lines": "    ''' Define the ``SERVER-INFO-REQ`` message for requesting a Bokeh server\n    provide information about itself.\n\n    The ``content`` fragment of for this message is empty.\n\n    '''\n\n    msgtype   = 'SERVER-INFO-REQ'\n\n    @classmethod\n    def create(cls, **metadata):\n        ''' Create an ``SERVER-INFO-REQ`` message\n\n",
  "slicing": "    msgtype   = 'SERVER-INFO-REQ'\n"
 },
 "74": {
  "name": "msgtype",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/protocol/messages/ack.py",
  "lineno": "45",
  "column": "4",
  "context": "gment of for this message is empty.\n\n    '''\n\n    msgtype  = 'ACK'\n\n    @classmethod\n    def create(cls, **metadata):",
  "context_lines": "    ''' Define the ``ACK`` message for acknowledging successful client\n    connection to a Bokeh server.\n\n    The ``content`` fragment of for this message is empty.\n\n    '''\n\n    msgtype  = 'ACK'\n\n    @classmethod\n    def create(cls, **metadata):\n        ''' Create an ``ACK`` message\n\n",
  "slicing": "    msgtype  = 'ACK'\n"
 },
 "75": {
  "name": "msgtype",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/protocol/messages/pull_doc_reply.py",
  "lineno": "52",
  "column": "4",
  "context": "  'doc' : <Document JSON>\n        }\n\n    '''\n\n    msgtype  = 'PULL-DOC-REPLY'\n\n    def __init__(self, header, metadata, content)",
  "context_lines": "        {\n            'doc' : <Document JSON>\n        }\n\n    '''\n\n    msgtype  = 'PULL-DOC-REPLY'\n\n    def __init__(self, header, metadata, content):\n        super().__init__(header, metadata, content)\n\n    @classmethod\n",
  "slicing": "    msgtype  = 'PULL-DOC-REPLY'\n"
 },
 "76": {
  "name": "msgtype",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/protocol/messages/error.py",
  "lineno": "58",
  "column": "4",
  "context": "eback' : <traceback text>\n        }\n\n    '''\n\n    msgtype  = 'ERROR'\n\n    def __repr__(self):\n        msg = super().__r",
  "context_lines": "            # this is optional\n            'traceback' : <traceback text>\n        }\n\n    '''\n\n    msgtype  = 'ERROR'\n\n    def __repr__(self):\n        msg = super().__repr__()\n        msg += \" --- \"\n",
  "slicing": "    msgtype  = 'ERROR'\n"
 },
 "77": {
  "name": "msgtype",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/protocol/messages/patch_doc.py",
  "lineno": "58",
  "column": "4",
  "context": "ces' : <model references>\n        }\n\n    '''\n\n    msgtype  = 'PATCH-DOC'\n\n    def __init__(self, header, metadata, content)",
  "context_lines": "            'events'     : <protocol document events>\n            'references' : <model references>\n        }\n\n    '''\n\n    msgtype  = 'PATCH-DOC'\n\n    def __init__(self, header, metadata, content):\n        super().__init__(header, metadata, content)\n\n    @classmethod\n",
  "slicing": "    msgtype  = 'PATCH-DOC'\n"
 },
 "78": {
  "name": "msgtype",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/protocol/messages/server_info_reply.py",
  "lineno": "57",
  "column": "4",
  "context": "er version>\n            }\n        }\n\n    '''\n\n    msgtype  = 'SERVER-INFO-REPLY'\n\n    @classmethod\n    def create(cls, request_id, ",
  "context_lines": "                'server' : <bokeh server version>\n            }\n        }\n\n    '''\n\n    msgtype  = 'SERVER-INFO-REPLY'\n\n    @classmethod\n    def create(cls, request_id, **metadata):\n        ''' Create an ``SERVER-INFO-REPLY`` message\n\n",
  "slicing": "    msgtype  = 'SERVER-INFO-REPLY'\n"
 },
 "79": {
  "name": "msgtype",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/protocol/messages/pull_doc_req.py",
  "lineno": "45",
  "column": "4",
  "context": "gment of for this message is empty.\n\n    '''\n\n    msgtype   = 'PULL-DOC-REQ'\n\n    @classmethod\n    def create(cls, **metadata):",
  "context_lines": "    ''' Define the ``PULL-DOC-REQ`` message for requesting a Bokeh server reply\n    with a new Bokeh Document.\n\n    The ``content`` fragment of for this message is empty.\n\n    '''\n\n    msgtype   = 'PULL-DOC-REQ'\n\n    @classmethod\n    def create(cls, **metadata):\n        ''' Create an ``PULL-DOC-REQ`` message\n\n",
  "slicing": "    msgtype   = 'PULL-DOC-REQ'\n"
 },
 "80": {
  "name": "msgtype",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/protocol/messages/push_doc.py",
  "lineno": "52",
  "column": "4",
  "context": "  'doc' : <Document JSON>\n        }\n\n    '''\n\n    msgtype  = 'PUSH-DOC'\n\n    def __init__(self, header, metadata, content)",
  "context_lines": "        {\n            'doc' : <Document JSON>\n        }\n\n    '''\n\n    msgtype  = 'PUSH-DOC'\n\n    def __init__(self, header, metadata, content):\n        super().__init__(header, metadata, content)\n\n    @classmethod\n",
  "slicing": "    msgtype  = 'PUSH-DOC'\n"
 },
 "81": {
  "name": "msgtype",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/protocol/messages/ok.py",
  "lineno": "45",
  "column": "4",
  "context": "gment of for this message is empty.\n\n    '''\n\n    msgtype  = 'OK'\n\n    @classmethod\n    def create(cls, request_id, ",
  "context_lines": "    ''' Define the ``OK`` message for acknowledging successful handling of a\n    previous message.\n\n    The ``content`` fragment of for this message is empty.\n\n    '''\n\n    msgtype  = 'OK'\n\n    @classmethod\n    def create(cls, request_id, **metadata):\n        ''' Create an ``OK`` message\n\n",
  "slicing": "    msgtype  = 'OK'\n"
 },
 "82": {
  "name": "_logger_text",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/application/handlers/notebook.py",
  "lineno": "58",
  "column": "4",
  "context": " for modifying Bokeh\n    Documents.\n\n    '''\n\n    _logger_text = \"%s: call to %s() ignored when running notebooks with the 'bokeh' command.\"\n\n    _origin = \"Notebook\"\n\n    def __init__(self, ",
  "context_lines": "class NotebookHandler(CodeHandler):\n    ''' A Handler that uses code in a Jupyter notebook for modifying Bokeh\n    Documents.\n\n    '''\n\n    _logger_text = \"%s: call to %s() ignored when running notebooks with the 'bokeh' command.\"\n\n    _origin = \"Notebook\"\n\n    def __init__(self, *args, **kwargs):\n        '''\n\n",
  "slicing": "    _logger_text = \"%s: call to %s() ignored when running notebooks with the 'bokeh' command.\"\n"
 },
 "83": {
  "name": "_origin",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/application/handlers/notebook.py",
  "lineno": "60",
  "column": "4",
  "context": "running notebooks with the 'bokeh' command.\"\n\n    _origin = \"Notebook\"\n\n    def __init__(self, *args, **kwargs):\n        ",
  "context_lines": "    ''' A Handler that uses code in a Jupyter notebook for modifying Bokeh\n    Documents.\n\n    '''\n\n    _logger_text = \"%s: call to %s() ignored when running notebooks with the 'bokeh' command.\"\n\n    _origin = \"Notebook\"\n\n    def __init__(self, *args, **kwargs):\n        '''\n\n        Keywords:\n",
  "slicing": "    _origin = \"Notebook\"\n"
 },
 "84": {
  "name": "_logger_text",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/application/handlers/script.py",
  "lineno": "70",
  "column": "4",
  "context": "executing code from Python scripts.\n\n    '''\n\n    _logger_text = \"%s: call to %s() ignored when running scripts with the 'bokeh' command.\"\n\n    _origin = \"Script\"\n\n    def __init__(self, *a",
  "context_lines": "#-----------------------------------------------------------------------------\n\nclass ScriptHandler(CodeHandler):\n    ''' Modify Bokeh documents by executing code from Python scripts.\n\n    '''\n\n    _logger_text = \"%s: call to %s() ignored when running scripts with the 'bokeh' command.\"\n\n    _origin = \"Script\"\n\n    def __init__(self, *args, **kwargs):\n        '''\n\n",
  "slicing": "    _logger_text = \"%s: call to %s() ignored when running scripts with the 'bokeh' command.\"\n"
 },
 "85": {
  "name": "_origin",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/application/handlers/script.py",
  "lineno": "72",
  "column": "4",
  "context": "n running scripts with the 'bokeh' command.\"\n\n    _origin = \"Script\"\n\n    def __init__(self, *args, **kwargs):\n        ",
  "context_lines": "class ScriptHandler(CodeHandler):\n    ''' Modify Bokeh documents by executing code from Python scripts.\n\n    '''\n\n    _logger_text = \"%s: call to %s() ignored when running scripts with the 'bokeh' command.\"\n\n    _origin = \"Script\"\n\n    def __init__(self, *args, **kwargs):\n        '''\n\n        Keywords:\n",
  "slicing": "    _origin = \"Script\"\n"
 },
 "86": {
  "name": "combined",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/themes/theme.py",
  "lineno": "187",
  "column": "16",
  "context": "           if len(combined) == 0:\n                combined = _empty_dict\n            self._by_class_cache[cls.__name__] = c",
  "context_lines": "                    continue\n                self._add_glyph_defaults(base, combined)\n                combined.update(attrs.get(base.__name__, _empty_dict))\n            if len(combined) == 0:\n                combined = _empty_dict\n            self._by_class_cache[cls.__name__] = combined\n        return self._by_class_cache[cls.__name__]\n\n    def apply_to_model(self, model):\n        ''' Apply this theme to a model.\n\n",
  "slicing": [
   "_empty_dict = dict()\n",
   "            with open(filename) as f:\n",
   "                json = yaml.safe_load(f)\n",
   "                if json is None:\n",
   "                    json = {}\n",
   "        if json is None:\n",
   "        self._json = json\n",
   "        for key, value in self._json['attrs'].items():\n",
   "            if not isinstance(value, dict):\n",
   "                raise ValueError(\"theme problem: attrs.%s should be a dictionary of properties, not %r\" % (key, value))\n",
   "        self._line_defaults = self._json.get('line_defaults', _empty_dict)\n",
   "        self._fill_defaults = self._json.get('fill_defaults', _empty_dict)\n",
   "        self._text_defaults = self._json.get('text_defaults', _empty_dict)\n",
   "            attrs = self._json['attrs']\n",
   "            combined = {}\n",
   "            for base in cls.__mro__[-2::-1]:\n",
   "                if not issubclass(base, HasProps):\n",
   "                self._add_glyph_defaults(base, combined)\n",
   "                combined.update(attrs.get(base.__name__, _empty_dict))\n",
   "            if len(combined) == 0:\n",
   "                combined = _empty_dict\n",
   "            self._by_class_cache[cls.__name__] = combined\n",
   "        if len(_empty_dict) > 0:\n"
  ]
 },
 "87": {
  "name": "message_callbacks",
  "type": "NoneType",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/document/document.py",
  "lineno": "671",
  "column": "8",
  "context": "callback: Callable[[Any], None]) -> None:\n        message_callbacks = self._message_callbacks.get(msg_type, None)\n        if message_callbacks is None:\n            ",
  "context_lines": "        self._held_events = []\n\n        for event in events:\n            self._trigger_on_change(event)\n\n    def on_message(self, msg_type: str, callback: Callable[[Any], None]) -> None:\n        message_callbacks = self._message_callbacks.get(msg_type, None)\n        if message_callbacks is None:\n            self._message_callbacks[msg_type] = [callback]\n        elif callback not in message_callbacks:\n            message_callbacks.append(callback)\n\n",
  "slicing": [
   "log = logging.getLogger(__name__)\n",
   "DEFAULT_TITLE = \"Bokeh Application\"\n",
   "        self._title = kwargs.pop('title', DEFAULT_TITLE)\n",
   "    @theme.setter\n",
   "            theme = default_theme\n",
   "        if self._theme is theme:\n",
   "        if isinstance(theme, str):\n",
   "                self._theme = built_in_themes[theme]\n",
   "                    \"{1}\".format(theme, ', '.join(built_in_themes.keys()))\n",
   "        elif isinstance(theme, Theme):\n",
   "            self._theme = theme\n",
   "        for model in self._all_models.values():\n",
   "            self._theme.apply_to_model(model)\n",
   "        cb = NextTickCallback(self, None)\n",
   "        return self._add_session_callback(cb, callback, one_shot=True, originator=self.add_next_tick_callback)\n",
   "        cb = PeriodicCallback(self,\n",
   "        return self._add_session_callback(cb, callback, one_shot=False, originator=self.add_periodic_callback)\n",
   "        if model in self._roots:\n",
   "            self._roots.append(model)\n",
   "        self._trigger_on_change(RootAddedEvent(self, model, setter))\n",
   "        cb = TimeoutCallback(self,\n",
   "        return self._add_session_callback(cb, callback, one_shot=True, originator=self.add_timeout_callback)\n",
   "        event = Event.decode_json(json)\n",
   "        if not isinstance(event, Event):\n",
   "            log.warning('Could not decode event json: %s' % json)\n",
   "            subscribed = self._subscribed_models[event.event_name].copy()\n",
   "            for model in subscribed:\n",
   "                model._trigger_event(event)\n",
   "        for cb in self._event_callbacks.get(event.event_name, []):\n",
   "            cb(event)\n",
   "        references_json = patch['references']\n",
   "        events_json = patch['events']\n",
   "        references = instantiate_references_json(references_json, self._all_models)\n",
   "        for event_json in events_json:\n",
   "            if 'model' in event_json:\n",
   "                model_id = event_json['model']['id']\n",
   "                if model_id in self._all_models:\n",
   "                    references[model_id] = self._all_models[model_id]\n",
   "        initialize_references_json(references_json, references, setter)\n",
   "        for event_json in events_json:\n",
   "            if event_json['kind'] == 'MessageSent':\n",
   "                self._trigger_on_message(event_json[\"msg_type\"], event_json[\"msg_data\"])\n",
   "            elif event_json['kind'] == 'ModelChanged':\n",
   "                patched_id = event_json['model']['id']\n",
   "                if patched_id not in self._all_models:\n",
   "                    if patched_id not in self._all_former_model_ids:\n",
   "                        raise RuntimeError(\"Cannot apply patch to %s which is not in the document\" % (str(patched_id)))\n",
   "                        log.debug(\"Cannot apply patch to %s which is not in the document anymore. This is usually harmless\" % (str(patched_id)))\n",
   "                patched_obj = self._all_models[patched_id]\n",
   "                attr = event_json['attr']\n",
   "                value = event_json['new']\n",
   "                patched_obj.set_from_json(attr, value, models=references, setter=setter)\n",
   "            elif event_json['kind'] == 'ColumnDataChanged':\n",
   "                source_id = event_json['column_source']['id']\n",
   "                if source_id not in self._all_models:\n",
   "                    raise RuntimeError(\"Cannot apply patch to %s which is not in the document\" % (str(source_id)))\n",
   "                source = self._all_models[source_id]\n",
   "                value = event_json['new']\n",
   "                source.set_from_json('data', value, models=references, setter=setter)\n",
   "            elif event_json['kind'] == 'ColumnsStreamed':\n",
   "                source_id = event_json['column_source']['id']\n",
   "                if source_id not in self._all_models:\n",
   "                    raise RuntimeError(\"Cannot stream to %s which is not in the document\" % (str(source_id)))\n",
   "                source = self._all_models[source_id]\n",
   "                data = event_json['data']\n",
   "                rollover = event_json.get('rollover', None)\n",
   "                source._stream(data, rollover, setter)\n",
   "            elif event_json['kind'] == 'ColumnsPatched':\n",
   "                source_id = event_json['column_source']['id']\n",
   "                if source_id not in self._all_models:\n",
   "                    raise RuntimeError(\"Cannot apply patch to %s which is not in the document\" % (str(source_id)))\n",
   "                source = self._all_models[source_id]\n",
   "                patches = event_json['patches']\n",
   "                source.patch(patches, setter)\n",
   "            elif event_json['kind'] == 'RootAdded':\n",
   "                root_id = event_json['model']['id']\n",
   "                root_obj = references[root_id]\n",
   "                self.add_root(root_obj, setter)\n",
   "            elif event_json['kind'] == 'RootRemoved':\n",
   "                root_id = event_json['model']['id']\n",
   "                root_obj = references[root_id]\n",
   "                self.remove_root(root_obj, setter)\n",
   "            elif event_json['kind'] == 'TitleChanged':\n",
   "                self._set_title(event_json['title'], setter)\n",
   "                raise RuntimeError(\"Unknown patch event \" + repr(event_json))\n",
   "        json_parsed = loads(patch)\n",
   "        self.apply_json_patch(json_parsed)\n",
   "                r = next(iter(self._roots))\n",
   "                self.remove_root(r)\n",
   "        for m in self._all_models.values():\n",
   "            m._document = None\n",
   "        log.debug(\"Deleting %s modules for %s\" % (len(self._modules), self))\n",
   "        for module in self._modules:\n",
   "            referrers = get_referrers(module)\n",
   "            referrers = [x for x in referrers if x is not sys.modules]  # lgtm [py/comparison-using-is]\n",
   "            referrers = [x for x in referrers if x is not self._modules]  # lgtm [py/comparison-using-is]\n",
   "            referrers = [x for x in referrers if not isinstance(x, FrameType)]\n",
   "            if len(referrers) != 0:\n",
   "                log.error(\"Module %r has extra unexpected referrers! This could indicate a serious memory leak. Extra referrers: %r\" % (module, referrers))\n",
   "            if module.__name__ in sys.modules:\n",
   "                del sys.modules[module.__name__]\n",
   "        roots_json = json['roots']\n",
   "        root_ids = roots_json['root_ids']\n",
   "        references_json = roots_json['references']\n",
   "        references = instantiate_references_json(references_json, {})\n",
   "        initialize_references_json(references_json, references)\n",
   "        doc = Document()\n",
   "        for r in root_ids:\n",
   "            doc.add_root(references[r])\n",
   "        doc.title = json['title']\n",
   "        return doc\n",
   "        json_parsed = loads(json)\n",
   "        return cls.from_json(json_parsed)\n",
   "        return self._all_models.get(model_id)\n",
   "            log.warning(\"hold already active with '%s', ignoring '%s'\" % (self._hold, policy))\n",
   "        events = list(self._held_events)\n",
   "        for event in events:\n",
   "            self._trigger_on_change(event)\n",
   "        message_callbacks = self._message_callbacks.get(msg_type, None)\n",
   "        if message_callbacks is None:\n",
   "        elif callback not in message_callbacks:\n",
   "            message_callbacks.append(callback)\n",
   "        message_callbacks = self._message_callbacks.get(msg_type, None)\n",
   "        if message_callbacks is not None and callback in message_callbacks:\n",
   "            message_callbacks.remove(callback)\n",
   "        message_callbacks = self._message_callbacks.get(msg_type, None)\n",
   "        if message_callbacks is not None:\n",
   "            for cb in message_callbacks:\n",
   "                cb(msg_data)\n",
   "        if not isinstance(event, str) and issubclass(event, Event):\n",
   "            event = event.event_name\n",
   "        if not issubclass(_CONCRETE_EVENT_CLASSES[event], DocumentEvent):\n",
   "        for callback in callbacks:\n",
   "            _check_callback(callback, ('event',), what='Event callback')\n",
   "        if event not in self._event_callbacks:\n",
   "            self._event_callbacks[event] = [cb for cb in callbacks]\n",
   "            self._event_callbacks[event].extend(callbacks)\n",
   "        for callback in callbacks:\n",
   "            if callback in self._callbacks: continue\n",
   "            _check_callback(callback, ('event',))\n",
   "            self._callbacks[callback] = callback\n",
   "            self._callbacks[receiver] = lambda event: event.dispatch(receiver)\n",
   "        for callback in callbacks:\n",
   "            _check_callback(callback, ('session_context',))\n",
   "            self._session_destroyed_callbacks.add(callback)\n",
   "        for callback in callbacks:\n",
   "            del self._callbacks[callback]\n",
   "        if model not in self._roots:\n",
   "            self._roots.remove(model)\n",
   "        self._trigger_on_change(RootRemovedEvent(self, model, setter))\n",
   "        replacement = self.from_json(json)\n",
   "        replacement._destructively_move(self)\n",
   "        result = list(self.select(selector))\n",
   "        if len(result) > 1:\n",
   "            raise ValueError(\"Found more than one model matching %s: %r\" % (selector, result))\n",
   "        if len(result) == 0:\n",
   "        return result[0]\n",
   "            selector = dict(type=selector)\n",
   "        for obj in self.select(selector):\n",
   "            for key, val in updates.items():\n",
   "                setattr(obj, key, val)\n",
   "        doc_json = self.to_json_string()\n",
   "        return loads(doc_json)\n",
   "        root_ids = []\n",
   "        for r in self._roots:\n",
   "            root_ids.append(r.id)\n",
   "        root_references = self._all_models.values()\n",
   "        json = {\n",
   "                'root_ids' : root_ids,\n",
   "                'references' : references_json(root_references)\n",
   "        return serialize_json(json, indent=indent)\n",
   "        for r in self.roots:\n",
   "            refs = r.references()\n",
   "            check_integrity(refs)\n",
   "            @wraps(callback)\n",
   "                return callback(*args, **kwargs)\n",
   "            actual_callback = remove_then_invoke\n",
   "            actual_callback = callback\n",
   "        callback_obj._callback = self._wrap_with_self_as_curdoc(actual_callback)\n",
   "        self._callback_objs_by_callable[originator][callback].add(callback_obj)\n",
   "        roots = []\n",
   "                r = next(iter(self.roots))\n",
   "                self.remove_root(r)\n",
   "                roots.append(r)\n",
   "        for r in roots:\n",
   "            if r.document is not None:\n",
   "                raise RuntimeError(\"Somehow we didn't detach %r\" % (r))\n",
   "        for r in roots:\n",
   "            dest_doc.add_root(r)\n",
   "        if len(selector) != 1:\n",
   "        if field not in selector:\n",
   "        return isinstance(selector[field], str)\n",
   "        if attr == 'name':\n",
   "                self._all_models_by_name.remove_value(old, model)\n",
   "                self._all_models_by_name.add_value(new, model)\n",
   "            serializable_new = model.lookup(attr).serializable_value(model)\n",
   "            serializable_new = None\n",
   "        event = ModelChangedEvent(self, model, attr, old, new, serializable_new, hint, setter, callback_invoker)\n",
   "        self._trigger_on_change(event)\n",
   "        new_all_models_set = set()\n",
   "        for r in self.roots:\n",
   "            new_all_models_set = new_all_models_set.union(r.references())\n",
   "        old_all_models_set = set(self._all_models.values())\n",
   "        to_detach = old_all_models_set - new_all_models_set\n",
   "        to_attach = new_all_models_set - old_all_models_set\n",
   "        for m in new_all_models_set:\n",
   "            recomputed[m.id] = m\n",
   "            if m.name is not None:\n",
   "                recomputed_by_name.add_value(m.name, m)\n",
   "        for d in to_detach:\n",
   "            self._all_former_model_ids.add(d.id)\n",
   "            d._detach_document()\n",
   "        for a in to_attach:\n",
   "            a._attach_document(self)\n",
   "                        del self._callback_objs_by_callable[originator][cb]\n",
   "            self._held_events.append(event)\n",
   "            _combine_document_events(event, self._held_events)\n",
   "        if event.callback_invoker is not None:\n",
   "            self._with_self_as_curdoc(event.callback_invoker)\n",
   "                cb(event)\n",
   "            return doc._with_self_as_curdoc(invoke)\n",
   "        if event.combine(new_event):\n"
  ]
 },
 "88": {
  "name": "serializable_new",
  "type": "int|str|dict|float",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/document/document.py",
  "lineno": "1056",
  "column": "12",
  "context": "new, model)\n\n        if hint is None:\n            serializable_new = model.lookup(attr).serializable_value(model)\n        else:\n            serializable_new = None\n",
  "context_lines": "                self._all_models_by_name.remove_value(old, model)\n            if new is not None:\n                self._all_models_by_name.add_value(new, model)\n\n        if hint is None:\n            serializable_new = model.lookup(attr).serializable_value(model)\n        else:\n            serializable_new = None\n\n        event = ModelChangedEvent(self, model, attr, old, new, serializable_new, hint, setter, callback_invoker)\n        self._trigger_on_change(event)\n\n",
  "slicing": [
   "log = logging.getLogger(__name__)\n",
   "DEFAULT_TITLE = \"Bokeh Application\"\n",
   "        self._title = kwargs.pop('title', DEFAULT_TITLE)\n",
   "    @theme.setter\n",
   "            theme = default_theme\n",
   "        if self._theme is theme:\n",
   "        if isinstance(theme, str):\n",
   "                self._theme = built_in_themes[theme]\n",
   "                    \"{1}\".format(theme, ', '.join(built_in_themes.keys()))\n",
   "        elif isinstance(theme, Theme):\n",
   "            self._theme = theme\n",
   "        for model in self._all_models.values():\n",
   "            self._theme.apply_to_model(model)\n",
   "        cb = NextTickCallback(self, None)\n",
   "        return self._add_session_callback(cb, callback, one_shot=True, originator=self.add_next_tick_callback)\n",
   "        cb = PeriodicCallback(self,\n",
   "        return self._add_session_callback(cb, callback, one_shot=False, originator=self.add_periodic_callback)\n",
   "        if model in self._roots:\n",
   "            self._roots.append(model)\n",
   "        self._trigger_on_change(RootAddedEvent(self, model, setter))\n",
   "        cb = TimeoutCallback(self,\n",
   "        return self._add_session_callback(cb, callback, one_shot=True, originator=self.add_timeout_callback)\n",
   "        event = Event.decode_json(json)\n",
   "        if not isinstance(event, Event):\n",
   "            log.warning('Could not decode event json: %s' % json)\n",
   "            subscribed = self._subscribed_models[event.event_name].copy()\n",
   "            for model in subscribed:\n",
   "                model._trigger_event(event)\n",
   "        for cb in self._event_callbacks.get(event.event_name, []):\n",
   "            cb(event)\n",
   "        references_json = patch['references']\n",
   "        events_json = patch['events']\n",
   "        references = instantiate_references_json(references_json, self._all_models)\n",
   "        for event_json in events_json:\n",
   "            if 'model' in event_json:\n",
   "                model_id = event_json['model']['id']\n",
   "                if model_id in self._all_models:\n",
   "                    references[model_id] = self._all_models[model_id]\n",
   "        initialize_references_json(references_json, references, setter)\n",
   "        for event_json in events_json:\n",
   "            if event_json['kind'] == 'MessageSent':\n",
   "                self._trigger_on_message(event_json[\"msg_type\"], event_json[\"msg_data\"])\n",
   "            elif event_json['kind'] == 'ModelChanged':\n",
   "                patched_id = event_json['model']['id']\n",
   "                if patched_id not in self._all_models:\n",
   "                    if patched_id not in self._all_former_model_ids:\n",
   "                        raise RuntimeError(\"Cannot apply patch to %s which is not in the document\" % (str(patched_id)))\n",
   "                        log.debug(\"Cannot apply patch to %s which is not in the document anymore. This is usually harmless\" % (str(patched_id)))\n",
   "                patched_obj = self._all_models[patched_id]\n",
   "                attr = event_json['attr']\n",
   "                value = event_json['new']\n",
   "                patched_obj.set_from_json(attr, value, models=references, setter=setter)\n",
   "            elif event_json['kind'] == 'ColumnDataChanged':\n",
   "                source_id = event_json['column_source']['id']\n",
   "                if source_id not in self._all_models:\n",
   "                    raise RuntimeError(\"Cannot apply patch to %s which is not in the document\" % (str(source_id)))\n",
   "                source = self._all_models[source_id]\n",
   "                value = event_json['new']\n",
   "                source.set_from_json('data', value, models=references, setter=setter)\n",
   "            elif event_json['kind'] == 'ColumnsStreamed':\n",
   "                source_id = event_json['column_source']['id']\n",
   "                if source_id not in self._all_models:\n",
   "                    raise RuntimeError(\"Cannot stream to %s which is not in the document\" % (str(source_id)))\n",
   "                source = self._all_models[source_id]\n",
   "                data = event_json['data']\n",
   "                rollover = event_json.get('rollover', None)\n",
   "                source._stream(data, rollover, setter)\n",
   "            elif event_json['kind'] == 'ColumnsPatched':\n",
   "                source_id = event_json['column_source']['id']\n",
   "                if source_id not in self._all_models:\n",
   "                    raise RuntimeError(\"Cannot apply patch to %s which is not in the document\" % (str(source_id)))\n",
   "                source = self._all_models[source_id]\n",
   "                patches = event_json['patches']\n",
   "                source.patch(patches, setter)\n",
   "            elif event_json['kind'] == 'RootAdded':\n",
   "                root_id = event_json['model']['id']\n",
   "                root_obj = references[root_id]\n",
   "                self.add_root(root_obj, setter)\n",
   "            elif event_json['kind'] == 'RootRemoved':\n",
   "                root_id = event_json['model']['id']\n",
   "                root_obj = references[root_id]\n",
   "                self.remove_root(root_obj, setter)\n",
   "            elif event_json['kind'] == 'TitleChanged':\n",
   "                self._set_title(event_json['title'], setter)\n",
   "                raise RuntimeError(\"Unknown patch event \" + repr(event_json))\n",
   "        json_parsed = loads(patch)\n",
   "        self.apply_json_patch(json_parsed)\n",
   "                r = next(iter(self._roots))\n",
   "                self.remove_root(r)\n",
   "        for m in self._all_models.values():\n",
   "            m._document = None\n",
   "        log.debug(\"Deleting %s modules for %s\" % (len(self._modules), self))\n",
   "        for module in self._modules:\n",
   "            referrers = get_referrers(module)\n",
   "            referrers = [x for x in referrers if x is not sys.modules]  # lgtm [py/comparison-using-is]\n",
   "            referrers = [x for x in referrers if x is not self._modules]  # lgtm [py/comparison-using-is]\n",
   "            referrers = [x for x in referrers if not isinstance(x, FrameType)]\n",
   "            if len(referrers) != 0:\n",
   "                log.error(\"Module %r has extra unexpected referrers! This could indicate a serious memory leak. Extra referrers: %r\" % (module, referrers))\n",
   "            if module.__name__ in sys.modules:\n",
   "                del sys.modules[module.__name__]\n",
   "        roots_json = json['roots']\n",
   "        root_ids = roots_json['root_ids']\n",
   "        references_json = roots_json['references']\n",
   "        references = instantiate_references_json(references_json, {})\n",
   "        initialize_references_json(references_json, references)\n",
   "        doc = Document()\n",
   "        for r in root_ids:\n",
   "            doc.add_root(references[r])\n",
   "        doc.title = json['title']\n",
   "        return doc\n",
   "        json_parsed = loads(json)\n",
   "        return cls.from_json(json_parsed)\n",
   "        return self._all_models.get(model_id)\n",
   "            log.warning(\"hold already active with '%s', ignoring '%s'\" % (self._hold, policy))\n",
   "        events = list(self._held_events)\n",
   "        for event in events:\n",
   "            self._trigger_on_change(event)\n",
   "        message_callbacks = self._message_callbacks.get(msg_type, None)\n",
   "        if message_callbacks is None:\n",
   "        elif callback not in message_callbacks:\n",
   "            message_callbacks.append(callback)\n",
   "        message_callbacks = self._message_callbacks.get(msg_type, None)\n",
   "        if message_callbacks is not None and callback in message_callbacks:\n",
   "            message_callbacks.remove(callback)\n",
   "        message_callbacks = self._message_callbacks.get(msg_type, None)\n",
   "        if message_callbacks is not None:\n",
   "            for cb in message_callbacks:\n",
   "                cb(msg_data)\n",
   "        if not isinstance(event, str) and issubclass(event, Event):\n",
   "            event = event.event_name\n",
   "        if not issubclass(_CONCRETE_EVENT_CLASSES[event], DocumentEvent):\n",
   "        for callback in callbacks:\n",
   "            _check_callback(callback, ('event',), what='Event callback')\n",
   "        if event not in self._event_callbacks:\n",
   "            self._event_callbacks[event] = [cb for cb in callbacks]\n",
   "            self._event_callbacks[event].extend(callbacks)\n",
   "        for callback in callbacks:\n",
   "            if callback in self._callbacks: continue\n",
   "            _check_callback(callback, ('event',))\n",
   "            self._callbacks[callback] = callback\n",
   "            self._callbacks[receiver] = lambda event: event.dispatch(receiver)\n",
   "        for callback in callbacks:\n",
   "            _check_callback(callback, ('session_context',))\n",
   "            self._session_destroyed_callbacks.add(callback)\n",
   "        for callback in callbacks:\n",
   "            del self._callbacks[callback]\n",
   "        if model not in self._roots:\n",
   "            self._roots.remove(model)\n",
   "        self._trigger_on_change(RootRemovedEvent(self, model, setter))\n",
   "        replacement = self.from_json(json)\n",
   "        replacement._destructively_move(self)\n",
   "        result = list(self.select(selector))\n",
   "        if len(result) > 1:\n",
   "            raise ValueError(\"Found more than one model matching %s: %r\" % (selector, result))\n",
   "        if len(result) == 0:\n",
   "        return result[0]\n",
   "            selector = dict(type=selector)\n",
   "        for obj in self.select(selector):\n",
   "            for key, val in updates.items():\n",
   "                setattr(obj, key, val)\n",
   "        doc_json = self.to_json_string()\n",
   "        return loads(doc_json)\n",
   "        root_ids = []\n",
   "        for r in self._roots:\n",
   "            root_ids.append(r.id)\n",
   "        root_references = self._all_models.values()\n",
   "        json = {\n",
   "                'root_ids' : root_ids,\n",
   "                'references' : references_json(root_references)\n",
   "        return serialize_json(json, indent=indent)\n",
   "        for r in self.roots:\n",
   "            refs = r.references()\n",
   "            check_integrity(refs)\n",
   "            @wraps(callback)\n",
   "                return callback(*args, **kwargs)\n",
   "            actual_callback = remove_then_invoke\n",
   "            actual_callback = callback\n",
   "        callback_obj._callback = self._wrap_with_self_as_curdoc(actual_callback)\n",
   "        self._callback_objs_by_callable[originator][callback].add(callback_obj)\n",
   "        roots = []\n",
   "                r = next(iter(self.roots))\n",
   "                self.remove_root(r)\n",
   "                roots.append(r)\n",
   "        for r in roots:\n",
   "            if r.document is not None:\n",
   "                raise RuntimeError(\"Somehow we didn't detach %r\" % (r))\n",
   "        for r in roots:\n",
   "            dest_doc.add_root(r)\n",
   "        if len(selector) != 1:\n",
   "        if field not in selector:\n",
   "        return isinstance(selector[field], str)\n",
   "        if attr == 'name':\n",
   "                self._all_models_by_name.remove_value(old, model)\n",
   "                self._all_models_by_name.add_value(new, model)\n",
   "            serializable_new = model.lookup(attr).serializable_value(model)\n",
   "            serializable_new = None\n",
   "        event = ModelChangedEvent(self, model, attr, old, new, serializable_new, hint, setter, callback_invoker)\n",
   "        self._trigger_on_change(event)\n",
   "        new_all_models_set = set()\n",
   "        for r in self.roots:\n",
   "            new_all_models_set = new_all_models_set.union(r.references())\n",
   "        old_all_models_set = set(self._all_models.values())\n",
   "        to_detach = old_all_models_set - new_all_models_set\n",
   "        to_attach = new_all_models_set - old_all_models_set\n",
   "        for m in new_all_models_set:\n",
   "            recomputed[m.id] = m\n",
   "            if m.name is not None:\n",
   "                recomputed_by_name.add_value(m.name, m)\n",
   "        for d in to_detach:\n",
   "            self._all_former_model_ids.add(d.id)\n",
   "            d._detach_document()\n",
   "        for a in to_attach:\n",
   "            a._attach_document(self)\n",
   "                        del self._callback_objs_by_callable[originator][cb]\n",
   "            self._held_events.append(event)\n",
   "            _combine_document_events(event, self._held_events)\n",
   "        if event.callback_invoker is not None:\n",
   "            self._with_self_as_curdoc(event.callback_invoker)\n",
   "                cb(event)\n",
   "            return doc._with_self_as_curdoc(invoke)\n",
   "        if event.combine(new_event):\n"
  ]
 },
 "89": {
  "name": "new_all_models_set",
  "type": "set",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/document/document.py",
  "lineno": "1083",
  "column": "12",
  "context": " = set()\n        for r in self.roots:\n            new_all_models_set = new_all_models_set.union(r.references())\n        old_all_models_set = set(self._all_models.",
  "context_lines": "        '''\n\n        '''\n        new_all_models_set = set()\n        for r in self.roots:\n            new_all_models_set = new_all_models_set.union(r.references())\n        old_all_models_set = set(self._all_models.values())\n        to_detach = old_all_models_set - new_all_models_set\n        to_attach = new_all_models_set - old_all_models_set\n\n        recomputed = {}\n",
  "slicing": [
   "log = logging.getLogger(__name__)\n",
   "DEFAULT_TITLE = \"Bokeh Application\"\n",
   "        self._title = kwargs.pop('title', DEFAULT_TITLE)\n",
   "    @theme.setter\n",
   "            theme = default_theme\n",
   "        if self._theme is theme:\n",
   "        if isinstance(theme, str):\n",
   "                self._theme = built_in_themes[theme]\n",
   "                    \"{1}\".format(theme, ', '.join(built_in_themes.keys()))\n",
   "        elif isinstance(theme, Theme):\n",
   "            self._theme = theme\n",
   "        for model in self._all_models.values():\n",
   "            self._theme.apply_to_model(model)\n",
   "        cb = NextTickCallback(self, None)\n",
   "        return self._add_session_callback(cb, callback, one_shot=True, originator=self.add_next_tick_callback)\n",
   "        cb = PeriodicCallback(self,\n",
   "        return self._add_session_callback(cb, callback, one_shot=False, originator=self.add_periodic_callback)\n",
   "        if model in self._roots:\n",
   "            self._roots.append(model)\n",
   "        self._trigger_on_change(RootAddedEvent(self, model, setter))\n",
   "        cb = TimeoutCallback(self,\n",
   "        return self._add_session_callback(cb, callback, one_shot=True, originator=self.add_timeout_callback)\n",
   "        event = Event.decode_json(json)\n",
   "        if not isinstance(event, Event):\n",
   "            log.warning('Could not decode event json: %s' % json)\n",
   "            subscribed = self._subscribed_models[event.event_name].copy()\n",
   "            for model in subscribed:\n",
   "                model._trigger_event(event)\n",
   "        for cb in self._event_callbacks.get(event.event_name, []):\n",
   "            cb(event)\n",
   "        references_json = patch['references']\n",
   "        events_json = patch['events']\n",
   "        references = instantiate_references_json(references_json, self._all_models)\n",
   "        for event_json in events_json:\n",
   "            if 'model' in event_json:\n",
   "                model_id = event_json['model']['id']\n",
   "                if model_id in self._all_models:\n",
   "                    references[model_id] = self._all_models[model_id]\n",
   "        initialize_references_json(references_json, references, setter)\n",
   "        for event_json in events_json:\n",
   "            if event_json['kind'] == 'MessageSent':\n",
   "                self._trigger_on_message(event_json[\"msg_type\"], event_json[\"msg_data\"])\n",
   "            elif event_json['kind'] == 'ModelChanged':\n",
   "                patched_id = event_json['model']['id']\n",
   "                if patched_id not in self._all_models:\n",
   "                    if patched_id not in self._all_former_model_ids:\n",
   "                        raise RuntimeError(\"Cannot apply patch to %s which is not in the document\" % (str(patched_id)))\n",
   "                        log.debug(\"Cannot apply patch to %s which is not in the document anymore. This is usually harmless\" % (str(patched_id)))\n",
   "                patched_obj = self._all_models[patched_id]\n",
   "                attr = event_json['attr']\n",
   "                value = event_json['new']\n",
   "                patched_obj.set_from_json(attr, value, models=references, setter=setter)\n",
   "            elif event_json['kind'] == 'ColumnDataChanged':\n",
   "                source_id = event_json['column_source']['id']\n",
   "                if source_id not in self._all_models:\n",
   "                    raise RuntimeError(\"Cannot apply patch to %s which is not in the document\" % (str(source_id)))\n",
   "                source = self._all_models[source_id]\n",
   "                value = event_json['new']\n",
   "                source.set_from_json('data', value, models=references, setter=setter)\n",
   "            elif event_json['kind'] == 'ColumnsStreamed':\n",
   "                source_id = event_json['column_source']['id']\n",
   "                if source_id not in self._all_models:\n",
   "                    raise RuntimeError(\"Cannot stream to %s which is not in the document\" % (str(source_id)))\n",
   "                source = self._all_models[source_id]\n",
   "                data = event_json['data']\n",
   "                rollover = event_json.get('rollover', None)\n",
   "                source._stream(data, rollover, setter)\n",
   "            elif event_json['kind'] == 'ColumnsPatched':\n",
   "                source_id = event_json['column_source']['id']\n",
   "                if source_id not in self._all_models:\n",
   "                    raise RuntimeError(\"Cannot apply patch to %s which is not in the document\" % (str(source_id)))\n",
   "                source = self._all_models[source_id]\n",
   "                patches = event_json['patches']\n",
   "                source.patch(patches, setter)\n",
   "            elif event_json['kind'] == 'RootAdded':\n",
   "                root_id = event_json['model']['id']\n",
   "                root_obj = references[root_id]\n",
   "                self.add_root(root_obj, setter)\n",
   "            elif event_json['kind'] == 'RootRemoved':\n",
   "                root_id = event_json['model']['id']\n",
   "                root_obj = references[root_id]\n",
   "                self.remove_root(root_obj, setter)\n",
   "            elif event_json['kind'] == 'TitleChanged':\n",
   "                self._set_title(event_json['title'], setter)\n",
   "                raise RuntimeError(\"Unknown patch event \" + repr(event_json))\n",
   "        json_parsed = loads(patch)\n",
   "        self.apply_json_patch(json_parsed)\n",
   "                r = next(iter(self._roots))\n",
   "                self.remove_root(r)\n",
   "        for m in self._all_models.values():\n",
   "            m._document = None\n",
   "        log.debug(\"Deleting %s modules for %s\" % (len(self._modules), self))\n",
   "        for module in self._modules:\n",
   "            referrers = get_referrers(module)\n",
   "            referrers = [x for x in referrers if x is not sys.modules]  # lgtm [py/comparison-using-is]\n",
   "            referrers = [x for x in referrers if x is not self._modules]  # lgtm [py/comparison-using-is]\n",
   "            referrers = [x for x in referrers if not isinstance(x, FrameType)]\n",
   "            if len(referrers) != 0:\n",
   "                log.error(\"Module %r has extra unexpected referrers! This could indicate a serious memory leak. Extra referrers: %r\" % (module, referrers))\n",
   "            if module.__name__ in sys.modules:\n",
   "                del sys.modules[module.__name__]\n",
   "        roots_json = json['roots']\n",
   "        root_ids = roots_json['root_ids']\n",
   "        references_json = roots_json['references']\n",
   "        references = instantiate_references_json(references_json, {})\n",
   "        initialize_references_json(references_json, references)\n",
   "        doc = Document()\n",
   "        for r in root_ids:\n",
   "            doc.add_root(references[r])\n",
   "        doc.title = json['title']\n",
   "        return doc\n",
   "        json_parsed = loads(json)\n",
   "        return cls.from_json(json_parsed)\n",
   "        return self._all_models.get(model_id)\n",
   "            log.warning(\"hold already active with '%s', ignoring '%s'\" % (self._hold, policy))\n",
   "        events = list(self._held_events)\n",
   "        for event in events:\n",
   "            self._trigger_on_change(event)\n",
   "        message_callbacks = self._message_callbacks.get(msg_type, None)\n",
   "        if message_callbacks is None:\n",
   "        elif callback not in message_callbacks:\n",
   "            message_callbacks.append(callback)\n",
   "        message_callbacks = self._message_callbacks.get(msg_type, None)\n",
   "        if message_callbacks is not None and callback in message_callbacks:\n",
   "            message_callbacks.remove(callback)\n",
   "        message_callbacks = self._message_callbacks.get(msg_type, None)\n",
   "        if message_callbacks is not None:\n",
   "            for cb in message_callbacks:\n",
   "                cb(msg_data)\n",
   "        if not isinstance(event, str) and issubclass(event, Event):\n",
   "            event = event.event_name\n",
   "        if not issubclass(_CONCRETE_EVENT_CLASSES[event], DocumentEvent):\n",
   "        for callback in callbacks:\n",
   "            _check_callback(callback, ('event',), what='Event callback')\n",
   "        if event not in self._event_callbacks:\n",
   "            self._event_callbacks[event] = [cb for cb in callbacks]\n",
   "            self._event_callbacks[event].extend(callbacks)\n",
   "        for callback in callbacks:\n",
   "            if callback in self._callbacks: continue\n",
   "            _check_callback(callback, ('event',))\n",
   "            self._callbacks[callback] = callback\n",
   "            self._callbacks[receiver] = lambda event: event.dispatch(receiver)\n",
   "        for callback in callbacks:\n",
   "            _check_callback(callback, ('session_context',))\n",
   "            self._session_destroyed_callbacks.add(callback)\n",
   "        for callback in callbacks:\n",
   "            del self._callbacks[callback]\n",
   "        if model not in self._roots:\n",
   "            self._roots.remove(model)\n",
   "        self._trigger_on_change(RootRemovedEvent(self, model, setter))\n",
   "        replacement = self.from_json(json)\n",
   "        replacement._destructively_move(self)\n",
   "        result = list(self.select(selector))\n",
   "        if len(result) > 1:\n",
   "            raise ValueError(\"Found more than one model matching %s: %r\" % (selector, result))\n",
   "        if len(result) == 0:\n",
   "        return result[0]\n",
   "            selector = dict(type=selector)\n",
   "        for obj in self.select(selector):\n",
   "            for key, val in updates.items():\n",
   "                setattr(obj, key, val)\n",
   "        doc_json = self.to_json_string()\n",
   "        return loads(doc_json)\n",
   "        root_ids = []\n",
   "        for r in self._roots:\n",
   "            root_ids.append(r.id)\n",
   "        root_references = self._all_models.values()\n",
   "        json = {\n",
   "                'root_ids' : root_ids,\n",
   "                'references' : references_json(root_references)\n",
   "        return serialize_json(json, indent=indent)\n",
   "        for r in self.roots:\n",
   "            refs = r.references()\n",
   "            check_integrity(refs)\n",
   "            @wraps(callback)\n",
   "                return callback(*args, **kwargs)\n",
   "            actual_callback = remove_then_invoke\n",
   "            actual_callback = callback\n",
   "        callback_obj._callback = self._wrap_with_self_as_curdoc(actual_callback)\n",
   "        self._callback_objs_by_callable[originator][callback].add(callback_obj)\n",
   "        roots = []\n",
   "                r = next(iter(self.roots))\n",
   "                self.remove_root(r)\n",
   "                roots.append(r)\n",
   "        for r in roots:\n",
   "            if r.document is not None:\n",
   "                raise RuntimeError(\"Somehow we didn't detach %r\" % (r))\n",
   "        for r in roots:\n",
   "            dest_doc.add_root(r)\n",
   "        if len(selector) != 1:\n",
   "        if field not in selector:\n",
   "        return isinstance(selector[field], str)\n",
   "        if attr == 'name':\n",
   "                self._all_models_by_name.remove_value(old, model)\n",
   "                self._all_models_by_name.add_value(new, model)\n",
   "            serializable_new = model.lookup(attr).serializable_value(model)\n",
   "            serializable_new = None\n",
   "        event = ModelChangedEvent(self, model, attr, old, new, serializable_new, hint, setter, callback_invoker)\n",
   "        self._trigger_on_change(event)\n",
   "        new_all_models_set = set()\n",
   "        for r in self.roots:\n",
   "            new_all_models_set = new_all_models_set.union(r.references())\n",
   "        old_all_models_set = set(self._all_models.values())\n",
   "        to_detach = old_all_models_set - new_all_models_set\n",
   "        to_attach = new_all_models_set - old_all_models_set\n",
   "        for m in new_all_models_set:\n",
   "            recomputed[m.id] = m\n",
   "            if m.name is not None:\n",
   "                recomputed_by_name.add_value(m.name, m)\n",
   "        for d in to_detach:\n",
   "            self._all_former_model_ids.add(d.id)\n",
   "            d._detach_document()\n",
   "        for a in to_attach:\n",
   "            a._attach_document(self)\n",
   "                        del self._callback_objs_by_callable[originator][cb]\n",
   "            self._held_events.append(event)\n",
   "            _combine_document_events(event, self._held_events)\n",
   "        if event.callback_invoker is not None:\n",
   "            self._with_self_as_curdoc(event.callback_invoker)\n",
   "                cb(event)\n",
   "            return doc._with_self_as_curdoc(invoke)\n",
   "        if event.combine(new_event):\n"
  ]
 },
 "90": {
  "name": "to_detach",
  "type": "set",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/document/document.py",
  "lineno": "1085",
  "column": "8",
  "context": "dels_set = set(self._all_models.values())\n        to_detach = old_all_models_set - new_all_models_set\n        to_attach = new_all_models_set - old_all_m",
  "context_lines": "        new_all_models_set = set()\n        for r in self.roots:\n            new_all_models_set = new_all_models_set.union(r.references())\n        old_all_models_set = set(self._all_models.values())\n        to_detach = old_all_models_set - new_all_models_set\n        to_attach = new_all_models_set - old_all_models_set\n\n        recomputed = {}\n        recomputed_by_name = MultiValuedDict()\n        for m in new_all_models_set:\n",
  "slicing": [
   "log = logging.getLogger(__name__)\n",
   "DEFAULT_TITLE = \"Bokeh Application\"\n",
   "        self._title = kwargs.pop('title', DEFAULT_TITLE)\n",
   "    @theme.setter\n",
   "            theme = default_theme\n",
   "        if self._theme is theme:\n",
   "        if isinstance(theme, str):\n",
   "                self._theme = built_in_themes[theme]\n",
   "                    \"{1}\".format(theme, ', '.join(built_in_themes.keys()))\n",
   "        elif isinstance(theme, Theme):\n",
   "            self._theme = theme\n",
   "        for model in self._all_models.values():\n",
   "            self._theme.apply_to_model(model)\n",
   "        cb = NextTickCallback(self, None)\n",
   "        return self._add_session_callback(cb, callback, one_shot=True, originator=self.add_next_tick_callback)\n",
   "        cb = PeriodicCallback(self,\n",
   "        return self._add_session_callback(cb, callback, one_shot=False, originator=self.add_periodic_callback)\n",
   "        if model in self._roots:\n",
   "            self._roots.append(model)\n",
   "        self._trigger_on_change(RootAddedEvent(self, model, setter))\n",
   "        cb = TimeoutCallback(self,\n",
   "        return self._add_session_callback(cb, callback, one_shot=True, originator=self.add_timeout_callback)\n",
   "        event = Event.decode_json(json)\n",
   "        if not isinstance(event, Event):\n",
   "            log.warning('Could not decode event json: %s' % json)\n",
   "            subscribed = self._subscribed_models[event.event_name].copy()\n",
   "            for model in subscribed:\n",
   "                model._trigger_event(event)\n",
   "        for cb in self._event_callbacks.get(event.event_name, []):\n",
   "            cb(event)\n",
   "        references_json = patch['references']\n",
   "        events_json = patch['events']\n",
   "        references = instantiate_references_json(references_json, self._all_models)\n",
   "        for event_json in events_json:\n",
   "            if 'model' in event_json:\n",
   "                model_id = event_json['model']['id']\n",
   "                if model_id in self._all_models:\n",
   "                    references[model_id] = self._all_models[model_id]\n",
   "        initialize_references_json(references_json, references, setter)\n",
   "        for event_json in events_json:\n",
   "            if event_json['kind'] == 'MessageSent':\n",
   "                self._trigger_on_message(event_json[\"msg_type\"], event_json[\"msg_data\"])\n",
   "            elif event_json['kind'] == 'ModelChanged':\n",
   "                patched_id = event_json['model']['id']\n",
   "                if patched_id not in self._all_models:\n",
   "                    if patched_id not in self._all_former_model_ids:\n",
   "                        raise RuntimeError(\"Cannot apply patch to %s which is not in the document\" % (str(patched_id)))\n",
   "                        log.debug(\"Cannot apply patch to %s which is not in the document anymore. This is usually harmless\" % (str(patched_id)))\n",
   "                patched_obj = self._all_models[patched_id]\n",
   "                attr = event_json['attr']\n",
   "                value = event_json['new']\n",
   "                patched_obj.set_from_json(attr, value, models=references, setter=setter)\n",
   "            elif event_json['kind'] == 'ColumnDataChanged':\n",
   "                source_id = event_json['column_source']['id']\n",
   "                if source_id not in self._all_models:\n",
   "                    raise RuntimeError(\"Cannot apply patch to %s which is not in the document\" % (str(source_id)))\n",
   "                source = self._all_models[source_id]\n",
   "                value = event_json['new']\n",
   "                source.set_from_json('data', value, models=references, setter=setter)\n",
   "            elif event_json['kind'] == 'ColumnsStreamed':\n",
   "                source_id = event_json['column_source']['id']\n",
   "                if source_id not in self._all_models:\n",
   "                    raise RuntimeError(\"Cannot stream to %s which is not in the document\" % (str(source_id)))\n",
   "                source = self._all_models[source_id]\n",
   "                data = event_json['data']\n",
   "                rollover = event_json.get('rollover', None)\n",
   "                source._stream(data, rollover, setter)\n",
   "            elif event_json['kind'] == 'ColumnsPatched':\n",
   "                source_id = event_json['column_source']['id']\n",
   "                if source_id not in self._all_models:\n",
   "                    raise RuntimeError(\"Cannot apply patch to %s which is not in the document\" % (str(source_id)))\n",
   "                source = self._all_models[source_id]\n",
   "                patches = event_json['patches']\n",
   "                source.patch(patches, setter)\n",
   "            elif event_json['kind'] == 'RootAdded':\n",
   "                root_id = event_json['model']['id']\n",
   "                root_obj = references[root_id]\n",
   "                self.add_root(root_obj, setter)\n",
   "            elif event_json['kind'] == 'RootRemoved':\n",
   "                root_id = event_json['model']['id']\n",
   "                root_obj = references[root_id]\n",
   "                self.remove_root(root_obj, setter)\n",
   "            elif event_json['kind'] == 'TitleChanged':\n",
   "                self._set_title(event_json['title'], setter)\n",
   "                raise RuntimeError(\"Unknown patch event \" + repr(event_json))\n",
   "        json_parsed = loads(patch)\n",
   "        self.apply_json_patch(json_parsed)\n",
   "                r = next(iter(self._roots))\n",
   "                self.remove_root(r)\n",
   "        for m in self._all_models.values():\n",
   "            m._document = None\n",
   "        log.debug(\"Deleting %s modules for %s\" % (len(self._modules), self))\n",
   "        for module in self._modules:\n",
   "            referrers = get_referrers(module)\n",
   "            referrers = [x for x in referrers if x is not sys.modules]  # lgtm [py/comparison-using-is]\n",
   "            referrers = [x for x in referrers if x is not self._modules]  # lgtm [py/comparison-using-is]\n",
   "            referrers = [x for x in referrers if not isinstance(x, FrameType)]\n",
   "            if len(referrers) != 0:\n",
   "                log.error(\"Module %r has extra unexpected referrers! This could indicate a serious memory leak. Extra referrers: %r\" % (module, referrers))\n",
   "            if module.__name__ in sys.modules:\n",
   "                del sys.modules[module.__name__]\n",
   "        roots_json = json['roots']\n",
   "        root_ids = roots_json['root_ids']\n",
   "        references_json = roots_json['references']\n",
   "        references = instantiate_references_json(references_json, {})\n",
   "        initialize_references_json(references_json, references)\n",
   "        doc = Document()\n",
   "        for r in root_ids:\n",
   "            doc.add_root(references[r])\n",
   "        doc.title = json['title']\n",
   "        return doc\n",
   "        json_parsed = loads(json)\n",
   "        return cls.from_json(json_parsed)\n",
   "        return self._all_models.get(model_id)\n",
   "            log.warning(\"hold already active with '%s', ignoring '%s'\" % (self._hold, policy))\n",
   "        events = list(self._held_events)\n",
   "        for event in events:\n",
   "            self._trigger_on_change(event)\n",
   "        message_callbacks = self._message_callbacks.get(msg_type, None)\n",
   "        if message_callbacks is None:\n",
   "        elif callback not in message_callbacks:\n",
   "            message_callbacks.append(callback)\n",
   "        message_callbacks = self._message_callbacks.get(msg_type, None)\n",
   "        if message_callbacks is not None and callback in message_callbacks:\n",
   "            message_callbacks.remove(callback)\n",
   "        message_callbacks = self._message_callbacks.get(msg_type, None)\n",
   "        if message_callbacks is not None:\n",
   "            for cb in message_callbacks:\n",
   "                cb(msg_data)\n",
   "        if not isinstance(event, str) and issubclass(event, Event):\n",
   "            event = event.event_name\n",
   "        if not issubclass(_CONCRETE_EVENT_CLASSES[event], DocumentEvent):\n",
   "        for callback in callbacks:\n",
   "            _check_callback(callback, ('event',), what='Event callback')\n",
   "        if event not in self._event_callbacks:\n",
   "            self._event_callbacks[event] = [cb for cb in callbacks]\n",
   "            self._event_callbacks[event].extend(callbacks)\n",
   "        for callback in callbacks:\n",
   "            if callback in self._callbacks: continue\n",
   "            _check_callback(callback, ('event',))\n",
   "            self._callbacks[callback] = callback\n",
   "            self._callbacks[receiver] = lambda event: event.dispatch(receiver)\n",
   "        for callback in callbacks:\n",
   "            _check_callback(callback, ('session_context',))\n",
   "            self._session_destroyed_callbacks.add(callback)\n",
   "        for callback in callbacks:\n",
   "            del self._callbacks[callback]\n",
   "        if model not in self._roots:\n",
   "            self._roots.remove(model)\n",
   "        self._trigger_on_change(RootRemovedEvent(self, model, setter))\n",
   "        replacement = self.from_json(json)\n",
   "        replacement._destructively_move(self)\n",
   "        result = list(self.select(selector))\n",
   "        if len(result) > 1:\n",
   "            raise ValueError(\"Found more than one model matching %s: %r\" % (selector, result))\n",
   "        if len(result) == 0:\n",
   "        return result[0]\n",
   "            selector = dict(type=selector)\n",
   "        for obj in self.select(selector):\n",
   "            for key, val in updates.items():\n",
   "                setattr(obj, key, val)\n",
   "        doc_json = self.to_json_string()\n",
   "        return loads(doc_json)\n",
   "        root_ids = []\n",
   "        for r in self._roots:\n",
   "            root_ids.append(r.id)\n",
   "        root_references = self._all_models.values()\n",
   "        json = {\n",
   "                'root_ids' : root_ids,\n",
   "                'references' : references_json(root_references)\n",
   "        return serialize_json(json, indent=indent)\n",
   "        for r in self.roots:\n",
   "            refs = r.references()\n",
   "            check_integrity(refs)\n",
   "            @wraps(callback)\n",
   "                return callback(*args, **kwargs)\n",
   "            actual_callback = remove_then_invoke\n",
   "            actual_callback = callback\n",
   "        callback_obj._callback = self._wrap_with_self_as_curdoc(actual_callback)\n",
   "        self._callback_objs_by_callable[originator][callback].add(callback_obj)\n",
   "        roots = []\n",
   "                r = next(iter(self.roots))\n",
   "                self.remove_root(r)\n",
   "                roots.append(r)\n",
   "        for r in roots:\n",
   "            if r.document is not None:\n",
   "                raise RuntimeError(\"Somehow we didn't detach %r\" % (r))\n",
   "        for r in roots:\n",
   "            dest_doc.add_root(r)\n",
   "        if len(selector) != 1:\n",
   "        if field not in selector:\n",
   "        return isinstance(selector[field], str)\n",
   "        if attr == 'name':\n",
   "                self._all_models_by_name.remove_value(old, model)\n",
   "                self._all_models_by_name.add_value(new, model)\n",
   "            serializable_new = model.lookup(attr).serializable_value(model)\n",
   "            serializable_new = None\n",
   "        event = ModelChangedEvent(self, model, attr, old, new, serializable_new, hint, setter, callback_invoker)\n",
   "        self._trigger_on_change(event)\n",
   "        new_all_models_set = set()\n",
   "        for r in self.roots:\n",
   "            new_all_models_set = new_all_models_set.union(r.references())\n",
   "        old_all_models_set = set(self._all_models.values())\n",
   "        to_detach = old_all_models_set - new_all_models_set\n",
   "        to_attach = new_all_models_set - old_all_models_set\n",
   "        for m in new_all_models_set:\n",
   "            recomputed[m.id] = m\n",
   "            if m.name is not None:\n",
   "                recomputed_by_name.add_value(m.name, m)\n",
   "        for d in to_detach:\n",
   "            self._all_former_model_ids.add(d.id)\n",
   "            d._detach_document()\n",
   "        for a in to_attach:\n",
   "            a._attach_document(self)\n",
   "                        del self._callback_objs_by_callable[originator][cb]\n",
   "            self._held_events.append(event)\n",
   "            _combine_document_events(event, self._held_events)\n",
   "        if event.callback_invoker is not None:\n",
   "            self._with_self_as_curdoc(event.callback_invoker)\n",
   "                cb(event)\n",
   "            return doc._with_self_as_curdoc(invoke)\n",
   "        if event.combine(new_event):\n"
  ]
 },
 "91": {
  "name": "to_attach",
  "type": "set",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/document/document.py",
  "lineno": "1086",
  "column": "8",
  "context": "= old_all_models_set - new_all_models_set\n        to_attach = new_all_models_set - old_all_models_set\n\n        recomputed = {}\n        recomputed_by_nam",
  "context_lines": "        for r in self.roots:\n            new_all_models_set = new_all_models_set.union(r.references())\n        old_all_models_set = set(self._all_models.values())\n        to_detach = old_all_models_set - new_all_models_set\n        to_attach = new_all_models_set - old_all_models_set\n\n        recomputed = {}\n        recomputed_by_name = MultiValuedDict()\n        for m in new_all_models_set:\n",
  "slicing": [
   "log = logging.getLogger(__name__)\n",
   "DEFAULT_TITLE = \"Bokeh Application\"\n",
   "        self._title = kwargs.pop('title', DEFAULT_TITLE)\n",
   "    @theme.setter\n",
   "            theme = default_theme\n",
   "        if self._theme is theme:\n",
   "        if isinstance(theme, str):\n",
   "                self._theme = built_in_themes[theme]\n",
   "                    \"{1}\".format(theme, ', '.join(built_in_themes.keys()))\n",
   "        elif isinstance(theme, Theme):\n",
   "            self._theme = theme\n",
   "        for model in self._all_models.values():\n",
   "            self._theme.apply_to_model(model)\n",
   "        cb = NextTickCallback(self, None)\n",
   "        return self._add_session_callback(cb, callback, one_shot=True, originator=self.add_next_tick_callback)\n",
   "        cb = PeriodicCallback(self,\n",
   "        return self._add_session_callback(cb, callback, one_shot=False, originator=self.add_periodic_callback)\n",
   "        if model in self._roots:\n",
   "            self._roots.append(model)\n",
   "        self._trigger_on_change(RootAddedEvent(self, model, setter))\n",
   "        cb = TimeoutCallback(self,\n",
   "        return self._add_session_callback(cb, callback, one_shot=True, originator=self.add_timeout_callback)\n",
   "        event = Event.decode_json(json)\n",
   "        if not isinstance(event, Event):\n",
   "            log.warning('Could not decode event json: %s' % json)\n",
   "            subscribed = self._subscribed_models[event.event_name].copy()\n",
   "            for model in subscribed:\n",
   "                model._trigger_event(event)\n",
   "        for cb in self._event_callbacks.get(event.event_name, []):\n",
   "            cb(event)\n",
   "        references_json = patch['references']\n",
   "        events_json = patch['events']\n",
   "        references = instantiate_references_json(references_json, self._all_models)\n",
   "        for event_json in events_json:\n",
   "            if 'model' in event_json:\n",
   "                model_id = event_json['model']['id']\n",
   "                if model_id in self._all_models:\n",
   "                    references[model_id] = self._all_models[model_id]\n",
   "        initialize_references_json(references_json, references, setter)\n",
   "        for event_json in events_json:\n",
   "            if event_json['kind'] == 'MessageSent':\n",
   "                self._trigger_on_message(event_json[\"msg_type\"], event_json[\"msg_data\"])\n",
   "            elif event_json['kind'] == 'ModelChanged':\n",
   "                patched_id = event_json['model']['id']\n",
   "                if patched_id not in self._all_models:\n",
   "                    if patched_id not in self._all_former_model_ids:\n",
   "                        raise RuntimeError(\"Cannot apply patch to %s which is not in the document\" % (str(patched_id)))\n",
   "                        log.debug(\"Cannot apply patch to %s which is not in the document anymore. This is usually harmless\" % (str(patched_id)))\n",
   "                patched_obj = self._all_models[patched_id]\n",
   "                attr = event_json['attr']\n",
   "                value = event_json['new']\n",
   "                patched_obj.set_from_json(attr, value, models=references, setter=setter)\n",
   "            elif event_json['kind'] == 'ColumnDataChanged':\n",
   "                source_id = event_json['column_source']['id']\n",
   "                if source_id not in self._all_models:\n",
   "                    raise RuntimeError(\"Cannot apply patch to %s which is not in the document\" % (str(source_id)))\n",
   "                source = self._all_models[source_id]\n",
   "                value = event_json['new']\n",
   "                source.set_from_json('data', value, models=references, setter=setter)\n",
   "            elif event_json['kind'] == 'ColumnsStreamed':\n",
   "                source_id = event_json['column_source']['id']\n",
   "                if source_id not in self._all_models:\n",
   "                    raise RuntimeError(\"Cannot stream to %s which is not in the document\" % (str(source_id)))\n",
   "                source = self._all_models[source_id]\n",
   "                data = event_json['data']\n",
   "                rollover = event_json.get('rollover', None)\n",
   "                source._stream(data, rollover, setter)\n",
   "            elif event_json['kind'] == 'ColumnsPatched':\n",
   "                source_id = event_json['column_source']['id']\n",
   "                if source_id not in self._all_models:\n",
   "                    raise RuntimeError(\"Cannot apply patch to %s which is not in the document\" % (str(source_id)))\n",
   "                source = self._all_models[source_id]\n",
   "                patches = event_json['patches']\n",
   "                source.patch(patches, setter)\n",
   "            elif event_json['kind'] == 'RootAdded':\n",
   "                root_id = event_json['model']['id']\n",
   "                root_obj = references[root_id]\n",
   "                self.add_root(root_obj, setter)\n",
   "            elif event_json['kind'] == 'RootRemoved':\n",
   "                root_id = event_json['model']['id']\n",
   "                root_obj = references[root_id]\n",
   "                self.remove_root(root_obj, setter)\n",
   "            elif event_json['kind'] == 'TitleChanged':\n",
   "                self._set_title(event_json['title'], setter)\n",
   "                raise RuntimeError(\"Unknown patch event \" + repr(event_json))\n",
   "        json_parsed = loads(patch)\n",
   "        self.apply_json_patch(json_parsed)\n",
   "                r = next(iter(self._roots))\n",
   "                self.remove_root(r)\n",
   "        for m in self._all_models.values():\n",
   "            m._document = None\n",
   "        log.debug(\"Deleting %s modules for %s\" % (len(self._modules), self))\n",
   "        for module in self._modules:\n",
   "            referrers = get_referrers(module)\n",
   "            referrers = [x for x in referrers if x is not sys.modules]  # lgtm [py/comparison-using-is]\n",
   "            referrers = [x for x in referrers if x is not self._modules]  # lgtm [py/comparison-using-is]\n",
   "            referrers = [x for x in referrers if not isinstance(x, FrameType)]\n",
   "            if len(referrers) != 0:\n",
   "                log.error(\"Module %r has extra unexpected referrers! This could indicate a serious memory leak. Extra referrers: %r\" % (module, referrers))\n",
   "            if module.__name__ in sys.modules:\n",
   "                del sys.modules[module.__name__]\n",
   "        roots_json = json['roots']\n",
   "        root_ids = roots_json['root_ids']\n",
   "        references_json = roots_json['references']\n",
   "        references = instantiate_references_json(references_json, {})\n",
   "        initialize_references_json(references_json, references)\n",
   "        doc = Document()\n",
   "        for r in root_ids:\n",
   "            doc.add_root(references[r])\n",
   "        doc.title = json['title']\n",
   "        return doc\n",
   "        json_parsed = loads(json)\n",
   "        return cls.from_json(json_parsed)\n",
   "        return self._all_models.get(model_id)\n",
   "            log.warning(\"hold already active with '%s', ignoring '%s'\" % (self._hold, policy))\n",
   "        events = list(self._held_events)\n",
   "        for event in events:\n",
   "            self._trigger_on_change(event)\n",
   "        message_callbacks = self._message_callbacks.get(msg_type, None)\n",
   "        if message_callbacks is None:\n",
   "        elif callback not in message_callbacks:\n",
   "            message_callbacks.append(callback)\n",
   "        message_callbacks = self._message_callbacks.get(msg_type, None)\n",
   "        if message_callbacks is not None and callback in message_callbacks:\n",
   "            message_callbacks.remove(callback)\n",
   "        message_callbacks = self._message_callbacks.get(msg_type, None)\n",
   "        if message_callbacks is not None:\n",
   "            for cb in message_callbacks:\n",
   "                cb(msg_data)\n",
   "        if not isinstance(event, str) and issubclass(event, Event):\n",
   "            event = event.event_name\n",
   "        if not issubclass(_CONCRETE_EVENT_CLASSES[event], DocumentEvent):\n",
   "        for callback in callbacks:\n",
   "            _check_callback(callback, ('event',), what='Event callback')\n",
   "        if event not in self._event_callbacks:\n",
   "            self._event_callbacks[event] = [cb for cb in callbacks]\n",
   "            self._event_callbacks[event].extend(callbacks)\n",
   "        for callback in callbacks:\n",
   "            if callback in self._callbacks: continue\n",
   "            _check_callback(callback, ('event',))\n",
   "            self._callbacks[callback] = callback\n",
   "            self._callbacks[receiver] = lambda event: event.dispatch(receiver)\n",
   "        for callback in callbacks:\n",
   "            _check_callback(callback, ('session_context',))\n",
   "            self._session_destroyed_callbacks.add(callback)\n",
   "        for callback in callbacks:\n",
   "            del self._callbacks[callback]\n",
   "        if model not in self._roots:\n",
   "            self._roots.remove(model)\n",
   "        self._trigger_on_change(RootRemovedEvent(self, model, setter))\n",
   "        replacement = self.from_json(json)\n",
   "        replacement._destructively_move(self)\n",
   "        result = list(self.select(selector))\n",
   "        if len(result) > 1:\n",
   "            raise ValueError(\"Found more than one model matching %s: %r\" % (selector, result))\n",
   "        if len(result) == 0:\n",
   "        return result[0]\n",
   "            selector = dict(type=selector)\n",
   "        for obj in self.select(selector):\n",
   "            for key, val in updates.items():\n",
   "                setattr(obj, key, val)\n",
   "        doc_json = self.to_json_string()\n",
   "        return loads(doc_json)\n",
   "        root_ids = []\n",
   "        for r in self._roots:\n",
   "            root_ids.append(r.id)\n",
   "        root_references = self._all_models.values()\n",
   "        json = {\n",
   "                'root_ids' : root_ids,\n",
   "                'references' : references_json(root_references)\n",
   "        return serialize_json(json, indent=indent)\n",
   "        for r in self.roots:\n",
   "            refs = r.references()\n",
   "            check_integrity(refs)\n",
   "            @wraps(callback)\n",
   "                return callback(*args, **kwargs)\n",
   "            actual_callback = remove_then_invoke\n",
   "            actual_callback = callback\n",
   "        callback_obj._callback = self._wrap_with_self_as_curdoc(actual_callback)\n",
   "        self._callback_objs_by_callable[originator][callback].add(callback_obj)\n",
   "        roots = []\n",
   "                r = next(iter(self.roots))\n",
   "                self.remove_root(r)\n",
   "                roots.append(r)\n",
   "        for r in roots:\n",
   "            if r.document is not None:\n",
   "                raise RuntimeError(\"Somehow we didn't detach %r\" % (r))\n",
   "        for r in roots:\n",
   "            dest_doc.add_root(r)\n",
   "        if len(selector) != 1:\n",
   "        if field not in selector:\n",
   "        return isinstance(selector[field], str)\n",
   "        if attr == 'name':\n",
   "                self._all_models_by_name.remove_value(old, model)\n",
   "                self._all_models_by_name.add_value(new, model)\n",
   "            serializable_new = model.lookup(attr).serializable_value(model)\n",
   "            serializable_new = None\n",
   "        event = ModelChangedEvent(self, model, attr, old, new, serializable_new, hint, setter, callback_invoker)\n",
   "        self._trigger_on_change(event)\n",
   "        new_all_models_set = set()\n",
   "        for r in self.roots:\n",
   "            new_all_models_set = new_all_models_set.union(r.references())\n",
   "        old_all_models_set = set(self._all_models.values())\n",
   "        to_detach = old_all_models_set - new_all_models_set\n",
   "        to_attach = new_all_models_set - old_all_models_set\n",
   "        for m in new_all_models_set:\n",
   "            recomputed[m.id] = m\n",
   "            if m.name is not None:\n",
   "                recomputed_by_name.add_value(m.name, m)\n",
   "        for d in to_detach:\n",
   "            self._all_former_model_ids.add(d.id)\n",
   "            d._detach_document()\n",
   "        for a in to_attach:\n",
   "            a._attach_document(self)\n",
   "                        del self._callback_objs_by_callable[originator][cb]\n",
   "            self._held_events.append(event)\n",
   "            _combine_document_events(event, self._held_events)\n",
   "        if event.callback_invoker is not None:\n",
   "            self._with_self_as_curdoc(event.callback_invoker)\n",
   "                cb(event)\n",
   "            return doc._with_self_as_curdoc(invoke)\n",
   "        if event.combine(new_event):\n"
  ]
 },
 "92": {
  "name": "tool_objs",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/plotting/_tools.py",
  "lineno": "128",
  "column": "4",
  "context": "map of supplied string names to tools\n    \"\"\"\n    tool_objs, tool_map = _resolve_tools(tools)\n\n    repeated_tools = [ str(obj) for obj in _colle",
  "context_lines": "            tooltips to use to configure a HoverTool\n\n    Returns:\n        list of Tools objects added to plot, map of supplied string names to tools\n    \"\"\"\n    tool_objs, tool_map = _resolve_tools(tools)\n\n    repeated_tools = [ str(obj) for obj in _collect_repeated_tools(tool_objs) ]\n    if repeated_tools:\n        warnings.warn(\"%s are being repeated\" % \",\".join(repeated_tools))\n\n",
  "slicing": [
   "Auto = Literal[\"auto\"]\n",
   "ActiveDrag = Union[Drag, Auto, str, None]\n",
   "ActiveInspect = Union[List[Inspection], Inspection, Auto, str, None]\n",
   "ActiveScroll = Union[Scroll, Auto, str, None]\n",
   "ActiveTap = Union[Tap, Auto, str, None]\n",
   "        active_drag: ActiveDrag, active_inspect: ActiveInspect, active_scroll: ActiveScroll, active_tap: ActiveTap) -> None:\n",
   "            (isinstance(active_inspect, list) and all(isinstance(t, Tool) for t in active_inspect)):\n",
   "    tool_objs, tool_map = _resolve_tools(tools)\n",
   "    repeated_tools = [ str(obj) for obj in _collect_repeated_tools(tool_objs) ]\n",
   "    if repeated_tools:\n",
   "        warnings.warn(\"%s are being repeated\" % \",\".join(repeated_tools))\n",
   "        for tool_obj in tool_objs:\n",
   "            if isinstance(tool_obj, HoverTool):\n",
   "                tool_obj.tooltips = tooltips\n",
   "            tool_objs.append(HoverTool(tooltips=tooltips)) # type: ignore\n",
   "    return tool_objs, tool_map\n",
   "    tool_objs = []\n",
   "    tool_map = {}\n",
   "        temp_tool_str = \"\"\n",
   "        for tool in tools:\n",
   "            if isinstance(tool, Tool):\n",
   "                tool_objs.append(tool)\n",
   "            elif isinstance(tool, str):\n",
   "                temp_tool_str += tool + ','\n",
   "        tools = temp_tool_str\n",
   "    for tool in re.split(r\"\\s*,\\s*\", tools.strip()):\n",
   "        if tool == \"\":\n",
   "        tool_obj = Tool.from_string(tool)\n",
   "        tool_objs.append(tool_obj)\n",
   "        tool_map[tool] = tool_obj\n",
   "    return tool_objs, tool_map\n",
   "        obj: Tool\n",
   "    key = lambda obj: obj.__class__.__name__\n",
   "    for _, group in itertools.groupby(sorted(tool_objs, key=key), key=key):\n",
   "        rest = [ Item(obj, obj.properties_with_values()) for obj in group ]\n",
   "        while len(rest) > 1:\n",
   "            head, *rest = rest\n",
   "            for item in rest:\n",
   "                if item.properties == head.properties:\n",
   "                    yield item.obj\n"
  ]
 },
 "93": {
  "name": "tool_map",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/plotting/_tools.py",
  "lineno": "128",
  "column": "15",
  "context": "lied string names to tools\n    \"\"\"\n    tool_objs, tool_map = _resolve_tools(tools)\n\n    repeated_tools = [ str(obj) for obj in _colle",
  "context_lines": "            tooltips to use to configure a HoverTool\n\n    Returns:\n        list of Tools objects added to plot, map of supplied string names to tools\n    \"\"\"\n    tool_objs, tool_map = _resolve_tools(tools)\n\n    repeated_tools = [ str(obj) for obj in _collect_repeated_tools(tool_objs) ]\n    if repeated_tools:\n        warnings.warn(\"%s are being repeated\" % \",\".join(repeated_tools))\n\n",
  "slicing": [
   "    tool_objs, tool_map = _resolve_tools(tools)\n",
   "    return tool_objs, tool_map\n",
   "        tool_map[tool] = tool_obj\n",
   "    return tool_objs, tool_map\n"
  ]
 },
 "94": {
  "name": "tool_obj",
  "type": "ResetTool",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/_tools.py",
  "lineno": "168",
  "column": "8",
  "context": "     if tool == \"\":\n            continue\n\n        tool_obj = Tool.from_string(tool)\n        tool_objs.append(tool_obj)\n        tool_ma",
  "context_lines": "    for tool in re.split(r\"\\s*,\\s*\", tools.strip()):\n        # re.split will return empty strings; ignore them.\n        if tool == \"\":\n            continue\n\n        tool_obj = Tool.from_string(tool)\n        tool_objs.append(tool_obj)\n        tool_map[tool] = tool_obj\n\n    return tool_objs, tool_map\n\ndef _collect_repeated_tools(tool_objs: List[Tool]) -> Iterator[Tool]:\n",
  "slicing": [
   "Auto = Literal[\"auto\"]\n",
   "ActiveDrag = Union[Drag, Auto, str, None]\n",
   "ActiveInspect = Union[List[Inspection], Inspection, Auto, str, None]\n",
   "ActiveScroll = Union[Scroll, Auto, str, None]\n",
   "ActiveTap = Union[Tap, Auto, str, None]\n",
   "        active_drag: ActiveDrag, active_inspect: ActiveInspect, active_scroll: ActiveScroll, active_tap: ActiveTap) -> None:\n",
   "            (isinstance(active_inspect, list) and all(isinstance(t, Tool) for t in active_inspect)):\n",
   "    tool_objs, tool_map = _resolve_tools(tools)\n",
   "    repeated_tools = [ str(obj) for obj in _collect_repeated_tools(tool_objs) ]\n",
   "    if repeated_tools:\n",
   "        warnings.warn(\"%s are being repeated\" % \",\".join(repeated_tools))\n",
   "        for tool_obj in tool_objs:\n",
   "            if isinstance(tool_obj, HoverTool):\n",
   "                tool_obj.tooltips = tooltips\n",
   "            tool_objs.append(HoverTool(tooltips=tooltips)) # type: ignore\n",
   "    return tool_objs, tool_map\n",
   "    tool_objs = []\n",
   "    tool_map = {}\n",
   "        temp_tool_str = \"\"\n",
   "        for tool in tools:\n",
   "            if isinstance(tool, Tool):\n",
   "                tool_objs.append(tool)\n",
   "            elif isinstance(tool, str):\n",
   "                temp_tool_str += tool + ','\n",
   "        tools = temp_tool_str\n",
   "    for tool in re.split(r\"\\s*,\\s*\", tools.strip()):\n",
   "        if tool == \"\":\n",
   "        tool_obj = Tool.from_string(tool)\n",
   "        tool_objs.append(tool_obj)\n",
   "        tool_map[tool] = tool_obj\n",
   "    return tool_objs, tool_map\n",
   "        obj: Tool\n",
   "    key = lambda obj: obj.__class__.__name__\n",
   "    for _, group in itertools.groupby(sorted(tool_objs, key=key), key=key):\n",
   "        rest = [ Item(obj, obj.properties_with_values()) for obj in group ]\n",
   "        while len(rest) > 1:\n",
   "            head, *rest = rest\n",
   "            for item in rest:\n",
   "                if item.properties == head.properties:\n",
   "                    yield item.obj\n"
  ]
 },
 "95": {
  "name": "key",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/_tools.py",
  "lineno": "179",
  "column": "4",
  "context": "obj: Tool\n        properties: Dict[str, Any]\n\n    key = lambda obj: obj.__class__.__name__\n\n    for _, group in itertools.groupby(sorted(tool",
  "context_lines": "def _collect_repeated_tools(tool_objs: List[Tool]) -> Iterator[Tool]:\n    class Item(NamedTuple):\n        obj: Tool\n        properties: Dict[str, Any]\n\n    key = lambda obj: obj.__class__.__name__\n\n    for _, group in itertools.groupby(sorted(tool_objs, key=key), key=key):\n        rest = [ Item(obj, obj.properties_with_values()) for obj in group ]\n        while len(rest) > 1:\n",
  "slicing": [
   "Auto = Literal[\"auto\"]\n",
   "ActiveDrag = Union[Drag, Auto, str, None]\n",
   "ActiveInspect = Union[List[Inspection], Inspection, Auto, str, None]\n",
   "ActiveScroll = Union[Scroll, Auto, str, None]\n",
   "ActiveTap = Union[Tap, Auto, str, None]\n",
   "        active_drag: ActiveDrag, active_inspect: ActiveInspect, active_scroll: ActiveScroll, active_tap: ActiveTap) -> None:\n",
   "            (isinstance(active_inspect, list) and all(isinstance(t, Tool) for t in active_inspect)):\n",
   "    tool_objs, tool_map = _resolve_tools(tools)\n",
   "    repeated_tools = [ str(obj) for obj in _collect_repeated_tools(tool_objs) ]\n",
   "    if repeated_tools:\n",
   "        warnings.warn(\"%s are being repeated\" % \",\".join(repeated_tools))\n",
   "        for tool_obj in tool_objs:\n",
   "            if isinstance(tool_obj, HoverTool):\n",
   "                tool_obj.tooltips = tooltips\n",
   "            tool_objs.append(HoverTool(tooltips=tooltips)) # type: ignore\n",
   "    return tool_objs, tool_map\n",
   "    tool_objs = []\n",
   "    tool_map = {}\n",
   "        temp_tool_str = \"\"\n",
   "        for tool in tools:\n",
   "            if isinstance(tool, Tool):\n",
   "                tool_objs.append(tool)\n",
   "            elif isinstance(tool, str):\n",
   "                temp_tool_str += tool + ','\n",
   "        tools = temp_tool_str\n",
   "    for tool in re.split(r\"\\s*,\\s*\", tools.strip()):\n",
   "        if tool == \"\":\n",
   "        tool_obj = Tool.from_string(tool)\n",
   "        tool_objs.append(tool_obj)\n",
   "        tool_map[tool] = tool_obj\n",
   "    return tool_objs, tool_map\n",
   "        obj: Tool\n",
   "    key = lambda obj: obj.__class__.__name__\n",
   "    for _, group in itertools.groupby(sorted(tool_objs, key=key), key=key):\n",
   "        rest = [ Item(obj, obj.properties_with_values()) for obj in group ]\n",
   "        while len(rest) > 1:\n",
   "            head, *rest = rest\n",
   "            for item in rest:\n",
   "                if item.properties == head.properties:\n",
   "                    yield item.obj\n"
  ]
 },
 "96": {
  "name": "is_user_source",
  "type": "bool",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/plotting/_renderer.py",
  "lineno": "79",
  "column": "4",
  "context": "rgs):\n    # convert data source, if necessary\n    is_user_source = _convert_data_source(kwargs)\n\n    # save off legend kwargs before we get going\n",
  "context_lines": "# Dev API\n#-----------------------------------------------------------------------------\n\n\ndef create_renderer(glyphclass, plot, **kwargs):\n    # convert data source, if necessary\n    is_user_source = _convert_data_source(kwargs)\n\n    # save off legend kwargs before we get going\n    legend_kwarg = pop_legend_kwarg(kwargs)\n\n    # need to check if user source is present before pop_renderer_args\n",
  "slicing": [
   "    colors = [\n",
   "        renderers = plot.renderers\n",
   "        renderers = [x for x in renderers if x.__view_model__ == \"GlyphRenderer\"]\n",
   "        num_renderers = len(renderers)\n",
   "        return colors[num_renderers]\n",
   "        return colors[0]\n",
   "    is_user_source = _convert_data_source(kwargs)\n",
   "    incompatible_literal_spec_values += _process_sequence_literals(glyphclass, kwargs, source, is_user_source)\n",
   "    incompatible_literal_spec_values += _process_sequence_literals(glyphclass, glyph_visuals, source, is_user_source)\n",
   "    if incompatible_literal_spec_values:\n",
   "        raise RuntimeError(_GLYPH_SOURCE_MSG % nice_join(incompatible_literal_spec_values, conjuction=\"and\"))\n",
   "    if any(x.startswith('selection_') for x in kwargs):\n",
   "    if any(x.startswith('hover_') for x in kwargs):\n",
   "    if any(x.startswith('muted_') for x in kwargs):\n",
   "    if is_user_source:\n",
   "    return is_user_source\n",
   "        if is_user_source:\n",
   "            incompatible_literal_spec_values.append(var)\n",
   "    return incompatible_literal_spec_values\n"
  ]
 },
 "97": {
  "name": "renderer_kws",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/plotting/_renderer.py",
  "lineno": "85",
  "column": "4",
  "context": "er source is present before pop_renderer_args\n    renderer_kws = _pop_renderer_args(kwargs)\n    source = renderer_kws['data_source']\n\n    # ha",
  "context_lines": "    is_user_source = _convert_data_source(kwargs)\n\n    # save off legend kwargs before we get going\n    legend_kwarg = pop_legend_kwarg(kwargs)\n\n    # need to check if user source is present before pop_renderer_args\n    renderer_kws = _pop_renderer_args(kwargs)\n    source = renderer_kws['data_source']\n\n    # handle the main glyph, need to process literals\n    glyph_visuals = pop_visuals(glyphclass, kwargs)\n    incompatible_literal_spec_values = []\n",
  "slicing": [
   "    colors = [\n",
   "        renderers = plot.renderers\n",
   "        renderers = [x for x in renderers if x.__view_model__ == \"GlyphRenderer\"]\n",
   "        num_renderers = len(renderers)\n",
   "        return colors[num_renderers]\n",
   "        return colors[0]\n",
   "    is_user_source = _convert_data_source(kwargs)\n",
   "    legend_kwarg = pop_legend_kwarg(kwargs)\n",
   "    renderer_kws = _pop_renderer_args(kwargs)\n",
   "    source = renderer_kws['data_source']\n",
   "    glyph_visuals = pop_visuals(glyphclass, kwargs)\n",
   "    incompatible_literal_spec_values = []\n",
   "    incompatible_literal_spec_values += _process_sequence_literals(glyphclass, kwargs, source, is_user_source)\n",
   "    incompatible_literal_spec_values += _process_sequence_literals(glyphclass, glyph_visuals, source, is_user_source)\n",
   "    if incompatible_literal_spec_values:\n",
   "        raise RuntimeError(_GLYPH_SOURCE_MSG % nice_join(incompatible_literal_spec_values, conjuction=\"and\"))\n",
   "    nonselection_visuals = pop_visuals(glyphclass, kwargs, prefix='nonselection_', defaults=glyph_visuals, override_defaults={'alpha':0.1})\n",
   "    if any(x.startswith('selection_') for x in kwargs):\n",
   "        selection_visuals = pop_visuals(glyphclass, kwargs, prefix='selection_', defaults=glyph_visuals)\n",
   "        selection_visuals = None\n",
   "    if any(x.startswith('hover_') for x in kwargs):\n",
   "        hover_visuals = pop_visuals(glyphclass, kwargs, prefix='hover_', defaults=glyph_visuals)\n",
   "        hover_visuals = None\n",
   "    if any(x.startswith('muted_') for x in kwargs):\n",
   "        muted_visuals = pop_visuals(glyphclass, kwargs, prefix='muted_', defaults=glyph_visuals)\n",
   "        muted_visuals = None\n",
   "    glyph_renderer = GlyphRenderer(\n",
   "        glyph=make_glyph(glyphclass, kwargs, glyph_visuals),\n",
   "        nonselection_glyph=make_glyph(glyphclass, kwargs, nonselection_visuals),\n",
   "        selection_glyph=make_glyph(glyphclass, kwargs, selection_visuals),\n",
   "        hover_glyph=make_glyph(glyphclass, kwargs, hover_visuals),\n",
   "        muted_glyph=make_glyph(glyphclass, kwargs, muted_visuals),\n",
   "        **renderer_kws)\n",
   "    plot.renderers.append(glyph_renderer)\n",
   "    if legend_kwarg:\n",
   "        update_legend(plot, legend_kwarg, glyph_renderer)\n",
   "    return glyph_renderer\n",
   "    kws = kws.copy()\n",
   "    kws.update(extra)\n",
   "    return glyphclass(**kws)\n",
   "    def split_feature_trait(ft):\n",
   "        ft = ft.split('_', 1)\n",
   "        return ft if len(ft)==2 else ft+[None]\n",
   "        feature, trait = split_feature_trait(ft)\n",
   "        return feature in ('line', 'fill', 'text', 'global') and trait is not None\n",
   "    defaults = defaults.copy()\n",
   "    defaults.setdefault('text_color', 'black')\n",
   "    trait_defaults = {}\n",
   "    trait_defaults.setdefault('color', get_default_color())\n",
   "    trait_defaults.setdefault('alpha', 1.0)\n",
   "    result, traits = dict(), set()\n",
   "    glyphprops = glyphclass.properties()\n",
   "    for pname in filter(is_visual, glyphprops):\n",
   "        _, trait = split_feature_trait(pname)\n",
   "        if prefix+pname in props:\n",
   "            result[pname] = props.pop(prefix+pname)\n",
   "        elif trait not in glyphprops and prefix+trait in props:\n",
   "            result[pname] = props[prefix+trait]\n",
   "        elif trait in override_defaults:\n",
   "            result[pname] = override_defaults[trait]\n",
   "        elif pname in defaults:\n",
   "            result[pname] = defaults[pname]\n",
   "        elif trait in trait_defaults:\n",
   "            result[pname] = trait_defaults[trait]\n",
   "        if trait not in glyphprops:\n",
   "            traits.add(trait)\n",
   "    for trait in traits:\n",
   "        props.pop(prefix+trait, None)\n",
   "    return result\n",
   "    is_user_source = kwargs.get('source', None) is not None\n",
   "    if is_user_source:\n",
   "        source = kwargs['source']\n",
   "        if not isinstance(source, ColumnarDataSource):\n",
   "                source = ColumnDataSource(source)\n",
   "                    curr_type=str(type(source)),\n",
   "            kwargs['source'] = source\n",
   "    return is_user_source\n",
   "    result['data_source'] = kwargs.pop('source', ColumnDataSource())\n",
   "    return result\n",
   "        if is_user_source:\n",
   "            incompatible_literal_spec_values.append(var)\n",
   "            source.add(val, name=var)\n",
   "    return incompatible_literal_spec_values\n"
  ]
 },
 "98": {
  "name": "glyph_visuals",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/plotting/_renderer.py",
  "lineno": "89",
  "column": "4",
  "context": "ndle the main glyph, need to process literals\n    glyph_visuals = pop_visuals(glyphclass, kwargs)\n    incompatible_literal_spec_values = []\n    inco",
  "context_lines": "    # need to check if user source is present before pop_renderer_args\n    renderer_kws = _pop_renderer_args(kwargs)\n    source = renderer_kws['data_source']\n\n    # handle the main glyph, need to process literals\n    glyph_visuals = pop_visuals(glyphclass, kwargs)\n    incompatible_literal_spec_values = []\n    incompatible_literal_spec_values += _process_sequence_literals(glyphclass, kwargs, source, is_user_source)\n    incompatible_literal_spec_values += _process_sequence_literals(glyphclass, glyph_visuals, source, is_user_source)\n    if incompatible_literal_spec_values:\n",
  "slicing": [
   "    colors = [\n",
   "        renderers = plot.renderers\n",
   "        renderers = [x for x in renderers if x.__view_model__ == \"GlyphRenderer\"]\n",
   "        num_renderers = len(renderers)\n",
   "        return colors[num_renderers]\n",
   "        return colors[0]\n",
   "    is_user_source = _convert_data_source(kwargs)\n",
   "    legend_kwarg = pop_legend_kwarg(kwargs)\n",
   "    renderer_kws = _pop_renderer_args(kwargs)\n",
   "    source = renderer_kws['data_source']\n",
   "    glyph_visuals = pop_visuals(glyphclass, kwargs)\n",
   "    incompatible_literal_spec_values = []\n",
   "    incompatible_literal_spec_values += _process_sequence_literals(glyphclass, kwargs, source, is_user_source)\n",
   "    incompatible_literal_spec_values += _process_sequence_literals(glyphclass, glyph_visuals, source, is_user_source)\n",
   "    if incompatible_literal_spec_values:\n",
   "        raise RuntimeError(_GLYPH_SOURCE_MSG % nice_join(incompatible_literal_spec_values, conjuction=\"and\"))\n",
   "    nonselection_visuals = pop_visuals(glyphclass, kwargs, prefix='nonselection_', defaults=glyph_visuals, override_defaults={'alpha':0.1})\n",
   "    if any(x.startswith('selection_') for x in kwargs):\n",
   "        selection_visuals = pop_visuals(glyphclass, kwargs, prefix='selection_', defaults=glyph_visuals)\n",
   "        selection_visuals = None\n",
   "    if any(x.startswith('hover_') for x in kwargs):\n",
   "        hover_visuals = pop_visuals(glyphclass, kwargs, prefix='hover_', defaults=glyph_visuals)\n",
   "        hover_visuals = None\n",
   "    if any(x.startswith('muted_') for x in kwargs):\n",
   "        muted_visuals = pop_visuals(glyphclass, kwargs, prefix='muted_', defaults=glyph_visuals)\n",
   "        muted_visuals = None\n",
   "    glyph_renderer = GlyphRenderer(\n",
   "        glyph=make_glyph(glyphclass, kwargs, glyph_visuals),\n",
   "        nonselection_glyph=make_glyph(glyphclass, kwargs, nonselection_visuals),\n",
   "        selection_glyph=make_glyph(glyphclass, kwargs, selection_visuals),\n",
   "        hover_glyph=make_glyph(glyphclass, kwargs, hover_visuals),\n",
   "        muted_glyph=make_glyph(glyphclass, kwargs, muted_visuals),\n",
   "        **renderer_kws)\n",
   "    plot.renderers.append(glyph_renderer)\n",
   "    if legend_kwarg:\n",
   "        update_legend(plot, legend_kwarg, glyph_renderer)\n",
   "    return glyph_renderer\n",
   "    kws = kws.copy()\n",
   "    kws.update(extra)\n",
   "    return glyphclass(**kws)\n",
   "    def split_feature_trait(ft):\n",
   "        ft = ft.split('_', 1)\n",
   "        return ft if len(ft)==2 else ft+[None]\n",
   "        feature, trait = split_feature_trait(ft)\n",
   "        return feature in ('line', 'fill', 'text', 'global') and trait is not None\n",
   "    defaults = defaults.copy()\n",
   "    defaults.setdefault('text_color', 'black')\n",
   "    trait_defaults = {}\n",
   "    trait_defaults.setdefault('color', get_default_color())\n",
   "    trait_defaults.setdefault('alpha', 1.0)\n",
   "    result, traits = dict(), set()\n",
   "    glyphprops = glyphclass.properties()\n",
   "    for pname in filter(is_visual, glyphprops):\n",
   "        _, trait = split_feature_trait(pname)\n",
   "        if prefix+pname in props:\n",
   "            result[pname] = props.pop(prefix+pname)\n",
   "        elif trait not in glyphprops and prefix+trait in props:\n",
   "            result[pname] = props[prefix+trait]\n",
   "        elif trait in override_defaults:\n",
   "            result[pname] = override_defaults[trait]\n",
   "        elif pname in defaults:\n",
   "            result[pname] = defaults[pname]\n",
   "        elif trait in trait_defaults:\n",
   "            result[pname] = trait_defaults[trait]\n",
   "        if trait not in glyphprops:\n",
   "            traits.add(trait)\n",
   "    for trait in traits:\n",
   "        props.pop(prefix+trait, None)\n",
   "    return result\n",
   "    is_user_source = kwargs.get('source', None) is not None\n",
   "    if is_user_source:\n",
   "        source = kwargs['source']\n",
   "        if not isinstance(source, ColumnarDataSource):\n",
   "                source = ColumnDataSource(source)\n",
   "                    curr_type=str(type(source)),\n",
   "            kwargs['source'] = source\n",
   "    return is_user_source\n",
   "    result['data_source'] = kwargs.pop('source', ColumnDataSource())\n",
   "    return result\n",
   "        if is_user_source:\n",
   "            incompatible_literal_spec_values.append(var)\n",
   "            source.add(val, name=var)\n",
   "    return incompatible_literal_spec_values\n"
  ]
 },
 "99": {
  "name": "incompatible_literal_spec_values",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/plotting/_renderer.py",
  "lineno": "91",
  "column": "4",
  "context": "gs)\n    incompatible_literal_spec_values = []\n    incompatible_literal_spec_values += _process_sequence_literals(glyphclass, kwargs, source, is_user_source)\n    incompatible_literal_spec_values += _process_s",
  "context_lines": "    source = renderer_kws['data_source']\n\n    # handle the main glyph, need to process literals\n    glyph_visuals = pop_visuals(glyphclass, kwargs)\n    incompatible_literal_spec_values = []\n    incompatible_literal_spec_values += _process_sequence_literals(glyphclass, kwargs, source, is_user_source)\n    incompatible_literal_spec_values += _process_sequence_literals(glyphclass, glyph_visuals, source, is_user_source)\n    if incompatible_literal_spec_values:\n        raise RuntimeError(_GLYPH_SOURCE_MSG % nice_join(incompatible_literal_spec_values, conjuction=\"and\"))\n\n    # handle the nonselection glyph, we always set one\n",
  "slicing": [
   "    incompatible_literal_spec_values += _process_sequence_literals(glyphclass, kwargs, source, is_user_source)\n",
   "    if incompatible_literal_spec_values:\n",
   "        raise RuntimeError(_GLYPH_SOURCE_MSG % nice_join(incompatible_literal_spec_values, conjuction=\"and\"))\n",
   "            incompatible_literal_spec_values.append(var)\n",
   "    return incompatible_literal_spec_values\n"
  ]
 },
 "100": {
  "name": "incompatible_literal_spec_values",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/plotting/_renderer.py",
  "lineno": "92",
  "column": "4",
  "context": "s(glyphclass, kwargs, source, is_user_source)\n    incompatible_literal_spec_values += _process_sequence_literals(glyphclass, glyph_visuals, source, is_user_source)\n    if incompatible_literal_spec_values:\n        r",
  "context_lines": "    # handle the main glyph, need to process literals\n    glyph_visuals = pop_visuals(glyphclass, kwargs)\n    incompatible_literal_spec_values = []\n    incompatible_literal_spec_values += _process_sequence_literals(glyphclass, kwargs, source, is_user_source)\n    incompatible_literal_spec_values += _process_sequence_literals(glyphclass, glyph_visuals, source, is_user_source)\n    if incompatible_literal_spec_values:\n        raise RuntimeError(_GLYPH_SOURCE_MSG % nice_join(incompatible_literal_spec_values, conjuction=\"and\"))\n\n    # handle the nonselection glyph, we always set one\n    nonselection_visuals = pop_visuals(glyphclass, kwargs, prefix='nonselection_', defaults=glyph_visuals, override_defaults={'alpha':0.1})\n\n",
  "slicing": [
   "    incompatible_literal_spec_values += _process_sequence_literals(glyphclass, glyph_visuals, source, is_user_source)\n",
   "    if incompatible_literal_spec_values:\n",
   "        raise RuntimeError(_GLYPH_SOURCE_MSG % nice_join(incompatible_literal_spec_values, conjuction=\"and\"))\n",
   "            incompatible_literal_spec_values.append(var)\n",
   "    return incompatible_literal_spec_values\n"
  ]
 },
 "101": {
  "name": "nonselection_visuals",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/plotting/_renderer.py",
  "lineno": "97",
  "column": "4",
  "context": "dle the nonselection glyph, we always set one\n    nonselection_visuals = pop_visuals(glyphclass, kwargs, prefix='nonselection_', defaults=glyph_visuals, override_defaults={'alpha':0.1})\n\n    # handle the selection glyph, if any properti",
  "context_lines": "    incompatible_literal_spec_values += _process_sequence_literals(glyphclass, glyph_visuals, source, is_user_source)\n    if incompatible_literal_spec_values:\n        raise RuntimeError(_GLYPH_SOURCE_MSG % nice_join(incompatible_literal_spec_values, conjuction=\"and\"))\n\n    # handle the nonselection glyph, we always set one\n    nonselection_visuals = pop_visuals(glyphclass, kwargs, prefix='nonselection_', defaults=glyph_visuals, override_defaults={'alpha':0.1})\n\n    # handle the selection glyph, if any properties were given\n    if any(x.startswith('selection_') for x in kwargs):\n        selection_visuals = pop_visuals(glyphclass, kwargs, prefix='selection_', defaults=glyph_visuals)\n",
  "slicing": [
   "    colors = [\n",
   "        renderers = plot.renderers\n",
   "        renderers = [x for x in renderers if x.__view_model__ == \"GlyphRenderer\"]\n",
   "        num_renderers = len(renderers)\n",
   "        return colors[num_renderers]\n",
   "        return colors[0]\n",
   "    is_user_source = _convert_data_source(kwargs)\n",
   "    legend_kwarg = pop_legend_kwarg(kwargs)\n",
   "    renderer_kws = _pop_renderer_args(kwargs)\n",
   "    source = renderer_kws['data_source']\n",
   "    glyph_visuals = pop_visuals(glyphclass, kwargs)\n",
   "    incompatible_literal_spec_values = []\n",
   "    incompatible_literal_spec_values += _process_sequence_literals(glyphclass, kwargs, source, is_user_source)\n",
   "    incompatible_literal_spec_values += _process_sequence_literals(glyphclass, glyph_visuals, source, is_user_source)\n",
   "    if incompatible_literal_spec_values:\n",
   "        raise RuntimeError(_GLYPH_SOURCE_MSG % nice_join(incompatible_literal_spec_values, conjuction=\"and\"))\n",
   "    nonselection_visuals = pop_visuals(glyphclass, kwargs, prefix='nonselection_', defaults=glyph_visuals, override_defaults={'alpha':0.1})\n",
   "    if any(x.startswith('selection_') for x in kwargs):\n",
   "        selection_visuals = pop_visuals(glyphclass, kwargs, prefix='selection_', defaults=glyph_visuals)\n",
   "        selection_visuals = None\n",
   "    if any(x.startswith('hover_') for x in kwargs):\n",
   "        hover_visuals = pop_visuals(glyphclass, kwargs, prefix='hover_', defaults=glyph_visuals)\n",
   "        hover_visuals = None\n",
   "    if any(x.startswith('muted_') for x in kwargs):\n",
   "        muted_visuals = pop_visuals(glyphclass, kwargs, prefix='muted_', defaults=glyph_visuals)\n",
   "        muted_visuals = None\n",
   "    glyph_renderer = GlyphRenderer(\n",
   "        glyph=make_glyph(glyphclass, kwargs, glyph_visuals),\n",
   "        nonselection_glyph=make_glyph(glyphclass, kwargs, nonselection_visuals),\n",
   "        selection_glyph=make_glyph(glyphclass, kwargs, selection_visuals),\n",
   "        hover_glyph=make_glyph(glyphclass, kwargs, hover_visuals),\n",
   "        muted_glyph=make_glyph(glyphclass, kwargs, muted_visuals),\n",
   "        **renderer_kws)\n",
   "    plot.renderers.append(glyph_renderer)\n",
   "    if legend_kwarg:\n",
   "        update_legend(plot, legend_kwarg, glyph_renderer)\n",
   "    return glyph_renderer\n",
   "    kws = kws.copy()\n",
   "    kws.update(extra)\n",
   "    return glyphclass(**kws)\n",
   "    def split_feature_trait(ft):\n",
   "        ft = ft.split('_', 1)\n",
   "        return ft if len(ft)==2 else ft+[None]\n",
   "        feature, trait = split_feature_trait(ft)\n",
   "        return feature in ('line', 'fill', 'text', 'global') and trait is not None\n",
   "    defaults = defaults.copy()\n",
   "    defaults.setdefault('text_color', 'black')\n",
   "    trait_defaults = {}\n",
   "    trait_defaults.setdefault('color', get_default_color())\n",
   "    trait_defaults.setdefault('alpha', 1.0)\n",
   "    result, traits = dict(), set()\n",
   "    glyphprops = glyphclass.properties()\n",
   "    for pname in filter(is_visual, glyphprops):\n",
   "        _, trait = split_feature_trait(pname)\n",
   "        if prefix+pname in props:\n",
   "            result[pname] = props.pop(prefix+pname)\n",
   "        elif trait not in glyphprops and prefix+trait in props:\n",
   "            result[pname] = props[prefix+trait]\n",
   "        elif trait in override_defaults:\n",
   "            result[pname] = override_defaults[trait]\n",
   "        elif pname in defaults:\n",
   "            result[pname] = defaults[pname]\n",
   "        elif trait in trait_defaults:\n",
   "            result[pname] = trait_defaults[trait]\n",
   "        if trait not in glyphprops:\n",
   "            traits.add(trait)\n",
   "    for trait in traits:\n",
   "        props.pop(prefix+trait, None)\n",
   "    return result\n",
   "    is_user_source = kwargs.get('source', None) is not None\n",
   "    if is_user_source:\n",
   "        source = kwargs['source']\n",
   "        if not isinstance(source, ColumnarDataSource):\n",
   "                source = ColumnDataSource(source)\n",
   "                    curr_type=str(type(source)),\n",
   "            kwargs['source'] = source\n",
   "    return is_user_source\n",
   "    result['data_source'] = kwargs.pop('source', ColumnDataSource())\n",
   "    return result\n",
   "        if is_user_source:\n",
   "            incompatible_literal_spec_values.append(var)\n",
   "            source.add(val, name=var)\n",
   "    return incompatible_literal_spec_values\n"
  ]
 },
 "102": {
  "name": "selection_visuals",
  "type": "NoneType",
  "class": "unknown",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/plotting/_renderer.py",
  "lineno": "103",
  "column": "8",
  "context": "tion_', defaults=glyph_visuals)\n    else:\n        selection_visuals = None\n\n    # handle the hover glyph, if any properties w",
  "context_lines": "    # handle the selection glyph, if any properties were given\n    if any(x.startswith('selection_') for x in kwargs):\n        selection_visuals = pop_visuals(glyphclass, kwargs, prefix='selection_', defaults=glyph_visuals)\n    else:\n        selection_visuals = None\n\n    # handle the hover glyph, if any properties were given\n    if any(x.startswith('hover_') for x in kwargs):\n        hover_visuals = pop_visuals(glyphclass, kwargs, prefix='hover_', defaults=glyph_visuals)\n",
  "slicing": [
   "        selection_visuals = None\n",
   "        selection_glyph=make_glyph(glyphclass, kwargs, selection_visuals),\n"
  ]
 },
 "103": {
  "name": "hover_visuals",
  "type": "NoneType",
  "class": "unknown",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/plotting/_renderer.py",
  "lineno": "109",
  "column": "8",
  "context": "over_', defaults=glyph_visuals)\n    else:\n        hover_visuals = None\n\n    # handle the mute glyph, if any properties we",
  "context_lines": "    # handle the hover glyph, if any properties were given\n    if any(x.startswith('hover_') for x in kwargs):\n        hover_visuals = pop_visuals(glyphclass, kwargs, prefix='hover_', defaults=glyph_visuals)\n    else:\n        hover_visuals = None\n\n    # handle the mute glyph, if any properties were given\n    if any(x.startswith('muted_') for x in kwargs):\n        muted_visuals = pop_visuals(glyphclass, kwargs, prefix='muted_', defaults=glyph_visuals)\n",
  "slicing": [
   "        hover_visuals = None\n",
   "        hover_glyph=make_glyph(glyphclass, kwargs, hover_visuals),\n"
  ]
 },
 "104": {
  "name": "muted_visuals",
  "type": "NoneType",
  "class": "unknown",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/plotting/_renderer.py",
  "lineno": "115",
  "column": "8",
  "context": "uted_', defaults=glyph_visuals)\n    else:\n        muted_visuals = None\n\n    glyph_renderer = GlyphRenderer(\n        glyph",
  "context_lines": "    # handle the mute glyph, if any properties were given\n    if any(x.startswith('muted_') for x in kwargs):\n        muted_visuals = pop_visuals(glyphclass, kwargs, prefix='muted_', defaults=glyph_visuals)\n    else:\n        muted_visuals = None\n\n    glyph_renderer = GlyphRenderer(\n        glyph=make_glyph(glyphclass, kwargs, glyph_visuals),\n        nonselection_glyph=make_glyph(glyphclass, kwargs, nonselection_visuals),\n",
  "slicing": [
   "        muted_visuals = None\n",
   "        muted_glyph=make_glyph(glyphclass, kwargs, muted_visuals),\n"
  ]
 },
 "105": {
  "name": "kws",
  "type": "dict",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/_renderer.py",
  "lineno": "138",
  "column": "4",
  "context": "a):\n    if extra is None:\n        return None\n    kws = kws.copy()\n    kws.update(extra)\n    return glyphclass(**kws)",
  "context_lines": "    return glyph_renderer\n\ndef make_glyph(glyphclass, kws, extra):\n    if extra is None:\n        return None\n    kws = kws.copy()\n    kws.update(extra)\n    return glyphclass(**kws)\n\ndef pop_visuals(glyphclass, props, prefix=\"\", defaults={}, override_defaults={}):\n    \"\"\"\n",
  "slicing": [
   "    colors = [\n",
   "        renderers = plot.renderers\n",
   "        renderers = [x for x in renderers if x.__view_model__ == \"GlyphRenderer\"]\n",
   "        num_renderers = len(renderers)\n",
   "        return colors[num_renderers]\n",
   "        return colors[0]\n",
   "    is_user_source = _convert_data_source(kwargs)\n",
   "    legend_kwarg = pop_legend_kwarg(kwargs)\n",
   "    renderer_kws = _pop_renderer_args(kwargs)\n",
   "    source = renderer_kws['data_source']\n",
   "    glyph_visuals = pop_visuals(glyphclass, kwargs)\n",
   "    incompatible_literal_spec_values = []\n",
   "    incompatible_literal_spec_values += _process_sequence_literals(glyphclass, kwargs, source, is_user_source)\n",
   "    incompatible_literal_spec_values += _process_sequence_literals(glyphclass, glyph_visuals, source, is_user_source)\n",
   "    if incompatible_literal_spec_values:\n",
   "        raise RuntimeError(_GLYPH_SOURCE_MSG % nice_join(incompatible_literal_spec_values, conjuction=\"and\"))\n",
   "    nonselection_visuals = pop_visuals(glyphclass, kwargs, prefix='nonselection_', defaults=glyph_visuals, override_defaults={'alpha':0.1})\n",
   "    if any(x.startswith('selection_') for x in kwargs):\n",
   "        selection_visuals = pop_visuals(glyphclass, kwargs, prefix='selection_', defaults=glyph_visuals)\n",
   "        selection_visuals = None\n",
   "    if any(x.startswith('hover_') for x in kwargs):\n",
   "        hover_visuals = pop_visuals(glyphclass, kwargs, prefix='hover_', defaults=glyph_visuals)\n",
   "        hover_visuals = None\n",
   "    if any(x.startswith('muted_') for x in kwargs):\n",
   "        muted_visuals = pop_visuals(glyphclass, kwargs, prefix='muted_', defaults=glyph_visuals)\n",
   "        muted_visuals = None\n",
   "    glyph_renderer = GlyphRenderer(\n",
   "        glyph=make_glyph(glyphclass, kwargs, glyph_visuals),\n",
   "        nonselection_glyph=make_glyph(glyphclass, kwargs, nonselection_visuals),\n",
   "        selection_glyph=make_glyph(glyphclass, kwargs, selection_visuals),\n",
   "        hover_glyph=make_glyph(glyphclass, kwargs, hover_visuals),\n",
   "        muted_glyph=make_glyph(glyphclass, kwargs, muted_visuals),\n",
   "        **renderer_kws)\n",
   "    plot.renderers.append(glyph_renderer)\n",
   "    if legend_kwarg:\n",
   "        update_legend(plot, legend_kwarg, glyph_renderer)\n",
   "    return glyph_renderer\n",
   "    kws = kws.copy()\n",
   "    kws.update(extra)\n",
   "    return glyphclass(**kws)\n",
   "    def split_feature_trait(ft):\n",
   "        ft = ft.split('_', 1)\n",
   "        return ft if len(ft)==2 else ft+[None]\n",
   "        feature, trait = split_feature_trait(ft)\n",
   "        return feature in ('line', 'fill', 'text', 'global') and trait is not None\n",
   "    defaults = defaults.copy()\n",
   "    defaults.setdefault('text_color', 'black')\n",
   "    trait_defaults = {}\n",
   "    trait_defaults.setdefault('color', get_default_color())\n",
   "    trait_defaults.setdefault('alpha', 1.0)\n",
   "    result, traits = dict(), set()\n",
   "    glyphprops = glyphclass.properties()\n",
   "    for pname in filter(is_visual, glyphprops):\n",
   "        _, trait = split_feature_trait(pname)\n",
   "        if prefix+pname in props:\n",
   "            result[pname] = props.pop(prefix+pname)\n",
   "        elif trait not in glyphprops and prefix+trait in props:\n",
   "            result[pname] = props[prefix+trait]\n",
   "        elif trait in override_defaults:\n",
   "            result[pname] = override_defaults[trait]\n",
   "        elif pname in defaults:\n",
   "            result[pname] = defaults[pname]\n",
   "        elif trait in trait_defaults:\n",
   "            result[pname] = trait_defaults[trait]\n",
   "        if trait not in glyphprops:\n",
   "            traits.add(trait)\n",
   "    for trait in traits:\n",
   "        props.pop(prefix+trait, None)\n",
   "    return result\n",
   "    is_user_source = kwargs.get('source', None) is not None\n",
   "    if is_user_source:\n",
   "        source = kwargs['source']\n",
   "        if not isinstance(source, ColumnarDataSource):\n",
   "                source = ColumnDataSource(source)\n",
   "                    curr_type=str(type(source)),\n",
   "            kwargs['source'] = source\n",
   "    return is_user_source\n",
   "    result['data_source'] = kwargs.pop('source', ColumnDataSource())\n",
   "    return result\n",
   "        if is_user_source:\n",
   "            incompatible_literal_spec_values.append(var)\n",
   "            source.add(val, name=var)\n",
   "    return incompatible_literal_spec_values\n"
  ]
 },
 "106": {
  "name": "ft",
  "type": "list",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/_renderer.py",
  "lineno": "186",
  "column": "8",
  "context": " Ex. 'line_color' => ['line', 'color']\"\"\"\n        ft = ft.split('_', 1)\n        return ft if len(ft)==2 else ft+[None]\n\n  ",
  "context_lines": "        ultimate defaults in case those can't be deduced.\n    \"\"\"\n    def split_feature_trait(ft):\n        \"\"\"Feature is up to first '_'. Ex. 'line_color' => ['line', 'color']\"\"\"\n        ft = ft.split('_', 1)\n        return ft if len(ft)==2 else ft+[None]\n\n    def is_visual(ft):\n        \"\"\"Whether a feature trait name is visual\"\"\"\n        feature, trait = split_feature_trait(ft)\n",
  "slicing": [
   "    colors = [\n",
   "        renderers = plot.renderers\n",
   "        renderers = [x for x in renderers if x.__view_model__ == \"GlyphRenderer\"]\n",
   "        num_renderers = len(renderers)\n",
   "        return colors[num_renderers]\n",
   "        return colors[0]\n",
   "    is_user_source = _convert_data_source(kwargs)\n",
   "    legend_kwarg = pop_legend_kwarg(kwargs)\n",
   "    renderer_kws = _pop_renderer_args(kwargs)\n",
   "    source = renderer_kws['data_source']\n",
   "    glyph_visuals = pop_visuals(glyphclass, kwargs)\n",
   "    incompatible_literal_spec_values = []\n",
   "    incompatible_literal_spec_values += _process_sequence_literals(glyphclass, kwargs, source, is_user_source)\n",
   "    incompatible_literal_spec_values += _process_sequence_literals(glyphclass, glyph_visuals, source, is_user_source)\n",
   "    if incompatible_literal_spec_values:\n",
   "        raise RuntimeError(_GLYPH_SOURCE_MSG % nice_join(incompatible_literal_spec_values, conjuction=\"and\"))\n",
   "    nonselection_visuals = pop_visuals(glyphclass, kwargs, prefix='nonselection_', defaults=glyph_visuals, override_defaults={'alpha':0.1})\n",
   "    if any(x.startswith('selection_') for x in kwargs):\n",
   "        selection_visuals = pop_visuals(glyphclass, kwargs, prefix='selection_', defaults=glyph_visuals)\n",
   "        selection_visuals = None\n",
   "    if any(x.startswith('hover_') for x in kwargs):\n",
   "        hover_visuals = pop_visuals(glyphclass, kwargs, prefix='hover_', defaults=glyph_visuals)\n",
   "        hover_visuals = None\n",
   "    if any(x.startswith('muted_') for x in kwargs):\n",
   "        muted_visuals = pop_visuals(glyphclass, kwargs, prefix='muted_', defaults=glyph_visuals)\n",
   "        muted_visuals = None\n",
   "    glyph_renderer = GlyphRenderer(\n",
   "        glyph=make_glyph(glyphclass, kwargs, glyph_visuals),\n",
   "        nonselection_glyph=make_glyph(glyphclass, kwargs, nonselection_visuals),\n",
   "        selection_glyph=make_glyph(glyphclass, kwargs, selection_visuals),\n",
   "        hover_glyph=make_glyph(glyphclass, kwargs, hover_visuals),\n",
   "        muted_glyph=make_glyph(glyphclass, kwargs, muted_visuals),\n",
   "        **renderer_kws)\n",
   "    plot.renderers.append(glyph_renderer)\n",
   "    if legend_kwarg:\n",
   "        update_legend(plot, legend_kwarg, glyph_renderer)\n",
   "    return glyph_renderer\n",
   "    kws = kws.copy()\n",
   "    kws.update(extra)\n",
   "    return glyphclass(**kws)\n",
   "    def split_feature_trait(ft):\n",
   "        ft = ft.split('_', 1)\n",
   "        return ft if len(ft)==2 else ft+[None]\n",
   "        feature, trait = split_feature_trait(ft)\n",
   "        return feature in ('line', 'fill', 'text', 'global') and trait is not None\n",
   "    defaults = defaults.copy()\n",
   "    defaults.setdefault('text_color', 'black')\n",
   "    trait_defaults = {}\n",
   "    trait_defaults.setdefault('color', get_default_color())\n",
   "    trait_defaults.setdefault('alpha', 1.0)\n",
   "    result, traits = dict(), set()\n",
   "    glyphprops = glyphclass.properties()\n",
   "    for pname in filter(is_visual, glyphprops):\n",
   "        _, trait = split_feature_trait(pname)\n",
   "        if prefix+pname in props:\n",
   "            result[pname] = props.pop(prefix+pname)\n",
   "        elif trait not in glyphprops and prefix+trait in props:\n",
   "            result[pname] = props[prefix+trait]\n",
   "        elif trait in override_defaults:\n",
   "            result[pname] = override_defaults[trait]\n",
   "        elif pname in defaults:\n",
   "            result[pname] = defaults[pname]\n",
   "        elif trait in trait_defaults:\n",
   "            result[pname] = trait_defaults[trait]\n",
   "        if trait not in glyphprops:\n",
   "            traits.add(trait)\n",
   "    for trait in traits:\n",
   "        props.pop(prefix+trait, None)\n",
   "    return result\n",
   "    is_user_source = kwargs.get('source', None) is not None\n",
   "    if is_user_source:\n",
   "        source = kwargs['source']\n",
   "        if not isinstance(source, ColumnarDataSource):\n",
   "                source = ColumnDataSource(source)\n",
   "                    curr_type=str(type(source)),\n",
   "            kwargs['source'] = source\n",
   "    return is_user_source\n",
   "    result['data_source'] = kwargs.pop('source', ColumnDataSource())\n",
   "    return result\n",
   "        if is_user_source:\n",
   "            incompatible_literal_spec_values.append(var)\n",
   "            source.add(val, name=var)\n",
   "    return incompatible_literal_spec_values\n"
  ]
 },
 "107": {
  "name": "feature",
  "type": "str",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/plotting/_renderer.py",
  "lineno": "191",
  "column": "8",
  "context": "Whether a feature trait name is visual\"\"\"\n        feature, trait = split_feature_trait(ft)\n        return feature in ('line', 'fill', 'text',",
  "context_lines": "        ft = ft.split('_', 1)\n        return ft if len(ft)==2 else ft+[None]\n\n    def is_visual(ft):\n        \"\"\"Whether a feature trait name is visual\"\"\"\n        feature, trait = split_feature_trait(ft)\n        return feature in ('line', 'fill', 'text', 'global') and trait is not None\n\n    defaults = defaults.copy()\n    defaults.setdefault('text_color', 'black')\n\n    trait_defaults = {}\n",
  "slicing": [
   "        feature, trait = split_feature_trait(ft)\n",
   "        return feature in ('line', 'fill', 'text', 'global') and trait is not None\n"
  ]
 },
 "108": {
  "name": "trait",
  "type": "NoneType|str",
  "class": "unknown",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/plotting/_renderer.py",
  "lineno": "191",
  "column": "17",
  "context": " feature trait name is visual\"\"\"\n        feature, trait = split_feature_trait(ft)\n        return feature in ('line', 'fill', 'text',",
  "context_lines": "        ft = ft.split('_', 1)\n        return ft if len(ft)==2 else ft+[None]\n\n    def is_visual(ft):\n        \"\"\"Whether a feature trait name is visual\"\"\"\n        feature, trait = split_feature_trait(ft)\n        return feature in ('line', 'fill', 'text', 'global') and trait is not None\n\n    defaults = defaults.copy()\n    defaults.setdefault('text_color', 'black')\n\n    trait_defaults = {}\n",
  "slicing": [
   "        feature, trait = split_feature_trait(ft)\n",
   "        return feature in ('line', 'fill', 'text', 'global') and trait is not None\n",
   "        elif trait not in glyphprops and prefix+trait in props:\n",
   "            result[pname] = props[prefix+trait]\n",
   "        elif trait in override_defaults:\n",
   "            result[pname] = override_defaults[trait]\n",
   "        elif trait in trait_defaults:\n",
   "            result[pname] = trait_defaults[trait]\n",
   "        if trait not in glyphprops:\n",
   "            traits.add(trait)\n",
   "        props.pop(prefix+trait, None)\n"
  ]
 },
 "109": {
  "name": "defaults",
  "type": "dict",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/_renderer.py",
  "lineno": "194",
  "column": "4",
  "context": "ll', 'text', 'global') and trait is not None\n\n    defaults = defaults.copy()\n    defaults.setdefault('text_color', 'black')\n\n  ",
  "context_lines": "    def is_visual(ft):\n        \"\"\"Whether a feature trait name is visual\"\"\"\n        feature, trait = split_feature_trait(ft)\n        return feature in ('line', 'fill', 'text', 'global') and trait is not None\n\n    defaults = defaults.copy()\n    defaults.setdefault('text_color', 'black')\n\n    trait_defaults = {}\n    trait_defaults.setdefault('color', get_default_color())\n    trait_defaults.setdefault('alpha', 1.0)\n\n",
  "slicing": [
   "    colors = [\n",
   "        renderers = plot.renderers\n",
   "        renderers = [x for x in renderers if x.__view_model__ == \"GlyphRenderer\"]\n",
   "        num_renderers = len(renderers)\n",
   "        return colors[num_renderers]\n",
   "        return colors[0]\n",
   "    is_user_source = _convert_data_source(kwargs)\n",
   "    legend_kwarg = pop_legend_kwarg(kwargs)\n",
   "    renderer_kws = _pop_renderer_args(kwargs)\n",
   "    source = renderer_kws['data_source']\n",
   "    glyph_visuals = pop_visuals(glyphclass, kwargs)\n",
   "    incompatible_literal_spec_values = []\n",
   "    incompatible_literal_spec_values += _process_sequence_literals(glyphclass, kwargs, source, is_user_source)\n",
   "    incompatible_literal_spec_values += _process_sequence_literals(glyphclass, glyph_visuals, source, is_user_source)\n",
   "    if incompatible_literal_spec_values:\n",
   "        raise RuntimeError(_GLYPH_SOURCE_MSG % nice_join(incompatible_literal_spec_values, conjuction=\"and\"))\n",
   "    nonselection_visuals = pop_visuals(glyphclass, kwargs, prefix='nonselection_', defaults=glyph_visuals, override_defaults={'alpha':0.1})\n",
   "    if any(x.startswith('selection_') for x in kwargs):\n",
   "        selection_visuals = pop_visuals(glyphclass, kwargs, prefix='selection_', defaults=glyph_visuals)\n",
   "        selection_visuals = None\n",
   "    if any(x.startswith('hover_') for x in kwargs):\n",
   "        hover_visuals = pop_visuals(glyphclass, kwargs, prefix='hover_', defaults=glyph_visuals)\n",
   "        hover_visuals = None\n",
   "    if any(x.startswith('muted_') for x in kwargs):\n",
   "        muted_visuals = pop_visuals(glyphclass, kwargs, prefix='muted_', defaults=glyph_visuals)\n",
   "        muted_visuals = None\n",
   "    glyph_renderer = GlyphRenderer(\n",
   "        glyph=make_glyph(glyphclass, kwargs, glyph_visuals),\n",
   "        nonselection_glyph=make_glyph(glyphclass, kwargs, nonselection_visuals),\n",
   "        selection_glyph=make_glyph(glyphclass, kwargs, selection_visuals),\n",
   "        hover_glyph=make_glyph(glyphclass, kwargs, hover_visuals),\n",
   "        muted_glyph=make_glyph(glyphclass, kwargs, muted_visuals),\n",
   "        **renderer_kws)\n",
   "    plot.renderers.append(glyph_renderer)\n",
   "    if legend_kwarg:\n",
   "        update_legend(plot, legend_kwarg, glyph_renderer)\n",
   "    return glyph_renderer\n",
   "    kws = kws.copy()\n",
   "    kws.update(extra)\n",
   "    return glyphclass(**kws)\n",
   "    def split_feature_trait(ft):\n",
   "        ft = ft.split('_', 1)\n",
   "        return ft if len(ft)==2 else ft+[None]\n",
   "        feature, trait = split_feature_trait(ft)\n",
   "        return feature in ('line', 'fill', 'text', 'global') and trait is not None\n",
   "    defaults = defaults.copy()\n",
   "    defaults.setdefault('text_color', 'black')\n",
   "    trait_defaults = {}\n",
   "    trait_defaults.setdefault('color', get_default_color())\n",
   "    trait_defaults.setdefault('alpha', 1.0)\n",
   "    result, traits = dict(), set()\n",
   "    glyphprops = glyphclass.properties()\n",
   "    for pname in filter(is_visual, glyphprops):\n",
   "        _, trait = split_feature_trait(pname)\n",
   "        if prefix+pname in props:\n",
   "            result[pname] = props.pop(prefix+pname)\n",
   "        elif trait not in glyphprops and prefix+trait in props:\n",
   "            result[pname] = props[prefix+trait]\n",
   "        elif trait in override_defaults:\n",
   "            result[pname] = override_defaults[trait]\n",
   "        elif pname in defaults:\n",
   "            result[pname] = defaults[pname]\n",
   "        elif trait in trait_defaults:\n",
   "            result[pname] = trait_defaults[trait]\n",
   "        if trait not in glyphprops:\n",
   "            traits.add(trait)\n",
   "    for trait in traits:\n",
   "        props.pop(prefix+trait, None)\n",
   "    return result\n",
   "    is_user_source = kwargs.get('source', None) is not None\n",
   "    if is_user_source:\n",
   "        source = kwargs['source']\n",
   "        if not isinstance(source, ColumnarDataSource):\n",
   "                source = ColumnDataSource(source)\n",
   "                    curr_type=str(type(source)),\n",
   "            kwargs['source'] = source\n",
   "    return is_user_source\n",
   "    result['data_source'] = kwargs.pop('source', ColumnDataSource())\n",
   "    return result\n",
   "        if is_user_source:\n",
   "            incompatible_literal_spec_values.append(var)\n",
   "            source.add(val, name=var)\n",
   "    return incompatible_literal_spec_values\n"
  ]
 },
 "110": {
  "name": "glyphprops",
  "type": "set",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/_renderer.py",
  "lineno": "202",
  "column": "4",
  "context": "ha', 1.0)\n\n    result, traits = dict(), set()\n    glyphprops = glyphclass.properties()\n    for pname in filter(is_visual, glyphprops):\n  ",
  "context_lines": "    trait_defaults = {}\n    trait_defaults.setdefault('color', get_default_color())\n    trait_defaults.setdefault('alpha', 1.0)\n\n    result, traits = dict(), set()\n    glyphprops = glyphclass.properties()\n    for pname in filter(is_visual, glyphprops):\n        _, trait = split_feature_trait(pname)\n\n        # e.g. \"line_color\", \"selection_fill_alpha\"\n        if prefix+pname in props:\n",
  "slicing": [
   "    colors = [\n",
   "        renderers = plot.renderers\n",
   "        renderers = [x for x in renderers if x.__view_model__ == \"GlyphRenderer\"]\n",
   "        num_renderers = len(renderers)\n",
   "        return colors[num_renderers]\n",
   "        return colors[0]\n",
   "    is_user_source = _convert_data_source(kwargs)\n",
   "    legend_kwarg = pop_legend_kwarg(kwargs)\n",
   "    renderer_kws = _pop_renderer_args(kwargs)\n",
   "    source = renderer_kws['data_source']\n",
   "    glyph_visuals = pop_visuals(glyphclass, kwargs)\n",
   "    incompatible_literal_spec_values = []\n",
   "    incompatible_literal_spec_values += _process_sequence_literals(glyphclass, kwargs, source, is_user_source)\n",
   "    incompatible_literal_spec_values += _process_sequence_literals(glyphclass, glyph_visuals, source, is_user_source)\n",
   "    if incompatible_literal_spec_values:\n",
   "        raise RuntimeError(_GLYPH_SOURCE_MSG % nice_join(incompatible_literal_spec_values, conjuction=\"and\"))\n",
   "    nonselection_visuals = pop_visuals(glyphclass, kwargs, prefix='nonselection_', defaults=glyph_visuals, override_defaults={'alpha':0.1})\n",
   "    if any(x.startswith('selection_') for x in kwargs):\n",
   "        selection_visuals = pop_visuals(glyphclass, kwargs, prefix='selection_', defaults=glyph_visuals)\n",
   "        selection_visuals = None\n",
   "    if any(x.startswith('hover_') for x in kwargs):\n",
   "        hover_visuals = pop_visuals(glyphclass, kwargs, prefix='hover_', defaults=glyph_visuals)\n",
   "        hover_visuals = None\n",
   "    if any(x.startswith('muted_') for x in kwargs):\n",
   "        muted_visuals = pop_visuals(glyphclass, kwargs, prefix='muted_', defaults=glyph_visuals)\n",
   "        muted_visuals = None\n",
   "    glyph_renderer = GlyphRenderer(\n",
   "        glyph=make_glyph(glyphclass, kwargs, glyph_visuals),\n",
   "        nonselection_glyph=make_glyph(glyphclass, kwargs, nonselection_visuals),\n",
   "        selection_glyph=make_glyph(glyphclass, kwargs, selection_visuals),\n",
   "        hover_glyph=make_glyph(glyphclass, kwargs, hover_visuals),\n",
   "        muted_glyph=make_glyph(glyphclass, kwargs, muted_visuals),\n",
   "        **renderer_kws)\n",
   "    plot.renderers.append(glyph_renderer)\n",
   "    if legend_kwarg:\n",
   "        update_legend(plot, legend_kwarg, glyph_renderer)\n",
   "    return glyph_renderer\n",
   "    kws = kws.copy()\n",
   "    kws.update(extra)\n",
   "    return glyphclass(**kws)\n",
   "    def split_feature_trait(ft):\n",
   "        ft = ft.split('_', 1)\n",
   "        return ft if len(ft)==2 else ft+[None]\n",
   "        feature, trait = split_feature_trait(ft)\n",
   "        return feature in ('line', 'fill', 'text', 'global') and trait is not None\n",
   "    defaults = defaults.copy()\n",
   "    defaults.setdefault('text_color', 'black')\n",
   "    trait_defaults = {}\n",
   "    trait_defaults.setdefault('color', get_default_color())\n",
   "    trait_defaults.setdefault('alpha', 1.0)\n",
   "    result, traits = dict(), set()\n",
   "    glyphprops = glyphclass.properties()\n",
   "    for pname in filter(is_visual, glyphprops):\n",
   "        _, trait = split_feature_trait(pname)\n",
   "        if prefix+pname in props:\n",
   "            result[pname] = props.pop(prefix+pname)\n",
   "        elif trait not in glyphprops and prefix+trait in props:\n",
   "            result[pname] = props[prefix+trait]\n",
   "        elif trait in override_defaults:\n",
   "            result[pname] = override_defaults[trait]\n",
   "        elif pname in defaults:\n",
   "            result[pname] = defaults[pname]\n",
   "        elif trait in trait_defaults:\n",
   "            result[pname] = trait_defaults[trait]\n",
   "        if trait not in glyphprops:\n",
   "            traits.add(trait)\n",
   "    for trait in traits:\n",
   "        props.pop(prefix+trait, None)\n",
   "    return result\n",
   "    is_user_source = kwargs.get('source', None) is not None\n",
   "    if is_user_source:\n",
   "        source = kwargs['source']\n",
   "        if not isinstance(source, ColumnarDataSource):\n",
   "                source = ColumnDataSource(source)\n",
   "                    curr_type=str(type(source)),\n",
   "            kwargs['source'] = source\n",
   "    return is_user_source\n",
   "    result['data_source'] = kwargs.pop('source', ColumnDataSource())\n",
   "    return result\n",
   "        if is_user_source:\n",
   "            incompatible_literal_spec_values.append(var)\n",
   "            source.add(val, name=var)\n",
   "    return incompatible_literal_spec_values\n"
  ]
 },
 "111": {
  "name": "_",
  "type": "str",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/plotting/_renderer.py",
  "lineno": "204",
  "column": "8",
  "context": "r pname in filter(is_visual, glyphprops):\n        _, trait = split_feature_trait(pname)\n\n        # e.g. \"line_color\", \"selection_fill_alph",
  "context_lines": "    trait_defaults.setdefault('alpha', 1.0)\n\n    result, traits = dict(), set()\n    glyphprops = glyphclass.properties()\n    for pname in filter(is_visual, glyphprops):\n        _, trait = split_feature_trait(pname)\n\n        # e.g. \"line_color\", \"selection_fill_alpha\"\n        if prefix+pname in props:\n            result[pname] = props.pop(prefix+pname)\n\n",
  "slicing": "        _, trait = split_feature_trait(pname)\n"
 },
 "112": {
  "name": "trait",
  "type": "str",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/plotting/_renderer.py",
  "lineno": "204",
  "column": "11",
  "context": "name in filter(is_visual, glyphprops):\n        _, trait = split_feature_trait(pname)\n\n        # e.g. \"line_color\", \"selection_fill_alph",
  "context_lines": "    trait_defaults.setdefault('alpha', 1.0)\n\n    result, traits = dict(), set()\n    glyphprops = glyphclass.properties()\n    for pname in filter(is_visual, glyphprops):\n        _, trait = split_feature_trait(pname)\n\n        # e.g. \"line_color\", \"selection_fill_alpha\"\n        if prefix+pname in props:\n            result[pname] = props.pop(prefix+pname)\n\n",
  "slicing": [
   "        _, trait = split_feature_trait(pname)\n",
   "        elif trait not in glyphprops and prefix+trait in props:\n",
   "            result[pname] = props[prefix+trait]\n",
   "        elif trait in override_defaults:\n",
   "            result[pname] = override_defaults[trait]\n",
   "        elif trait in trait_defaults:\n",
   "            result[pname] = trait_defaults[trait]\n",
   "        if trait not in glyphprops:\n",
   "            traits.add(trait)\n",
   "        props.pop(prefix+trait, None)\n"
  ]
 },
 "113": {
  "name": "dataspecs",
  "type": "dict",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/_renderer.py",
  "lineno": "266",
  "column": "4",
  "context": "e):\n    incompatible_literal_spec_values = []\n    dataspecs = glyphclass.dataspecs_with_props()\n    for var, val in kwargs.items():\n\n        # ign",
  "context_lines": "    result['data_source'] = kwargs.pop('source', ColumnDataSource())\n    return result\n\ndef _process_sequence_literals(glyphclass, kwargs, source, is_user_source):\n    incompatible_literal_spec_values = []\n    dataspecs = glyphclass.dataspecs_with_props()\n    for var, val in kwargs.items():\n\n        # ignore things that are not iterable\n        if not isinstance(val, Iterable):\n            continue\n\n",
  "slicing": [
   "RENDERER_ARGS = ['name', 'x_range_name', 'y_range_name',\n",
   "    colors = [\n",
   "        renderers = plot.renderers\n",
   "        renderers = [x for x in renderers if x.__view_model__ == \"GlyphRenderer\"]\n",
   "        num_renderers = len(renderers)\n",
   "        return colors[num_renderers]\n",
   "        return colors[0]\n",
   "    is_user_source = _convert_data_source(kwargs)\n",
   "    legend_kwarg = pop_legend_kwarg(kwargs)\n",
   "    renderer_kws = _pop_renderer_args(kwargs)\n",
   "    source = renderer_kws['data_source']\n",
   "    glyph_visuals = pop_visuals(glyphclass, kwargs)\n",
   "    incompatible_literal_spec_values = []\n",
   "    incompatible_literal_spec_values += _process_sequence_literals(glyphclass, kwargs, source, is_user_source)\n",
   "    incompatible_literal_spec_values += _process_sequence_literals(glyphclass, glyph_visuals, source, is_user_source)\n",
   "    if incompatible_literal_spec_values:\n",
   "        raise RuntimeError(_GLYPH_SOURCE_MSG % nice_join(incompatible_literal_spec_values, conjuction=\"and\"))\n",
   "    nonselection_visuals = pop_visuals(glyphclass, kwargs, prefix='nonselection_', defaults=glyph_visuals, override_defaults={'alpha':0.1})\n",
   "    if any(x.startswith('selection_') for x in kwargs):\n",
   "        selection_visuals = pop_visuals(glyphclass, kwargs, prefix='selection_', defaults=glyph_visuals)\n",
   "        selection_visuals = None\n",
   "    if any(x.startswith('hover_') for x in kwargs):\n",
   "        hover_visuals = pop_visuals(glyphclass, kwargs, prefix='hover_', defaults=glyph_visuals)\n",
   "        hover_visuals = None\n",
   "    if any(x.startswith('muted_') for x in kwargs):\n",
   "        muted_visuals = pop_visuals(glyphclass, kwargs, prefix='muted_', defaults=glyph_visuals)\n",
   "        muted_visuals = None\n",
   "    glyph_renderer = GlyphRenderer(\n",
   "        glyph=make_glyph(glyphclass, kwargs, glyph_visuals),\n",
   "        nonselection_glyph=make_glyph(glyphclass, kwargs, nonselection_visuals),\n",
   "        selection_glyph=make_glyph(glyphclass, kwargs, selection_visuals),\n",
   "        hover_glyph=make_glyph(glyphclass, kwargs, hover_visuals),\n",
   "        muted_glyph=make_glyph(glyphclass, kwargs, muted_visuals),\n",
   "        **renderer_kws)\n",
   "    plot.renderers.append(glyph_renderer)\n",
   "    if legend_kwarg:\n",
   "        update_legend(plot, legend_kwarg, glyph_renderer)\n",
   "    return glyph_renderer\n",
   "    kws = kws.copy()\n",
   "    kws.update(extra)\n",
   "    return glyphclass(**kws)\n",
   "    def split_feature_trait(ft):\n",
   "        ft = ft.split('_', 1)\n",
   "        return ft if len(ft)==2 else ft+[None]\n",
   "        feature, trait = split_feature_trait(ft)\n",
   "        return feature in ('line', 'fill', 'text', 'global') and trait is not None\n",
   "    defaults = defaults.copy()\n",
   "    defaults.setdefault('text_color', 'black')\n",
   "    trait_defaults = {}\n",
   "    trait_defaults.setdefault('color', get_default_color())\n",
   "    trait_defaults.setdefault('alpha', 1.0)\n",
   "    result, traits = dict(), set()\n",
   "    glyphprops = glyphclass.properties()\n",
   "    for pname in filter(is_visual, glyphprops):\n",
   "        _, trait = split_feature_trait(pname)\n",
   "        if prefix+pname in props:\n",
   "            result[pname] = props.pop(prefix+pname)\n",
   "        elif trait not in glyphprops and prefix+trait in props:\n",
   "            result[pname] = props[prefix+trait]\n",
   "        elif trait in override_defaults:\n",
   "            result[pname] = override_defaults[trait]\n",
   "        elif pname in defaults:\n",
   "            result[pname] = defaults[pname]\n",
   "        elif trait in trait_defaults:\n",
   "            result[pname] = trait_defaults[trait]\n",
   "        if trait not in glyphprops:\n",
   "            traits.add(trait)\n",
   "    for trait in traits:\n",
   "        props.pop(prefix+trait, None)\n",
   "    return result\n",
   "    is_user_source = kwargs.get('source', None) is not None\n",
   "    if is_user_source:\n",
   "        source = kwargs['source']\n",
   "        if not isinstance(source, ColumnarDataSource):\n",
   "                source = ColumnDataSource(source)\n",
   "                msg = \"Failed to auto-convert {curr_type} to ColumnDataSource.\\n Original error: {err}\".format(\n",
   "                    curr_type=str(type(source)),\n",
   "                raise ValueError(msg).with_traceback(sys.exc_info()[2])\n",
   "            kwargs['source'] = source\n",
   "    return is_user_source\n",
   "    result = {attr: kwargs.pop(attr)\n",
   "              for attr in RENDERER_ARGS\n",
   "              if attr in kwargs}\n",
   "    result['data_source'] = kwargs.pop('source', ColumnDataSource())\n",
   "    return result\n",
   "    incompatible_literal_spec_values = []\n",
   "    dataspecs = glyphclass.dataspecs_with_props()\n",
   "        if var not in dataspecs:\n",
   "        if (isinstance(dataspecs[var].property, ColorSpec) and isinstance(val, tuple) and len(val) in (3, 4) and all(isinstance(v, (float, int)) for v in val)):\n",
   "        if is_user_source:\n",
   "            incompatible_literal_spec_values.append(var)\n",
   "            source.add(val, name=var)\n",
   "    return incompatible_literal_spec_values\n"
  ]
 },
 "114": {
  "name": "legend",
  "type": "Legend",
  "class": "customized",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/plotting/_legends.py",
  "lineno": "53",
  "column": "4",
  "context": "e_legend(plot, legend_kwarg, glyph_renderer):\n    legend = _get_or_create_legend(plot)\n    kwarg, value = list(legend_kwarg.items())[0]\n\n",
  "context_lines": "    if len(result) > 1:\n        raise ValueError(\"Only one of %s may be provided, got: %s\" % (nice_join(LEGEND_ARGS), nice_join(result.keys())))\n    return result\n\ndef update_legend(plot, legend_kwarg, glyph_renderer):\n    legend = _get_or_create_legend(plot)\n    kwarg, value = list(legend_kwarg.items())[0]\n\n    _LEGEND_KWARG_HANDLERS[kwarg](value, legend, glyph_renderer)\n\n#-----------------------------------------------------------------------------\n# Private API\n",
  "slicing": [
   "LEGEND_ARGS = ['legend', 'legend_label', 'legend_field', 'legend_group']\n",
   "    result = {attr: kwargs.pop(attr) for attr in LEGEND_ARGS if attr in kwargs}\n",
   "    if len(result) > 1:\n",
   "        raise ValueError(\"Only one of %s may be provided, got: %s\" % (nice_join(LEGEND_ARGS), nice_join(result.keys())))\n",
   "    return result\n",
   "    legend = _get_or_create_legend(plot)\n",
   "    kwarg, value = list(legend_kwarg.items())[0]\n",
   "    _LEGEND_KWARG_HANDLERS[kwarg](value, legend, glyph_renderer)\n",
   "def _find_legend_item(label, legend):\n",
   "    for item in legend.items:\n",
   "        if item.label == label:\n",
   "            return item\n",
   "    legends = plot.select(type=Legend)\n",
   "    if not legends:\n",
   "        legend = Legend()\n",
   "        plot.add_layout(legend)\n",
   "        return legend\n",
   "    if len(legends) == 1:\n",
   "        return legends[0]\n",
   "            label = label['field']\n",
   "            _handle_legend_field(label, legend, glyph_renderer)\n",
   "        elif \"value\" in label and len(label) == 1:\n",
   "            label = label['value']\n",
   "            _handle_legend_label(label, legend, glyph_renderer)\n",
   "            raise ValueError(\"Bad 'legend' parameter value: %s\" % label)\n",
   "        source = glyph_renderer.data_source\n",
   "        if source is not None and hasattr(source, 'column_names') and label in source.column_names:\n",
   "            _handle_legend_field(label, legend, glyph_renderer)\n",
   "            _handle_legend_label(label, legend, glyph_renderer)\n",
   "    if not isinstance(label, str):\n",
   "    label = field(label)\n",
   "    item = _find_legend_item(label, legend)\n",
   "    if item:\n",
   "        item.renderers.append(glyph_renderer)\n",
   "        new_item = LegendItem(label=label, renderers=[glyph_renderer])\n",
   "        legend.items.append(new_item)\n",
   "    if not isinstance(label, str):\n",
   "    source = glyph_renderer.data_source\n",
   "    if source is None:\n",
   "    if not (hasattr(source, 'column_names') and label in source.column_names):\n",
   "    column = source.data[label]\n",
   "    vals, inds = np.unique(column, return_index=1)\n",
   "    for val, ind in zip(vals, inds):\n",
   "        label = value(str(val))\n",
   "        new_item = LegendItem(label=label, renderers=[glyph_renderer], index=ind)\n",
   "        legend.items.append(new_item)\n",
   "    if not isinstance(label, str):\n",
   "    label = value(label)\n",
   "    item = _find_legend_item(label, legend)\n",
   "    if item:\n",
   "        item.renderers.append(glyph_renderer)\n",
   "        new_item = LegendItem(label=label, renderers=[glyph_renderer])\n",
   "        legend.items.append(new_item)\n"
  ]
 },
 "115": {
  "name": "legends",
  "type": "_list_attr_splat",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/_legends.py",
  "lineno": "69",
  "column": "4",
  "context": "return None\n\ndef _get_or_create_legend(plot):\n    legends = plot.select(type=Legend)\n    if not legends:\n        legend = Legend()\n    ",
  "context_lines": "        if item.label == label:\n            return item\n    return None\n\ndef _get_or_create_legend(plot):\n    legends = plot.select(type=Legend)\n    if not legends:\n        legend = Legend()\n        plot.add_layout(legend)\n        return legend\n",
  "slicing": [
   "LEGEND_ARGS = ['legend', 'legend_label', 'legend_field', 'legend_group']\n",
   "    result = {attr: kwargs.pop(attr) for attr in LEGEND_ARGS if attr in kwargs}\n",
   "    if len(result) > 1:\n",
   "        raise ValueError(\"Only one of %s may be provided, got: %s\" % (nice_join(LEGEND_ARGS), nice_join(result.keys())))\n",
   "    return result\n",
   "    legend = _get_or_create_legend(plot)\n",
   "    kwarg, value = list(legend_kwarg.items())[0]\n",
   "    _LEGEND_KWARG_HANDLERS[kwarg](value, legend, glyph_renderer)\n",
   "def _find_legend_item(label, legend):\n",
   "    for item in legend.items:\n",
   "        if item.label == label:\n",
   "            return item\n",
   "    legends = plot.select(type=Legend)\n",
   "    if not legends:\n",
   "        legend = Legend()\n",
   "        plot.add_layout(legend)\n",
   "        return legend\n",
   "    if len(legends) == 1:\n",
   "        return legends[0]\n",
   "            label = label['field']\n",
   "            _handle_legend_field(label, legend, glyph_renderer)\n",
   "        elif \"value\" in label and len(label) == 1:\n",
   "            label = label['value']\n",
   "            _handle_legend_label(label, legend, glyph_renderer)\n",
   "            raise ValueError(\"Bad 'legend' parameter value: %s\" % label)\n",
   "        source = glyph_renderer.data_source\n",
   "        if source is not None and hasattr(source, 'column_names') and label in source.column_names:\n",
   "            _handle_legend_field(label, legend, glyph_renderer)\n",
   "            _handle_legend_label(label, legend, glyph_renderer)\n",
   "    if not isinstance(label, str):\n",
   "    label = field(label)\n",
   "    item = _find_legend_item(label, legend)\n",
   "    if item:\n",
   "        item.renderers.append(glyph_renderer)\n",
   "        new_item = LegendItem(label=label, renderers=[glyph_renderer])\n",
   "        legend.items.append(new_item)\n",
   "    if not isinstance(label, str):\n",
   "    source = glyph_renderer.data_source\n",
   "    if source is None:\n",
   "    if not (hasattr(source, 'column_names') and label in source.column_names):\n",
   "    column = source.data[label]\n",
   "    vals, inds = np.unique(column, return_index=1)\n",
   "    for val, ind in zip(vals, inds):\n",
   "        label = value(str(val))\n",
   "        new_item = LegendItem(label=label, renderers=[glyph_renderer], index=ind)\n",
   "        legend.items.append(new_item)\n",
   "    if not isinstance(label, str):\n",
   "    label = value(label)\n",
   "    item = _find_legend_item(label, legend)\n",
   "    if item:\n",
   "        item.renderers.append(glyph_renderer)\n",
   "        new_item = LegendItem(label=label, renderers=[glyph_renderer])\n",
   "        legend.items.append(new_item)\n"
  ]
 },
 "116": {
  "name": "item",
  "type": "NoneType",
  "class": "unknown",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/plotting/_legends.py",
  "lineno": "133",
  "column": "4",
  "context": "e must be a string\")\n    label = value(label)\n    item = _find_legend_item(label, legend)\n    if item:\n        item.renderers.append(glyph_r",
  "context_lines": "def _handle_legend_label(label, legend, glyph_renderer):\n    if not isinstance(label, str):\n        raise ValueError(\"legend_label value must be a string\")\n    label = value(label)\n    item = _find_legend_item(label, legend)\n    if item:\n        item.renderers.append(glyph_renderer)\n    else:\n        new_item = LegendItem(label=label, renderers=[glyph_renderer])\n",
  "slicing": [
   "LEGEND_ARGS = ['legend', 'legend_label', 'legend_field', 'legend_group']\n",
   "    result = {attr: kwargs.pop(attr) for attr in LEGEND_ARGS if attr in kwargs}\n",
   "    if len(result) > 1:\n",
   "        raise ValueError(\"Only one of %s may be provided, got: %s\" % (nice_join(LEGEND_ARGS), nice_join(result.keys())))\n",
   "    return result\n",
   "    legend = _get_or_create_legend(plot)\n",
   "    kwarg, value = list(legend_kwarg.items())[0]\n",
   "    _LEGEND_KWARG_HANDLERS[kwarg](value, legend, glyph_renderer)\n",
   "def _find_legend_item(label, legend):\n",
   "    for item in legend.items:\n",
   "        if item.label == label:\n",
   "            return item\n",
   "    legends = plot.select(type=Legend)\n",
   "    if not legends:\n",
   "        legend = Legend()\n",
   "        plot.add_layout(legend)\n",
   "        return legend\n",
   "    if len(legends) == 1:\n",
   "        return legends[0]\n",
   "            label = label['field']\n",
   "            _handle_legend_field(label, legend, glyph_renderer)\n",
   "        elif \"value\" in label and len(label) == 1:\n",
   "            label = label['value']\n",
   "            _handle_legend_label(label, legend, glyph_renderer)\n",
   "            raise ValueError(\"Bad 'legend' parameter value: %s\" % label)\n",
   "        source = glyph_renderer.data_source\n",
   "        if source is not None and hasattr(source, 'column_names') and label in source.column_names:\n",
   "            _handle_legend_field(label, legend, glyph_renderer)\n",
   "            _handle_legend_label(label, legend, glyph_renderer)\n",
   "    if not isinstance(label, str):\n",
   "    label = field(label)\n",
   "    item = _find_legend_item(label, legend)\n",
   "    if item:\n",
   "        item.renderers.append(glyph_renderer)\n",
   "        new_item = LegendItem(label=label, renderers=[glyph_renderer])\n",
   "        legend.items.append(new_item)\n",
   "    if not isinstance(label, str):\n",
   "    source = glyph_renderer.data_source\n",
   "    if source is None:\n",
   "    if not (hasattr(source, 'column_names') and label in source.column_names):\n",
   "    column = source.data[label]\n",
   "    vals, inds = np.unique(column, return_index=1)\n",
   "    for val, ind in zip(vals, inds):\n",
   "        label = value(str(val))\n",
   "        new_item = LegendItem(label=label, renderers=[glyph_renderer], index=ind)\n",
   "        legend.items.append(new_item)\n",
   "    if not isinstance(label, str):\n",
   "    label = value(label)\n",
   "    item = _find_legend_item(label, legend)\n",
   "    if item:\n",
   "        item.renderers.append(glyph_renderer)\n",
   "        new_item = LegendItem(label=label, renderers=[glyph_renderer])\n",
   "        legend.items.append(new_item)\n"
  ]
 },
 "117": {
  "name": "default",
  "type": "bool|NoneType|bokeh.core.property.wrappers.PropertyValueList|list|int|str|dict|bokeh.core.property.wrappers.PropertyValueDict|float",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/_docstring.py",
  "lineno": "70",
  "column": "4",
  "context": "def _add_arglines(arglines, param, typ, doc):\n    default = param.default if param.default != Parameter.empty else None\n\n    # add a line for the arg\n    arglines.append(",
  "context_lines": "#-----------------------------------------------------------------------------\n# Private API\n#-----------------------------------------------------------------------------\n\ndef _add_arglines(arglines, param, typ, doc):\n    default = param.default if param.default != Parameter.empty else None\n\n    # add a line for the arg\n    arglines.append(f\"    {param.name} ({typ}{', optional' if default else ''}):\")\n\n    # add the docs for the argument\n",
  "slicing": [
   "    default = param.default if param.default != Parameter.empty else None\n",
   "    arglines.append(f\"    {param.name} ({typ}{', optional' if default else ''}):\")\n",
   "    if default is not None:\n",
   "        arglines.append(f\"\\n        (default: {default})\")\n"
  ]
 },
 "118": {
  "name": "module",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/_docstring.py",
  "lineno": "96",
  "column": "4",
  "context": "xtra_docs\n\ndef _docstring_header(glyphclass):\n    module = \"markers\" if issubclass(glyphclass, Marker) else \"glyphs\"\n    return f\"Configure and add :class:`~bokeh.mode",
  "context_lines": "    return \"\\n\".join(arglines)\n\ndef _docstring_extra(extra_docs):\n    return \"\" if extra_docs is None else extra_docs\n\ndef _docstring_header(glyphclass):\n    module = \"markers\" if issubclass(glyphclass, Marker) else \"glyphs\"\n    return f\"Configure and add :class:`~bokeh.models.{module}.{glyphclass.__name__}` glyphs to this Figure.\"\n\ndef _docstring_kwargs(parameters):\n    arglines = []\n    for param, typ, doc in (x for x in parameters if x[0].kind == Parameter.KEYWORD_ONLY):\n",
  "slicing": [
   "def _add_arglines(arglines, param, typ, doc):\n",
   "    default = param.default if param.default != Parameter.empty else None\n",
   "    arglines.append(f\"    {param.name} ({typ}{', optional' if default else ''}):\")\n",
   "        arglines += [f\"    {x}\" for x in doc.rstrip().strip(\"\\n\").split(\"\\n\")]\n",
   "    if default is not None:\n",
   "        arglines.append(f\"\\n        (default: {default})\")\n",
   "    arglines.append(\"\")\n",
   "    arglines = []\n",
   "    for param, typ, doc in (x for x in parameters if x[0].kind == Parameter.POSITIONAL_OR_KEYWORD):\n",
   "        _add_arglines(arglines, param, typ, doc)\n",
   "    return \"\\n\".join(arglines)\n",
   "    module = \"markers\" if issubclass(glyphclass, Marker) else \"glyphs\"\n",
   "    return f\"Configure and add :class:`~bokeh.models.{module}.{glyphclass.__name__}` glyphs to this Figure.\"\n",
   "    for param, typ, doc in (x for x in parameters if x[0].kind == Parameter.KEYWORD_ONLY):\n",
   "        _add_arglines(arglines, param, typ, doc)\n",
   "    return \"\\n\".join(arglines)\n"
  ]
 },
 "119": {
  "name": "__subtype__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "73",
  "column": "4",
  "context": "       :module: bokeh.plotting.gmap\n\n    '''\n\n    __subtype__ = \"GMap\"\n    __view_model__ = \"GMapPlot\"\n\n    def __init__(",
  "context_lines": "    help simplify configuration:\n\n    .. bokeh-options:: GMapFigureOptions\n        :module: bokeh.plotting.gmap\n\n    '''\n\n    __subtype__ = \"GMap\"\n    __view_model__ = \"GMapPlot\"\n\n    def __init__(self, **kw):\n\n        if 'plot_width' in kw and 'width' in kw:\n            raise ValueError(\"Figure called with both 'plot_width' and 'width' supplied, supply only one\")\n",
  "slicing": "    __subtype__ = \"GMap\"\n"
 },
 "120": {
  "name": "__view_model__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "74",
  "column": "4",
  "context": "tting.gmap\n\n    '''\n\n    __subtype__ = \"GMap\"\n    __view_model__ = \"GMapPlot\"\n\n    def __init__(self, **kw):\n\n        if 'plot_w",
  "context_lines": "    .. bokeh-options:: GMapFigureOptions\n        :module: bokeh.plotting.gmap\n\n    '''\n\n    __subtype__ = \"GMap\"\n    __view_model__ = \"GMapPlot\"\n\n    def __init__(self, **kw):\n\n        if 'plot_width' in kw and 'width' in kw:\n            raise ValueError(\"Figure called with both 'plot_width' and 'width' supplied, supply only one\")\n",
  "slicing": "    __view_model__ = \"GMapPlot\"\n"
 },
 "121": {
  "name": "annular_wedge",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "108",
  "column": "4",
  "context": "spect, opts.active_scroll, opts.active_tap)\n\n\n    annular_wedge = Figure.annular_wedge\n\n    annulus = Figure.annulus\n\n    arc = Figure.ar",
  "context_lines": "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n\n        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n        self.add_tools(*tool_objs)\n        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n\n\n    annular_wedge = Figure.annular_wedge\n\n    annulus = Figure.annulus\n\n    arc = Figure.arc\n\n    asterisk = Figure.asterisk\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    annular_wedge = Figure.annular_wedge\n"
  ]
 },
 "122": {
  "name": "annulus",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "110",
  "column": "4",
  "context": ")\n\n\n    annular_wedge = Figure.annular_wedge\n\n    annulus = Figure.annulus\n\n    arc = Figure.arc\n\n    asterisk = Figure.aster",
  "context_lines": "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n        self.add_tools(*tool_objs)\n        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n\n\n    annular_wedge = Figure.annular_wedge\n\n    annulus = Figure.annulus\n\n    arc = Figure.arc\n\n    asterisk = Figure.asterisk\n\n    bezier = Figure.bezier\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    annulus = Figure.annulus\n"
  ]
 },
 "123": {
  "name": "arc",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "112",
  "column": "4",
  "context": ".annular_wedge\n\n    annulus = Figure.annulus\n\n    arc = Figure.arc\n\n    asterisk = Figure.asterisk\n\n    bezier = Figu",
  "context_lines": "        self.add_tools(*tool_objs)\n        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n\n\n    annular_wedge = Figure.annular_wedge\n\n    annulus = Figure.annulus\n\n    arc = Figure.arc\n\n    asterisk = Figure.asterisk\n\n    bezier = Figure.bezier\n\n    circle = Figure.circle\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    arc = Figure.arc\n"
  ]
 },
 "124": {
  "name": "asterisk",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "114",
  "column": "4",
  "context": "nulus = Figure.annulus\n\n    arc = Figure.arc\n\n    asterisk = Figure.asterisk\n\n    bezier = Figure.bezier\n\n    circle = Figure.c",
  "context_lines": "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n\n\n    annular_wedge = Figure.annular_wedge\n\n    annulus = Figure.annulus\n\n    arc = Figure.arc\n\n    asterisk = Figure.asterisk\n\n    bezier = Figure.bezier\n\n    circle = Figure.circle\n\n    circle_cross = Figure.circle_cross\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    asterisk = Figure.asterisk\n"
  ]
 },
 "125": {
  "name": "bezier",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "116",
  "column": "4",
  "context": "= Figure.arc\n\n    asterisk = Figure.asterisk\n\n    bezier = Figure.bezier\n\n    circle = Figure.circle\n\n    circle_cross = Fi",
  "context_lines": "    annular_wedge = Figure.annular_wedge\n\n    annulus = Figure.annulus\n\n    arc = Figure.arc\n\n    asterisk = Figure.asterisk\n\n    bezier = Figure.bezier\n\n    circle = Figure.circle\n\n    circle_cross = Figure.circle_cross\n\n    circle_x = Figure.circle_x\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    bezier = Figure.bezier\n"
  ]
 },
 "126": {
  "name": "circle",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "118",
  "column": "4",
  "context": " Figure.asterisk\n\n    bezier = Figure.bezier\n\n    circle = Figure.circle\n\n    circle_cross = Figure.circle_cross\n\n    circl",
  "context_lines": "    annulus = Figure.annulus\n\n    arc = Figure.arc\n\n    asterisk = Figure.asterisk\n\n    bezier = Figure.bezier\n\n    circle = Figure.circle\n\n    circle_cross = Figure.circle_cross\n\n    circle_x = Figure.circle_x\n\n    cross = Figure.cross\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    circle = Figure.circle\n"
  ]
 },
 "127": {
  "name": "circle_cross",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "120",
  "column": "4",
  "context": " = Figure.bezier\n\n    circle = Figure.circle\n\n    circle_cross = Figure.circle_cross\n\n    circle_x = Figure.circle_x\n\n    cross = Figur",
  "context_lines": "    arc = Figure.arc\n\n    asterisk = Figure.asterisk\n\n    bezier = Figure.bezier\n\n    circle = Figure.circle\n\n    circle_cross = Figure.circle_cross\n\n    circle_x = Figure.circle_x\n\n    cross = Figure.cross\n\n    dash = Figure.dash\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    circle_cross = Figure.circle_cross\n"
  ]
 },
 "128": {
  "name": "circle_x",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "122",
  "column": "4",
  "context": "rcle\n\n    circle_cross = Figure.circle_cross\n\n    circle_x = Figure.circle_x\n\n    cross = Figure.cross\n\n    dash = Figure.dash\n",
  "context_lines": "    asterisk = Figure.asterisk\n\n    bezier = Figure.bezier\n\n    circle = Figure.circle\n\n    circle_cross = Figure.circle_cross\n\n    circle_x = Figure.circle_x\n\n    cross = Figure.cross\n\n    dash = Figure.dash\n\n    diamond = Figure.diamond\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    circle_x = Figure.circle_x\n"
  ]
 },
 "129": {
  "name": "cross",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "124",
  "column": "4",
  "context": "circle_cross\n\n    circle_x = Figure.circle_x\n\n    cross = Figure.cross\n\n    dash = Figure.dash\n\n    diamond = Figure.diam",
  "context_lines": "    bezier = Figure.bezier\n\n    circle = Figure.circle\n\n    circle_cross = Figure.circle_cross\n\n    circle_x = Figure.circle_x\n\n    cross = Figure.cross\n\n    dash = Figure.dash\n\n    diamond = Figure.diamond\n\n    diamond_cross = Figure.diamond_cross\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    cross = Figure.cross\n"
  ]
 },
 "130": {
  "name": "dash",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "126",
  "column": "4",
  "context": " = Figure.circle_x\n\n    cross = Figure.cross\n\n    dash = Figure.dash\n\n    diamond = Figure.diamond\n\n    diamond_cross =",
  "context_lines": "    circle = Figure.circle\n\n    circle_cross = Figure.circle_cross\n\n    circle_x = Figure.circle_x\n\n    cross = Figure.cross\n\n    dash = Figure.dash\n\n    diamond = Figure.diamond\n\n    diamond_cross = Figure.diamond_cross\n\n    graph = Figure.graph\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    dash = Figure.dash\n"
  ]
 },
 "131": {
  "name": "diamond",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "128",
  "column": "4",
  "context": "cross = Figure.cross\n\n    dash = Figure.dash\n\n    diamond = Figure.diamond\n\n    diamond_cross = Figure.diamond_cross\n\n    gra",
  "context_lines": "    circle_cross = Figure.circle_cross\n\n    circle_x = Figure.circle_x\n\n    cross = Figure.cross\n\n    dash = Figure.dash\n\n    diamond = Figure.diamond\n\n    diamond_cross = Figure.diamond_cross\n\n    graph = Figure.graph\n\n    harea = Figure.harea\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    diamond = Figure.diamond\n"
  ]
 },
 "132": {
  "name": "diamond_cross",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "130",
  "column": "4",
  "context": " = Figure.dash\n\n    diamond = Figure.diamond\n\n    diamond_cross = Figure.diamond_cross\n\n    graph = Figure.graph\n\n    harea = Figure.hare",
  "context_lines": "    circle_x = Figure.circle_x\n\n    cross = Figure.cross\n\n    dash = Figure.dash\n\n    diamond = Figure.diamond\n\n    diamond_cross = Figure.diamond_cross\n\n    graph = Figure.graph\n\n    harea = Figure.harea\n\n    harea_stack = Figure.harea_stack\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    diamond_cross = Figure.diamond_cross\n"
  ]
 },
 "133": {
  "name": "graph",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "132",
  "column": "4",
  "context": "nd\n\n    diamond_cross = Figure.diamond_cross\n\n    graph = Figure.graph\n\n    harea = Figure.harea\n\n    harea_stack = Figur",
  "context_lines": "    cross = Figure.cross\n\n    dash = Figure.dash\n\n    diamond = Figure.diamond\n\n    diamond_cross = Figure.diamond_cross\n\n    graph = Figure.graph\n\n    harea = Figure.harea\n\n    harea_stack = Figure.harea_stack\n\n    hbar = Figure.hbar\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    graph = Figure.graph\n"
  ]
 },
 "134": {
  "name": "harea",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "134",
  "column": "4",
  "context": "gure.diamond_cross\n\n    graph = Figure.graph\n\n    harea = Figure.harea\n\n    harea_stack = Figure.harea_stack\n\n    hbar = ",
  "context_lines": "    dash = Figure.dash\n\n    diamond = Figure.diamond\n\n    diamond_cross = Figure.diamond_cross\n\n    graph = Figure.graph\n\n    harea = Figure.harea\n\n    harea_stack = Figure.harea_stack\n\n    hbar = Figure.hbar\n\n    hbar_stack = Figure.hbar_stack\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    harea = Figure.harea\n"
  ]
 },
 "135": {
  "name": "harea_stack",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "136",
  "column": "4",
  "context": "aph = Figure.graph\n\n    harea = Figure.harea\n\n    harea_stack = Figure.harea_stack\n\n    hbar = Figure.hbar\n\n    hbar_stack = Figure.h",
  "context_lines": "    diamond = Figure.diamond\n\n    diamond_cross = Figure.diamond_cross\n\n    graph = Figure.graph\n\n    harea = Figure.harea\n\n    harea_stack = Figure.harea_stack\n\n    hbar = Figure.hbar\n\n    hbar_stack = Figure.hbar_stack\n\n    hline_stack = Figure.hline_stack\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    harea_stack = Figure.harea_stack\n"
  ]
 },
 "136": {
  "name": "hbar",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "138",
  "column": "4",
  "context": ".harea\n\n    harea_stack = Figure.harea_stack\n\n    hbar = Figure.hbar\n\n    hbar_stack = Figure.hbar_stack\n\n    hline_sta",
  "context_lines": "    diamond_cross = Figure.diamond_cross\n\n    graph = Figure.graph\n\n    harea = Figure.harea\n\n    harea_stack = Figure.harea_stack\n\n    hbar = Figure.hbar\n\n    hbar_stack = Figure.hbar_stack\n\n    hline_stack = Figure.hline_stack\n\n    ellipse = Figure.ellipse\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    hbar = Figure.hbar\n"
  ]
 },
 "137": {
  "name": "hbar_stack",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "140",
  "column": "4",
  "context": "= Figure.harea_stack\n\n    hbar = Figure.hbar\n\n    hbar_stack = Figure.hbar_stack\n\n    hline_stack = Figure.hline_stack\n\n    ellipse",
  "context_lines": "    graph = Figure.graph\n\n    harea = Figure.harea\n\n    harea_stack = Figure.harea_stack\n\n    hbar = Figure.hbar\n\n    hbar_stack = Figure.hbar_stack\n\n    hline_stack = Figure.hline_stack\n\n    ellipse = Figure.ellipse\n\n    hex = Figure.hex\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    hbar_stack = Figure.hbar_stack\n"
  ]
 },
 "138": {
  "name": "hline_stack",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "142",
  "column": "4",
  "context": "ure.hbar\n\n    hbar_stack = Figure.hbar_stack\n\n    hline_stack = Figure.hline_stack\n\n    ellipse = Figure.ellipse\n\n    hex = Figure.he",
  "context_lines": "    harea = Figure.harea\n\n    harea_stack = Figure.harea_stack\n\n    hbar = Figure.hbar\n\n    hbar_stack = Figure.hbar_stack\n\n    hline_stack = Figure.hline_stack\n\n    ellipse = Figure.ellipse\n\n    hex = Figure.hex\n\n    hexbin = Figure.hexbin\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    hline_stack = Figure.hline_stack\n"
  ]
 },
 "139": {
  "name": "ellipse",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "144",
  "column": "4",
  "context": "_stack\n\n    hline_stack = Figure.hline_stack\n\n    ellipse = Figure.ellipse\n\n    hex = Figure.hex\n\n    hexbin = Figure.hexbin\n",
  "context_lines": "    harea_stack = Figure.harea_stack\n\n    hbar = Figure.hbar\n\n    hbar_stack = Figure.hbar_stack\n\n    hline_stack = Figure.hline_stack\n\n    ellipse = Figure.ellipse\n\n    hex = Figure.hex\n\n    hexbin = Figure.hexbin\n\n    hex_tile = Figure.hex_tile\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    ellipse = Figure.ellipse\n"
  ]
 },
 "140": {
  "name": "hex",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "146",
  "column": "4",
  "context": "re.hline_stack\n\n    ellipse = Figure.ellipse\n\n    hex = Figure.hex\n\n    hexbin = Figure.hexbin\n\n    hex_tile = Figure",
  "context_lines": "    hbar = Figure.hbar\n\n    hbar_stack = Figure.hbar_stack\n\n    hline_stack = Figure.hline_stack\n\n    ellipse = Figure.ellipse\n\n    hex = Figure.hex\n\n    hexbin = Figure.hexbin\n\n    hex_tile = Figure.hex_tile\n\n    image = Figure.image\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    hex = Figure.hex\n"
  ]
 },
 "141": {
  "name": "hexbin",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "148",
  "column": "4",
  "context": "lipse = Figure.ellipse\n\n    hex = Figure.hex\n\n    hexbin = Figure.hexbin\n\n    hex_tile = Figure.hex_tile\n\n    image = Figur",
  "context_lines": "    hbar_stack = Figure.hbar_stack\n\n    hline_stack = Figure.hline_stack\n\n    ellipse = Figure.ellipse\n\n    hex = Figure.hex\n\n    hexbin = Figure.hexbin\n\n    hex_tile = Figure.hex_tile\n\n    image = Figure.image\n\n    image_rgba = Figure.image_rgba\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    hexbin = Figure.hexbin\n"
  ]
 },
 "142": {
  "name": "hex_tile",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "150",
  "column": "4",
  "context": "hex = Figure.hex\n\n    hexbin = Figure.hexbin\n\n    hex_tile = Figure.hex_tile\n\n    image = Figure.image\n\n    image_rgba = Figure",
  "context_lines": "    hline_stack = Figure.hline_stack\n\n    ellipse = Figure.ellipse\n\n    hex = Figure.hex\n\n    hexbin = Figure.hexbin\n\n    hex_tile = Figure.hex_tile\n\n    image = Figure.image\n\n    image_rgba = Figure.image_rgba\n\n    image_url = Figure.image_url\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    hex_tile = Figure.hex_tile\n"
  ]
 },
 "143": {
  "name": "image",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "152",
  "column": "4",
  "context": "igure.hexbin\n\n    hex_tile = Figure.hex_tile\n\n    image = Figure.image\n\n    image_rgba = Figure.image_rgba\n\n    image_url",
  "context_lines": "    ellipse = Figure.ellipse\n\n    hex = Figure.hex\n\n    hexbin = Figure.hexbin\n\n    hex_tile = Figure.hex_tile\n\n    image = Figure.image\n\n    image_rgba = Figure.image_rgba\n\n    image_url = Figure.image_url\n\n    inverted_triangle = Figure.inverted_triangle\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    image = Figure.image\n"
  ]
 },
 "144": {
  "name": "image_rgba",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "154",
  "column": "4",
  "context": " = Figure.hex_tile\n\n    image = Figure.image\n\n    image_rgba = Figure.image_rgba\n\n    image_url = Figure.image_url\n\n    inverted_tr",
  "context_lines": "    hex = Figure.hex\n\n    hexbin = Figure.hexbin\n\n    hex_tile = Figure.hex_tile\n\n    image = Figure.image\n\n    image_rgba = Figure.image_rgba\n\n    image_url = Figure.image_url\n\n    inverted_triangle = Figure.inverted_triangle\n\n    line = Figure.line\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    image_rgba = Figure.image_rgba\n"
  ]
 },
 "145": {
  "name": "image_url",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "156",
  "column": "4",
  "context": "re.image\n\n    image_rgba = Figure.image_rgba\n\n    image_url = Figure.image_url\n\n    inverted_triangle = Figure.inverted_triangle\n",
  "context_lines": "    hexbin = Figure.hexbin\n\n    hex_tile = Figure.hex_tile\n\n    image = Figure.image\n\n    image_rgba = Figure.image_rgba\n\n    image_url = Figure.image_url\n\n    inverted_triangle = Figure.inverted_triangle\n\n    line = Figure.line\n\n    multi_line = Figure.multi_line\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    image_url = Figure.image_url\n"
  ]
 },
 "146": {
  "name": "inverted_triangle",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "158",
  "column": "4",
  "context": "image_rgba\n\n    image_url = Figure.image_url\n\n    inverted_triangle = Figure.inverted_triangle\n\n    line = Figure.line\n\n    multi_line = Figure.m",
  "context_lines": "    hex_tile = Figure.hex_tile\n\n    image = Figure.image\n\n    image_rgba = Figure.image_rgba\n\n    image_url = Figure.image_url\n\n    inverted_triangle = Figure.inverted_triangle\n\n    line = Figure.line\n\n    multi_line = Figure.multi_line\n\n    multi_polygons = Figure.multi_polygons\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    inverted_triangle = Figure.inverted_triangle\n"
  ]
 },
 "147": {
  "name": "line",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "160",
  "column": "4",
  "context": "inverted_triangle = Figure.inverted_triangle\n\n    line = Figure.line\n\n    multi_line = Figure.multi_line\n\n    multi_pol",
  "context_lines": "    image = Figure.image\n\n    image_rgba = Figure.image_rgba\n\n    image_url = Figure.image_url\n\n    inverted_triangle = Figure.inverted_triangle\n\n    line = Figure.line\n\n    multi_line = Figure.multi_line\n\n    multi_polygons = Figure.multi_polygons\n\n    oval = Figure.oval\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    line = Figure.line\n"
  ]
 },
 "148": {
  "name": "multi_line",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "162",
  "column": "4",
  "context": "re.inverted_triangle\n\n    line = Figure.line\n\n    multi_line = Figure.multi_line\n\n    multi_polygons = Figure.multi_polygons\n\n    o",
  "context_lines": "    image_rgba = Figure.image_rgba\n\n    image_url = Figure.image_url\n\n    inverted_triangle = Figure.inverted_triangle\n\n    line = Figure.line\n\n    multi_line = Figure.multi_line\n\n    multi_polygons = Figure.multi_polygons\n\n    oval = Figure.oval\n\n    patch = Figure.patch\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    multi_line = Figure.multi_line\n"
  ]
 },
 "149": {
  "name": "multi_polygons",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "164",
  "column": "4",
  "context": "ure.line\n\n    multi_line = Figure.multi_line\n\n    multi_polygons = Figure.multi_polygons\n\n    oval = Figure.oval\n\n    patch = Figure.patch\n",
  "context_lines": "    image_url = Figure.image_url\n\n    inverted_triangle = Figure.inverted_triangle\n\n    line = Figure.line\n\n    multi_line = Figure.multi_line\n\n    multi_polygons = Figure.multi_polygons\n\n    oval = Figure.oval\n\n    patch = Figure.patch\n\n    patches = Figure.patches\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    multi_polygons = Figure.multi_polygons\n"
  ]
 },
 "150": {
  "name": "oval",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "166",
  "column": "4",
  "context": "\n\n    multi_polygons = Figure.multi_polygons\n\n    oval = Figure.oval\n\n    patch = Figure.patch\n\n    patches = Figure.pa",
  "context_lines": "    inverted_triangle = Figure.inverted_triangle\n\n    line = Figure.line\n\n    multi_line = Figure.multi_line\n\n    multi_polygons = Figure.multi_polygons\n\n    oval = Figure.oval\n\n    patch = Figure.patch\n\n    patches = Figure.patches\n\n    quad = Figure.quad\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    oval = Figure.oval\n"
  ]
 },
 "151": {
  "name": "patch",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "168",
  "column": "4",
  "context": "igure.multi_polygons\n\n    oval = Figure.oval\n\n    patch = Figure.patch\n\n    patches = Figure.patches\n\n    quad = Figure.q",
  "context_lines": "    line = Figure.line\n\n    multi_line = Figure.multi_line\n\n    multi_polygons = Figure.multi_polygons\n\n    oval = Figure.oval\n\n    patch = Figure.patch\n\n    patches = Figure.patches\n\n    quad = Figure.quad\n\n    quadratic = Figure.quadratic\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    patch = Figure.patch\n"
  ]
 },
 "152": {
  "name": "patches",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "170",
  "column": "4",
  "context": "oval = Figure.oval\n\n    patch = Figure.patch\n\n    patches = Figure.patches\n\n    quad = Figure.quad\n\n    quadratic = Figure.qu",
  "context_lines": "    multi_line = Figure.multi_line\n\n    multi_polygons = Figure.multi_polygons\n\n    oval = Figure.oval\n\n    patch = Figure.patch\n\n    patches = Figure.patches\n\n    quad = Figure.quad\n\n    quadratic = Figure.quadratic\n\n    ray = Figure.ray\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    patches = Figure.patches\n"
  ]
 },
 "153": {
  "name": "quad",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "172",
  "column": "4",
  "context": "= Figure.patch\n\n    patches = Figure.patches\n\n    quad = Figure.quad\n\n    quadratic = Figure.quadratic\n\n    ray = Figur",
  "context_lines": "    multi_polygons = Figure.multi_polygons\n\n    oval = Figure.oval\n\n    patch = Figure.patch\n\n    patches = Figure.patches\n\n    quad = Figure.quad\n\n    quadratic = Figure.quadratic\n\n    ray = Figure.ray\n\n    rect = Figure.rect\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    quad = Figure.quad\n"
  ]
 },
 "154": {
  "name": "quadratic",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "174",
  "column": "4",
  "context": "hes = Figure.patches\n\n    quad = Figure.quad\n\n    quadratic = Figure.quadratic\n\n    ray = Figure.ray\n\n    rect = Figure.rect\n\n   ",
  "context_lines": "    oval = Figure.oval\n\n    patch = Figure.patch\n\n    patches = Figure.patches\n\n    quad = Figure.quad\n\n    quadratic = Figure.quadratic\n\n    ray = Figure.ray\n\n    rect = Figure.rect\n\n    step = Figure.step\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    quadratic = Figure.quadratic\n"
  ]
 },
 "155": {
  "name": "ray",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "176",
  "column": "4",
  "context": "igure.quad\n\n    quadratic = Figure.quadratic\n\n    ray = Figure.ray\n\n    rect = Figure.rect\n\n    step = Figure.step\n\n ",
  "context_lines": "    patch = Figure.patch\n\n    patches = Figure.patches\n\n    quad = Figure.quad\n\n    quadratic = Figure.quadratic\n\n    ray = Figure.ray\n\n    rect = Figure.rect\n\n    step = Figure.step\n\n    scatter = Figure.scatter\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    ray = Figure.ray\n"
  ]
 },
 "156": {
  "name": "rect",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "178",
  "column": "4",
  "context": "tic = Figure.quadratic\n\n    ray = Figure.ray\n\n    rect = Figure.rect\n\n    step = Figure.step\n\n    scatter = Figure.scat",
  "context_lines": "    patches = Figure.patches\n\n    quad = Figure.quad\n\n    quadratic = Figure.quadratic\n\n    ray = Figure.ray\n\n    rect = Figure.rect\n\n    step = Figure.step\n\n    scatter = Figure.scatter\n\n    segment = Figure.segment\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    rect = Figure.rect\n"
  ]
 },
 "157": {
  "name": "step",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "180",
  "column": "4",
  "context": "    ray = Figure.ray\n\n    rect = Figure.rect\n\n    step = Figure.step\n\n    scatter = Figure.scatter\n\n    segment = Figur",
  "context_lines": "    quad = Figure.quad\n\n    quadratic = Figure.quadratic\n\n    ray = Figure.ray\n\n    rect = Figure.rect\n\n    step = Figure.step\n\n    scatter = Figure.scatter\n\n    segment = Figure.segment\n\n    square = Figure.square\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    step = Figure.step\n"
  ]
 },
 "158": {
  "name": "scatter",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "182",
  "column": "4",
  "context": "  rect = Figure.rect\n\n    step = Figure.step\n\n    scatter = Figure.scatter\n\n    segment = Figure.segment\n\n    square = Figure",
  "context_lines": "    quadratic = Figure.quadratic\n\n    ray = Figure.ray\n\n    rect = Figure.rect\n\n    step = Figure.step\n\n    scatter = Figure.scatter\n\n    segment = Figure.segment\n\n    square = Figure.square\n\n    square_cross = Figure.square_cross\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    scatter = Figure.scatter\n"
  ]
 },
 "159": {
  "name": "segment",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "184",
  "column": "4",
  "context": " = Figure.step\n\n    scatter = Figure.scatter\n\n    segment = Figure.segment\n\n    square = Figure.square\n\n    square_cross = Fi",
  "context_lines": "    ray = Figure.ray\n\n    rect = Figure.rect\n\n    step = Figure.step\n\n    scatter = Figure.scatter\n\n    segment = Figure.segment\n\n    square = Figure.square\n\n    square_cross = Figure.square_cross\n\n    square_x = Figure.square_x\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    segment = Figure.segment\n"
  ]
 },
 "160": {
  "name": "square",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "186",
  "column": "4",
  "context": "Figure.scatter\n\n    segment = Figure.segment\n\n    square = Figure.square\n\n    square_cross = Figure.square_cross\n\n    squar",
  "context_lines": "    rect = Figure.rect\n\n    step = Figure.step\n\n    scatter = Figure.scatter\n\n    segment = Figure.segment\n\n    square = Figure.square\n\n    square_cross = Figure.square_cross\n\n    square_x = Figure.square_x\n\n    text = Figure.text\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    square = Figure.square\n"
  ]
 },
 "161": {
  "name": "square_cross",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "188",
  "column": "4",
  "context": "= Figure.segment\n\n    square = Figure.square\n\n    square_cross = Figure.square_cross\n\n    square_x = Figure.square_x\n\n    text = Figure",
  "context_lines": "    step = Figure.step\n\n    scatter = Figure.scatter\n\n    segment = Figure.segment\n\n    square = Figure.square\n\n    square_cross = Figure.square_cross\n\n    square_x = Figure.square_x\n\n    text = Figure.text\n\n    triangle = Figure.triangle\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    square_cross = Figure.square_cross\n"
  ]
 },
 "162": {
  "name": "square_x",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "190",
  "column": "4",
  "context": "uare\n\n    square_cross = Figure.square_cross\n\n    square_x = Figure.square_x\n\n    text = Figure.text\n\n    triangle = Figure.tri",
  "context_lines": "    scatter = Figure.scatter\n\n    segment = Figure.segment\n\n    square = Figure.square\n\n    square_cross = Figure.square_cross\n\n    square_x = Figure.square_x\n\n    text = Figure.text\n\n    triangle = Figure.triangle\n\n    varea = Figure.varea\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    square_x = Figure.square_x\n"
  ]
 },
 "163": {
  "name": "text",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "192",
  "column": "4",
  "context": "square_cross\n\n    square_x = Figure.square_x\n\n    text = Figure.text\n\n    triangle = Figure.triangle\n\n    varea = Figur",
  "context_lines": "    segment = Figure.segment\n\n    square = Figure.square\n\n    square_cross = Figure.square_cross\n\n    square_x = Figure.square_x\n\n    text = Figure.text\n\n    triangle = Figure.triangle\n\n    varea = Figure.varea\n\n    varea_stack = Figure.varea_stack\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    text = Figure.text\n"
  ]
 },
 "164": {
  "name": "triangle",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "194",
  "column": "4",
  "context": "_x = Figure.square_x\n\n    text = Figure.text\n\n    triangle = Figure.triangle\n\n    varea = Figure.varea\n\n    varea_stack = Figur",
  "context_lines": "    square = Figure.square\n\n    square_cross = Figure.square_cross\n\n    square_x = Figure.square_x\n\n    text = Figure.text\n\n    triangle = Figure.triangle\n\n    varea = Figure.varea\n\n    varea_stack = Figure.varea_stack\n\n    vbar = Figure.vbar\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    triangle = Figure.triangle\n"
  ]
 },
 "165": {
  "name": "varea",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "196",
  "column": "4",
  "context": " Figure.text\n\n    triangle = Figure.triangle\n\n    varea = Figure.varea\n\n    varea_stack = Figure.varea_stack\n\n    vbar = ",
  "context_lines": "    square_cross = Figure.square_cross\n\n    square_x = Figure.square_x\n\n    text = Figure.text\n\n    triangle = Figure.triangle\n\n    varea = Figure.varea\n\n    varea_stack = Figure.varea_stack\n\n    vbar = Figure.vbar\n\n    vbar_stack = Figure.vbar_stack\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    varea = Figure.varea\n"
  ]
 },
 "166": {
  "name": "varea_stack",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "198",
  "column": "4",
  "context": " = Figure.triangle\n\n    varea = Figure.varea\n\n    varea_stack = Figure.varea_stack\n\n    vbar = Figure.vbar\n\n    vbar_stack = Figure.v",
  "context_lines": "    square_x = Figure.square_x\n\n    text = Figure.text\n\n    triangle = Figure.triangle\n\n    varea = Figure.varea\n\n    varea_stack = Figure.varea_stack\n\n    vbar = Figure.vbar\n\n    vbar_stack = Figure.vbar_stack\n\n    vline_stack = Figure.vline_stack\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    varea_stack = Figure.varea_stack\n"
  ]
 },
 "167": {
  "name": "vbar",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "200",
  "column": "4",
  "context": ".varea\n\n    varea_stack = Figure.varea_stack\n\n    vbar = Figure.vbar\n\n    vbar_stack = Figure.vbar_stack\n\n    vline_sta",
  "context_lines": "    text = Figure.text\n\n    triangle = Figure.triangle\n\n    varea = Figure.varea\n\n    varea_stack = Figure.varea_stack\n\n    vbar = Figure.vbar\n\n    vbar_stack = Figure.vbar_stack\n\n    vline_stack = Figure.vline_stack\n\n    wedge = Figure.wedge\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    vbar = Figure.vbar\n"
  ]
 },
 "168": {
  "name": "vbar_stack",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "202",
  "column": "4",
  "context": "= Figure.varea_stack\n\n    vbar = Figure.vbar\n\n    vbar_stack = Figure.vbar_stack\n\n    vline_stack = Figure.vline_stack\n\n    wedge =",
  "context_lines": "    triangle = Figure.triangle\n\n    varea = Figure.varea\n\n    varea_stack = Figure.varea_stack\n\n    vbar = Figure.vbar\n\n    vbar_stack = Figure.vbar_stack\n\n    vline_stack = Figure.vline_stack\n\n    wedge = Figure.wedge\n\n    x = Figure.x\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    vbar_stack = Figure.vbar_stack\n"
  ]
 },
 "169": {
  "name": "vline_stack",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "204",
  "column": "4",
  "context": "ure.vbar\n\n    vbar_stack = Figure.vbar_stack\n\n    vline_stack = Figure.vline_stack\n\n    wedge = Figure.wedge\n\n    x = Figure.x\n\ndef g",
  "context_lines": "    varea = Figure.varea\n\n    varea_stack = Figure.varea_stack\n\n    vbar = Figure.vbar\n\n    vbar_stack = Figure.vbar_stack\n\n    vline_stack = Figure.vline_stack\n\n    wedge = Figure.wedge\n\n    x = Figure.x\n\ndef gmap(google_api_key, map_options, **kwargs):\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    vline_stack = Figure.vline_stack\n"
  ]
 },
 "170": {
  "name": "wedge",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "206",
  "column": "4",
  "context": "_stack\n\n    vline_stack = Figure.vline_stack\n\n    wedge = Figure.wedge\n\n    x = Figure.x\n\ndef gmap(google_api_key, map_op",
  "context_lines": "    varea_stack = Figure.varea_stack\n\n    vbar = Figure.vbar\n\n    vbar_stack = Figure.vbar_stack\n\n    vline_stack = Figure.vline_stack\n\n    wedge = Figure.wedge\n\n    x = Figure.x\n\ndef gmap(google_api_key, map_options, **kwargs):\n    ''' Create a new :class:`~bokeh.plotting.gmap.GMap` for plotting.\n\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    wedge = Figure.wedge\n"
  ]
 },
 "171": {
  "name": "x",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/gmap.py",
  "lineno": "208",
  "column": "4",
  "context": "Figure.vline_stack\n\n    wedge = Figure.wedge\n\n    x = Figure.x\n\ndef gmap(google_api_key, map_options, **kwargs):\n",
  "context_lines": "    vbar = Figure.vbar\n\n    vbar_stack = Figure.vbar_stack\n\n    vline_stack = Figure.vline_stack\n\n    wedge = Figure.wedge\n\n    x = Figure.x\n\ndef gmap(google_api_key, map_options, **kwargs):\n    ''' Create a new :class:`~bokeh.plotting.gmap.GMap` for plotting.\n\n    Args:\n",
  "slicing": [
   "        opts = GMapFigureOptions(kw)\n",
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n",
   "        xf = MercatorTickFormatter(dimension=\"lon\")\n",
   "        xt = MercatorTicker(dimension=\"lon\")\n",
   "        self.add_layout(LinearAxis(formatter=xf, ticker=xt), 'below')\n",
   "        yf = MercatorTickFormatter(dimension=\"lat\")\n",
   "        yt = MercatorTicker(dimension=\"lat\")\n",
   "        self.add_layout(LinearAxis(formatter=yf, ticker=yt), 'left')\n",
   "        tool_objs, tool_map = process_tools_arg(self, opts.tools)\n",
   "        self.add_tools(*tool_objs)\n",
   "        process_active_tools(self.toolbar, tool_map, opts.active_drag, opts.active_inspect, opts.active_scroll, opts.active_tap)\n",
   "    x = Figure.x\n"
  ]
 },
 "172": {
  "name": "__subtype__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/figure.py",
  "lineno": "145",
  "column": "4",
  "context": "     :module: bokeh.plotting.figure\n\n    '''\n\n    __subtype__ = \"Figure\"\n    __view_model__ = \"Plot\"\n\n    def __init__(self",
  "context_lines": "    options are also accepted:\n\n    .. bokeh-options:: FigureOptions\n        :module: bokeh.plotting.figure\n\n    '''\n\n    __subtype__ = \"Figure\"\n    __view_model__ = \"Plot\"\n\n    def __init__(self, *arg, **kw):\n\n        if 'plot_width' in kw and 'width' in kw:\n            raise ValueError(\"Figure called with both 'plot_width' and 'width' supplied, supply only one\")\n",
  "slicing": "    __subtype__ = \"Figure\"\n"
 },
 "173": {
  "name": "__view_model__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/figure.py",
  "lineno": "146",
  "column": "4",
  "context": "g.figure\n\n    '''\n\n    __subtype__ = \"Figure\"\n    __view_model__ = \"Plot\"\n\n    def __init__(self, *arg, **kw):\n\n        if '",
  "context_lines": "    .. bokeh-options:: FigureOptions\n        :module: bokeh.plotting.figure\n\n    '''\n\n    __subtype__ = \"Figure\"\n    __view_model__ = \"Plot\"\n\n    def __init__(self, *arg, **kw):\n\n        if 'plot_width' in kw and 'width' in kw:\n            raise ValueError(\"Figure called with both 'plot_width' and 'width' supplied, supply only one\")\n",
  "slicing": "    __view_model__ = \"Plot\"\n"
 },
 "174": {
  "name": "title",
  "type": "NoneType",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/figure.py",
  "lineno": "161",
  "column": "8",
  "context": "idth')\n\n        opts = FigureOptions(kw)\n\n        title = kw.get(\"title\", None)\n        if isinstance(title, str):\n            kw[",
  "context_lines": "            kw['plot_height'] = kw.pop('height')\n        if 'width' in kw:\n            kw['plot_width'] = kw.pop('width')\n\n        opts = FigureOptions(kw)\n\n        title = kw.get(\"title\", None)\n        if isinstance(title, str):\n            kw['title'] = Title(text=title)\n\n        super().__init__(*arg, **kw)\n\n        self.x_range = get_range(opts.x_range)\n",
  "slicing": [
   "        title = kw.get(\"title\", None)\n",
   "        if isinstance(title, str):\n",
   "            kw['title'] = Title(text=title)\n"
  ]
 },
 "175": {
  "name": "parameters",
  "type": "list",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/plotting/_decorators.py",
  "lineno": "44",
  "column": "8",
  "context": "hod(glyphclass):\n    def decorator(func):\n        parameters = glyphclass.parameters()\n\n        sigparams = [Parameter(\"self\", Parameter.",
  "context_lines": "# Dev API\n#-----------------------------------------------------------------------------\n\ndef glyph_method(glyphclass):\n    def decorator(func):\n        parameters = glyphclass.parameters()\n\n        sigparams = [Parameter(\"self\", Parameter.POSITIONAL_OR_KEYWORD)] + [x[0] for x in parameters] + [Parameter(\"kwargs\", Parameter.VAR_KEYWORD)]\n\n        @wraps(func)\n        def wrapped(self, *args, **kwargs):\n",
  "slicing": [
   "        parameters = glyphclass.parameters()\n",
   "        sigparams = [Parameter(\"self\", Parameter.POSITIONAL_OR_KEYWORD)] + [x[0] for x in parameters] + [Parameter(\"kwargs\", Parameter.VAR_KEYWORD)]\n",
   "            for arg, param in zip(args, sigparams[1:]):\n",
   "                kwargs[param.name] = arg\n",
   "        wrapped.__signature__ = Signature(parameters=sigparams)\n",
   "        wrapped.__doc__ = generate_docstring(glyphclass, parameters, func.__doc__)\n"
  ]
 },
 "176": {
  "name": "axiscls",
  "type": "MetaHasProps",
  "class": "customized",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/plotting/_plot.py",
  "lineno": "94",
  "column": "4",
  "context": "location, minor_ticks, axis_label, rng, dim):\n    axiscls, axiskw = _get_axis_class(axis_type, rng, dim)\n\n    if axiscls:\n        axis = axiscls(**axiskw)\n",
  "context_lines": "        return CategoricalScale()\n    else:\n        raise ValueError(\"Unable to determine proper scale for: '%s'\" % str(range_input))\n\ndef process_axis_and_grid(plot, axis_type, axis_location, minor_ticks, axis_label, rng, dim):\n    axiscls, axiskw = _get_axis_class(axis_type, rng, dim)\n\n    if axiscls:\n        axis = axiscls(**axiskw)\n\n        if isinstance(axis.ticker, ContinuousTicker):\n",
  "slicing": [
   "pd = import_optional('pandas')\n",
   "    if pd and isinstance(range_input, pd.core.groupby.GroupBy):\n",
   "    if pd and isinstance(range_input, pd.Series):\n",
   "        range_input = range_input.values\n",
   "    if isinstance(range_input, (Sequence, np.ndarray)):\n",
   "        if all(isinstance(x, str) for x in range_input):\n",
   "            return FactorRange(factors=list(range_input))\n",
   "        if len(range_input) == 2:\n",
   "                return Range1d(start=range_input[0], end=range_input[1])\n",
   "    raise ValueError(\"Unrecognized range input: '%s'\" % str(range_input))\n",
   "    if isinstance(range_input, (DataRange1d, Range1d)) and axis_type in [\"linear\", \"datetime\", \"mercator\", \"auto\", None]:\n",
   "    elif isinstance(range_input, (DataRange1d, Range1d)) and axis_type == \"log\":\n",
   "    elif isinstance(range_input, FactorRange):\n",
   "        raise ValueError(\"Unable to determine proper scale for: '%s'\" % str(range_input))\n",
   "    axiscls, axiskw = _get_axis_class(axis_type, rng, dim)\n",
   "    if axiscls:\n",
   "        axis = axiscls(**axiskw)\n",
   "        if isinstance(axis.ticker, ContinuousTicker):\n",
   "            axis.ticker.num_minor_ticks = _get_num_minor_ticks(axiscls, minor_ticks)\n",
   "            axis.axis_label = axis_label\n",
   "        grid = Grid(dimension=dim, axis=axis)\n",
   "        plot.add_layout(grid, \"center\")\n",
   "            getattr(plot, axis_location).append(axis)\n",
   "        if isinstance(range_input, FactorRange):\n",
   "        elif isinstance(range_input, Range1d):\n",
   "                value = range_input.start\n",
   "                if Datetime.is_timestamp(value):\n",
   "                Datetime.validate(Datetime(), value)\n"
  ]
 },
 "177": {
  "name": "axiskw",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/plotting/_plot.py",
  "lineno": "94",
  "column": "13",
  "context": " minor_ticks, axis_label, rng, dim):\n    axiscls, axiskw = _get_axis_class(axis_type, rng, dim)\n\n    if axiscls:\n        axis = axiscls(**axiskw)\n",
  "context_lines": "        return CategoricalScale()\n    else:\n        raise ValueError(\"Unable to determine proper scale for: '%s'\" % str(range_input))\n\ndef process_axis_and_grid(plot, axis_type, axis_location, minor_ticks, axis_label, rng, dim):\n    axiscls, axiskw = _get_axis_class(axis_type, rng, dim)\n\n    if axiscls:\n        axis = axiscls(**axiskw)\n\n        if isinstance(axis.ticker, ContinuousTicker):\n",
  "slicing": [
   "pd = import_optional('pandas')\n",
   "    if pd and isinstance(range_input, pd.core.groupby.GroupBy):\n",
   "    if pd and isinstance(range_input, pd.Series):\n",
   "        range_input = range_input.values\n",
   "    if isinstance(range_input, (Sequence, np.ndarray)):\n",
   "        if all(isinstance(x, str) for x in range_input):\n",
   "            return FactorRange(factors=list(range_input))\n",
   "        if len(range_input) == 2:\n",
   "                return Range1d(start=range_input[0], end=range_input[1])\n",
   "    raise ValueError(\"Unrecognized range input: '%s'\" % str(range_input))\n",
   "    if isinstance(range_input, (DataRange1d, Range1d)) and axis_type in [\"linear\", \"datetime\", \"mercator\", \"auto\", None]:\n",
   "    elif isinstance(range_input, (DataRange1d, Range1d)) and axis_type == \"log\":\n",
   "    elif isinstance(range_input, FactorRange):\n",
   "        raise ValueError(\"Unable to determine proper scale for: '%s'\" % str(range_input))\n",
   "    axiscls, axiskw = _get_axis_class(axis_type, rng, dim)\n",
   "    if axiscls:\n",
   "        axis = axiscls(**axiskw)\n",
   "        if isinstance(axis.ticker, ContinuousTicker):\n",
   "            axis.ticker.num_minor_ticks = _get_num_minor_ticks(axiscls, minor_ticks)\n",
   "            axis.axis_label = axis_label\n",
   "        grid = Grid(dimension=dim, axis=axis)\n",
   "        plot.add_layout(grid, \"center\")\n",
   "            getattr(plot, axis_location).append(axis)\n",
   "        if isinstance(range_input, FactorRange):\n",
   "        elif isinstance(range_input, Range1d):\n",
   "                value = range_input.start\n",
   "                if Datetime.is_timestamp(value):\n",
   "                Datetime.validate(Datetime(), value)\n"
  ]
 },
 "178": {
  "name": "axis",
  "type": "LinearAxis",
  "class": "customized",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/plotting/_plot.py",
  "lineno": "97",
  "column": "8",
  "context": "ass(axis_type, rng, dim)\n\n    if axiscls:\n        axis = axiscls(**axiskw)\n\n        if isinstance(axis.ticker, ContinuousTick",
  "context_lines": "        raise ValueError(\"Unable to determine proper scale for: '%s'\" % str(range_input))\n\ndef process_axis_and_grid(plot, axis_type, axis_location, minor_ticks, axis_label, rng, dim):\n    axiscls, axiskw = _get_axis_class(axis_type, rng, dim)\n\n    if axiscls:\n        axis = axiscls(**axiskw)\n\n        if isinstance(axis.ticker, ContinuousTicker):\n            axis.ticker.num_minor_ticks = _get_num_minor_ticks(axiscls, minor_ticks)\n\n        if axis_label:\n",
  "slicing": [
   "pd = import_optional('pandas')\n",
   "    if pd and isinstance(range_input, pd.core.groupby.GroupBy):\n",
   "    if pd and isinstance(range_input, pd.Series):\n",
   "        range_input = range_input.values\n",
   "    if isinstance(range_input, (Sequence, np.ndarray)):\n",
   "        if all(isinstance(x, str) for x in range_input):\n",
   "            return FactorRange(factors=list(range_input))\n",
   "        if len(range_input) == 2:\n",
   "                return Range1d(start=range_input[0], end=range_input[1])\n",
   "    raise ValueError(\"Unrecognized range input: '%s'\" % str(range_input))\n",
   "    if isinstance(range_input, (DataRange1d, Range1d)) and axis_type in [\"linear\", \"datetime\", \"mercator\", \"auto\", None]:\n",
   "    elif isinstance(range_input, (DataRange1d, Range1d)) and axis_type == \"log\":\n",
   "    elif isinstance(range_input, FactorRange):\n",
   "        raise ValueError(\"Unable to determine proper scale for: '%s'\" % str(range_input))\n",
   "    axiscls, axiskw = _get_axis_class(axis_type, rng, dim)\n",
   "    if axiscls:\n",
   "        axis = axiscls(**axiskw)\n",
   "        if isinstance(axis.ticker, ContinuousTicker):\n",
   "            axis.ticker.num_minor_ticks = _get_num_minor_ticks(axiscls, minor_ticks)\n",
   "            axis.axis_label = axis_label\n",
   "        grid = Grid(dimension=dim, axis=axis)\n",
   "        plot.add_layout(grid, \"center\")\n",
   "            getattr(plot, axis_location).append(axis)\n",
   "        if isinstance(range_input, FactorRange):\n",
   "        elif isinstance(range_input, Range1d):\n",
   "                value = range_input.start\n",
   "                if Datetime.is_timestamp(value):\n",
   "                Datetime.validate(Datetime(), value)\n"
  ]
 },
 "179": {
  "name": "df",
  "type": "pandas",
  "class": "imported",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/sampledata/autompg.py",
  "lineno": "50",
  "column": "4",
  "context": "-----\n\n\ndef _clean_data(df):\n    '''\n\n    '''\n    df = df.copy()\n    df['mfr'] = [x.split()[0] for x in df.name]\n  ",
  "context_lines": "#-----------------------------------------------------------------------------\n\n\ndef _clean_data(df):\n    '''\n\n    '''\n    df = df.copy()\n    df['mfr'] = [x.split()[0] for x in df.name]\n    df.loc[df.mfr=='chevy', 'mfr'] = 'chevrolet'\n    df.loc[df.mfr=='chevroelt', 'mfr'] = 'chevrolet'\n    df.loc[df.mfr=='maxda', 'mfr'] = 'mazda'\n",
  "slicing": [
   "    df = df.copy()\n",
   "    df['mfr'] = [x.split()[0] for x in df.name]\n",
   "    df.loc[df.mfr=='chevy', 'mfr'] = 'chevrolet'\n",
   "    df.loc[df.mfr=='chevroelt', 'mfr'] = 'chevrolet'\n",
   "    df.loc[df.mfr=='maxda', 'mfr'] = 'mazda'\n",
   "    df.loc[df.mfr=='mercedes-benz', 'mfr'] = 'mercedes'\n",
   "    df.loc[df.mfr=='toyouta', 'mfr'] = 'toyota'\n",
   "    df.loc[df.mfr=='vokswagen', 'mfr'] = 'volkswagen'\n",
   "    df.loc[df.mfr=='vw', 'mfr'] = 'volkswagen'\n",
   "    df.origin = [ORIGINS[x-1] for x in df.origin]\n",
   "    return df\n"
  ]
 },
 "180": {
  "name": "js",
  "type": "int",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/_testing/util/examples.py",
  "lineno": "57",
  "column": "4",
  "context": "-------------------------------\n\nclass Flags:\n    js       = 1 << 0\n    file     = 1 << 1\n    server   = 1 << 2\n    no",
  "context_lines": "#-----------------------------------------------------------------------------\n# General API\n#-----------------------------------------------------------------------------\n\nclass Flags:\n    js       = 1 << 0\n    file     = 1 << 1\n    server   = 1 << 2\n    notebook = 1 << 3\n    slow     = 1 << 4  # example needs a lot of time to run (> 30 s) (e.g. choropleth.py)\n",
  "slicing": "    js       = 1 << 0\n"
 },
 "181": {
  "name": "file",
  "type": "int",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/_testing/util/examples.py",
  "lineno": "58",
  "column": "4",
  "context": "---------\n\nclass Flags:\n    js       = 1 << 0\n    file     = 1 << 1\n    server   = 1 << 2\n    notebook = 1 << 3\n    sl",
  "context_lines": "# General API\n#-----------------------------------------------------------------------------\n\nclass Flags:\n    js       = 1 << 0\n    file     = 1 << 1\n    server   = 1 << 2\n    notebook = 1 << 3\n    slow     = 1 << 4  # example needs a lot of time to run (> 30 s) (e.g. choropleth.py)\n    skip     = 1 << 5  # don't run example at all (e.g. notebooks are completely broken)\n",
  "slicing": "    file     = 1 << 1\n"
 },
 "182": {
  "name": "server",
  "type": "int",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/_testing/util/examples.py",
  "lineno": "59",
  "column": "4",
  "context": ":\n    js       = 1 << 0\n    file     = 1 << 1\n    server   = 1 << 2\n    notebook = 1 << 3\n    slow     = 1 << 4  # exa",
  "context_lines": "#-----------------------------------------------------------------------------\n\nclass Flags:\n    js       = 1 << 0\n    file     = 1 << 1\n    server   = 1 << 2\n    notebook = 1 << 3\n    slow     = 1 << 4  # example needs a lot of time to run (> 30 s) (e.g. choropleth.py)\n    skip     = 1 << 5  # don't run example at all (e.g. notebooks are completely broken)\n    xfail    = 1 << 6  # test is expected to fail, which doesn't fail the test suite\n",
  "slicing": "    server   = 1 << 2\n"
 },
 "183": {
  "name": "notebook",
  "type": "int",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/_testing/util/examples.py",
  "lineno": "60",
  "column": "4",
  "context": "0\n    file     = 1 << 1\n    server   = 1 << 2\n    notebook = 1 << 3\n    slow     = 1 << 4  # example needs a lot of ti",
  "context_lines": "class Flags:\n    js       = 1 << 0\n    file     = 1 << 1\n    server   = 1 << 2\n    notebook = 1 << 3\n    slow     = 1 << 4  # example needs a lot of time to run (> 30 s) (e.g. choropleth.py)\n    skip     = 1 << 5  # don't run example at all (e.g. notebooks are completely broken)\n    xfail    = 1 << 6  # test is expected to fail, which doesn't fail the test suite\n    no_js    = 1 << 7  # skip bokehjs and thus image diff (e.g. google maps key issue)\n\n\n",
  "slicing": "    notebook = 1 << 3\n"
 },
 "184": {
  "name": "slow",
  "type": "int",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/_testing/util/examples.py",
  "lineno": "61",
  "column": "4",
  "context": "1\n    server   = 1 << 2\n    notebook = 1 << 3\n    slow     = 1 << 4  # example needs a lot of time to run (> 30 s) (e.g. choropleth.py)\n    skip     = 1 << 5  # don't run example at all ",
  "context_lines": "    js       = 1 << 0\n    file     = 1 << 1\n    server   = 1 << 2\n    notebook = 1 << 3\n    slow     = 1 << 4  # example needs a lot of time to run (> 30 s) (e.g. choropleth.py)\n    skip     = 1 << 5  # don't run example at all (e.g. notebooks are completely broken)\n    xfail    = 1 << 6  # test is expected to fail, which doesn't fail the test suite\n    no_js    = 1 << 7  # skip bokehjs and thus image diff (e.g. google maps key issue)\n\n\nclass Example:\n",
  "slicing": [
   "    slow     = 1 << 4  # example needs a lot of time to run (> 30 s) (e.g. choropleth.py)\n",
   "                add_examples(list_of_examples, join(path[:-1], name), examples_dir, example_type, slow, skip, xfail, no_js)\n",
   "        if slow is not None and orig_name in slow:\n"
  ]
 },
 "185": {
  "name": "skip",
  "type": "int",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/_testing/util/examples.py",
  "lineno": "62",
  "column": "4",
  "context": " of time to run (> 30 s) (e.g. choropleth.py)\n    skip     = 1 << 5  # don't run example at all (e.g. notebooks are completely broken)\n    xfail    = 1 << 6  # test is expected to fail,",
  "context_lines": "    file     = 1 << 1\n    server   = 1 << 2\n    notebook = 1 << 3\n    slow     = 1 << 4  # example needs a lot of time to run (> 30 s) (e.g. choropleth.py)\n    skip     = 1 << 5  # don't run example at all (e.g. notebooks are completely broken)\n    xfail    = 1 << 6  # test is expected to fail, which doesn't fail the test suite\n    no_js    = 1 << 7  # skip bokehjs and thus image diff (e.g. google maps key issue)\n\n\nclass Example:\n    def __init__(self, path, flags, examples_dir):\n",
  "slicing": [
   "    skip     = 1 << 5  # don't run example at all (e.g. notebooks are completely broken)\n",
   "                add_examples(list_of_examples, join(path[:-1], name), examples_dir, example_type, slow, skip, xfail, no_js)\n",
   "        if skip is not None and (skip == 'all' or orig_name in skip):\n"
  ]
 },
 "186": {
  "name": "xfail",
  "type": "int",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/_testing/util/examples.py",
  "lineno": "63",
  "column": "4",
  "context": "at all (e.g. notebooks are completely broken)\n    xfail    = 1 << 6  # test is expected to fail, which doesn't fail the test suite\n    no_js    = 1 << 7  # skip bokehjs and thus ima",
  "context_lines": "    server   = 1 << 2\n    notebook = 1 << 3\n    slow     = 1 << 4  # example needs a lot of time to run (> 30 s) (e.g. choropleth.py)\n    skip     = 1 << 5  # don't run example at all (e.g. notebooks are completely broken)\n    xfail    = 1 << 6  # test is expected to fail, which doesn't fail the test suite\n    no_js    = 1 << 7  # skip bokehjs and thus image diff (e.g. google maps key issue)\n\n\nclass Example:\n    def __init__(self, path, flags, examples_dir):\n        self.path = normpath(path)\n",
  "slicing": [
   "    xfail    = 1 << 6  # test is expected to fail, which doesn't fail the test suite\n",
   "                add_examples(list_of_examples, join(path[:-1], name), examples_dir, example_type, slow, skip, xfail, no_js)\n",
   "        if xfail is not None and (xfail == 'all' or orig_name in xfail):\n"
  ]
 },
 "187": {
  "name": "no_js",
  "type": "int",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/_testing/util/examples.py",
  "lineno": "64",
  "column": "4",
  "context": "ed to fail, which doesn't fail the test suite\n    no_js    = 1 << 7  # skip bokehjs and thus image diff (e.g. google maps key issue)\n\n\nclass Example:\n    def __init__(self, path, flag",
  "context_lines": "    notebook = 1 << 3\n    slow     = 1 << 4  # example needs a lot of time to run (> 30 s) (e.g. choropleth.py)\n    skip     = 1 << 5  # don't run example at all (e.g. notebooks are completely broken)\n    xfail    = 1 << 6  # test is expected to fail, which doesn't fail the test suite\n    no_js    = 1 << 7  # skip bokehjs and thus image diff (e.g. google maps key issue)\n\n\nclass Example:\n    def __init__(self, path, flags, examples_dir):\n        self.path = normpath(path)\n",
  "slicing": [
   "    no_js    = 1 << 7  # skip bokehjs and thus image diff (e.g. google maps key issue)\n",
   "                add_examples(list_of_examples, join(path[:-1], name), examples_dir, example_type, slow, skip, xfail, no_js)\n",
   "        if no_js is not None and (no_js == 'all' or orig_name in no_js):\n"
  ]
 },
 "188": {
  "name": "__repr__",
  "type": "function",
  "class": "unknown",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/_testing/util/examples.py",
  "lineno": "90",
  "column": "4",
  "context": "lf.relpath, \"|\".join(f for f in flags if f))\n\n    __repr__ = __str__\n\n    @property\n    def name(self):\n        return ",
  "context_lines": "            \"xfail\"    if self.xfail       else \"\",\n            \"no_js\"    if self.no_js       else \"\",\n        ]\n\n        return \"Example(%r, %s)\" % (self.relpath, \"|\".join(f for f in flags if f))\n\n    __repr__ = __str__\n\n    @property\n    def name(self):\n        return basename(self.path_no_ext)\n\n",
  "slicing": [
   "    slow     = 1 << 4  # example needs a lot of time to run (> 30 s) (e.g. choropleth.py)\n",
   "    skip     = 1 << 5  # don't run example at all (e.g. notebooks are completely broken)\n",
   "    xfail    = 1 << 6  # test is expected to fail, which doesn't fail the test suite\n",
   "    no_js    = 1 << 7  # skip bokehjs and thus image diff (e.g. google maps key issue)\n",
   "        flags = [\n",
   "        return \"Example(%r, %s)\" % (self.relpath, \"|\".join(f for f in flags if f))\n",
   "    __repr__ = __str__\n",
   "def add_examples(list_of_examples, path, examples_dir, example_type=None, slow=None, skip=None, xfail=None, no_js=None):\n",
   "        star_path = join(examples_dir, path[:-1])\n",
   "        for name in sorted(os.listdir(star_path)):\n",
   "            if isdir(join(star_path, name)):\n",
   "                add_examples(list_of_examples, join(path[:-1], name), examples_dir, example_type, slow, skip, xfail, no_js)\n",
   "    example_path = join(examples_dir, path)\n",
   "    for name in sorted(os.listdir(example_path)):\n",
   "        flags = 0\n",
   "        orig_name = name\n",
   "        if name.startswith(('_', '.')):\n",
   "        elif name.endswith(\".py\"):\n",
   "            flags |= example_type if example_type else Flags.file\n",
   "        elif name.endswith(\".ipynb\"):\n",
   "            flags |= Flags.notebook\n",
   "        elif isdir(join(example_path, name)):\n",
   "            if exists(join(example_path, name, name + \".html\")):\n",
   "                name = join(name, name + \".html\")\n",
   "                flags |= example_type if example_type else Flags.js\n",
   "            elif exists(join(example_path, name, name + \".py\")):\n",
   "                name = join(name, name + \".py\")\n",
   "                flags |= example_type if example_type else Flags.file\n",
   "            elif exists(join(example_path, name, \"main.py\")):\n",
   "                flags |= example_type if example_type else Flags.server\n",
   "        if slow is not None and orig_name in slow:\n",
   "            flags |= Flags.slow\n",
   "        if skip is not None and (skip == 'all' or orig_name in skip):\n",
   "            flags |= Flags.skip\n",
   "        if xfail is not None and (xfail == 'all' or orig_name in xfail):\n",
   "            flags |= Flags.xfail\n",
   "        if no_js is not None and (no_js == 'all' or orig_name in no_js):\n",
   "            flags |= Flags.no_js\n",
   "        list_of_examples.append(Example(join(example_path, name), flags, examples_dir))\n",
   "    examples_dir = join(dirname(config_path), pardir)\n",
   "    list_of_examples = []\n",
   "    with open(config_path, \"r\") as f:\n",
   "        examples = yaml.safe_load(f.read())\n",
   "    for example in examples:\n",
   "        path = example[\"path\"]\n",
   "        if example.get(\"type\") is not None:\n",
   "            example_type = getattr(Flags, example[\"type\"])\n",
   "            example_type = None\n",
   "        slow_status = example.get(\"slow\")\n",
   "        skip_status = example.get(\"skip\")\n",
   "        xfail_status = example.get(\"xfail\")\n",
   "        no_js_status = example.get(\"no_js\")\n",
   "        add_examples(list_of_examples, path, examples_dir,\n",
   "            example_type=example_type, slow=slow_status, skip=skip_status, xfail=xfail_status, no_js=no_js_status)\n",
   "    return list_of_examples\n",
   "    directory = dirname(path)\n",
   "    if not exists(directory):\n",
   "        os.makedirs(directory)\n",
   "    with open(path, \"wb\") as f:\n",
   "        f.write(data)\n"
  ]
 },
 "189": {
  "name": "_callbacks",
  "type": "list",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/util/callback_manager.py",
  "lineno": "121",
  "column": "8",
  "context": "more callbacks, got only one parameter\")\n\n        _callbacks = self._callbacks.setdefault(attr, [])\n        for callback in callbacks:\n\n            if",
  "context_lines": "            None\n\n        '''\n        if len(callbacks) == 0:\n            raise ValueError(\"on_change takes an attribute name and one or more callbacks, got only one parameter\")\n\n        _callbacks = self._callbacks.setdefault(attr, [])\n        for callback in callbacks:\n\n            if callback in _callbacks:\n                continue\n\n            _check_callback(callback, ('attr', 'old', 'new'))\n\n",
  "slicing": [
   "            event = event.event_name\n",
   "        for callback in callbacks:\n",
   "            if _nargs(callback) != 0:\n",
   "                _check_callback(callback, ('event',), what='Event callback')\n",
   "        if event not in self._event_callbacks:\n",
   "            self._event_callbacks[event] = [cb for cb in callbacks]\n",
   "            self._event_callbacks[event].extend(callbacks)\n",
   "        if event not in self.subscribed_events:\n",
   "            self.subscribed_events.append(event)\n",
   "            for callback in self._event_callbacks.get(event.event_name,[]):\n",
   "                if event._model_id is not None and self.id == event._model_id:\n",
   "                    if _nargs(callback) == 0:\n",
   "                        callback()\n",
   "                        callback(event)\n",
   "        for key in self._event_callbacks:\n",
   "            self.document._subscribed_models[key].add(self)\n",
   "        _callbacks = self._callbacks.setdefault(attr, [])\n",
   "        for callback in callbacks:\n",
   "            if callback in _callbacks:\n",
   "            _check_callback(callback, ('attr', 'old', 'new'))\n",
   "            _callbacks.append(callback)\n",
   "        _callbacks = self._callbacks.setdefault(attr, [])\n",
   "        for callback in callbacks:\n",
   "            _callbacks.remove(callback)\n",
   "            callbacks = self._callbacks.get(attr)\n",
   "            if callbacks:\n",
   "                for callback in callbacks:\n",
   "                    callback(attr, old, new)\n",
   "    sig = signature(fn)\n",
   "    all_names, default_values = get_param_info(sig)\n",
   "    return len(all_names) - len(default_values)\n",
   "    sig = signature(callback)\n",
   "    formatted_args = str(sig)\n",
   "    all_names, default_values = get_param_info(sig)\n",
   "    nargs = len(all_names) - len(default_values)\n",
   "    if nargs != len(fargs):\n",
   "        raise ValueError(error_msg % (\", \".join(fargs), formatted_args))\n"
  ]
 },
 "190": {
  "name": "callbacks",
  "type": "NoneType",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/util/callback_manager.py",
  "lineno": "152",
  "column": "12",
  "context": "ne\n\n        '''\n        def invoke():\n            callbacks = self._callbacks.get(attr)\n            if callbacks:\n                for call",
  "context_lines": "        Returns:\n            None\n\n        '''\n        def invoke():\n            callbacks = self._callbacks.get(attr)\n            if callbacks:\n                for callback in callbacks:\n                    callback(attr, old, new)\n        if hasattr(self, '_document') and self._document is not None:\n",
  "slicing": [
   "            event = event.event_name\n",
   "        for callback in callbacks:\n",
   "            if _nargs(callback) != 0:\n",
   "                _check_callback(callback, ('event',), what='Event callback')\n",
   "        if event not in self._event_callbacks:\n",
   "            self._event_callbacks[event] = [cb for cb in callbacks]\n",
   "            self._event_callbacks[event].extend(callbacks)\n",
   "        if event not in self.subscribed_events:\n",
   "            self.subscribed_events.append(event)\n",
   "            for callback in self._event_callbacks.get(event.event_name,[]):\n",
   "                if event._model_id is not None and self.id == event._model_id:\n",
   "                    if _nargs(callback) == 0:\n",
   "                        callback()\n",
   "                        callback(event)\n",
   "        for key in self._event_callbacks:\n",
   "            self.document._subscribed_models[key].add(self)\n",
   "        _callbacks = self._callbacks.setdefault(attr, [])\n",
   "        for callback in callbacks:\n",
   "            if callback in _callbacks:\n",
   "            _check_callback(callback, ('attr', 'old', 'new'))\n",
   "            _callbacks.append(callback)\n",
   "        _callbacks = self._callbacks.setdefault(attr, [])\n",
   "        for callback in callbacks:\n",
   "            _callbacks.remove(callback)\n",
   "            callbacks = self._callbacks.get(attr)\n",
   "            if callbacks:\n",
   "                for callback in callbacks:\n",
   "                    callback(attr, old, new)\n",
   "    sig = signature(fn)\n",
   "    all_names, default_values = get_param_info(sig)\n",
   "    return len(all_names) - len(default_values)\n",
   "    sig = signature(callback)\n",
   "    formatted_args = str(sig)\n",
   "    all_names, default_values = get_param_info(sig)\n",
   "    nargs = len(all_names) - len(default_values)\n",
   "    if nargs != len(fargs):\n",
   "        raise ValueError(error_msg % (\", \".join(fargs), formatted_args))\n"
  ]
 },
 "191": {
  "name": "error_msg",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/util/callback_manager.py",
  "lineno": "178",
  "column": "4",
  "context": "ature(callback)\n    formatted_args = str(sig)\n    error_msg = what + \" must have signature func(%s), got func%s\"\n\n    all_names, default_values = get_param_info(si",
  "context_lines": "def _check_callback(callback, fargs, what=\"Callback functions\"):\n    '''Bokeh-internal function to check callback signature'''\n    sig = signature(callback)\n    formatted_args = str(sig)\n    error_msg = what + \" must have signature func(%s), got func%s\"\n\n    all_names, default_values = get_param_info(sig)\n\n    nargs = len(all_names) - len(default_values)\n    if nargs != len(fargs):\n",
  "slicing": [
   "            event = event.event_name\n",
   "        for callback in callbacks:\n",
   "            if _nargs(callback) != 0:\n",
   "                _check_callback(callback, ('event',), what='Event callback')\n",
   "        if event not in self._event_callbacks:\n",
   "            self._event_callbacks[event] = [cb for cb in callbacks]\n",
   "            self._event_callbacks[event].extend(callbacks)\n",
   "        if event not in self.subscribed_events:\n",
   "            self.subscribed_events.append(event)\n",
   "            for callback in self._event_callbacks.get(event.event_name,[]):\n",
   "                if event._model_id is not None and self.id == event._model_id:\n",
   "                    if _nargs(callback) == 0:\n",
   "                        callback()\n",
   "                        callback(event)\n",
   "        for key in self._event_callbacks:\n",
   "            self.document._subscribed_models[key].add(self)\n",
   "        _callbacks = self._callbacks.setdefault(attr, [])\n",
   "        for callback in callbacks:\n",
   "            if callback in _callbacks:\n",
   "            _check_callback(callback, ('attr', 'old', 'new'))\n",
   "            _callbacks.append(callback)\n",
   "        _callbacks = self._callbacks.setdefault(attr, [])\n",
   "        for callback in callbacks:\n",
   "            _callbacks.remove(callback)\n",
   "            callbacks = self._callbacks.get(attr)\n",
   "            if callbacks:\n",
   "                for callback in callbacks:\n",
   "                    callback(attr, old, new)\n",
   "    sig = signature(fn)\n",
   "    all_names, default_values = get_param_info(sig)\n",
   "    return len(all_names) - len(default_values)\n",
   "    sig = signature(callback)\n",
   "    formatted_args = str(sig)\n",
   "    error_msg = what + \" must have signature func(%s), got func%s\"\n",
   "    all_names, default_values = get_param_info(sig)\n",
   "    nargs = len(all_names) - len(default_values)\n",
   "    if nargs != len(fargs):\n",
   "        raise ValueError(error_msg % (\", \".join(fargs), formatted_args))\n"
  ]
 },
 "192": {
  "name": "file",
  "type": "NoneType",
  "class": "unknown",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/util/compiler.py",
  "lineno": "117",
  "column": "4",
  "context": " Bokeh custom model implementations.\n\n    '''\n    file = None\n\nclass Inline(Implementation):\n    ''' Base class ",
  "context_lines": "        return dict(error=obj)\n\nclass Implementation:\n    ''' Base class for representing Bokeh custom model implementations.\n\n    '''\n    file = None\n\nclass Inline(Implementation):\n    ''' Base class for representing Bokeh custom model implementations that may\n    be given as inline code in some language.\n\n",
  "slicing": [
   "bokehjs_dir = settings.bokehjsdir()\n",
   "nodejs_min_version = (10, 13, 0)\n",
   "def nodejs_compile(code, lang=\"javascript\", file=None):\n",
   "    compilejs_script = join(bokehjs_dir, \"js\", \"compiler.js\")\n",
   "    output = _run_nodejs([compilejs_script], dict(code=code, lang=lang, file=file, bokehjs_dir=bokehjs_dir))\n",
   "    lines = output.split(\"\\n\")\n",
   "    for i, line in enumerate(lines):\n",
   "        if not line.startswith(\"LOG\"):\n",
   "            print(line)\n",
   "    obj = json.loads(\"\\n\".join(lines[i:]))\n",
   "    if isinstance(obj, dict):\n",
   "        return AttrDict(obj)\n",
   "        return dict(error=obj)\n",
   "    file = None\n",
   "        self.code = code\n",
   "        self.file = file\n",
   "        with open(path, encoding=\"utf-8\") as f:\n",
   "            self.code = f.read()\n",
   "exts = (\".ts\", \".js\", \".css\", \".less\")\n",
   "        name = self.cls.__module__ + \".\" + self.name\n",
   "        return name.replace(\"__main__.\", \"\")\n",
   "        module = sys.modules[self.cls.__module__]\n",
   "        if hasattr(module, \"__file__\"):\n",
   "            return abspath(module.__file__)\n",
   "        path = getattr(self.cls, \"__base_path__\", None)\n",
   "        if path is not None:\n",
   "            return path\n",
   "        impl = self.cls.__implementation__\n",
   "        if isinstance(impl, str):\n",
   "            if \"\\n\" not in impl and impl.endswith(exts):\n",
   "                impl = FromFile(impl if isabs(impl) else join(self.path, impl))\n",
   "                impl = TypeScript(impl)\n",
   "        if isinstance(impl, Inline) and impl.file is None:\n",
   "            file = \"%s%s.ts\" % (self.file + \":\" if self.file else \"\", self.name)\n",
   "            impl = impl.__class__(impl.code, file)\n",
   "        return impl\n",
   "    _CACHING_IMPLEMENTATION = hook\n",
   "def calc_cache_key(custom_models):\n",
   "    model_names = {model.full_name for model in custom_models.values()}\n",
   "    encoded_names = \",\".join(sorted(model_names)).encode('utf-8')\n",
   "    return hashlib.sha256(encoded_names).hexdigest()\n",
   "_bundle_cache = {}\n",
   "def bundle_models(models):\n",
   "    custom_models = _get_custom_models(models)\n",
   "    if custom_models is None:\n",
   "    key = calc_cache_key(custom_models)\n",
   "    bundle = _bundle_cache.get(key, None)\n",
   "    if bundle is None:\n",
   "            _bundle_cache[key] = bundle = _bundle_models(custom_models)\n",
   "    return bundle\n",
   "_plugin_prelude = \\\n",
   "_plugin_template = \\\n",
   "_style_template = \\\n",
   "_export_template = \\\n",
   "_module_template = \\\n",
   "        nodejs_paths = [settings.nodejs_path()]\n",
   "        nodejs_paths = [\"nodejs\", \"node\"]\n",
   "    for nodejs_path in nodejs_paths:\n",
   "            proc = Popen([nodejs_path, \"--version\"], stdout=PIPE, stderr=PIPE)\n",
   "            (stdout, _) = proc.communicate()\n",
   "        if proc.returncode != 0:\n",
   "        match = re.match(r\"^v(\\d+)\\.(\\d+)\\.(\\d+).*$\", stdout.decode(\"utf-8\"))\n",
   "        if match is not None:\n",
   "            version = tuple(int(v) for v in match.groups())\n",
   "            if version >= nodejs_min_version:\n",
   "                return nodejs_path\n",
   "    version = \".\".join(map(str, nodejs_min_version))\n",
   "    raise RuntimeError('node.js v%s or higher is needed to allow compilation of custom models ' % version +\n",
   "_nodejs = None\n",
   "_npmjs = None\n",
   "    if _nodejs is None:\n",
   "        _nodejs = _detect_nodejs()\n",
   "    return _nodejs\n",
   "    if _npmjs is None:\n",
   "        _npmjs = join(dirname(_nodejs_path()), \"npm\")\n",
   "            _npmjs += '.cmd'\n",
   "    return _npmjs\n",
   "def _crlf_cr_2_lf(s):\n",
   "    return re.sub(r\"\\\\r\\\\n|\\\\r|\\\\n\", r\"\\\\n\", s)\n",
   "def _run(app, argv, input=None):\n",
   "    proc = Popen([app] + argv, stdout=PIPE, stderr=PIPE, stdin=PIPE)\n",
   "    (stdout, errout) = proc.communicate(input=None if input is None else json.dumps(input).encode())\n",
   "    if proc.returncode != 0:\n",
   "        raise RuntimeError(errout.decode('utf-8'))\n",
   "        return _crlf_cr_2_lf(stdout.decode('utf-8'))\n",
   "    return _run(_nodejs_path(), argv, input)\n",
   "def _run_npmjs(argv, input=None):\n",
   "    return _run(_npmjs_path(), argv, input)\n",
   "        version = run_app([\"--version\"])\n",
   "        return version.strip()\n",
   "_CACHING_IMPLEMENTATION = _model_cache_no_op\n",
   "    if models is None:\n",
   "        models = Model.model_class_reverse_map.values()\n",
   "    custom_models = OrderedDict()\n",
   "    for cls in models:\n",
   "        impl = getattr(cls, \"__implementation__\", None)\n",
   "        if impl is not None:\n",
   "            model = CustomModel(cls)\n",
   "            custom_models[model.full_name] = model\n",
   "    if not custom_models:\n",
   "    return custom_models\n",
   "def _compile_models(custom_models):\n",
   "    ordered_models = sorted(custom_models.values(), key=lambda model: model.full_name)\n",
   "    custom_impls = {}\n",
   "    dependencies = []\n",
   "    for model in ordered_models:\n",
   "        dependencies.extend(list(model.dependencies.items()))\n",
   "    if dependencies:\n",
   "        dependencies = sorted(dependencies, key=lambda name_version: name_version[0])\n",
   "        _run_npmjs([\"install\", \"--no-progress\"] + [ name + \"@\" + version for (name, version) in dependencies ])\n",
   "    for model in ordered_models:\n",
   "        impl = model.implementation\n",
   "        compiled = _CACHING_IMPLEMENTATION(model, impl)\n",
   "        if compiled is None:\n",
   "            compiled = nodejs_compile(impl.code, lang=impl.lang, file=impl.file)\n",
   "        if \"error\" in compiled:\n",
   "            raise CompilationError(compiled.error)\n",
   "        custom_impls[model.full_name] = compiled\n",
   "    return custom_impls\n",
   "    exports = []\n",
   "    modules = []\n",
   "    with open(join(bokehjs_dir, \"js\", \"bokeh.json\"), encoding=\"utf-8\") as f:\n",
   "        bokeh = json.loads(f.read())\n",
   "    known_modules = set()\n",
   "    for artifact in bokeh[\"artifacts\"]:\n",
   "        canonical = artifact[\"module\"].get(\"canonical\")\n",
   "        if canonical is not None:\n",
   "            known_modules.add(canonical)\n",
   "    custom_impls = _compile_models(custom_models)\n",
   "    extra_modules = {}\n",
   "    def resolve_modules(to_resolve, root):\n",
   "        resolved = {}\n",
   "        for module in to_resolve:\n",
   "            if module.startswith((\"./\", \"../\")):\n",
   "                def mkpath(module, ext=\"\"):\n",
   "                    return abspath(join(root, *module.split(\"/\")) + ext)\n",
   "                if module.endswith(exts):\n",
   "                    path = mkpath(module)\n",
   "                    if not exists(path):\n",
   "                        raise RuntimeError(\"no such module: %s\" % module)\n",
   "                    for ext in exts:\n",
   "                        path = mkpath(module, ext)\n",
   "                        if exists(path):\n",
   "                        raise RuntimeError(\"no such module: %s\" % module)\n",
   "                impl = FromFile(path)\n",
   "                compiled = nodejs_compile(impl.code, lang=impl.lang, file=impl.file)\n",
   "                if \"error\" in compiled:\n",
   "                    raise CompilationError(compiled.error)\n",
   "                if impl.lang == \"less\":\n",
   "                    code = _style_template % dict(css=json.dumps(compiled.code))\n",
   "                    deps = []\n",
   "                    code = compiled.code\n",
   "                    deps = compiled.deps\n",
   "                sig = hashlib.sha256(code.encode('utf-8')).hexdigest()\n",
   "                resolved[module] = sig\n",
   "                deps_map = resolve_deps(deps, dirname(path))\n",
   "                if sig not in extra_modules:\n",
   "                    extra_modules[sig] = True\n",
   "                    modules.append((sig, code, deps_map))\n",
   "                index = module + (\"\" if module.endswith(\"/\") else \"/\") + \"index\"\n",
   "                if index not in known_modules:\n",
   "                    raise RuntimeError(\"no such module: %s\" % module)\n",
   "        return resolved\n",
   "    def resolve_deps(deps, root):\n",
   "        custom_modules = {model.module for model in custom_models.values()}\n",
   "        missing = set(deps) - known_modules - custom_modules\n",
   "        return resolve_modules(missing, root)\n",
   "    for model in custom_models.values():\n",
   "        compiled = custom_impls[model.full_name]\n",
   "        deps_map = resolve_deps(compiled.deps, model.path)\n",
   "        exports.append((model.name, model.module))\n",
   "        modules.append((model.module, compiled.code, deps_map))\n",
   "    exports = sorted(exports, key=lambda spec: spec[1])\n",
   "    modules = sorted(modules, key=lambda spec: spec[0])\n",
   "    for i, (module, code, deps) in enumerate(modules):\n",
   "        for name, ref in deps.items():\n",
   "            code = code.replace(\"\"\"require(\"%s\")\"\"\" % name, \"\"\"require(\"%s\")\"\"\" % ref)\n",
   "            code = code.replace(\"\"\"require('%s')\"\"\" % name, \"\"\"require('%s')\"\"\" % ref)\n",
   "        modules[i] = (module, code)\n",
   "    sep = \",\\n\"\n",
   "    exports = sep.join(_export_template % dict(name=name, module=module) for (name, module) in exports)\n",
   "    modules = sep.join(_module_template % dict(module=module, source=code) for (module, code) in modules)\n",
   "    content = _plugin_template % dict(prelude=_plugin_prelude, exports=exports, modules=modules)\n",
   "    return _plugin_umd % dict(content=content)\n"
  ]
 },
 "193": {
  "name": "VERSION_PAT",
  "type": "_sre.SRE_Pattern",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/util/version.py",
  "lineno": "62",
  "column": "4",
  "context": "mport re\n    version = version or __version__\n    VERSION_PAT = re.compile(r\"^(\\d+\\.\\d+\\.\\d+)$\")\n    return bool(VERSION_PAT.match(version))\n\n#----",
  "context_lines": "    return _base_version_helper(__version__)\n\ndef is_full_release(version: str = None) -> bool:\n    import re\n    version = version or __version__\n    VERSION_PAT = re.compile(r\"^(\\d+\\.\\d+\\.\\d+)$\")\n    return bool(VERSION_PAT.match(version))\n\n#-----------------------------------------------------------------------------\n# Dev API\n#-----------------------------------------------------------------------------\n\n",
  "slicing": [
   "    version = version or __version__\n",
   "    VERSION_PAT = re.compile(r\"^(\\d+\\.\\d+\\.\\d+)$\")\n",
   "    return bool(VERSION_PAT.match(version))\n",
   "    VERSION_PAT = re.compile(r\"^(\\d+\\.\\d+\\.\\d+)((?:dev|rc).*)?\")\n",
   "    match = VERSION_PAT.search(version)\n",
   "    assert match is not None\n",
   "    return match.group(1)\n"
  ]
 },
 "194": {
  "name": "_simple_id",
  "type": "int",
  "class": "build-in",
  "approach": "UNKNOWN",
  "file_path": "bokeh/bokeh/util/serialization.py",
  "lineno": "255",
  "column": "12",
  "context": "_ids():\n        with _simple_id_lock:\n            _simple_id += 1\n            return str(_simple_id)\n    else:\n     ",
  "context_lines": "    '''\n    global _simple_id\n\n    if settings.simple_ids():\n        with _simple_id_lock:\n            _simple_id += 1\n            return str(_simple_id)\n    else:\n        return make_globally_unique_id()\n\ndef make_globally_unique_id():\n",
  "slicing": [
   "            _simple_id += 1\n",
   "            return str(_simple_id)\n"
  ]
 },
 "195": {
  "name": "name",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/command/subcommands/secret.py",
  "lineno": "63",
  "column": "4",
  "context": "ey.\n\n    '''\n\n    #: name for this subcommand\n    name = \"secret\"\n\n    help = \"Create a Bokeh secret key for use wit",
  "context_lines": "class Secret(Subcommand):\n    ''' Subcommand to generate a new secret key.\n\n    '''\n\n    #: name for this subcommand\n    name = \"secret\"\n\n    help = \"Create a Bokeh secret key for use with Bokeh server\"\n\n    args = (\n    )\n\n",
  "slicing": "    name = \"secret\"\n"
 },
 "196": {
  "name": "help",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/command/subcommands/secret.py",
  "lineno": "65",
  "column": "4",
  "context": "name for this subcommand\n    name = \"secret\"\n\n    help = \"Create a Bokeh secret key for use with Bokeh server\"\n\n    args = (\n    )\n\n    def invoke(self, args: Na",
  "context_lines": "    ''' Subcommand to generate a new secret key.\n\n    '''\n\n    #: name for this subcommand\n    name = \"secret\"\n\n    help = \"Create a Bokeh secret key for use with Bokeh server\"\n\n    args = (\n    )\n\n    def invoke(self, args: Namespace) -> None:\n",
  "slicing": "    help = \"Create a Bokeh secret key for use with Bokeh server\"\n"
 },
 "197": {
  "name": "name",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/command/subcommands/info.py",
  "lineno": "103",
  "column": "4",
  "context": "on.\n\n    '''\n\n    #: name for this subcommand\n    name = \"info\"\n\n    help = \"Print information about Bokeh and Bok",
  "context_lines": "class Info(Subcommand):\n    ''' Subcommand to print information about Bokeh and Bokeh server configuration.\n\n    '''\n\n    #: name for this subcommand\n    name = \"info\"\n\n    help = \"Print information about Bokeh and Bokeh server configuration\"\n\n    args = (\n\n        ('--static', dict(\n",
  "slicing": "    name = \"info\"\n"
 },
 "198": {
  "name": "help",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/command/subcommands/info.py",
  "lineno": "105",
  "column": "4",
  "context": ": name for this subcommand\n    name = \"info\"\n\n    help = \"Print information about Bokeh and Bokeh server configuration\"\n\n    args = (\n\n        ('--static', dict(\n        ",
  "context_lines": "    ''' Subcommand to print information about Bokeh and Bokeh server configuration.\n\n    '''\n\n    #: name for this subcommand\n    name = \"info\"\n\n    help = \"Print information about Bokeh and Bokeh server configuration\"\n\n    args = (\n\n        ('--static', dict(\n            action='store_true',\n",
  "slicing": "    help = \"Print information about Bokeh and Bokeh server configuration\"\n"
 },
 "199": {
  "name": "name",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/command/subcommands/init.py",
  "lineno": "47",
  "column": "4",
  "context": " directory as a new bokeh extension.\n    '''\n\n    name = \"init\"\n\n    help = \"Initialize a bokeh extension\"\n\n    ar",
  "context_lines": "class Init(Subcommand):\n    '''\n    Initialize a directory as a new bokeh extension.\n    '''\n\n    name = \"init\"\n\n    help = \"Initialize a bokeh extension\"\n\n    args = (\n        (\"base_dir\", dict(\n",
  "slicing": "    name = \"init\"\n"
 },
 "200": {
  "name": "help",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/command/subcommands/init.py",
  "lineno": "49",
  "column": "4",
  "context": " bokeh extension.\n    '''\n\n    name = \"init\"\n\n    help = \"Initialize a bokeh extension\"\n\n    args = (\n        (\"base_dir\", dict(\n         ",
  "context_lines": "    '''\n    Initialize a directory as a new bokeh extension.\n    '''\n\n    name = \"init\"\n\n    help = \"Initialize a bokeh extension\"\n\n    args = (\n        (\"base_dir\", dict(\n            metavar=\"BASE_DIR\",\n",
  "slicing": "    help = \"Initialize a bokeh extension\"\n"
 },
 "201": {
  "name": "name",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/command/subcommands/sampledata.py",
  "lineno": "64",
  "column": "4",
  "context": "ts.\n\n    '''\n\n    #: name for this subcommand\n    name = \"sampledata\"\n\n    help = \"Download the bokeh sample data sets\"\n",
  "context_lines": "class Sampledata(Subcommand):\n    ''' Subcommand to download bokeh sample data sets.\n\n    '''\n\n    #: name for this subcommand\n    name = \"sampledata\"\n\n    help = \"Download the bokeh sample data sets\"\n\n    args = (\n    )\n\n",
  "slicing": "    name = \"sampledata\"\n"
 },
 "202": {
  "name": "help",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/command/subcommands/sampledata.py",
  "lineno": "66",
  "column": "4",
  "context": " for this subcommand\n    name = \"sampledata\"\n\n    help = \"Download the bokeh sample data sets\"\n\n    args = (\n    )\n\n    def invoke(self, args: Na",
  "context_lines": "    ''' Subcommand to download bokeh sample data sets.\n\n    '''\n\n    #: name for this subcommand\n    name = \"sampledata\"\n\n    help = \"Download the bokeh sample data sets\"\n\n    args = (\n    )\n\n    def invoke(self, args: Namespace) -> None:\n",
  "slicing": "    help = \"Download the bokeh sample data sets\"\n"
 },
 "203": {
  "name": "attr",
  "type": "Settings",
  "class": "customized",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/command/subcommands/__init__.py",
  "lineno": "63",
  "column": "12",
  "context": "age__)\n\n        for name in dir(mod):\n            attr = getattr(mod, name)\n            if isinstance(attr, type) and issubcla",
  "context_lines": "            continue\n\n        modname = file.rstrip(\".py\")\n        mod = import_module(\".\" + modname, __package__)\n\n        for name in dir(mod):\n            attr = getattr(mod, name)\n            if isinstance(attr, type) and issubclass(attr, Subcommand):\n                if not getattr(attr, 'name', None): continue  # instance attribute not defined on abstract base class\n                results.append(attr)\n\n    results = sorted(results, key=lambda attr: attr.name)\n\n",
  "slicing": [
   "    results = []\n",
   "    for file in listdir(dirname(__file__)):\n",
   "        if not file.endswith(\".py\") or file in (\"__init__.py\", \"__main__.py\"):\n",
   "        modname = file.rstrip(\".py\")\n",
   "        mod = import_module(\".\" + modname, __package__)\n",
   "        for name in dir(mod):\n",
   "            attr = getattr(mod, name)\n",
   "            if isinstance(attr, type) and issubclass(attr, Subcommand):\n",
   "                if not getattr(attr, 'name', None): continue  # instance attribute not defined on abstract base class\n",
   "                results.append(attr)\n",
   "    results = sorted(results, key=lambda attr: attr.name)\n",
   "    return results\n"
  ]
 },
 "204": {
  "name": "results",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/command/subcommands/__init__.py",
  "lineno": "68",
  "column": "4",
  "context": "e class\n                results.append(attr)\n\n    results = sorted(results, key=lambda attr: attr.name)\n\n    return results\n\n#----------------------------",
  "context_lines": "            attr = getattr(mod, name)\n            if isinstance(attr, type) and issubclass(attr, Subcommand):\n                if not getattr(attr, 'name', None): continue  # instance attribute not defined on abstract base class\n                results.append(attr)\n\n    results = sorted(results, key=lambda attr: attr.name)\n\n    return results\n\n#-----------------------------------------------------------------------------\n# Code\n",
  "slicing": [
   "    results = []\n",
   "    for file in listdir(dirname(__file__)):\n",
   "        if not file.endswith(\".py\") or file in (\"__init__.py\", \"__main__.py\"):\n",
   "        modname = file.rstrip(\".py\")\n",
   "        mod = import_module(\".\" + modname, __package__)\n",
   "        for name in dir(mod):\n",
   "            attr = getattr(mod, name)\n",
   "            if isinstance(attr, type) and issubclass(attr, Subcommand):\n",
   "                if not getattr(attr, 'name', None): continue  # instance attribute not defined on abstract base class\n",
   "                results.append(attr)\n",
   "    results = sorted(results, key=lambda attr: attr.name)\n",
   "    return results\n"
  ]
 },
 "205": {
  "name": "name",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/command/subcommands/serve.py",
  "lineno": "504",
  "column": "4",
  "context": "er.\n\n    '''\n\n    #: name for this subcommand\n    name = \"serve\"\n\n    help = \"Run a Bokeh server hosting one or mor",
  "context_lines": "class Serve(Subcommand):\n    ''' Subcommand to launch the Bokeh server.\n\n    '''\n\n    #: name for this subcommand\n    name = \"serve\"\n\n    help = \"Run a Bokeh server hosting one or more applications\"\n\n    args = base_serve_args + (\n        ('files', dict(\n",
  "slicing": [
   "    name = \"serve\"\n",
   "                    if (fnmatch(name, '*.html') or\n",
   "                        fnmatch(name, '*.css') or\n",
   "                        fnmatch(name, '*.yaml')):\n",
   "                        log.info(\"Watching: \" + os.path.join(path, name))\n",
   "                        watch(os.path.join(path, name))\n"
  ]
 },
 "206": {
  "name": "help",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/command/subcommands/serve.py",
  "lineno": "506",
  "column": "4",
  "context": " name for this subcommand\n    name = \"serve\"\n\n    help = \"Run a Bokeh server hosting one or more applications\"\n\n    args = base_serve_args + (\n        ('files', ",
  "context_lines": "    ''' Subcommand to launch the Bokeh server.\n\n    '''\n\n    #: name for this subcommand\n    name = \"serve\"\n\n    help = \"Run a Bokeh server hosting one or more applications\"\n\n    args = base_serve_args + (\n        ('files', dict(\n            metavar = 'DIRECTORY-OR-SCRIPT',\n",
  "slicing": "    help = \"Run a Bokeh server hosting one or more applications\"\n"
 },
 "207": {
  "name": "args",
  "type": "tuple",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/command/subcommands/serve.py",
  "lineno": "508",
  "column": "4",
  "context": "keh server hosting one or more applications\"\n\n    args = base_serve_args + (\n        ('files', dict(\n            metavar = 'DIR",
  "context_lines": "    '''\n\n    #: name for this subcommand\n    name = \"serve\"\n\n    help = \"Run a Bokeh server hosting one or more applications\"\n\n    args = base_serve_args + (\n        ('files', dict(\n            metavar = 'DIRECTORY-OR-SCRIPT',\n            nargs   = '*',\n            help    = \"The app directories or scripts to serve (serve empty document if not specified)\",\n",
  "slicing": [
   "log = logging.getLogger(__name__)\n",
   "LOGLEVELS = ('trace', 'debug', 'info', 'warning', 'error', 'critical')\n",
   "SESSION_ID_MODES = ('unsigned', 'signed', 'external-signed')\n",
   "DEFAULT_LOG_FORMAT = \"%(asctime)s %(message)s\"\n",
   "base_serve_args = (\n",
   "        choices = LOGLEVELS + (\"None\", ),\n",
   "        help    = \"One of: %s\" % nice_join(LOGLEVELS),\n",
   "        default = DEFAULT_LOG_FORMAT,\n",
   "        help    = \"A standard Python logging format string (default: %r)\" % DEFAULT_LOG_FORMAT.replace(\"%\", \"%%\"),\n",
   "    name = \"serve\"\n",
   "    args = base_serve_args + (\n",
   "            choices = SESSION_ID_MODES,\n",
   "            help    = \"One of: %s\" % nice_join(SESSION_ID_MODES),\n",
   "        basicConfig(format=args.log_format, filename=args.log_file)\n",
   "        log_level = settings.py_log_level(args.log_level)\n",
   "        if log_level is None:\n",
   "            log_level = logging.INFO\n",
   "        logging.getLogger('bokeh').setLevel(log_level)\n",
   "        if args.use_config is not None:\n",
   "            log.info(f\"Using override config file: {args.use_config}\")\n",
   "            settings.load_config(args.use_config)\n",
   "        files = []\n",
   "        for f in args.files:\n",
   "            if args.glob:\n",
   "                files.extend(glob(f))\n",
   "                files.append(f)\n",
   "        argvs = { f : args.args for f in files}\n",
   "        applications = build_single_handler_applications(files, argvs)\n",
   "        if len(applications) == 0:\n",
   "            applications['/'] = Application()\n",
   "        if args.keep_alive is not None:\n",
   "            args.keep_alive_milliseconds = args.keep_alive\n",
   "        if args.check_unused_sessions is not None:\n",
   "            args.check_unused_sessions_milliseconds = args.check_unused_sessions\n",
   "        if args.unused_session_lifetime is not None:\n",
   "            args.unused_session_lifetime_milliseconds = args.unused_session_lifetime\n",
   "        if args.stats_log_frequency is not None:\n",
   "            args.stats_log_frequency_milliseconds = args.stats_log_frequency\n",
   "        if args.mem_log_frequency is not None:\n",
   "            args.mem_log_frequency_milliseconds = args.mem_log_frequency\n",
   "        server_kwargs = { key: getattr(args, key) for key in ['port',\n",
   "                          if getattr(args, key, None) is not None }\n",
   "        server_kwargs['sign_sessions'] = settings.sign_sessions()\n",
   "        server_kwargs['secret_key'] = settings.secret_key_bytes()\n",
   "        server_kwargs['ssl_certfile'] = settings.ssl_certfile(getattr(args, 'ssl_certfile', None))\n",
   "        server_kwargs['ssl_keyfile'] = settings.ssl_keyfile(getattr(args, 'ssl_keyfile', None))\n",
   "        server_kwargs['ssl_password'] = settings.ssl_password()\n",
   "        server_kwargs['generate_session_ids'] = True\n",
   "        if args.session_ids is None:\n",
   "        elif args.session_ids == 'unsigned':\n",
   "            server_kwargs['sign_sessions'] = False\n",
   "        elif args.session_ids == 'signed':\n",
   "            server_kwargs['sign_sessions'] = True\n",
   "        elif args.session_ids == 'external-signed':\n",
   "            server_kwargs['sign_sessions'] = True\n",
   "            server_kwargs['generate_session_ids'] = False\n",
   "                               args.session_ids)\n",
   "        if server_kwargs['sign_sessions'] and not server_kwargs['secret_key']:\n",
   "        auth_module_path = settings.auth_module(getattr(args, 'auth_module', None))\n",
   "        if auth_module_path:\n",
   "            server_kwargs['auth_provider'] = AuthModule(auth_module_path)\n",
   "            server_kwargs['auth_provider'] = NullAuth()\n",
   "        server_kwargs['xsrf_cookies'] = settings.xsrf_cookies(getattr(args, 'enable_xsrf_cookies', False))\n",
   "        server_kwargs['cookie_secret'] = settings.cookie_secret(getattr(args, 'cookie_secret', None))\n",
   "        server_kwargs['use_index'] = not args.disable_index\n",
   "        server_kwargs['redirect_root'] = not args.disable_index_redirect\n",
   "        server_kwargs['autoreload'] = args.dev is not None\n",
   "        def find_autoreload_targets(app_path: str) -> None:\n",
   "            path = os.path.abspath(app_path)\n",
   "            if not os.path.isdir(path):\n",
   "            for path, subdirs, files in os.walk(path):\n",
   "                for name in files:\n",
   "                    if (fnmatch(name, '*.html') or\n",
   "                        fnmatch(name, '*.css') or\n",
   "                        fnmatch(name, '*.yaml')):\n",
   "                        log.info(\"Watching: \" + os.path.join(path, name))\n",
   "                        watch(os.path.join(path, name))\n",
   "        def add_optional_autoreload_files(file_list: List[str]) -> None:\n",
   "            for filen in file_list:\n",
   "                if os.path.isdir(filen):\n",
   "                    log.warning(\"Cannot watch directory \" + filen)\n",
   "                log.info(\"Watching: \" + filen)\n",
   "                watch(filen)\n",
   "        if server_kwargs['autoreload']:\n",
   "            if len(applications.keys()) != 1:\n",
   "            if server_kwargs['num_procs'] != 1:\n",
   "                log.info(\"Running in --dev mode. --num-procs is limited to 1.\")\n",
   "                server_kwargs['num_procs'] = 1\n",
   "            find_autoreload_targets(args.files[0])\n",
   "            add_optional_autoreload_files(args.dev)\n",
   "        server_kwargs = self.customize_kwargs(args, server_kwargs)\n",
   "        with report_server_init_errors(**server_kwargs):\n",
   "            server = Server(applications, **server_kwargs)\n",
   "            if args.show:\n",
   "                    for route in applications.keys():\n",
   "                        server.show(route)\n",
   "                server.io_loop.add_callback(show_callback)\n",
   "            address_string = 'localhost'\n",
   "            if server.address is not None and server.address != '':\n",
   "                address_string = server.address\n",
   "            for route in sorted(applications.keys()):\n",
   "                url = \"http://%s:%d%s%s\" % (address_string, server.port, server.prefix, route)\n",
   "                log.info(\"Bokeh app running at: %s\" % url)\n",
   "            log.info(\"Starting Bokeh server with process id: %d\" % os.getpid())\n",
   "            server.run_until_shutdown()\n",
   "    LOGLEVELS=nice_join(LOGLEVELS),\n",
   "    SESSION_ID_MODES=nice_join(SESSION_ID_MODES),\n",
   "    DEFAULT_LOG_FORMAT=DEFAULT_LOG_FORMAT\n"
  ]
 },
 "208": {
  "name": "name",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/command/subcommands/static.py",
  "lineno": "48",
  "column": "4",
  "context": " server. '''\n\n    #: name for this subcommand\n    name = \"static\"\n\n    help = \"Serve bokehjs' static assets (JavaScr",
  "context_lines": "#-----------------------------------------------------------------------------\n\nclass Static(Subcommand):\n    ''' Subcommand to launch the Bokeh static server. '''\n\n    #: name for this subcommand\n    name = \"static\"\n\n    help = \"Serve bokehjs' static assets (JavaScript, CSS, images, fonts, etc.)\"\n\n    args = base_serve_args\n\n    def invoke(self, args: Namespace) -> None:\n",
  "slicing": "    name = \"static\"\n"
 },
 "209": {
  "name": "help",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/command/subcommands/static.py",
  "lineno": "50",
  "column": "4",
  "context": "name for this subcommand\n    name = \"static\"\n\n    help = \"Serve bokehjs' static assets (JavaScript, CSS, images, fonts, etc.)\"\n\n    args = base_serve_args\n\n    def invoke(self, ",
  "context_lines": "class Static(Subcommand):\n    ''' Subcommand to launch the Bokeh static server. '''\n\n    #: name for this subcommand\n    name = \"static\"\n\n    help = \"Serve bokehjs' static assets (JavaScript, CSS, images, fonts, etc.)\"\n\n    args = base_serve_args\n\n    def invoke(self, args: Namespace) -> None:\n        '''\n\n",
  "slicing": "    help = \"Serve bokehjs' static assets (JavaScript, CSS, images, fonts, etc.)\"\n"
 },
 "210": {
  "name": "name",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/command/subcommands/json.py",
  "lineno": "73",
  "column": "4",
  "context": "SON\n\n    '''\n\n    #: name for this subcommand\n    name = \"json\"\n\n    #: file extension for output generated by thi",
  "context_lines": "class JSON(FileOutputSubcommand):\n    ''' Subcommand to output applications as serialized JSON\n\n    '''\n\n    #: name for this subcommand\n    name = \"json\"\n\n    #: file extension for output generated by this :class:`~bokeh.command.subcommands.file_output.FileOutputSubcommand`\n    extension = \"json\"\n\n    help = \"Create JSON files for one or more applications\"\n\n",
  "slicing": "    name = \"json\"\n"
 },
 "211": {
  "name": "extension",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/command/subcommands/json.py",
  "lineno": "76",
  "column": "4",
  "context": "subcommands.file_output.FileOutputSubcommand`\n    extension = \"json\"\n\n    help = \"Create JSON files for one or more app",
  "context_lines": "    '''\n\n    #: name for this subcommand\n    name = \"json\"\n\n    #: file extension for output generated by this :class:`~bokeh.command.subcommands.file_output.FileOutputSubcommand`\n    extension = \"json\"\n\n    help = \"Create JSON files for one or more applications\"\n\n    args = (\n\n        FileOutputSubcommand.files_arg(\"JSON\"),\n\n",
  "slicing": "    extension = \"json\"\n"
 },
 "212": {
  "name": "help",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/command/subcommands/json.py",
  "lineno": "78",
  "column": "4",
  "context": "FileOutputSubcommand`\n    extension = \"json\"\n\n    help = \"Create JSON files for one or more applications\"\n\n    args = (\n\n        FileOutputSubcommand.files_",
  "context_lines": "    #: name for this subcommand\n    name = \"json\"\n\n    #: file extension for output generated by this :class:`~bokeh.command.subcommands.file_output.FileOutputSubcommand`\n    extension = \"json\"\n\n    help = \"Create JSON files for one or more applications\"\n\n    args = (\n\n        FileOutputSubcommand.files_arg(\"JSON\"),\n\n        ('--indent', dict(\n",
  "slicing": "    help = \"Create JSON files for one or more applications\"\n"
 },
 "213": {
  "name": "args",
  "type": "tuple",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/command/subcommands/json.py",
  "lineno": "80",
  "column": "4",
  "context": "ate JSON files for one or more applications\"\n\n    args = (\n\n        FileOutputSubcommand.files_arg(\"JSON\"),\n\n",
  "context_lines": "    name = \"json\"\n\n    #: file extension for output generated by this :class:`~bokeh.command.subcommands.file_output.FileOutputSubcommand`\n    extension = \"json\"\n\n    help = \"Create JSON files for one or more applications\"\n\n    args = (\n\n        FileOutputSubcommand.files_arg(\"JSON\"),\n\n        ('--indent', dict(\n            metavar='LEVEL',\n",
  "slicing": [
   "    args = (\n",
   "        return doc.to_json_string(indent=args.indent)\n"
  ]
 },
 "214": {
  "name": "name",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/command/subcommands/build.py",
  "lineno": "47",
  "column": "4",
  "context": "eh extension in the given directory.\n    '''\n\n    name = \"build\"\n\n    help = \"Manage and build a bokeh extension\"\n\n",
  "context_lines": "class Build(Subcommand):\n    '''\n    Build a bokeh extension in the given directory.\n    '''\n\n    name = \"build\"\n\n    help = \"Manage and build a bokeh extension\"\n\n    args = (\n        (\"base_dir\", dict(\n",
  "slicing": "    name = \"build\"\n"
 },
 "215": {
  "name": "help",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/command/subcommands/build.py",
  "lineno": "49",
  "column": "4",
  "context": "given directory.\n    '''\n\n    name = \"build\"\n\n    help = \"Manage and build a bokeh extension\"\n\n    args = (\n        (\"base_dir\", dict(\n         ",
  "context_lines": "    '''\n    Build a bokeh extension in the given directory.\n    '''\n\n    name = \"build\"\n\n    help = \"Manage and build a bokeh extension\"\n\n    args = (\n        (\"base_dir\", dict(\n            metavar=\"BASE_DIR\",\n",
  "slicing": "    help = \"Manage and build a bokeh extension\"\n"
 },
 "216": {
  "name": "value",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/enums.py",
  "lineno": "161",
  "column": "12",
  "context": "\n        if not self._case_sensitive:\n            value = value.lower()\n        return value in self._values\n\n    def __st",
  "context_lines": "    def __iter__(self):\n        return iter(self._values)\n\n    def __contains__(self, value):\n        if not self._case_sensitive:\n            value = value.lower()\n        return value in self._values\n\n    def __str__(self):\n        if self._quote:\n            return \"Enumeration(%s)\" % \", \".join(repr(x) for x in self._values)\n",
  "slicing": [
   "            value = value.lower()\n",
   "        return value in self._values\n",
   "            return \"Enumeration(%s)\" % \", \".join(repr(x) for x in self._values)\n",
   "    if not (values and all(isinstance(value, str) and value for value in values)):\n",
   "    attrs = {value: value for value in values}\n",
   "    attrs.update({\n",
   "    return type(\"Enumeration\", (Enumeration,), attrs)()\n"
  ]
 },
 "217": {
  "name": "__repr__",
  "type": "function",
  "class": "unknown",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/core/enums.py",
  "lineno": "173",
  "column": "4",
  "context": "en__(self):\n        return len(self._values)\n\n    __repr__ = __str__\n\ndef enumeration(*values, **kwargs):\n    ''' Creat",
  "context_lines": "        else:\n            return \"Enumeration(%s)\" % \", \".join(self._values)\n\n    def __len__(self):\n        return len(self._values)\n\n    __repr__ = __str__\n\ndef enumeration(*values, **kwargs):\n    ''' Create an |Enumeration| object from a sequence of values.\n\n    Call ``enumeration`` with a sequence of (unique) strings to create an\n",
  "slicing": [
   "            value = value.lower()\n",
   "        return value in self._values\n",
   "            return \"Enumeration(%s)\" % \", \".join(repr(x) for x in self._values)\n",
   "    __repr__ = __str__\n",
   "    if not (values and all(isinstance(value, str) and value for value in values)):\n",
   "    attrs = {value: value for value in values}\n",
   "    attrs.update({\n",
   "    return type(\"Enumeration\", (Enumeration,), attrs)()\n"
  ]
 },
 "218": {
  "name": "prop_descriptors",
  "type": "list",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/has_props.py",
  "lineno": "114",
  "column": "12",
  "context": "ame, generator in generators.items():\n            prop_descriptors = generator.make_descriptors(name)\n            replaced_self = False\n            for ",
  "context_lines": "                generators[name] = generator.autocreate()\n\n        dataspecs = {}\n        new_class_attrs = {}\n\n        for name, generator in generators.items():\n            prop_descriptors = generator.make_descriptors(name)\n            replaced_self = False\n            for prop_descriptor in prop_descriptors:\n                if prop_descriptor.name in generators:\n                    if generators[prop_descriptor.name] is generator:\n",
  "slicing": [
   "log = logging.getLogger(__name__)\n",
   "        names_with_refs = set()\n",
   "        container_names = set()\n",
   "        overridden_defaults = {}\n",
   "        for name, prop in class_dict.items():\n",
   "            if not isinstance(prop, Override):\n",
   "            if prop.default_overridden:\n",
   "                overridden_defaults[name] = prop.default\n",
   "        for name, default in overridden_defaults.items():\n",
   "            del class_dict[name]\n",
   "        generators = dict()\n",
   "        for name, generator in class_dict.items():\n",
   "            if isinstance(generator, PropertyDescriptorFactory):\n",
   "                generators[name] = generator\n",
   "            elif isinstance(generator, type) and issubclass(generator, PropertyDescriptorFactory):\n",
   "                generators[name] = generator.autocreate()\n",
   "        dataspecs = {}\n",
   "        new_class_attrs = {}\n",
   "        for name, generator in generators.items():\n",
   "            prop_descriptors = generator.make_descriptors(name)\n",
   "            replaced_self = False\n",
   "            for prop_descriptor in prop_descriptors:\n",
   "                if prop_descriptor.name in generators:\n",
   "                    if generators[prop_descriptor.name] is generator:\n",
   "                        replaced_self = True\n",
   "                        prop_descriptor.add_prop_descriptor_to_class(class_name, new_class_attrs, names_with_refs, container_names, dataspecs)\n",
   "                    prop_descriptor.add_prop_descriptor_to_class(class_name, new_class_attrs, names_with_refs, container_names, dataspecs)\n",
   "            if not replaced_self:\n",
   "                del class_dict[name]\n",
   "        class_dict.update(new_class_attrs)\n",
   "        class_dict[\"__properties__\"] = set(new_class_attrs)\n",
   "        class_dict[\"__properties_with_refs__\"] = names_with_refs\n",
   "        class_dict[\"__container_props__\"] = container_names\n",
   "        if len(overridden_defaults) > 0:\n",
   "            class_dict[\"__overridden_defaults__\"] = overridden_defaults\n",
   "        if dataspecs:\n",
   "            class_dict[\"__dataspecs__\"] = dataspecs\n",
   "            path = class_dict[\"__example__\"]\n",
   "                class_dict[\"__doc__\"] += _EXAMPLE_TEMPLATE % dict(path=path)\n",
   "        cls_attrs = cls.__dict__.keys() # we do NOT want inherited attrs here\n",
   "        for attr in cls_attrs:\n",
   "            for base in bases:\n",
   "                if issubclass(base, HasProps) and attr in base.properties():\n",
   "                         (attr, base.__name__, attr, class_name,\n",
   "                          base.__name__, attr,\n",
   "                          class_name, attr,\n",
   "                          base.__name__, attr),\n",
   "            our_props = cls.properties()\n",
   "            for key in cls.__dict__[\"__overridden_defaults__\"].keys():\n",
   "                if key not in our_props:\n",
   "                    warn(('Override() of %s in class %s does not override anything.') % (key, class_name),\n",
   "def accumulate_from_superclasses(cls, propname):\n",
   "    cachename = \"__cached_all\" + propname\n",
   "    if cachename not in cls.__dict__:\n",
   "        s = set()\n",
   "        for c in cls.__mro__:\n",
   "            if issubclass(c, HasProps) and hasattr(c, propname):\n",
   "                base = getattr(c, propname)\n",
   "                s.update(base)\n",
   "        setattr(cls, cachename, s)\n",
   "    return cls.__dict__[cachename]\n",
   "def accumulate_dict_from_superclasses(cls, propname):\n",
   "    cachename = \"__cached_all\" + propname\n",
   "    if cachename not in cls.__dict__:\n",
   "        d = dict()\n",
   "        for c in cls.__mro__:\n",
   "            if issubclass(c, HasProps) and hasattr(c, propname):\n",
   "                base = getattr(c, propname)\n",
   "                for k,v in base.items():\n",
   "                    if k not in d:\n",
   "                        d[k] = v\n",
   "        setattr(cls, cachename, d)\n",
   "    return cls.__dict__[cachename]\n",
   "        for name, value in properties.items():\n",
   "            setattr(self, name, value)\n",
   "        if name.startswith(\"_\"):\n",
   "            super().__setattr__(name, value)\n",
   "        props = sorted(self.properties())\n",
   "        descriptor = getattr(self.__class__, name, None)\n",
   "        if name in props or (descriptor is not None and descriptor.fset is not None):\n",
   "            super().__setattr__(name, value)\n",
   "            matches, text = difflib.get_close_matches(name.lower(), props), \"similar\"\n",
   "            if not matches:\n",
   "                matches, text = props, \"possible\"\n",
   "                (name, self.__class__.__name__, text, nice_join(matches)))\n",
   "        if name in self.properties():\n",
   "            log.trace(\"Patching attribute %r of %r with %r\", name, self, json)\n",
   "            descriptor = self.lookup(name)\n",
   "            descriptor.set_from_json(self, json, models, setter)\n",
   "            log.warning(\"JSON had attr %r on obj %r, which is a client-only or invalid attribute that shouldn't have been sent\", name, self)\n",
   "        for k,v in kwargs.items():\n",
   "            setattr(self, k, v)\n",
   "        for k, v in json_attributes.items():\n",
   "            self.set_from_json(k, v, models, setter)\n",
   "        return getattr(cls, name)\n",
   "        return accumulate_from_superclasses(cls, \"__properties_with_refs__\")\n",
   "        return accumulate_from_superclasses(cls, \"__container_props__\")\n",
   "            return accumulate_from_superclasses(cls, \"__properties__\")\n",
   "            return set(cls.__properties__)\n",
   "        return set(cls.dataspecs_with_props().keys())\n",
   "        return accumulate_dict_from_superclasses(cls, \"__dataspecs__\")\n",
   "        return self.query_properties_with_values(lambda prop: prop.serialized, include_defaults)\n",
   "        return accumulate_dict_from_superclasses(cls, \"__overridden_defaults__\")\n",
   "        themed_keys = set()\n",
   "        result = dict()\n",
   "            keys = self.properties()\n",
   "            keys = set(self._property_values.keys()) | set(self._unstable_default_values.keys())\n",
   "                themed_keys = set(self.themed_values().keys())\n",
   "                keys |= themed_keys\n",
   "        for key in keys:\n",
   "            descriptor = self.lookup(key)\n",
   "            if not query(descriptor):\n",
   "            value = descriptor.serializable_value(self)\n",
   "            if not include_defaults and key not in themed_keys:\n",
   "                if isinstance(value, PropertyValueContainer) and key in self._unstable_default_values:\n",
   "            result[key] = value\n",
   "        return result\n",
   "        old_dict = self.themed_values()\n",
   "        if old_dict is property_values:  # lgtm [py/comparison-using-is]\n",
   "        removed = set()\n",
   "        if old_dict is not None:\n",
   "            removed.update(set(old_dict.keys()))\n",
   "        added = set(property_values.keys())\n",
   "        old_values = dict()\n",
   "        for k in added.union(removed):\n",
   "            old_values[k] = getattr(self, k)\n",
   "        for k, v in old_values.items():\n",
   "            if k in self._unstable_themed_values:\n",
   "                del self._unstable_themed_values[k]\n",
   "        for k, v in old_values.items():\n",
   "            descriptor = self.lookup(k)\n",
   "            descriptor.trigger_if_changed(self, v)\n"
  ]
 },
 "219": {
  "name": "our_props",
  "type": "set",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/has_props.py",
  "lineno": "179",
  "column": "12",
  "context": "erridden_defaults__\" in cls.__dict__:\n            our_props = cls.properties()\n            for key in cls.__dict__[\"__overridden_",
  "context_lines": "                          class_name, attr,\n                          base.__name__, attr),\n                         RuntimeWarning, stacklevel=2)\n\n        if \"__overridden_defaults__\" in cls.__dict__:\n            our_props = cls.properties()\n            for key in cls.__dict__[\"__overridden_defaults__\"].keys():\n                if key not in our_props:\n                    warn(('Override() of %s in class %s does not override anything.') % (key, class_name),\n                         RuntimeWarning, stacklevel=2)\n\n",
  "slicing": [
   "log = logging.getLogger(__name__)\n",
   "        names_with_refs = set()\n",
   "        container_names = set()\n",
   "        overridden_defaults = {}\n",
   "        for name, prop in class_dict.items():\n",
   "            if not isinstance(prop, Override):\n",
   "            if prop.default_overridden:\n",
   "                overridden_defaults[name] = prop.default\n",
   "        for name, default in overridden_defaults.items():\n",
   "            del class_dict[name]\n",
   "        generators = dict()\n",
   "        for name, generator in class_dict.items():\n",
   "            if isinstance(generator, PropertyDescriptorFactory):\n",
   "                generators[name] = generator\n",
   "            elif isinstance(generator, type) and issubclass(generator, PropertyDescriptorFactory):\n",
   "                generators[name] = generator.autocreate()\n",
   "        dataspecs = {}\n",
   "        new_class_attrs = {}\n",
   "        for name, generator in generators.items():\n",
   "            prop_descriptors = generator.make_descriptors(name)\n",
   "            replaced_self = False\n",
   "            for prop_descriptor in prop_descriptors:\n",
   "                if prop_descriptor.name in generators:\n",
   "                    if generators[prop_descriptor.name] is generator:\n",
   "                        replaced_self = True\n",
   "                        prop_descriptor.add_prop_descriptor_to_class(class_name, new_class_attrs, names_with_refs, container_names, dataspecs)\n",
   "                    prop_descriptor.add_prop_descriptor_to_class(class_name, new_class_attrs, names_with_refs, container_names, dataspecs)\n",
   "            if not replaced_self:\n",
   "                del class_dict[name]\n",
   "        class_dict.update(new_class_attrs)\n",
   "        class_dict[\"__properties__\"] = set(new_class_attrs)\n",
   "        class_dict[\"__properties_with_refs__\"] = names_with_refs\n",
   "        class_dict[\"__container_props__\"] = container_names\n",
   "        if len(overridden_defaults) > 0:\n",
   "            class_dict[\"__overridden_defaults__\"] = overridden_defaults\n",
   "        if dataspecs:\n",
   "            class_dict[\"__dataspecs__\"] = dataspecs\n",
   "            path = class_dict[\"__example__\"]\n",
   "                class_dict[\"__doc__\"] += _EXAMPLE_TEMPLATE % dict(path=path)\n",
   "        cls_attrs = cls.__dict__.keys() # we do NOT want inherited attrs here\n",
   "        for attr in cls_attrs:\n",
   "            for base in bases:\n",
   "                if issubclass(base, HasProps) and attr in base.properties():\n",
   "                         (attr, base.__name__, attr, class_name,\n",
   "                          base.__name__, attr,\n",
   "                          class_name, attr,\n",
   "                          base.__name__, attr),\n",
   "            our_props = cls.properties()\n",
   "            for key in cls.__dict__[\"__overridden_defaults__\"].keys():\n",
   "                if key not in our_props:\n",
   "                    warn(('Override() of %s in class %s does not override anything.') % (key, class_name),\n",
   "def accumulate_from_superclasses(cls, propname):\n",
   "    cachename = \"__cached_all\" + propname\n",
   "    if cachename not in cls.__dict__:\n",
   "        s = set()\n",
   "        for c in cls.__mro__:\n",
   "            if issubclass(c, HasProps) and hasattr(c, propname):\n",
   "                base = getattr(c, propname)\n",
   "                s.update(base)\n",
   "        setattr(cls, cachename, s)\n",
   "    return cls.__dict__[cachename]\n",
   "def accumulate_dict_from_superclasses(cls, propname):\n",
   "    cachename = \"__cached_all\" + propname\n",
   "    if cachename not in cls.__dict__:\n",
   "        d = dict()\n",
   "        for c in cls.__mro__:\n",
   "            if issubclass(c, HasProps) and hasattr(c, propname):\n",
   "                base = getattr(c, propname)\n",
   "                for k,v in base.items():\n",
   "                    if k not in d:\n",
   "                        d[k] = v\n",
   "        setattr(cls, cachename, d)\n",
   "    return cls.__dict__[cachename]\n",
   "        for name, value in properties.items():\n",
   "            setattr(self, name, value)\n",
   "        if name.startswith(\"_\"):\n",
   "            super().__setattr__(name, value)\n",
   "        props = sorted(self.properties())\n",
   "        descriptor = getattr(self.__class__, name, None)\n",
   "        if name in props or (descriptor is not None and descriptor.fset is not None):\n",
   "            super().__setattr__(name, value)\n",
   "            matches, text = difflib.get_close_matches(name.lower(), props), \"similar\"\n",
   "            if not matches:\n",
   "                matches, text = props, \"possible\"\n",
   "                (name, self.__class__.__name__, text, nice_join(matches)))\n",
   "        if name in self.properties():\n",
   "            log.trace(\"Patching attribute %r of %r with %r\", name, self, json)\n",
   "            descriptor = self.lookup(name)\n",
   "            descriptor.set_from_json(self, json, models, setter)\n",
   "            log.warning(\"JSON had attr %r on obj %r, which is a client-only or invalid attribute that shouldn't have been sent\", name, self)\n",
   "        for k,v in kwargs.items():\n",
   "            setattr(self, k, v)\n",
   "        for k, v in json_attributes.items():\n",
   "            self.set_from_json(k, v, models, setter)\n",
   "        return getattr(cls, name)\n",
   "        return accumulate_from_superclasses(cls, \"__properties_with_refs__\")\n",
   "        return accumulate_from_superclasses(cls, \"__container_props__\")\n",
   "            return accumulate_from_superclasses(cls, \"__properties__\")\n",
   "            return set(cls.__properties__)\n",
   "        return set(cls.dataspecs_with_props().keys())\n",
   "        return accumulate_dict_from_superclasses(cls, \"__dataspecs__\")\n",
   "        return self.query_properties_with_values(lambda prop: prop.serialized, include_defaults)\n",
   "        return accumulate_dict_from_superclasses(cls, \"__overridden_defaults__\")\n",
   "        themed_keys = set()\n",
   "        result = dict()\n",
   "            keys = self.properties()\n",
   "            keys = set(self._property_values.keys()) | set(self._unstable_default_values.keys())\n",
   "                themed_keys = set(self.themed_values().keys())\n",
   "                keys |= themed_keys\n",
   "        for key in keys:\n",
   "            descriptor = self.lookup(key)\n",
   "            if not query(descriptor):\n",
   "            value = descriptor.serializable_value(self)\n",
   "            if not include_defaults and key not in themed_keys:\n",
   "                if isinstance(value, PropertyValueContainer) and key in self._unstable_default_values:\n",
   "            result[key] = value\n",
   "        return result\n",
   "        old_dict = self.themed_values()\n",
   "        if old_dict is property_values:  # lgtm [py/comparison-using-is]\n",
   "        removed = set()\n",
   "        if old_dict is not None:\n",
   "            removed.update(set(old_dict.keys()))\n",
   "        added = set(property_values.keys())\n",
   "        old_values = dict()\n",
   "        for k in added.union(removed):\n",
   "            old_values[k] = getattr(self, k)\n",
   "        for k, v in old_values.items():\n",
   "            if k in self._unstable_themed_values:\n",
   "                del self._unstable_themed_values[k]\n",
   "        for k, v in old_values.items():\n",
   "            descriptor = self.lookup(k)\n",
   "            descriptor.trigger_if_changed(self, v)\n"
  ]
 },
 "220": {
  "name": "cachename",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/has_props.py",
  "lineno": "196",
  "column": "4",
  "context": "es__``, ``__properties_with_refs__``\n\n    '''\n    cachename = \"__cached_all\" + propname\n    # we MUST use cls.__dict__ NOT hasattr(). hasa",
  "context_lines": "        name (str) : name of the special attribute to collect.\n\n            Typically meaningful values are: ``__container_props__``,\n            ``__properties__``, ``__properties_with_refs__``\n\n    '''\n    cachename = \"__cached_all\" + propname\n    # we MUST use cls.__dict__ NOT hasattr(). hasattr() would also look at base\n    # classes, and the cache must be separate for each class\n    if cachename not in cls.__dict__:\n        s = set()\n",
  "slicing": [
   "log = logging.getLogger(__name__)\n",
   "        names_with_refs = set()\n",
   "        container_names = set()\n",
   "        overridden_defaults = {}\n",
   "        for name, prop in class_dict.items():\n",
   "            if not isinstance(prop, Override):\n",
   "            if prop.default_overridden:\n",
   "                overridden_defaults[name] = prop.default\n",
   "        for name, default in overridden_defaults.items():\n",
   "            del class_dict[name]\n",
   "        generators = dict()\n",
   "        for name, generator in class_dict.items():\n",
   "            if isinstance(generator, PropertyDescriptorFactory):\n",
   "                generators[name] = generator\n",
   "            elif isinstance(generator, type) and issubclass(generator, PropertyDescriptorFactory):\n",
   "                generators[name] = generator.autocreate()\n",
   "        dataspecs = {}\n",
   "        new_class_attrs = {}\n",
   "        for name, generator in generators.items():\n",
   "            prop_descriptors = generator.make_descriptors(name)\n",
   "            replaced_self = False\n",
   "            for prop_descriptor in prop_descriptors:\n",
   "                if prop_descriptor.name in generators:\n",
   "                    if generators[prop_descriptor.name] is generator:\n",
   "                        replaced_self = True\n",
   "                        prop_descriptor.add_prop_descriptor_to_class(class_name, new_class_attrs, names_with_refs, container_names, dataspecs)\n",
   "                    prop_descriptor.add_prop_descriptor_to_class(class_name, new_class_attrs, names_with_refs, container_names, dataspecs)\n",
   "            if not replaced_self:\n",
   "                del class_dict[name]\n",
   "        class_dict.update(new_class_attrs)\n",
   "        class_dict[\"__properties__\"] = set(new_class_attrs)\n",
   "        class_dict[\"__properties_with_refs__\"] = names_with_refs\n",
   "        class_dict[\"__container_props__\"] = container_names\n",
   "        if len(overridden_defaults) > 0:\n",
   "            class_dict[\"__overridden_defaults__\"] = overridden_defaults\n",
   "        if dataspecs:\n",
   "            class_dict[\"__dataspecs__\"] = dataspecs\n",
   "            path = class_dict[\"__example__\"]\n",
   "                class_dict[\"__doc__\"] += _EXAMPLE_TEMPLATE % dict(path=path)\n",
   "        cls_attrs = cls.__dict__.keys() # we do NOT want inherited attrs here\n",
   "        for attr in cls_attrs:\n",
   "            for base in bases:\n",
   "                if issubclass(base, HasProps) and attr in base.properties():\n",
   "                         (attr, base.__name__, attr, class_name,\n",
   "                          base.__name__, attr,\n",
   "                          class_name, attr,\n",
   "                          base.__name__, attr),\n",
   "            our_props = cls.properties()\n",
   "            for key in cls.__dict__[\"__overridden_defaults__\"].keys():\n",
   "                if key not in our_props:\n",
   "                    warn(('Override() of %s in class %s does not override anything.') % (key, class_name),\n",
   "def accumulate_from_superclasses(cls, propname):\n",
   "    cachename = \"__cached_all\" + propname\n",
   "    if cachename not in cls.__dict__:\n",
   "        s = set()\n",
   "        for c in cls.__mro__:\n",
   "            if issubclass(c, HasProps) and hasattr(c, propname):\n",
   "                base = getattr(c, propname)\n",
   "                s.update(base)\n",
   "        setattr(cls, cachename, s)\n",
   "    return cls.__dict__[cachename]\n",
   "def accumulate_dict_from_superclasses(cls, propname):\n",
   "    cachename = \"__cached_all\" + propname\n",
   "    if cachename not in cls.__dict__:\n",
   "        d = dict()\n",
   "        for c in cls.__mro__:\n",
   "            if issubclass(c, HasProps) and hasattr(c, propname):\n",
   "                base = getattr(c, propname)\n",
   "                for k,v in base.items():\n",
   "                    if k not in d:\n",
   "                        d[k] = v\n",
   "        setattr(cls, cachename, d)\n",
   "    return cls.__dict__[cachename]\n",
   "        for name, value in properties.items():\n",
   "            setattr(self, name, value)\n",
   "        if name.startswith(\"_\"):\n",
   "            super().__setattr__(name, value)\n",
   "        props = sorted(self.properties())\n",
   "        descriptor = getattr(self.__class__, name, None)\n",
   "        if name in props or (descriptor is not None and descriptor.fset is not None):\n",
   "            super().__setattr__(name, value)\n",
   "            matches, text = difflib.get_close_matches(name.lower(), props), \"similar\"\n",
   "            if not matches:\n",
   "                matches, text = props, \"possible\"\n",
   "                (name, self.__class__.__name__, text, nice_join(matches)))\n",
   "        if name in self.properties():\n",
   "            log.trace(\"Patching attribute %r of %r with %r\", name, self, json)\n",
   "            descriptor = self.lookup(name)\n",
   "            descriptor.set_from_json(self, json, models, setter)\n",
   "            log.warning(\"JSON had attr %r on obj %r, which is a client-only or invalid attribute that shouldn't have been sent\", name, self)\n",
   "        for k,v in kwargs.items():\n",
   "            setattr(self, k, v)\n",
   "        for k, v in json_attributes.items():\n",
   "            self.set_from_json(k, v, models, setter)\n",
   "        return getattr(cls, name)\n",
   "        return accumulate_from_superclasses(cls, \"__properties_with_refs__\")\n",
   "        return accumulate_from_superclasses(cls, \"__container_props__\")\n",
   "            return accumulate_from_superclasses(cls, \"__properties__\")\n",
   "            return set(cls.__properties__)\n",
   "        return set(cls.dataspecs_with_props().keys())\n",
   "        return accumulate_dict_from_superclasses(cls, \"__dataspecs__\")\n",
   "        return self.query_properties_with_values(lambda prop: prop.serialized, include_defaults)\n",
   "        return accumulate_dict_from_superclasses(cls, \"__overridden_defaults__\")\n",
   "        themed_keys = set()\n",
   "        result = dict()\n",
   "            keys = self.properties()\n",
   "            keys = set(self._property_values.keys()) | set(self._unstable_default_values.keys())\n",
   "                themed_keys = set(self.themed_values().keys())\n",
   "                keys |= themed_keys\n",
   "        for key in keys:\n",
   "            descriptor = self.lookup(key)\n",
   "            if not query(descriptor):\n",
   "            value = descriptor.serializable_value(self)\n",
   "            if not include_defaults and key not in themed_keys:\n",
   "                if isinstance(value, PropertyValueContainer) and key in self._unstable_default_values:\n",
   "            result[key] = value\n",
   "        return result\n",
   "        old_dict = self.themed_values()\n",
   "        if old_dict is property_values:  # lgtm [py/comparison-using-is]\n",
   "        removed = set()\n",
   "        if old_dict is not None:\n",
   "            removed.update(set(old_dict.keys()))\n",
   "        added = set(property_values.keys())\n",
   "        old_values = dict()\n",
   "        for k in added.union(removed):\n",
   "            old_values[k] = getattr(self, k)\n",
   "        for k, v in old_values.items():\n",
   "            if k in self._unstable_themed_values:\n",
   "                del self._unstable_themed_values[k]\n",
   "        for k, v in old_values.items():\n",
   "            descriptor = self.lookup(k)\n",
   "            descriptor.trigger_if_changed(self, v)\n"
  ]
 },
 "221": {
  "name": "base",
  "type": "set",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/core/has_props.py",
  "lineno": "203",
  "column": "16",
  "context": "sProps) and hasattr(c, propname):\n                base = getattr(c, propname)\n                s.update(base)\n        setattr(cls",
  "context_lines": "    if cachename not in cls.__dict__:\n        s = set()\n        for c in cls.__mro__:\n            if issubclass(c, HasProps) and hasattr(c, propname):\n                base = getattr(c, propname)\n                s.update(base)\n        setattr(cls, cachename, s)\n    return cls.__dict__[cachename]\n\ndef accumulate_dict_from_superclasses(cls, propname):\n",
  "slicing": [
   "log = logging.getLogger(__name__)\n",
   "        names_with_refs = set()\n",
   "        container_names = set()\n",
   "        overridden_defaults = {}\n",
   "        for name, prop in class_dict.items():\n",
   "            if not isinstance(prop, Override):\n",
   "            if prop.default_overridden:\n",
   "                overridden_defaults[name] = prop.default\n",
   "        for name, default in overridden_defaults.items():\n",
   "            del class_dict[name]\n",
   "        generators = dict()\n",
   "        for name, generator in class_dict.items():\n",
   "            if isinstance(generator, PropertyDescriptorFactory):\n",
   "                generators[name] = generator\n",
   "            elif isinstance(generator, type) and issubclass(generator, PropertyDescriptorFactory):\n",
   "                generators[name] = generator.autocreate()\n",
   "        dataspecs = {}\n",
   "        new_class_attrs = {}\n",
   "        for name, generator in generators.items():\n",
   "            prop_descriptors = generator.make_descriptors(name)\n",
   "            replaced_self = False\n",
   "            for prop_descriptor in prop_descriptors:\n",
   "                if prop_descriptor.name in generators:\n",
   "                    if generators[prop_descriptor.name] is generator:\n",
   "                        replaced_self = True\n",
   "                        prop_descriptor.add_prop_descriptor_to_class(class_name, new_class_attrs, names_with_refs, container_names, dataspecs)\n",
   "                    prop_descriptor.add_prop_descriptor_to_class(class_name, new_class_attrs, names_with_refs, container_names, dataspecs)\n",
   "            if not replaced_self:\n",
   "                del class_dict[name]\n",
   "        class_dict.update(new_class_attrs)\n",
   "        class_dict[\"__properties__\"] = set(new_class_attrs)\n",
   "        class_dict[\"__properties_with_refs__\"] = names_with_refs\n",
   "        class_dict[\"__container_props__\"] = container_names\n",
   "        if len(overridden_defaults) > 0:\n",
   "            class_dict[\"__overridden_defaults__\"] = overridden_defaults\n",
   "        if dataspecs:\n",
   "            class_dict[\"__dataspecs__\"] = dataspecs\n",
   "            path = class_dict[\"__example__\"]\n",
   "                class_dict[\"__doc__\"] += _EXAMPLE_TEMPLATE % dict(path=path)\n",
   "        cls_attrs = cls.__dict__.keys() # we do NOT want inherited attrs here\n",
   "        for attr in cls_attrs:\n",
   "            for base in bases:\n",
   "                if issubclass(base, HasProps) and attr in base.properties():\n",
   "                         (attr, base.__name__, attr, class_name,\n",
   "                          base.__name__, attr,\n",
   "                          class_name, attr,\n",
   "                          base.__name__, attr),\n",
   "            our_props = cls.properties()\n",
   "            for key in cls.__dict__[\"__overridden_defaults__\"].keys():\n",
   "                if key not in our_props:\n",
   "                    warn(('Override() of %s in class %s does not override anything.') % (key, class_name),\n",
   "def accumulate_from_superclasses(cls, propname):\n",
   "    cachename = \"__cached_all\" + propname\n",
   "    if cachename not in cls.__dict__:\n",
   "        s = set()\n",
   "        for c in cls.__mro__:\n",
   "            if issubclass(c, HasProps) and hasattr(c, propname):\n",
   "                base = getattr(c, propname)\n",
   "                s.update(base)\n",
   "        setattr(cls, cachename, s)\n",
   "    return cls.__dict__[cachename]\n",
   "def accumulate_dict_from_superclasses(cls, propname):\n",
   "    cachename = \"__cached_all\" + propname\n",
   "    if cachename not in cls.__dict__:\n",
   "        d = dict()\n",
   "        for c in cls.__mro__:\n",
   "            if issubclass(c, HasProps) and hasattr(c, propname):\n",
   "                base = getattr(c, propname)\n",
   "                for k,v in base.items():\n",
   "                    if k not in d:\n",
   "                        d[k] = v\n",
   "        setattr(cls, cachename, d)\n",
   "    return cls.__dict__[cachename]\n",
   "        for name, value in properties.items():\n",
   "            setattr(self, name, value)\n",
   "        if name.startswith(\"_\"):\n",
   "            super().__setattr__(name, value)\n",
   "        props = sorted(self.properties())\n",
   "        descriptor = getattr(self.__class__, name, None)\n",
   "        if name in props or (descriptor is not None and descriptor.fset is not None):\n",
   "            super().__setattr__(name, value)\n",
   "            matches, text = difflib.get_close_matches(name.lower(), props), \"similar\"\n",
   "            if not matches:\n",
   "                matches, text = props, \"possible\"\n",
   "                (name, self.__class__.__name__, text, nice_join(matches)))\n",
   "        if name in self.properties():\n",
   "            log.trace(\"Patching attribute %r of %r with %r\", name, self, json)\n",
   "            descriptor = self.lookup(name)\n",
   "            descriptor.set_from_json(self, json, models, setter)\n",
   "            log.warning(\"JSON had attr %r on obj %r, which is a client-only or invalid attribute that shouldn't have been sent\", name, self)\n",
   "        for k,v in kwargs.items():\n",
   "            setattr(self, k, v)\n",
   "        for k, v in json_attributes.items():\n",
   "            self.set_from_json(k, v, models, setter)\n",
   "        return getattr(cls, name)\n",
   "        return accumulate_from_superclasses(cls, \"__properties_with_refs__\")\n",
   "        return accumulate_from_superclasses(cls, \"__container_props__\")\n",
   "            return accumulate_from_superclasses(cls, \"__properties__\")\n",
   "            return set(cls.__properties__)\n",
   "        return set(cls.dataspecs_with_props().keys())\n",
   "        return accumulate_dict_from_superclasses(cls, \"__dataspecs__\")\n",
   "        return self.query_properties_with_values(lambda prop: prop.serialized, include_defaults)\n",
   "        return accumulate_dict_from_superclasses(cls, \"__overridden_defaults__\")\n",
   "        themed_keys = set()\n",
   "        result = dict()\n",
   "            keys = self.properties()\n",
   "            keys = set(self._property_values.keys()) | set(self._unstable_default_values.keys())\n",
   "                themed_keys = set(self.themed_values().keys())\n",
   "                keys |= themed_keys\n",
   "        for key in keys:\n",
   "            descriptor = self.lookup(key)\n",
   "            if not query(descriptor):\n",
   "            value = descriptor.serializable_value(self)\n",
   "            if not include_defaults and key not in themed_keys:\n",
   "                if isinstance(value, PropertyValueContainer) and key in self._unstable_default_values:\n",
   "            result[key] = value\n",
   "        return result\n",
   "        old_dict = self.themed_values()\n",
   "        if old_dict is property_values:  # lgtm [py/comparison-using-is]\n",
   "        removed = set()\n",
   "        if old_dict is not None:\n",
   "            removed.update(set(old_dict.keys()))\n",
   "        added = set(property_values.keys())\n",
   "        old_values = dict()\n",
   "        for k in added.union(removed):\n",
   "            old_values[k] = getattr(self, k)\n",
   "        for k, v in old_values.items():\n",
   "            if k in self._unstable_themed_values:\n",
   "                del self._unstable_themed_values[k]\n",
   "        for k, v in old_values.items():\n",
   "            descriptor = self.lookup(k)\n",
   "            descriptor.trigger_if_changed(self, v)\n"
  ]
 },
 "222": {
  "name": "cachename",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/has_props.py",
  "lineno": "219",
  "column": "4",
  "context": "         ``__overridden_defaults__``\n\n    '''\n    cachename = \"__cached_all\" + propname\n    # we MUST use cls.__dict__ NOT hasattr(). hasa",
  "context_lines": "        name (str) : name of the special attribute to collect.\n\n            Typically meaningful values are: ``__dataspecs__``,\n            ``__overridden_defaults__``\n\n    '''\n    cachename = \"__cached_all\" + propname\n    # we MUST use cls.__dict__ NOT hasattr(). hasattr() would also look at base\n    # classes, and the cache must be separate for each class\n    if cachename not in cls.__dict__:\n        d = dict()\n",
  "slicing": [
   "log = logging.getLogger(__name__)\n",
   "        names_with_refs = set()\n",
   "        container_names = set()\n",
   "        overridden_defaults = {}\n",
   "        for name, prop in class_dict.items():\n",
   "            if not isinstance(prop, Override):\n",
   "            if prop.default_overridden:\n",
   "                overridden_defaults[name] = prop.default\n",
   "        for name, default in overridden_defaults.items():\n",
   "            del class_dict[name]\n",
   "        generators = dict()\n",
   "        for name, generator in class_dict.items():\n",
   "            if isinstance(generator, PropertyDescriptorFactory):\n",
   "                generators[name] = generator\n",
   "            elif isinstance(generator, type) and issubclass(generator, PropertyDescriptorFactory):\n",
   "                generators[name] = generator.autocreate()\n",
   "        dataspecs = {}\n",
   "        new_class_attrs = {}\n",
   "        for name, generator in generators.items():\n",
   "            prop_descriptors = generator.make_descriptors(name)\n",
   "            replaced_self = False\n",
   "            for prop_descriptor in prop_descriptors:\n",
   "                if prop_descriptor.name in generators:\n",
   "                    if generators[prop_descriptor.name] is generator:\n",
   "                        replaced_self = True\n",
   "                        prop_descriptor.add_prop_descriptor_to_class(class_name, new_class_attrs, names_with_refs, container_names, dataspecs)\n",
   "                    prop_descriptor.add_prop_descriptor_to_class(class_name, new_class_attrs, names_with_refs, container_names, dataspecs)\n",
   "            if not replaced_self:\n",
   "                del class_dict[name]\n",
   "        class_dict.update(new_class_attrs)\n",
   "        class_dict[\"__properties__\"] = set(new_class_attrs)\n",
   "        class_dict[\"__properties_with_refs__\"] = names_with_refs\n",
   "        class_dict[\"__container_props__\"] = container_names\n",
   "        if len(overridden_defaults) > 0:\n",
   "            class_dict[\"__overridden_defaults__\"] = overridden_defaults\n",
   "        if dataspecs:\n",
   "            class_dict[\"__dataspecs__\"] = dataspecs\n",
   "            path = class_dict[\"__example__\"]\n",
   "                class_dict[\"__doc__\"] += _EXAMPLE_TEMPLATE % dict(path=path)\n",
   "        cls_attrs = cls.__dict__.keys() # we do NOT want inherited attrs here\n",
   "        for attr in cls_attrs:\n",
   "            for base in bases:\n",
   "                if issubclass(base, HasProps) and attr in base.properties():\n",
   "                         (attr, base.__name__, attr, class_name,\n",
   "                          base.__name__, attr,\n",
   "                          class_name, attr,\n",
   "                          base.__name__, attr),\n",
   "            our_props = cls.properties()\n",
   "            for key in cls.__dict__[\"__overridden_defaults__\"].keys():\n",
   "                if key not in our_props:\n",
   "                    warn(('Override() of %s in class %s does not override anything.') % (key, class_name),\n",
   "def accumulate_from_superclasses(cls, propname):\n",
   "    cachename = \"__cached_all\" + propname\n",
   "    if cachename not in cls.__dict__:\n",
   "        s = set()\n",
   "        for c in cls.__mro__:\n",
   "            if issubclass(c, HasProps) and hasattr(c, propname):\n",
   "                base = getattr(c, propname)\n",
   "                s.update(base)\n",
   "        setattr(cls, cachename, s)\n",
   "    return cls.__dict__[cachename]\n",
   "def accumulate_dict_from_superclasses(cls, propname):\n",
   "    cachename = \"__cached_all\" + propname\n",
   "    if cachename not in cls.__dict__:\n",
   "        d = dict()\n",
   "        for c in cls.__mro__:\n",
   "            if issubclass(c, HasProps) and hasattr(c, propname):\n",
   "                base = getattr(c, propname)\n",
   "                for k,v in base.items():\n",
   "                    if k not in d:\n",
   "                        d[k] = v\n",
   "        setattr(cls, cachename, d)\n",
   "    return cls.__dict__[cachename]\n",
   "        for name, value in properties.items():\n",
   "            setattr(self, name, value)\n",
   "        if name.startswith(\"_\"):\n",
   "            super().__setattr__(name, value)\n",
   "        props = sorted(self.properties())\n",
   "        descriptor = getattr(self.__class__, name, None)\n",
   "        if name in props or (descriptor is not None and descriptor.fset is not None):\n",
   "            super().__setattr__(name, value)\n",
   "            matches, text = difflib.get_close_matches(name.lower(), props), \"similar\"\n",
   "            if not matches:\n",
   "                matches, text = props, \"possible\"\n",
   "                (name, self.__class__.__name__, text, nice_join(matches)))\n",
   "        if name in self.properties():\n",
   "            log.trace(\"Patching attribute %r of %r with %r\", name, self, json)\n",
   "            descriptor = self.lookup(name)\n",
   "            descriptor.set_from_json(self, json, models, setter)\n",
   "            log.warning(\"JSON had attr %r on obj %r, which is a client-only or invalid attribute that shouldn't have been sent\", name, self)\n",
   "        for k,v in kwargs.items():\n",
   "            setattr(self, k, v)\n",
   "        for k, v in json_attributes.items():\n",
   "            self.set_from_json(k, v, models, setter)\n",
   "        return getattr(cls, name)\n",
   "        return accumulate_from_superclasses(cls, \"__properties_with_refs__\")\n",
   "        return accumulate_from_superclasses(cls, \"__container_props__\")\n",
   "            return accumulate_from_superclasses(cls, \"__properties__\")\n",
   "            return set(cls.__properties__)\n",
   "        return set(cls.dataspecs_with_props().keys())\n",
   "        return accumulate_dict_from_superclasses(cls, \"__dataspecs__\")\n",
   "        return self.query_properties_with_values(lambda prop: prop.serialized, include_defaults)\n",
   "        return accumulate_dict_from_superclasses(cls, \"__overridden_defaults__\")\n",
   "        themed_keys = set()\n",
   "        result = dict()\n",
   "            keys = self.properties()\n",
   "            keys = set(self._property_values.keys()) | set(self._unstable_default_values.keys())\n",
   "                themed_keys = set(self.themed_values().keys())\n",
   "                keys |= themed_keys\n",
   "        for key in keys:\n",
   "            descriptor = self.lookup(key)\n",
   "            if not query(descriptor):\n",
   "            value = descriptor.serializable_value(self)\n",
   "            if not include_defaults and key not in themed_keys:\n",
   "                if isinstance(value, PropertyValueContainer) and key in self._unstable_default_values:\n",
   "            result[key] = value\n",
   "        return result\n",
   "        old_dict = self.themed_values()\n",
   "        if old_dict is property_values:  # lgtm [py/comparison-using-is]\n",
   "        removed = set()\n",
   "        if old_dict is not None:\n",
   "            removed.update(set(old_dict.keys()))\n",
   "        added = set(property_values.keys())\n",
   "        old_values = dict()\n",
   "        for k in added.union(removed):\n",
   "            old_values[k] = getattr(self, k)\n",
   "        for k, v in old_values.items():\n",
   "            if k in self._unstable_themed_values:\n",
   "                del self._unstable_themed_values[k]\n",
   "        for k, v in old_values.items():\n",
   "            descriptor = self.lookup(k)\n",
   "            descriptor.trigger_if_changed(self, v)\n"
  ]
 },
 "223": {
  "name": "base",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/core/has_props.py",
  "lineno": "226",
  "column": "16",
  "context": "sProps) and hasattr(c, propname):\n                base = getattr(c, propname)\n                for k,v in base.items():\n         ",
  "context_lines": "    if cachename not in cls.__dict__:\n        d = dict()\n        for c in cls.__mro__:\n            if issubclass(c, HasProps) and hasattr(c, propname):\n                base = getattr(c, propname)\n                for k,v in base.items():\n                    if k not in d:\n                        d[k] = v\n        setattr(cls, cachename, d)\n",
  "slicing": [
   "log = logging.getLogger(__name__)\n",
   "        names_with_refs = set()\n",
   "        container_names = set()\n",
   "        overridden_defaults = {}\n",
   "        for name, prop in class_dict.items():\n",
   "            if not isinstance(prop, Override):\n",
   "            if prop.default_overridden:\n",
   "                overridden_defaults[name] = prop.default\n",
   "        for name, default in overridden_defaults.items():\n",
   "            del class_dict[name]\n",
   "        generators = dict()\n",
   "        for name, generator in class_dict.items():\n",
   "            if isinstance(generator, PropertyDescriptorFactory):\n",
   "                generators[name] = generator\n",
   "            elif isinstance(generator, type) and issubclass(generator, PropertyDescriptorFactory):\n",
   "                generators[name] = generator.autocreate()\n",
   "        dataspecs = {}\n",
   "        new_class_attrs = {}\n",
   "        for name, generator in generators.items():\n",
   "            prop_descriptors = generator.make_descriptors(name)\n",
   "            replaced_self = False\n",
   "            for prop_descriptor in prop_descriptors:\n",
   "                if prop_descriptor.name in generators:\n",
   "                    if generators[prop_descriptor.name] is generator:\n",
   "                        replaced_self = True\n",
   "                        prop_descriptor.add_prop_descriptor_to_class(class_name, new_class_attrs, names_with_refs, container_names, dataspecs)\n",
   "                    prop_descriptor.add_prop_descriptor_to_class(class_name, new_class_attrs, names_with_refs, container_names, dataspecs)\n",
   "            if not replaced_self:\n",
   "                del class_dict[name]\n",
   "        class_dict.update(new_class_attrs)\n",
   "        class_dict[\"__properties__\"] = set(new_class_attrs)\n",
   "        class_dict[\"__properties_with_refs__\"] = names_with_refs\n",
   "        class_dict[\"__container_props__\"] = container_names\n",
   "        if len(overridden_defaults) > 0:\n",
   "            class_dict[\"__overridden_defaults__\"] = overridden_defaults\n",
   "        if dataspecs:\n",
   "            class_dict[\"__dataspecs__\"] = dataspecs\n",
   "            path = class_dict[\"__example__\"]\n",
   "                class_dict[\"__doc__\"] += _EXAMPLE_TEMPLATE % dict(path=path)\n",
   "        cls_attrs = cls.__dict__.keys() # we do NOT want inherited attrs here\n",
   "        for attr in cls_attrs:\n",
   "            for base in bases:\n",
   "                if issubclass(base, HasProps) and attr in base.properties():\n",
   "                         (attr, base.__name__, attr, class_name,\n",
   "                          base.__name__, attr,\n",
   "                          class_name, attr,\n",
   "                          base.__name__, attr),\n",
   "            our_props = cls.properties()\n",
   "            for key in cls.__dict__[\"__overridden_defaults__\"].keys():\n",
   "                if key not in our_props:\n",
   "                    warn(('Override() of %s in class %s does not override anything.') % (key, class_name),\n",
   "def accumulate_from_superclasses(cls, propname):\n",
   "    cachename = \"__cached_all\" + propname\n",
   "    if cachename not in cls.__dict__:\n",
   "        s = set()\n",
   "        for c in cls.__mro__:\n",
   "            if issubclass(c, HasProps) and hasattr(c, propname):\n",
   "                base = getattr(c, propname)\n",
   "                s.update(base)\n",
   "        setattr(cls, cachename, s)\n",
   "    return cls.__dict__[cachename]\n",
   "def accumulate_dict_from_superclasses(cls, propname):\n",
   "    cachename = \"__cached_all\" + propname\n",
   "    if cachename not in cls.__dict__:\n",
   "        d = dict()\n",
   "        for c in cls.__mro__:\n",
   "            if issubclass(c, HasProps) and hasattr(c, propname):\n",
   "                base = getattr(c, propname)\n",
   "                for k,v in base.items():\n",
   "                    if k not in d:\n",
   "                        d[k] = v\n",
   "        setattr(cls, cachename, d)\n",
   "    return cls.__dict__[cachename]\n",
   "        for name, value in properties.items():\n",
   "            setattr(self, name, value)\n",
   "        if name.startswith(\"_\"):\n",
   "            super().__setattr__(name, value)\n",
   "        props = sorted(self.properties())\n",
   "        descriptor = getattr(self.__class__, name, None)\n",
   "        if name in props or (descriptor is not None and descriptor.fset is not None):\n",
   "            super().__setattr__(name, value)\n",
   "            matches, text = difflib.get_close_matches(name.lower(), props), \"similar\"\n",
   "            if not matches:\n",
   "                matches, text = props, \"possible\"\n",
   "                (name, self.__class__.__name__, text, nice_join(matches)))\n",
   "        if name in self.properties():\n",
   "            log.trace(\"Patching attribute %r of %r with %r\", name, self, json)\n",
   "            descriptor = self.lookup(name)\n",
   "            descriptor.set_from_json(self, json, models, setter)\n",
   "            log.warning(\"JSON had attr %r on obj %r, which is a client-only or invalid attribute that shouldn't have been sent\", name, self)\n",
   "        for k,v in kwargs.items():\n",
   "            setattr(self, k, v)\n",
   "        for k, v in json_attributes.items():\n",
   "            self.set_from_json(k, v, models, setter)\n",
   "        return getattr(cls, name)\n",
   "        return accumulate_from_superclasses(cls, \"__properties_with_refs__\")\n",
   "        return accumulate_from_superclasses(cls, \"__container_props__\")\n",
   "            return accumulate_from_superclasses(cls, \"__properties__\")\n",
   "            return set(cls.__properties__)\n",
   "        return set(cls.dataspecs_with_props().keys())\n",
   "        return accumulate_dict_from_superclasses(cls, \"__dataspecs__\")\n",
   "        return self.query_properties_with_values(lambda prop: prop.serialized, include_defaults)\n",
   "        return accumulate_dict_from_superclasses(cls, \"__overridden_defaults__\")\n",
   "        themed_keys = set()\n",
   "        result = dict()\n",
   "            keys = self.properties()\n",
   "            keys = set(self._property_values.keys()) | set(self._unstable_default_values.keys())\n",
   "                themed_keys = set(self.themed_values().keys())\n",
   "                keys |= themed_keys\n",
   "        for key in keys:\n",
   "            descriptor = self.lookup(key)\n",
   "            if not query(descriptor):\n",
   "            value = descriptor.serializable_value(self)\n",
   "            if not include_defaults and key not in themed_keys:\n",
   "                if isinstance(value, PropertyValueContainer) and key in self._unstable_default_values:\n",
   "            result[key] = value\n",
   "        return result\n",
   "        old_dict = self.themed_values()\n",
   "        if old_dict is property_values:  # lgtm [py/comparison-using-is]\n",
   "        removed = set()\n",
   "        if old_dict is not None:\n",
   "            removed.update(set(old_dict.keys()))\n",
   "        added = set(property_values.keys())\n",
   "        old_values = dict()\n",
   "        for k in added.union(removed):\n",
   "            old_values[k] = getattr(self, k)\n",
   "        for k, v in old_values.items():\n",
   "            if k in self._unstable_themed_values:\n",
   "                del self._unstable_themed_values[k]\n",
   "        for k, v in old_values.items():\n",
   "            descriptor = self.lookup(k)\n",
   "            descriptor.trigger_if_changed(self, v)\n"
  ]
 },
 "224": {
  "name": "props",
  "type": "list",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/core/has_props.py",
  "lineno": "274",
  "column": "8",
  "context": "etattr__(name, value)\n            return\n\n        props = sorted(self.properties())\n        descriptor = getattr(self.__class__, name,",
  "context_lines": "        # if we're just setting a private underscore field\n        if name.startswith(\"_\"):\n            super().__setattr__(name, value)\n            return\n\n        props = sorted(self.properties())\n        descriptor = getattr(self.__class__, name, None)\n\n        if name in props or (descriptor is not None and descriptor.fset is not None):\n            super().__setattr__(name, value)\n        else:\n",
  "slicing": [
   "log = logging.getLogger(__name__)\n",
   "        names_with_refs = set()\n",
   "        container_names = set()\n",
   "        overridden_defaults = {}\n",
   "        for name, prop in class_dict.items():\n",
   "            if not isinstance(prop, Override):\n",
   "            if prop.default_overridden:\n",
   "                overridden_defaults[name] = prop.default\n",
   "        for name, default in overridden_defaults.items():\n",
   "            del class_dict[name]\n",
   "        generators = dict()\n",
   "        for name, generator in class_dict.items():\n",
   "            if isinstance(generator, PropertyDescriptorFactory):\n",
   "                generators[name] = generator\n",
   "            elif isinstance(generator, type) and issubclass(generator, PropertyDescriptorFactory):\n",
   "                generators[name] = generator.autocreate()\n",
   "        dataspecs = {}\n",
   "        new_class_attrs = {}\n",
   "        for name, generator in generators.items():\n",
   "            prop_descriptors = generator.make_descriptors(name)\n",
   "            replaced_self = False\n",
   "            for prop_descriptor in prop_descriptors:\n",
   "                if prop_descriptor.name in generators:\n",
   "                    if generators[prop_descriptor.name] is generator:\n",
   "                        replaced_self = True\n",
   "                        prop_descriptor.add_prop_descriptor_to_class(class_name, new_class_attrs, names_with_refs, container_names, dataspecs)\n",
   "                    prop_descriptor.add_prop_descriptor_to_class(class_name, new_class_attrs, names_with_refs, container_names, dataspecs)\n",
   "            if not replaced_self:\n",
   "                del class_dict[name]\n",
   "        class_dict.update(new_class_attrs)\n",
   "        class_dict[\"__properties__\"] = set(new_class_attrs)\n",
   "        class_dict[\"__properties_with_refs__\"] = names_with_refs\n",
   "        class_dict[\"__container_props__\"] = container_names\n",
   "        if len(overridden_defaults) > 0:\n",
   "            class_dict[\"__overridden_defaults__\"] = overridden_defaults\n",
   "        if dataspecs:\n",
   "            class_dict[\"__dataspecs__\"] = dataspecs\n",
   "            path = class_dict[\"__example__\"]\n",
   "                class_dict[\"__doc__\"] += _EXAMPLE_TEMPLATE % dict(path=path)\n",
   "        cls_attrs = cls.__dict__.keys() # we do NOT want inherited attrs here\n",
   "        for attr in cls_attrs:\n",
   "            for base in bases:\n",
   "                if issubclass(base, HasProps) and attr in base.properties():\n",
   "                         (attr, base.__name__, attr, class_name,\n",
   "                          base.__name__, attr,\n",
   "                          class_name, attr,\n",
   "                          base.__name__, attr),\n",
   "            our_props = cls.properties()\n",
   "            for key in cls.__dict__[\"__overridden_defaults__\"].keys():\n",
   "                if key not in our_props:\n",
   "                    warn(('Override() of %s in class %s does not override anything.') % (key, class_name),\n",
   "def accumulate_from_superclasses(cls, propname):\n",
   "    cachename = \"__cached_all\" + propname\n",
   "    if cachename not in cls.__dict__:\n",
   "        s = set()\n",
   "        for c in cls.__mro__:\n",
   "            if issubclass(c, HasProps) and hasattr(c, propname):\n",
   "                base = getattr(c, propname)\n",
   "                s.update(base)\n",
   "        setattr(cls, cachename, s)\n",
   "    return cls.__dict__[cachename]\n",
   "def accumulate_dict_from_superclasses(cls, propname):\n",
   "    cachename = \"__cached_all\" + propname\n",
   "    if cachename not in cls.__dict__:\n",
   "        d = dict()\n",
   "        for c in cls.__mro__:\n",
   "            if issubclass(c, HasProps) and hasattr(c, propname):\n",
   "                base = getattr(c, propname)\n",
   "                for k,v in base.items():\n",
   "                    if k not in d:\n",
   "                        d[k] = v\n",
   "        setattr(cls, cachename, d)\n",
   "    return cls.__dict__[cachename]\n",
   "        for name, value in properties.items():\n",
   "            setattr(self, name, value)\n",
   "        if name.startswith(\"_\"):\n",
   "            super().__setattr__(name, value)\n",
   "        props = sorted(self.properties())\n",
   "        descriptor = getattr(self.__class__, name, None)\n",
   "        if name in props or (descriptor is not None and descriptor.fset is not None):\n",
   "            super().__setattr__(name, value)\n",
   "            matches, text = difflib.get_close_matches(name.lower(), props), \"similar\"\n",
   "            if not matches:\n",
   "                matches, text = props, \"possible\"\n",
   "                (name, self.__class__.__name__, text, nice_join(matches)))\n",
   "        if name in self.properties():\n",
   "            log.trace(\"Patching attribute %r of %r with %r\", name, self, json)\n",
   "            descriptor = self.lookup(name)\n",
   "            descriptor.set_from_json(self, json, models, setter)\n",
   "            log.warning(\"JSON had attr %r on obj %r, which is a client-only or invalid attribute that shouldn't have been sent\", name, self)\n",
   "        for k,v in kwargs.items():\n",
   "            setattr(self, k, v)\n",
   "        for k, v in json_attributes.items():\n",
   "            self.set_from_json(k, v, models, setter)\n",
   "        return getattr(cls, name)\n",
   "        return accumulate_from_superclasses(cls, \"__properties_with_refs__\")\n",
   "        return accumulate_from_superclasses(cls, \"__container_props__\")\n",
   "            return accumulate_from_superclasses(cls, \"__properties__\")\n",
   "            return set(cls.__properties__)\n",
   "        return set(cls.dataspecs_with_props().keys())\n",
   "        return accumulate_dict_from_superclasses(cls, \"__dataspecs__\")\n",
   "        return self.query_properties_with_values(lambda prop: prop.serialized, include_defaults)\n",
   "        return accumulate_dict_from_superclasses(cls, \"__overridden_defaults__\")\n",
   "        themed_keys = set()\n",
   "        result = dict()\n",
   "            keys = self.properties()\n",
   "            keys = set(self._property_values.keys()) | set(self._unstable_default_values.keys())\n",
   "                themed_keys = set(self.themed_values().keys())\n",
   "                keys |= themed_keys\n",
   "        for key in keys:\n",
   "            descriptor = self.lookup(key)\n",
   "            if not query(descriptor):\n",
   "            value = descriptor.serializable_value(self)\n",
   "            if not include_defaults and key not in themed_keys:\n",
   "                if isinstance(value, PropertyValueContainer) and key in self._unstable_default_values:\n",
   "            result[key] = value\n",
   "        return result\n",
   "        old_dict = self.themed_values()\n",
   "        if old_dict is property_values:  # lgtm [py/comparison-using-is]\n",
   "        removed = set()\n",
   "        if old_dict is not None:\n",
   "            removed.update(set(old_dict.keys()))\n",
   "        added = set(property_values.keys())\n",
   "        old_values = dict()\n",
   "        for k in added.union(removed):\n",
   "            old_values[k] = getattr(self, k)\n",
   "        for k, v in old_values.items():\n",
   "            if k in self._unstable_themed_values:\n",
   "                del self._unstable_themed_values[k]\n",
   "        for k, v in old_values.items():\n",
   "            descriptor = self.lookup(k)\n",
   "            descriptor.trigger_if_changed(self, v)\n"
  ]
 },
 "225": {
  "name": "descriptor",
  "type": "DataSpecPropertyDescriptor",
  "class": "customized",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/core/has_props.py",
  "lineno": "275",
  "column": "8",
  "context": "        props = sorted(self.properties())\n        descriptor = getattr(self.__class__, name, None)\n\n        if name in props or (descriptor is not No",
  "context_lines": "        if name.startswith(\"_\"):\n            super().__setattr__(name, value)\n            return\n\n        props = sorted(self.properties())\n        descriptor = getattr(self.__class__, name, None)\n\n        if name in props or (descriptor is not None and descriptor.fset is not None):\n            super().__setattr__(name, value)\n        else:\n",
  "slicing": [
   "log = logging.getLogger(__name__)\n",
   "        names_with_refs = set()\n",
   "        container_names = set()\n",
   "        overridden_defaults = {}\n",
   "        for name, prop in class_dict.items():\n",
   "            if not isinstance(prop, Override):\n",
   "            if prop.default_overridden:\n",
   "                overridden_defaults[name] = prop.default\n",
   "        for name, default in overridden_defaults.items():\n",
   "            del class_dict[name]\n",
   "        generators = dict()\n",
   "        for name, generator in class_dict.items():\n",
   "            if isinstance(generator, PropertyDescriptorFactory):\n",
   "                generators[name] = generator\n",
   "            elif isinstance(generator, type) and issubclass(generator, PropertyDescriptorFactory):\n",
   "                generators[name] = generator.autocreate()\n",
   "        dataspecs = {}\n",
   "        new_class_attrs = {}\n",
   "        for name, generator in generators.items():\n",
   "            prop_descriptors = generator.make_descriptors(name)\n",
   "            replaced_self = False\n",
   "            for prop_descriptor in prop_descriptors:\n",
   "                if prop_descriptor.name in generators:\n",
   "                    if generators[prop_descriptor.name] is generator:\n",
   "                        replaced_self = True\n",
   "                        prop_descriptor.add_prop_descriptor_to_class(class_name, new_class_attrs, names_with_refs, container_names, dataspecs)\n",
   "                    prop_descriptor.add_prop_descriptor_to_class(class_name, new_class_attrs, names_with_refs, container_names, dataspecs)\n",
   "            if not replaced_self:\n",
   "                del class_dict[name]\n",
   "        class_dict.update(new_class_attrs)\n",
   "        class_dict[\"__properties__\"] = set(new_class_attrs)\n",
   "        class_dict[\"__properties_with_refs__\"] = names_with_refs\n",
   "        class_dict[\"__container_props__\"] = container_names\n",
   "        if len(overridden_defaults) > 0:\n",
   "            class_dict[\"__overridden_defaults__\"] = overridden_defaults\n",
   "        if dataspecs:\n",
   "            class_dict[\"__dataspecs__\"] = dataspecs\n",
   "            path = class_dict[\"__example__\"]\n",
   "                class_dict[\"__doc__\"] += _EXAMPLE_TEMPLATE % dict(path=path)\n",
   "        cls_attrs = cls.__dict__.keys() # we do NOT want inherited attrs here\n",
   "        for attr in cls_attrs:\n",
   "            for base in bases:\n",
   "                if issubclass(base, HasProps) and attr in base.properties():\n",
   "                         (attr, base.__name__, attr, class_name,\n",
   "                          base.__name__, attr,\n",
   "                          class_name, attr,\n",
   "                          base.__name__, attr),\n",
   "            our_props = cls.properties()\n",
   "            for key in cls.__dict__[\"__overridden_defaults__\"].keys():\n",
   "                if key not in our_props:\n",
   "                    warn(('Override() of %s in class %s does not override anything.') % (key, class_name),\n",
   "def accumulate_from_superclasses(cls, propname):\n",
   "    cachename = \"__cached_all\" + propname\n",
   "    if cachename not in cls.__dict__:\n",
   "        s = set()\n",
   "        for c in cls.__mro__:\n",
   "            if issubclass(c, HasProps) and hasattr(c, propname):\n",
   "                base = getattr(c, propname)\n",
   "                s.update(base)\n",
   "        setattr(cls, cachename, s)\n",
   "    return cls.__dict__[cachename]\n",
   "def accumulate_dict_from_superclasses(cls, propname):\n",
   "    cachename = \"__cached_all\" + propname\n",
   "    if cachename not in cls.__dict__:\n",
   "        d = dict()\n",
   "        for c in cls.__mro__:\n",
   "            if issubclass(c, HasProps) and hasattr(c, propname):\n",
   "                base = getattr(c, propname)\n",
   "                for k,v in base.items():\n",
   "                    if k not in d:\n",
   "                        d[k] = v\n",
   "        setattr(cls, cachename, d)\n",
   "    return cls.__dict__[cachename]\n",
   "        for name, value in properties.items():\n",
   "            setattr(self, name, value)\n",
   "        if name.startswith(\"_\"):\n",
   "            super().__setattr__(name, value)\n",
   "        props = sorted(self.properties())\n",
   "        descriptor = getattr(self.__class__, name, None)\n",
   "        if name in props or (descriptor is not None and descriptor.fset is not None):\n",
   "            super().__setattr__(name, value)\n",
   "            matches, text = difflib.get_close_matches(name.lower(), props), \"similar\"\n",
   "            if not matches:\n",
   "                matches, text = props, \"possible\"\n",
   "                (name, self.__class__.__name__, text, nice_join(matches)))\n",
   "        if name in self.properties():\n",
   "            log.trace(\"Patching attribute %r of %r with %r\", name, self, json)\n",
   "            descriptor = self.lookup(name)\n",
   "            descriptor.set_from_json(self, json, models, setter)\n",
   "            log.warning(\"JSON had attr %r on obj %r, which is a client-only or invalid attribute that shouldn't have been sent\", name, self)\n",
   "        for k,v in kwargs.items():\n",
   "            setattr(self, k, v)\n",
   "        for k, v in json_attributes.items():\n",
   "            self.set_from_json(k, v, models, setter)\n",
   "        return getattr(cls, name)\n",
   "        return accumulate_from_superclasses(cls, \"__properties_with_refs__\")\n",
   "        return accumulate_from_superclasses(cls, \"__container_props__\")\n",
   "            return accumulate_from_superclasses(cls, \"__properties__\")\n",
   "            return set(cls.__properties__)\n",
   "        return set(cls.dataspecs_with_props().keys())\n",
   "        return accumulate_dict_from_superclasses(cls, \"__dataspecs__\")\n",
   "        return self.query_properties_with_values(lambda prop: prop.serialized, include_defaults)\n",
   "        return accumulate_dict_from_superclasses(cls, \"__overridden_defaults__\")\n",
   "        themed_keys = set()\n",
   "        result = dict()\n",
   "            keys = self.properties()\n",
   "            keys = set(self._property_values.keys()) | set(self._unstable_default_values.keys())\n",
   "                themed_keys = set(self.themed_values().keys())\n",
   "                keys |= themed_keys\n",
   "        for key in keys:\n",
   "            descriptor = self.lookup(key)\n",
   "            if not query(descriptor):\n",
   "            value = descriptor.serializable_value(self)\n",
   "            if not include_defaults and key not in themed_keys:\n",
   "                if isinstance(value, PropertyValueContainer) and key in self._unstable_default_values:\n",
   "            result[key] = value\n",
   "        return result\n",
   "        old_dict = self.themed_values()\n",
   "        if old_dict is property_values:  # lgtm [py/comparison-using-is]\n",
   "        removed = set()\n",
   "        if old_dict is not None:\n",
   "            removed.update(set(old_dict.keys()))\n",
   "        added = set(property_values.keys())\n",
   "        old_values = dict()\n",
   "        for k in added.union(removed):\n",
   "            old_values[k] = getattr(self, k)\n",
   "        for k, v in old_values.items():\n",
   "            if k in self._unstable_themed_values:\n",
   "                del self._unstable_themed_values[k]\n",
   "        for k, v in old_values.items():\n",
   "            descriptor = self.lookup(k)\n",
   "            descriptor.trigger_if_changed(self, v)\n"
  ]
 },
 "226": {
  "name": "__repr__",
  "type": "function",
  "class": "unknown",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/core/has_props.py",
  "lineno": "291",
  "column": "4",
  "context": "  return \"%s(...)\" % self.__class__.__name__\n\n    __repr__ = __str__\n\n    def equals(self, other):\n        ''' Structur",
  "context_lines": "            raise AttributeError(\"unexpected attribute '%s' to %s, %s attributes are %s\" %\n                (name, self.__class__.__name__, text, nice_join(matches)))\n\n    def __str__(self):\n        return \"%s(...)\" % self.__class__.__name__\n\n    __repr__ = __str__\n\n    def equals(self, other):\n        ''' Structural equality of models.\n\n        Args:\n",
  "slicing": [
   "log = logging.getLogger(__name__)\n",
   "        names_with_refs = set()\n",
   "        container_names = set()\n",
   "        overridden_defaults = {}\n",
   "        for name, prop in class_dict.items():\n",
   "            if not isinstance(prop, Override):\n",
   "            if prop.default_overridden:\n",
   "                overridden_defaults[name] = prop.default\n",
   "        for name, default in overridden_defaults.items():\n",
   "            del class_dict[name]\n",
   "        generators = dict()\n",
   "        for name, generator in class_dict.items():\n",
   "            if isinstance(generator, PropertyDescriptorFactory):\n",
   "                generators[name] = generator\n",
   "            elif isinstance(generator, type) and issubclass(generator, PropertyDescriptorFactory):\n",
   "                generators[name] = generator.autocreate()\n",
   "        dataspecs = {}\n",
   "        new_class_attrs = {}\n",
   "        for name, generator in generators.items():\n",
   "            prop_descriptors = generator.make_descriptors(name)\n",
   "            replaced_self = False\n",
   "            for prop_descriptor in prop_descriptors:\n",
   "                if prop_descriptor.name in generators:\n",
   "                    if generators[prop_descriptor.name] is generator:\n",
   "                        replaced_self = True\n",
   "                        prop_descriptor.add_prop_descriptor_to_class(class_name, new_class_attrs, names_with_refs, container_names, dataspecs)\n",
   "                    prop_descriptor.add_prop_descriptor_to_class(class_name, new_class_attrs, names_with_refs, container_names, dataspecs)\n",
   "            if not replaced_self:\n",
   "                del class_dict[name]\n",
   "        class_dict.update(new_class_attrs)\n",
   "        class_dict[\"__properties__\"] = set(new_class_attrs)\n",
   "        class_dict[\"__properties_with_refs__\"] = names_with_refs\n",
   "        class_dict[\"__container_props__\"] = container_names\n",
   "        if len(overridden_defaults) > 0:\n",
   "            class_dict[\"__overridden_defaults__\"] = overridden_defaults\n",
   "        if dataspecs:\n",
   "            class_dict[\"__dataspecs__\"] = dataspecs\n",
   "            path = class_dict[\"__example__\"]\n",
   "                class_dict[\"__doc__\"] += _EXAMPLE_TEMPLATE % dict(path=path)\n",
   "        cls_attrs = cls.__dict__.keys() # we do NOT want inherited attrs here\n",
   "        for attr in cls_attrs:\n",
   "            for base in bases:\n",
   "                if issubclass(base, HasProps) and attr in base.properties():\n",
   "                         (attr, base.__name__, attr, class_name,\n",
   "                          base.__name__, attr,\n",
   "                          class_name, attr,\n",
   "                          base.__name__, attr),\n",
   "            our_props = cls.properties()\n",
   "            for key in cls.__dict__[\"__overridden_defaults__\"].keys():\n",
   "                if key not in our_props:\n",
   "                    warn(('Override() of %s in class %s does not override anything.') % (key, class_name),\n",
   "def accumulate_from_superclasses(cls, propname):\n",
   "    cachename = \"__cached_all\" + propname\n",
   "    if cachename not in cls.__dict__:\n",
   "        s = set()\n",
   "        for c in cls.__mro__:\n",
   "            if issubclass(c, HasProps) and hasattr(c, propname):\n",
   "                base = getattr(c, propname)\n",
   "                s.update(base)\n",
   "        setattr(cls, cachename, s)\n",
   "    return cls.__dict__[cachename]\n",
   "def accumulate_dict_from_superclasses(cls, propname):\n",
   "    cachename = \"__cached_all\" + propname\n",
   "    if cachename not in cls.__dict__:\n",
   "        d = dict()\n",
   "        for c in cls.__mro__:\n",
   "            if issubclass(c, HasProps) and hasattr(c, propname):\n",
   "                base = getattr(c, propname)\n",
   "                for k,v in base.items():\n",
   "                    if k not in d:\n",
   "                        d[k] = v\n",
   "        setattr(cls, cachename, d)\n",
   "    return cls.__dict__[cachename]\n",
   "        for name, value in properties.items():\n",
   "            setattr(self, name, value)\n",
   "        if name.startswith(\"_\"):\n",
   "            super().__setattr__(name, value)\n",
   "        props = sorted(self.properties())\n",
   "        descriptor = getattr(self.__class__, name, None)\n",
   "        if name in props or (descriptor is not None and descriptor.fset is not None):\n",
   "            super().__setattr__(name, value)\n",
   "            matches, text = difflib.get_close_matches(name.lower(), props), \"similar\"\n",
   "            if not matches:\n",
   "                matches, text = props, \"possible\"\n",
   "                (name, self.__class__.__name__, text, nice_join(matches)))\n",
   "    __repr__ = __str__\n",
   "        if name in self.properties():\n",
   "            log.trace(\"Patching attribute %r of %r with %r\", name, self, json)\n",
   "            descriptor = self.lookup(name)\n",
   "            descriptor.set_from_json(self, json, models, setter)\n",
   "            log.warning(\"JSON had attr %r on obj %r, which is a client-only or invalid attribute that shouldn't have been sent\", name, self)\n",
   "        for k,v in kwargs.items():\n",
   "            setattr(self, k, v)\n",
   "        for k, v in json_attributes.items():\n",
   "            self.set_from_json(k, v, models, setter)\n",
   "        return getattr(cls, name)\n",
   "        return accumulate_from_superclasses(cls, \"__properties_with_refs__\")\n",
   "        return accumulate_from_superclasses(cls, \"__container_props__\")\n",
   "            return accumulate_from_superclasses(cls, \"__properties__\")\n",
   "            return set(cls.__properties__)\n",
   "        return set(cls.dataspecs_with_props().keys())\n",
   "        return accumulate_dict_from_superclasses(cls, \"__dataspecs__\")\n",
   "        return self.query_properties_with_values(lambda prop: prop.serialized, include_defaults)\n",
   "        return accumulate_dict_from_superclasses(cls, \"__overridden_defaults__\")\n",
   "        themed_keys = set()\n",
   "        result = dict()\n",
   "            keys = self.properties()\n",
   "            keys = set(self._property_values.keys()) | set(self._unstable_default_values.keys())\n",
   "                themed_keys = set(self.themed_values().keys())\n",
   "                keys |= themed_keys\n",
   "        for key in keys:\n",
   "            descriptor = self.lookup(key)\n",
   "            if not query(descriptor):\n",
   "            value = descriptor.serializable_value(self)\n",
   "            if not include_defaults and key not in themed_keys:\n",
   "                if isinstance(value, PropertyValueContainer) and key in self._unstable_default_values:\n",
   "            result[key] = value\n",
   "        return result\n",
   "        old_dict = self.themed_values()\n",
   "        if old_dict is property_values:  # lgtm [py/comparison-using-is]\n",
   "        removed = set()\n",
   "        if old_dict is not None:\n",
   "            removed.update(set(old_dict.keys()))\n",
   "        added = set(property_values.keys())\n",
   "        old_values = dict()\n",
   "        for k in added.union(removed):\n",
   "            old_values[k] = getattr(self, k)\n",
   "        for k, v in old_values.items():\n",
   "            if k in self._unstable_themed_values:\n",
   "                del self._unstable_themed_values[k]\n",
   "        for k, v in old_values.items():\n",
   "            descriptor = self.lookup(k)\n",
   "            descriptor.trigger_if_changed(self, v)\n"
  ]
 },
 "227": {
  "name": "keys",
  "type": "set",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/has_props.py",
  "lineno": "546",
  "column": "12",
  "context": "= dict()\n        if include_defaults:\n            keys = self.properties()\n        else:\n            # TODO (bev) For now, in",
  "context_lines": "        '''\n        themed_keys = set()\n        result = dict()\n        if include_defaults:\n            keys = self.properties()\n        else:\n            # TODO (bev) For now, include unstable default values. Things rely on Instances\n            # always getting serialized, even defaults, and adding unstable defaults here\n            # accomplishes that. Unmodified defaults for property value containers will be\n",
  "slicing": [
   "log = logging.getLogger(__name__)\n",
   "        names_with_refs = set()\n",
   "        container_names = set()\n",
   "        overridden_defaults = {}\n",
   "        for name, prop in class_dict.items():\n",
   "            if not isinstance(prop, Override):\n",
   "            if prop.default_overridden:\n",
   "                overridden_defaults[name] = prop.default\n",
   "        for name, default in overridden_defaults.items():\n",
   "            del class_dict[name]\n",
   "        generators = dict()\n",
   "        for name, generator in class_dict.items():\n",
   "            if isinstance(generator, PropertyDescriptorFactory):\n",
   "                generators[name] = generator\n",
   "            elif isinstance(generator, type) and issubclass(generator, PropertyDescriptorFactory):\n",
   "                generators[name] = generator.autocreate()\n",
   "        dataspecs = {}\n",
   "        new_class_attrs = {}\n",
   "        for name, generator in generators.items():\n",
   "            prop_descriptors = generator.make_descriptors(name)\n",
   "            replaced_self = False\n",
   "            for prop_descriptor in prop_descriptors:\n",
   "                if prop_descriptor.name in generators:\n",
   "                    if generators[prop_descriptor.name] is generator:\n",
   "                        replaced_self = True\n",
   "                        prop_descriptor.add_prop_descriptor_to_class(class_name, new_class_attrs, names_with_refs, container_names, dataspecs)\n",
   "                    prop_descriptor.add_prop_descriptor_to_class(class_name, new_class_attrs, names_with_refs, container_names, dataspecs)\n",
   "            if not replaced_self:\n",
   "                del class_dict[name]\n",
   "        class_dict.update(new_class_attrs)\n",
   "        class_dict[\"__properties__\"] = set(new_class_attrs)\n",
   "        class_dict[\"__properties_with_refs__\"] = names_with_refs\n",
   "        class_dict[\"__container_props__\"] = container_names\n",
   "        if len(overridden_defaults) > 0:\n",
   "            class_dict[\"__overridden_defaults__\"] = overridden_defaults\n",
   "        if dataspecs:\n",
   "            class_dict[\"__dataspecs__\"] = dataspecs\n",
   "            path = class_dict[\"__example__\"]\n",
   "                class_dict[\"__doc__\"] += _EXAMPLE_TEMPLATE % dict(path=path)\n",
   "        cls_attrs = cls.__dict__.keys() # we do NOT want inherited attrs here\n",
   "        for attr in cls_attrs:\n",
   "            for base in bases:\n",
   "                if issubclass(base, HasProps) and attr in base.properties():\n",
   "                         (attr, base.__name__, attr, class_name,\n",
   "                          base.__name__, attr,\n",
   "                          class_name, attr,\n",
   "                          base.__name__, attr),\n",
   "            our_props = cls.properties()\n",
   "            for key in cls.__dict__[\"__overridden_defaults__\"].keys():\n",
   "                if key not in our_props:\n",
   "                    warn(('Override() of %s in class %s does not override anything.') % (key, class_name),\n",
   "def accumulate_from_superclasses(cls, propname):\n",
   "    cachename = \"__cached_all\" + propname\n",
   "    if cachename not in cls.__dict__:\n",
   "        s = set()\n",
   "        for c in cls.__mro__:\n",
   "            if issubclass(c, HasProps) and hasattr(c, propname):\n",
   "                base = getattr(c, propname)\n",
   "                s.update(base)\n",
   "        setattr(cls, cachename, s)\n",
   "    return cls.__dict__[cachename]\n",
   "def accumulate_dict_from_superclasses(cls, propname):\n",
   "    cachename = \"__cached_all\" + propname\n",
   "    if cachename not in cls.__dict__:\n",
   "        d = dict()\n",
   "        for c in cls.__mro__:\n",
   "            if issubclass(c, HasProps) and hasattr(c, propname):\n",
   "                base = getattr(c, propname)\n",
   "                for k,v in base.items():\n",
   "                    if k not in d:\n",
   "                        d[k] = v\n",
   "        setattr(cls, cachename, d)\n",
   "    return cls.__dict__[cachename]\n",
   "        for name, value in properties.items():\n",
   "            setattr(self, name, value)\n",
   "        if name.startswith(\"_\"):\n",
   "            super().__setattr__(name, value)\n",
   "        props = sorted(self.properties())\n",
   "        descriptor = getattr(self.__class__, name, None)\n",
   "        if name in props or (descriptor is not None and descriptor.fset is not None):\n",
   "            super().__setattr__(name, value)\n",
   "            matches, text = difflib.get_close_matches(name.lower(), props), \"similar\"\n",
   "            if not matches:\n",
   "                matches, text = props, \"possible\"\n",
   "                (name, self.__class__.__name__, text, nice_join(matches)))\n",
   "        if name in self.properties():\n",
   "            log.trace(\"Patching attribute %r of %r with %r\", name, self, json)\n",
   "            descriptor = self.lookup(name)\n",
   "            descriptor.set_from_json(self, json, models, setter)\n",
   "            log.warning(\"JSON had attr %r on obj %r, which is a client-only or invalid attribute that shouldn't have been sent\", name, self)\n",
   "        for k,v in kwargs.items():\n",
   "            setattr(self, k, v)\n",
   "        for k, v in json_attributes.items():\n",
   "            self.set_from_json(k, v, models, setter)\n",
   "        return getattr(cls, name)\n",
   "        return accumulate_from_superclasses(cls, \"__properties_with_refs__\")\n",
   "        return accumulate_from_superclasses(cls, \"__container_props__\")\n",
   "            return accumulate_from_superclasses(cls, \"__properties__\")\n",
   "            return set(cls.__properties__)\n",
   "        return set(cls.dataspecs_with_props().keys())\n",
   "        return accumulate_dict_from_superclasses(cls, \"__dataspecs__\")\n",
   "        return self.query_properties_with_values(lambda prop: prop.serialized, include_defaults)\n",
   "        return accumulate_dict_from_superclasses(cls, \"__overridden_defaults__\")\n",
   "        themed_keys = set()\n",
   "        result = dict()\n",
   "            keys = self.properties()\n",
   "            keys = set(self._property_values.keys()) | set(self._unstable_default_values.keys())\n",
   "                themed_keys = set(self.themed_values().keys())\n",
   "                keys |= themed_keys\n",
   "        for key in keys:\n",
   "            descriptor = self.lookup(key)\n",
   "            if not query(descriptor):\n",
   "            value = descriptor.serializable_value(self)\n",
   "            if not include_defaults and key not in themed_keys:\n",
   "                if isinstance(value, PropertyValueContainer) and key in self._unstable_default_values:\n",
   "            result[key] = value\n",
   "        return result\n",
   "        old_dict = self.themed_values()\n",
   "        if old_dict is property_values:  # lgtm [py/comparison-using-is]\n",
   "        removed = set()\n",
   "        if old_dict is not None:\n",
   "            removed.update(set(old_dict.keys()))\n",
   "        added = set(property_values.keys())\n",
   "        old_values = dict()\n",
   "        for k in added.union(removed):\n",
   "            old_values[k] = getattr(self, k)\n",
   "        for k, v in old_values.items():\n",
   "            if k in self._unstable_themed_values:\n",
   "                del self._unstable_themed_values[k]\n",
   "        for k, v in old_values.items():\n",
   "            descriptor = self.lookup(k)\n",
   "            descriptor.trigger_if_changed(self, v)\n"
  ]
 },
 "228": {
  "name": "descriptor",
  "type": "BasicPropertyDescriptor",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/has_props.py",
  "lineno": "558",
  "column": "12",
  "context": "themed_keys\n\n        for key in keys:\n            descriptor = self.lookup(key)\n            if not query(descriptor):\n            ",
  "context_lines": "            if self.themed_values():\n                themed_keys = set(self.themed_values().keys())\n                keys |= themed_keys\n\n        for key in keys:\n            descriptor = self.lookup(key)\n            if not query(descriptor):\n                continue\n\n            value = descriptor.serializable_value(self)\n            if not include_defaults and key not in themed_keys:\n",
  "slicing": [
   "log = logging.getLogger(__name__)\n",
   "        names_with_refs = set()\n",
   "        container_names = set()\n",
   "        overridden_defaults = {}\n",
   "        for name, prop in class_dict.items():\n",
   "            if not isinstance(prop, Override):\n",
   "            if prop.default_overridden:\n",
   "                overridden_defaults[name] = prop.default\n",
   "        for name, default in overridden_defaults.items():\n",
   "            del class_dict[name]\n",
   "        generators = dict()\n",
   "        for name, generator in class_dict.items():\n",
   "            if isinstance(generator, PropertyDescriptorFactory):\n",
   "                generators[name] = generator\n",
   "            elif isinstance(generator, type) and issubclass(generator, PropertyDescriptorFactory):\n",
   "                generators[name] = generator.autocreate()\n",
   "        dataspecs = {}\n",
   "        new_class_attrs = {}\n",
   "        for name, generator in generators.items():\n",
   "            prop_descriptors = generator.make_descriptors(name)\n",
   "            replaced_self = False\n",
   "            for prop_descriptor in prop_descriptors:\n",
   "                if prop_descriptor.name in generators:\n",
   "                    if generators[prop_descriptor.name] is generator:\n",
   "                        replaced_self = True\n",
   "                        prop_descriptor.add_prop_descriptor_to_class(class_name, new_class_attrs, names_with_refs, container_names, dataspecs)\n",
   "                    prop_descriptor.add_prop_descriptor_to_class(class_name, new_class_attrs, names_with_refs, container_names, dataspecs)\n",
   "            if not replaced_self:\n",
   "                del class_dict[name]\n",
   "        class_dict.update(new_class_attrs)\n",
   "        class_dict[\"__properties__\"] = set(new_class_attrs)\n",
   "        class_dict[\"__properties_with_refs__\"] = names_with_refs\n",
   "        class_dict[\"__container_props__\"] = container_names\n",
   "        if len(overridden_defaults) > 0:\n",
   "            class_dict[\"__overridden_defaults__\"] = overridden_defaults\n",
   "        if dataspecs:\n",
   "            class_dict[\"__dataspecs__\"] = dataspecs\n",
   "            path = class_dict[\"__example__\"]\n",
   "                class_dict[\"__doc__\"] += _EXAMPLE_TEMPLATE % dict(path=path)\n",
   "        cls_attrs = cls.__dict__.keys() # we do NOT want inherited attrs here\n",
   "        for attr in cls_attrs:\n",
   "            for base in bases:\n",
   "                if issubclass(base, HasProps) and attr in base.properties():\n",
   "                         (attr, base.__name__, attr, class_name,\n",
   "                          base.__name__, attr,\n",
   "                          class_name, attr,\n",
   "                          base.__name__, attr),\n",
   "            our_props = cls.properties()\n",
   "            for key in cls.__dict__[\"__overridden_defaults__\"].keys():\n",
   "                if key not in our_props:\n",
   "                    warn(('Override() of %s in class %s does not override anything.') % (key, class_name),\n",
   "def accumulate_from_superclasses(cls, propname):\n",
   "    cachename = \"__cached_all\" + propname\n",
   "    if cachename not in cls.__dict__:\n",
   "        s = set()\n",
   "        for c in cls.__mro__:\n",
   "            if issubclass(c, HasProps) and hasattr(c, propname):\n",
   "                base = getattr(c, propname)\n",
   "                s.update(base)\n",
   "        setattr(cls, cachename, s)\n",
   "    return cls.__dict__[cachename]\n",
   "def accumulate_dict_from_superclasses(cls, propname):\n",
   "    cachename = \"__cached_all\" + propname\n",
   "    if cachename not in cls.__dict__:\n",
   "        d = dict()\n",
   "        for c in cls.__mro__:\n",
   "            if issubclass(c, HasProps) and hasattr(c, propname):\n",
   "                base = getattr(c, propname)\n",
   "                for k,v in base.items():\n",
   "                    if k not in d:\n",
   "                        d[k] = v\n",
   "        setattr(cls, cachename, d)\n",
   "    return cls.__dict__[cachename]\n",
   "        for name, value in properties.items():\n",
   "            setattr(self, name, value)\n",
   "        if name.startswith(\"_\"):\n",
   "            super().__setattr__(name, value)\n",
   "        props = sorted(self.properties())\n",
   "        descriptor = getattr(self.__class__, name, None)\n",
   "        if name in props or (descriptor is not None and descriptor.fset is not None):\n",
   "            super().__setattr__(name, value)\n",
   "            matches, text = difflib.get_close_matches(name.lower(), props), \"similar\"\n",
   "            if not matches:\n",
   "                matches, text = props, \"possible\"\n",
   "                (name, self.__class__.__name__, text, nice_join(matches)))\n",
   "        if name in self.properties():\n",
   "            log.trace(\"Patching attribute %r of %r with %r\", name, self, json)\n",
   "            descriptor = self.lookup(name)\n",
   "            descriptor.set_from_json(self, json, models, setter)\n",
   "            log.warning(\"JSON had attr %r on obj %r, which is a client-only or invalid attribute that shouldn't have been sent\", name, self)\n",
   "        for k,v in kwargs.items():\n",
   "            setattr(self, k, v)\n",
   "        for k, v in json_attributes.items():\n",
   "            self.set_from_json(k, v, models, setter)\n",
   "        return getattr(cls, name)\n",
   "        return accumulate_from_superclasses(cls, \"__properties_with_refs__\")\n",
   "        return accumulate_from_superclasses(cls, \"__container_props__\")\n",
   "            return accumulate_from_superclasses(cls, \"__properties__\")\n",
   "            return set(cls.__properties__)\n",
   "        return set(cls.dataspecs_with_props().keys())\n",
   "        return accumulate_dict_from_superclasses(cls, \"__dataspecs__\")\n",
   "        return self.query_properties_with_values(lambda prop: prop.serialized, include_defaults)\n",
   "        return accumulate_dict_from_superclasses(cls, \"__overridden_defaults__\")\n",
   "        themed_keys = set()\n",
   "        result = dict()\n",
   "            keys = self.properties()\n",
   "            keys = set(self._property_values.keys()) | set(self._unstable_default_values.keys())\n",
   "                themed_keys = set(self.themed_values().keys())\n",
   "                keys |= themed_keys\n",
   "        for key in keys:\n",
   "            descriptor = self.lookup(key)\n",
   "            if not query(descriptor):\n",
   "            value = descriptor.serializable_value(self)\n",
   "            if not include_defaults and key not in themed_keys:\n",
   "                if isinstance(value, PropertyValueContainer) and key in self._unstable_default_values:\n",
   "            result[key] = value\n",
   "        return result\n",
   "        old_dict = self.themed_values()\n",
   "        if old_dict is property_values:  # lgtm [py/comparison-using-is]\n",
   "        removed = set()\n",
   "        if old_dict is not None:\n",
   "            removed.update(set(old_dict.keys()))\n",
   "        added = set(property_values.keys())\n",
   "        old_values = dict()\n",
   "        for k in added.union(removed):\n",
   "            old_values[k] = getattr(self, k)\n",
   "        for k, v in old_values.items():\n",
   "            if k in self._unstable_themed_values:\n",
   "                del self._unstable_themed_values[k]\n",
   "        for k, v in old_values.items():\n",
   "            descriptor = self.lookup(k)\n",
   "            descriptor.trigger_if_changed(self, v)\n"
  ]
 },
 "229": {
  "name": "value",
  "type": "BoxAnnotation",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/has_props.py",
  "lineno": "562",
  "column": "12",
  "context": "escriptor):\n                continue\n\n            value = descriptor.serializable_value(self)\n            if not include_defaults and key not in",
  "context_lines": "        for key in keys:\n            descriptor = self.lookup(key)\n            if not query(descriptor):\n                continue\n\n            value = descriptor.serializable_value(self)\n            if not include_defaults and key not in themed_keys:\n                if isinstance(value, PropertyValueContainer) and key in self._unstable_default_values:\n                    continue\n            result[key] = value\n\n",
  "slicing": [
   "log = logging.getLogger(__name__)\n",
   "        names_with_refs = set()\n",
   "        container_names = set()\n",
   "        overridden_defaults = {}\n",
   "        for name, prop in class_dict.items():\n",
   "            if not isinstance(prop, Override):\n",
   "            if prop.default_overridden:\n",
   "                overridden_defaults[name] = prop.default\n",
   "        for name, default in overridden_defaults.items():\n",
   "            del class_dict[name]\n",
   "        generators = dict()\n",
   "        for name, generator in class_dict.items():\n",
   "            if isinstance(generator, PropertyDescriptorFactory):\n",
   "                generators[name] = generator\n",
   "            elif isinstance(generator, type) and issubclass(generator, PropertyDescriptorFactory):\n",
   "                generators[name] = generator.autocreate()\n",
   "        dataspecs = {}\n",
   "        new_class_attrs = {}\n",
   "        for name, generator in generators.items():\n",
   "            prop_descriptors = generator.make_descriptors(name)\n",
   "            replaced_self = False\n",
   "            for prop_descriptor in prop_descriptors:\n",
   "                if prop_descriptor.name in generators:\n",
   "                    if generators[prop_descriptor.name] is generator:\n",
   "                        replaced_self = True\n",
   "                        prop_descriptor.add_prop_descriptor_to_class(class_name, new_class_attrs, names_with_refs, container_names, dataspecs)\n",
   "                    prop_descriptor.add_prop_descriptor_to_class(class_name, new_class_attrs, names_with_refs, container_names, dataspecs)\n",
   "            if not replaced_self:\n",
   "                del class_dict[name]\n",
   "        class_dict.update(new_class_attrs)\n",
   "        class_dict[\"__properties__\"] = set(new_class_attrs)\n",
   "        class_dict[\"__properties_with_refs__\"] = names_with_refs\n",
   "        class_dict[\"__container_props__\"] = container_names\n",
   "        if len(overridden_defaults) > 0:\n",
   "            class_dict[\"__overridden_defaults__\"] = overridden_defaults\n",
   "        if dataspecs:\n",
   "            class_dict[\"__dataspecs__\"] = dataspecs\n",
   "            path = class_dict[\"__example__\"]\n",
   "                class_dict[\"__doc__\"] += _EXAMPLE_TEMPLATE % dict(path=path)\n",
   "        cls_attrs = cls.__dict__.keys() # we do NOT want inherited attrs here\n",
   "        for attr in cls_attrs:\n",
   "            for base in bases:\n",
   "                if issubclass(base, HasProps) and attr in base.properties():\n",
   "                         (attr, base.__name__, attr, class_name,\n",
   "                          base.__name__, attr,\n",
   "                          class_name, attr,\n",
   "                          base.__name__, attr),\n",
   "            our_props = cls.properties()\n",
   "            for key in cls.__dict__[\"__overridden_defaults__\"].keys():\n",
   "                if key not in our_props:\n",
   "                    warn(('Override() of %s in class %s does not override anything.') % (key, class_name),\n",
   "def accumulate_from_superclasses(cls, propname):\n",
   "    cachename = \"__cached_all\" + propname\n",
   "    if cachename not in cls.__dict__:\n",
   "        s = set()\n",
   "        for c in cls.__mro__:\n",
   "            if issubclass(c, HasProps) and hasattr(c, propname):\n",
   "                base = getattr(c, propname)\n",
   "                s.update(base)\n",
   "        setattr(cls, cachename, s)\n",
   "    return cls.__dict__[cachename]\n",
   "def accumulate_dict_from_superclasses(cls, propname):\n",
   "    cachename = \"__cached_all\" + propname\n",
   "    if cachename not in cls.__dict__:\n",
   "        d = dict()\n",
   "        for c in cls.__mro__:\n",
   "            if issubclass(c, HasProps) and hasattr(c, propname):\n",
   "                base = getattr(c, propname)\n",
   "                for k,v in base.items():\n",
   "                    if k not in d:\n",
   "                        d[k] = v\n",
   "        setattr(cls, cachename, d)\n",
   "    return cls.__dict__[cachename]\n",
   "        for name, value in properties.items():\n",
   "            setattr(self, name, value)\n",
   "        if name.startswith(\"_\"):\n",
   "            super().__setattr__(name, value)\n",
   "        props = sorted(self.properties())\n",
   "        descriptor = getattr(self.__class__, name, None)\n",
   "        if name in props or (descriptor is not None and descriptor.fset is not None):\n",
   "            super().__setattr__(name, value)\n",
   "            matches, text = difflib.get_close_matches(name.lower(), props), \"similar\"\n",
   "            if not matches:\n",
   "                matches, text = props, \"possible\"\n",
   "                (name, self.__class__.__name__, text, nice_join(matches)))\n",
   "        if name in self.properties():\n",
   "            log.trace(\"Patching attribute %r of %r with %r\", name, self, json)\n",
   "            descriptor = self.lookup(name)\n",
   "            descriptor.set_from_json(self, json, models, setter)\n",
   "            log.warning(\"JSON had attr %r on obj %r, which is a client-only or invalid attribute that shouldn't have been sent\", name, self)\n",
   "        for k,v in kwargs.items():\n",
   "            setattr(self, k, v)\n",
   "        for k, v in json_attributes.items():\n",
   "            self.set_from_json(k, v, models, setter)\n",
   "        return getattr(cls, name)\n",
   "        return accumulate_from_superclasses(cls, \"__properties_with_refs__\")\n",
   "        return accumulate_from_superclasses(cls, \"__container_props__\")\n",
   "            return accumulate_from_superclasses(cls, \"__properties__\")\n",
   "            return set(cls.__properties__)\n",
   "        return set(cls.dataspecs_with_props().keys())\n",
   "        return accumulate_dict_from_superclasses(cls, \"__dataspecs__\")\n",
   "        return self.query_properties_with_values(lambda prop: prop.serialized, include_defaults)\n",
   "        return accumulate_dict_from_superclasses(cls, \"__overridden_defaults__\")\n",
   "        themed_keys = set()\n",
   "        result = dict()\n",
   "            keys = self.properties()\n",
   "            keys = set(self._property_values.keys()) | set(self._unstable_default_values.keys())\n",
   "                themed_keys = set(self.themed_values().keys())\n",
   "                keys |= themed_keys\n",
   "        for key in keys:\n",
   "            descriptor = self.lookup(key)\n",
   "            if not query(descriptor):\n",
   "            value = descriptor.serializable_value(self)\n",
   "            if not include_defaults and key not in themed_keys:\n",
   "                if isinstance(value, PropertyValueContainer) and key in self._unstable_default_values:\n",
   "            result[key] = value\n",
   "        return result\n",
   "        old_dict = self.themed_values()\n",
   "        if old_dict is property_values:  # lgtm [py/comparison-using-is]\n",
   "        removed = set()\n",
   "        if old_dict is not None:\n",
   "            removed.update(set(old_dict.keys()))\n",
   "        added = set(property_values.keys())\n",
   "        old_values = dict()\n",
   "        for k in added.union(removed):\n",
   "            old_values[k] = getattr(self, k)\n",
   "        for k, v in old_values.items():\n",
   "            if k in self._unstable_themed_values:\n",
   "                del self._unstable_themed_values[k]\n",
   "        for k, v in old_values.items():\n",
   "            descriptor = self.lookup(k)\n",
   "            descriptor.trigger_if_changed(self, v)\n"
  ]
 },
 "230": {
  "name": "old_dict",
  "type": "NoneType",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/has_props.py",
  "lineno": "597",
  "column": "8",
  "context": "   Returns:\n            None\n\n        '''\n        old_dict = self.themed_values()\n\n        # if the same theme is set again, it shou",
  "context_lines": "            property_values (dict) : theme values to use in place of defaults\n\n        Returns:\n            None\n\n        '''\n        old_dict = self.themed_values()\n\n        # if the same theme is set again, it should reuse the same dict\n        if old_dict is property_values:  # lgtm [py/comparison-using-is]\n            return\n\n",
  "slicing": [
   "log = logging.getLogger(__name__)\n",
   "        names_with_refs = set()\n",
   "        container_names = set()\n",
   "        overridden_defaults = {}\n",
   "        for name, prop in class_dict.items():\n",
   "            if not isinstance(prop, Override):\n",
   "            if prop.default_overridden:\n",
   "                overridden_defaults[name] = prop.default\n",
   "        for name, default in overridden_defaults.items():\n",
   "            del class_dict[name]\n",
   "        generators = dict()\n",
   "        for name, generator in class_dict.items():\n",
   "            if isinstance(generator, PropertyDescriptorFactory):\n",
   "                generators[name] = generator\n",
   "            elif isinstance(generator, type) and issubclass(generator, PropertyDescriptorFactory):\n",
   "                generators[name] = generator.autocreate()\n",
   "        dataspecs = {}\n",
   "        new_class_attrs = {}\n",
   "        for name, generator in generators.items():\n",
   "            prop_descriptors = generator.make_descriptors(name)\n",
   "            replaced_self = False\n",
   "            for prop_descriptor in prop_descriptors:\n",
   "                if prop_descriptor.name in generators:\n",
   "                    if generators[prop_descriptor.name] is generator:\n",
   "                        replaced_self = True\n",
   "                        prop_descriptor.add_prop_descriptor_to_class(class_name, new_class_attrs, names_with_refs, container_names, dataspecs)\n",
   "                    prop_descriptor.add_prop_descriptor_to_class(class_name, new_class_attrs, names_with_refs, container_names, dataspecs)\n",
   "            if not replaced_self:\n",
   "                del class_dict[name]\n",
   "        class_dict.update(new_class_attrs)\n",
   "        class_dict[\"__properties__\"] = set(new_class_attrs)\n",
   "        class_dict[\"__properties_with_refs__\"] = names_with_refs\n",
   "        class_dict[\"__container_props__\"] = container_names\n",
   "        if len(overridden_defaults) > 0:\n",
   "            class_dict[\"__overridden_defaults__\"] = overridden_defaults\n",
   "        if dataspecs:\n",
   "            class_dict[\"__dataspecs__\"] = dataspecs\n",
   "            path = class_dict[\"__example__\"]\n",
   "                class_dict[\"__doc__\"] += _EXAMPLE_TEMPLATE % dict(path=path)\n",
   "        cls_attrs = cls.__dict__.keys() # we do NOT want inherited attrs here\n",
   "        for attr in cls_attrs:\n",
   "            for base in bases:\n",
   "                if issubclass(base, HasProps) and attr in base.properties():\n",
   "                         (attr, base.__name__, attr, class_name,\n",
   "                          base.__name__, attr,\n",
   "                          class_name, attr,\n",
   "                          base.__name__, attr),\n",
   "            our_props = cls.properties()\n",
   "            for key in cls.__dict__[\"__overridden_defaults__\"].keys():\n",
   "                if key not in our_props:\n",
   "                    warn(('Override() of %s in class %s does not override anything.') % (key, class_name),\n",
   "def accumulate_from_superclasses(cls, propname):\n",
   "    cachename = \"__cached_all\" + propname\n",
   "    if cachename not in cls.__dict__:\n",
   "        s = set()\n",
   "        for c in cls.__mro__:\n",
   "            if issubclass(c, HasProps) and hasattr(c, propname):\n",
   "                base = getattr(c, propname)\n",
   "                s.update(base)\n",
   "        setattr(cls, cachename, s)\n",
   "    return cls.__dict__[cachename]\n",
   "def accumulate_dict_from_superclasses(cls, propname):\n",
   "    cachename = \"__cached_all\" + propname\n",
   "    if cachename not in cls.__dict__:\n",
   "        d = dict()\n",
   "        for c in cls.__mro__:\n",
   "            if issubclass(c, HasProps) and hasattr(c, propname):\n",
   "                base = getattr(c, propname)\n",
   "                for k,v in base.items():\n",
   "                    if k not in d:\n",
   "                        d[k] = v\n",
   "        setattr(cls, cachename, d)\n",
   "    return cls.__dict__[cachename]\n",
   "        for name, value in properties.items():\n",
   "            setattr(self, name, value)\n",
   "        if name.startswith(\"_\"):\n",
   "            super().__setattr__(name, value)\n",
   "        props = sorted(self.properties())\n",
   "        descriptor = getattr(self.__class__, name, None)\n",
   "        if name in props or (descriptor is not None and descriptor.fset is not None):\n",
   "            super().__setattr__(name, value)\n",
   "            matches, text = difflib.get_close_matches(name.lower(), props), \"similar\"\n",
   "            if not matches:\n",
   "                matches, text = props, \"possible\"\n",
   "                (name, self.__class__.__name__, text, nice_join(matches)))\n",
   "        if name in self.properties():\n",
   "            log.trace(\"Patching attribute %r of %r with %r\", name, self, json)\n",
   "            descriptor = self.lookup(name)\n",
   "            descriptor.set_from_json(self, json, models, setter)\n",
   "            log.warning(\"JSON had attr %r on obj %r, which is a client-only or invalid attribute that shouldn't have been sent\", name, self)\n",
   "        for k,v in kwargs.items():\n",
   "            setattr(self, k, v)\n",
   "        for k, v in json_attributes.items():\n",
   "            self.set_from_json(k, v, models, setter)\n",
   "        return getattr(cls, name)\n",
   "        return accumulate_from_superclasses(cls, \"__properties_with_refs__\")\n",
   "        return accumulate_from_superclasses(cls, \"__container_props__\")\n",
   "            return accumulate_from_superclasses(cls, \"__properties__\")\n",
   "            return set(cls.__properties__)\n",
   "        return set(cls.dataspecs_with_props().keys())\n",
   "        return accumulate_dict_from_superclasses(cls, \"__dataspecs__\")\n",
   "        return self.query_properties_with_values(lambda prop: prop.serialized, include_defaults)\n",
   "        return accumulate_dict_from_superclasses(cls, \"__overridden_defaults__\")\n",
   "        themed_keys = set()\n",
   "        result = dict()\n",
   "            keys = self.properties()\n",
   "            keys = set(self._property_values.keys()) | set(self._unstable_default_values.keys())\n",
   "                themed_keys = set(self.themed_values().keys())\n",
   "                keys |= themed_keys\n",
   "        for key in keys:\n",
   "            descriptor = self.lookup(key)\n",
   "            if not query(descriptor):\n",
   "            value = descriptor.serializable_value(self)\n",
   "            if not include_defaults and key not in themed_keys:\n",
   "                if isinstance(value, PropertyValueContainer) and key in self._unstable_default_values:\n",
   "            result[key] = value\n",
   "        return result\n",
   "        old_dict = self.themed_values()\n",
   "        if old_dict is property_values:  # lgtm [py/comparison-using-is]\n",
   "        removed = set()\n",
   "        if old_dict is not None:\n",
   "            removed.update(set(old_dict.keys()))\n",
   "        added = set(property_values.keys())\n",
   "        old_values = dict()\n",
   "        for k in added.union(removed):\n",
   "            old_values[k] = getattr(self, k)\n",
   "        for k, v in old_values.items():\n",
   "            if k in self._unstable_themed_values:\n",
   "                del self._unstable_themed_values[k]\n",
   "        for k, v in old_values.items():\n",
   "            descriptor = self.lookup(k)\n",
   "            descriptor.trigger_if_changed(self, v)\n"
  ]
 },
 "231": {
  "name": "descriptor",
  "type": "DataSpecPropertyDescriptor",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/has_props.py",
  "lineno": "626",
  "column": "12",
  "context": "      for k, v in old_values.items():\n            descriptor = self.lookup(k)\n            descriptor.trigger_if_changed(self, v)",
  "context_lines": "            if k in self._unstable_themed_values:\n                del self._unstable_themed_values[k]\n\n        # Emit any change notifications that result\n        for k, v in old_values.items():\n            descriptor = self.lookup(k)\n            descriptor.trigger_if_changed(self, v)\n\n    def unapply_theme(self):\n        ''' Remove any themed values and restore defaults.\n\n        Returns:\n",
  "slicing": [
   "log = logging.getLogger(__name__)\n",
   "        names_with_refs = set()\n",
   "        container_names = set()\n",
   "        overridden_defaults = {}\n",
   "        for name, prop in class_dict.items():\n",
   "            if not isinstance(prop, Override):\n",
   "            if prop.default_overridden:\n",
   "                overridden_defaults[name] = prop.default\n",
   "        for name, default in overridden_defaults.items():\n",
   "            del class_dict[name]\n",
   "        generators = dict()\n",
   "        for name, generator in class_dict.items():\n",
   "            if isinstance(generator, PropertyDescriptorFactory):\n",
   "                generators[name] = generator\n",
   "            elif isinstance(generator, type) and issubclass(generator, PropertyDescriptorFactory):\n",
   "                generators[name] = generator.autocreate()\n",
   "        dataspecs = {}\n",
   "        new_class_attrs = {}\n",
   "        for name, generator in generators.items():\n",
   "            prop_descriptors = generator.make_descriptors(name)\n",
   "            replaced_self = False\n",
   "            for prop_descriptor in prop_descriptors:\n",
   "                if prop_descriptor.name in generators:\n",
   "                    if generators[prop_descriptor.name] is generator:\n",
   "                        replaced_self = True\n",
   "                        prop_descriptor.add_prop_descriptor_to_class(class_name, new_class_attrs, names_with_refs, container_names, dataspecs)\n",
   "                    prop_descriptor.add_prop_descriptor_to_class(class_name, new_class_attrs, names_with_refs, container_names, dataspecs)\n",
   "            if not replaced_self:\n",
   "                del class_dict[name]\n",
   "        class_dict.update(new_class_attrs)\n",
   "        class_dict[\"__properties__\"] = set(new_class_attrs)\n",
   "        class_dict[\"__properties_with_refs__\"] = names_with_refs\n",
   "        class_dict[\"__container_props__\"] = container_names\n",
   "        if len(overridden_defaults) > 0:\n",
   "            class_dict[\"__overridden_defaults__\"] = overridden_defaults\n",
   "        if dataspecs:\n",
   "            class_dict[\"__dataspecs__\"] = dataspecs\n",
   "            path = class_dict[\"__example__\"]\n",
   "                class_dict[\"__doc__\"] += _EXAMPLE_TEMPLATE % dict(path=path)\n",
   "        cls_attrs = cls.__dict__.keys() # we do NOT want inherited attrs here\n",
   "        for attr in cls_attrs:\n",
   "            for base in bases:\n",
   "                if issubclass(base, HasProps) and attr in base.properties():\n",
   "                         (attr, base.__name__, attr, class_name,\n",
   "                          base.__name__, attr,\n",
   "                          class_name, attr,\n",
   "                          base.__name__, attr),\n",
   "            our_props = cls.properties()\n",
   "            for key in cls.__dict__[\"__overridden_defaults__\"].keys():\n",
   "                if key not in our_props:\n",
   "                    warn(('Override() of %s in class %s does not override anything.') % (key, class_name),\n",
   "def accumulate_from_superclasses(cls, propname):\n",
   "    cachename = \"__cached_all\" + propname\n",
   "    if cachename not in cls.__dict__:\n",
   "        s = set()\n",
   "        for c in cls.__mro__:\n",
   "            if issubclass(c, HasProps) and hasattr(c, propname):\n",
   "                base = getattr(c, propname)\n",
   "                s.update(base)\n",
   "        setattr(cls, cachename, s)\n",
   "    return cls.__dict__[cachename]\n",
   "def accumulate_dict_from_superclasses(cls, propname):\n",
   "    cachename = \"__cached_all\" + propname\n",
   "    if cachename not in cls.__dict__:\n",
   "        d = dict()\n",
   "        for c in cls.__mro__:\n",
   "            if issubclass(c, HasProps) and hasattr(c, propname):\n",
   "                base = getattr(c, propname)\n",
   "                for k,v in base.items():\n",
   "                    if k not in d:\n",
   "                        d[k] = v\n",
   "        setattr(cls, cachename, d)\n",
   "    return cls.__dict__[cachename]\n",
   "        for name, value in properties.items():\n",
   "            setattr(self, name, value)\n",
   "        if name.startswith(\"_\"):\n",
   "            super().__setattr__(name, value)\n",
   "        props = sorted(self.properties())\n",
   "        descriptor = getattr(self.__class__, name, None)\n",
   "        if name in props or (descriptor is not None and descriptor.fset is not None):\n",
   "            super().__setattr__(name, value)\n",
   "            matches, text = difflib.get_close_matches(name.lower(), props), \"similar\"\n",
   "            if not matches:\n",
   "                matches, text = props, \"possible\"\n",
   "                (name, self.__class__.__name__, text, nice_join(matches)))\n",
   "        if name in self.properties():\n",
   "            log.trace(\"Patching attribute %r of %r with %r\", name, self, json)\n",
   "            descriptor = self.lookup(name)\n",
   "            descriptor.set_from_json(self, json, models, setter)\n",
   "            log.warning(\"JSON had attr %r on obj %r, which is a client-only or invalid attribute that shouldn't have been sent\", name, self)\n",
   "        for k,v in kwargs.items():\n",
   "            setattr(self, k, v)\n",
   "        for k, v in json_attributes.items():\n",
   "            self.set_from_json(k, v, models, setter)\n",
   "        return getattr(cls, name)\n",
   "        return accumulate_from_superclasses(cls, \"__properties_with_refs__\")\n",
   "        return accumulate_from_superclasses(cls, \"__container_props__\")\n",
   "            return accumulate_from_superclasses(cls, \"__properties__\")\n",
   "            return set(cls.__properties__)\n",
   "        return set(cls.dataspecs_with_props().keys())\n",
   "        return accumulate_dict_from_superclasses(cls, \"__dataspecs__\")\n",
   "        return self.query_properties_with_values(lambda prop: prop.serialized, include_defaults)\n",
   "        return accumulate_dict_from_superclasses(cls, \"__overridden_defaults__\")\n",
   "        themed_keys = set()\n",
   "        result = dict()\n",
   "            keys = self.properties()\n",
   "            keys = set(self._property_values.keys()) | set(self._unstable_default_values.keys())\n",
   "                themed_keys = set(self.themed_values().keys())\n",
   "                keys |= themed_keys\n",
   "        for key in keys:\n",
   "            descriptor = self.lookup(key)\n",
   "            if not query(descriptor):\n",
   "            value = descriptor.serializable_value(self)\n",
   "            if not include_defaults and key not in themed_keys:\n",
   "                if isinstance(value, PropertyValueContainer) and key in self._unstable_default_values:\n",
   "            result[key] = value\n",
   "        return result\n",
   "        old_dict = self.themed_values()\n",
   "        if old_dict is property_values:  # lgtm [py/comparison-using-is]\n",
   "        removed = set()\n",
   "        if old_dict is not None:\n",
   "            removed.update(set(old_dict.keys()))\n",
   "        added = set(property_values.keys())\n",
   "        old_values = dict()\n",
   "        for k in added.union(removed):\n",
   "            old_values[k] = getattr(self, k)\n",
   "        for k, v in old_values.items():\n",
   "            if k in self._unstable_themed_values:\n",
   "                del self._unstable_themed_values[k]\n",
   "        for k, v in old_values.items():\n",
   "            descriptor = self.lookup(k)\n",
   "            descriptor.trigger_if_changed(self, v)\n"
  ]
 },
 "232": {
  "name": "enum",
  "type": "bokeh.core.enums.Enumeration",
  "class": "imported",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/property/enum.py",
  "lineno": "49",
  "column": "12",
  "context": "isinstance(enum, enums.Enumeration)):\n            enum = enums.enumeration(enum, *values)\n\n        self._enum = enum\n\n        default = kwar",
  "context_lines": "    See :ref:`bokeh.core.enums` for more information.\n\n    '''\n    def __init__(self, enum, *values, **kwargs):\n        if not (not values and isinstance(enum, enums.Enumeration)):\n            enum = enums.enumeration(enum, *values)\n\n        self._enum = enum\n\n        default = kwargs.get(\"default\", enum._default)\n        help = kwargs.get(\"help\")\n\n",
  "slicing": [
   "            enum = enums.enumeration(enum, *values)\n",
   "        self._enum = enum\n",
   "        default = kwargs.get(\"default\", enum._default)\n",
   "        super().__init__(default=default, help=help)\n"
  ]
 },
 "233": {
  "name": "default",
  "type": "NoneType|str",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/property/enum.py",
  "lineno": "53",
  "column": "8",
  "context": "num, *values)\n\n        self._enum = enum\n\n        default = kwargs.get(\"default\", enum._default)\n        help = kwargs.get(\"help\")\n\n        super()",
  "context_lines": "    def __init__(self, enum, *values, **kwargs):\n        if not (not values and isinstance(enum, enums.Enumeration)):\n            enum = enums.enumeration(enum, *values)\n\n        self._enum = enum\n\n        default = kwargs.get(\"default\", enum._default)\n        help = kwargs.get(\"help\")\n\n        super().__init__(default=default, help=help)\n\n    def __str__(self):\n        return \"%s(%s)\" % (self.__class__.__name__, \", \".join(map(repr, self.allowed_values)))\n\n",
  "slicing": [
   "            enum = enums.enumeration(enum, *values)\n",
   "        self._enum = enum\n",
   "        default = kwargs.get(\"default\", enum._default)\n",
   "        super().__init__(default=default, help=help)\n"
  ]
 },
 "234": {
  "name": "help",
  "type": "NoneType|str",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/property/enum.py",
  "lineno": "54",
  "column": "8",
  "context": "lt = kwargs.get(\"default\", enum._default)\n        help = kwargs.get(\"help\")\n\n        super().__init__(default=default, help=he",
  "context_lines": "        if not (not values and isinstance(enum, enums.Enumeration)):\n            enum = enums.enumeration(enum, *values)\n\n        self._enum = enum\n\n        default = kwargs.get(\"default\", enum._default)\n        help = kwargs.get(\"help\")\n\n        super().__init__(default=default, help=help)\n\n    def __str__(self):\n        return \"%s(%s)\" % (self.__class__.__name__, \", \".join(map(repr, self.allowed_values)))\n\n",
  "slicing": [
   "            enum = enums.enumeration(enum, *values)\n",
   "        self._enum = enum\n",
   "        default = kwargs.get(\"default\", enum._default)\n",
   "        help = kwargs.get(\"help\")\n",
   "        super().__init__(default=default, help=help)\n"
  ]
 },
 "235": {
  "name": "msg",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/property/enum.py",
  "lineno": "69",
  "column": "12",
  "context": "alue is None or value in self._enum):\n            msg = \"\" if not detail else \"invalid value: %r; allowed values are %s\" % (value, nice_join(self.allowed_values))\n            raise ValueError(msg)\n\n    def _sphinx",
  "context_lines": "        return self._enum._values\n\n    def validate(self, value, detail=True):\n        super().validate(value, detail)\n\n        if not (value is None or value in self._enum):\n            msg = \"\" if not detail else \"invalid value: %r; allowed values are %s\" % (value, nice_join(self.allowed_values))\n            raise ValueError(msg)\n\n    def _sphinx_type(self):\n        # try to return a link to a proper enum in bokeh.core.enums if possible\n        if self._enum in enums.__dict__.values():\n",
  "slicing": [
   "            enum = enums.enumeration(enum, *values)\n",
   "        self._enum = enum\n",
   "        default = kwargs.get(\"default\", enum._default)\n",
   "        help = kwargs.get(\"help\")\n",
   "        super().__init__(default=default, help=help)\n",
   "            msg = \"\" if not detail else \"invalid value: %r; allowed values are %s\" % (value, nice_join(self.allowed_values))\n",
   "            raise ValueError(msg)\n"
  ]
 },
 "236": {
  "name": "val",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/property/enum.py",
  "lineno": "77",
  "column": "20",
  "context": "        if self._enum is obj:\n                    val = self._sphinx_model_link(\"%s.%s\" % (self._enum.__module__, name))\n        else:\n            val = str(self._enum)\n  ",
  "context_lines": "        # try to return a link to a proper enum in bokeh.core.enums if possible\n        if self._enum in enums.__dict__.values():\n            for name, obj in enums.__dict__.items():\n                if self._enum is obj:\n                    val = self._sphinx_model_link(\"%s.%s\" % (self._enum.__module__, name))\n        else:\n            val = str(self._enum)\n        return self._sphinx_prop_link() + \"( %s )\" % val\n\n#-----------------------------------------------------------------------------\n",
  "slicing": [
   "            enum = enums.enumeration(enum, *values)\n",
   "        self._enum = enum\n",
   "        default = kwargs.get(\"default\", enum._default)\n",
   "        help = kwargs.get(\"help\")\n",
   "        super().__init__(default=default, help=help)\n",
   "            msg = \"\" if not detail else \"invalid value: %r; allowed values are %s\" % (value, nice_join(self.allowed_values))\n",
   "            raise ValueError(msg)\n",
   "            for name, obj in enums.__dict__.items():\n",
   "                if self._enum is obj:\n",
   "                    val = self._sphinx_model_link(\"%s.%s\" % (self._enum.__module__, name))\n",
   "        return self._sphinx_prop_link() + \"( %s )\" % val\n"
  ]
 },
 "237": {
  "name": "overrides",
  "type": "NoneType|dict",
  "class": "unknown",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/core/property/bases.py",
  "lineno": "178",
  "column": "8",
  "context": "e() and the theme overrides.\n\n        '''\n        overrides = theme_overrides\n        if overrides is None or name not in overri",
  "context_lines": "        return self._copy_default(self._default)\n\n    def themed_default(self, cls, name, theme_overrides):\n        ''' The default, transformed by prepare_value() and the theme overrides.\n\n        '''\n        overrides = theme_overrides\n        if overrides is None or name not in overrides:\n            overrides = cls._overridden_defaults()\n\n        if name in overrides:\n            default = self._copy_default(overrides[name])\n",
  "slicing": [
   "        overrides = theme_overrides\n",
   "        if overrides is None or name not in overrides:\n",
   "            overrides = cls._overridden_defaults()\n",
   "        if name in overrides:\n",
   "            default = self._copy_default(overrides[name])\n",
   "        return self.prepare_value(cls, name, default)\n"
  ]
 },
 "238": {
  "name": "overrides",
  "type": "dict",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/property/bases.py",
  "lineno": "180",
  "column": "12",
  "context": "des is None or name not in overrides:\n            overrides = cls._overridden_defaults()\n\n        if name in overrides:\n            default",
  "context_lines": "        ''' The default, transformed by prepare_value() and the theme overrides.\n\n        '''\n        overrides = theme_overrides\n        if overrides is None or name not in overrides:\n            overrides = cls._overridden_defaults()\n\n        if name in overrides:\n            default = self._copy_default(overrides[name])\n        else:\n",
  "slicing": [
   "        overrides = theme_overrides\n",
   "        if overrides is None or name not in overrides:\n",
   "            overrides = cls._overridden_defaults()\n",
   "        if name in overrides:\n",
   "            default = self._copy_default(overrides[name])\n",
   "        return self.prepare_value(cls, name, default)\n"
  ]
 },
 "239": {
  "name": "default",
  "type": "NoneType|bokeh.models.formatters.BasicTickFormatter|int|str|bokeh.models.tickers.BasicTicker|float",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/property/bases.py",
  "lineno": "183",
  "column": "12",
  "context": "ults()\n\n        if name in overrides:\n            default = self._copy_default(overrides[name])\n        else:\n            default = self._raw_defa",
  "context_lines": "        overrides = theme_overrides\n        if overrides is None or name not in overrides:\n            overrides = cls._overridden_defaults()\n\n        if name in overrides:\n            default = self._copy_default(overrides[name])\n        else:\n            default = self._raw_default()\n        return self.prepare_value(cls, name, default)\n\n    @property\n",
  "slicing": [
   "        overrides = theme_overrides\n",
   "        if overrides is None or name not in overrides:\n",
   "            overrides = cls._overridden_defaults()\n",
   "        if name in overrides:\n",
   "            default = self._copy_default(overrides[name])\n",
   "        return self.prepare_value(cls, name, default)\n"
  ]
 },
 "240": {
  "name": "default",
  "type": "BoxAnnotation",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/property/bases.py",
  "lineno": "185",
  "column": "12",
  "context": "efault(overrides[name])\n        else:\n            default = self._raw_default()\n        return self.prepare_value(cls, name, defau",
  "context_lines": "            overrides = cls._overridden_defaults()\n\n        if name in overrides:\n            default = self._copy_default(overrides[name])\n        else:\n            default = self._raw_default()\n        return self.prepare_value(cls, name, default)\n\n    @property\n    def serialized(self):\n        ''' Whether the property should be serialized when serializing an object.\n\n",
  "slicing": [
   "        overrides = theme_overrides\n",
   "        if overrides is None or name not in overrides:\n",
   "            overrides = cls._overridden_defaults()\n",
   "        if name in overrides:\n",
   "            default = self._copy_default(overrides[name])\n",
   "            default = self._raw_default()\n",
   "        return self.prepare_value(cls, name, default)\n"
  ]
 },
 "241": {
  "name": "obj",
  "type": "BoxAnnotation",
  "class": "customized",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/core/property/bases.py",
  "lineno": "336",
  "column": "12",
  "context": " if isinstance(obj_or_cls, HasProps):\n            obj = obj_or_cls\n\n            for fn, msg_or_fn in self.assertions:",
  "context_lines": "                raise e\n        else:\n            value = self.transform(value)\n\n        if isinstance(obj_or_cls, HasProps):\n            obj = obj_or_cls\n\n            for fn, msg_or_fn in self.assertions:\n                if isinstance(fn, bool):\n                    result = fn\n",
  "slicing": [
   "pd = import_optional('pandas')\n",
   "        overrides = theme_overrides\n",
   "        if overrides is None or name not in overrides:\n",
   "            overrides = cls._overridden_defaults()\n",
   "        if name in overrides:\n",
   "            default = self._copy_default(overrides[name])\n",
   "            default = self._raw_default()\n",
   "        return self.prepare_value(cls, name, default)\n",
   "        if pd:\n",
   "            if isinstance(new, pd.Series) or isinstance(old, pd.Series):\n",
   "            if isinstance(new, pd.Index) or isinstance(old, pd.Index):\n",
   "                return all(self.matches(new[k], old[k]) for k in new)\n",
   "            for tp, converter in self.alternatives:\n",
   "                if tp.is_valid(value):\n",
   "                    value = converter(value)\n",
   "            value = self.transform(value)\n",
   "            obj = obj_or_cls\n",
   "            for fn, msg_or_fn in self.assertions:\n",
   "                if isinstance(fn, bool):\n",
   "                    result = fn\n",
   "                    result = fn(obj, value)\n",
   "                assert isinstance(result, bool)\n",
   "                if not result:\n",
   "                    if isinstance(msg_or_fn, str):\n",
   "                        raise ValueError(msg_or_fn)\n",
   "                        msg_or_fn(obj, name, value)\n",
   "        return self.wrap(value)\n",
   "        tp = ParameterizedProperty._validate_type_param(tp)\n",
   "        self.alternatives.append((tp, converter))\n",
   "        self.assertions.append((fn, msg_or_fn))\n",
   "                type_param = type_param.__name__\n",
   "        elif isinstance(type_param, Property):\n",
   "            return type_param\n",
   "        raise ValueError(\"expected a Property as type parameter, got %s\" % type_param)\n",
   "        return any(type_param.has_ref for type_param in self.type_params)\n",
   "        super().validate(value, detail)\n",
   "        if not (value is None or isinstance(value, self._underlying_type)):\n",
   "            msg = \"\" if not detail else \"expected a value of type %s, got %s of type %s\" % (\n",
   "                nice_join([ cls.__name__ for cls in self._underlying_type ]), value, type(value).__name__\n",
   "            raise ValueError(msg)\n",
   "            expected = nice_join([ cls.__name__ for cls in self._underlying_type ])\n",
   "            raise DeserializationError(\"%s expected %s, got %s of type %s\" % (self, expected, json, type(json).__name__))\n"
  ]
 },
 "242": {
  "name": "result",
  "type": "bool",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/core/property/bases.py",
  "lineno": "342",
  "column": "20",
  "context": "lt = fn\n                else:\n                    result = fn(obj, value)\n\n                assert isinstance(result, bool)\n\n",
  "context_lines": "            for fn, msg_or_fn in self.assertions:\n                if isinstance(fn, bool):\n                    result = fn\n                else:\n                    result = fn(obj, value)\n\n                assert isinstance(result, bool)\n\n                if not result:\n                    if isinstance(msg_or_fn, str):\n",
  "slicing": [
   "pd = import_optional('pandas')\n",
   "        overrides = theme_overrides\n",
   "        if overrides is None or name not in overrides:\n",
   "            overrides = cls._overridden_defaults()\n",
   "        if name in overrides:\n",
   "            default = self._copy_default(overrides[name])\n",
   "            default = self._raw_default()\n",
   "        return self.prepare_value(cls, name, default)\n",
   "        if pd:\n",
   "            if isinstance(new, pd.Series) or isinstance(old, pd.Series):\n",
   "            if isinstance(new, pd.Index) or isinstance(old, pd.Index):\n",
   "                return all(self.matches(new[k], old[k]) for k in new)\n",
   "            for tp, converter in self.alternatives:\n",
   "                if tp.is_valid(value):\n",
   "                    value = converter(value)\n",
   "            value = self.transform(value)\n",
   "            obj = obj_or_cls\n",
   "            for fn, msg_or_fn in self.assertions:\n",
   "                if isinstance(fn, bool):\n",
   "                    result = fn\n",
   "                    result = fn(obj, value)\n",
   "                assert isinstance(result, bool)\n",
   "                if not result:\n",
   "                    if isinstance(msg_or_fn, str):\n",
   "                        raise ValueError(msg_or_fn)\n",
   "                        msg_or_fn(obj, name, value)\n",
   "        return self.wrap(value)\n",
   "        tp = ParameterizedProperty._validate_type_param(tp)\n",
   "        self.alternatives.append((tp, converter))\n",
   "        self.assertions.append((fn, msg_or_fn))\n",
   "                type_param = type_param.__name__\n",
   "        elif isinstance(type_param, Property):\n",
   "            return type_param\n",
   "        raise ValueError(\"expected a Property as type parameter, got %s\" % type_param)\n",
   "        return any(type_param.has_ref for type_param in self.type_params)\n",
   "        super().validate(value, detail)\n",
   "        if not (value is None or isinstance(value, self._underlying_type)):\n",
   "            msg = \"\" if not detail else \"expected a value of type %s, got %s of type %s\" % (\n",
   "                nice_join([ cls.__name__ for cls in self._underlying_type ]), value, type(value).__name__\n",
   "            raise ValueError(msg)\n",
   "            expected = nice_join([ cls.__name__ for cls in self._underlying_type ])\n",
   "            raise DeserializationError(\"%s expected %s, got %s of type %s\" % (self, expected, json, type(json).__name__))\n"
  ]
 },
 "243": {
  "name": "_underlying_type",
  "type": "NoneType",
  "class": "unknown",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/core/property/bases.py",
  "lineno": "447",
  "column": "4",
  "context": " _underlying_type = (numbers.Real,)\n\n    '''\n\n    _underlying_type = None\n\n    def validate(self, value, detail=True):\n     ",
  "context_lines": "        .. code-block:: python\n\n            class Float(PrimitiveProperty):\n                _underlying_type = (numbers.Real,)\n\n    '''\n\n    _underlying_type = None\n\n    def validate(self, value, detail=True):\n        super().validate(value, detail)\n\n        if not (value is None or isinstance(value, self._underlying_type)):\n",
  "slicing": "    _underlying_type = None\n"
 },
 "244": {
  "name": "msg",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/property/bases.py",
  "lineno": "453",
  "column": "12",
  "context": "tance(value, self._underlying_type)):\n            msg = \"\" if not detail else \"expected a value of type %s, got %s of type %s\" % (\n                nice_join([ cls.__name__ for cls i",
  "context_lines": "    _underlying_type = None\n\n    def validate(self, value, detail=True):\n        super().validate(value, detail)\n\n        if not (value is None or isinstance(value, self._underlying_type)):\n            msg = \"\" if not detail else \"expected a value of type %s, got %s of type %s\" % (\n                nice_join([ cls.__name__ for cls in self._underlying_type ]), value, type(value).__name__\n            )\n            raise ValueError(msg)\n\n    def from_json(self, json, models=None):\n",
  "slicing": [
   "pd = import_optional('pandas')\n",
   "        overrides = theme_overrides\n",
   "        if overrides is None or name not in overrides:\n",
   "            overrides = cls._overridden_defaults()\n",
   "        if name in overrides:\n",
   "            default = self._copy_default(overrides[name])\n",
   "            default = self._raw_default()\n",
   "        return self.prepare_value(cls, name, default)\n",
   "        if pd:\n",
   "            if isinstance(new, pd.Series) or isinstance(old, pd.Series):\n",
   "            if isinstance(new, pd.Index) or isinstance(old, pd.Index):\n",
   "                return all(self.matches(new[k], old[k]) for k in new)\n",
   "            for tp, converter in self.alternatives:\n",
   "                if tp.is_valid(value):\n",
   "                    value = converter(value)\n",
   "            value = self.transform(value)\n",
   "            obj = obj_or_cls\n",
   "            for fn, msg_or_fn in self.assertions:\n",
   "                if isinstance(fn, bool):\n",
   "                    result = fn\n",
   "                    result = fn(obj, value)\n",
   "                assert isinstance(result, bool)\n",
   "                if not result:\n",
   "                    if isinstance(msg_or_fn, str):\n",
   "                        raise ValueError(msg_or_fn)\n",
   "                        msg_or_fn(obj, name, value)\n",
   "        return self.wrap(value)\n",
   "        tp = ParameterizedProperty._validate_type_param(tp)\n",
   "        self.alternatives.append((tp, converter))\n",
   "        self.assertions.append((fn, msg_or_fn))\n",
   "                type_param = type_param.__name__\n",
   "        elif isinstance(type_param, Property):\n",
   "            return type_param\n",
   "        raise ValueError(\"expected a Property as type parameter, got %s\" % type_param)\n",
   "        return any(type_param.has_ref for type_param in self.type_params)\n",
   "        super().validate(value, detail)\n",
   "        if not (value is None or isinstance(value, self._underlying_type)):\n",
   "            msg = \"\" if not detail else \"expected a value of type %s, got %s of type %s\" % (\n",
   "                nice_join([ cls.__name__ for cls in self._underlying_type ]), value, type(value).__name__\n",
   "            raise ValueError(msg)\n",
   "            expected = nice_join([ cls.__name__ for cls in self._underlying_type ])\n",
   "            raise DeserializationError(\"%s expected %s, got %s of type %s\" % (self, expected, json, type(json).__name__))\n"
  ]
 },
 "245": {
  "name": "old",
  "type": "list",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/property/wrappers.py",
  "lineno": "121",
  "column": "8",
  "context": "'\n    def wrapper(self, *args, **kwargs):\n        old = self._saved_copy()\n        result = func(self, *args, **kwargs)\n     ",
  "context_lines": "    The returned wrapped method will have a docstring indicating what\n    original method it is wrapping.\n\n    '''\n    def wrapper(self, *args, **kwargs):\n        old = self._saved_copy()\n        result = func(self, *args, **kwargs)\n        self._notify_owners(old)\n        return result\n    wrapper.__doc__ = \"Container method ``%s`` instrumented to notify property owners\" % func.__name__\n",
  "slicing": [
   "        old = self._saved_copy()\n",
   "        self._notify_owners(old)\n",
   "            descriptor._notify_mutated(owner, old, hint=hint)\n",
   "            descriptor._notify_mutated(owner, old, hint=hint)\n",
   "        self._notify_owners(old,\n",
   "        self._notify_owners(old,\n"
  ]
 },
 "246": {
  "name": "result",
  "type": "NoneType",
  "class": "unknown",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/core/property/wrappers.py",
  "lineno": "122",
  "column": "8",
  "context": "kwargs):\n        old = self._saved_copy()\n        result = func(self, *args, **kwargs)\n        self._notify_owners(old)\n        return re",
  "context_lines": "    original method it is wrapping.\n\n    '''\n    def wrapper(self, *args, **kwargs):\n        old = self._saved_copy()\n        result = func(self, *args, **kwargs)\n        self._notify_owners(old)\n        return result\n    wrapper.__doc__ = \"Container method ``%s`` instrumented to notify property owners\" % func.__name__\n    return wrapper\n\n",
  "slicing": [
   "        result = func(self, *args, **kwargs)\n",
   "        return result\n",
   "        return result\n"
  ]
 },
 "247": {
  "name": "result",
  "type": "NoneType",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/property/wrappers.py",
  "lineno": "357",
  "column": "8",
  "context": "tly, bypass wrapped version on base class\n        result = dict.update(self, *args, **kwargs)\n\n        from ...document.events import ColumnData",
  "context_lines": "    # don't wrap with notify_owner --- notifies owners explicitly\n    def update(self, *args, **kwargs):\n        old = self._saved_copy()\n\n        # call dict.update directly, bypass wrapped version on base class\n        result = dict.update(self, *args, **kwargs)\n\n        from ...document.events import ColumnDataChangedEvent\n\n        # Grab keys to update according to  Python docstring for update([E, ]**F)\n        #\n",
  "slicing": [
   "        old = self._saved_copy()\n",
   "        result = func(self, *args, **kwargs)\n",
   "        self._notify_owners(old)\n",
   "        return result\n",
   "        for (owner, descriptor) in self._owners:\n",
   "            descriptor._notify_mutated(owner, old, hint=hint)\n",
   "        old = self._saved_copy()\n",
   "        result = dict.update(self, *args, **kwargs)\n",
   "        cols = set(kwargs.keys())\n",
   "            E = args[0]\n",
   "            if hasattr(E, 'keys'):\n",
   "                cols |= set(E.keys())\n",
   "                cols |= { x[0] for x in E }\n",
   "        for (owner, descriptor) in self._owners:\n",
   "            hint = ColumnDataChangedEvent(owner.document, owner, cols=list(cols))\n",
   "            descriptor._notify_mutated(owner, old, hint=hint)\n",
   "        return result\n",
   "        self._notify_owners(old,\n",
   "        self._notify_owners(old,\n"
  ]
 },
 "248": {
  "name": "_underlying_type",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/core/property/primitive.py",
  "lineno": "90",
  "column": "4",
  "context": "    >>> m.prop = 10  # ValueError !!\n\n    '''\n    _underlying_type = bokeh_bool_types\n\nclass Complex(PrimitiveProperty):\n    ''' Accept ",
  "context_lines": "            >>> m.prop = True\n\n            >>> m.prop = False\n\n            >>> m.prop = 10  # ValueError !!\n\n    '''\n    _underlying_type = bokeh_bool_types\n\nclass Complex(PrimitiveProperty):\n    ''' Accept complex floating point values.\n\n    Args:\n",
  "slicing": [
   "bokeh_bool_types = (bool,)\n",
   "    bokeh_bool_types += (np.bool8,)\n",
   "    _underlying_type = bokeh_bool_types\n"
  ]
 },
 "249": {
  "name": "_underlying_type",
  "type": "tuple",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/core/property/primitive.py",
  "lineno": "154",
  "column": "4",
  "context": "  >>> m.prop = 10.3  # ValueError !!\n\n    '''\n    _underlying_type = bokeh_integer_types\n\nclass Float(PrimitiveProperty):\n    ''' Accept fl",
  "context_lines": "            >>> m.prop = 10\n\n            >>> m.prop = -200\n\n            >>> m.prop = 10.3  # ValueError !!\n\n    '''\n    _underlying_type = bokeh_integer_types\n\nclass Float(PrimitiveProperty):\n    ''' Accept floating point values.\n\n    Args:\n",
  "slicing": [
   "bokeh_bool_types = (bool,)\n",
   "    bokeh_bool_types += (np.bool8,)\n",
   "bokeh_integer_types = (numbers.Integral,)\n",
   "    _underlying_type = bokeh_bool_types\n",
   "    _underlying_type = bokeh_integer_types\n"
  ]
 },
 "250": {
  "name": "default",
  "type": "NoneType",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/property/struct.py",
  "lineno": "43",
  "column": "8",
  "context": "    '''\n    def __init__(self, **fields):\n        default = fields.pop(\"default\", None)\n        help = fields.pop(\"help\", None)\n\n        s",
  "context_lines": "class Struct(ParameterizedProperty):\n    ''' Accept values that are structures.\n\n\n    '''\n    def __init__(self, **fields):\n        default = fields.pop(\"default\", None)\n        help = fields.pop(\"help\", None)\n\n        self._fields = {}\n        for name, type in fields.items():\n            self._fields[name] = self._validate_type_param(type)\n\n",
  "slicing": [
   "        default = fields.pop(\"default\", None)\n",
   "        super().__init__(default=default, help=help)\n"
  ]
 },
 "251": {
  "name": "help",
  "type": "NoneType",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/property/struct.py",
  "lineno": "44",
  "column": "8",
  "context": "    default = fields.pop(\"default\", None)\n        help = fields.pop(\"help\", None)\n\n        self._fields = {}\n        for name, type ",
  "context_lines": "    ''' Accept values that are structures.\n\n\n    '''\n    def __init__(self, **fields):\n        default = fields.pop(\"default\", None)\n        help = fields.pop(\"help\", None)\n\n        self._fields = {}\n        for name, type in fields.items():\n            self._fields[name] = self._validate_type_param(type)\n\n",
  "slicing": [
   "        help = fields.pop(\"help\", None)\n",
   "        super().__init__(default=default, help=help)\n"
  ]
 },
 "252": {
  "name": "value",
  "type": "list",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/property/visual.py",
  "lineno": "94",
  "column": "8",
  "context": "__name__\n\n    def transform(self, value):\n        value = super().transform(value)\n\n        if isinstance(value, str):\n            tr",
  "context_lines": "        super().__init__(*types, default=default, help=help)\n\n    def __str__(self):\n        return self.__class__.__name__\n\n    def transform(self, value):\n        value = super().transform(value)\n\n        if isinstance(value, str):\n            try:\n                return self._dash_patterns[value]\n",
  "slicing": [
   "        types = Enum(enums.DashPattern), Regex(r\"^(\\d+(\\s+\\d+)*)?$\"), Seq(Int)\n",
   "        super().__init__(*types, default=default, help=help)\n",
   "        value = super().transform(value)\n",
   "        if isinstance(value, str):\n",
   "                return self._dash_patterns[value]\n",
   "                return [int(x) for x in  value.split()]\n",
   "            return value\n",
   "        super().validate(value, detail)\n",
   "        if isinstance(value, str):\n",
   "            if len(value) == 0:\n",
   "                msg = \"\" if not detail else \"empty string is not a valid font size value\"\n",
   "                raise ValueError(msg)\n",
   "            elif self._font_size_re.match(value) is None:\n",
   "                msg = \"\" if not detail else \"%r is not a valid font size value\" % value\n",
   "                raise ValueError(msg)\n",
   "        types = Enum(enums.HatchPattern), Enum(enums.HatchPatternAbbreviation)\n",
   "        super().__init__(*types, default=default, help=help)\n",
   "        valid = False\n",
   "        if value is None or isinstance(value, (str, PIL.Image.Image)):\n",
   "            valid = True\n",
   "        if isinstance(value, np.ndarray):\n",
   "            valid = value.dtype == \"uint8\" and len(value.shape) == 3 and value.shape[2] in (3, 4)\n",
   "        if not valid:\n",
   "            msg = \"\" if not detail else \"invalid value: %r; allowed values are string filenames, PIL.Image.Image instances, or RGB(A) NumPy arrays\" % value\n",
   "            raise ValueError(msg)\n",
   "        if value is None:\n",
   "        if isinstance(value, np.ndarray):\n",
   "            value = PIL.Image.fromarray(value)\n",
   "        if isinstance(value, str):\n",
   "            value = PIL.Image.open(value)\n",
   "        if isinstance(value, PIL.Image.Image):\n",
   "            out = BytesIO()\n",
   "            fmt = value.format or \"PNG\"\n",
   "            value.save(out, fmt)\n",
   "            return \"data:image/%s;base64,\" % fmt.lower() + base64.b64encode(out.getvalue()).decode('ascii')\n",
   "        raise ValueError(\"Could not transform %r\" % value)\n",
   "            types = (\n",
   "            types = (\n",
   "        super().__init__(*types, default=default, help=help)\n",
   "        super().validate(value, detail)\n",
   "        if value is None:\n",
   "        if value[0] is None or value[1] is None:\n",
   "        value = list(value)\n",
   "        if isinstance(value[0], datetime.datetime):\n",
   "            value[0] = convert_datetime_type(value[0])\n",
   "        if isinstance(value[1], datetime.datetime):\n",
   "            value[1] = convert_datetime_type(value[1])\n",
   "        if value[0] >= value[1]:\n",
   "            raise ValueError(msg)\n"
  ]
 },
 "253": {
  "name": "_font_size_re",
  "type": "_sre.SRE_Pattern",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/property/visual.py",
  "lineno": "109",
  "column": "4",
  "context": "_sphinx_prop_link()\n\nclass FontSize(String):\n\n    _font_size_re = re.compile(r\"^[0-9]+(.[0-9]+)?(%|em|ex|ch|ic|rem|vw|vh|vi|vb|vmin|vmax|cm|mm|q|in|pc|pt|px)$\", re.I)\n\n    def validate(self, value, detail=True):\n     ",
  "context_lines": "            return value\n\n    def _sphinx_type(self):\n        return self._sphinx_prop_link()\n\nclass FontSize(String):\n\n    _font_size_re = re.compile(r\"^[0-9]+(.[0-9]+)?(%|em|ex|ch|ic|rem|vw|vh|vi|vb|vmin|vmax|cm|mm|q|in|pc|pt|px)$\", re.I)\n\n    def validate(self, value, detail=True):\n        super().validate(value, detail)\n\n        if isinstance(value, str):\n",
  "slicing": [
   "        types = Enum(enums.DashPattern), Regex(r\"^(\\d+(\\s+\\d+)*)?$\"), Seq(Int)\n",
   "        super().__init__(*types, default=default, help=help)\n",
   "        value = super().transform(value)\n",
   "        if isinstance(value, str):\n",
   "                return self._dash_patterns[value]\n",
   "                return [int(x) for x in  value.split()]\n",
   "            return value\n",
   "    _font_size_re = re.compile(r\"^[0-9]+(.[0-9]+)?(%|em|ex|ch|ic|rem|vw|vh|vi|vb|vmin|vmax|cm|mm|q|in|pc|pt|px)$\", re.I)\n",
   "        super().validate(value, detail)\n",
   "        if isinstance(value, str):\n",
   "            if len(value) == 0:\n",
   "                msg = \"\" if not detail else \"empty string is not a valid font size value\"\n",
   "                raise ValueError(msg)\n",
   "            elif self._font_size_re.match(value) is None:\n",
   "                msg = \"\" if not detail else \"%r is not a valid font size value\" % value\n",
   "                raise ValueError(msg)\n",
   "        types = Enum(enums.HatchPattern), Enum(enums.HatchPatternAbbreviation)\n",
   "        super().__init__(*types, default=default, help=help)\n",
   "        valid = False\n",
   "        if value is None or isinstance(value, (str, PIL.Image.Image)):\n",
   "            valid = True\n",
   "        if isinstance(value, np.ndarray):\n",
   "            valid = value.dtype == \"uint8\" and len(value.shape) == 3 and value.shape[2] in (3, 4)\n",
   "        if not valid:\n",
   "            msg = \"\" if not detail else \"invalid value: %r; allowed values are string filenames, PIL.Image.Image instances, or RGB(A) NumPy arrays\" % value\n",
   "            raise ValueError(msg)\n",
   "        if value is None:\n",
   "        if isinstance(value, np.ndarray):\n",
   "            value = PIL.Image.fromarray(value)\n",
   "        if isinstance(value, str):\n",
   "            value = PIL.Image.open(value)\n",
   "        if isinstance(value, PIL.Image.Image):\n",
   "            out = BytesIO()\n",
   "            fmt = value.format or \"PNG\"\n",
   "            value.save(out, fmt)\n",
   "            return \"data:image/%s;base64,\" % fmt.lower() + base64.b64encode(out.getvalue()).decode('ascii')\n",
   "        raise ValueError(\"Could not transform %r\" % value)\n",
   "            types = (\n",
   "            types = (\n",
   "        super().__init__(*types, default=default, help=help)\n",
   "        super().validate(value, detail)\n",
   "        if value is None:\n",
   "        if value[0] is None or value[1] is None:\n",
   "        value = list(value)\n",
   "        if isinstance(value[0], datetime.datetime):\n",
   "            value[0] = convert_datetime_type(value[0])\n",
   "        if isinstance(value[1], datetime.datetime):\n",
   "            value[1] = convert_datetime_type(value[1])\n",
   "        if value[0] >= value[1]:\n",
   "            raise ValueError(msg)\n"
  ]
 },
 "254": {
  "name": "units_name",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/property/dataspec.py",
  "lineno": "413",
  "column": "8",
  "context": "lasses during class creation.\n        '''\n        units_name = base_name + \"_units\"\n        units_props = self._units_type.make_descri",
  "context_lines": "            list[PropertyDescriptor]\n\n        The descriptors returned are collected by the ``MetaHasProps``\n        metaclass and added to ``HasProps`` subclasses during class creation.\n        '''\n        units_name = base_name + \"_units\"\n        units_props = self._units_type.make_descriptors(units_name)\n        return units_props + [ UnitsSpecPropertyDescriptor(base_name, self, units_props[0]) ]\n\nclass AngleSpec(PropertyUnitsSpec):\n    ''' A |DataSpec| property that accepts numeric fixed values, and also\n",
  "slicing": [
   "_ExprFieldValueTransform = Enum(\"expr\", \"field\", \"value\", \"transform\")\n",
   "_ExprFieldValueTransformUnits = Enum(\"expr\", \"field\", \"value\", \"transform\", \"units\")\n",
   "    def __init__(self, default=None, help=None, key_type=_ExprFieldValueTransform, accept_datetime=True, accept_timedelta=True):\n",
   "    def __init__(self, default, help=None, key_type=_ExprFieldValueTransform):\n",
   "            value = dict(value=value[0])\n",
   "        return super().prepare_value(cls, name, value)\n",
   "    def __init__(self, default, help=None, key_type=_ExprFieldValueTransform):\n",
   "        super().validate(value, detail)\n",
   "        if isinstance(value, str):\n",
   "            if len(value) == 0 or value[0].isdigit() and FontSize._font_size_re.match(value) is None:\n",
   "                msg = \"\" if not detail else \"%r is not a valid font size value\" % value\n",
   "                raise ValueError(msg)\n",
   "    def __init__(self, default, help=None, key_type=_ExprFieldValueTransform):\n",
   "    def __init__(self, default, help=None, key_type=_ExprFieldValueTransform):\n",
   "        super().__init__(default=default, help=help, key_type=_ExprFieldValueTransformUnits)\n",
   "        units_props = self._units_type.make_descriptors(\"unused\")\n",
   "        return [ UnitsSpecPropertyDescriptor(base_name, self, units_props[0]) ]\n",
   "        d = super().to_serializable(obj, name, val)\n",
   "        if d is not None and 'units' not in d:\n",
   "            d = dict(d)\n",
   "            d[\"units\"] = self.get_units(obj, name)\n",
   "        return d\n",
   "        units_name = base_name + \"_units\"\n",
   "        units_props = self._units_type.make_descriptors(units_name)\n",
   "        return units_props + [ UnitsSpecPropertyDescriptor(base_name, self, units_props[0]) ]\n",
   "            if value is not None and value < 0:\n",
   "        return super().prepare_value(cls, name, value)\n",
   "            if value is not None and value < 0:\n",
   "        return super().prepare_value(cls, name, value)\n",
   "    def __init__(self, default, help=None, key_type=_ExprFieldValueTransform):\n",
   "        if isinstance(value, tuple) and len(value) in (3, 4) and all(isinstance(v, (float, int)) for v in value):\n",
   "            value = tuple(int(v) if i < 3 else v for i, v in enumerate(value))\n",
   "        return super().prepare_value(cls, name, value)\n"
  ]
 },
 "255": {
  "name": "_units",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/property/dataspec.py",
  "lineno": "467",
  "column": "4",
  "context": "ports\n    ``\"screen\"`` as the units.\n\n    '''\n    _units = \"screen\"\n\nclass DataDistanceSpec(_FixedUnitsDistanceSpec):\n",
  "context_lines": "    ''' A |DataSpec| property that accepts numeric fixed values for screen-space\n    distances, and also provides an associated units property that reports\n    ``\"screen\"`` as the units.\n\n    '''\n    _units = \"screen\"\n\nclass DataDistanceSpec(_FixedUnitsDistanceSpec):\n    ''' A |DataSpec| property that accepts numeric fixed values for data-space\n    distances, and also provides an associated units property that reports\n",
  "slicing": "    _units = \"screen\"\n"
 },
 "256": {
  "name": "_units",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/property/dataspec.py",
  "lineno": "475",
  "column": "4",
  "context": "reports\n    ``\"data\"`` as the units.\n\n    '''\n    _units = \"data\"\n\nclass ColorSpec(DataSpec):\n    ''' A |DataSpec| p",
  "context_lines": "    ''' A |DataSpec| property that accepts numeric fixed values for data-space\n    distances, and also provides an associated units property that reports\n    ``\"data\"`` as the units.\n\n    '''\n    _units = \"data\"\n\nclass ColorSpec(DataSpec):\n    ''' A |DataSpec| property that accepts |Color| fixed values.\n\n    The ``ColorSpec`` property attempts to first interpret string values as\n",
  "slicing": "    _units = \"data\"\n"
 },
 "257": {
  "name": "prefix",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/property/include.py",
  "lineno": "62",
  "column": "16",
  "context": "sinstance(self.use_prefix, bool):\n                prefix = re.sub(\"_props$\", \"\", base_name) + \"_\"\n            else:\n                prefix = self.us",
  "context_lines": "        descriptors = []\n        delegate = self.delegate\n        if self.use_prefix:\n            if isinstance(self.use_prefix, bool):\n                prefix = re.sub(\"_props$\", \"\", base_name) + \"_\"\n            else:\n                prefix = self.use_prefix + \"_\"\n        else:\n            prefix = \"\"\n\n",
  "slicing": [
   "        delegate = self.delegate\n",
   "                prefix = re.sub(\"_props$\", \"\", base_name) + \"_\"\n",
   "                prefix = self.use_prefix + \"_\"\n",
   "            prefix = \"\"\n",
   "        for subpropname in delegate.properties(with_bases=False):\n",
   "            fullpropname = prefix + subpropname\n",
   "            subprop_descriptor = delegate.lookup(subpropname)\n",
   "            if isinstance(subprop_descriptor, BasicPropertyDescriptor):\n",
   "                prop = copy(subprop_descriptor.property)\n",
   "                    doc = self.help % subpropname.replace('_', ' ')\n",
   "                prop.__doc__ = doc\n",
   "                descriptors += prop.make_descriptors(fullpropname)\n",
   "        return descriptors\n"
  ]
 },
 "258": {
  "name": "fullpropname",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/property/include.py",
  "lineno": "71",
  "column": "12",
  "context": "elegate.properties(with_bases=False):\n            fullpropname = prefix + subpropname\n            subprop_descriptor = delegate.lookup(s",
  "context_lines": "            prefix = \"\"\n\n        # it would be better if we kept the original generators from\n        # the delegate and built our Include props from those, perhaps.\n        for subpropname in delegate.properties(with_bases=False):\n            fullpropname = prefix + subpropname\n            subprop_descriptor = delegate.lookup(subpropname)\n            if isinstance(subprop_descriptor, BasicPropertyDescriptor):\n                prop = copy(subprop_descriptor.property)\n                if \"%s\" in self.help:\n",
  "slicing": [
   "        delegate = self.delegate\n",
   "                prefix = re.sub(\"_props$\", \"\", base_name) + \"_\"\n",
   "                prefix = self.use_prefix + \"_\"\n",
   "            prefix = \"\"\n",
   "        for subpropname in delegate.properties(with_bases=False):\n",
   "            fullpropname = prefix + subpropname\n",
   "            subprop_descriptor = delegate.lookup(subpropname)\n",
   "            if isinstance(subprop_descriptor, BasicPropertyDescriptor):\n",
   "                prop = copy(subprop_descriptor.property)\n",
   "                    doc = self.help % subpropname.replace('_', ' ')\n",
   "                prop.__doc__ = doc\n",
   "                descriptors += prop.make_descriptors(fullpropname)\n",
   "        return descriptors\n"
  ]
 },
 "259": {
  "name": "subprop_descriptor",
  "type": "DataSpecPropertyDescriptor",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/property/include.py",
  "lineno": "72",
  "column": "12",
  "context": "  fullpropname = prefix + subpropname\n            subprop_descriptor = delegate.lookup(subpropname)\n            if isinstance(subprop_descriptor, Basi",
  "context_lines": "        # it would be better if we kept the original generators from\n        # the delegate and built our Include props from those, perhaps.\n        for subpropname in delegate.properties(with_bases=False):\n            fullpropname = prefix + subpropname\n            subprop_descriptor = delegate.lookup(subpropname)\n            if isinstance(subprop_descriptor, BasicPropertyDescriptor):\n                prop = copy(subprop_descriptor.property)\n                if \"%s\" in self.help:\n                    doc = self.help % subpropname.replace('_', ' ')\n",
  "slicing": [
   "        delegate = self.delegate\n",
   "                prefix = re.sub(\"_props$\", \"\", base_name) + \"_\"\n",
   "                prefix = self.use_prefix + \"_\"\n",
   "            prefix = \"\"\n",
   "        for subpropname in delegate.properties(with_bases=False):\n",
   "            fullpropname = prefix + subpropname\n",
   "            subprop_descriptor = delegate.lookup(subpropname)\n",
   "            if isinstance(subprop_descriptor, BasicPropertyDescriptor):\n",
   "                prop = copy(subprop_descriptor.property)\n",
   "                    doc = self.help % subpropname.replace('_', ' ')\n",
   "                prop.__doc__ = doc\n",
   "                descriptors += prop.make_descriptors(fullpropname)\n",
   "        return descriptors\n"
  ]
 },
 "260": {
  "name": "doc",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/property/include.py",
  "lineno": "76",
  "column": "20",
  "context": "        if \"%s\" in self.help:\n                    doc = self.help % subpropname.replace('_', ' ')\n                else:\n                    doc = se",
  "context_lines": "            subprop_descriptor = delegate.lookup(subpropname)\n            if isinstance(subprop_descriptor, BasicPropertyDescriptor):\n                prop = copy(subprop_descriptor.property)\n                if \"%s\" in self.help:\n                    doc = self.help % subpropname.replace('_', ' ')\n                else:\n                    doc = self.help\n                prop.__doc__ = doc\n                descriptors += prop.make_descriptors(fullpropname)\n\n",
  "slicing": [
   "        delegate = self.delegate\n",
   "                prefix = re.sub(\"_props$\", \"\", base_name) + \"_\"\n",
   "                prefix = self.use_prefix + \"_\"\n",
   "            prefix = \"\"\n",
   "        for subpropname in delegate.properties(with_bases=False):\n",
   "            fullpropname = prefix + subpropname\n",
   "            subprop_descriptor = delegate.lookup(subpropname)\n",
   "            if isinstance(subprop_descriptor, BasicPropertyDescriptor):\n",
   "                prop = copy(subprop_descriptor.property)\n",
   "                    doc = self.help % subpropname.replace('_', ' ')\n",
   "                prop.__doc__ = doc\n",
   "                descriptors += prop.make_descriptors(fullpropname)\n",
   "        return descriptors\n"
  ]
 },
 "261": {
  "name": "prefix",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/property/include.py",
  "lineno": "64",
  "column": "16",
  "context": "ase_name) + \"_\"\n            else:\n                prefix = self.use_prefix + \"_\"\n        else:\n            prefix = \"\"\n\n        # i",
  "context_lines": "        if self.use_prefix:\n            if isinstance(self.use_prefix, bool):\n                prefix = re.sub(\"_props$\", \"\", base_name) + \"_\"\n            else:\n                prefix = self.use_prefix + \"_\"\n        else:\n            prefix = \"\"\n\n        # it would be better if we kept the original generators from\n        # the delegate and built our Include props from those, perhaps.\n",
  "slicing": [
   "        delegate = self.delegate\n",
   "                prefix = re.sub(\"_props$\", \"\", base_name) + \"_\"\n",
   "                prefix = self.use_prefix + \"_\"\n",
   "            prefix = \"\"\n",
   "        for subpropname in delegate.properties(with_bases=False):\n",
   "            fullpropname = prefix + subpropname\n",
   "            subprop_descriptor = delegate.lookup(subpropname)\n",
   "            if isinstance(subprop_descriptor, BasicPropertyDescriptor):\n",
   "                prop = copy(subprop_descriptor.property)\n",
   "                    doc = self.help % subpropname.replace('_', ' ')\n",
   "                prop.__doc__ = doc\n",
   "                descriptors += prop.make_descriptors(fullpropname)\n",
   "        return descriptors\n"
  ]
 },
 "262": {
  "name": "prefix",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/property/include.py",
  "lineno": "66",
  "column": "12",
  "context": "= self.use_prefix + \"_\"\n        else:\n            prefix = \"\"\n\n        # it would be better if we kept the origi",
  "context_lines": "                prefix = re.sub(\"_props$\", \"\", base_name) + \"_\"\n            else:\n                prefix = self.use_prefix + \"_\"\n        else:\n            prefix = \"\"\n\n        # it would be better if we kept the original generators from\n        # the delegate and built our Include props from those, perhaps.\n        for subpropname in delegate.properties(with_bases=False):\n",
  "slicing": [
   "        delegate = self.delegate\n",
   "                prefix = re.sub(\"_props$\", \"\", base_name) + \"_\"\n",
   "                prefix = self.use_prefix + \"_\"\n",
   "            prefix = \"\"\n",
   "        for subpropname in delegate.properties(with_bases=False):\n",
   "            fullpropname = prefix + subpropname\n",
   "            subprop_descriptor = delegate.lookup(subpropname)\n",
   "            if isinstance(subprop_descriptor, BasicPropertyDescriptor):\n",
   "                prop = copy(subprop_descriptor.property)\n",
   "                    doc = self.help % subpropname.replace('_', ' ')\n",
   "                prop.__doc__ = doc\n",
   "                descriptors += prop.make_descriptors(fullpropname)\n",
   "        return descriptors\n"
  ]
 },
 "263": {
  "name": "doc",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/property/include.py",
  "lineno": "78",
  "column": "20",
  "context": "', ' ')\n                else:\n                    doc = self.help\n                prop.__doc__ = doc\n               ",
  "context_lines": "                prop = copy(subprop_descriptor.property)\n                if \"%s\" in self.help:\n                    doc = self.help % subpropname.replace('_', ' ')\n                else:\n                    doc = self.help\n                prop.__doc__ = doc\n                descriptors += prop.make_descriptors(fullpropname)\n\n        return descriptors\n\n#-----------------------------------------------------------------------------\n",
  "slicing": [
   "        delegate = self.delegate\n",
   "                prefix = re.sub(\"_props$\", \"\", base_name) + \"_\"\n",
   "                prefix = self.use_prefix + \"_\"\n",
   "            prefix = \"\"\n",
   "        for subpropname in delegate.properties(with_bases=False):\n",
   "            fullpropname = prefix + subpropname\n",
   "            subprop_descriptor = delegate.lookup(subpropname)\n",
   "            if isinstance(subprop_descriptor, BasicPropertyDescriptor):\n",
   "                prop = copy(subprop_descriptor.property)\n",
   "                    doc = self.help % subpropname.replace('_', ' ')\n",
   "                    doc = self.help\n",
   "                prop.__doc__ = doc\n",
   "                descriptors += prop.make_descriptors(fullpropname)\n",
   "        return descriptors\n"
  ]
 },
 "264": {
  "name": "help",
  "type": "NoneType|str",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/property/either.py",
  "lineno": "67",
  "column": "8",
  "context": "te_type_param, (tp1, tp2) + type_params))\n        help = kwargs.get(\"help\")\n        def choose_default():\n            return s",
  "context_lines": "            >>> m.prop = \"foo\"  # ValueError !!\n\n    '''\n\n    def __init__(self, tp1, tp2, *type_params, **kwargs):\n        self._type_params = list(map(self._validate_type_param, (tp1, tp2) + type_params))\n        help = kwargs.get(\"help\")\n        def choose_default():\n            return self._type_params[0]._raw_default()\n        default = kwargs.get(\"default\", choose_default)\n        super().__init__(default=default, help=help)\n",
  "slicing": [
   "        help = kwargs.get(\"help\")\n",
   "        super().__init__(default=default, help=help)\n"
  ]
 },
 "265": {
  "name": "default",
  "type": "NoneType|list|function|int|str|dict|float",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/property/either.py",
  "lineno": "70",
  "column": "8",
  "context": "eturn self._type_params[0]._raw_default()\n        default = kwargs.get(\"default\", choose_default)\n        super().__init__(default=default, help=hel",
  "context_lines": "        self._type_params = list(map(self._validate_type_param, (tp1, tp2) + type_params))\n        help = kwargs.get(\"help\")\n        def choose_default():\n            return self._type_params[0]._raw_default()\n        default = kwargs.get(\"default\", choose_default)\n        super().__init__(default=default, help=help)\n        self.alternatives = []\n        for tp in self._type_params:\n            self.alternatives.extend(tp.alternatives)\n\n",
  "slicing": [
   "        default = kwargs.get(\"default\", choose_default)\n",
   "        super().__init__(default=default, help=help)\n"
  ]
 },
 "266": {
  "name": "module",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/property/instance.py",
  "lineno": "73",
  "column": "12",
  "context": "isinstance(self._instance_type, str):\n            module, name = self._instance_type.rsplit(\".\", 1)\n            self._instance_type = getattr(import_m",
  "context_lines": "        return True\n\n    @property\n    def instance_type(self):\n        if isinstance(self._instance_type, str):\n            module, name = self._instance_type.rsplit(\".\", 1)\n            self._instance_type = getattr(import_module(module, \"bokeh\"), name)\n\n        return self._instance_type\n\n    def from_json(self, json, models=None):\n        if json is None:\n",
  "slicing": [
   "            module, name = self._instance_type.rsplit(\".\", 1)\n",
   "            self._instance_type = getattr(import_module(module, \"bokeh\"), name)\n"
  ]
 },
 "267": {
  "name": "name",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/property/instance.py",
  "lineno": "73",
  "column": "20",
  "context": "ce(self._instance_type, str):\n            module, name = self._instance_type.rsplit(\".\", 1)\n            self._instance_type = getattr(import_m",
  "context_lines": "        return True\n\n    @property\n    def instance_type(self):\n        if isinstance(self._instance_type, str):\n            module, name = self._instance_type.rsplit(\".\", 1)\n            self._instance_type = getattr(import_module(module, \"bokeh\"), name)\n\n        return self._instance_type\n\n    def from_json(self, json, models=None):\n        if json is None:\n",
  "slicing": [
   "            module, name = self._instance_type.rsplit(\".\", 1)\n",
   "            self._instance_type = getattr(import_module(module, \"bokeh\"), name)\n",
   "                    model = models.get(json[\"id\"])\n",
   "                    if model is not None:\n",
   "                        return model\n",
   "                for name, value in json.items():\n",
   "                    prop_descriptor = self.instance_type.lookup(name).property\n",
   "                    attrs[name] = prop_descriptor.from_json(value, models)\n"
  ]
 },
 "268": {
  "name": "fullname",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/property/instance.py",
  "lineno": "119",
  "column": "8",
  "context": " return True\n\n    def _sphinx_type(self):\n        fullname = \"%s.%s\" % (self.instance_type.__module__, self.instance_type.__name__)\n        return self._sphinx_prop_link() + \"( %s )\"",
  "context_lines": "    def _may_have_unstable_default(self):\n        # because the instance value is mutable\n        return True\n\n    def _sphinx_type(self):\n        fullname = \"%s.%s\" % (self.instance_type.__module__, self.instance_type.__name__)\n        return self._sphinx_prop_link() + \"( %s )\" % self._sphinx_model_link(fullname)\n\n#-----------------------------------------------------------------------------\n# Dev API\n#-----------------------------------------------------------------------------\n\n",
  "slicing": [
   "            module, name = self._instance_type.rsplit(\".\", 1)\n",
   "            self._instance_type = getattr(import_module(module, \"bokeh\"), name)\n",
   "                    model = models.get(json[\"id\"])\n",
   "                    if model is not None:\n",
   "                        return model\n",
   "                attrs = {}\n",
   "                for name, value in json.items():\n",
   "                    prop_descriptor = self.instance_type.lookup(name).property\n",
   "                    attrs[name] = prop_descriptor.from_json(value, models)\n",
   "                return self.instance_type(**attrs)\n",
   "        super().validate(value, detail)\n",
   "        if value is not None:\n",
   "            if not isinstance(value, self.instance_type):\n",
   "                msg = \"\" if not detail else \"expected an instance of type %s, got %s of type %s\" % (self.instance_type.__name__, value, type(value).__name__)\n",
   "                raise ValueError(msg)\n",
   "        fullname = \"%s.%s\" % (self.instance_type.__module__, self.instance_type.__name__)\n",
   "        return self._sphinx_prop_link() + \"( %s )\" % self._sphinx_model_link(fullname)\n"
  ]
 },
 "269": {
  "name": "name",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/property/descriptors.py",
  "lineno": "248",
  "column": "8",
  "context": "ty\n        from .dataspec import DataSpec\n        name = self.name\n        if name in new_class_attrs:\n            ra",
  "context_lines": "            None\n\n        '''\n        from .bases import ContainerProperty\n        from .dataspec import DataSpec\n        name = self.name\n        if name in new_class_attrs:\n            raise RuntimeError(\"Two property generators both created %s.%s\" % (class_name, name))\n        new_class_attrs[name] = self\n\n        if self.has_ref:\n",
  "slicing": [
   "        name = self.name\n",
   "        if name in new_class_attrs:\n",
   "            raise RuntimeError(\"Two property generators both created %s.%s\" % (class_name, name))\n",
   "        new_class_attrs[name] = self\n",
   "            names_with_refs.add(name)\n",
   "                container_names.add(name)\n",
   "                dataspecs[name] = self\n",
   "        super().__init__(name)\n",
   "        super().__init__(name, property)\n"
  ]
 },
 "270": {
  "name": "value",
  "type": "BoxAnnotation",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/property/descriptors.py",
  "lineno": "289",
  "column": "8",
  "context": "turns:\n            JSON-like\n\n        '''\n        value = self.__get__(obj, obj.__class__)\n        return self.property.serialize_value(value",
  "context_lines": "            obj (HasProps) : the object to get the serialized attribute for\n\n        Returns:\n            JSON-like\n\n        '''\n        value = self.__get__(obj, obj.__class__)\n        return self.property.serialize_value(value)\n\n    def set_from_json(self, obj, json, models=None, setter=None):\n        '''Sets the value of this property from a JSON value.\n\n        Args:\n",
  "slicing": [
   "        name = self.name\n",
   "        if name in new_class_attrs:\n",
   "            raise RuntimeError(\"Two property generators both created %s.%s\" % (class_name, name))\n",
   "        new_class_attrs[name] = self\n",
   "            names_with_refs.add(name)\n",
   "                container_names.add(name)\n",
   "                dataspecs[name] = self\n",
   "        value = self.__get__(obj, obj.__class__)\n",
   "        return self.property.serialize_value(value)\n",
   "        super().__init__(name)\n",
   "        self._internal_set(obj, value, setter=setter)\n",
   "            old_value = obj._property_values[self.name]\n",
   "            self.trigger_if_changed(obj, old_value)\n",
   "        new_value = self.__get__(obj, obj.__class__)\n",
   "        if not self.property.matches(old, new_value):\n",
   "            self._trigger(obj, old, new_value)\n",
   "        is_themed = obj.themed_values() is not None and self.name in obj.themed_values()\n",
   "        default = self.instance_default(obj)\n",
   "        if is_themed:\n",
   "            unstable_dict = obj._unstable_themed_values\n",
   "            unstable_dict = obj._unstable_default_values\n",
   "        if self.name in unstable_dict:\n",
   "            return unstable_dict[self.name]\n",
   "            if isinstance(default, PropertyValueContainer):\n",
   "                default._register_owner(obj, self)\n",
   "            unstable_dict[self.name] = default\n",
   "        return default\n",
   "        value = self.property.prepare_value(obj, self.name, value)\n",
   "        old = self.__get__(obj, obj.__class__)\n",
   "        self._real_set(obj, old, value, hint=hint, setter=setter)\n",
   "        if self.property.matches(value, old) and (hint is None):\n",
   "        was_set = self.name in obj._property_values\n",
   "        if was_set:\n",
   "            old_attr_value = obj._property_values[self.name]\n",
   "            old_attr_value = old\n",
   "        if old_attr_value is not value:\n",
   "            if isinstance(old_attr_value, PropertyValueContainer):\n",
   "                old_attr_value._unregister_owner(obj, self)\n",
   "            if isinstance(value, PropertyValueContainer):\n",
   "                value._register_owner(obj, self)\n",
   "            obj._property_values[self.name] = value\n",
   "        self._trigger(obj, old, value, hint=hint, setter=setter)\n",
   "        value = self.__get__(obj, obj.__class__)\n",
   "        value = self.property.prepare_value(obj, self.name, value)\n",
   "        self._real_set(obj, old, value, hint=hint)\n",
   "            obj.trigger(self.name, old, value, hint, setter)\n",
   "_CDS_SET_FROM_CDS_ERROR = \"\"\"\n",
   "        if isinstance(value, PropertyValueColumnData):\n",
   "            raise ValueError(_CDS_SET_FROM_CDS_ERROR)\n",
   "            hint = ColumnDataChangedEvent(obj.document, obj, setter=setter)\n",
   "            hint = None\n",
   "        self._internal_set(obj, value, hint=hint, setter=setter)\n",
   "            old = getattr(obj, self.name)\n",
   "            if old is not None:\n",
   "                    self.property._type.validate(old, False)\n",
   "                        json = json['value']\n",
   "                    if isinstance(old, str) and 'field' in json:\n",
   "                        json = json['field']\n",
   "        super().set_from_json(obj, json, models, setter)\n",
   "        super().__init__(name, property)\n",
   "        value = self._extract_units(obj, value)\n",
   "        super().__set__(obj, value, setter)\n",
   "        json = self._extract_units(obj, json)\n",
   "        super().set_from_json(obj, json, models, setter)\n",
   "        if isinstance(value, dict):\n",
   "            if 'units' in value:\n",
   "                value = copy(value) # so we can modify it\n",
   "            units = value.pop(\"units\", None)\n",
   "            if units:\n",
   "                self.units_prop.__set__(obj, units)\n",
   "        return value\n"
  ]
 },
 "271": {
  "name": "new_value",
  "type": "int|str|float",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/property/descriptors.py",
  "lineno": "629",
  "column": "8",
  "context": "   Returns:\n            None\n\n        '''\n        new_value = self.__get__(obj, obj.__class__)\n        if not self.property.matches(old, new_valu",
  "context_lines": "                The previous value of the property to compare\n\n        Returns:\n            None\n\n        '''\n        new_value = self.__get__(obj, obj.__class__)\n        if not self.property.matches(old, new_value):\n            self._trigger(obj, old, new_value)\n\n    @property\n    def has_ref(self):\n",
  "slicing": [
   "        name = self.name\n",
   "        if name in new_class_attrs:\n",
   "            raise RuntimeError(\"Two property generators both created %s.%s\" % (class_name, name))\n",
   "        new_class_attrs[name] = self\n",
   "            names_with_refs.add(name)\n",
   "                container_names.add(name)\n",
   "                dataspecs[name] = self\n",
   "        value = self.__get__(obj, obj.__class__)\n",
   "        return self.property.serialize_value(value)\n",
   "        super().__init__(name)\n",
   "        self._internal_set(obj, value, setter=setter)\n",
   "            old_value = obj._property_values[self.name]\n",
   "            self.trigger_if_changed(obj, old_value)\n",
   "        new_value = self.__get__(obj, obj.__class__)\n",
   "        if not self.property.matches(old, new_value):\n",
   "            self._trigger(obj, old, new_value)\n",
   "        is_themed = obj.themed_values() is not None and self.name in obj.themed_values()\n",
   "        default = self.instance_default(obj)\n",
   "        if is_themed:\n",
   "            unstable_dict = obj._unstable_themed_values\n",
   "            unstable_dict = obj._unstable_default_values\n",
   "        if self.name in unstable_dict:\n",
   "            return unstable_dict[self.name]\n",
   "            if isinstance(default, PropertyValueContainer):\n",
   "                default._register_owner(obj, self)\n",
   "            unstable_dict[self.name] = default\n",
   "        return default\n",
   "        value = self.property.prepare_value(obj, self.name, value)\n",
   "        old = self.__get__(obj, obj.__class__)\n",
   "        self._real_set(obj, old, value, hint=hint, setter=setter)\n",
   "        if self.property.matches(value, old) and (hint is None):\n",
   "        was_set = self.name in obj._property_values\n",
   "        if was_set:\n",
   "            old_attr_value = obj._property_values[self.name]\n",
   "            old_attr_value = old\n",
   "        if old_attr_value is not value:\n",
   "            if isinstance(old_attr_value, PropertyValueContainer):\n",
   "                old_attr_value._unregister_owner(obj, self)\n",
   "            if isinstance(value, PropertyValueContainer):\n",
   "                value._register_owner(obj, self)\n",
   "            obj._property_values[self.name] = value\n",
   "        self._trigger(obj, old, value, hint=hint, setter=setter)\n",
   "        value = self.__get__(obj, obj.__class__)\n",
   "        value = self.property.prepare_value(obj, self.name, value)\n",
   "        self._real_set(obj, old, value, hint=hint)\n",
   "            obj.trigger(self.name, old, value, hint, setter)\n",
   "_CDS_SET_FROM_CDS_ERROR = \"\"\"\n",
   "        if isinstance(value, PropertyValueColumnData):\n",
   "            raise ValueError(_CDS_SET_FROM_CDS_ERROR)\n",
   "            hint = ColumnDataChangedEvent(obj.document, obj, setter=setter)\n",
   "            hint = None\n",
   "        self._internal_set(obj, value, hint=hint, setter=setter)\n",
   "            old = getattr(obj, self.name)\n",
   "            if old is not None:\n",
   "                    self.property._type.validate(old, False)\n",
   "                        json = json['value']\n",
   "                    if isinstance(old, str) and 'field' in json:\n",
   "                        json = json['field']\n",
   "        super().set_from_json(obj, json, models, setter)\n",
   "        super().__init__(name, property)\n",
   "        value = self._extract_units(obj, value)\n",
   "        super().__set__(obj, value, setter)\n",
   "        json = self._extract_units(obj, json)\n",
   "        super().set_from_json(obj, json, models, setter)\n",
   "        if isinstance(value, dict):\n",
   "            if 'units' in value:\n",
   "                value = copy(value) # so we can modify it\n",
   "            units = value.pop(\"units\", None)\n",
   "            if units:\n",
   "                self.units_prop.__set__(obj, units)\n",
   "        return value\n"
  ]
 },
 "272": {
  "name": "default",
  "type": "NoneType|bokeh.models.formatters.BasicTickFormatter|int|bokeh.models.scales.LinearScale|bokeh.models.tools.Toolbar|bokeh.models.annotations.Title|bokeh.core.property.wrappers.PropertyValueList|bokeh.models.ranges.DataRange1d|bokeh.core.property.wrappers.PropertyValueDict|float|bokeh.core.property.wrappers.PropertyValueColumnData|bokeh.models.selections.UnionRenderers|str|bokeh.models.selections.Selection|bokeh.models.annotations.BoxAnnotation|bool|list|bokeh.models.tickers.BasicTicker|dict",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/property/descriptors.py",
  "lineno": "706",
  "column": "8",
  "context": "one and self.name in obj.themed_values()\n\n        default = self.instance_default(obj)\n\n        if is_themed:\n            unstable_dict =",
  "context_lines": "        if self.name in obj._property_values:\n            # this shouldn't happen because we should have checked before _get_default()\n            raise RuntimeError(\"Bokeh internal error, does not handle the case of self.name already in _property_values\")\n\n        is_themed = obj.themed_values() is not None and self.name in obj.themed_values()\n\n        default = self.instance_default(obj)\n\n        if is_themed:\n            unstable_dict = obj._unstable_themed_values\n        else:\n",
  "slicing": [
   "        name = self.name\n",
   "        if name in new_class_attrs:\n",
   "            raise RuntimeError(\"Two property generators both created %s.%s\" % (class_name, name))\n",
   "        new_class_attrs[name] = self\n",
   "            names_with_refs.add(name)\n",
   "                container_names.add(name)\n",
   "                dataspecs[name] = self\n",
   "        value = self.__get__(obj, obj.__class__)\n",
   "        return self.property.serialize_value(value)\n",
   "        super().__init__(name)\n",
   "        self._internal_set(obj, value, setter=setter)\n",
   "            old_value = obj._property_values[self.name]\n",
   "            self.trigger_if_changed(obj, old_value)\n",
   "        new_value = self.__get__(obj, obj.__class__)\n",
   "        if not self.property.matches(old, new_value):\n",
   "            self._trigger(obj, old, new_value)\n",
   "        is_themed = obj.themed_values() is not None and self.name in obj.themed_values()\n",
   "        default = self.instance_default(obj)\n",
   "        if is_themed:\n",
   "            unstable_dict = obj._unstable_themed_values\n",
   "            unstable_dict = obj._unstable_default_values\n",
   "        if self.name in unstable_dict:\n",
   "            return unstable_dict[self.name]\n",
   "            if isinstance(default, PropertyValueContainer):\n",
   "                default._register_owner(obj, self)\n",
   "            unstable_dict[self.name] = default\n",
   "        return default\n",
   "        value = self.property.prepare_value(obj, self.name, value)\n",
   "        old = self.__get__(obj, obj.__class__)\n",
   "        self._real_set(obj, old, value, hint=hint, setter=setter)\n",
   "        if self.property.matches(value, old) and (hint is None):\n",
   "        was_set = self.name in obj._property_values\n",
   "        if was_set:\n",
   "            old_attr_value = obj._property_values[self.name]\n",
   "            old_attr_value = old\n",
   "        if old_attr_value is not value:\n",
   "            if isinstance(old_attr_value, PropertyValueContainer):\n",
   "                old_attr_value._unregister_owner(obj, self)\n",
   "            if isinstance(value, PropertyValueContainer):\n",
   "                value._register_owner(obj, self)\n",
   "            obj._property_values[self.name] = value\n",
   "        self._trigger(obj, old, value, hint=hint, setter=setter)\n",
   "        value = self.__get__(obj, obj.__class__)\n",
   "        value = self.property.prepare_value(obj, self.name, value)\n",
   "        self._real_set(obj, old, value, hint=hint)\n",
   "            obj.trigger(self.name, old, value, hint, setter)\n",
   "_CDS_SET_FROM_CDS_ERROR = \"\"\"\n",
   "        if isinstance(value, PropertyValueColumnData):\n",
   "            raise ValueError(_CDS_SET_FROM_CDS_ERROR)\n",
   "            hint = ColumnDataChangedEvent(obj.document, obj, setter=setter)\n",
   "            hint = None\n",
   "        self._internal_set(obj, value, hint=hint, setter=setter)\n",
   "            old = getattr(obj, self.name)\n",
   "            if old is not None:\n",
   "                    self.property._type.validate(old, False)\n",
   "                        json = json['value']\n",
   "                    if isinstance(old, str) and 'field' in json:\n",
   "                        json = json['field']\n",
   "        super().set_from_json(obj, json, models, setter)\n",
   "        super().__init__(name, property)\n",
   "        value = self._extract_units(obj, value)\n",
   "        super().__set__(obj, value, setter)\n",
   "        json = self._extract_units(obj, json)\n",
   "        super().set_from_json(obj, json, models, setter)\n",
   "        if isinstance(value, dict):\n",
   "            if 'units' in value:\n",
   "                value = copy(value) # so we can modify it\n",
   "            units = value.pop(\"units\", None)\n",
   "            if units:\n",
   "                self.units_prop.__set__(obj, units)\n",
   "        return value\n"
  ]
 },
 "273": {
  "name": "unstable_dict",
  "type": "dict",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/property/descriptors.py",
  "lineno": "709",
  "column": "12",
  "context": "e_default(obj)\n\n        if is_themed:\n            unstable_dict = obj._unstable_themed_values\n        else:\n            unstable_dict = obj._uns",
  "context_lines": "            raise RuntimeError(\"Bokeh internal error, does not handle the case of self.name already in _property_values\")\n\n        is_themed = obj.themed_values() is not None and self.name in obj.themed_values()\n\n        default = self.instance_default(obj)\n\n        if is_themed:\n            unstable_dict = obj._unstable_themed_values\n        else:\n            unstable_dict = obj._unstable_default_values\n\n        if self.name in unstable_dict:\n            return unstable_dict[self.name]\n\n",
  "slicing": [
   "        name = self.name\n",
   "        if name in new_class_attrs:\n",
   "            raise RuntimeError(\"Two property generators both created %s.%s\" % (class_name, name))\n",
   "        new_class_attrs[name] = self\n",
   "            names_with_refs.add(name)\n",
   "                container_names.add(name)\n",
   "                dataspecs[name] = self\n",
   "        value = self.__get__(obj, obj.__class__)\n",
   "        return self.property.serialize_value(value)\n",
   "        super().__init__(name)\n",
   "        self._internal_set(obj, value, setter=setter)\n",
   "            old_value = obj._property_values[self.name]\n",
   "            self.trigger_if_changed(obj, old_value)\n",
   "        new_value = self.__get__(obj, obj.__class__)\n",
   "        if not self.property.matches(old, new_value):\n",
   "            self._trigger(obj, old, new_value)\n",
   "        is_themed = obj.themed_values() is not None and self.name in obj.themed_values()\n",
   "        default = self.instance_default(obj)\n",
   "        if is_themed:\n",
   "            unstable_dict = obj._unstable_themed_values\n",
   "            unstable_dict = obj._unstable_default_values\n",
   "        if self.name in unstable_dict:\n",
   "            return unstable_dict[self.name]\n",
   "            if isinstance(default, PropertyValueContainer):\n",
   "                default._register_owner(obj, self)\n",
   "            unstable_dict[self.name] = default\n",
   "        return default\n",
   "        value = self.property.prepare_value(obj, self.name, value)\n",
   "        old = self.__get__(obj, obj.__class__)\n",
   "        self._real_set(obj, old, value, hint=hint, setter=setter)\n",
   "        if self.property.matches(value, old) and (hint is None):\n",
   "        was_set = self.name in obj._property_values\n",
   "        if was_set:\n",
   "            old_attr_value = obj._property_values[self.name]\n",
   "            old_attr_value = old\n",
   "        if old_attr_value is not value:\n",
   "            if isinstance(old_attr_value, PropertyValueContainer):\n",
   "                old_attr_value._unregister_owner(obj, self)\n",
   "            if isinstance(value, PropertyValueContainer):\n",
   "                value._register_owner(obj, self)\n",
   "            obj._property_values[self.name] = value\n",
   "        self._trigger(obj, old, value, hint=hint, setter=setter)\n",
   "        value = self.__get__(obj, obj.__class__)\n",
   "        value = self.property.prepare_value(obj, self.name, value)\n",
   "        self._real_set(obj, old, value, hint=hint)\n",
   "            obj.trigger(self.name, old, value, hint, setter)\n",
   "_CDS_SET_FROM_CDS_ERROR = \"\"\"\n",
   "        if isinstance(value, PropertyValueColumnData):\n",
   "            raise ValueError(_CDS_SET_FROM_CDS_ERROR)\n",
   "            hint = ColumnDataChangedEvent(obj.document, obj, setter=setter)\n",
   "            hint = None\n",
   "        self._internal_set(obj, value, hint=hint, setter=setter)\n",
   "            old = getattr(obj, self.name)\n",
   "            if old is not None:\n",
   "                    self.property._type.validate(old, False)\n",
   "                        json = json['value']\n",
   "                    if isinstance(old, str) and 'field' in json:\n",
   "                        json = json['field']\n",
   "        super().set_from_json(obj, json, models, setter)\n",
   "        super().__init__(name, property)\n",
   "        value = self._extract_units(obj, value)\n",
   "        super().__set__(obj, value, setter)\n",
   "        json = self._extract_units(obj, json)\n",
   "        super().set_from_json(obj, json, models, setter)\n",
   "        if isinstance(value, dict):\n",
   "            if 'units' in value:\n",
   "                value = copy(value) # so we can modify it\n",
   "            units = value.pop(\"units\", None)\n",
   "            if units:\n",
   "                self.units_prop.__set__(obj, units)\n",
   "        return value\n"
  ]
 },
 "274": {
  "name": "unstable_dict",
  "type": "dict",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/property/descriptors.py",
  "lineno": "711",
  "column": "12",
  "context": "_unstable_themed_values\n        else:\n            unstable_dict = obj._unstable_default_values\n\n        if self.name in unstable_dict:\n          ",
  "context_lines": "        default = self.instance_default(obj)\n\n        if is_themed:\n            unstable_dict = obj._unstable_themed_values\n        else:\n            unstable_dict = obj._unstable_default_values\n\n        if self.name in unstable_dict:\n            return unstable_dict[self.name]\n\n        if self.property._may_have_unstable_default():\n",
  "slicing": [
   "        name = self.name\n",
   "        if name in new_class_attrs:\n",
   "            raise RuntimeError(\"Two property generators both created %s.%s\" % (class_name, name))\n",
   "        new_class_attrs[name] = self\n",
   "            names_with_refs.add(name)\n",
   "                container_names.add(name)\n",
   "                dataspecs[name] = self\n",
   "        value = self.__get__(obj, obj.__class__)\n",
   "        return self.property.serialize_value(value)\n",
   "        super().__init__(name)\n",
   "        self._internal_set(obj, value, setter=setter)\n",
   "            old_value = obj._property_values[self.name]\n",
   "            self.trigger_if_changed(obj, old_value)\n",
   "        new_value = self.__get__(obj, obj.__class__)\n",
   "        if not self.property.matches(old, new_value):\n",
   "            self._trigger(obj, old, new_value)\n",
   "        is_themed = obj.themed_values() is not None and self.name in obj.themed_values()\n",
   "        default = self.instance_default(obj)\n",
   "        if is_themed:\n",
   "            unstable_dict = obj._unstable_themed_values\n",
   "            unstable_dict = obj._unstable_default_values\n",
   "        if self.name in unstable_dict:\n",
   "            return unstable_dict[self.name]\n",
   "            if isinstance(default, PropertyValueContainer):\n",
   "                default._register_owner(obj, self)\n",
   "            unstable_dict[self.name] = default\n",
   "        return default\n",
   "        value = self.property.prepare_value(obj, self.name, value)\n",
   "        old = self.__get__(obj, obj.__class__)\n",
   "        self._real_set(obj, old, value, hint=hint, setter=setter)\n",
   "        if self.property.matches(value, old) and (hint is None):\n",
   "        was_set = self.name in obj._property_values\n",
   "        if was_set:\n",
   "            old_attr_value = obj._property_values[self.name]\n",
   "            old_attr_value = old\n",
   "        if old_attr_value is not value:\n",
   "            if isinstance(old_attr_value, PropertyValueContainer):\n",
   "                old_attr_value._unregister_owner(obj, self)\n",
   "            if isinstance(value, PropertyValueContainer):\n",
   "                value._register_owner(obj, self)\n",
   "            obj._property_values[self.name] = value\n",
   "        self._trigger(obj, old, value, hint=hint, setter=setter)\n",
   "        value = self.__get__(obj, obj.__class__)\n",
   "        value = self.property.prepare_value(obj, self.name, value)\n",
   "        self._real_set(obj, old, value, hint=hint)\n",
   "            obj.trigger(self.name, old, value, hint, setter)\n",
   "_CDS_SET_FROM_CDS_ERROR = \"\"\"\n",
   "        if isinstance(value, PropertyValueColumnData):\n",
   "            raise ValueError(_CDS_SET_FROM_CDS_ERROR)\n",
   "            hint = ColumnDataChangedEvent(obj.document, obj, setter=setter)\n",
   "            hint = None\n",
   "        self._internal_set(obj, value, hint=hint, setter=setter)\n",
   "            old = getattr(obj, self.name)\n",
   "            if old is not None:\n",
   "                    self.property._type.validate(old, False)\n",
   "                        json = json['value']\n",
   "                    if isinstance(old, str) and 'field' in json:\n",
   "                        json = json['field']\n",
   "        super().set_from_json(obj, json, models, setter)\n",
   "        super().__init__(name, property)\n",
   "        value = self._extract_units(obj, value)\n",
   "        super().__set__(obj, value, setter)\n",
   "        json = self._extract_units(obj, json)\n",
   "        super().set_from_json(obj, json, models, setter)\n",
   "        if isinstance(value, dict):\n",
   "            if 'units' in value:\n",
   "                value = copy(value) # so we can modify it\n",
   "            units = value.pop(\"units\", None)\n",
   "            if units:\n",
   "                self.units_prop.__set__(obj, units)\n",
   "        return value\n"
  ]
 },
 "275": {
  "name": "value",
  "type": "NoneType|bokeh.core.property.wrappers.PropertyValueList|bokeh.models.sources.ColumnDataSource|list|bokeh.models.sources.CDSView|int|bokeh.models.scales.LinearScale|bokeh.models.glyphs.Line|str|bokeh.models.ranges.DataRange1d|bokeh.models.axes.LinearAxis|dict|float",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/property/descriptors.py",
  "lineno": "760",
  "column": "8",
  "context": "   Returns:\n            None\n\n        '''\n        value = self.property.prepare_value(obj, self.name, value)\n\n        old = self.__get__(obj, obj.__class__)\n  ",
  "context_lines": "                suppress any updates that originate from itself.\n\n        Returns:\n            None\n\n        '''\n        value = self.property.prepare_value(obj, self.name, value)\n\n        old = self.__get__(obj, obj.__class__)\n        self._real_set(obj, old, value, hint=hint, setter=setter)\n\n    def _real_set(self, obj, old, value, hint=None, setter=None):\n",
  "slicing": [
   "        name = self.name\n",
   "        if name in new_class_attrs:\n",
   "            raise RuntimeError(\"Two property generators both created %s.%s\" % (class_name, name))\n",
   "        new_class_attrs[name] = self\n",
   "            names_with_refs.add(name)\n",
   "                container_names.add(name)\n",
   "                dataspecs[name] = self\n",
   "        value = self.__get__(obj, obj.__class__)\n",
   "        return self.property.serialize_value(value)\n",
   "        super().__init__(name)\n",
   "        self._internal_set(obj, value, setter=setter)\n",
   "            old_value = obj._property_values[self.name]\n",
   "            self.trigger_if_changed(obj, old_value)\n",
   "        new_value = self.__get__(obj, obj.__class__)\n",
   "        if not self.property.matches(old, new_value):\n",
   "            self._trigger(obj, old, new_value)\n",
   "        is_themed = obj.themed_values() is not None and self.name in obj.themed_values()\n",
   "        default = self.instance_default(obj)\n",
   "        if is_themed:\n",
   "            unstable_dict = obj._unstable_themed_values\n",
   "            unstable_dict = obj._unstable_default_values\n",
   "        if self.name in unstable_dict:\n",
   "            return unstable_dict[self.name]\n",
   "            if isinstance(default, PropertyValueContainer):\n",
   "                default._register_owner(obj, self)\n",
   "            unstable_dict[self.name] = default\n",
   "        return default\n",
   "        value = self.property.prepare_value(obj, self.name, value)\n",
   "        old = self.__get__(obj, obj.__class__)\n",
   "        self._real_set(obj, old, value, hint=hint, setter=setter)\n",
   "        if self.property.matches(value, old) and (hint is None):\n",
   "        was_set = self.name in obj._property_values\n",
   "        if was_set:\n",
   "            old_attr_value = obj._property_values[self.name]\n",
   "            old_attr_value = old\n",
   "        if old_attr_value is not value:\n",
   "            if isinstance(old_attr_value, PropertyValueContainer):\n",
   "                old_attr_value._unregister_owner(obj, self)\n",
   "            if isinstance(value, PropertyValueContainer):\n",
   "                value._register_owner(obj, self)\n",
   "            obj._property_values[self.name] = value\n",
   "        self._trigger(obj, old, value, hint=hint, setter=setter)\n",
   "        value = self.__get__(obj, obj.__class__)\n",
   "        value = self.property.prepare_value(obj, self.name, value)\n",
   "        self._real_set(obj, old, value, hint=hint)\n",
   "            obj.trigger(self.name, old, value, hint, setter)\n",
   "_CDS_SET_FROM_CDS_ERROR = \"\"\"\n",
   "        if isinstance(value, PropertyValueColumnData):\n",
   "            raise ValueError(_CDS_SET_FROM_CDS_ERROR)\n",
   "            hint = ColumnDataChangedEvent(obj.document, obj, setter=setter)\n",
   "            hint = None\n",
   "        self._internal_set(obj, value, hint=hint, setter=setter)\n",
   "            old = getattr(obj, self.name)\n",
   "            if old is not None:\n",
   "                    self.property._type.validate(old, False)\n",
   "                        json = json['value']\n",
   "                    if isinstance(old, str) and 'field' in json:\n",
   "                        json = json['field']\n",
   "        super().set_from_json(obj, json, models, setter)\n",
   "        super().__init__(name, property)\n",
   "        value = self._extract_units(obj, value)\n",
   "        super().__set__(obj, value, setter)\n",
   "        json = self._extract_units(obj, json)\n",
   "        super().set_from_json(obj, json, models, setter)\n",
   "        if isinstance(value, dict):\n",
   "            if 'units' in value:\n",
   "                value = copy(value) # so we can modify it\n",
   "            units = value.pop(\"units\", None)\n",
   "            if units:\n",
   "                self.units_prop.__set__(obj, units)\n",
   "        return value\n"
  ]
 },
 "276": {
  "name": "old",
  "type": "NoneType|bokeh.core.property.wrappers.PropertyValueList|list|int|bokeh.models.scales.LinearScale|str|bokeh.models.ranges.DataRange1d|dict|float",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/property/descriptors.py",
  "lineno": "762",
  "column": "8",
  "context": "rty.prepare_value(obj, self.name, value)\n\n        old = self.__get__(obj, obj.__class__)\n        self._real_set(obj, old, value, hint=hint,",
  "context_lines": "        Returns:\n            None\n\n        '''\n        value = self.property.prepare_value(obj, self.name, value)\n\n        old = self.__get__(obj, obj.__class__)\n        self._real_set(obj, old, value, hint=hint, setter=setter)\n\n    def _real_set(self, obj, old, value, hint=None, setter=None):\n        ''' Internal implementation helper to set property values.\n\n        This function handles bookkeeping around noting whether values have\n",
  "slicing": [
   "        name = self.name\n",
   "        if name in new_class_attrs:\n",
   "            raise RuntimeError(\"Two property generators both created %s.%s\" % (class_name, name))\n",
   "        new_class_attrs[name] = self\n",
   "            names_with_refs.add(name)\n",
   "                container_names.add(name)\n",
   "                dataspecs[name] = self\n",
   "        value = self.__get__(obj, obj.__class__)\n",
   "        return self.property.serialize_value(value)\n",
   "        super().__init__(name)\n",
   "        self._internal_set(obj, value, setter=setter)\n",
   "            old_value = obj._property_values[self.name]\n",
   "            self.trigger_if_changed(obj, old_value)\n",
   "        new_value = self.__get__(obj, obj.__class__)\n",
   "        if not self.property.matches(old, new_value):\n",
   "            self._trigger(obj, old, new_value)\n",
   "        is_themed = obj.themed_values() is not None and self.name in obj.themed_values()\n",
   "        default = self.instance_default(obj)\n",
   "        if is_themed:\n",
   "            unstable_dict = obj._unstable_themed_values\n",
   "            unstable_dict = obj._unstable_default_values\n",
   "        if self.name in unstable_dict:\n",
   "            return unstable_dict[self.name]\n",
   "            if isinstance(default, PropertyValueContainer):\n",
   "                default._register_owner(obj, self)\n",
   "            unstable_dict[self.name] = default\n",
   "        return default\n",
   "        value = self.property.prepare_value(obj, self.name, value)\n",
   "        old = self.__get__(obj, obj.__class__)\n",
   "        self._real_set(obj, old, value, hint=hint, setter=setter)\n",
   "        if self.property.matches(value, old) and (hint is None):\n",
   "        was_set = self.name in obj._property_values\n",
   "        if was_set:\n",
   "            old_attr_value = obj._property_values[self.name]\n",
   "            old_attr_value = old\n",
   "        if old_attr_value is not value:\n",
   "            if isinstance(old_attr_value, PropertyValueContainer):\n",
   "                old_attr_value._unregister_owner(obj, self)\n",
   "            if isinstance(value, PropertyValueContainer):\n",
   "                value._register_owner(obj, self)\n",
   "            obj._property_values[self.name] = value\n",
   "        self._trigger(obj, old, value, hint=hint, setter=setter)\n",
   "        value = self.__get__(obj, obj.__class__)\n",
   "        value = self.property.prepare_value(obj, self.name, value)\n",
   "        self._real_set(obj, old, value, hint=hint)\n",
   "            obj.trigger(self.name, old, value, hint, setter)\n",
   "_CDS_SET_FROM_CDS_ERROR = \"\"\"\n",
   "        if isinstance(value, PropertyValueColumnData):\n",
   "            raise ValueError(_CDS_SET_FROM_CDS_ERROR)\n",
   "            hint = ColumnDataChangedEvent(obj.document, obj, setter=setter)\n",
   "            hint = None\n",
   "        self._internal_set(obj, value, hint=hint, setter=setter)\n",
   "            old = getattr(obj, self.name)\n",
   "            if old is not None:\n",
   "                    self.property._type.validate(old, False)\n",
   "                        json = json['value']\n",
   "                    if isinstance(old, str) and 'field' in json:\n",
   "                        json = json['field']\n",
   "        super().set_from_json(obj, json, models, setter)\n",
   "        super().__init__(name, property)\n",
   "        value = self._extract_units(obj, value)\n",
   "        super().__set__(obj, value, setter)\n",
   "        json = self._extract_units(obj, json)\n",
   "        super().set_from_json(obj, json, models, setter)\n",
   "        if isinstance(value, dict):\n",
   "            if 'units' in value:\n",
   "                value = copy(value) # so we can modify it\n",
   "            units = value.pop(\"units\", None)\n",
   "            if units:\n",
   "                self.units_prop.__set__(obj, units)\n",
   "        return value\n"
  ]
 },
 "277": {
  "name": "old_attr_value",
  "type": "NoneType|bokeh.core.property.wrappers.PropertyValueList|list|int|bokeh.models.scales.LinearScale|str|bokeh.models.ranges.DataRange1d|dict|float",
  "class": "unknown",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/core/property/descriptors.py",
  "lineno": "815",
  "column": "12",
  "context": "perty_values[self.name]\n        else:\n            old_attr_value = old\n\n        if old_attr_value is not value:\n         ",
  "context_lines": "        # _notify_mutated.\n        if was_set:\n            old_attr_value = obj._property_values[self.name]\n        else:\n            old_attr_value = old\n\n        if old_attr_value is not value:\n            if isinstance(old_attr_value, PropertyValueContainer):\n                old_attr_value._unregister_owner(obj, self)\n",
  "slicing": [
   "        name = self.name\n",
   "        if name in new_class_attrs:\n",
   "            raise RuntimeError(\"Two property generators both created %s.%s\" % (class_name, name))\n",
   "        new_class_attrs[name] = self\n",
   "            names_with_refs.add(name)\n",
   "                container_names.add(name)\n",
   "                dataspecs[name] = self\n",
   "        value = self.__get__(obj, obj.__class__)\n",
   "        return self.property.serialize_value(value)\n",
   "        super().__init__(name)\n",
   "        self._internal_set(obj, value, setter=setter)\n",
   "            old_value = obj._property_values[self.name]\n",
   "            self.trigger_if_changed(obj, old_value)\n",
   "        new_value = self.__get__(obj, obj.__class__)\n",
   "        if not self.property.matches(old, new_value):\n",
   "            self._trigger(obj, old, new_value)\n",
   "        is_themed = obj.themed_values() is not None and self.name in obj.themed_values()\n",
   "        default = self.instance_default(obj)\n",
   "        if is_themed:\n",
   "            unstable_dict = obj._unstable_themed_values\n",
   "            unstable_dict = obj._unstable_default_values\n",
   "        if self.name in unstable_dict:\n",
   "            return unstable_dict[self.name]\n",
   "            if isinstance(default, PropertyValueContainer):\n",
   "                default._register_owner(obj, self)\n",
   "            unstable_dict[self.name] = default\n",
   "        return default\n",
   "        value = self.property.prepare_value(obj, self.name, value)\n",
   "        old = self.__get__(obj, obj.__class__)\n",
   "        self._real_set(obj, old, value, hint=hint, setter=setter)\n",
   "        if self.property.matches(value, old) and (hint is None):\n",
   "        was_set = self.name in obj._property_values\n",
   "        if was_set:\n",
   "            old_attr_value = obj._property_values[self.name]\n",
   "            old_attr_value = old\n",
   "        if old_attr_value is not value:\n",
   "            if isinstance(old_attr_value, PropertyValueContainer):\n",
   "                old_attr_value._unregister_owner(obj, self)\n",
   "            if isinstance(value, PropertyValueContainer):\n",
   "                value._register_owner(obj, self)\n",
   "            obj._property_values[self.name] = value\n",
   "        self._trigger(obj, old, value, hint=hint, setter=setter)\n",
   "        value = self.__get__(obj, obj.__class__)\n",
   "        value = self.property.prepare_value(obj, self.name, value)\n",
   "        self._real_set(obj, old, value, hint=hint)\n",
   "            obj.trigger(self.name, old, value, hint, setter)\n",
   "_CDS_SET_FROM_CDS_ERROR = \"\"\"\n",
   "        if isinstance(value, PropertyValueColumnData):\n",
   "            raise ValueError(_CDS_SET_FROM_CDS_ERROR)\n",
   "            hint = ColumnDataChangedEvent(obj.document, obj, setter=setter)\n",
   "            hint = None\n",
   "        self._internal_set(obj, value, hint=hint, setter=setter)\n",
   "            old = getattr(obj, self.name)\n",
   "            if old is not None:\n",
   "                    self.property._type.validate(old, False)\n",
   "                        json = json['value']\n",
   "                    if isinstance(old, str) and 'field' in json:\n",
   "                        json = json['field']\n",
   "        super().set_from_json(obj, json, models, setter)\n",
   "        super().__init__(name, property)\n",
   "        value = self._extract_units(obj, value)\n",
   "        super().__set__(obj, value, setter)\n",
   "        json = self._extract_units(obj, json)\n",
   "        super().set_from_json(obj, json, models, setter)\n",
   "        if isinstance(value, dict):\n",
   "            if 'units' in value:\n",
   "                value = copy(value) # so we can modify it\n",
   "            units = value.pop(\"units\", None)\n",
   "            if units:\n",
   "                self.units_prop.__set__(obj, units)\n",
   "        return value\n"
  ]
 },
 "278": {
  "name": "value",
  "type": "PropertyValueList",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/property/descriptors.py",
  "lineno": "863",
  "column": "8",
  "context": "   Returns:\n            None\n\n        '''\n        value = self.__get__(obj, obj.__class__)\n\n        # re-validate because the contents of 'ol",
  "context_lines": "                some way (e.g. streaming or patching column data sources)\n\n        Returns:\n            None\n\n        '''\n        value = self.__get__(obj, obj.__class__)\n\n        # re-validate because the contents of 'old' have changed,\n        # in some cases this could give us a new object for the value\n        value = self.property.prepare_value(obj, self.name, value)\n\n",
  "slicing": [
   "        name = self.name\n",
   "        if name in new_class_attrs:\n",
   "            raise RuntimeError(\"Two property generators both created %s.%s\" % (class_name, name))\n",
   "        new_class_attrs[name] = self\n",
   "            names_with_refs.add(name)\n",
   "                container_names.add(name)\n",
   "                dataspecs[name] = self\n",
   "        value = self.__get__(obj, obj.__class__)\n",
   "        return self.property.serialize_value(value)\n",
   "        super().__init__(name)\n",
   "        self._internal_set(obj, value, setter=setter)\n",
   "            old_value = obj._property_values[self.name]\n",
   "            self.trigger_if_changed(obj, old_value)\n",
   "        new_value = self.__get__(obj, obj.__class__)\n",
   "        if not self.property.matches(old, new_value):\n",
   "            self._trigger(obj, old, new_value)\n",
   "        is_themed = obj.themed_values() is not None and self.name in obj.themed_values()\n",
   "        default = self.instance_default(obj)\n",
   "        if is_themed:\n",
   "            unstable_dict = obj._unstable_themed_values\n",
   "            unstable_dict = obj._unstable_default_values\n",
   "        if self.name in unstable_dict:\n",
   "            return unstable_dict[self.name]\n",
   "            if isinstance(default, PropertyValueContainer):\n",
   "                default._register_owner(obj, self)\n",
   "            unstable_dict[self.name] = default\n",
   "        return default\n",
   "        value = self.property.prepare_value(obj, self.name, value)\n",
   "        old = self.__get__(obj, obj.__class__)\n",
   "        self._real_set(obj, old, value, hint=hint, setter=setter)\n",
   "        if self.property.matches(value, old) and (hint is None):\n",
   "        was_set = self.name in obj._property_values\n",
   "        if was_set:\n",
   "            old_attr_value = obj._property_values[self.name]\n",
   "            old_attr_value = old\n",
   "        if old_attr_value is not value:\n",
   "            if isinstance(old_attr_value, PropertyValueContainer):\n",
   "                old_attr_value._unregister_owner(obj, self)\n",
   "            if isinstance(value, PropertyValueContainer):\n",
   "                value._register_owner(obj, self)\n",
   "            obj._property_values[self.name] = value\n",
   "        self._trigger(obj, old, value, hint=hint, setter=setter)\n",
   "        value = self.__get__(obj, obj.__class__)\n",
   "        value = self.property.prepare_value(obj, self.name, value)\n",
   "        self._real_set(obj, old, value, hint=hint)\n",
   "            obj.trigger(self.name, old, value, hint, setter)\n",
   "_CDS_SET_FROM_CDS_ERROR = \"\"\"\n",
   "        if isinstance(value, PropertyValueColumnData):\n",
   "            raise ValueError(_CDS_SET_FROM_CDS_ERROR)\n",
   "            hint = ColumnDataChangedEvent(obj.document, obj, setter=setter)\n",
   "            hint = None\n",
   "        self._internal_set(obj, value, hint=hint, setter=setter)\n",
   "            old = getattr(obj, self.name)\n",
   "            if old is not None:\n",
   "                    self.property._type.validate(old, False)\n",
   "                        json = json['value']\n",
   "                    if isinstance(old, str) and 'field' in json:\n",
   "                        json = json['field']\n",
   "        super().set_from_json(obj, json, models, setter)\n",
   "        super().__init__(name, property)\n",
   "        value = self._extract_units(obj, value)\n",
   "        super().__set__(obj, value, setter)\n",
   "        json = self._extract_units(obj, json)\n",
   "        super().set_from_json(obj, json, models, setter)\n",
   "        if isinstance(value, dict):\n",
   "            if 'units' in value:\n",
   "                value = copy(value) # so we can modify it\n",
   "            units = value.pop(\"units\", None)\n",
   "            if units:\n",
   "                self.units_prop.__set__(obj, units)\n",
   "        return value\n"
  ]
 },
 "279": {
  "name": "value",
  "type": "PropertyValueList",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/property/descriptors.py",
  "lineno": "867",
  "column": "8",
  "context": " could give us a new object for the value\n        value = self.property.prepare_value(obj, self.name, value)\n\n        self._real_set(obj, old, value, hint=hint",
  "context_lines": "        '''\n        value = self.__get__(obj, obj.__class__)\n\n        # re-validate because the contents of 'old' have changed,\n        # in some cases this could give us a new object for the value\n        value = self.property.prepare_value(obj, self.name, value)\n\n        self._real_set(obj, old, value, hint=hint)\n\n    def _trigger(self, obj, old, value, hint=None, setter=None):\n        ''' Unconditionally send a change event notification for the property.\n\n",
  "slicing": [
   "        name = self.name\n",
   "        if name in new_class_attrs:\n",
   "            raise RuntimeError(\"Two property generators both created %s.%s\" % (class_name, name))\n",
   "        new_class_attrs[name] = self\n",
   "            names_with_refs.add(name)\n",
   "                container_names.add(name)\n",
   "                dataspecs[name] = self\n",
   "        value = self.__get__(obj, obj.__class__)\n",
   "        return self.property.serialize_value(value)\n",
   "        super().__init__(name)\n",
   "        self._internal_set(obj, value, setter=setter)\n",
   "            old_value = obj._property_values[self.name]\n",
   "            self.trigger_if_changed(obj, old_value)\n",
   "        new_value = self.__get__(obj, obj.__class__)\n",
   "        if not self.property.matches(old, new_value):\n",
   "            self._trigger(obj, old, new_value)\n",
   "        is_themed = obj.themed_values() is not None and self.name in obj.themed_values()\n",
   "        default = self.instance_default(obj)\n",
   "        if is_themed:\n",
   "            unstable_dict = obj._unstable_themed_values\n",
   "            unstable_dict = obj._unstable_default_values\n",
   "        if self.name in unstable_dict:\n",
   "            return unstable_dict[self.name]\n",
   "            if isinstance(default, PropertyValueContainer):\n",
   "                default._register_owner(obj, self)\n",
   "            unstable_dict[self.name] = default\n",
   "        return default\n",
   "        value = self.property.prepare_value(obj, self.name, value)\n",
   "        old = self.__get__(obj, obj.__class__)\n",
   "        self._real_set(obj, old, value, hint=hint, setter=setter)\n",
   "        if self.property.matches(value, old) and (hint is None):\n",
   "        was_set = self.name in obj._property_values\n",
   "        if was_set:\n",
   "            old_attr_value = obj._property_values[self.name]\n",
   "            old_attr_value = old\n",
   "        if old_attr_value is not value:\n",
   "            if isinstance(old_attr_value, PropertyValueContainer):\n",
   "                old_attr_value._unregister_owner(obj, self)\n",
   "            if isinstance(value, PropertyValueContainer):\n",
   "                value._register_owner(obj, self)\n",
   "            obj._property_values[self.name] = value\n",
   "        self._trigger(obj, old, value, hint=hint, setter=setter)\n",
   "        value = self.__get__(obj, obj.__class__)\n",
   "        value = self.property.prepare_value(obj, self.name, value)\n",
   "        self._real_set(obj, old, value, hint=hint)\n",
   "            obj.trigger(self.name, old, value, hint, setter)\n",
   "_CDS_SET_FROM_CDS_ERROR = \"\"\"\n",
   "        if isinstance(value, PropertyValueColumnData):\n",
   "            raise ValueError(_CDS_SET_FROM_CDS_ERROR)\n",
   "            hint = ColumnDataChangedEvent(obj.document, obj, setter=setter)\n",
   "            hint = None\n",
   "        self._internal_set(obj, value, hint=hint, setter=setter)\n",
   "            old = getattr(obj, self.name)\n",
   "            if old is not None:\n",
   "                    self.property._type.validate(old, False)\n",
   "                        json = json['value']\n",
   "                    if isinstance(old, str) and 'field' in json:\n",
   "                        json = json['field']\n",
   "        super().set_from_json(obj, json, models, setter)\n",
   "        super().__init__(name, property)\n",
   "        value = self._extract_units(obj, value)\n",
   "        super().__set__(obj, value, setter)\n",
   "        json = self._extract_units(obj, json)\n",
   "        super().set_from_json(obj, json, models, setter)\n",
   "        if isinstance(value, dict):\n",
   "            if 'units' in value:\n",
   "                value = copy(value) # so we can modify it\n",
   "            units = value.pop(\"units\", None)\n",
   "            if units:\n",
   "                self.units_prop.__set__(obj, units)\n",
   "        return value\n"
  ]
 },
 "280": {
  "name": "msg",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/core/property/container.py",
  "lineno": "184",
  "column": "16",
  "context": " for key, val in value.items())):\n                msg = \"\" if not detail else \"expected an element of %s, got %r\" % (self, value)\n                raise ValueError(msg)\n\n    @classm",
  "context_lines": "        super().validate(value, detail)\n\n        if value is not None:\n            if not (isinstance(value, dict) and \\\n                    all(self.keys_type.is_valid(key) and self.values_type.is_valid(val) for key, val in value.items())):\n                msg = \"\" if not detail else \"expected an element of %s, got %r\" % (self, value)\n                raise ValueError(msg)\n\n    @classmethod\n    def wrap(cls, value):\n        ''' Some property types need to wrap their values in special containers, etc.\n\n",
  "slicing": [
   "            return self._new_instance([ self.item_type.from_json(item, models) for item in json ])\n",
   "            if not (self._is_seq(value) and all(self.item_type.is_valid(item) for item in value)):\n",
   "                    invalid = []\n",
   "                    for item in value:\n",
   "                        if not self.item_type.is_valid(item):\n",
   "                            invalid.append(item)\n",
   "                    msg = \"\" if not detail else \"expected an element of %s, got seq with invalid items %r\" % (self, invalid)\n",
   "                    raise ValueError(msg)\n",
   "                    msg = \"\" if not detail else \"expected an element of %s, got %r\" % (self, value)\n",
   "                    raise ValueError(msg)\n",
   "            return { self.keys_type.from_json(key, models): self.values_type.from_json(value, models) for key, value in json.items() }\n",
   "        super().validate(value, detail)\n",
   "        if value is not None:\n",
   "            if not (isinstance(value, dict) and \\\n",
   "                    all(self.keys_type.is_valid(key) and self.values_type.is_valid(val) for key, val in value.items())):\n",
   "                msg = \"\" if not detail else \"expected an element of %s, got %r\" % (self, value)\n",
   "                raise ValueError(msg)\n",
   "        if isinstance(value, dict):\n",
   "            if isinstance(value, PropertyValueDict):\n",
   "                return value\n",
   "                return PropertyValueDict(value)\n",
   "            return value\n",
   "        new_data = {}\n",
   "        for key, value in json.items():\n",
   "            key = self.keys_type.from_json(key, models)\n",
   "            if isinstance(value, dict) and '__ndarray__' in value:\n",
   "                new_data[key] = decode_base64_dict(value)\n",
   "            elif isinstance(value, list) and any(isinstance(el, dict) and '__ndarray__' in el for el in value):\n",
   "                new_list = []\n",
   "                for el in value:\n",
   "                    if isinstance(el, dict) and '__ndarray__' in el:\n",
   "                        el = decode_base64_dict(el)\n",
   "                    elif isinstance(el, list):\n",
   "                        el = self.values_type.from_json(el)\n",
   "                    new_list.append(el)\n",
   "                new_data[key] = new_list\n",
   "                new_data[key] = self.values_type.from_json(value, models)\n",
   "        return new_data\n",
   "        return transform_column_source_data(value)\n",
   "        if isinstance(value, dict):\n",
   "            if isinstance(value, PropertyValueColumnData):\n",
   "                return value\n",
   "                return PropertyValueColumnData(value)\n",
   "            return value\n",
   "            return tuple(type_param.from_json(item, models) for type_param, item in zip(self.type_params, json))\n",
   "        super().validate(value, detail)\n",
   "        if value is not None:\n",
   "            if not (isinstance(value, (tuple, list)) and len(self.type_params) == len(value) and \\\n",
   "                    all(type_param.is_valid(item) for type_param, item in zip(self.type_params, value))):\n",
   "                msg = \"\" if not detail else \"expected an element of %s, got %r\" % (self, value)\n",
   "                raise ValueError(msg)\n",
   "        if value is None:\n",
   "        return tuple(typ.transform(x) for (typ, x) in zip(self.type_params, value))\n",
   "        if value is None:\n",
   "        return tuple(typ.serialize_value(x) for (typ, x) in zip(self.type_params, value))\n",
   "        return self._sphinx_prop_link() + \"( %s )\" % \", \".join(x._sphinx_type() for x in self.type_params)\n"
  ]
 },
 "281": {
  "name": "get_login_url",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/server/views/session_handler.py",
  "lineno": "126",
  "column": "4",
  "context": "ich of the versions is intended to be called.\n    get_login_url = AuthMixin.get_login_url\n    get_current_user = AuthMixin.get_current_user\n",
  "context_lines": "        session = await self.application_context.create_session_if_needed(session_id, self.request, token)\n\n        return session\n\n    # NOTE: The methods below exist on both AuthMixin and RequestHandler. This\n    # makes it explicit which of the versions is intended to be called.\n    get_login_url = AuthMixin.get_login_url\n    get_current_user = AuthMixin.get_current_user\n    prepare = AuthMixin.prepare\n\n#-----------------------------------------------------------------------------\n# Private API\n",
  "slicing": [
   "log = logging.getLogger(__name__)\n",
   "        token = self.get_argument(\"bokeh-token\", default=None)\n",
   "        session_id = self.get_argument(\"bokeh-session-id\", default=None)\n",
   "            if session_id is not None:\n",
   "                log.debug(\"Server received session ID in request argument and header, expected only one\")\n",
   "            session_id = self.request.headers.get('Bokeh-Session-Id')\n",
   "        if token is not None:\n",
   "            if session_id is not None:\n",
   "                log.debug(\"Server received both token and session ID, expected only one\")\n",
   "            session_id = get_session_id(token)\n",
   "        elif session_id is None:\n",
   "                session_id = generate_session_id(secret_key=self.application.secret_key,\n",
   "                log.debug(\"Server configured not to generate session IDs and none was provided\")\n",
   "        if token is None:\n",
   "                excluded_headers = (self.application.exclude_headers or [])\n",
   "                allowed_headers = [header for header in self.request.headers\n",
   "                                   if header not in excluded_headers]\n",
   "                allowed_headers = self.application.include_headers\n",
   "            headers = {k: v for k, v in self.request.headers.items()\n",
   "                       if k in allowed_headers}\n",
   "                excluded_cookies = (self.application.exclude_cookies or [])\n",
   "                allowed_cookies = [cookie for cookie in self.request.cookies\n",
   "                                   if cookie not in excluded_cookies]\n",
   "                allowed_cookies = self.application.include_cookies\n",
   "            cookies = {k: v.value for k, v in self.request.cookies.items()\n",
   "                       if k in allowed_cookies}\n",
   "            payload = {'headers': headers, 'cookies': cookies}\n",
   "            payload.update(self.application_context.application.process_request(self.request))\n",
   "            token = generate_jwt_token(session_id,\n",
   "                                       extra_payload=payload)\n",
   "        if not check_token_signature(token,\n",
   "            log.error(\"Session id had invalid signature: %r\", session_id)\n",
   "        session = await self.application_context.create_session_if_needed(session_id, self.request, token)\n",
   "        return session\n",
   "    get_login_url = AuthMixin.get_login_url\n"
  ]
 },
 "282": {
  "name": "get_current_user",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/server/views/session_handler.py",
  "lineno": "127",
  "column": "4",
  "context": ".\n    get_login_url = AuthMixin.get_login_url\n    get_current_user = AuthMixin.get_current_user\n    prepare = AuthMixin.prepare\n\n#----------------",
  "context_lines": "        return session\n\n    # NOTE: The methods below exist on both AuthMixin and RequestHandler. This\n    # makes it explicit which of the versions is intended to be called.\n    get_login_url = AuthMixin.get_login_url\n    get_current_user = AuthMixin.get_current_user\n    prepare = AuthMixin.prepare\n\n#-----------------------------------------------------------------------------\n# Private API\n#-----------------------------------------------------------------------------\n\n",
  "slicing": [
   "log = logging.getLogger(__name__)\n",
   "        token = self.get_argument(\"bokeh-token\", default=None)\n",
   "        session_id = self.get_argument(\"bokeh-session-id\", default=None)\n",
   "            if session_id is not None:\n",
   "                log.debug(\"Server received session ID in request argument and header, expected only one\")\n",
   "            session_id = self.request.headers.get('Bokeh-Session-Id')\n",
   "        if token is not None:\n",
   "            if session_id is not None:\n",
   "                log.debug(\"Server received both token and session ID, expected only one\")\n",
   "            session_id = get_session_id(token)\n",
   "        elif session_id is None:\n",
   "                session_id = generate_session_id(secret_key=self.application.secret_key,\n",
   "                log.debug(\"Server configured not to generate session IDs and none was provided\")\n",
   "        if token is None:\n",
   "                excluded_headers = (self.application.exclude_headers or [])\n",
   "                allowed_headers = [header for header in self.request.headers\n",
   "                                   if header not in excluded_headers]\n",
   "                allowed_headers = self.application.include_headers\n",
   "            headers = {k: v for k, v in self.request.headers.items()\n",
   "                       if k in allowed_headers}\n",
   "                excluded_cookies = (self.application.exclude_cookies or [])\n",
   "                allowed_cookies = [cookie for cookie in self.request.cookies\n",
   "                                   if cookie not in excluded_cookies]\n",
   "                allowed_cookies = self.application.include_cookies\n",
   "            cookies = {k: v.value for k, v in self.request.cookies.items()\n",
   "                       if k in allowed_cookies}\n",
   "            payload = {'headers': headers, 'cookies': cookies}\n",
   "            payload.update(self.application_context.application.process_request(self.request))\n",
   "            token = generate_jwt_token(session_id,\n",
   "                                       extra_payload=payload)\n",
   "        if not check_token_signature(token,\n",
   "            log.error(\"Session id had invalid signature: %r\", session_id)\n",
   "        session = await self.application_context.create_session_if_needed(session_id, self.request, token)\n",
   "        return session\n",
   "    get_current_user = AuthMixin.get_current_user\n"
  ]
 },
 "283": {
  "name": "prepare",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/server/views/session_handler.py",
  "lineno": "128",
  "column": "4",
  "context": "get_current_user = AuthMixin.get_current_user\n    prepare = AuthMixin.prepare\n\n#------------------------------------------------",
  "context_lines": "    # NOTE: The methods below exist on both AuthMixin and RequestHandler. This\n    # makes it explicit which of the versions is intended to be called.\n    get_login_url = AuthMixin.get_login_url\n    get_current_user = AuthMixin.get_current_user\n    prepare = AuthMixin.prepare\n\n#-----------------------------------------------------------------------------\n# Private API\n#-----------------------------------------------------------------------------\n\n",
  "slicing": [
   "log = logging.getLogger(__name__)\n",
   "        token = self.get_argument(\"bokeh-token\", default=None)\n",
   "        session_id = self.get_argument(\"bokeh-session-id\", default=None)\n",
   "            if session_id is not None:\n",
   "                log.debug(\"Server received session ID in request argument and header, expected only one\")\n",
   "            session_id = self.request.headers.get('Bokeh-Session-Id')\n",
   "        if token is not None:\n",
   "            if session_id is not None:\n",
   "                log.debug(\"Server received both token and session ID, expected only one\")\n",
   "            session_id = get_session_id(token)\n",
   "        elif session_id is None:\n",
   "                session_id = generate_session_id(secret_key=self.application.secret_key,\n",
   "                log.debug(\"Server configured not to generate session IDs and none was provided\")\n",
   "        if token is None:\n",
   "                excluded_headers = (self.application.exclude_headers or [])\n",
   "                allowed_headers = [header for header in self.request.headers\n",
   "                                   if header not in excluded_headers]\n",
   "                allowed_headers = self.application.include_headers\n",
   "            headers = {k: v for k, v in self.request.headers.items()\n",
   "                       if k in allowed_headers}\n",
   "                excluded_cookies = (self.application.exclude_cookies or [])\n",
   "                allowed_cookies = [cookie for cookie in self.request.cookies\n",
   "                                   if cookie not in excluded_cookies]\n",
   "                allowed_cookies = self.application.include_cookies\n",
   "            cookies = {k: v.value for k, v in self.request.cookies.items()\n",
   "                       if k in allowed_cookies}\n",
   "            payload = {'headers': headers, 'cookies': cookies}\n",
   "            payload.update(self.application_context.application.process_request(self.request))\n",
   "            token = generate_jwt_token(session_id,\n",
   "                                       extra_payload=payload)\n",
   "        if not check_token_signature(token,\n",
   "            log.error(\"Session id had invalid signature: %r\", session_id)\n",
   "        session = await self.application_context.create_session_if_needed(session_id, self.request, token)\n",
   "        return session\n",
   "    prepare = AuthMixin.prepare\n"
  ]
 },
 "284": {
  "name": "get_login_url",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/server/views/root_handler.py",
  "lineno": "68",
  "column": "4",
  "context": "ich of the versions is intended to be called.\n    get_login_url = AuthMixin.get_login_url\n    get_current_user = AuthMixin.get_current_user\n",
  "context_lines": "            index = \"app_index.html\" if self.index is None else self.index\n            self.render(index, prefix=prefix, items=sorted(self.applications.keys()))\n\n    # NOTE: The methods below exist on both AuthMixin and RequestHandler. This\n    # makes it explicit which of the versions is intended to be called.\n    get_login_url = AuthMixin.get_login_url\n    get_current_user = AuthMixin.get_current_user\n    prepare = AuthMixin.prepare\n\n#-----------------------------------------------------------------------------\n# Private API\n",
  "slicing": [
   "        prefix = \"\" if self.prefix is None else self.prefix\n",
   "            app_names = list(self.applications.keys())\n",
   "            redirect_to = prefix + app_names[0]\n",
   "            self.redirect(redirect_to)\n",
   "            index = \"app_index.html\" if self.index is None else self.index\n",
   "            self.render(index, prefix=prefix, items=sorted(self.applications.keys()))\n",
   "    get_login_url = AuthMixin.get_login_url\n"
  ]
 },
 "285": {
  "name": "get_current_user",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/server/views/root_handler.py",
  "lineno": "69",
  "column": "4",
  "context": ".\n    get_login_url = AuthMixin.get_login_url\n    get_current_user = AuthMixin.get_current_user\n    prepare = AuthMixin.prepare\n\n#----------------",
  "context_lines": "            self.render(index, prefix=prefix, items=sorted(self.applications.keys()))\n\n    # NOTE: The methods below exist on both AuthMixin and RequestHandler. This\n    # makes it explicit which of the versions is intended to be called.\n    get_login_url = AuthMixin.get_login_url\n    get_current_user = AuthMixin.get_current_user\n    prepare = AuthMixin.prepare\n\n#-----------------------------------------------------------------------------\n# Private API\n#-----------------------------------------------------------------------------\n\n",
  "slicing": [
   "        prefix = \"\" if self.prefix is None else self.prefix\n",
   "            app_names = list(self.applications.keys())\n",
   "            redirect_to = prefix + app_names[0]\n",
   "            self.redirect(redirect_to)\n",
   "            index = \"app_index.html\" if self.index is None else self.index\n",
   "            self.render(index, prefix=prefix, items=sorted(self.applications.keys()))\n",
   "    get_current_user = AuthMixin.get_current_user\n"
  ]
 },
 "286": {
  "name": "prepare",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/server/views/root_handler.py",
  "lineno": "70",
  "column": "4",
  "context": "get_current_user = AuthMixin.get_current_user\n    prepare = AuthMixin.prepare\n\n#------------------------------------------------",
  "context_lines": "    # NOTE: The methods below exist on both AuthMixin and RequestHandler. This\n    # makes it explicit which of the versions is intended to be called.\n    get_login_url = AuthMixin.get_login_url\n    get_current_user = AuthMixin.get_current_user\n    prepare = AuthMixin.prepare\n\n#-----------------------------------------------------------------------------\n# Private API\n#-----------------------------------------------------------------------------\n\n",
  "slicing": [
   "        prefix = \"\" if self.prefix is None else self.prefix\n",
   "            app_names = list(self.applications.keys())\n",
   "            redirect_to = prefix + app_names[0]\n",
   "            self.redirect(redirect_to)\n",
   "            index = \"app_index.html\" if self.index is None else self.index\n",
   "            self.render(index, prefix=prefix, items=sorted(self.applications.keys()))\n",
   "    prepare = AuthMixin.prepare\n"
  ]
 },
 "287": {
  "name": "reprotocoled",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/client/util.py",
  "lineno": "83",
  "column": "8",
  "context": "\n\n    '''\n    if url.startswith(\"http:\"):\n        reprotocoled = \"ws\" + url[4:]\n    elif url.startswith(\"https:\"):\n        reproto",
  "context_lines": "        ValueError:\n            If the input URL is not of the proper form.\n\n    '''\n    if url.startswith(\"http:\"):\n        reprotocoled = \"ws\" + url[4:]\n    elif url.startswith(\"https:\"):\n        reprotocoled = \"wss\" + url[5:]\n    else:\n        raise ValueError(\"URL has unknown protocol \" + url)\n",
  "slicing": [
   "        reprotocoled = \"http\" + url[2:]\n",
   "        reprotocoled = \"https\" + url[3:]\n",
   "    if not reprotocoled.endswith(\"/ws\"):\n",
   "    return reprotocoled[:-2]\n",
   "        reprotocoled = \"ws\" + url[4:]\n",
   "    if reprotocoled.endswith(\"/\"):\n",
   "        return reprotocoled + \"ws\"\n",
   "        return reprotocoled + \"/ws\"\n"
  ]
 },
 "288": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/glyphs.py",
  "lineno": "142",
  "column": "4",
  "context": "ph):\n    ''' Render annular wedges.\n\n    '''\n\n    __example__ = \"examples/reference/models/AnnularWedge.py\"\n\n    # a canonical order for positional args that ",
  "context_lines": "#-----------------------------------------------------------------------------\n\nclass AnnularWedge(XYGlyph, LineGlyph, FillGlyph):\n    ''' Render annular wedges.\n\n    '''\n\n    __example__ = \"examples/reference/models/AnnularWedge.py\"\n\n    # a canonical order for positional args that can be used for any\n    # functions derived from this class\n    _args = ('x', 'y', 'inner_radius', 'outer_radius', 'start_angle', 'end_angle', 'direction')\n\n",
  "slicing": "    __example__ = \"examples/reference/models/AnnularWedge.py\"\n"
 },
 "289": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/glyphs.py",
  "lineno": "189",
  "column": "4",
  "context": " FillGlyph):\n    ''' Render annuli.\n\n    '''\n\n    __example__ = \"examples/reference/models/Annulus.py\"\n\n    # a canonical order for positional args that ",
  "context_lines": "    \"\"\")\n\nclass Annulus(XYGlyph, LineGlyph, FillGlyph):\n    ''' Render annuli.\n\n    '''\n\n    __example__ = \"examples/reference/models/Annulus.py\"\n\n    # a canonical order for positional args that can be used for any\n    # functions derived from this class\n    _args = ('x', 'y', 'inner_radius', 'outer_radius')\n\n",
  "slicing": "    __example__ = \"examples/reference/models/Annulus.py\"\n"
 },
 "290": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/glyphs.py",
  "lineno": "224",
  "column": "4",
  "context": "h, LineGlyph):\n    ''' Render arcs.\n\n    '''\n\n    __example__ = \"examples/reference/models/Arc.py\"\n\n    # a canonical order for positional args that ",
  "context_lines": "    \"\"\")\n\nclass Arc(XYGlyph, LineGlyph):\n    ''' Render arcs.\n\n    '''\n\n    __example__ = \"examples/reference/models/Arc.py\"\n\n    # a canonical order for positional args that can be used for any\n    # functions derived from this class\n    _args = ('x', 'y', 'radius', 'start_angle', 'end_angle', 'direction')\n\n",
  "slicing": "    __example__ = \"examples/reference/models/Arc.py\"\n"
 },
 "291": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/glyphs.py",
  "lineno": "267",
  "column": "4",
  "context": "/en.wikipedia.org/wiki/Bezier_curve\n\n    '''\n\n    __example__ = \"examples/reference/models/Bezier.py\"\n\n    # a canonical order for positional args that ",
  "context_lines": "    ''' Render Bezier curves.\n\n    For more information consult the `Wikipedia article for Bezier curve`_.\n\n    .. _Wikipedia article for Bezier curve: http://en.wikipedia.org/wiki/Bezier_curve\n\n    '''\n\n    __example__ = \"examples/reference/models/Bezier.py\"\n\n    # a canonical order for positional args that can be used for any\n    # functions derived from this class\n    _args = (\"x0\", \"y0\", \"x1\", \"y1\", \"cx0\", \"cy0\", \"cx1\", \"cy1\")\n\n",
  "slicing": "    __example__ = \"examples/reference/models/Bezier.py\"\n"
 },
 "292": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/glyphs.py",
  "lineno": "314",
  "column": "4",
  "context": "illGlyph):\n    ''' Render ellipses.\n\n    '''\n\n    __example__ = \"examples/reference/models/Ellipse.py\"\n\n    # a canonical order for positional args that ",
  "context_lines": "    \"\"\")\n\nclass Ellipse(XYGlyph, LineGlyph, FillGlyph):\n    ''' Render ellipses.\n\n    '''\n\n    __example__ = \"examples/reference/models/Ellipse.py\"\n\n    # a canonical order for positional args that can be used for any\n    # functions derived from this class\n    _args = ('x', 'y', 'width', 'height', 'angle')\n\n",
  "slicing": "    __example__ = \"examples/reference/models/Ellipse.py\"\n"
 },
 "293": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/glyphs.py",
  "lineno": "354",
  "column": "4",
  "context": "inates with the same y-coordinates.\n\n    '''\n\n    __example__ = \"examples/reference/models/HArea.py\"\n\n    # a canonical order for positional args that ",
  "context_lines": "class HArea(FillGlyph, HatchGlyph, LineGlyph):\n    ''' Render a horizontally directed area between two equal length sequences\n    of x-coordinates with the same y-coordinates.\n\n    '''\n\n    __example__ = \"examples/reference/models/HArea.py\"\n\n    # a canonical order for positional args that can be used for any\n    # functions derived from this class\n    _args = ('x1', 'x2', 'y')\n\n",
  "slicing": "    __example__ = \"examples/reference/models/HArea.py\"\n"
 },
 "294": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/glyphs.py",
  "lineno": "386",
  "column": "4",
  "context": " (``left``, ``right``) coordinates.\n\n    '''\n\n    __example__ = \"examples/reference/models/HBar.py\"\n\n    # a canonical order for positional args that ",
  "context_lines": "class HBar(LineGlyph, FillGlyph, HatchGlyph):\n    ''' Render horizontal bars, given a center coordinate, ``height`` and\n    (``left``, ``right``) coordinates.\n\n    '''\n\n    __example__ = \"examples/reference/models/HBar.py\"\n\n    # a canonical order for positional args that can be used for any\n    # functions derived from this class\n    _args = ('y', 'height', 'right', 'left')\n\n",
  "slicing": "    __example__ = \"examples/reference/models/HBar.py\"\n"
 },
 "295": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/glyphs.py",
  "lineno": "425",
  "column": "4",
  "context": " tiles on a regular hexagonal grid.\n\n    '''\n\n    __example__ = \"examples/reference/models/HexTile.py\"\n\n    # a canonical order for positional args that ",
  "context_lines": "    \"\"\")\n\nclass HexTile(LineGlyph, FillGlyph):\n    ''' Render horizontal tiles on a regular hexagonal grid.\n\n    '''\n\n    __example__ = \"examples/reference/models/HexTile.py\"\n\n    # a canonical order for positional args that can be used for any\n    # functions derived from this class\n    _args = ('q', 'r')\n\n",
  "slicing": "    __example__ = \"examples/reference/models/HexTile.py\"\n"
 },
 "296": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/glyphs.py",
  "lineno": "621",
  "column": "4",
  "context": "nder images loaded from given URLs.\n\n    '''\n\n    __example__ = \"examples/reference/models/ImageURL.py\"\n\n    # a canonical order for positional args that ",
  "context_lines": "    # ref: https://github.com/bokeh/bokeh/issues/1763\n\nclass ImageURL(XYGlyph):\n    ''' Render images loaded from given URLs.\n\n    '''\n\n    __example__ = \"examples/reference/models/ImageURL.py\"\n\n    # a canonical order for positional args that can be used for any\n    # functions derived from this class\n    _args = ('url', 'x', 'y', 'w', 'h', 'angle', 'dilate')\n\n",
  "slicing": "    __example__ = \"examples/reference/models/ImageURL.py\"\n"
 },
 "297": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/glyphs.py",
  "lineno": "700",
  "column": "4",
  "context": "rived from this class\n    _args = ('x', 'y')\n\n    __example__ = \"examples/reference/models/Line.py\"\n\n    x = NumberSpec(default=field(\"x\"), help=\"\"\"\n ",
  "context_lines": "    '''\n    # a canonical order for positional args that can be used for any\n    # functions derived from this class\n    _args = ('x', 'y')\n\n    __example__ = \"examples/reference/models/Line.py\"\n\n    x = NumberSpec(default=field(\"x\"), help=\"\"\"\n    The x-coordinates for the points of the line.\n    \"\"\")\n\n",
  "slicing": "    __example__ = \"examples/reference/models/Line.py\"\n"
 },
 "298": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/glyphs.py",
  "lineno": "722",
  "column": "4",
  "context": "s. Rather, it is a \"list of lists\".\n\n    '''\n\n    __example__ = \"examples/reference/models/MultiLine.py\"\n\n    # a canonical order for positional args that ",
  "context_lines": "    ''' Render several lines.\n\n    The data for the ``MultiLine`` glyph is different in that the vector of\n    values is not a vector of scalars. Rather, it is a \"list of lists\".\n\n    '''\n\n    __example__ = \"examples/reference/models/MultiLine.py\"\n\n    # a canonical order for positional args that can be used for any\n    # functions derived from this class\n    _args = ('xs', 'ys')\n\n",
  "slicing": "    __example__ = \"examples/reference/models/MultiLine.py\"\n"
 },
 "299": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/glyphs.py",
  "lineno": "752",
  "column": "4",
  "context": "    selection box will be included.\n\n    '''\n\n    __example__ = \"examples/reference/models/MultiPolygons.py\"\n\n    # a canonical order for positional args that ",
  "context_lines": "    Rather, it is a \"list of lists of lists of lists\".\n\n    During box selection only multi-polygons entirely contained in the\n    selection box will be included.\n\n    '''\n\n    __example__ = \"examples/reference/models/MultiPolygons.py\"\n\n    # a canonical order for positional args that can be used for any\n    # functions derived from this class\n    _args = ('xs', 'ys')\n\n",
  "slicing": "    __example__ = \"examples/reference/models/MultiPolygons.py\"\n"
 },
 "300": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/glyphs.py",
  "lineno": "801",
  "column": "4",
  "context": "instead\")\n        super().__init__(**kwargs)\n\n    __example__ = \"examples/reference/models/Oval.py\"\n\n    # a canonical order for positional args that ",
  "context_lines": "    '''\n\n    def __init__(self, **kwargs):\n        deprecated(\"'Oval' is deprecated and will be removed in Bokeh 3.0, use the Ellipse glyph instead\")\n        super().__init__(**kwargs)\n\n    __example__ = \"examples/reference/models/Oval.py\"\n\n    # a canonical order for positional args that can be used for any\n    # functions derived from this class\n    _args = ('x', 'y', 'width', 'height', 'angle')\n\n",
  "slicing": "    __example__ = \"examples/reference/models/Oval.py\"\n"
 },
 "301": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/glyphs.py",
  "lineno": "843",
  "column": "4",
  "context": "nly produces one glyph on the Plot.\n\n    '''\n\n    __example__ = \"examples/reference/models/Patch.py\"\n\n    # a canonical order for positional args that ",
  "context_lines": "    ''' Render a single patch.\n\n    The ``Patch`` glyph is different from most other glyphs in that the vector\n    of values only produces one glyph on the Plot.\n\n    '''\n\n    __example__ = \"examples/reference/models/Patch.py\"\n\n    # a canonical order for positional args that can be used for any\n    # functions derived from this class\n    _args = ('x', 'y')\n\n",
  "slicing": "    __example__ = \"examples/reference/models/Patch.py\"\n"
 },
 "302": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/glyphs.py",
  "lineno": "890",
  "column": "4",
  "context": "    selection box will be included.\n\n    '''\n\n    __example__ = \"examples/reference/models/Patches.py\"\n\n    # a canonical order for positional args that ",
  "context_lines": "    values is not a vector of scalars. Rather, it is a \"list of lists\".\n\n    During box selection only patches entirely contained in the\n    selection box will be included.\n\n    '''\n\n    __example__ = \"examples/reference/models/Patches.py\"\n\n    # a canonical order for positional args that can be used for any\n    # functions derived from this class\n    _args = ('xs', 'ys')\n\n",
  "slicing": "    __example__ = \"examples/reference/models/Patches.py\"\n"
 },
 "303": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/glyphs.py",
  "lineno": "931",
  "column": "4",
  "context": "\n    ''' Render axis-aligned quads.\n\n    '''\n\n    __example__ = \"examples/reference/models/Quad.py\"\n\n    # a canonical order for positional args that ",
  "context_lines": "    \"\"\")\n\nclass Quad(LineGlyph, FillGlyph, HatchGlyph):\n    ''' Render axis-aligned quads.\n\n    '''\n\n    __example__ = \"examples/reference/models/Quad.py\"\n\n    # a canonical order for positional args that can be used for any\n    # functions derived from this class\n    _args = ('left', 'right', 'top', 'bottom')\n\n",
  "slicing": "    __example__ = \"examples/reference/models/Quad.py\"\n"
 },
 "304": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/glyphs.py",
  "lineno": "970",
  "column": "4",
  "context": "neGlyph):\n    ''' Render parabolas.\n\n    '''\n\n    __example__ = \"examples/reference/models/Quadratic.py\"\n\n    # a canonical order for positional args that ",
  "context_lines": "    \"\"\")\n\nclass Quadratic(LineGlyph):\n    ''' Render parabolas.\n\n    '''\n\n    __example__ = \"examples/reference/models/Quadratic.py\"\n\n    # a canonical order for positional args that can be used for any\n    # functions derived from this class\n    _args = (\"x0\", \"y0\", \"x1\", \"y1\", \"cx\", \"cy\")\n\n",
  "slicing": "    __example__ = \"examples/reference/models/Quadratic.py\"\n"
 },
 "305": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/glyphs.py",
  "lineno": "1009",
  "column": "4",
  "context": "h, LineGlyph):\n    ''' Render rays.\n\n    '''\n\n    __example__ = \"examples/reference/models/Ray.py\"\n\n    # a canonical order for positional args that ",
  "context_lines": "    \"\"\")\n\nclass Ray(XYGlyph, LineGlyph):\n    ''' Render rays.\n\n    '''\n\n    __example__ = \"examples/reference/models/Ray.py\"\n\n    # a canonical order for positional args that can be used for any\n    # functions derived from this class\n    _args = ('x', 'y', 'length', 'angle')\n\n",
  "slicing": "    __example__ = \"examples/reference/models/Ray.py\"\n"
 },
 "306": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/glyphs.py",
  "lineno": "1041",
  "column": "4",
  "context": "lGlyph):\n    ''' Render rectangles.\n\n    '''\n\n    __example__ = \"examples/reference/models/Rect.py\"\n\n    # a canonical order for positional args that ",
  "context_lines": "    \"\"\")\n\nclass Rect(XYGlyph, LineGlyph, FillGlyph):\n    ''' Render rectangles.\n\n    '''\n\n    __example__ = \"examples/reference/models/Rect.py\"\n\n    # a canonical order for positional args that can be used for any\n    # functions derived from this class\n    _args = ('x', 'y', 'width', 'height', 'angle', 'dilate')\n\n",
  "slicing": "    __example__ = \"examples/reference/models/Rect.py\"\n"
 },
 "307": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/glyphs.py",
  "lineno": "1089",
  "column": "4",
  "context": "ineGlyph):\n    ''' Render segments.\n\n    '''\n\n    __example__ = \"examples/reference/models/Segment.py\"\n\n    # a canonical order for positional args that ",
  "context_lines": "    \"\"\")\n\nclass Segment(LineGlyph):\n    ''' Render segments.\n\n    '''\n\n    __example__ = \"examples/reference/models/Segment.py\"\n\n    # a canonical order for positional args that can be used for any\n    # functions derived from this class\n    _args = ('x0', 'y0', 'x1', 'y1')\n\n",
  "slicing": "    __example__ = \"examples/reference/models/Segment.py\"\n"
 },
 "308": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/glyphs.py",
  "lineno": "1126",
  "column": "4",
  "context": " for steps to be properly rendered.\n\n    '''\n\n    __example__ = \"examples/reference/models/Step.py\"\n\n    # a canonical order for positional args that ",
  "context_lines": "    to the value of the ``mode`` property.\n\n    The x-coordinates are assumed to be (and must be) sorted in ascending order\n    for steps to be properly rendered.\n\n    '''\n\n    __example__ = \"examples/reference/models/Step.py\"\n\n    # a canonical order for positional args that can be used for any\n    # functions derived from this class\n    _args = ('x', 'y')\n\n",
  "slicing": "    __example__ = \"examples/reference/models/Step.py\"\n"
 },
 "309": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/glyphs.py",
  "lineno": "1158",
  "column": "4",
  "context": "h, TextGlyph):\n    ''' Render text.\n\n    '''\n\n    __example__ = \"examples/reference/models/Text.py\"\n\n    # a canonical order for positional args that ",
  "context_lines": "    \"\"\")\n\nclass Text(XYGlyph, TextGlyph):\n    ''' Render text.\n\n    '''\n\n    __example__ = \"examples/reference/models/Text.py\"\n\n    # a canonical order for positional args that can be used for any\n    # functions derived from this class\n    _args = ('x', 'y', 'text', 'angle', 'x_offset', 'y_offset')\n\n",
  "slicing": "    __example__ = \"examples/reference/models/Text.py\"\n"
 },
 "310": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/glyphs.py",
  "lineno": "1204",
  "column": "4",
  "context": "inates with the same x-coordinates.\n\n    '''\n\n    __example__ = \"examples/reference/models/VArea.py\"\n\n    # a canonical order for positional args that ",
  "context_lines": "class VArea(FillGlyph, HatchGlyph):\n    ''' Render a vertically directed area between two equal length sequences\n    of y-coordinates with the same x-coordinates.\n\n    '''\n\n    __example__ = \"examples/reference/models/VArea.py\"\n\n    # a canonical order for positional args that can be used for any\n    # functions derived from this class\n    _args = ('x', 'y1', 'y2')\n\n",
  "slicing": "    __example__ = \"examples/reference/models/VArea.py\"\n"
 },
 "311": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/glyphs.py",
  "lineno": "1235",
  "column": "4",
  "context": "idth and (top, bottom) coordinates.\n\n    '''\n\n    __example__ = \"examples/reference/models/VBar.py\"\n\n    # a canonical order for positional args that ",
  "context_lines": "    \"\"\")\n\nclass VBar(LineGlyph, FillGlyph, HatchGlyph):\n    ''' Render vertical bars, given a center coordinate, width and (top, bottom) coordinates.\n\n    '''\n\n    __example__ = \"examples/reference/models/VBar.py\"\n\n    # a canonical order for positional args that can be used for any\n    # functions derived from this class\n    _args = ('x', 'width', 'top', 'bottom')\n\n",
  "slicing": "    __example__ = \"examples/reference/models/VBar.py\"\n"
 },
 "312": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/glyphs.py",
  "lineno": "1274",
  "column": "4",
  "context": " FillGlyph):\n    ''' Render wedges.\n\n    '''\n\n    __example__ = \"examples/reference/models/Wedge.py\"\n\n    # a canonical order for positional args that ",
  "context_lines": "    \"\"\")\n\nclass Wedge(XYGlyph, LineGlyph, FillGlyph):\n    ''' Render wedges.\n\n    '''\n\n    __example__ = \"examples/reference/models/Wedge.py\"\n\n    # a canonical order for positional args that can be used for any\n    # functions derived from this class\n    _args = ('x', 'y', 'radius', 'start_angle', 'end_angle', 'direction')\n\n",
  "slicing": "    __example__ = \"examples/reference/models/Wedge.py\"\n"
 },
 "313": {
  "name": "constructor",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/tools.py",
  "lineno": "154",
  "column": "8",
  "context": "urns a corresponding `Tool` instance. \"\"\"\n        constructor = cls._known_aliases.get(name)\n        if constructor is not None:\n            re",
  "context_lines": "    _known_aliases: tp.ClassVar[tp.Dict[str, tp.Callable[[], \"Tool\"]]] = {}\n\n    @classmethod\n    def from_string(cls, name: str) -> \"Tool\":\n        \"\"\" Takes a string and returns a corresponding `Tool` instance. \"\"\"\n        constructor = cls._known_aliases.get(name)\n        if constructor is not None:\n            return constructor()\n        else:\n            known_names = cls._known_aliases.keys()\n",
  "slicing": [
   "        constructor = cls._known_aliases.get(name)\n",
   "        if constructor is not None:\n",
   "            return constructor()\n",
   "        cls._known_aliases[name] = constructor\n"
  ]
 },
 "314": {
  "name": "DEFAULT_BOX_OVERLAY",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/tools.py",
  "lineno": "618",
  "column": "0",
  "context": "en 0 (transparent)\n    and 1 (opaque).\n\n    \"\"\")\n\nDEFAULT_BOX_OVERLAY = lambda: BoxAnnotation(\n    level=\"overlay\",\n    top_units=\"screen\",\n    l",
  "context_lines": "    An alpha value to use to stroke paths with.\n\n    Acceptable values are floating point numbers between 0 (transparent)\n    and 1 (opaque).\n\n    \"\"\")\n\nDEFAULT_BOX_OVERLAY = lambda: BoxAnnotation(\n    level=\"overlay\",\n    top_units=\"screen\",\n    left_units=\"screen\",\n    bottom_units=\"screen\",\n",
  "slicing": [
   "        constructor = cls._known_aliases.get(name)\n",
   "        if constructor is not None:\n",
   "            return constructor()\n",
   "            known_names = cls._known_aliases.keys()\n",
   "            matches, text = difflib.get_close_matches(name.lower(), known_names), \"similar\"\n",
   "            if not matches:\n",
   "                matches, text = known_names, \"possible\"\n",
   "            raise ValueError(f\"unexpected tool name '{name}', {text} tools are {nice_join(matches)}\")\n",
   "        cls._known_aliases[name] = constructor\n",
   "DEFAULT_RANGE_OVERLAY = lambda: BoxAnnotation(\n",
   "    overlay = Instance(BoxAnnotation, default=DEFAULT_RANGE_OVERLAY, help=\"\"\"\n",
   "DEFAULT_BOX_OVERLAY = lambda: BoxAnnotation(\n",
   "    overlay = Instance(BoxAnnotation, default=DEFAULT_BOX_OVERLAY, help=\"\"\"\n",
   "    overlay = Instance(BoxAnnotation, default=DEFAULT_BOX_OVERLAY, help=\"\"\"\n"
  ]
 },
 "315": {
  "name": "tooltips",
  "type": "Either",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/tools.py",
  "lineno": "1029",
  "column": "4",
  "context": "the coordinates of the hover cursor\n    \"\"\")\n\n    tooltips = Either(String, List(Tuple(String, String)),\n            default=[\n                (\"index\",\"$i",
  "context_lines": "    ``HoverTool`` specific fields:\n\n    :index: object containing the indices of the hovered points in the data source\n    :geometry: object containing the coordinates of the hover cursor\n    \"\"\")\n\n    tooltips = Either(String, List(Tuple(String, String)),\n            default=[\n                (\"index\",\"$index\"),\n                (\"data (x, y)\",\"($x, $y)\"),\n                (\"screen (x, y)\",\"($sx, $sy)\"),\n",
  "slicing": [
   "        constructor = cls._known_aliases.get(name)\n",
   "        if constructor is not None:\n",
   "            return constructor()\n",
   "            known_names = cls._known_aliases.keys()\n",
   "            matches, text = difflib.get_close_matches(name.lower(), known_names), \"similar\"\n",
   "            if not matches:\n",
   "                matches, text = known_names, \"possible\"\n",
   "            raise ValueError(f\"unexpected tool name '{name}', {text} tools are {nice_join(matches)}\")\n",
   "        cls._known_aliases[name] = constructor\n",
   "DEFAULT_RANGE_OVERLAY = lambda: BoxAnnotation(\n",
   "    overlay = Instance(BoxAnnotation, default=DEFAULT_RANGE_OVERLAY, help=\"\"\"\n",
   "DEFAULT_BOX_OVERLAY = lambda: BoxAnnotation(\n",
   "    overlay = Instance(BoxAnnotation, default=DEFAULT_BOX_OVERLAY, help=\"\"\"\n",
   "    overlay = Instance(BoxAnnotation, default=DEFAULT_BOX_OVERLAY, help=\"\"\"\n",
   "DEFAULT_POLY_OVERLAY = lambda: PolyAnnotation(\n",
   "    overlay = Instance(PolyAnnotation, default=DEFAULT_POLY_OVERLAY, help=\"\"\"\n",
   "    overlay = Instance(PolyAnnotation, default=DEFAULT_POLY_OVERLAY, help=\"\"\"\n",
   "    tooltips = Either(String, List(Tuple(String, String)),\n"
  ]
 },
 "316": {
  "name": "data",
  "type": "ColumnData",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/sources.py",
  "lineno": "161",
  "column": "4",
  "context": "    of a data source \"all at once\".\n\n    '''\n\n    data = ColumnData(String, Seq(Any), help=\"\"\"\n    Mapping of column names to sequences of data. ",
  "context_lines": "        ``ColumnDataSource`` all have the same length at all times. For this\n        reason, it is usually preferable to update the ``.data`` property\n        of a data source \"all at once\".\n\n    '''\n\n    data = ColumnData(String, Seq(Any), help=\"\"\"\n    Mapping of column names to sequences of data. The columns can be, e.g,\n    Python lists or tuples, NumPy arrays, etc.\n\n    The .data attribute can also be set from Pandas DataFrames or GroupBy\n    objects. In these cases, the behaviour is identical to passing the objects\n",
  "slicing": [
   "pd = import_optional('pandas')\n",
   "    data = ColumnData(String, Seq(Any), help=\"\"\"\n",
   "    ).asserts(lambda _, data: len({len(x) for x in data.values()}) <= 1,\n",
   "                    \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n",
   "        raw_data = kw.pop(\"data\", {})\n",
   "        if not isinstance(raw_data, dict):\n",
   "            if pd and isinstance(raw_data, pd.DataFrame):\n",
   "                raw_data = self._data_from_df(raw_data)\n",
   "            elif pd and isinstance(raw_data, pd.core.groupby.GroupBy):\n",
   "                raw_data = self._data_from_groupby(raw_data)\n",
   "                raise ValueError(\"expected a dict or pandas.DataFrame, got %s\" % raw_data)\n",
   "        self.data.update(raw_data)\n",
   "        _df = df.copy()\n",
   "        if isinstance(df.columns, pd.MultiIndex):\n",
   "                _df.columns = ['_'.join(col) for col in _df.columns.values]\n",
   "        if isinstance(df.columns, pd.CategoricalIndex):\n",
   "            _df.columns = df.columns.tolist()\n",
   "        index_name = ColumnDataSource._df_index_name(df)\n",
   "        if index_name == 'index':\n",
   "            _df.index = pd.Index(_df.index.values)\n",
   "            _df.index = pd.Index(_df.index.values, name=index_name)\n",
   "        _df.reset_index(inplace=True)\n",
   "        tmp_data = {c: v.values for c, v in _df.items()}\n",
   "        new_data = {}\n",
   "        for k, v in tmp_data.items():\n",
   "            new_data[k] = v\n",
   "        return new_data\n",
   "        return cls._data_from_df(data)\n",
   "        return cls._data_from_df(data.describe())\n",
   "        if not pd:\n",
   "        return pd.DataFrame(self.data)\n",
   "            n = len(self.data)\n",
   "            while \"Series %d\"%n in self.data:\n",
   "                n += 1\n",
   "            name = \"Series %d\"%n\n",
   "        self.data[name] = data\n",
   "        return name\n",
   "            del self.data[name]\n",
   "            warnings.warn(\"Unable to find column '%s' in data source\" % name)\n",
   "        self._stream(new_data, rollover)\n",
   "        needs_length_check = True\n",
   "        if pd and isinstance(new_data, pd.Series):\n",
   "            new_data = new_data.to_frame().T\n",
   "        if pd and isinstance(new_data, pd.DataFrame):\n",
   "            needs_length_check = False # DataFrame lengths equal by definition\n",
   "            _df = new_data\n",
   "            newkeys = set(_df.columns)\n",
   "            index_name = ColumnDataSource._df_index_name(_df)\n",
   "            newkeys.add(index_name)\n",
   "            new_data = dict(_df.items())\n",
   "            new_data[index_name] = _df.index.values\n",
   "            newkeys = set(new_data.keys())\n",
   "        oldkeys = set(self.data.keys())\n",
   "        if newkeys != oldkeys:\n",
   "            missing = oldkeys - newkeys\n",
   "            extra = newkeys - oldkeys\n",
   "            if missing and extra:\n",
   "                    \"Must stream updates to all existing columns (missing: %s, extra: %s)\" % (\", \".join(sorted(missing)), \", \".join(sorted(extra)))\n",
   "            elif missing:\n",
   "                raise ValueError(\"Must stream updates to all existing columns (missing: %s)\" % \", \".join(sorted(missing)))\n",
   "                raise ValueError(\"Must stream updates to all existing columns (extra: %s)\" % \", \".join(sorted(extra)))\n",
   "        if needs_length_check:\n",
   "            lengths = set()\n",
   "            arr_types = (np.ndarray, pd.Series) if pd else np.ndarray\n",
   "            for k, x in new_data.items():\n",
   "                if isinstance(x, arr_types):\n",
   "                    if len(x.shape) != 1:\n",
   "                        raise ValueError(\"stream(...) only supports 1d sequences, got ndarray with size %r\" % (x.shape,))\n",
   "                    lengths.add(x.shape[0])\n",
   "                    lengths.add(len(x))\n",
   "            if len(lengths) > 1:\n",
   "        for key, values in new_data.items():\n",
   "            if pd and isinstance(values, (pd.Series, pd.Index)):\n",
   "                values = values.values\n",
   "            old_values = self.data[key]\n",
   "            if (isinstance(values, np.ndarray) and values.dtype.kind.lower() == 'm' and\n",
   "                isinstance(old_values, np.ndarray) and old_values.dtype.kind.lower() != 'm'):\n",
   "                new_data[key] = convert_datetime_array(values)\n",
   "                new_data[key] = values\n",
   "        self.data._stream(self.document, self, new_data, rollover, setter)\n",
   "        extra = set(patches.keys()) - set(self.data.keys())\n",
   "        if extra:\n",
   "            raise ValueError(\"Can only patch existing columns (extra: %s)\" % \", \".join(sorted(extra)))\n",
   "        for name, patch in patches.items():\n",
   "            col_len = len(self.data[name])\n",
   "                    if ind > col_len or ind < 0:\n",
   "                        raise ValueError(\"Out-of bounds index (%d) in patch for column: %s\" % (ind, name))\n",
   "                    if ind.stop is not None and ind.stop > col_len:\n",
   "                        raise ValueError(\"Out-of bounds slice index stop (%d) in patch for column: %s\" % (ind.stop, name))\n",
   "                    if ind[0] > col_len or ind[0] < 0:\n",
   "                        raise ValueError(\"Out-of bounds initial sub-index (%d) in patch for column: %s\" % (ind, name))\n",
   "                    if not isinstance(self.data[name][ind[0]], np.ndarray):\n",
   "                    if len(self.data[name][ind[0]].shape) != (len(ind)-1):\n",
   "                        if ind[0].stop is not None and ind[0].stop > col_len:\n",
   "                            raise ValueError(\"Out-of bounds initial slice sub-index stop (%d) in patch for column: %s\" % (ind.stop, name))\n"
  ]
 },
 "317": {
  "name": "raw_data",
  "type": "dict",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/sources.py",
  "lineno": "186",
  "column": "8",
  "context": "rgs and \"data\", check and raise exception\n        raw_data = kw.pop(\"data\", {})\n\n        if not isinstance(raw_data, dict):\n      ",
  "context_lines": "        '''\n        if len(args) == 1 and \"data\" not in kw:\n            kw[\"data\"] = args[0]\n\n        # TODO (bev) invalid to pass args and \"data\", check and raise exception\n        raw_data = kw.pop(\"data\", {})\n\n        if not isinstance(raw_data, dict):\n            if pd and isinstance(raw_data, pd.DataFrame):\n                raw_data = self._data_from_df(raw_data)\n",
  "slicing": [
   "pd = import_optional('pandas')\n",
   "    data = ColumnData(String, Seq(Any), help=\"\"\"\n",
   "    ).asserts(lambda _, data: len({len(x) for x in data.values()}) <= 1,\n",
   "                    \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n",
   "        raw_data = kw.pop(\"data\", {})\n",
   "        if not isinstance(raw_data, dict):\n",
   "            if pd and isinstance(raw_data, pd.DataFrame):\n",
   "                raw_data = self._data_from_df(raw_data)\n",
   "            elif pd and isinstance(raw_data, pd.core.groupby.GroupBy):\n",
   "                raw_data = self._data_from_groupby(raw_data)\n",
   "                raise ValueError(\"expected a dict or pandas.DataFrame, got %s\" % raw_data)\n",
   "        self.data.update(raw_data)\n",
   "        _df = df.copy()\n",
   "        if isinstance(df.columns, pd.MultiIndex):\n",
   "                _df.columns = ['_'.join(col) for col in _df.columns.values]\n",
   "        if isinstance(df.columns, pd.CategoricalIndex):\n",
   "            _df.columns = df.columns.tolist()\n",
   "        index_name = ColumnDataSource._df_index_name(df)\n",
   "        if index_name == 'index':\n",
   "            _df.index = pd.Index(_df.index.values)\n",
   "            _df.index = pd.Index(_df.index.values, name=index_name)\n",
   "        _df.reset_index(inplace=True)\n",
   "        tmp_data = {c: v.values for c, v in _df.items()}\n",
   "        new_data = {}\n",
   "        for k, v in tmp_data.items():\n",
   "            new_data[k] = v\n",
   "        return new_data\n",
   "        return cls._data_from_df(data)\n",
   "        return cls._data_from_df(data.describe())\n",
   "        if not pd:\n",
   "        return pd.DataFrame(self.data)\n",
   "            n = len(self.data)\n",
   "            while \"Series %d\"%n in self.data:\n",
   "                n += 1\n",
   "            name = \"Series %d\"%n\n",
   "        self.data[name] = data\n",
   "        return name\n",
   "            del self.data[name]\n",
   "            warnings.warn(\"Unable to find column '%s' in data source\" % name)\n",
   "        self._stream(new_data, rollover)\n",
   "        needs_length_check = True\n",
   "        if pd and isinstance(new_data, pd.Series):\n",
   "            new_data = new_data.to_frame().T\n",
   "        if pd and isinstance(new_data, pd.DataFrame):\n",
   "            needs_length_check = False # DataFrame lengths equal by definition\n",
   "            _df = new_data\n",
   "            newkeys = set(_df.columns)\n",
   "            index_name = ColumnDataSource._df_index_name(_df)\n",
   "            newkeys.add(index_name)\n",
   "            new_data = dict(_df.items())\n",
   "            new_data[index_name] = _df.index.values\n",
   "            newkeys = set(new_data.keys())\n",
   "        oldkeys = set(self.data.keys())\n",
   "        if newkeys != oldkeys:\n",
   "            missing = oldkeys - newkeys\n",
   "            extra = newkeys - oldkeys\n",
   "            if missing and extra:\n",
   "                    \"Must stream updates to all existing columns (missing: %s, extra: %s)\" % (\", \".join(sorted(missing)), \", \".join(sorted(extra)))\n",
   "            elif missing:\n",
   "                raise ValueError(\"Must stream updates to all existing columns (missing: %s)\" % \", \".join(sorted(missing)))\n",
   "                raise ValueError(\"Must stream updates to all existing columns (extra: %s)\" % \", \".join(sorted(extra)))\n",
   "        if needs_length_check:\n",
   "            lengths = set()\n",
   "            arr_types = (np.ndarray, pd.Series) if pd else np.ndarray\n",
   "            for k, x in new_data.items():\n",
   "                if isinstance(x, arr_types):\n",
   "                    if len(x.shape) != 1:\n",
   "                        raise ValueError(\"stream(...) only supports 1d sequences, got ndarray with size %r\" % (x.shape,))\n",
   "                    lengths.add(x.shape[0])\n",
   "                    lengths.add(len(x))\n",
   "            if len(lengths) > 1:\n",
   "        for key, values in new_data.items():\n",
   "            if pd and isinstance(values, (pd.Series, pd.Index)):\n",
   "                values = values.values\n",
   "            old_values = self.data[key]\n",
   "            if (isinstance(values, np.ndarray) and values.dtype.kind.lower() == 'm' and\n",
   "                isinstance(old_values, np.ndarray) and old_values.dtype.kind.lower() != 'm'):\n",
   "                new_data[key] = convert_datetime_array(values)\n",
   "                new_data[key] = values\n",
   "        self.data._stream(self.document, self, new_data, rollover, setter)\n",
   "        extra = set(patches.keys()) - set(self.data.keys())\n",
   "        if extra:\n",
   "            raise ValueError(\"Can only patch existing columns (extra: %s)\" % \", \".join(sorted(extra)))\n",
   "        for name, patch in patches.items():\n",
   "            col_len = len(self.data[name])\n",
   "                    if ind > col_len or ind < 0:\n",
   "                        raise ValueError(\"Out-of bounds index (%d) in patch for column: %s\" % (ind, name))\n",
   "                    if ind.stop is not None and ind.stop > col_len:\n",
   "                        raise ValueError(\"Out-of bounds slice index stop (%d) in patch for column: %s\" % (ind.stop, name))\n",
   "                    if ind[0] > col_len or ind[0] < 0:\n",
   "                        raise ValueError(\"Out-of bounds initial sub-index (%d) in patch for column: %s\" % (ind, name))\n",
   "                    if not isinstance(self.data[name][ind[0]], np.ndarray):\n",
   "                    if len(self.data[name][ind[0]].shape) != (len(ind)-1):\n",
   "                        if ind[0].stop is not None and ind[0].stop > col_len:\n",
   "                            raise ValueError(\"Out-of bounds initial slice sub-index stop (%d) in patch for column: %s\" % (ind.stop, name))\n"
  ]
 },
 "318": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/markers.py",
  "lineno": "196",
  "column": "4",
  "context": " data column containing such names.\n    \"\"\")\n\n    __example__ = \"examples/reference/models/Scatter.py\"\n\nclass Asterisk(Marker):\n    ''' Render asterisk '",
  "context_lines": "    marker = MarkerSpec(default=\"circle\", help=\"\"\"\n    Which marker to render. This can be the name of any built in marker,\n    e.g. \"circle\", or a reference to a data column containing such names.\n    \"\"\")\n\n    __example__ = \"examples/reference/models/Scatter.py\"\n\nclass Asterisk(Marker):\n    ''' Render asterisk '*' markers. '''\n\n    __example__ = \"examples/reference/models/Asterisk.py\"\n\n\n",
  "slicing": "    __example__ = \"examples/reference/models/Scatter.py\"\n"
 },
 "319": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/markers.py",
  "lineno": "201",
  "column": "4",
  "context": "r):\n    ''' Render asterisk '*' markers. '''\n\n    __example__ = \"examples/reference/models/Asterisk.py\"\n\n\nclass Circle(Marker):\n    ''' Render circle mark",
  "context_lines": "    \"\"\")\n\n    __example__ = \"examples/reference/models/Scatter.py\"\n\nclass Asterisk(Marker):\n    ''' Render asterisk '*' markers. '''\n\n    __example__ = \"examples/reference/models/Asterisk.py\"\n\n\nclass Circle(Marker):\n    ''' Render circle markers. '''\n\n    __example__ = \"examples/reference/models/Circle.py\"\n\n",
  "slicing": "    __example__ = \"examples/reference/models/Asterisk.py\"\n"
 },
 "320": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/markers.py",
  "lineno": "207",
  "column": "4",
  "context": "(Marker):\n    ''' Render circle markers. '''\n\n    __example__ = \"examples/reference/models/Circle.py\"\n\n    # a canonical order for positional args that ",
  "context_lines": "    ''' Render asterisk '*' markers. '''\n\n    __example__ = \"examples/reference/models/Asterisk.py\"\n\n\nclass Circle(Marker):\n    ''' Render circle markers. '''\n\n    __example__ = \"examples/reference/models/Circle.py\"\n\n    # a canonical order for positional args that can be used for any\n    # functions derived from this class\n    _args = ('x', 'y')\n\n",
  "slicing": "    __example__ = \"examples/reference/models/Circle.py\"\n"
 },
 "321": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/markers.py",
  "lineno": "246",
  "column": "4",
  "context": "ers with a '+' cross through the center. '''\n\n    __example__ = \"examples/reference/models/CircleCross.py\"\n\nclass CircleDot(Marker):\n    ''' Render circle ma",
  "context_lines": "    and y dimensions and use the maximum of the two, 'min' selects the minimum.\n    \"\"\")\n\nclass CircleCross(Marker):\n    ''' Render circle markers with a '+' cross through the center. '''\n\n    __example__ = \"examples/reference/models/CircleCross.py\"\n\nclass CircleDot(Marker):\n    ''' Render circle markers with center dots. '''\n\n    __example__ = \"examples/reference/models/CircleDot.py\"\n\n",
  "slicing": "    __example__ = \"examples/reference/models/CircleCross.py\"\n"
 },
 "322": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/markers.py",
  "lineno": "251",
  "column": "4",
  "context": " Render circle markers with center dots. '''\n\n    __example__ = \"examples/reference/models/CircleDot.py\"\n\nclass CircleX(Marker):\n    ''' Render circle mark",
  "context_lines": "    ''' Render circle markers with a '+' cross through the center. '''\n\n    __example__ = \"examples/reference/models/CircleCross.py\"\n\nclass CircleDot(Marker):\n    ''' Render circle markers with center dots. '''\n\n    __example__ = \"examples/reference/models/CircleDot.py\"\n\nclass CircleX(Marker):\n    ''' Render circle markers with an 'X' cross through the center. '''\n\n    __example__ = \"examples/reference/models/CircleX.py\"\n\n",
  "slicing": "    __example__ = \"examples/reference/models/CircleDot.py\"\n"
 },
 "323": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/markers.py",
  "lineno": "256",
  "column": "4",
  "context": "rs with an 'X' cross through the center. '''\n\n    __example__ = \"examples/reference/models/CircleX.py\"\n\nclass CircleY(Marker):\n    ''' Render circle mark",
  "context_lines": "    ''' Render circle markers with center dots. '''\n\n    __example__ = \"examples/reference/models/CircleDot.py\"\n\nclass CircleX(Marker):\n    ''' Render circle markers with an 'X' cross through the center. '''\n\n    __example__ = \"examples/reference/models/CircleX.py\"\n\nclass CircleY(Marker):\n    ''' Render circle markers with an 'Y' cross through the center. '''\n\n    __example__ = \"examples/reference/models/CircleY.py\"\n\n",
  "slicing": "    __example__ = \"examples/reference/models/CircleX.py\"\n"
 },
 "324": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/markers.py",
  "lineno": "261",
  "column": "4",
  "context": "rs with an 'Y' cross through the center. '''\n\n    __example__ = \"examples/reference/models/CircleY.py\"\n\nclass Cross(Marker):\n    ''' Render '+' cross mar",
  "context_lines": "    ''' Render circle markers with an 'X' cross through the center. '''\n\n    __example__ = \"examples/reference/models/CircleX.py\"\n\nclass CircleY(Marker):\n    ''' Render circle markers with an 'Y' cross through the center. '''\n\n    __example__ = \"examples/reference/models/CircleY.py\"\n\nclass Cross(Marker):\n    ''' Render '+' cross markers. '''\n\n    __example__ = \"examples/reference/models/Cross.py\"\n\n",
  "slicing": "    __example__ = \"examples/reference/models/CircleY.py\"\n"
 },
 "325": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/markers.py",
  "lineno": "266",
  "column": "4",
  "context": "rker):\n    ''' Render '+' cross markers. '''\n\n    __example__ = \"examples/reference/models/Cross.py\"\n\nclass Dash(Marker):\n    ''' Render dash markers. ",
  "context_lines": "    ''' Render circle markers with an 'Y' cross through the center. '''\n\n    __example__ = \"examples/reference/models/CircleY.py\"\n\nclass Cross(Marker):\n    ''' Render '+' cross markers. '''\n\n    __example__ = \"examples/reference/models/Cross.py\"\n\nclass Dash(Marker):\n    ''' Render dash markers. Use ``angle`` to rotate and create vertically\n    oriented short lines.\n",
  "slicing": "    __example__ = \"examples/reference/models/Cross.py\"\n"
 },
 "326": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/markers.py",
  "lineno": "273",
  "column": "4",
  "context": "vertically\n    oriented short lines.\n    '''\n\n    __example__ = \"examples/reference/models/Dash.py\"\n\nclass Diamond(Marker):\n    ''' Render diamond mar",
  "context_lines": "class Dash(Marker):\n    ''' Render dash markers. Use ``angle`` to rotate and create vertically\n    oriented short lines.\n    '''\n\n    __example__ = \"examples/reference/models/Dash.py\"\n\nclass Diamond(Marker):\n    ''' Render diamond markers. '''\n\n    __example__ = \"examples/reference/models/Diamond.py\"\n\n",
  "slicing": "    __example__ = \"examples/reference/models/Dash.py\"\n"
 },
 "327": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/markers.py",
  "lineno": "278",
  "column": "4",
  "context": "Marker):\n    ''' Render diamond markers. '''\n\n    __example__ = \"examples/reference/models/Diamond.py\"\n\nclass DiamondCross(Marker):\n    ''' Render diamon",
  "context_lines": "    '''\n\n    __example__ = \"examples/reference/models/Dash.py\"\n\nclass Diamond(Marker):\n    ''' Render diamond markers. '''\n\n    __example__ = \"examples/reference/models/Diamond.py\"\n\nclass DiamondCross(Marker):\n    ''' Render diamond markers with a '+' cross through the center. '''\n\n    __example__ = \"examples/reference/models/DiamondCross.py\"\n\n",
  "slicing": "    __example__ = \"examples/reference/models/Diamond.py\"\n"
 },
 "328": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/markers.py",
  "lineno": "283",
  "column": "4",
  "context": "ers with a '+' cross through the center. '''\n\n    __example__ = \"examples/reference/models/DiamondCross.py\"\n\nclass DiamondDot(Marker):\n    ''' Render diamond ",
  "context_lines": "    ''' Render diamond markers. '''\n\n    __example__ = \"examples/reference/models/Diamond.py\"\n\nclass DiamondCross(Marker):\n    ''' Render diamond markers with a '+' cross through the center. '''\n\n    __example__ = \"examples/reference/models/DiamondCross.py\"\n\nclass DiamondDot(Marker):\n    ''' Render diamond markers with center dots. '''\n\n    __example__ = \"examples/reference/models/DiamondDot.py\"\n\n",
  "slicing": "    __example__ = \"examples/reference/models/DiamondCross.py\"\n"
 },
 "329": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/markers.py",
  "lineno": "288",
  "column": "4",
  "context": "Render diamond markers with center dots. '''\n\n    __example__ = \"examples/reference/models/DiamondDot.py\"\n\nclass Dot(Marker):\n    ''' Render dots (one-quart",
  "context_lines": "    ''' Render diamond markers with a '+' cross through the center. '''\n\n    __example__ = \"examples/reference/models/DiamondCross.py\"\n\nclass DiamondDot(Marker):\n    ''' Render diamond markers with center dots. '''\n\n    __example__ = \"examples/reference/models/DiamondDot.py\"\n\nclass Dot(Marker):\n    ''' Render dots (one-quarter radius circles). '''\n\n    __example__ = \"examples/reference/models/Dot.py\"\n\n",
  "slicing": "    __example__ = \"examples/reference/models/DiamondDot.py\"\n"
 },
 "330": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/markers.py",
  "lineno": "293",
  "column": "4",
  "context": "ender dots (one-quarter radius circles). '''\n\n    __example__ = \"examples/reference/models/Dot.py\"\n\nclass Hex(Marker):\n    ''' Render hexagon markers",
  "context_lines": "    ''' Render diamond markers with center dots. '''\n\n    __example__ = \"examples/reference/models/DiamondDot.py\"\n\nclass Dot(Marker):\n    ''' Render dots (one-quarter radius circles). '''\n\n    __example__ = \"examples/reference/models/Dot.py\"\n\nclass Hex(Marker):\n    ''' Render hexagon markers. '''\n\n    __example__ = \"examples/reference/models/Hex.py\"\n\n",
  "slicing": "    __example__ = \"examples/reference/models/Dot.py\"\n"
 },
 "331": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/markers.py",
  "lineno": "298",
  "column": "4",
  "context": "Marker):\n    ''' Render hexagon markers. '''\n\n    __example__ = \"examples/reference/models/Hex.py\"\n\nclass HexDot(Marker):\n    ''' Render hexagon mark",
  "context_lines": "    ''' Render dots (one-quarter radius circles). '''\n\n    __example__ = \"examples/reference/models/Dot.py\"\n\nclass Hex(Marker):\n    ''' Render hexagon markers. '''\n\n    __example__ = \"examples/reference/models/Hex.py\"\n\nclass HexDot(Marker):\n    ''' Render hexagon markers with center dots. '''\n\n    __example__ = \"examples/reference/models/HexDot.py\"\n\n",
  "slicing": "    __example__ = \"examples/reference/models/Hex.py\"\n"
 },
 "332": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/markers.py",
  "lineno": "303",
  "column": "4",
  "context": "Render hexagon markers with center dots. '''\n\n    __example__ = \"examples/reference/models/HexDot.py\"\n\nclass InvertedTriangle(Marker):\n    ''' Render up",
  "context_lines": "    ''' Render hexagon markers. '''\n\n    __example__ = \"examples/reference/models/Hex.py\"\n\nclass HexDot(Marker):\n    ''' Render hexagon markers with center dots. '''\n\n    __example__ = \"examples/reference/models/HexDot.py\"\n\nclass InvertedTriangle(Marker):\n    ''' Render upside-down triangle markers. '''\n\n    __example__ = \"examples/reference/models/InvertedTriangle.py\"\n\n",
  "slicing": "    __example__ = \"examples/reference/models/HexDot.py\"\n"
 },
 "333": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/markers.py",
  "lineno": "308",
  "column": "4",
  "context": "''' Render upside-down triangle markers. '''\n\n    __example__ = \"examples/reference/models/InvertedTriangle.py\"\n\nclass Plus(Marker):\n    ''' Render filled plus ma",
  "context_lines": "    ''' Render hexagon markers with center dots. '''\n\n    __example__ = \"examples/reference/models/HexDot.py\"\n\nclass InvertedTriangle(Marker):\n    ''' Render upside-down triangle markers. '''\n\n    __example__ = \"examples/reference/models/InvertedTriangle.py\"\n\nclass Plus(Marker):\n    ''' Render filled plus markers '''\n\n    __example__ = \"examples/reference/models/Plus.py\"\n\n",
  "slicing": "    __example__ = \"examples/reference/models/InvertedTriangle.py\"\n"
 },
 "334": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/markers.py",
  "lineno": "313",
  "column": "4",
  "context": "ker):\n    ''' Render filled plus markers '''\n\n    __example__ = \"examples/reference/models/Plus.py\"\n\nclass Square(Marker):\n    ''' Render square marke",
  "context_lines": "    ''' Render upside-down triangle markers. '''\n\n    __example__ = \"examples/reference/models/InvertedTriangle.py\"\n\nclass Plus(Marker):\n    ''' Render filled plus markers '''\n\n    __example__ = \"examples/reference/models/Plus.py\"\n\nclass Square(Marker):\n    ''' Render square markers. '''\n\n    __example__ = \"examples/reference/models/Square.py\"\n\n",
  "slicing": "    __example__ = \"examples/reference/models/Plus.py\"\n"
 },
 "335": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/markers.py",
  "lineno": "318",
  "column": "4",
  "context": "(Marker):\n    ''' Render square markers. '''\n\n    __example__ = \"examples/reference/models/Square.py\"\n\nclass SquareDot(Marker):\n    ''' Render square ma",
  "context_lines": "    ''' Render filled plus markers '''\n\n    __example__ = \"examples/reference/models/Plus.py\"\n\nclass Square(Marker):\n    ''' Render square markers. '''\n\n    __example__ = \"examples/reference/models/Square.py\"\n\nclass SquareDot(Marker):\n    ''' Render square markers with center dots. '''\n\n    __example__ = \"examples/reference/models/SquareDot.py\"\n\n",
  "slicing": "    __example__ = \"examples/reference/models/Square.py\"\n"
 },
 "336": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/markers.py",
  "lineno": "323",
  "column": "4",
  "context": " Render square markers with center dots. '''\n\n    __example__ = \"examples/reference/models/SquareDot.py\"\n\nclass SquarePin(Marker):\n    ''' Render pin-cushi",
  "context_lines": "    ''' Render square markers. '''\n\n    __example__ = \"examples/reference/models/Square.py\"\n\nclass SquareDot(Marker):\n    ''' Render square markers with center dots. '''\n\n    __example__ = \"examples/reference/models/SquareDot.py\"\n\nclass SquarePin(Marker):\n    ''' Render pin-cushion square markers. '''\n\n    __example__ = \"examples/reference/models/SquarePin.py\"\n\n",
  "slicing": "    __example__ = \"examples/reference/models/SquareDot.py\"\n"
 },
 "337": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/markers.py",
  "lineno": "328",
  "column": "4",
  "context": "  ''' Render pin-cushion square markers. '''\n\n    __example__ = \"examples/reference/models/SquarePin.py\"\n\nclass SquareCross(Marker):\n    ''' Render square ",
  "context_lines": "    ''' Render square markers with center dots. '''\n\n    __example__ = \"examples/reference/models/SquareDot.py\"\n\nclass SquarePin(Marker):\n    ''' Render pin-cushion square markers. '''\n\n    __example__ = \"examples/reference/models/SquarePin.py\"\n\nclass SquareCross(Marker):\n    ''' Render square markers with a '+' cross through the center. '''\n\n    __example__ = \"examples/reference/models/SquareCross.py\"\n\n",
  "slicing": "    __example__ = \"examples/reference/models/SquarePin.py\"\n"
 },
 "338": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/markers.py",
  "lineno": "333",
  "column": "4",
  "context": "ers with a '+' cross through the center. '''\n\n    __example__ = \"examples/reference/models/SquareCross.py\"\n\nclass SquareX(Marker):\n    ''' Render square mark",
  "context_lines": "    ''' Render pin-cushion square markers. '''\n\n    __example__ = \"examples/reference/models/SquarePin.py\"\n\nclass SquareCross(Marker):\n    ''' Render square markers with a '+' cross through the center. '''\n\n    __example__ = \"examples/reference/models/SquareCross.py\"\n\nclass SquareX(Marker):\n    ''' Render square markers with an 'X' cross through the center. '''\n\n    __example__ = \"examples/reference/models/SquareX.py\"\n\n",
  "slicing": "    __example__ = \"examples/reference/models/SquareCross.py\"\n"
 },
 "339": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/markers.py",
  "lineno": "338",
  "column": "4",
  "context": "rs with an 'X' cross through the center. '''\n\n    __example__ = \"examples/reference/models/SquareX.py\"\n\nclass Triangle(Marker):\n    ''' Render triangle m",
  "context_lines": "    ''' Render square markers with a '+' cross through the center. '''\n\n    __example__ = \"examples/reference/models/SquareCross.py\"\n\nclass SquareX(Marker):\n    ''' Render square markers with an 'X' cross through the center. '''\n\n    __example__ = \"examples/reference/models/SquareX.py\"\n\nclass Triangle(Marker):\n    ''' Render triangle markers. '''\n\n    __example__ = \"examples/reference/models/Triangle.py\"\n\n",
  "slicing": "    __example__ = \"examples/reference/models/SquareX.py\"\n"
 },
 "340": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/markers.py",
  "lineno": "343",
  "column": "4",
  "context": "arker):\n    ''' Render triangle markers. '''\n\n    __example__ = \"examples/reference/models/Triangle.py\"\n\nclass TriangleDot(Marker):\n    ''' Render triangl",
  "context_lines": "    ''' Render square markers with an 'X' cross through the center. '''\n\n    __example__ = \"examples/reference/models/SquareX.py\"\n\nclass Triangle(Marker):\n    ''' Render triangle markers. '''\n\n    __example__ = \"examples/reference/models/Triangle.py\"\n\nclass TriangleDot(Marker):\n    ''' Render triangle markers with center dots. '''\n\n    __example__ = \"examples/reference/models/TriangleDot.py\"\n\n",
  "slicing": "    __example__ = \"examples/reference/models/Triangle.py\"\n"
 },
 "341": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/markers.py",
  "lineno": "348",
  "column": "4",
  "context": "ender triangle markers with center dots. '''\n\n    __example__ = \"examples/reference/models/TriangleDot.py\"\n\nclass TrianglePin(Marker):\n    ''' Render pin-cus",
  "context_lines": "    ''' Render triangle markers. '''\n\n    __example__ = \"examples/reference/models/Triangle.py\"\n\nclass TriangleDot(Marker):\n    ''' Render triangle markers with center dots. '''\n\n    __example__ = \"examples/reference/models/TriangleDot.py\"\n\nclass TrianglePin(Marker):\n    ''' Render pin-cushion triangle markers. '''\n\n    __example__ = \"examples/reference/models/TrianglePin.py\"\n\n",
  "slicing": "    __example__ = \"examples/reference/models/TriangleDot.py\"\n"
 },
 "342": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/markers.py",
  "lineno": "353",
  "column": "4",
  "context": "''' Render pin-cushion triangle markers. '''\n\n    __example__ = \"examples/reference/models/TrianglePin.py\"\n\nclass X(Marker):\n    ''' Render 'X' markers. '''\n",
  "context_lines": "    ''' Render triangle markers with center dots. '''\n\n    __example__ = \"examples/reference/models/TriangleDot.py\"\n\nclass TrianglePin(Marker):\n    ''' Render pin-cushion triangle markers. '''\n\n    __example__ = \"examples/reference/models/TrianglePin.py\"\n\nclass X(Marker):\n    ''' Render 'X' markers. '''\n\n    __example__ = \"examples/reference/models/X.py\"\n\n",
  "slicing": "    __example__ = \"examples/reference/models/TrianglePin.py\"\n"
 },
 "343": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/markers.py",
  "lineno": "358",
  "column": "4",
  "context": "s X(Marker):\n    ''' Render 'X' markers. '''\n\n    __example__ = \"examples/reference/models/X.py\"\n\nclass Y(Marker):\n    ''' Render 'Y' markers. '''\n",
  "context_lines": "    ''' Render pin-cushion triangle markers. '''\n\n    __example__ = \"examples/reference/models/TrianglePin.py\"\n\nclass X(Marker):\n    ''' Render 'X' markers. '''\n\n    __example__ = \"examples/reference/models/X.py\"\n\nclass Y(Marker):\n    ''' Render 'Y' markers. '''\n\n    __example__ = \"examples/reference/models/Y.py\"\n\n",
  "slicing": "    __example__ = \"examples/reference/models/X.py\"\n"
 },
 "344": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/markers.py",
  "lineno": "363",
  "column": "4",
  "context": "s Y(Marker):\n    ''' Render 'Y' markers. '''\n\n    __example__ = \"examples/reference/models/Y.py\"\n\n#------------------------------------------------",
  "context_lines": "    ''' Render 'X' markers. '''\n\n    __example__ = \"examples/reference/models/X.py\"\n\nclass Y(Marker):\n    ''' Render 'Y' markers. '''\n\n    __example__ = \"examples/reference/models/Y.py\"\n\n#-----------------------------------------------------------------------------\n# Dev API\n#-----------------------------------------------------------------------------\n\n",
  "slicing": "    __example__ = \"examples/reference/models/Y.py\"\n"
 },
 "345": {
  "name": "x",
  "type": "Float",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/annotations.py",
  "lineno": "682",
  "column": "4",
  "context": "for information on plotting labels.\n\n    '''\n\n    x = Float(help=\"\"\"\n    The x-coordinate in screen coordinates to loca",
  "context_lines": "    appearance of the text, its background, as well as the rectangular bounding\n    box border.\n\n    See :ref:`userguide_plotting_labels` for information on plotting labels.\n\n    '''\n\n    x = Float(help=\"\"\"\n    The x-coordinate in screen coordinates to locate the text anchors.\n\n    Datetime values are also accepted, but note that they are immediately\n    converted to milliseconds-since-epoch.\n    \"\"\").accepts(Datetime, convert_datetime_type)\n\n",
  "slicing": [
   "            if len({r.data_source for r in self.renderers}) != 1:\n",
   "            source = self.renderers[0].data_source\n",
   "            if self.label.get('field') not in source.column_names:\n",
   "    items = List(Instance(LegendItem), help=\"\"\"\n",
   "    \"\"\").accepts(List(Tuple(String, List(Instance(GlyphRenderer)))), lambda items: [LegendItem(label=item[0], renderers=item[1]) for item in items])\n",
   "    source = Instance(DataSource, help=\"\"\"\n",
   "    source = Instance(DataSource, default=lambda: ColumnDataSource(), help=\"\"\"\n",
   "    x = Float(help=\"\"\"\n"
  ]
 },
 "346": {
  "name": "y",
  "type": "Float",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/annotations.py",
  "lineno": "694",
  "column": "4",
  "context": " \"data space\" units\n    by default.\n    \"\"\")\n\n    y = Float(help=\"\"\"\n    The y-coordinate in screen coordinates to loca",
  "context_lines": "    x_units = Enum(SpatialUnits, default='data', help=\"\"\"\n    The unit type for the x attribute. Interpreted as \"data space\" units\n    by default.\n    \"\"\")\n\n    y = Float(help=\"\"\"\n    The y-coordinate in screen coordinates to locate the text anchors.\n\n    Datetime values are also accepted, but note that they are immediately\n    converted to milliseconds-since-epoch.\n    \"\"\").accepts(Datetime, convert_datetime_type)\n\n",
  "slicing": [
   "            if len({r.data_source for r in self.renderers}) != 1:\n",
   "            source = self.renderers[0].data_source\n",
   "            if self.label.get('field') not in source.column_names:\n",
   "    items = List(Instance(LegendItem), help=\"\"\"\n",
   "    \"\"\").accepts(List(Tuple(String, List(Instance(GlyphRenderer)))), lambda items: [LegendItem(label=item[0], renderers=item[1]) for item in items])\n",
   "    source = Instance(DataSource, help=\"\"\"\n",
   "    source = Instance(DataSource, default=lambda: ColumnDataSource(), help=\"\"\"\n",
   "    y = Float(help=\"\"\"\n"
  ]
 },
 "347": {
  "name": "location",
  "type": "Float",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/annotations.py",
  "lineno": "910",
  "column": "4",
  "context": " for information on plotting spans.\n\n    \"\"\"\n\n    location = Float(help=\"\"\"\n    The location of the span, along ``dimension``.",
  "context_lines": "class Span(Annotation):\n    \"\"\" Render a horizontal or vertical line span.\n\n    See :ref:`userguide_plotting_spans` for information on plotting spans.\n\n    \"\"\"\n\n    location = Float(help=\"\"\"\n    The location of the span, along ``dimension``.\n\n    Datetime values are also accepted, but note that they are immediately\n    converted to milliseconds-since-epoch.\n    \"\"\").accepts(Datetime, convert_datetime_type)\n\n",
  "slicing": [
   "            if len({r.data_source for r in self.renderers}) != 1:\n",
   "            source = self.renderers[0].data_source\n",
   "            if self.label.get('field') not in source.column_names:\n",
   "    items = List(Instance(LegendItem), help=\"\"\"\n",
   "    \"\"\").accepts(List(Tuple(String, List(Instance(GlyphRenderer)))), lambda items: [LegendItem(label=item[0], renderers=item[1]) for item in items])\n",
   "    source = Instance(DataSource, help=\"\"\"\n",
   "    source = Instance(DataSource, default=lambda: ColumnDataSource(), help=\"\"\"\n",
   "    source = Instance(DataSource, default=lambda: ColumnDataSource(), help=\"\"\"\n",
   "    location = Float(help=\"\"\"\n"
  ]
 },
 "348": {
  "name": "palette",
  "type": "Seq",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/mappers.py",
  "lineno": "80",
  "column": "4",
  "context": " Base class for color mapper types.\n\n    '''\n\n    palette = Seq(Color, help=\"\"\"\n    A sequence of colors to use as the target pale",
  "context_lines": "@abstract\nclass ColorMapper(Mapper):\n    ''' Base class for color mapper types.\n\n    '''\n\n    palette = Seq(Color, help=\"\"\"\n    A sequence of colors to use as the target palette for mapping.\n\n    This property can also be set as a ``String``, to the name of any of the\n    palettes shown in :ref:`bokeh.palettes`.\n    \"\"\").accepts(Enum(Palette), lambda pal: getattr(palettes, pal))\n\n",
  "slicing": [
   "    palette = Seq(Color, help=\"\"\"\n",
   "        if palette is not None:\n",
   "            kwargs['palette'] = palette\n",
   "    factors = Either(Seq(String), Seq(Tuple(String, String)), Seq(Tuple(String, String, String)), default=None, help=\"\"\"\n",
   "        palette = self.palette\n",
   "        factors = self.factors\n",
   "        if palette is not None and factors is not None:\n",
   "            if len(palette) < len(factors):\n",
   "                extra_factors = factors[len(palette):]\n",
   "                warnings.warn(\"Palette length does not match number of factors. %s will be assigned to `nan_color` %s\" % (extra_factors, self.nan_color))\n"
  ]
 },
 "349": {
  "name": "margin",
  "type": "Tuple",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/layouts.py",
  "lineno": "121",
  "column": "4",
  "context": "in pixels) if height is adjustable.\n    \"\"\")\n\n    margin = Tuple(Int, Int, Int, Int, default=(0, 0, 0, 0), help=\"\"\"\n    Allows to create additional space around the c",
  "context_lines": "    \"\"\")\n\n    max_height = NonNegativeInt(default=None, help=\"\"\"\n    Maximal height of the component (in pixels) if height is adjustable.\n    \"\"\")\n\n    margin = Tuple(Int, Int, Int, Int, default=(0, 0, 0, 0), help=\"\"\"\n    Allows to create additional space around the component.\n    The values in the tuple are ordered as follows - Margin-Top, Margin-Right, Margin-Bottom and Margin-Left,\n    similar to CSS standards.\n    Negative margin values may be used to shrink the space from any direction.\n",
  "slicing": [
   "    margin = Tuple(Int, Int, Int, Int, default=(0, 0, 0, 0), help=\"\"\"\n"
  ]
 },
 "350": {
  "name": "css_classes",
  "type": "List",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/layouts.py",
  "lineno": "258",
  "column": "4",
  "context": "f: https://github.com/bokeh/bokeh/issues/6841\n    css_classes = List(String, help=\"\"\"\n    A list of CSS class names to add to this DOM e",
  "context_lines": "    background = Color(default=None, help=\"\"\"\n    Background color of the component.\n    \"\"\")\n\n    # List in order for in-place changes to trigger changes, ref: https://github.com/bokeh/bokeh/issues/6841\n    css_classes = List(String, help=\"\"\"\n    A list of CSS class names to add to this DOM element. Note: the class names are\n    simply added as-is, no other guarantees are provided.\n\n    It is also permissible to assign from tuples, however these are adapted -- the\n    property will always contain a list.\n",
  "slicing": [
   "    css_classes = List(String, help=\"\"\"\n"
  ]
 },
 "351": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/layouts.py",
  "lineno": "470",
  "column": "4",
  "context": " panel widget with navigation tabs.\n\n    '''\n\n    __example__ = \"sphinx/source/docs/user_guide/examples/interaction_tab_panes.py\"\n\n    tabs = List(Instance(Panel), help=\"\"\"\n    The",
  "context_lines": "    \"\"\")\n\nclass Tabs(LayoutDOM):\n    ''' A panel widget with navigation tabs.\n\n    '''\n\n    __example__ = \"sphinx/source/docs/user_guide/examples/interaction_tab_panes.py\"\n\n    tabs = List(Instance(Panel), help=\"\"\"\n    The list of child panel widgets.\n    \"\"\").accepts(List(Tuple(String, Instance(LayoutDOM))),\n",
  "slicing": "    __example__ = \"sphinx/source/docs/user_guide/examples/interaction_tab_panes.py\"\n"
 },
 "352": {
  "name": "tabs",
  "type": "List",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/layouts.py",
  "lineno": "472",
  "column": "4",
  "context": "ser_guide/examples/interaction_tab_panes.py\"\n\n    tabs = List(Instance(Panel), help=\"\"\"\n    The list of child panel widgets.\n    \"\"\").acce",
  "context_lines": "class Tabs(LayoutDOM):\n    ''' A panel widget with navigation tabs.\n\n    '''\n\n    __example__ = \"sphinx/source/docs/user_guide/examples/interaction_tab_panes.py\"\n\n    tabs = List(Instance(Panel), help=\"\"\"\n    The list of child panel widgets.\n    \"\"\").accepts(List(Tuple(String, Instance(LayoutDOM))),\n                 lambda items: [ Panel(title=title, child=child) for (title, child) in items ])\n\n    tabs_location = Enum(Location, default=\"above\", help=\"\"\"\n",
  "slicing": [
   "    width = NonNegativeInt(default=None, help=\"\"\"\n",
   "    height = NonNegativeInt(default=None, help=\"\"\"\n",
   "    min_width = NonNegativeInt(default=None, help=\"\"\"\n",
   "    min_height = NonNegativeInt(default=None, help=\"\"\"\n",
   "    max_width = NonNegativeInt(default=None, help=\"\"\"\n",
   "    max_height = NonNegativeInt(default=None, help=\"\"\"\n",
   "        min_width = self.min_width if self.min_width is not None else 0\n",
   "        width     = self.width     if self.width     is not None else min_width\n",
   "        max_width = self.max_width if self.max_width is not None else width\n",
   "        if not (min_width <= width <= max_width):\n",
   "        min_height = self.min_height if self.min_height is not None else 0\n",
   "        height     = self.height     if self.height     is not None else min_height\n",
   "        max_height = self.max_height if self.max_height is not None else height\n",
   "        if not (min_height <= height <= max_height):\n",
   "QuickTrackSizing = Either(Enum(\"auto\", \"min\", \"fit\", \"max\"), Int)\n",
   "TrackAlign = Either(Auto, Enum(Align))\n",
   "RowSizing = Either(\n",
   "    QuickTrackSizing,\n",
   "    Struct(policy=Enum(\"auto\", \"min\"), align=TrackAlign),\n",
   "    Struct(policy=Enum(\"fixed\"), height=Int, align=TrackAlign),\n",
   "    Struct(policy=Enum(\"fit\", \"max\"), flex=Float, align=TrackAlign))\n",
   "ColSizing = Either(\n",
   "    QuickTrackSizing,\n",
   "    Struct(policy=Enum(\"auto\", \"min\"), align=TrackAlign),\n",
   "    Struct(policy=Enum(\"fixed\"), width=Int, align=TrackAlign),\n",
   "    Struct(policy=Enum(\"fit\", \"max\"), flex=Float, align=TrackAlign))\n",
   "IntOrString = Either(Int, String) # XXX: work around issue #8166\n",
   "    children = List(Either(\n",
   "    rows = Either(QuickTrackSizing, Dict(IntOrString, RowSizing), default=\"auto\", help=\"\"\"\n",
   "    cols = Either(QuickTrackSizing, Dict(IntOrString, ColSizing), default=\"auto\", help=\"\"\"\n",
   "        children = [ child[0] for child in self.children ]\n",
   "        if len(children) != len(set(children)):\n",
   "        problems = []\n",
   "        for c in self.children:\n",
   "            if c.document is not None and c in c.document.roots:\n",
   "                problems.append(str(c))\n",
   "        if problems:\n",
   "            return \", \".join(problems)\n",
   "    children = List(Instance(LayoutDOM), help=\"\"\"\n",
   "    cols = Either(QuickTrackSizing, Dict(IntOrString, ColSizing), default=\"auto\", help=\"\"\"\n",
   "    rows = Either(QuickTrackSizing, Dict(IntOrString, RowSizing), default=\"auto\", help=\"\"\"\n",
   "    title = String(default=\"\", help=\"\"\"\n",
   "    child = Instance(LayoutDOM, help=\"\"\"\n",
   "    tabs = List(Instance(Panel), help=\"\"\"\n",
   "                 lambda items: [ Panel(title=title, child=child) for (title, child) in items ])\n"
  ]
 },
 "353": {
  "name": "selector",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/models/plots.py",
  "lineno": "135",
  "column": "8",
  "context": "name=\"foo\", type=HoverTool)\n\n        '''\n\n        selector = _select_helper(args, kwargs)\n\n        # Want to pass selector that is a diction",
  "context_lines": "                # Keyword arguments can be supplied in place of selector dict\n                p.select({\"name\": \"foo\", \"type\": HoverTool})\n                p.select(name=\"foo\", type=HoverTool)\n\n        '''\n\n        selector = _select_helper(args, kwargs)\n\n        # Want to pass selector that is a dictionary\n        return _list_attr_splat(find(self.references(), selector, {'plot': self}))\n\n    def row(self, row, gridplot):\n",
  "slicing": [
   "        selector = _select_helper(args, kwargs)\n",
   "        return _list_attr_splat(find(self.references(), selector, {'plot': self}))\n",
   "    return selector\n"
  ]
 },
 "354": {
  "name": "selector",
  "type": "dict",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "bokeh/bokeh/models/plots.py",
  "lineno": "801",
  "column": "8",
  "context": " keyword args may be present\")\n\n    else:\n        selector = kwargs\n\n    return selector\n\n#---------------------------",
  "context_lines": "            selector = kwargs['selector']\n        else:\n            raise TypeError(\"when passing 'selector' keyword arg, not other keyword args may be present\")\n\n    else:\n        selector = kwargs\n\n    return selector\n\n#-----------------------------------------------------------------------------\n# Code\n",
  "slicing": [
   "        selector = _select_helper(args, kwargs)\n",
   "        return _list_attr_splat(find(self.references(), selector, {'plot': self}))\n",
   "        objs = []\n",
   "        for s in sides:\n",
   "            objs.extend(getattr(self, s, []))\n",
   "        axis = [obj for obj in objs if isinstance(obj, Axis)]\n",
   "        return _list_attr_splat(axis)\n",
   "        panels = self.above + self.below + self.left + self.right + self.center\n",
   "        legends = [obj for obj in panels if isinstance(obj, Legend)]\n",
   "        return _legend_attr_splat(legends)\n",
   "        hovers = [obj for obj in self.tools if isinstance(obj, HoverTool)]\n",
   "        return _list_attr_splat(hovers)\n",
   "        grid = [obj for obj in self.center if isinstance(obj, Grid) and obj.dimension == dimension]\n",
   "        return _list_attr_splat(grid)\n",
   "        valid_places = ['left', 'right', 'above', 'below', 'center']\n",
   "        if place not in valid_places:\n",
   "                \"Invalid place '%s' specified. Valid place values are: %s\" % (place, nice_join(valid_places))\n",
   "        getattr(self, place).append(obj)\n",
   "        for tool in tools:\n",
   "            if not isinstance(tool, Tool):\n",
   "            self.toolbar.tools.append(tool)\n",
   "            source = source_or_glyph\n",
   "            source, glyph = ColumnDataSource(), source_or_glyph\n",
   "        if not isinstance(source, DataSource):\n",
   "        if not isinstance(glyph, Glyph):\n",
   "        g = GlyphRenderer(data_source=source, glyph=glyph, **kw)\n",
   "        self.renderers.append(g)\n",
   "        return g\n",
   "        tile_renderer = TileRenderer(tile_source=tile_source, **kw)\n",
   "        self.renderers.append(tile_renderer)\n",
   "        return tile_renderer\n",
   "        missing = []\n",
   "        if not self.x_range: missing.append('x_range')\n",
   "        if not self.y_range: missing.append('y_range')\n",
   "        if missing:\n",
   "            return \", \".join(missing) + \" [%s]\" % self\n",
   "        missing = []\n",
   "        if not self.x_scale: missing.append('x_scale')\n",
   "        if not self.y_scale: missing.append('y_scale')\n",
   "        if missing:\n",
   "            return \", \".join(missing) + \" [%s]\" % self\n",
   "        incompatible = []\n",
   "        x_ranges = list(self.extra_x_ranges.values())\n",
   "        if self.x_range: x_ranges.append(self.x_range)\n",
   "        y_ranges = list(self.extra_y_ranges.values())\n",
   "        if self.y_range: y_ranges.append(self.y_range)\n",
   "            for rng in x_ranges:\n",
   "                if isinstance(rng, (DataRange1d, Range1d)) and not isinstance(self.x_scale, (LinearScale, LogScale)):\n",
   "                    incompatible.append(\"incompatibility on x-dimension: %s, %s\" %(rng, self.x_scale))\n",
   "                elif isinstance(rng, FactorRange) and not isinstance(self.x_scale, CategoricalScale):\n",
   "                    incompatible.append(\"incompatibility on x-dimension: %s/%s\" %(rng, self.x_scale))\n",
   "                if isinstance(rng, (DataRange1d, Range1d)) and isinstance(self.x_scale, CategoricalScale):\n",
   "                    incompatible.append(\"incompatibility on x-dimension: %s, %s\" %(rng, self.x_scale))\n",
   "            for rng in y_ranges:\n",
   "                if isinstance(rng, (DataRange1d, Range1d)) and not isinstance(self.y_scale, (LinearScale, LogScale)):\n",
   "                    incompatible.append(\"incompatibility on y-dimension: %s/%s\" %(rng, self.y_scale))\n",
   "                elif isinstance(rng, FactorRange) and not isinstance(self.y_scale, CategoricalScale):\n",
   "                    incompatible.append(\"incompatibility on y-dimension: %s/%s\" %(rng, self.y_scale))\n",
   "                if isinstance(rng, (DataRange1d, Range1d)) and isinstance(self.y_scale, CategoricalScale):\n",
   "                    incompatible.append(\"incompatibility on y-dimension: %s, %s\" %(rng, self.y_scale))\n",
   "        if incompatible:\n",
   "            return \", \".join(incompatible) + \" [%s]\" % self\n",
   "        if len(self.renderers) == 0 and len([x for x in self.center if isinstance(x, Annotation)]) == 0:\n",
   "        msg  = \"\"\n",
   "        filt = lambda x: x is not self and isinstance(x, Plot)\n",
   "        for ref in collect_filtered_models(filt, self):\n",
   "            prop_names = ref.properties()\n",
   "            bad = []\n",
   "            if 'x_range_name' in prop_names and 'y_range_name' in prop_names:\n",
   "                if ref.x_range_name not in self.extra_x_ranges and ref.x_range_name != \"default\":\n",
   "                    bad.append(('x_range_name', ref.x_range_name))\n",
   "                if ref.y_range_name not in self.extra_y_ranges and ref.y_range_name != \"default\":\n",
   "                    bad.append(('y_range_name', ref.y_range_name))\n",
   "            if bad:\n",
   "                if msg: msg += \", \"\n",
   "                msg += (\", \".join(\"%s=%r\" % (a, b) for (a,b) in bad) + \" [%s]\" % ref)\n",
   "        if msg:\n",
   "            return msg\n",
   "        for x in self:\n",
   "            setattr(x, attr, value)\n",
   "            return _list_attr_splat([getattr(x, attr) for x in self])\n",
   "        if len({type(x) for x in self}) == 1:\n",
   "_LEGEND_EMPTY_WARNING = \"\"\"\n",
   "            warnings.warn(_LEGEND_EMPTY_WARNING % attr)\n",
   "        arg = args[0]\n",
   "        if isinstance(arg, dict):\n",
   "            selector = arg\n",
   "        elif isinstance(arg, str):\n",
   "            selector = dict(name=arg)\n",
   "        elif isinstance(arg, type) and issubclass(arg, Model):\n",
   "            selector = {\"type\": arg}\n",
   "            selector = kwargs['selector']\n",
   "        selector = kwargs\n",
   "    return selector\n"
  ]
 },
 "355": {
  "name": "microseconds",
  "type": "List",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/formatters.py",
  "lineno": "540",
  "column": "4",
  "context": "ttps://github.com/bokeh/bokeh/issues\n\n    '''\n    microseconds = List(String,\n                        help=_DATETIME_TICK_FORMAT",
  "context_lines": "    .. _strftime: http://man7.org/linux/man-pages/man3/strftime.3.html\n    .. _timezone: http://bigeasy.github.io/timezone/\n    .. _github issue: https://github.com/bokeh/bokeh/issues\n\n    '''\n    microseconds = List(String,\n                        help=_DATETIME_TICK_FORMATTER_HELP(\"``microseconds``\"),\n                        default=['%fus']).accepts(String, lambda fmt: [fmt])\n\n    milliseconds = List(String,\n                        help=_DATETIME_TICK_FORMATTER_HELP(\"``milliseconds``\"),\n",
  "slicing": [
   "def _DATETIME_TICK_FORMATTER_HELP(field):\n",
   "    \"\"\" % field\n",
   "    microseconds = List(String,\n"
  ]
 },
 "356": {
  "name": "milliseconds",
  "type": "List",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/formatters.py",
  "lineno": "544",
  "column": "4",
  "context": "['%fus']).accepts(String, lambda fmt: [fmt])\n\n    milliseconds = List(String,\n                        help=_DATETIME_TICK_FORMAT",
  "context_lines": "    '''\n    microseconds = List(String,\n                        help=_DATETIME_TICK_FORMATTER_HELP(\"``microseconds``\"),\n                        default=['%fus']).accepts(String, lambda fmt: [fmt])\n\n    milliseconds = List(String,\n                        help=_DATETIME_TICK_FORMATTER_HELP(\"``milliseconds``\"),\n                        default=['%3Nms', '%S.%3Ns']).accepts(String, lambda fmt: [fmt])\n\n    seconds      = List(String,\n                        help=_DATETIME_TICK_FORMATTER_HELP(\"``seconds``\"),\n",
  "slicing": [
   "def _DATETIME_TICK_FORMATTER_HELP(field):\n",
   "    \"\"\" % field\n",
   "    milliseconds = List(String,\n"
  ]
 },
 "357": {
  "name": "seconds",
  "type": "List",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/formatters.py",
  "lineno": "548",
  "column": "4",
  "context": "S.%3Ns']).accepts(String, lambda fmt: [fmt])\n\n    seconds      = List(String,\n                        help=_DATETIME_TICK_FORMAT",
  "context_lines": "                        default=['%fus']).accepts(String, lambda fmt: [fmt])\n\n    milliseconds = List(String,\n                        help=_DATETIME_TICK_FORMATTER_HELP(\"``milliseconds``\"),\n                        default=['%3Nms', '%S.%3Ns']).accepts(String, lambda fmt: [fmt])\n\n    seconds      = List(String,\n                        help=_DATETIME_TICK_FORMATTER_HELP(\"``seconds``\"),\n                        default=['%Ss']).accepts(String, lambda fmt: [fmt])\n\n    minsec       = List(String,\n                        help=_DATETIME_TICK_FORMATTER_HELP(\"``minsec`` (for combined minutes and seconds)\"),\n",
  "slicing": [
   "def _DATETIME_TICK_FORMATTER_HELP(field):\n",
   "    \"\"\" % field\n",
   "    seconds      = List(String,\n"
  ]
 },
 "358": {
  "name": "minsec",
  "type": "List",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/formatters.py",
  "lineno": "552",
  "column": "4",
  "context": "=['%Ss']).accepts(String, lambda fmt: [fmt])\n\n    minsec       = List(String,\n                        help=_DATETIME_TICK_FORMAT",
  "context_lines": "                        default=['%3Nms', '%S.%3Ns']).accepts(String, lambda fmt: [fmt])\n\n    seconds      = List(String,\n                        help=_DATETIME_TICK_FORMATTER_HELP(\"``seconds``\"),\n                        default=['%Ss']).accepts(String, lambda fmt: [fmt])\n\n    minsec       = List(String,\n                        help=_DATETIME_TICK_FORMATTER_HELP(\"``minsec`` (for combined minutes and seconds)\"),\n                        default=[':%M:%S']).accepts(String, lambda fmt: [fmt])\n\n    minutes      = List(String,\n                        help=_DATETIME_TICK_FORMATTER_HELP(\"``minutes``\"),\n",
  "slicing": [
   "def _DATETIME_TICK_FORMATTER_HELP(field):\n",
   "    \"\"\" % field\n",
   "    minsec       = List(String,\n"
  ]
 },
 "359": {
  "name": "minutes",
  "type": "List",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/formatters.py",
  "lineno": "556",
  "column": "4",
  "context": ":%M:%S']).accepts(String, lambda fmt: [fmt])\n\n    minutes      = List(String,\n                        help=_DATETIME_TICK_FORMAT",
  "context_lines": "                        default=['%Ss']).accepts(String, lambda fmt: [fmt])\n\n    minsec       = List(String,\n                        help=_DATETIME_TICK_FORMATTER_HELP(\"``minsec`` (for combined minutes and seconds)\"),\n                        default=[':%M:%S']).accepts(String, lambda fmt: [fmt])\n\n    minutes      = List(String,\n                        help=_DATETIME_TICK_FORMATTER_HELP(\"``minutes``\"),\n                        default=[':%M', '%Mm']).accepts(String, lambda fmt: [fmt])\n\n    hourmin      = List(String,\n                        help=_DATETIME_TICK_FORMATTER_HELP(\"``hourmin`` (for combined hours and minutes)\"),\n",
  "slicing": [
   "def _DATETIME_TICK_FORMATTER_HELP(field):\n",
   "    \"\"\" % field\n",
   "    minutes      = List(String,\n"
  ]
 },
 "360": {
  "name": "hourmin",
  "type": "List",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/formatters.py",
  "lineno": "560",
  "column": "4",
  "context": ", '%Mm']).accepts(String, lambda fmt: [fmt])\n\n    hourmin      = List(String,\n                        help=_DATETIME_TICK_FORMAT",
  "context_lines": "                        default=[':%M:%S']).accepts(String, lambda fmt: [fmt])\n\n    minutes      = List(String,\n                        help=_DATETIME_TICK_FORMATTER_HELP(\"``minutes``\"),\n                        default=[':%M', '%Mm']).accepts(String, lambda fmt: [fmt])\n\n    hourmin      = List(String,\n                        help=_DATETIME_TICK_FORMATTER_HELP(\"``hourmin`` (for combined hours and minutes)\"),\n                        default=['%H:%M']).accepts(String, lambda fmt: [fmt])\n\n    hours        = List(String,\n                        help=_DATETIME_TICK_FORMATTER_HELP(\"``hours``\"),\n",
  "slicing": [
   "def _DATETIME_TICK_FORMATTER_HELP(field):\n",
   "    \"\"\" % field\n",
   "    hourmin      = List(String,\n"
  ]
 },
 "361": {
  "name": "hours",
  "type": "List",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/formatters.py",
  "lineno": "564",
  "column": "4",
  "context": "'%H:%M']).accepts(String, lambda fmt: [fmt])\n\n    hours        = List(String,\n                        help=_DATETIME_TICK_FORMAT",
  "context_lines": "                        default=[':%M', '%Mm']).accepts(String, lambda fmt: [fmt])\n\n    hourmin      = List(String,\n                        help=_DATETIME_TICK_FORMATTER_HELP(\"``hourmin`` (for combined hours and minutes)\"),\n                        default=['%H:%M']).accepts(String, lambda fmt: [fmt])\n\n    hours        = List(String,\n                        help=_DATETIME_TICK_FORMATTER_HELP(\"``hours``\"),\n                        default=['%Hh', '%H:%M']).accepts(String, lambda fmt: [fmt])\n\n    days         = List(String,\n                        help=_DATETIME_TICK_FORMATTER_HELP(\"``days``\"),\n",
  "slicing": [
   "def _DATETIME_TICK_FORMATTER_HELP(field):\n",
   "    \"\"\" % field\n",
   "    hours        = List(String,\n"
  ]
 },
 "362": {
  "name": "days",
  "type": "List",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/formatters.py",
  "lineno": "568",
  "column": "4",
  "context": "'%H:%M']).accepts(String, lambda fmt: [fmt])\n\n    days         = List(String,\n                        help=_DATETIME_TICK_FORMAT",
  "context_lines": "                        default=['%H:%M']).accepts(String, lambda fmt: [fmt])\n\n    hours        = List(String,\n                        help=_DATETIME_TICK_FORMATTER_HELP(\"``hours``\"),\n                        default=['%Hh', '%H:%M']).accepts(String, lambda fmt: [fmt])\n\n    days         = List(String,\n                        help=_DATETIME_TICK_FORMATTER_HELP(\"``days``\"),\n                        default=['%m/%d', '%a%d']).accepts(String, lambda fmt: [fmt])\n\n    months       = List(String,\n                        help=_DATETIME_TICK_FORMATTER_HELP(\"``months``\"),\n",
  "slicing": [
   "def _DATETIME_TICK_FORMATTER_HELP(field):\n",
   "    \"\"\" % field\n",
   "    days         = List(String,\n"
  ]
 },
 "363": {
  "name": "months",
  "type": "List",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/formatters.py",
  "lineno": "572",
  "column": "4",
  "context": " '%a%d']).accepts(String, lambda fmt: [fmt])\n\n    months       = List(String,\n                        help=_DATETIME_TICK_FORMAT",
  "context_lines": "                        default=['%Hh', '%H:%M']).accepts(String, lambda fmt: [fmt])\n\n    days         = List(String,\n                        help=_DATETIME_TICK_FORMATTER_HELP(\"``days``\"),\n                        default=['%m/%d', '%a%d']).accepts(String, lambda fmt: [fmt])\n\n    months       = List(String,\n                        help=_DATETIME_TICK_FORMATTER_HELP(\"``months``\"),\n                        default=['%m/%Y', '%b %Y']).accepts(String, lambda fmt: [fmt])\n\n    years        = List(String,\n                        help=_DATETIME_TICK_FORMATTER_HELP(\"``years``\"),\n",
  "slicing": [
   "def _DATETIME_TICK_FORMATTER_HELP(field):\n",
   "    \"\"\" % field\n",
   "    months       = List(String,\n"
  ]
 },
 "364": {
  "name": "years",
  "type": "List",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/formatters.py",
  "lineno": "576",
  "column": "4",
  "context": "'%b %Y']).accepts(String, lambda fmt: [fmt])\n\n    years        = List(String,\n                        help=_DATETIME_TICK_FORMAT",
  "context_lines": "                        default=['%m/%d', '%a%d']).accepts(String, lambda fmt: [fmt])\n\n    months       = List(String,\n                        help=_DATETIME_TICK_FORMATTER_HELP(\"``months``\"),\n                        default=['%m/%Y', '%b %Y']).accepts(String, lambda fmt: [fmt])\n\n    years        = List(String,\n                        help=_DATETIME_TICK_FORMATTER_HELP(\"``years``\"),\n                        default=['%Y']).accepts(String, lambda fmt: [fmt])\n\n#-----------------------------------------------------------------------------\n# Dev API\n",
  "slicing": [
   "def _DATETIME_TICK_FORMATTER_HELP(field):\n",
   "    \"\"\" % field\n",
   "    years        = List(String,\n"
  ]
 },
 "365": {
  "name": "descriptor",
  "type": "UnitsSpecPropertyDescriptor",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/glyph.py",
  "lineno": "72",
  "column": "12",
  "context": "      for arg in reversed(cls._args):\n            descriptor = cls.lookup(arg)\n            default = descriptor.class_default(cls",
  "context_lines": "        '''\n        arg_params = []\n        no_more_defaults = False\n\n        for arg in reversed(cls._args):\n            descriptor = cls.lookup(arg)\n            default = descriptor.class_default(cls)\n            if default is None:\n                no_more_defaults = True\n            param = Parameter(\n",
  "slicing": [
   "        arg_params = []\n",
   "        no_more_defaults = False\n",
   "        for arg in reversed(cls._args):\n",
   "            descriptor = cls.lookup(arg)\n",
   "            default = descriptor.class_default(cls)\n",
   "            if default is None:\n",
   "                no_more_defaults = True\n",
   "            param = Parameter(\n",
   "                name=arg,\n",
   "                default=Parameter.empty if no_more_defaults else default\n",
   "            typ = descriptor.property._sphinx_type()\n",
   "            arg_params.insert(0, (param, typ, descriptor.__doc__))\n",
   "        omissions = {'js_event_callbacks', 'js_property_callbacks', 'subscribed_events'}\n",
   "        kws = cls.properties() - set(cls._args) - omissions\n",
   "        for kw in kws:\n",
   "            descriptor = cls.lookup(kw)\n",
   "            param = Parameter(\n",
   "                name=kw,\n",
   "                default=descriptor.class_default(cls)\n",
   "            typ = descriptor.property._sphinx_type()\n",
   "            kwarg_params.append((param, typ, descriptor.__doc__))\n",
   "                name=kw,\n",
   "            kwarg_params.append((param, typ, doc))\n",
   "        return arg_params + kwarg_params\n"
  ]
 },
 "366": {
  "name": "default",
  "type": "bool|NoneType|int|str|dict|float",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/glyph.py",
  "lineno": "73",
  "column": "12",
  "context": "         descriptor = cls.lookup(arg)\n            default = descriptor.class_default(cls)\n            if default is None:\n                no",
  "context_lines": "        arg_params = []\n        no_more_defaults = False\n\n        for arg in reversed(cls._args):\n            descriptor = cls.lookup(arg)\n            default = descriptor.class_default(cls)\n            if default is None:\n                no_more_defaults = True\n            param = Parameter(\n                name=arg,\n",
  "slicing": [
   "        arg_params = []\n",
   "        no_more_defaults = False\n",
   "        for arg in reversed(cls._args):\n",
   "            descriptor = cls.lookup(arg)\n",
   "            default = descriptor.class_default(cls)\n",
   "            if default is None:\n",
   "                no_more_defaults = True\n",
   "            param = Parameter(\n",
   "                name=arg,\n",
   "                default=Parameter.empty if no_more_defaults else default\n",
   "            typ = descriptor.property._sphinx_type()\n",
   "            arg_params.insert(0, (param, typ, descriptor.__doc__))\n",
   "        omissions = {'js_event_callbacks', 'js_property_callbacks', 'subscribed_events'}\n",
   "        kws = cls.properties() - set(cls._args) - omissions\n",
   "        for kw in kws:\n",
   "            descriptor = cls.lookup(kw)\n",
   "            param = Parameter(\n",
   "                name=kw,\n",
   "                default=descriptor.class_default(cls)\n",
   "            typ = descriptor.property._sphinx_type()\n",
   "            kwarg_params.append((param, typ, descriptor.__doc__))\n",
   "                name=kw,\n",
   "            kwarg_params.append((param, typ, doc))\n",
   "        return arg_params + kwarg_params\n"
  ]
 },
 "367": {
  "name": "typ",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/glyph.py",
  "lineno": "82",
  "column": "12",
  "context": "e_defaults else default\n            )\n            typ = descriptor.property._sphinx_type()\n            arg_params.insert(0, (param, typ, desc",
  "context_lines": "                kind=Parameter.POSITIONAL_OR_KEYWORD,\n                # For positional arg properties, default=None means no default.\n                default=Parameter.empty if no_more_defaults else default\n            )\n            typ = descriptor.property._sphinx_type()\n            arg_params.insert(0, (param, typ, descriptor.__doc__))\n\n        # these are not really useful, and should also really be private, just skip them\n        omissions = {'js_event_callbacks', 'js_property_callbacks', 'subscribed_events'}\n\n        kwarg_params = []\n\n",
  "slicing": [
   "        arg_params = []\n",
   "        no_more_defaults = False\n",
   "        for arg in reversed(cls._args):\n",
   "            descriptor = cls.lookup(arg)\n",
   "            default = descriptor.class_default(cls)\n",
   "            if default is None:\n",
   "                no_more_defaults = True\n",
   "            param = Parameter(\n",
   "                name=arg,\n",
   "                default=Parameter.empty if no_more_defaults else default\n",
   "            typ = descriptor.property._sphinx_type()\n",
   "            arg_params.insert(0, (param, typ, descriptor.__doc__))\n",
   "        omissions = {'js_event_callbacks', 'js_property_callbacks', 'subscribed_events'}\n",
   "        kws = cls.properties() - set(cls._args) - omissions\n",
   "        for kw in kws:\n",
   "            descriptor = cls.lookup(kw)\n",
   "            param = Parameter(\n",
   "                name=kw,\n",
   "                default=descriptor.class_default(cls)\n",
   "            typ = descriptor.property._sphinx_type()\n",
   "            kwarg_params.append((param, typ, descriptor.__doc__))\n",
   "                name=kw,\n",
   "            kwarg_params.append((param, typ, doc))\n",
   "        return arg_params + kwarg_params\n"
  ]
 },
 "368": {
  "name": "descriptor",
  "type": "UnitsSpecPropertyDescriptor",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/glyph.py",
  "lineno": "92",
  "column": "12",
  "context": "s) - omissions\n        for kw in kws:\n            descriptor = cls.lookup(kw)\n            param = Parameter(\n                nam",
  "context_lines": "        omissions = {'js_event_callbacks', 'js_property_callbacks', 'subscribed_events'}\n\n        kwarg_params = []\n\n        kws = cls.properties() - set(cls._args) - omissions\n        for kw in kws:\n            descriptor = cls.lookup(kw)\n            param = Parameter(\n                name=kw,\n                kind=Parameter.KEYWORD_ONLY,\n                default=descriptor.class_default(cls)\n",
  "slicing": [
   "        arg_params = []\n",
   "        no_more_defaults = False\n",
   "        for arg in reversed(cls._args):\n",
   "            descriptor = cls.lookup(arg)\n",
   "            default = descriptor.class_default(cls)\n",
   "            if default is None:\n",
   "                no_more_defaults = True\n",
   "            param = Parameter(\n",
   "                name=arg,\n",
   "                default=Parameter.empty if no_more_defaults else default\n",
   "            typ = descriptor.property._sphinx_type()\n",
   "            arg_params.insert(0, (param, typ, descriptor.__doc__))\n",
   "        omissions = {'js_event_callbacks', 'js_property_callbacks', 'subscribed_events'}\n",
   "        kws = cls.properties() - set(cls._args) - omissions\n",
   "        for kw in kws:\n",
   "            descriptor = cls.lookup(kw)\n",
   "            param = Parameter(\n",
   "                name=kw,\n",
   "                default=descriptor.class_default(cls)\n",
   "            typ = descriptor.property._sphinx_type()\n",
   "            kwarg_params.append((param, typ, descriptor.__doc__))\n",
   "                name=kw,\n",
   "            kwarg_params.append((param, typ, doc))\n",
   "        return arg_params + kwarg_params\n"
  ]
 },
 "369": {
  "name": "typ",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/glyph.py",
  "lineno": "98",
  "column": "12",
  "context": "ptor.class_default(cls)\n            )\n            typ = descriptor.property._sphinx_type()\n            kwarg_params.append((param, typ, descr",
  "context_lines": "                name=kw,\n                kind=Parameter.KEYWORD_ONLY,\n                default=descriptor.class_default(cls)\n            )\n            typ = descriptor.property._sphinx_type()\n            kwarg_params.append((param, typ, descriptor.__doc__))\n\n        for kw, (typ, doc) in cls._extra_kws.items():\n            param = Parameter(\n                name=kw,\n",
  "slicing": [
   "        arg_params = []\n",
   "        no_more_defaults = False\n",
   "        for arg in reversed(cls._args):\n",
   "            descriptor = cls.lookup(arg)\n",
   "            default = descriptor.class_default(cls)\n",
   "            if default is None:\n",
   "                no_more_defaults = True\n",
   "            param = Parameter(\n",
   "                name=arg,\n",
   "                default=Parameter.empty if no_more_defaults else default\n",
   "            typ = descriptor.property._sphinx_type()\n",
   "            arg_params.insert(0, (param, typ, descriptor.__doc__))\n",
   "        omissions = {'js_event_callbacks', 'js_property_callbacks', 'subscribed_events'}\n",
   "        kws = cls.properties() - set(cls._args) - omissions\n",
   "        for kw in kws:\n",
   "            descriptor = cls.lookup(kw)\n",
   "            param = Parameter(\n",
   "                name=kw,\n",
   "                default=descriptor.class_default(cls)\n",
   "            typ = descriptor.property._sphinx_type()\n",
   "            kwarg_params.append((param, typ, descriptor.__doc__))\n",
   "                name=kw,\n",
   "            kwarg_params.append((param, typ, doc))\n",
   "        return arg_params + kwarg_params\n"
  ]
 },
 "370": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/widgets/markups.py",
  "lineno": "83",
  "column": "4",
  "context": "esponds to an HTML ``<p>`` element.\n\n    '''\n\n    __example__ = \"sphinx/source/docs/user_guide/examples/interaction_paragraph.py\"\n\nclass Div(Markup):\n    ''' A block (div) of text.",
  "context_lines": "class Paragraph(Markup):\n    ''' A block (paragraph) of text.\n\n    This Bokeh model corresponds to an HTML ``<p>`` element.\n\n    '''\n\n    __example__ = \"sphinx/source/docs/user_guide/examples/interaction_paragraph.py\"\n\nclass Div(Markup):\n    ''' A block (div) of text.\n\n    This Bokeh model corresponds to an HTML ``<div>`` element.\n\n",
  "slicing": "    __example__ = \"sphinx/source/docs/user_guide/examples/interaction_paragraph.py\"\n"
 },
 "371": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/widgets/markups.py",
  "lineno": "92",
  "column": "4",
  "context": "ponds to an HTML ``<div>`` element.\n\n    '''\n\n    __example__ = \"sphinx/source/docs/user_guide/examples/interaction_div.py\"\n\n    render_as_text = Bool(False, help=\"\"\"\n    Whe",
  "context_lines": "class Div(Markup):\n    ''' A block (div) of text.\n\n    This Bokeh model corresponds to an HTML ``<div>`` element.\n\n    '''\n\n    __example__ = \"sphinx/source/docs/user_guide/examples/interaction_div.py\"\n\n    render_as_text = Bool(False, help=\"\"\"\n    Whether the contents should be rendered as raw text or as interpreted HTML.\n    The default value is ``False``, meaning contents are rendered as HTML.\n",
  "slicing": "    __example__ = \"sphinx/source/docs/user_guide/examples/interaction_div.py\"\n"
 },
 "372": {
  "name": "__example__",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "bokeh/bokeh/models/widgets/markups.py",
  "lineno": "106",
  "column": "4",
  "context": "ponds to an HTML ``<pre>`` element.\n\n    '''\n\n    __example__ = \"sphinx/source/docs/user_guide/examples/interaction_pretext.py\"\n\n#------------------------------------------------",
  "context_lines": "class PreText(Paragraph):\n    ''' A block (paragraph) of pre-formatted text.\n\n    This Bokeh model corresponds to an HTML ``<pre>`` element.\n\n    '''\n\n    __example__ = \"sphinx/source/docs/user_guide/examples/interaction_pretext.py\"\n\n#-----------------------------------------------------------------------------\n# Private API\n#-----------------------------------------------------------------------------\n\n",
  "slicing": "    __example__ = \"sphinx/source/docs/user_guide/examples/interaction_pretext.py\"\n"
 }
}