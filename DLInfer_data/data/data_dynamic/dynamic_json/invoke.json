{
 "1": {
  "name": "func",
  "type": "function",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/tasks.py",
  "lineno": "152",
  "column": "8",
  "context": " a way to get the \"really callable\" spec?\n        func = body if isinstance(body, types.FunctionType) else body.__call__\n        spec = inspect.getargspec(func)\n        ar",
  "context_lines": "        \"\"\"\n        # Handle callable-but-not-function objects\n        # TODO: __call__ exhibits the 'self' arg; do we manually nix 1st result\n        # in argspec, or is there a way to get the \"really callable\" spec?\n        func = body if isinstance(body, types.FunctionType) else body.__call__\n        spec = inspect.getargspec(func)\n        arg_names = spec.args[:]\n        matched_args = [reversed(x) for x in [spec.args, spec.defaults or []]]\n        spec_dict = dict(zip_longest(*matched_args, fillvalue=NO_DEFAULT))\n",
  "slicing": [
   "NO_DEFAULT = object()\n",
   "        aliases = \"\"\n",
   "            aliases = \" ({})\".format(\", \".join(self.aliases))\n",
   "        return \"<Task {!r}{}>\".format(self.name, aliases)\n",
   "            err = \"Task expected a Context as its first arg, got {} instead!\"\n",
   "            raise TypeError(err.format(type(args[0])))\n",
   "        result = self.body(*args, **kwargs)\n",
   "        return result\n",
   "        func = body if isinstance(body, types.FunctionType) else body.__call__\n",
   "        spec = inspect.getargspec(func)\n",
   "        arg_names = spec.args[:]\n",
   "        matched_args = [reversed(x) for x in [spec.args, spec.defaults or []]]\n",
   "        spec_dict = dict(zip_longest(*matched_args, fillvalue=NO_DEFAULT))\n",
   "            context_arg = arg_names.pop(0)\n",
   "        del spec_dict[context_arg]\n",
   "        return arg_names, spec_dict\n",
   "        args, spec_dict = self.argspec(self.body)\n",
   "            positional = []\n",
   "            for name in args:  # Go in defined order, not dict \"order\"\n",
   "                default = spec_dict[name]\n",
   "                if default is NO_DEFAULT:\n",
   "                    positional.append(name)\n",
   "        return positional\n",
   "        opts = {}\n",
   "        opts[\"positional\"] = name in self.positional\n",
   "        opts[\"optional\"] = name in self.optional\n",
   "        if name in self.iterable:\n",
   "            opts[\"kind\"] = list\n",
   "            opts[\"default\"] = default if default is not None else []\n",
   "        if name in self.incrementable:\n",
   "            opts[\"incrementable\"] = True\n",
   "        if \"_\" in name:\n",
   "            opts[\"attr_name\"] = name\n",
   "            name = translate_underscores(name)\n",
   "        names = [name]\n",
   "            for char in name:\n",
   "                if not (char == name or char in taken_names):\n",
   "                    names.append(char)\n",
   "        opts[\"names\"] = names\n",
   "        if default not in (None, NO_DEFAULT):\n",
   "            kind = type(default)\n",
   "            if not (opts[\"optional\"] and kind is bool):\n",
   "                opts[\"kind\"] = kind\n",
   "            opts[\"default\"] = default\n",
   "        if name in self.help:\n",
   "            opts[\"help\"] = self.help[name]\n",
   "        return opts\n",
   "        arg_names, spec_dict = self.argspec(self.body)\n",
   "        tuples = [(x, spec_dict[x]) for x in arg_names]\n",
   "        taken_names = {x[0] for x in tuples}\n",
   "        args = []\n",
   "        for name, default in tuples:\n",
   "            new_arg = Argument(**self.arg_opts(name, default, taken_names))\n",
   "            args.append(new_arg)\n",
   "            taken_names.update(set(new_arg.names))\n",
   "            for i, arg in enumerate(args):\n",
   "                if arg.name == posarg:\n",
   "                    args.insert(0, args.pop(i))\n",
   "        return args\n",
   "    if len(args) == 1 and callable(args[0]) and not isinstance(args[0], Task):\n",
   "        return klass(args[0], **kwargs)\n",
   "    if args:\n",
   "        kwargs[\"pre\"] = args\n",
   "            name=name,\n",
   "            aliases=aliases,\n",
   "            positional=positional,\n",
   "            default=default,\n",
   "        self.args = args or tuple()\n",
   "        return getattr(self.task, name)\n",
   "    return Call(task=task, args=args, kwargs=kwargs)\n"
  ]
 },
 "2": {
  "name": "spec",
  "type": "inspect",
  "class": "imported",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/tasks.py",
  "lineno": "153",
  "column": "8",
  "context": "y, types.FunctionType) else body.__call__\n        spec = inspect.getargspec(func)\n        arg_names = spec.args[:]\n        matched_a",
  "context_lines": "        # Handle callable-but-not-function objects\n        # TODO: __call__ exhibits the 'self' arg; do we manually nix 1st result\n        # in argspec, or is there a way to get the \"really callable\" spec?\n        func = body if isinstance(body, types.FunctionType) else body.__call__\n        spec = inspect.getargspec(func)\n        arg_names = spec.args[:]\n        matched_args = [reversed(x) for x in [spec.args, spec.defaults or []]]\n        spec_dict = dict(zip_longest(*matched_args, fillvalue=NO_DEFAULT))\n        # Pop context argument\n",
  "slicing": [
   "NO_DEFAULT = object()\n",
   "        aliases = \"\"\n",
   "            aliases = \" ({})\".format(\", \".join(self.aliases))\n",
   "        return \"<Task {!r}{}>\".format(self.name, aliases)\n",
   "            err = \"Task expected a Context as its first arg, got {} instead!\"\n",
   "            raise TypeError(err.format(type(args[0])))\n",
   "        result = self.body(*args, **kwargs)\n",
   "        return result\n",
   "        func = body if isinstance(body, types.FunctionType) else body.__call__\n",
   "        spec = inspect.getargspec(func)\n",
   "        arg_names = spec.args[:]\n",
   "        matched_args = [reversed(x) for x in [spec.args, spec.defaults or []]]\n",
   "        spec_dict = dict(zip_longest(*matched_args, fillvalue=NO_DEFAULT))\n",
   "            context_arg = arg_names.pop(0)\n",
   "        del spec_dict[context_arg]\n",
   "        return arg_names, spec_dict\n",
   "        args, spec_dict = self.argspec(self.body)\n",
   "            positional = []\n",
   "            for name in args:  # Go in defined order, not dict \"order\"\n",
   "                default = spec_dict[name]\n",
   "                if default is NO_DEFAULT:\n",
   "                    positional.append(name)\n",
   "        return positional\n",
   "        opts = {}\n",
   "        opts[\"positional\"] = name in self.positional\n",
   "        opts[\"optional\"] = name in self.optional\n",
   "        if name in self.iterable:\n",
   "            opts[\"kind\"] = list\n",
   "            opts[\"default\"] = default if default is not None else []\n",
   "        if name in self.incrementable:\n",
   "            opts[\"incrementable\"] = True\n",
   "        if \"_\" in name:\n",
   "            opts[\"attr_name\"] = name\n",
   "            name = translate_underscores(name)\n",
   "        names = [name]\n",
   "            for char in name:\n",
   "                if not (char == name or char in taken_names):\n",
   "                    names.append(char)\n",
   "        opts[\"names\"] = names\n",
   "        if default not in (None, NO_DEFAULT):\n",
   "            kind = type(default)\n",
   "            if not (opts[\"optional\"] and kind is bool):\n",
   "                opts[\"kind\"] = kind\n",
   "            opts[\"default\"] = default\n",
   "        if name in self.help:\n",
   "            opts[\"help\"] = self.help[name]\n",
   "        return opts\n",
   "        arg_names, spec_dict = self.argspec(self.body)\n",
   "        tuples = [(x, spec_dict[x]) for x in arg_names]\n",
   "        taken_names = {x[0] for x in tuples}\n",
   "        args = []\n",
   "        for name, default in tuples:\n",
   "            new_arg = Argument(**self.arg_opts(name, default, taken_names))\n",
   "            args.append(new_arg)\n",
   "            taken_names.update(set(new_arg.names))\n",
   "            for i, arg in enumerate(args):\n",
   "                if arg.name == posarg:\n",
   "                    args.insert(0, args.pop(i))\n",
   "        return args\n",
   "    if len(args) == 1 and callable(args[0]) and not isinstance(args[0], Task):\n",
   "        return klass(args[0], **kwargs)\n",
   "    if args:\n",
   "        kwargs[\"pre\"] = args\n",
   "            name=name,\n",
   "            aliases=aliases,\n",
   "            positional=positional,\n",
   "            default=default,\n",
   "        self.args = args or tuple()\n",
   "        return getattr(self.task, name)\n",
   "    return Call(task=task, args=args, kwargs=kwargs)\n"
  ]
 },
 "3": {
  "name": "args",
  "type": "list",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/tasks.py",
  "lineno": "167",
  "column": "8",
  "context": "l_implicit_positionals(self, positional):\n        args, spec_dict = self.argspec(self.body)\n        # If positionals is None, everything lacki",
  "context_lines": "            raise TypeError(\"Tasks must have an initial Context argument!\")\n        del spec_dict[context_arg]\n        return arg_names, spec_dict\n\n    def fill_implicit_positionals(self, positional):\n        args, spec_dict = self.argspec(self.body)\n        # If positionals is None, everything lacking a default\n        # value will be automatically considered positional.\n        if positional is None:\n            positional = []\n",
  "slicing": [
   "NO_DEFAULT = object()\n",
   "        aliases = \"\"\n",
   "            aliases = \" ({})\".format(\", \".join(self.aliases))\n",
   "        return \"<Task {!r}{}>\".format(self.name, aliases)\n",
   "            err = \"Task expected a Context as its first arg, got {} instead!\"\n",
   "            raise TypeError(err.format(type(args[0])))\n",
   "        result = self.body(*args, **kwargs)\n",
   "        return result\n",
   "        func = body if isinstance(body, types.FunctionType) else body.__call__\n",
   "        spec = inspect.getargspec(func)\n",
   "        arg_names = spec.args[:]\n",
   "        matched_args = [reversed(x) for x in [spec.args, spec.defaults or []]]\n",
   "        spec_dict = dict(zip_longest(*matched_args, fillvalue=NO_DEFAULT))\n",
   "            context_arg = arg_names.pop(0)\n",
   "        del spec_dict[context_arg]\n",
   "        return arg_names, spec_dict\n",
   "        args, spec_dict = self.argspec(self.body)\n",
   "            positional = []\n",
   "            for name in args:  # Go in defined order, not dict \"order\"\n",
   "                default = spec_dict[name]\n",
   "                if default is NO_DEFAULT:\n",
   "                    positional.append(name)\n",
   "        return positional\n",
   "        opts = {}\n",
   "        opts[\"positional\"] = name in self.positional\n",
   "        opts[\"optional\"] = name in self.optional\n",
   "        if name in self.iterable:\n",
   "            opts[\"kind\"] = list\n",
   "            opts[\"default\"] = default if default is not None else []\n",
   "        if name in self.incrementable:\n",
   "            opts[\"incrementable\"] = True\n",
   "        if \"_\" in name:\n",
   "            opts[\"attr_name\"] = name\n",
   "            name = translate_underscores(name)\n",
   "        names = [name]\n",
   "            for char in name:\n",
   "                if not (char == name or char in taken_names):\n",
   "                    names.append(char)\n",
   "        opts[\"names\"] = names\n",
   "        if default not in (None, NO_DEFAULT):\n",
   "            kind = type(default)\n",
   "            if not (opts[\"optional\"] and kind is bool):\n",
   "                opts[\"kind\"] = kind\n",
   "            opts[\"default\"] = default\n",
   "        if name in self.help:\n",
   "            opts[\"help\"] = self.help[name]\n",
   "        return opts\n",
   "        arg_names, spec_dict = self.argspec(self.body)\n",
   "        tuples = [(x, spec_dict[x]) for x in arg_names]\n",
   "        taken_names = {x[0] for x in tuples}\n",
   "        args = []\n",
   "        for name, default in tuples:\n",
   "            new_arg = Argument(**self.arg_opts(name, default, taken_names))\n",
   "            args.append(new_arg)\n",
   "            taken_names.update(set(new_arg.names))\n",
   "            for i, arg in enumerate(args):\n",
   "                if arg.name == posarg:\n",
   "                    args.insert(0, args.pop(i))\n",
   "        return args\n",
   "    if len(args) == 1 and callable(args[0]) and not isinstance(args[0], Task):\n",
   "        return klass(args[0], **kwargs)\n",
   "    if args:\n",
   "        kwargs[\"pre\"] = args\n",
   "            name=name,\n",
   "            aliases=aliases,\n",
   "            positional=positional,\n",
   "            default=default,\n",
   "        self.args = args or tuple()\n",
   "        return getattr(self.task, name)\n",
   "    return Call(task=task, args=args, kwargs=kwargs)\n"
  ]
 },
 "4": {
  "name": "klass",
  "type": "type",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/tasks.py",
  "lineno": "309",
  "column": "4",
  "context": "Added the ``klass`` keyword argument.\n    \"\"\"\n    klass = kwargs.pop(\"klass\", Task)\n    # @task -- no options were (probably) given.\n ",
  "context_lines": "    .. versionadded:: 1.0\n    .. versionchanged:: 1.1\n        Added the ``klass`` keyword argument.\n    \"\"\"\n    klass = kwargs.pop(\"klass\", Task)\n    # @task -- no options were (probably) given.\n    if len(args) == 1 and callable(args[0]) and not isinstance(args[0], Task):\n        return klass(args[0], **kwargs)\n    # @task(pre, tasks, here)\n",
  "slicing": [
   "NO_DEFAULT = object()\n",
   "        aliases = \"\"\n",
   "            aliases = \" ({})\".format(\", \".join(self.aliases))\n",
   "        return \"<Task {!r}{}>\".format(self.name, aliases)\n",
   "            err = \"Task expected a Context as its first arg, got {} instead!\"\n",
   "            raise TypeError(err.format(type(args[0])))\n",
   "        result = self.body(*args, **kwargs)\n",
   "        return result\n",
   "        func = body if isinstance(body, types.FunctionType) else body.__call__\n",
   "        spec = inspect.getargspec(func)\n",
   "        arg_names = spec.args[:]\n",
   "        matched_args = [reversed(x) for x in [spec.args, spec.defaults or []]]\n",
   "        spec_dict = dict(zip_longest(*matched_args, fillvalue=NO_DEFAULT))\n",
   "            context_arg = arg_names.pop(0)\n",
   "        del spec_dict[context_arg]\n",
   "        return arg_names, spec_dict\n",
   "        args, spec_dict = self.argspec(self.body)\n",
   "            positional = []\n",
   "            for name in args:  # Go in defined order, not dict \"order\"\n",
   "                default = spec_dict[name]\n",
   "                if default is NO_DEFAULT:\n",
   "                    positional.append(name)\n",
   "        return positional\n",
   "        opts = {}\n",
   "        opts[\"positional\"] = name in self.positional\n",
   "        opts[\"optional\"] = name in self.optional\n",
   "        if name in self.iterable:\n",
   "            opts[\"kind\"] = list\n",
   "            opts[\"default\"] = default if default is not None else []\n",
   "        if name in self.incrementable:\n",
   "            opts[\"incrementable\"] = True\n",
   "        if \"_\" in name:\n",
   "            opts[\"attr_name\"] = name\n",
   "            name = translate_underscores(name)\n",
   "        names = [name]\n",
   "            for char in name:\n",
   "                if not (char == name or char in taken_names):\n",
   "                    names.append(char)\n",
   "        opts[\"names\"] = names\n",
   "        if default not in (None, NO_DEFAULT):\n",
   "            kind = type(default)\n",
   "            if not (opts[\"optional\"] and kind is bool):\n",
   "                opts[\"kind\"] = kind\n",
   "            opts[\"default\"] = default\n",
   "        if name in self.help:\n",
   "            opts[\"help\"] = self.help[name]\n",
   "        return opts\n",
   "        arg_names, spec_dict = self.argspec(self.body)\n",
   "        tuples = [(x, spec_dict[x]) for x in arg_names]\n",
   "        taken_names = {x[0] for x in tuples}\n",
   "        args = []\n",
   "        for name, default in tuples:\n",
   "            new_arg = Argument(**self.arg_opts(name, default, taken_names))\n",
   "            args.append(new_arg)\n",
   "            taken_names.update(set(new_arg.names))\n",
   "        for posarg in reversed(self.positional):\n",
   "            for i, arg in enumerate(args):\n",
   "                if arg.name == posarg:\n",
   "                    args.insert(0, args.pop(i))\n",
   "        return args\n",
   "    klass = kwargs.pop(\"klass\", Task)\n",
   "    if len(args) == 1 and callable(args[0]) and not isinstance(args[0], Task):\n",
   "        return klass(args[0], **kwargs)\n",
   "    if args:\n",
   "        kwargs[\"pre\"] = args\n",
   "    name = kwargs.pop(\"name\", None)\n",
   "    aliases = kwargs.pop(\"aliases\", ())\n",
   "    positional = kwargs.pop(\"positional\", None)\n",
   "    optional = tuple(kwargs.pop(\"optional\", ()))\n",
   "    iterable = kwargs.pop(\"iterable\", None)\n",
   "    incrementable = kwargs.pop(\"incrementable\", None)\n",
   "    default = kwargs.pop(\"default\", False)\n",
   "    auto_shortflags = kwargs.pop(\"auto_shortflags\", True)\n",
   "    help = kwargs.pop(\"help\", {})\n",
   "    pre = kwargs.pop(\"pre\", [])\n",
   "    post = kwargs.pop(\"post\", [])\n",
   "    autoprint = kwargs.pop(\"autoprint\", False)\n",
   "        obj = klass(\n",
   "            obj,\n",
   "            name=name,\n",
   "            aliases=aliases,\n",
   "            positional=positional,\n",
   "            optional=optional,\n",
   "            iterable=iterable,\n",
   "            incrementable=incrementable,\n",
   "            default=default,\n",
   "            auto_shortflags=auto_shortflags,\n",
   "            help=help,\n",
   "            pre=pre,\n",
   "            post=post,\n",
   "            autoprint=autoprint,\n",
   "        return obj\n",
   "        self.args = args or tuple()\n",
   "        return getattr(self.task, name)\n",
   "        return klass(**data)\n",
   "    return Call(task=task, args=args, kwargs=kwargs)\n"
  ]
 },
 "5": {
  "name": "name",
  "type": "str|NoneType",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/tasks.py",
  "lineno": "324",
  "column": "4",
  "context": "metime & see\n    # what, if anything, breaks.\n    name = kwargs.pop(\"name\", None)\n    aliases = kwargs.pop(\"aliases\", ())\n    positi",
  "context_lines": "    # @task(options)\n    # TODO: why the heck did we originally do this in this manner instead of\n    # simply delegating to Task?! Let's just remove all this sometime & see\n    # what, if anything, breaks.\n    name = kwargs.pop(\"name\", None)\n    aliases = kwargs.pop(\"aliases\", ())\n    positional = kwargs.pop(\"positional\", None)\n    optional = tuple(kwargs.pop(\"optional\", ()))\n    iterable = kwargs.pop(\"iterable\", None)\n",
  "slicing": [
   "NO_DEFAULT = object()\n",
   "        aliases = \"\"\n",
   "            aliases = \" ({})\".format(\", \".join(self.aliases))\n",
   "        return \"<Task {!r}{}>\".format(self.name, aliases)\n",
   "            err = \"Task expected a Context as its first arg, got {} instead!\"\n",
   "            raise TypeError(err.format(type(args[0])))\n",
   "        result = self.body(*args, **kwargs)\n",
   "        return result\n",
   "        func = body if isinstance(body, types.FunctionType) else body.__call__\n",
   "        spec = inspect.getargspec(func)\n",
   "        arg_names = spec.args[:]\n",
   "        matched_args = [reversed(x) for x in [spec.args, spec.defaults or []]]\n",
   "        spec_dict = dict(zip_longest(*matched_args, fillvalue=NO_DEFAULT))\n",
   "            context_arg = arg_names.pop(0)\n",
   "        del spec_dict[context_arg]\n",
   "        return arg_names, spec_dict\n",
   "        args, spec_dict = self.argspec(self.body)\n",
   "            positional = []\n",
   "            for name in args:  # Go in defined order, not dict \"order\"\n",
   "                default = spec_dict[name]\n",
   "                if default is NO_DEFAULT:\n",
   "                    positional.append(name)\n",
   "        return positional\n",
   "        opts = {}\n",
   "        opts[\"positional\"] = name in self.positional\n",
   "        opts[\"optional\"] = name in self.optional\n",
   "        if name in self.iterable:\n",
   "            opts[\"kind\"] = list\n",
   "            opts[\"default\"] = default if default is not None else []\n",
   "        if name in self.incrementable:\n",
   "            opts[\"incrementable\"] = True\n",
   "        if \"_\" in name:\n",
   "            opts[\"attr_name\"] = name\n",
   "            name = translate_underscores(name)\n",
   "        names = [name]\n",
   "            for char in name:\n",
   "                if not (char == name or char in taken_names):\n",
   "                    names.append(char)\n",
   "        opts[\"names\"] = names\n",
   "        if default not in (None, NO_DEFAULT):\n",
   "            kind = type(default)\n",
   "            if not (opts[\"optional\"] and kind is bool):\n",
   "                opts[\"kind\"] = kind\n",
   "            opts[\"default\"] = default\n",
   "        if name in self.help:\n",
   "            opts[\"help\"] = self.help[name]\n",
   "        return opts\n",
   "        arg_names, spec_dict = self.argspec(self.body)\n",
   "        tuples = [(x, spec_dict[x]) for x in arg_names]\n",
   "        taken_names = {x[0] for x in tuples}\n",
   "        args = []\n",
   "        for name, default in tuples:\n",
   "            new_arg = Argument(**self.arg_opts(name, default, taken_names))\n",
   "            args.append(new_arg)\n",
   "            taken_names.update(set(new_arg.names))\n",
   "        for posarg in reversed(self.positional):\n",
   "            for i, arg in enumerate(args):\n",
   "                if arg.name == posarg:\n",
   "                    args.insert(0, args.pop(i))\n",
   "        return args\n",
   "    klass = kwargs.pop(\"klass\", Task)\n",
   "    if len(args) == 1 and callable(args[0]) and not isinstance(args[0], Task):\n",
   "        return klass(args[0], **kwargs)\n",
   "    if args:\n",
   "        kwargs[\"pre\"] = args\n",
   "    name = kwargs.pop(\"name\", None)\n",
   "    aliases = kwargs.pop(\"aliases\", ())\n",
   "    positional = kwargs.pop(\"positional\", None)\n",
   "    optional = tuple(kwargs.pop(\"optional\", ()))\n",
   "    iterable = kwargs.pop(\"iterable\", None)\n",
   "    incrementable = kwargs.pop(\"incrementable\", None)\n",
   "    default = kwargs.pop(\"default\", False)\n",
   "    auto_shortflags = kwargs.pop(\"auto_shortflags\", True)\n",
   "    help = kwargs.pop(\"help\", {})\n",
   "    pre = kwargs.pop(\"pre\", [])\n",
   "    post = kwargs.pop(\"post\", [])\n",
   "    autoprint = kwargs.pop(\"autoprint\", False)\n",
   "        obj = klass(\n",
   "            obj,\n",
   "            name=name,\n",
   "            aliases=aliases,\n",
   "            positional=positional,\n",
   "            optional=optional,\n",
   "            iterable=iterable,\n",
   "            incrementable=incrementable,\n",
   "            default=default,\n",
   "            auto_shortflags=auto_shortflags,\n",
   "            help=help,\n",
   "            pre=pre,\n",
   "            post=post,\n",
   "            autoprint=autoprint,\n",
   "        return obj\n",
   "        self.args = args or tuple()\n",
   "        return getattr(self.task, name)\n",
   "        return klass(**data)\n",
   "    return Call(task=task, args=args, kwargs=kwargs)\n"
  ]
 },
 "6": {
  "name": "aliases",
  "type": "list|tuple",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/tasks.py",
  "lineno": "325",
  "column": "4",
  "context": ", breaks.\n    name = kwargs.pop(\"name\", None)\n    aliases = kwargs.pop(\"aliases\", ())\n    positional = kwargs.pop(\"positional\", None)\n  ",
  "context_lines": "    # TODO: why the heck did we originally do this in this manner instead of\n    # simply delegating to Task?! Let's just remove all this sometime & see\n    # what, if anything, breaks.\n    name = kwargs.pop(\"name\", None)\n    aliases = kwargs.pop(\"aliases\", ())\n    positional = kwargs.pop(\"positional\", None)\n    optional = tuple(kwargs.pop(\"optional\", ()))\n    iterable = kwargs.pop(\"iterable\", None)\n    incrementable = kwargs.pop(\"incrementable\", None)\n",
  "slicing": [
   "NO_DEFAULT = object()\n",
   "        aliases = \"\"\n",
   "            aliases = \" ({})\".format(\", \".join(self.aliases))\n",
   "        return \"<Task {!r}{}>\".format(self.name, aliases)\n",
   "            err = \"Task expected a Context as its first arg, got {} instead!\"\n",
   "            raise TypeError(err.format(type(args[0])))\n",
   "        result = self.body(*args, **kwargs)\n",
   "        return result\n",
   "        func = body if isinstance(body, types.FunctionType) else body.__call__\n",
   "        spec = inspect.getargspec(func)\n",
   "        arg_names = spec.args[:]\n",
   "        matched_args = [reversed(x) for x in [spec.args, spec.defaults or []]]\n",
   "        spec_dict = dict(zip_longest(*matched_args, fillvalue=NO_DEFAULT))\n",
   "            context_arg = arg_names.pop(0)\n",
   "        del spec_dict[context_arg]\n",
   "        return arg_names, spec_dict\n",
   "        args, spec_dict = self.argspec(self.body)\n",
   "            positional = []\n",
   "            for name in args:  # Go in defined order, not dict \"order\"\n",
   "                default = spec_dict[name]\n",
   "                if default is NO_DEFAULT:\n",
   "                    positional.append(name)\n",
   "        return positional\n",
   "        opts = {}\n",
   "        opts[\"positional\"] = name in self.positional\n",
   "        opts[\"optional\"] = name in self.optional\n",
   "        if name in self.iterable:\n",
   "            opts[\"kind\"] = list\n",
   "            opts[\"default\"] = default if default is not None else []\n",
   "        if name in self.incrementable:\n",
   "            opts[\"incrementable\"] = True\n",
   "        if \"_\" in name:\n",
   "            opts[\"attr_name\"] = name\n",
   "            name = translate_underscores(name)\n",
   "        names = [name]\n",
   "            for char in name:\n",
   "                if not (char == name or char in taken_names):\n",
   "                    names.append(char)\n",
   "        opts[\"names\"] = names\n",
   "        if default not in (None, NO_DEFAULT):\n",
   "            kind = type(default)\n",
   "            if not (opts[\"optional\"] and kind is bool):\n",
   "                opts[\"kind\"] = kind\n",
   "            opts[\"default\"] = default\n",
   "        if name in self.help:\n",
   "            opts[\"help\"] = self.help[name]\n",
   "        return opts\n",
   "        arg_names, spec_dict = self.argspec(self.body)\n",
   "        tuples = [(x, spec_dict[x]) for x in arg_names]\n",
   "        taken_names = {x[0] for x in tuples}\n",
   "        args = []\n",
   "        for name, default in tuples:\n",
   "            new_arg = Argument(**self.arg_opts(name, default, taken_names))\n",
   "            args.append(new_arg)\n",
   "            taken_names.update(set(new_arg.names))\n",
   "        for posarg in reversed(self.positional):\n",
   "            for i, arg in enumerate(args):\n",
   "                if arg.name == posarg:\n",
   "                    args.insert(0, args.pop(i))\n",
   "        return args\n",
   "    klass = kwargs.pop(\"klass\", Task)\n",
   "    if len(args) == 1 and callable(args[0]) and not isinstance(args[0], Task):\n",
   "        return klass(args[0], **kwargs)\n",
   "    if args:\n",
   "        kwargs[\"pre\"] = args\n",
   "    name = kwargs.pop(\"name\", None)\n",
   "    aliases = kwargs.pop(\"aliases\", ())\n",
   "    positional = kwargs.pop(\"positional\", None)\n",
   "    optional = tuple(kwargs.pop(\"optional\", ()))\n",
   "    iterable = kwargs.pop(\"iterable\", None)\n",
   "    incrementable = kwargs.pop(\"incrementable\", None)\n",
   "    default = kwargs.pop(\"default\", False)\n",
   "    auto_shortflags = kwargs.pop(\"auto_shortflags\", True)\n",
   "    help = kwargs.pop(\"help\", {})\n",
   "    pre = kwargs.pop(\"pre\", [])\n",
   "    post = kwargs.pop(\"post\", [])\n",
   "    autoprint = kwargs.pop(\"autoprint\", False)\n",
   "        obj = klass(\n",
   "            obj,\n",
   "            name=name,\n",
   "            aliases=aliases,\n",
   "            positional=positional,\n",
   "            optional=optional,\n",
   "            iterable=iterable,\n",
   "            incrementable=incrementable,\n",
   "            default=default,\n",
   "            auto_shortflags=auto_shortflags,\n",
   "            help=help,\n",
   "            pre=pre,\n",
   "            post=post,\n",
   "            autoprint=autoprint,\n",
   "        return obj\n",
   "        self.args = args or tuple()\n",
   "        return getattr(self.task, name)\n",
   "        return klass(**data)\n",
   "    return Call(task=task, args=args, kwargs=kwargs)\n"
  ]
 },
 "7": {
  "name": "positional",
  "type": "list|NoneType",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/tasks.py",
  "lineno": "326",
  "column": "4",
  "context": "None)\n    aliases = kwargs.pop(\"aliases\", ())\n    positional = kwargs.pop(\"positional\", None)\n    optional = tuple(kwargs.pop(\"optional\", ()))\n ",
  "context_lines": "    # simply delegating to Task?! Let's just remove all this sometime & see\n    # what, if anything, breaks.\n    name = kwargs.pop(\"name\", None)\n    aliases = kwargs.pop(\"aliases\", ())\n    positional = kwargs.pop(\"positional\", None)\n    optional = tuple(kwargs.pop(\"optional\", ()))\n    iterable = kwargs.pop(\"iterable\", None)\n    incrementable = kwargs.pop(\"incrementable\", None)\n    default = kwargs.pop(\"default\", False)\n",
  "slicing": [
   "NO_DEFAULT = object()\n",
   "        aliases = \"\"\n",
   "            aliases = \" ({})\".format(\", \".join(self.aliases))\n",
   "        return \"<Task {!r}{}>\".format(self.name, aliases)\n",
   "            err = \"Task expected a Context as its first arg, got {} instead!\"\n",
   "            raise TypeError(err.format(type(args[0])))\n",
   "        result = self.body(*args, **kwargs)\n",
   "        return result\n",
   "        func = body if isinstance(body, types.FunctionType) else body.__call__\n",
   "        spec = inspect.getargspec(func)\n",
   "        arg_names = spec.args[:]\n",
   "        matched_args = [reversed(x) for x in [spec.args, spec.defaults or []]]\n",
   "        spec_dict = dict(zip_longest(*matched_args, fillvalue=NO_DEFAULT))\n",
   "            context_arg = arg_names.pop(0)\n",
   "        del spec_dict[context_arg]\n",
   "        return arg_names, spec_dict\n",
   "        args, spec_dict = self.argspec(self.body)\n",
   "            positional = []\n",
   "            for name in args:  # Go in defined order, not dict \"order\"\n",
   "                default = spec_dict[name]\n",
   "                if default is NO_DEFAULT:\n",
   "                    positional.append(name)\n",
   "        return positional\n",
   "        opts = {}\n",
   "        opts[\"positional\"] = name in self.positional\n",
   "        opts[\"optional\"] = name in self.optional\n",
   "        if name in self.iterable:\n",
   "            opts[\"kind\"] = list\n",
   "            opts[\"default\"] = default if default is not None else []\n",
   "        if name in self.incrementable:\n",
   "            opts[\"incrementable\"] = True\n",
   "        if \"_\" in name:\n",
   "            opts[\"attr_name\"] = name\n",
   "            name = translate_underscores(name)\n",
   "        names = [name]\n",
   "            for char in name:\n",
   "                if not (char == name or char in taken_names):\n",
   "                    names.append(char)\n",
   "        opts[\"names\"] = names\n",
   "        if default not in (None, NO_DEFAULT):\n",
   "            kind = type(default)\n",
   "            if not (opts[\"optional\"] and kind is bool):\n",
   "                opts[\"kind\"] = kind\n",
   "            opts[\"default\"] = default\n",
   "        if name in self.help:\n",
   "            opts[\"help\"] = self.help[name]\n",
   "        return opts\n",
   "        arg_names, spec_dict = self.argspec(self.body)\n",
   "        tuples = [(x, spec_dict[x]) for x in arg_names]\n",
   "        taken_names = {x[0] for x in tuples}\n",
   "        args = []\n",
   "        for name, default in tuples:\n",
   "            new_arg = Argument(**self.arg_opts(name, default, taken_names))\n",
   "            args.append(new_arg)\n",
   "            taken_names.update(set(new_arg.names))\n",
   "        for posarg in reversed(self.positional):\n",
   "            for i, arg in enumerate(args):\n",
   "                if arg.name == posarg:\n",
   "                    args.insert(0, args.pop(i))\n",
   "        return args\n",
   "    klass = kwargs.pop(\"klass\", Task)\n",
   "    if len(args) == 1 and callable(args[0]) and not isinstance(args[0], Task):\n",
   "        return klass(args[0], **kwargs)\n",
   "    if args:\n",
   "        kwargs[\"pre\"] = args\n",
   "    name = kwargs.pop(\"name\", None)\n",
   "    aliases = kwargs.pop(\"aliases\", ())\n",
   "    positional = kwargs.pop(\"positional\", None)\n",
   "    optional = tuple(kwargs.pop(\"optional\", ()))\n",
   "    iterable = kwargs.pop(\"iterable\", None)\n",
   "    incrementable = kwargs.pop(\"incrementable\", None)\n",
   "    default = kwargs.pop(\"default\", False)\n",
   "    auto_shortflags = kwargs.pop(\"auto_shortflags\", True)\n",
   "    help = kwargs.pop(\"help\", {})\n",
   "    pre = kwargs.pop(\"pre\", [])\n",
   "    post = kwargs.pop(\"post\", [])\n",
   "    autoprint = kwargs.pop(\"autoprint\", False)\n",
   "        obj = klass(\n",
   "            obj,\n",
   "            name=name,\n",
   "            aliases=aliases,\n",
   "            positional=positional,\n",
   "            optional=optional,\n",
   "            iterable=iterable,\n",
   "            incrementable=incrementable,\n",
   "            default=default,\n",
   "            auto_shortflags=auto_shortflags,\n",
   "            help=help,\n",
   "            pre=pre,\n",
   "            post=post,\n",
   "            autoprint=autoprint,\n",
   "        return obj\n",
   "        self.args = args or tuple()\n",
   "        return getattr(self.task, name)\n",
   "        return klass(**data)\n",
   "    return Call(task=task, args=args, kwargs=kwargs)\n"
  ]
 },
 "8": {
  "name": "iterable",
  "type": "list|NoneType",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/tasks.py",
  "lineno": "328",
  "column": "4",
  "context": " optional = tuple(kwargs.pop(\"optional\", ()))\n    iterable = kwargs.pop(\"iterable\", None)\n    incrementable = kwargs.pop(\"incrementable\", No",
  "context_lines": "    name = kwargs.pop(\"name\", None)\n    aliases = kwargs.pop(\"aliases\", ())\n    positional = kwargs.pop(\"positional\", None)\n    optional = tuple(kwargs.pop(\"optional\", ()))\n    iterable = kwargs.pop(\"iterable\", None)\n    incrementable = kwargs.pop(\"incrementable\", None)\n    default = kwargs.pop(\"default\", False)\n    auto_shortflags = kwargs.pop(\"auto_shortflags\", True)\n    help = kwargs.pop(\"help\", {})\n",
  "slicing": [
   "NO_DEFAULT = object()\n",
   "        aliases = \"\"\n",
   "            aliases = \" ({})\".format(\", \".join(self.aliases))\n",
   "        return \"<Task {!r}{}>\".format(self.name, aliases)\n",
   "            err = \"Task expected a Context as its first arg, got {} instead!\"\n",
   "            raise TypeError(err.format(type(args[0])))\n",
   "        result = self.body(*args, **kwargs)\n",
   "        return result\n",
   "        func = body if isinstance(body, types.FunctionType) else body.__call__\n",
   "        spec = inspect.getargspec(func)\n",
   "        arg_names = spec.args[:]\n",
   "        matched_args = [reversed(x) for x in [spec.args, spec.defaults or []]]\n",
   "        spec_dict = dict(zip_longest(*matched_args, fillvalue=NO_DEFAULT))\n",
   "            context_arg = arg_names.pop(0)\n",
   "        del spec_dict[context_arg]\n",
   "        return arg_names, spec_dict\n",
   "        args, spec_dict = self.argspec(self.body)\n",
   "            positional = []\n",
   "            for name in args:  # Go in defined order, not dict \"order\"\n",
   "                default = spec_dict[name]\n",
   "                if default is NO_DEFAULT:\n",
   "                    positional.append(name)\n",
   "        return positional\n",
   "        opts = {}\n",
   "        opts[\"positional\"] = name in self.positional\n",
   "        opts[\"optional\"] = name in self.optional\n",
   "        if name in self.iterable:\n",
   "            opts[\"kind\"] = list\n",
   "            opts[\"default\"] = default if default is not None else []\n",
   "        if name in self.incrementable:\n",
   "            opts[\"incrementable\"] = True\n",
   "        if \"_\" in name:\n",
   "            opts[\"attr_name\"] = name\n",
   "            name = translate_underscores(name)\n",
   "        names = [name]\n",
   "            for char in name:\n",
   "                if not (char == name or char in taken_names):\n",
   "                    names.append(char)\n",
   "        opts[\"names\"] = names\n",
   "        if default not in (None, NO_DEFAULT):\n",
   "            kind = type(default)\n",
   "            if not (opts[\"optional\"] and kind is bool):\n",
   "                opts[\"kind\"] = kind\n",
   "            opts[\"default\"] = default\n",
   "        if name in self.help:\n",
   "            opts[\"help\"] = self.help[name]\n",
   "        return opts\n",
   "        arg_names, spec_dict = self.argspec(self.body)\n",
   "        tuples = [(x, spec_dict[x]) for x in arg_names]\n",
   "        taken_names = {x[0] for x in tuples}\n",
   "        args = []\n",
   "        for name, default in tuples:\n",
   "            new_arg = Argument(**self.arg_opts(name, default, taken_names))\n",
   "            args.append(new_arg)\n",
   "            taken_names.update(set(new_arg.names))\n",
   "        for posarg in reversed(self.positional):\n",
   "            for i, arg in enumerate(args):\n",
   "                if arg.name == posarg:\n",
   "                    args.insert(0, args.pop(i))\n",
   "        return args\n",
   "    klass = kwargs.pop(\"klass\", Task)\n",
   "    if len(args) == 1 and callable(args[0]) and not isinstance(args[0], Task):\n",
   "        return klass(args[0], **kwargs)\n",
   "    if args:\n",
   "        kwargs[\"pre\"] = args\n",
   "    name = kwargs.pop(\"name\", None)\n",
   "    aliases = kwargs.pop(\"aliases\", ())\n",
   "    positional = kwargs.pop(\"positional\", None)\n",
   "    optional = tuple(kwargs.pop(\"optional\", ()))\n",
   "    iterable = kwargs.pop(\"iterable\", None)\n",
   "    incrementable = kwargs.pop(\"incrementable\", None)\n",
   "    default = kwargs.pop(\"default\", False)\n",
   "    auto_shortflags = kwargs.pop(\"auto_shortflags\", True)\n",
   "    help = kwargs.pop(\"help\", {})\n",
   "    pre = kwargs.pop(\"pre\", [])\n",
   "    post = kwargs.pop(\"post\", [])\n",
   "    autoprint = kwargs.pop(\"autoprint\", False)\n",
   "        obj = klass(\n",
   "            obj,\n",
   "            name=name,\n",
   "            aliases=aliases,\n",
   "            positional=positional,\n",
   "            optional=optional,\n",
   "            iterable=iterable,\n",
   "            incrementable=incrementable,\n",
   "            default=default,\n",
   "            auto_shortflags=auto_shortflags,\n",
   "            help=help,\n",
   "            pre=pre,\n",
   "            post=post,\n",
   "            autoprint=autoprint,\n",
   "        return obj\n",
   "        self.args = args or tuple()\n",
   "        return getattr(self.task, name)\n",
   "        return klass(**data)\n",
   "    return Call(task=task, args=args, kwargs=kwargs)\n"
  ]
 },
 "9": {
  "name": "incrementable",
  "type": "list|NoneType",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/tasks.py",
  "lineno": "329",
  "column": "4",
  "context": ")\n    iterable = kwargs.pop(\"iterable\", None)\n    incrementable = kwargs.pop(\"incrementable\", None)\n    default = kwargs.pop(\"default\", False)\n    aut",
  "context_lines": "    aliases = kwargs.pop(\"aliases\", ())\n    positional = kwargs.pop(\"positional\", None)\n    optional = tuple(kwargs.pop(\"optional\", ()))\n    iterable = kwargs.pop(\"iterable\", None)\n    incrementable = kwargs.pop(\"incrementable\", None)\n    default = kwargs.pop(\"default\", False)\n    auto_shortflags = kwargs.pop(\"auto_shortflags\", True)\n    help = kwargs.pop(\"help\", {})\n    pre = kwargs.pop(\"pre\", [])\n",
  "slicing": [
   "NO_DEFAULT = object()\n",
   "        aliases = \"\"\n",
   "            aliases = \" ({})\".format(\", \".join(self.aliases))\n",
   "        return \"<Task {!r}{}>\".format(self.name, aliases)\n",
   "            err = \"Task expected a Context as its first arg, got {} instead!\"\n",
   "            raise TypeError(err.format(type(args[0])))\n",
   "        result = self.body(*args, **kwargs)\n",
   "        return result\n",
   "        func = body if isinstance(body, types.FunctionType) else body.__call__\n",
   "        spec = inspect.getargspec(func)\n",
   "        arg_names = spec.args[:]\n",
   "        matched_args = [reversed(x) for x in [spec.args, spec.defaults or []]]\n",
   "        spec_dict = dict(zip_longest(*matched_args, fillvalue=NO_DEFAULT))\n",
   "            context_arg = arg_names.pop(0)\n",
   "        del spec_dict[context_arg]\n",
   "        return arg_names, spec_dict\n",
   "        args, spec_dict = self.argspec(self.body)\n",
   "            positional = []\n",
   "            for name in args:  # Go in defined order, not dict \"order\"\n",
   "                default = spec_dict[name]\n",
   "                if default is NO_DEFAULT:\n",
   "                    positional.append(name)\n",
   "        return positional\n",
   "        opts = {}\n",
   "        opts[\"positional\"] = name in self.positional\n",
   "        opts[\"optional\"] = name in self.optional\n",
   "        if name in self.iterable:\n",
   "            opts[\"kind\"] = list\n",
   "            opts[\"default\"] = default if default is not None else []\n",
   "        if name in self.incrementable:\n",
   "            opts[\"incrementable\"] = True\n",
   "        if \"_\" in name:\n",
   "            opts[\"attr_name\"] = name\n",
   "            name = translate_underscores(name)\n",
   "        names = [name]\n",
   "            for char in name:\n",
   "                if not (char == name or char in taken_names):\n",
   "                    names.append(char)\n",
   "        opts[\"names\"] = names\n",
   "        if default not in (None, NO_DEFAULT):\n",
   "            kind = type(default)\n",
   "            if not (opts[\"optional\"] and kind is bool):\n",
   "                opts[\"kind\"] = kind\n",
   "            opts[\"default\"] = default\n",
   "        if name in self.help:\n",
   "            opts[\"help\"] = self.help[name]\n",
   "        return opts\n",
   "        arg_names, spec_dict = self.argspec(self.body)\n",
   "        tuples = [(x, spec_dict[x]) for x in arg_names]\n",
   "        taken_names = {x[0] for x in tuples}\n",
   "        args = []\n",
   "        for name, default in tuples:\n",
   "            new_arg = Argument(**self.arg_opts(name, default, taken_names))\n",
   "            args.append(new_arg)\n",
   "            taken_names.update(set(new_arg.names))\n",
   "        for posarg in reversed(self.positional):\n",
   "            for i, arg in enumerate(args):\n",
   "                if arg.name == posarg:\n",
   "                    args.insert(0, args.pop(i))\n",
   "        return args\n",
   "    klass = kwargs.pop(\"klass\", Task)\n",
   "    if len(args) == 1 and callable(args[0]) and not isinstance(args[0], Task):\n",
   "        return klass(args[0], **kwargs)\n",
   "    if args:\n",
   "        kwargs[\"pre\"] = args\n",
   "    name = kwargs.pop(\"name\", None)\n",
   "    aliases = kwargs.pop(\"aliases\", ())\n",
   "    positional = kwargs.pop(\"positional\", None)\n",
   "    optional = tuple(kwargs.pop(\"optional\", ()))\n",
   "    iterable = kwargs.pop(\"iterable\", None)\n",
   "    incrementable = kwargs.pop(\"incrementable\", None)\n",
   "    default = kwargs.pop(\"default\", False)\n",
   "    auto_shortflags = kwargs.pop(\"auto_shortflags\", True)\n",
   "    help = kwargs.pop(\"help\", {})\n",
   "    pre = kwargs.pop(\"pre\", [])\n",
   "    post = kwargs.pop(\"post\", [])\n",
   "    autoprint = kwargs.pop(\"autoprint\", False)\n",
   "        obj = klass(\n",
   "            obj,\n",
   "            name=name,\n",
   "            aliases=aliases,\n",
   "            positional=positional,\n",
   "            optional=optional,\n",
   "            iterable=iterable,\n",
   "            incrementable=incrementable,\n",
   "            default=default,\n",
   "            auto_shortflags=auto_shortflags,\n",
   "            help=help,\n",
   "            pre=pre,\n",
   "            post=post,\n",
   "            autoprint=autoprint,\n",
   "        return obj\n",
   "        self.args = args or tuple()\n",
   "        return getattr(self.task, name)\n",
   "        return klass(**data)\n",
   "    return Call(task=task, args=args, kwargs=kwargs)\n"
  ]
 },
 "10": {
  "name": "default",
  "type": "bool",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/tasks.py",
  "lineno": "330",
  "column": "4",
  "context": "ementable = kwargs.pop(\"incrementable\", None)\n    default = kwargs.pop(\"default\", False)\n    auto_shortflags = kwargs.pop(\"auto_shortflags\"",
  "context_lines": "    positional = kwargs.pop(\"positional\", None)\n    optional = tuple(kwargs.pop(\"optional\", ()))\n    iterable = kwargs.pop(\"iterable\", None)\n    incrementable = kwargs.pop(\"incrementable\", None)\n    default = kwargs.pop(\"default\", False)\n    auto_shortflags = kwargs.pop(\"auto_shortflags\", True)\n    help = kwargs.pop(\"help\", {})\n    pre = kwargs.pop(\"pre\", [])\n    post = kwargs.pop(\"post\", [])\n",
  "slicing": [
   "NO_DEFAULT = object()\n",
   "        aliases = \"\"\n",
   "            aliases = \" ({})\".format(\", \".join(self.aliases))\n",
   "        return \"<Task {!r}{}>\".format(self.name, aliases)\n",
   "            err = \"Task expected a Context as its first arg, got {} instead!\"\n",
   "            raise TypeError(err.format(type(args[0])))\n",
   "        result = self.body(*args, **kwargs)\n",
   "        return result\n",
   "        func = body if isinstance(body, types.FunctionType) else body.__call__\n",
   "        spec = inspect.getargspec(func)\n",
   "        arg_names = spec.args[:]\n",
   "        matched_args = [reversed(x) for x in [spec.args, spec.defaults or []]]\n",
   "        spec_dict = dict(zip_longest(*matched_args, fillvalue=NO_DEFAULT))\n",
   "            context_arg = arg_names.pop(0)\n",
   "        del spec_dict[context_arg]\n",
   "        return arg_names, spec_dict\n",
   "        args, spec_dict = self.argspec(self.body)\n",
   "            positional = []\n",
   "            for name in args:  # Go in defined order, not dict \"order\"\n",
   "                default = spec_dict[name]\n",
   "                if default is NO_DEFAULT:\n",
   "                    positional.append(name)\n",
   "        return positional\n",
   "        opts = {}\n",
   "        opts[\"positional\"] = name in self.positional\n",
   "        opts[\"optional\"] = name in self.optional\n",
   "        if name in self.iterable:\n",
   "            opts[\"kind\"] = list\n",
   "            opts[\"default\"] = default if default is not None else []\n",
   "        if name in self.incrementable:\n",
   "            opts[\"incrementable\"] = True\n",
   "        if \"_\" in name:\n",
   "            opts[\"attr_name\"] = name\n",
   "            name = translate_underscores(name)\n",
   "        names = [name]\n",
   "            for char in name:\n",
   "                if not (char == name or char in taken_names):\n",
   "                    names.append(char)\n",
   "        opts[\"names\"] = names\n",
   "        if default not in (None, NO_DEFAULT):\n",
   "            kind = type(default)\n",
   "            if not (opts[\"optional\"] and kind is bool):\n",
   "                opts[\"kind\"] = kind\n",
   "            opts[\"default\"] = default\n",
   "        if name in self.help:\n",
   "            opts[\"help\"] = self.help[name]\n",
   "        return opts\n",
   "        arg_names, spec_dict = self.argspec(self.body)\n",
   "        tuples = [(x, spec_dict[x]) for x in arg_names]\n",
   "        taken_names = {x[0] for x in tuples}\n",
   "        args = []\n",
   "        for name, default in tuples:\n",
   "            new_arg = Argument(**self.arg_opts(name, default, taken_names))\n",
   "            args.append(new_arg)\n",
   "            taken_names.update(set(new_arg.names))\n",
   "        for posarg in reversed(self.positional):\n",
   "            for i, arg in enumerate(args):\n",
   "                if arg.name == posarg:\n",
   "                    args.insert(0, args.pop(i))\n",
   "        return args\n",
   "    klass = kwargs.pop(\"klass\", Task)\n",
   "    if len(args) == 1 and callable(args[0]) and not isinstance(args[0], Task):\n",
   "        return klass(args[0], **kwargs)\n",
   "    if args:\n",
   "        kwargs[\"pre\"] = args\n",
   "    name = kwargs.pop(\"name\", None)\n",
   "    aliases = kwargs.pop(\"aliases\", ())\n",
   "    positional = kwargs.pop(\"positional\", None)\n",
   "    optional = tuple(kwargs.pop(\"optional\", ()))\n",
   "    iterable = kwargs.pop(\"iterable\", None)\n",
   "    incrementable = kwargs.pop(\"incrementable\", None)\n",
   "    default = kwargs.pop(\"default\", False)\n",
   "    auto_shortflags = kwargs.pop(\"auto_shortflags\", True)\n",
   "    help = kwargs.pop(\"help\", {})\n",
   "    pre = kwargs.pop(\"pre\", [])\n",
   "    post = kwargs.pop(\"post\", [])\n",
   "    autoprint = kwargs.pop(\"autoprint\", False)\n",
   "        obj = klass(\n",
   "            obj,\n",
   "            name=name,\n",
   "            aliases=aliases,\n",
   "            positional=positional,\n",
   "            optional=optional,\n",
   "            iterable=iterable,\n",
   "            incrementable=incrementable,\n",
   "            default=default,\n",
   "            auto_shortflags=auto_shortflags,\n",
   "            help=help,\n",
   "            pre=pre,\n",
   "            post=post,\n",
   "            autoprint=autoprint,\n",
   "        return obj\n",
   "        self.args = args or tuple()\n",
   "        return getattr(self.task, name)\n",
   "        return klass(**data)\n",
   "    return Call(task=task, args=args, kwargs=kwargs)\n"
  ]
 },
 "11": {
  "name": "auto_shortflags",
  "type": "bool",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/tasks.py",
  "lineno": "331",
  "column": "4",
  "context": "e)\n    default = kwargs.pop(\"default\", False)\n    auto_shortflags = kwargs.pop(\"auto_shortflags\", True)\n    help = kwargs.pop(\"help\", {})\n    pre = kwargs",
  "context_lines": "    optional = tuple(kwargs.pop(\"optional\", ()))\n    iterable = kwargs.pop(\"iterable\", None)\n    incrementable = kwargs.pop(\"incrementable\", None)\n    default = kwargs.pop(\"default\", False)\n    auto_shortflags = kwargs.pop(\"auto_shortflags\", True)\n    help = kwargs.pop(\"help\", {})\n    pre = kwargs.pop(\"pre\", [])\n    post = kwargs.pop(\"post\", [])\n    autoprint = kwargs.pop(\"autoprint\", False)\n\n",
  "slicing": [
   "NO_DEFAULT = object()\n",
   "        aliases = \"\"\n",
   "            aliases = \" ({})\".format(\", \".join(self.aliases))\n",
   "        return \"<Task {!r}{}>\".format(self.name, aliases)\n",
   "            err = \"Task expected a Context as its first arg, got {} instead!\"\n",
   "            raise TypeError(err.format(type(args[0])))\n",
   "        result = self.body(*args, **kwargs)\n",
   "        return result\n",
   "        func = body if isinstance(body, types.FunctionType) else body.__call__\n",
   "        spec = inspect.getargspec(func)\n",
   "        arg_names = spec.args[:]\n",
   "        matched_args = [reversed(x) for x in [spec.args, spec.defaults or []]]\n",
   "        spec_dict = dict(zip_longest(*matched_args, fillvalue=NO_DEFAULT))\n",
   "            context_arg = arg_names.pop(0)\n",
   "        del spec_dict[context_arg]\n",
   "        return arg_names, spec_dict\n",
   "        args, spec_dict = self.argspec(self.body)\n",
   "            positional = []\n",
   "            for name in args:  # Go in defined order, not dict \"order\"\n",
   "                default = spec_dict[name]\n",
   "                if default is NO_DEFAULT:\n",
   "                    positional.append(name)\n",
   "        return positional\n",
   "        opts = {}\n",
   "        opts[\"positional\"] = name in self.positional\n",
   "        opts[\"optional\"] = name in self.optional\n",
   "        if name in self.iterable:\n",
   "            opts[\"kind\"] = list\n",
   "            opts[\"default\"] = default if default is not None else []\n",
   "        if name in self.incrementable:\n",
   "            opts[\"incrementable\"] = True\n",
   "        if \"_\" in name:\n",
   "            opts[\"attr_name\"] = name\n",
   "            name = translate_underscores(name)\n",
   "        names = [name]\n",
   "            for char in name:\n",
   "                if not (char == name or char in taken_names):\n",
   "                    names.append(char)\n",
   "        opts[\"names\"] = names\n",
   "        if default not in (None, NO_DEFAULT):\n",
   "            kind = type(default)\n",
   "            if not (opts[\"optional\"] and kind is bool):\n",
   "                opts[\"kind\"] = kind\n",
   "            opts[\"default\"] = default\n",
   "        if name in self.help:\n",
   "            opts[\"help\"] = self.help[name]\n",
   "        return opts\n",
   "        arg_names, spec_dict = self.argspec(self.body)\n",
   "        tuples = [(x, spec_dict[x]) for x in arg_names]\n",
   "        taken_names = {x[0] for x in tuples}\n",
   "        args = []\n",
   "        for name, default in tuples:\n",
   "            new_arg = Argument(**self.arg_opts(name, default, taken_names))\n",
   "            args.append(new_arg)\n",
   "            taken_names.update(set(new_arg.names))\n",
   "        for posarg in reversed(self.positional):\n",
   "            for i, arg in enumerate(args):\n",
   "                if arg.name == posarg:\n",
   "                    args.insert(0, args.pop(i))\n",
   "        return args\n",
   "    klass = kwargs.pop(\"klass\", Task)\n",
   "    if len(args) == 1 and callable(args[0]) and not isinstance(args[0], Task):\n",
   "        return klass(args[0], **kwargs)\n",
   "    if args:\n",
   "        kwargs[\"pre\"] = args\n",
   "    name = kwargs.pop(\"name\", None)\n",
   "    aliases = kwargs.pop(\"aliases\", ())\n",
   "    positional = kwargs.pop(\"positional\", None)\n",
   "    optional = tuple(kwargs.pop(\"optional\", ()))\n",
   "    iterable = kwargs.pop(\"iterable\", None)\n",
   "    incrementable = kwargs.pop(\"incrementable\", None)\n",
   "    default = kwargs.pop(\"default\", False)\n",
   "    auto_shortflags = kwargs.pop(\"auto_shortflags\", True)\n",
   "    help = kwargs.pop(\"help\", {})\n",
   "    pre = kwargs.pop(\"pre\", [])\n",
   "    post = kwargs.pop(\"post\", [])\n",
   "    autoprint = kwargs.pop(\"autoprint\", False)\n",
   "        obj = klass(\n",
   "            obj,\n",
   "            name=name,\n",
   "            aliases=aliases,\n",
   "            positional=positional,\n",
   "            optional=optional,\n",
   "            iterable=iterable,\n",
   "            incrementable=incrementable,\n",
   "            default=default,\n",
   "            auto_shortflags=auto_shortflags,\n",
   "            help=help,\n",
   "            pre=pre,\n",
   "            post=post,\n",
   "            autoprint=autoprint,\n",
   "        return obj\n",
   "        self.args = args or tuple()\n",
   "        return getattr(self.task, name)\n",
   "        return klass(**data)\n",
   "    return Call(task=task, args=args, kwargs=kwargs)\n"
  ]
 },
 "12": {
  "name": "help",
  "type": "dict",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/tasks.py",
  "lineno": "332",
  "column": "4",
  "context": "rtflags = kwargs.pop(\"auto_shortflags\", True)\n    help = kwargs.pop(\"help\", {})\n    pre = kwargs.pop(\"pre\", [])\n    post = kwargs.",
  "context_lines": "    iterable = kwargs.pop(\"iterable\", None)\n    incrementable = kwargs.pop(\"incrementable\", None)\n    default = kwargs.pop(\"default\", False)\n    auto_shortflags = kwargs.pop(\"auto_shortflags\", True)\n    help = kwargs.pop(\"help\", {})\n    pre = kwargs.pop(\"pre\", [])\n    post = kwargs.pop(\"post\", [])\n    autoprint = kwargs.pop(\"autoprint\", False)\n\n    def inner(obj):\n",
  "slicing": [
   "NO_DEFAULT = object()\n",
   "        aliases = \"\"\n",
   "            aliases = \" ({})\".format(\", \".join(self.aliases))\n",
   "        return \"<Task {!r}{}>\".format(self.name, aliases)\n",
   "            err = \"Task expected a Context as its first arg, got {} instead!\"\n",
   "            raise TypeError(err.format(type(args[0])))\n",
   "        result = self.body(*args, **kwargs)\n",
   "        return result\n",
   "        func = body if isinstance(body, types.FunctionType) else body.__call__\n",
   "        spec = inspect.getargspec(func)\n",
   "        arg_names = spec.args[:]\n",
   "        matched_args = [reversed(x) for x in [spec.args, spec.defaults or []]]\n",
   "        spec_dict = dict(zip_longest(*matched_args, fillvalue=NO_DEFAULT))\n",
   "            context_arg = arg_names.pop(0)\n",
   "        del spec_dict[context_arg]\n",
   "        return arg_names, spec_dict\n",
   "        args, spec_dict = self.argspec(self.body)\n",
   "            positional = []\n",
   "            for name in args:  # Go in defined order, not dict \"order\"\n",
   "                default = spec_dict[name]\n",
   "                if default is NO_DEFAULT:\n",
   "                    positional.append(name)\n",
   "        return positional\n",
   "        opts = {}\n",
   "        opts[\"positional\"] = name in self.positional\n",
   "        opts[\"optional\"] = name in self.optional\n",
   "        if name in self.iterable:\n",
   "            opts[\"kind\"] = list\n",
   "            opts[\"default\"] = default if default is not None else []\n",
   "        if name in self.incrementable:\n",
   "            opts[\"incrementable\"] = True\n",
   "        if \"_\" in name:\n",
   "            opts[\"attr_name\"] = name\n",
   "            name = translate_underscores(name)\n",
   "        names = [name]\n",
   "            for char in name:\n",
   "                if not (char == name or char in taken_names):\n",
   "                    names.append(char)\n",
   "        opts[\"names\"] = names\n",
   "        if default not in (None, NO_DEFAULT):\n",
   "            kind = type(default)\n",
   "            if not (opts[\"optional\"] and kind is bool):\n",
   "                opts[\"kind\"] = kind\n",
   "            opts[\"default\"] = default\n",
   "        if name in self.help:\n",
   "            opts[\"help\"] = self.help[name]\n",
   "        return opts\n",
   "        arg_names, spec_dict = self.argspec(self.body)\n",
   "        tuples = [(x, spec_dict[x]) for x in arg_names]\n",
   "        taken_names = {x[0] for x in tuples}\n",
   "        args = []\n",
   "        for name, default in tuples:\n",
   "            new_arg = Argument(**self.arg_opts(name, default, taken_names))\n",
   "            args.append(new_arg)\n",
   "            taken_names.update(set(new_arg.names))\n",
   "        for posarg in reversed(self.positional):\n",
   "            for i, arg in enumerate(args):\n",
   "                if arg.name == posarg:\n",
   "                    args.insert(0, args.pop(i))\n",
   "        return args\n",
   "    klass = kwargs.pop(\"klass\", Task)\n",
   "    if len(args) == 1 and callable(args[0]) and not isinstance(args[0], Task):\n",
   "        return klass(args[0], **kwargs)\n",
   "    if args:\n",
   "        kwargs[\"pre\"] = args\n",
   "    name = kwargs.pop(\"name\", None)\n",
   "    aliases = kwargs.pop(\"aliases\", ())\n",
   "    positional = kwargs.pop(\"positional\", None)\n",
   "    optional = tuple(kwargs.pop(\"optional\", ()))\n",
   "    iterable = kwargs.pop(\"iterable\", None)\n",
   "    incrementable = kwargs.pop(\"incrementable\", None)\n",
   "    default = kwargs.pop(\"default\", False)\n",
   "    auto_shortflags = kwargs.pop(\"auto_shortflags\", True)\n",
   "    help = kwargs.pop(\"help\", {})\n",
   "    pre = kwargs.pop(\"pre\", [])\n",
   "    post = kwargs.pop(\"post\", [])\n",
   "    autoprint = kwargs.pop(\"autoprint\", False)\n",
   "        obj = klass(\n",
   "            obj,\n",
   "            name=name,\n",
   "            aliases=aliases,\n",
   "            positional=positional,\n",
   "            optional=optional,\n",
   "            iterable=iterable,\n",
   "            incrementable=incrementable,\n",
   "            default=default,\n",
   "            auto_shortflags=auto_shortflags,\n",
   "            help=help,\n",
   "            pre=pre,\n",
   "            post=post,\n",
   "            autoprint=autoprint,\n",
   "        return obj\n",
   "        self.args = args or tuple()\n",
   "        return getattr(self.task, name)\n",
   "        return klass(**data)\n",
   "    return Call(task=task, args=args, kwargs=kwargs)\n"
  ]
 },
 "13": {
  "name": "pre",
  "type": "list|tuple",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/tasks.py",
  "lineno": "333",
  "column": "4",
  "context": "ags\", True)\n    help = kwargs.pop(\"help\", {})\n    pre = kwargs.pop(\"pre\", [])\n    post = kwargs.pop(\"post\", [])\n    autoprint = ",
  "context_lines": "    incrementable = kwargs.pop(\"incrementable\", None)\n    default = kwargs.pop(\"default\", False)\n    auto_shortflags = kwargs.pop(\"auto_shortflags\", True)\n    help = kwargs.pop(\"help\", {})\n    pre = kwargs.pop(\"pre\", [])\n    post = kwargs.pop(\"post\", [])\n    autoprint = kwargs.pop(\"autoprint\", False)\n\n    def inner(obj):\n        obj = klass(\n",
  "slicing": [
   "NO_DEFAULT = object()\n",
   "        aliases = \"\"\n",
   "            aliases = \" ({})\".format(\", \".join(self.aliases))\n",
   "        return \"<Task {!r}{}>\".format(self.name, aliases)\n",
   "            err = \"Task expected a Context as its first arg, got {} instead!\"\n",
   "            raise TypeError(err.format(type(args[0])))\n",
   "        result = self.body(*args, **kwargs)\n",
   "        return result\n",
   "        func = body if isinstance(body, types.FunctionType) else body.__call__\n",
   "        spec = inspect.getargspec(func)\n",
   "        arg_names = spec.args[:]\n",
   "        matched_args = [reversed(x) for x in [spec.args, spec.defaults or []]]\n",
   "        spec_dict = dict(zip_longest(*matched_args, fillvalue=NO_DEFAULT))\n",
   "            context_arg = arg_names.pop(0)\n",
   "        del spec_dict[context_arg]\n",
   "        return arg_names, spec_dict\n",
   "        args, spec_dict = self.argspec(self.body)\n",
   "            positional = []\n",
   "            for name in args:  # Go in defined order, not dict \"order\"\n",
   "                default = spec_dict[name]\n",
   "                if default is NO_DEFAULT:\n",
   "                    positional.append(name)\n",
   "        return positional\n",
   "        opts = {}\n",
   "        opts[\"positional\"] = name in self.positional\n",
   "        opts[\"optional\"] = name in self.optional\n",
   "        if name in self.iterable:\n",
   "            opts[\"kind\"] = list\n",
   "            opts[\"default\"] = default if default is not None else []\n",
   "        if name in self.incrementable:\n",
   "            opts[\"incrementable\"] = True\n",
   "        if \"_\" in name:\n",
   "            opts[\"attr_name\"] = name\n",
   "            name = translate_underscores(name)\n",
   "        names = [name]\n",
   "            for char in name:\n",
   "                if not (char == name or char in taken_names):\n",
   "                    names.append(char)\n",
   "        opts[\"names\"] = names\n",
   "        if default not in (None, NO_DEFAULT):\n",
   "            kind = type(default)\n",
   "            if not (opts[\"optional\"] and kind is bool):\n",
   "                opts[\"kind\"] = kind\n",
   "            opts[\"default\"] = default\n",
   "        if name in self.help:\n",
   "            opts[\"help\"] = self.help[name]\n",
   "        return opts\n",
   "        arg_names, spec_dict = self.argspec(self.body)\n",
   "        tuples = [(x, spec_dict[x]) for x in arg_names]\n",
   "        taken_names = {x[0] for x in tuples}\n",
   "        args = []\n",
   "        for name, default in tuples:\n",
   "            new_arg = Argument(**self.arg_opts(name, default, taken_names))\n",
   "            args.append(new_arg)\n",
   "            taken_names.update(set(new_arg.names))\n",
   "        for posarg in reversed(self.positional):\n",
   "            for i, arg in enumerate(args):\n",
   "                if arg.name == posarg:\n",
   "                    args.insert(0, args.pop(i))\n",
   "        return args\n",
   "    klass = kwargs.pop(\"klass\", Task)\n",
   "    if len(args) == 1 and callable(args[0]) and not isinstance(args[0], Task):\n",
   "        return klass(args[0], **kwargs)\n",
   "    if args:\n",
   "        kwargs[\"pre\"] = args\n",
   "    name = kwargs.pop(\"name\", None)\n",
   "    aliases = kwargs.pop(\"aliases\", ())\n",
   "    positional = kwargs.pop(\"positional\", None)\n",
   "    optional = tuple(kwargs.pop(\"optional\", ()))\n",
   "    iterable = kwargs.pop(\"iterable\", None)\n",
   "    incrementable = kwargs.pop(\"incrementable\", None)\n",
   "    default = kwargs.pop(\"default\", False)\n",
   "    auto_shortflags = kwargs.pop(\"auto_shortflags\", True)\n",
   "    help = kwargs.pop(\"help\", {})\n",
   "    pre = kwargs.pop(\"pre\", [])\n",
   "    post = kwargs.pop(\"post\", [])\n",
   "    autoprint = kwargs.pop(\"autoprint\", False)\n",
   "        obj = klass(\n",
   "            obj,\n",
   "            name=name,\n",
   "            aliases=aliases,\n",
   "            positional=positional,\n",
   "            optional=optional,\n",
   "            iterable=iterable,\n",
   "            incrementable=incrementable,\n",
   "            default=default,\n",
   "            auto_shortflags=auto_shortflags,\n",
   "            help=help,\n",
   "            pre=pre,\n",
   "            post=post,\n",
   "            autoprint=autoprint,\n",
   "        return obj\n",
   "        self.args = args or tuple()\n",
   "        return getattr(self.task, name)\n",
   "        return klass(**data)\n",
   "    return Call(task=task, args=args, kwargs=kwargs)\n"
  ]
 },
 "14": {
  "name": "post",
  "type": "list",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/tasks.py",
  "lineno": "334",
  "column": "4",
  "context": "p(\"help\", {})\n    pre = kwargs.pop(\"pre\", [])\n    post = kwargs.pop(\"post\", [])\n    autoprint = kwargs.pop(\"autoprint\", False)\n\n  ",
  "context_lines": "    default = kwargs.pop(\"default\", False)\n    auto_shortflags = kwargs.pop(\"auto_shortflags\", True)\n    help = kwargs.pop(\"help\", {})\n    pre = kwargs.pop(\"pre\", [])\n    post = kwargs.pop(\"post\", [])\n    autoprint = kwargs.pop(\"autoprint\", False)\n\n    def inner(obj):\n        obj = klass(\n            obj,\n",
  "slicing": [
   "NO_DEFAULT = object()\n",
   "        aliases = \"\"\n",
   "            aliases = \" ({})\".format(\", \".join(self.aliases))\n",
   "        return \"<Task {!r}{}>\".format(self.name, aliases)\n",
   "            err = \"Task expected a Context as its first arg, got {} instead!\"\n",
   "            raise TypeError(err.format(type(args[0])))\n",
   "        result = self.body(*args, **kwargs)\n",
   "        return result\n",
   "        func = body if isinstance(body, types.FunctionType) else body.__call__\n",
   "        spec = inspect.getargspec(func)\n",
   "        arg_names = spec.args[:]\n",
   "        matched_args = [reversed(x) for x in [spec.args, spec.defaults or []]]\n",
   "        spec_dict = dict(zip_longest(*matched_args, fillvalue=NO_DEFAULT))\n",
   "            context_arg = arg_names.pop(0)\n",
   "        del spec_dict[context_arg]\n",
   "        return arg_names, spec_dict\n",
   "        args, spec_dict = self.argspec(self.body)\n",
   "            positional = []\n",
   "            for name in args:  # Go in defined order, not dict \"order\"\n",
   "                default = spec_dict[name]\n",
   "                if default is NO_DEFAULT:\n",
   "                    positional.append(name)\n",
   "        return positional\n",
   "        opts = {}\n",
   "        opts[\"positional\"] = name in self.positional\n",
   "        opts[\"optional\"] = name in self.optional\n",
   "        if name in self.iterable:\n",
   "            opts[\"kind\"] = list\n",
   "            opts[\"default\"] = default if default is not None else []\n",
   "        if name in self.incrementable:\n",
   "            opts[\"incrementable\"] = True\n",
   "        if \"_\" in name:\n",
   "            opts[\"attr_name\"] = name\n",
   "            name = translate_underscores(name)\n",
   "        names = [name]\n",
   "            for char in name:\n",
   "                if not (char == name or char in taken_names):\n",
   "                    names.append(char)\n",
   "        opts[\"names\"] = names\n",
   "        if default not in (None, NO_DEFAULT):\n",
   "            kind = type(default)\n",
   "            if not (opts[\"optional\"] and kind is bool):\n",
   "                opts[\"kind\"] = kind\n",
   "            opts[\"default\"] = default\n",
   "        if name in self.help:\n",
   "            opts[\"help\"] = self.help[name]\n",
   "        return opts\n",
   "        arg_names, spec_dict = self.argspec(self.body)\n",
   "        tuples = [(x, spec_dict[x]) for x in arg_names]\n",
   "        taken_names = {x[0] for x in tuples}\n",
   "        args = []\n",
   "        for name, default in tuples:\n",
   "            new_arg = Argument(**self.arg_opts(name, default, taken_names))\n",
   "            args.append(new_arg)\n",
   "            taken_names.update(set(new_arg.names))\n",
   "        for posarg in reversed(self.positional):\n",
   "            for i, arg in enumerate(args):\n",
   "                if arg.name == posarg:\n",
   "                    args.insert(0, args.pop(i))\n",
   "        return args\n",
   "    klass = kwargs.pop(\"klass\", Task)\n",
   "    if len(args) == 1 and callable(args[0]) and not isinstance(args[0], Task):\n",
   "        return klass(args[0], **kwargs)\n",
   "    if args:\n",
   "        kwargs[\"pre\"] = args\n",
   "    name = kwargs.pop(\"name\", None)\n",
   "    aliases = kwargs.pop(\"aliases\", ())\n",
   "    positional = kwargs.pop(\"positional\", None)\n",
   "    optional = tuple(kwargs.pop(\"optional\", ()))\n",
   "    iterable = kwargs.pop(\"iterable\", None)\n",
   "    incrementable = kwargs.pop(\"incrementable\", None)\n",
   "    default = kwargs.pop(\"default\", False)\n",
   "    auto_shortflags = kwargs.pop(\"auto_shortflags\", True)\n",
   "    help = kwargs.pop(\"help\", {})\n",
   "    pre = kwargs.pop(\"pre\", [])\n",
   "    post = kwargs.pop(\"post\", [])\n",
   "    autoprint = kwargs.pop(\"autoprint\", False)\n",
   "        obj = klass(\n",
   "            obj,\n",
   "            name=name,\n",
   "            aliases=aliases,\n",
   "            positional=positional,\n",
   "            optional=optional,\n",
   "            iterable=iterable,\n",
   "            incrementable=incrementable,\n",
   "            default=default,\n",
   "            auto_shortflags=auto_shortflags,\n",
   "            help=help,\n",
   "            pre=pre,\n",
   "            post=post,\n",
   "            autoprint=autoprint,\n",
   "        return obj\n",
   "        self.args = args or tuple()\n",
   "        return getattr(self.task, name)\n",
   "        return klass(**data)\n",
   "    return Call(task=task, args=args, kwargs=kwargs)\n"
  ]
 },
 "15": {
  "name": "autoprint",
  "type": "bool",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/tasks.py",
  "lineno": "335",
  "column": "4",
  "context": "(\"pre\", [])\n    post = kwargs.pop(\"post\", [])\n    autoprint = kwargs.pop(\"autoprint\", False)\n\n    def inner(obj):\n        obj = klass(\n        ",
  "context_lines": "    auto_shortflags = kwargs.pop(\"auto_shortflags\", True)\n    help = kwargs.pop(\"help\", {})\n    pre = kwargs.pop(\"pre\", [])\n    post = kwargs.pop(\"post\", [])\n    autoprint = kwargs.pop(\"autoprint\", False)\n\n    def inner(obj):\n        obj = klass(\n            obj,\n",
  "slicing": [
   "NO_DEFAULT = object()\n",
   "        aliases = \"\"\n",
   "            aliases = \" ({})\".format(\", \".join(self.aliases))\n",
   "        return \"<Task {!r}{}>\".format(self.name, aliases)\n",
   "            err = \"Task expected a Context as its first arg, got {} instead!\"\n",
   "            raise TypeError(err.format(type(args[0])))\n",
   "        result = self.body(*args, **kwargs)\n",
   "        return result\n",
   "        func = body if isinstance(body, types.FunctionType) else body.__call__\n",
   "        spec = inspect.getargspec(func)\n",
   "        arg_names = spec.args[:]\n",
   "        matched_args = [reversed(x) for x in [spec.args, spec.defaults or []]]\n",
   "        spec_dict = dict(zip_longest(*matched_args, fillvalue=NO_DEFAULT))\n",
   "            context_arg = arg_names.pop(0)\n",
   "        del spec_dict[context_arg]\n",
   "        return arg_names, spec_dict\n",
   "        args, spec_dict = self.argspec(self.body)\n",
   "            positional = []\n",
   "            for name in args:  # Go in defined order, not dict \"order\"\n",
   "                default = spec_dict[name]\n",
   "                if default is NO_DEFAULT:\n",
   "                    positional.append(name)\n",
   "        return positional\n",
   "        opts = {}\n",
   "        opts[\"positional\"] = name in self.positional\n",
   "        opts[\"optional\"] = name in self.optional\n",
   "        if name in self.iterable:\n",
   "            opts[\"kind\"] = list\n",
   "            opts[\"default\"] = default if default is not None else []\n",
   "        if name in self.incrementable:\n",
   "            opts[\"incrementable\"] = True\n",
   "        if \"_\" in name:\n",
   "            opts[\"attr_name\"] = name\n",
   "            name = translate_underscores(name)\n",
   "        names = [name]\n",
   "            for char in name:\n",
   "                if not (char == name or char in taken_names):\n",
   "                    names.append(char)\n",
   "        opts[\"names\"] = names\n",
   "        if default not in (None, NO_DEFAULT):\n",
   "            kind = type(default)\n",
   "            if not (opts[\"optional\"] and kind is bool):\n",
   "                opts[\"kind\"] = kind\n",
   "            opts[\"default\"] = default\n",
   "        if name in self.help:\n",
   "            opts[\"help\"] = self.help[name]\n",
   "        return opts\n",
   "        arg_names, spec_dict = self.argspec(self.body)\n",
   "        tuples = [(x, spec_dict[x]) for x in arg_names]\n",
   "        taken_names = {x[0] for x in tuples}\n",
   "        args = []\n",
   "        for name, default in tuples:\n",
   "            new_arg = Argument(**self.arg_opts(name, default, taken_names))\n",
   "            args.append(new_arg)\n",
   "            taken_names.update(set(new_arg.names))\n",
   "        for posarg in reversed(self.positional):\n",
   "            for i, arg in enumerate(args):\n",
   "                if arg.name == posarg:\n",
   "                    args.insert(0, args.pop(i))\n",
   "        return args\n",
   "    klass = kwargs.pop(\"klass\", Task)\n",
   "    if len(args) == 1 and callable(args[0]) and not isinstance(args[0], Task):\n",
   "        return klass(args[0], **kwargs)\n",
   "    if args:\n",
   "        kwargs[\"pre\"] = args\n",
   "    name = kwargs.pop(\"name\", None)\n",
   "    aliases = kwargs.pop(\"aliases\", ())\n",
   "    positional = kwargs.pop(\"positional\", None)\n",
   "    optional = tuple(kwargs.pop(\"optional\", ()))\n",
   "    iterable = kwargs.pop(\"iterable\", None)\n",
   "    incrementable = kwargs.pop(\"incrementable\", None)\n",
   "    default = kwargs.pop(\"default\", False)\n",
   "    auto_shortflags = kwargs.pop(\"auto_shortflags\", True)\n",
   "    help = kwargs.pop(\"help\", {})\n",
   "    pre = kwargs.pop(\"pre\", [])\n",
   "    post = kwargs.pop(\"post\", [])\n",
   "    autoprint = kwargs.pop(\"autoprint\", False)\n",
   "        obj = klass(\n",
   "            obj,\n",
   "            name=name,\n",
   "            aliases=aliases,\n",
   "            positional=positional,\n",
   "            optional=optional,\n",
   "            iterable=iterable,\n",
   "            incrementable=incrementable,\n",
   "            default=default,\n",
   "            auto_shortflags=auto_shortflags,\n",
   "            help=help,\n",
   "            pre=pre,\n",
   "            post=post,\n",
   "            autoprint=autoprint,\n",
   "        return obj\n",
   "        self.args = args or tuple()\n",
   "        return getattr(self.task, name)\n",
   "        return klass(**data)\n",
   "    return Call(task=task, args=args, kwargs=kwargs)\n"
  ]
 },
 "16": {
  "name": "obj",
  "type": "Task",
  "class": "customized",
  "approach": "annotation",
  "file_path": "invoke/invoke/tasks.py",
  "lineno": "338",
  "column": "8",
  "context": "(\"autoprint\", False)\n\n    def inner(obj):\n        obj = klass(\n            obj,\n            name=name,\n          ",
  "context_lines": "    pre = kwargs.pop(\"pre\", [])\n    post = kwargs.pop(\"post\", [])\n    autoprint = kwargs.pop(\"autoprint\", False)\n\n    def inner(obj):\n        obj = klass(\n            obj,\n            name=name,\n            aliases=aliases,\n            positional=positional,\n",
  "slicing": [
   "NO_DEFAULT = object()\n",
   "        aliases = \"\"\n",
   "            aliases = \" ({})\".format(\", \".join(self.aliases))\n",
   "        return \"<Task {!r}{}>\".format(self.name, aliases)\n",
   "            err = \"Task expected a Context as its first arg, got {} instead!\"\n",
   "            raise TypeError(err.format(type(args[0])))\n",
   "        result = self.body(*args, **kwargs)\n",
   "        return result\n",
   "        func = body if isinstance(body, types.FunctionType) else body.__call__\n",
   "        spec = inspect.getargspec(func)\n",
   "        arg_names = spec.args[:]\n",
   "        matched_args = [reversed(x) for x in [spec.args, spec.defaults or []]]\n",
   "        spec_dict = dict(zip_longest(*matched_args, fillvalue=NO_DEFAULT))\n",
   "            context_arg = arg_names.pop(0)\n",
   "        del spec_dict[context_arg]\n",
   "        return arg_names, spec_dict\n",
   "        args, spec_dict = self.argspec(self.body)\n",
   "            positional = []\n",
   "            for name in args:  # Go in defined order, not dict \"order\"\n",
   "                default = spec_dict[name]\n",
   "                if default is NO_DEFAULT:\n",
   "                    positional.append(name)\n",
   "        return positional\n",
   "        opts = {}\n",
   "        opts[\"positional\"] = name in self.positional\n",
   "        opts[\"optional\"] = name in self.optional\n",
   "        if name in self.iterable:\n",
   "            opts[\"kind\"] = list\n",
   "            opts[\"default\"] = default if default is not None else []\n",
   "        if name in self.incrementable:\n",
   "            opts[\"incrementable\"] = True\n",
   "        if \"_\" in name:\n",
   "            opts[\"attr_name\"] = name\n",
   "            name = translate_underscores(name)\n",
   "        names = [name]\n",
   "            for char in name:\n",
   "                if not (char == name or char in taken_names):\n",
   "                    names.append(char)\n",
   "        opts[\"names\"] = names\n",
   "        if default not in (None, NO_DEFAULT):\n",
   "            kind = type(default)\n",
   "            if not (opts[\"optional\"] and kind is bool):\n",
   "                opts[\"kind\"] = kind\n",
   "            opts[\"default\"] = default\n",
   "        if name in self.help:\n",
   "            opts[\"help\"] = self.help[name]\n",
   "        return opts\n",
   "        arg_names, spec_dict = self.argspec(self.body)\n",
   "        tuples = [(x, spec_dict[x]) for x in arg_names]\n",
   "        taken_names = {x[0] for x in tuples}\n",
   "        args = []\n",
   "        for name, default in tuples:\n",
   "            new_arg = Argument(**self.arg_opts(name, default, taken_names))\n",
   "            args.append(new_arg)\n",
   "            taken_names.update(set(new_arg.names))\n",
   "        for posarg in reversed(self.positional):\n",
   "            for i, arg in enumerate(args):\n",
   "                if arg.name == posarg:\n",
   "                    args.insert(0, args.pop(i))\n",
   "        return args\n",
   "    klass = kwargs.pop(\"klass\", Task)\n",
   "    if len(args) == 1 and callable(args[0]) and not isinstance(args[0], Task):\n",
   "        return klass(args[0], **kwargs)\n",
   "    if args:\n",
   "        kwargs[\"pre\"] = args\n",
   "    name = kwargs.pop(\"name\", None)\n",
   "    aliases = kwargs.pop(\"aliases\", ())\n",
   "    positional = kwargs.pop(\"positional\", None)\n",
   "    optional = tuple(kwargs.pop(\"optional\", ()))\n",
   "    iterable = kwargs.pop(\"iterable\", None)\n",
   "    incrementable = kwargs.pop(\"incrementable\", None)\n",
   "    default = kwargs.pop(\"default\", False)\n",
   "    auto_shortflags = kwargs.pop(\"auto_shortflags\", True)\n",
   "    help = kwargs.pop(\"help\", {})\n",
   "    pre = kwargs.pop(\"pre\", [])\n",
   "    post = kwargs.pop(\"post\", [])\n",
   "    autoprint = kwargs.pop(\"autoprint\", False)\n",
   "        obj = klass(\n",
   "            obj,\n",
   "            name=name,\n",
   "            aliases=aliases,\n",
   "            positional=positional,\n",
   "            optional=optional,\n",
   "            iterable=iterable,\n",
   "            incrementable=incrementable,\n",
   "            default=default,\n",
   "            auto_shortflags=auto_shortflags,\n",
   "            help=help,\n",
   "            pre=pre,\n",
   "            post=post,\n",
   "            autoprint=autoprint,\n",
   "        return obj\n",
   "        self.args = args or tuple()\n",
   "        return getattr(self.task, name)\n",
   "        return klass(**data)\n",
   "    return Call(task=task, args=args, kwargs=kwargs)\n"
  ]
 },
 "17": {
  "name": "_proxies",
  "type": "tuple",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/config.py",
  "lineno": "51",
  "column": "4",
  "context": "xied through to inner merged-dict config obj.\n    _proxies = (\n        tuple(\n            \"\"\"\n        get\n       ",
  "context_lines": "        run into recursion errors!\n\n    .. versionadded:: 1.0\n    \"\"\"\n\n    # Attributes which get proxied through to inner merged-dict config obj.\n    _proxies = (\n        tuple(\n            \"\"\"\n        get\n        has_key\n",
  "slicing": "    _proxies = (\n"
 },
 "18": {
  "name": "__hash__",
  "type": "NoneType",
  "class": "unknown",
  "approach": "annotation",
  "file_path": "invoke/invoke/config.py",
  "lineno": "157",
  "column": "4",
  "context": "ession to Python 2, v3 does it automatically.\n    __hash__ = None\n\n    def __len__(self):\n        return len(self._c",
  "context_lines": "        return self._config == other_val\n\n    # Make unhashable, because our entire raison d'etre is to be somewhat\n    # mutable. Subclasses with mutable attributes may override this.\n    # NOTE: this is mostly a concession to Python 2, v3 does it automatically.\n    __hash__ = None\n\n    def __len__(self):\n        return len(self._config)\n\n    def __setitem__(self, key, value):\n",
  "slicing": "    __hash__ = None\n"
 },
 "19": {
  "name": "prefix",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/config.py",
  "lineno": "424",
  "column": "4",
  "context": "prefix``.\n\n    .. versionadded:: 1.0\n    \"\"\"\n\n    prefix = \"invoke\"\n    file_prefix = None\n    env_prefix = None\n\n    ",
  "context_lines": "      default.\n\n      Defaults to ``None``, meaning to use the value of ``prefix``.\n\n    .. versionadded:: 1.0\n    \"\"\"\n\n    prefix = \"invoke\"\n    file_prefix = None\n    env_prefix = None\n\n    @staticmethod\n    def global_defaults():\n",
  "slicing": [
   "    def load_source(name, path):\n",
   "            for x in \"\"\"\n",
   "        obj = cls()\n",
   "        obj._set(_config=data)\n",
   "        obj._set(_root=root)\n",
   "        obj._set(_keypath=keypath)\n",
   "        return obj\n",
   "            err = \"No attribute or config key found for {!r}\".format(key)\n",
   "            attrs = [x for x in dir(self.__class__) if not x.startswith(\"_\")]\n",
   "            err += \"\\n\\nValid keys: {!r}\".format(\n",
   "            err += \"\\n\\nValid real attributes: {!r}\".format(attrs)\n",
   "            raise AttributeError(err)\n",
   "        has_real_attr = key in dir(self)\n",
   "        if not has_real_attr:\n",
   "        other_val = getattr(other, \"_config\", None)\n",
   "            other_val = other\n",
   "        return self._config == other_val\n",
   "        value = self._config[key]\n",
   "        if isinstance(value, dict):\n",
   "            keypath = (key,)\n",
   "                keypath = self._keypath + keypath\n",
   "            root = getattr(self, \"_root\", self)\n",
   "            value = DataProxy.from_data(data=value, root=root, keypath=keypath)\n",
   "        return value\n",
   "        for key, value in six.iteritems(kwargs):\n",
   "            object.__setattr__(self, key, value)\n",
   "        return key in self._config\n",
   "        target = None\n",
   "            target = self._root\n",
   "            target = self\n",
   "        if target is not None:\n",
   "            target._remove(getattr(self, \"_keypath\", tuple()), key)\n",
   "        target = None\n",
   "            target = self._root\n",
   "            target = self\n",
   "        if target is not None:\n",
   "            target._modify(getattr(self, \"_keypath\", tuple()), key, value)\n",
   "        del self._config[key]\n",
   "        self._track_removal_of(key)\n",
   "            object.__delattr__(self, name)\n",
   "        keys = list(self.keys())\n",
   "        for key in keys:\n",
   "            del self[key]\n",
   "        key_existed = args and args[0] in self._config\n",
   "        ret = self._config.pop(*args)\n",
   "        if not key_existed:\n",
   "            return ret\n",
   "        return ret\n",
   "        ret = self._config.popitem()\n",
   "        self._track_removal_of(ret[0])\n",
   "        return ret\n",
   "        key_existed = args and args[0] in self._config\n",
   "        ret = self._config.setdefault(*args)\n",
   "        if key_existed:\n",
   "            return ret\n",
   "        key, default = args\n",
   "        self._track_modification_of(key, default)\n",
   "        return ret\n",
   "            for key, value in six.iteritems(kwargs):\n",
   "                self[key] = value\n",
   "            arg = args[0]\n",
   "            if isinstance(arg, dict):\n",
   "                for key in arg:\n",
   "                    self[key] = arg[key]\n",
   "                for pair in arg:\n",
   "                    self[pair[0]] = pair[1]\n",
   "    prefix = \"invoke\"\n",
   "    env_prefix = None\n",
   "            shell = os.environ.get(\"COMSPEC\", \"cmd.exe\")\n",
   "            shell = \"/bin/bash\"\n",
   "                \"shell\": shell,\n",
   "            defaults = copy_dict(self.global_defaults())\n",
   "        self._set(_defaults=defaults)\n",
   "            system_prefix = \"/etc/\"\n",
   "        self._set(_system_prefix=system_prefix)\n",
   "            user_prefix = \"~/.\"\n",
   "        self._set(_user_prefix=user_prefix)\n",
   "        env_prefix = self.env_prefix\n",
   "        if env_prefix is None:\n",
   "            env_prefix = self.prefix\n",
   "        env_prefix = \"{}_\".format(env_prefix.upper())\n",
   "        self._set(_env_prefix=env_prefix)\n",
   "            overrides = {}\n",
   "        self._set(_overrides=overrides)\n",
   "        loader = Environment(config=self._config, prefix=self._env_prefix)\n",
   "        self._set(_env=loader.load())\n",
   "        project_prefix = None\n",
   "            project_prefix = join(path, \"\")\n",
   "        self._set(_project_prefix=project_prefix)\n",
   "        found = \"_{}_found\".format(prefix)\n",
   "        path = \"_{}_path\".format(prefix)\n",
   "        data = \"_{}\".format(prefix)\n",
   "        midfix = self.file_prefix\n",
   "        if midfix is None:\n",
   "            midfix = self.prefix\n",
   "        if getattr(self, found) is not None:\n",
   "            absolute_path = getattr(self, path)\n",
   "            if absolute_path is None:\n",
   "            paths = [absolute_path]\n",
   "            path_prefix = getattr(self, \"_{}_prefix\".format(prefix))\n",
   "            if path_prefix is None:\n",
   "            paths = [\n",
   "                \".\".join((path_prefix + midfix, x))\n",
   "                for x in self._file_suffixes\n",
   "        for filepath in paths:\n",
   "            filepath = expanduser(filepath)\n",
   "                    type_ = splitext(filepath)[1].lstrip(\".\")\n",
   "                    loader = getattr(self, \"_load_{}\".format(type_))\n",
   "                    msg = \"Config files of type {!r} (from file {!r}) are not supported! Please use one of: {!r}\"  # noqa\n",
   "                        msg.format(type_, filepath, self._file_suffixes)\n",
   "                self._set(data, loader(filepath))\n",
   "                self._set(path, filepath)\n",
   "                self._set(found, True)\n",
   "                    err = \"Didn't see any {}, skipping.\"\n",
   "                    debug(err.format(filepath))\n",
   "        if getattr(self, path) is None:\n",
   "            self._set(found, False)\n",
   "        with open(path) as fd:\n",
   "            return yaml.load(fd)\n",
   "        return self._load_yaml(path)\n",
   "        with open(path) as fd:\n",
   "            return json.load(fd)\n",
   "        data = {}\n",
   "        for key, value in six.iteritems(load_source(\"mod\", path)):\n",
   "            if key.startswith(\"__\"):\n",
   "            if isinstance(value, types.ModuleType):\n",
   "                err = \"'{}' is a module, which can't be used as a config value. (Are you perhaps giving a tasks file instead of a config file by mistake?)\"  # noqa\n",
   "                raise UnpicklableConfigMember(err.format(key))\n",
   "            data[key] = value\n",
   "        return data\n",
   "        desc += \" config file\"  # yup\n",
   "        found = getattr(self, \"_{}_found\".format(name))\n",
   "        path = getattr(self, \"_{}_path\".format(name))\n",
   "        data = getattr(self, \"_{}\".format(name))\n",
   "        if found is None:\n",
   "            debug(\"{} has not been loaded yet, skipping\".format(desc))\n",
   "        elif found:\n",
   "            debug(\"{} ({}): {!r}\".format(desc, path, data))\n",
   "            merge_dicts(self._config, data)\n",
   "            debug(\"{} not found, skipping\".format(desc))\n",
   "            err = \"'into' must be a subclass of {}!\"\n",
   "            raise TypeError(err.format(self.__class__.__name__))\n",
   "        klass = self.__class__ if into is None else into\n",
   "        new = klass(**self._clone_init_kwargs(into=into))\n",
   "        for name in \"\"\"\n",
   "            name = \"_{}\".format(name)\n",
   "            my_data = getattr(self, name)\n",
   "            if not isinstance(my_data, dict):\n",
   "                new._set(name, copy.copy(my_data))\n",
   "                merge_dicts(getattr(new, name), my_data)\n",
   "        new.load_base_conf_files()\n",
   "        new.merge()\n",
   "        return new\n",
   "        new_defaults = copy_dict(self._defaults)\n",
   "            merge_dicts(new_defaults, into.global_defaults())\n",
   "            defaults=new_defaults,\n",
   "        excise(self._deletions, keypath + (key,))\n",
   "        data = self._modifications\n",
   "        keypath = list(keypath)\n",
   "        while keypath:\n",
   "            subkey = keypath.pop(0)\n",
   "            if subkey not in data:\n",
   "                data[subkey] = {}\n",
   "            data = data[subkey]\n",
   "        data[key] = value\n",
   "        data = self._deletions\n",
   "        keypath = list(keypath)\n",
   "        while keypath:\n",
   "            subkey = keypath.pop(0)\n",
   "            if subkey in data:\n",
   "                data = data[subkey]\n",
   "                if data is None:\n",
   "                data[subkey] = {}\n",
   "                data = data[subkey]\n",
   "        data[key] = None\n",
   "def merge_dicts(base, updates):\n",
   "    for key, value in (updates or {}).items():\n",
   "        if key in base:\n",
   "            if isinstance(value, dict):\n",
   "                if isinstance(base[key], dict):\n",
   "                    merge_dicts(base[key], value)\n",
   "                    raise _merge_error(base[key], value)\n",
   "                if isinstance(base[key], dict):\n",
   "                    raise _merge_error(base[key], value)\n",
   "                elif hasattr(value, \"fileno\"):\n",
   "                    base[key] = value\n",
   "                    base[key] = copy.copy(value)\n",
   "            if isinstance(value, dict):\n",
   "                base[key] = copy_dict(value)\n",
   "            elif hasattr(value, \"fileno\"):\n",
   "                base[key] = value\n",
   "                base[key] = copy.copy(value)\n",
   "    return base\n",
   "    return \"{} ({!r})\".format(type(x), x)\n",
   "    return merge_dicts({}, source)\n",
   "    data = dict_\n",
   "    keypath = list(keypath)\n",
   "    leaf_key = keypath.pop()\n",
   "    while keypath:\n",
   "        key = keypath.pop(0)\n",
   "        if key not in data:\n",
   "        data = data[key]\n",
   "    if leaf_key in data:\n",
   "        del data[leaf_key]\n",
   "        if isinstance(value, dict):\n",
   "            obliterate(base[key], deletions[key])\n",
   "            del base[key]\n"
  ]
 },
 "20": {
  "name": "file_prefix",
  "type": "NoneType",
  "class": "unknown",
  "approach": "annotation",
  "file_path": "invoke/invoke/config.py",
  "lineno": "425",
  "column": "4",
  "context": "ionadded:: 1.0\n    \"\"\"\n\n    prefix = \"invoke\"\n    file_prefix = None\n    env_prefix = None\n\n    @staticmethod\n    def g",
  "context_lines": "      Defaults to ``None``, meaning to use the value of ``prefix``.\n\n    .. versionadded:: 1.0\n    \"\"\"\n\n    prefix = \"invoke\"\n    file_prefix = None\n    env_prefix = None\n\n    @staticmethod\n    def global_defaults():\n        \"\"\"\n",
  "slicing": "    file_prefix = None\n"
 },
 "21": {
  "name": "env_prefix",
  "type": "NoneType",
  "class": "unknown",
  "approach": "annotation",
  "file_path": "invoke/invoke/config.py",
  "lineno": "426",
  "column": "4",
  "context": "\n    prefix = \"invoke\"\n    file_prefix = None\n    env_prefix = None\n\n    @staticmethod\n    def global_defaults():\n    ",
  "context_lines": "    .. versionadded:: 1.0\n    \"\"\"\n\n    prefix = \"invoke\"\n    file_prefix = None\n    env_prefix = None\n\n    @staticmethod\n    def global_defaults():\n        \"\"\"\n",
  "slicing": [
   "    def load_source(name, path):\n",
   "            for x in \"\"\"\n",
   "        obj = cls()\n",
   "        obj._set(_config=data)\n",
   "        obj._set(_root=root)\n",
   "        obj._set(_keypath=keypath)\n",
   "        return obj\n",
   "            err = \"No attribute or config key found for {!r}\".format(key)\n",
   "            attrs = [x for x in dir(self.__class__) if not x.startswith(\"_\")]\n",
   "            err += \"\\n\\nValid keys: {!r}\".format(\n",
   "            err += \"\\n\\nValid real attributes: {!r}\".format(attrs)\n",
   "            raise AttributeError(err)\n",
   "        has_real_attr = key in dir(self)\n",
   "        if not has_real_attr:\n",
   "        other_val = getattr(other, \"_config\", None)\n",
   "            other_val = other\n",
   "        return self._config == other_val\n",
   "        value = self._config[key]\n",
   "        if isinstance(value, dict):\n",
   "            keypath = (key,)\n",
   "                keypath = self._keypath + keypath\n",
   "            root = getattr(self, \"_root\", self)\n",
   "            value = DataProxy.from_data(data=value, root=root, keypath=keypath)\n",
   "        return value\n",
   "        for key, value in six.iteritems(kwargs):\n",
   "            object.__setattr__(self, key, value)\n",
   "        return key in self._config\n",
   "        target = None\n",
   "            target = self._root\n",
   "            target = self\n",
   "        if target is not None:\n",
   "            target._remove(getattr(self, \"_keypath\", tuple()), key)\n",
   "        target = None\n",
   "            target = self._root\n",
   "            target = self\n",
   "        if target is not None:\n",
   "            target._modify(getattr(self, \"_keypath\", tuple()), key, value)\n",
   "        del self._config[key]\n",
   "        self._track_removal_of(key)\n",
   "            object.__delattr__(self, name)\n",
   "        keys = list(self.keys())\n",
   "        for key in keys:\n",
   "            del self[key]\n",
   "        key_existed = args and args[0] in self._config\n",
   "        ret = self._config.pop(*args)\n",
   "        if not key_existed:\n",
   "            return ret\n",
   "        return ret\n",
   "        ret = self._config.popitem()\n",
   "        self._track_removal_of(ret[0])\n",
   "        return ret\n",
   "        key_existed = args and args[0] in self._config\n",
   "        ret = self._config.setdefault(*args)\n",
   "        if key_existed:\n",
   "            return ret\n",
   "        key, default = args\n",
   "        self._track_modification_of(key, default)\n",
   "        return ret\n",
   "            for key, value in six.iteritems(kwargs):\n",
   "                self[key] = value\n",
   "            arg = args[0]\n",
   "            if isinstance(arg, dict):\n",
   "                for key in arg:\n",
   "                    self[key] = arg[key]\n",
   "                for pair in arg:\n",
   "                    self[pair[0]] = pair[1]\n",
   "    prefix = \"invoke\"\n",
   "    env_prefix = None\n",
   "            shell = os.environ.get(\"COMSPEC\", \"cmd.exe\")\n",
   "            shell = \"/bin/bash\"\n",
   "                \"shell\": shell,\n",
   "            defaults = copy_dict(self.global_defaults())\n",
   "        self._set(_defaults=defaults)\n",
   "            system_prefix = \"/etc/\"\n",
   "        self._set(_system_prefix=system_prefix)\n",
   "            user_prefix = \"~/.\"\n",
   "        self._set(_user_prefix=user_prefix)\n",
   "        env_prefix = self.env_prefix\n",
   "        if env_prefix is None:\n",
   "            env_prefix = self.prefix\n",
   "        env_prefix = \"{}_\".format(env_prefix.upper())\n",
   "        self._set(_env_prefix=env_prefix)\n",
   "            overrides = {}\n",
   "        self._set(_overrides=overrides)\n",
   "        loader = Environment(config=self._config, prefix=self._env_prefix)\n",
   "        self._set(_env=loader.load())\n",
   "        project_prefix = None\n",
   "            project_prefix = join(path, \"\")\n",
   "        self._set(_project_prefix=project_prefix)\n",
   "        found = \"_{}_found\".format(prefix)\n",
   "        path = \"_{}_path\".format(prefix)\n",
   "        data = \"_{}\".format(prefix)\n",
   "        midfix = self.file_prefix\n",
   "        if midfix is None:\n",
   "            midfix = self.prefix\n",
   "        if getattr(self, found) is not None:\n",
   "            absolute_path = getattr(self, path)\n",
   "            if absolute_path is None:\n",
   "            paths = [absolute_path]\n",
   "            path_prefix = getattr(self, \"_{}_prefix\".format(prefix))\n",
   "            if path_prefix is None:\n",
   "            paths = [\n",
   "                \".\".join((path_prefix + midfix, x))\n",
   "                for x in self._file_suffixes\n",
   "        for filepath in paths:\n",
   "            filepath = expanduser(filepath)\n",
   "                    type_ = splitext(filepath)[1].lstrip(\".\")\n",
   "                    loader = getattr(self, \"_load_{}\".format(type_))\n",
   "                    msg = \"Config files of type {!r} (from file {!r}) are not supported! Please use one of: {!r}\"  # noqa\n",
   "                        msg.format(type_, filepath, self._file_suffixes)\n",
   "                self._set(data, loader(filepath))\n",
   "                self._set(path, filepath)\n",
   "                self._set(found, True)\n",
   "                    err = \"Didn't see any {}, skipping.\"\n",
   "                    debug(err.format(filepath))\n",
   "        if getattr(self, path) is None:\n",
   "            self._set(found, False)\n",
   "        with open(path) as fd:\n",
   "            return yaml.load(fd)\n",
   "        return self._load_yaml(path)\n",
   "        with open(path) as fd:\n",
   "            return json.load(fd)\n",
   "        data = {}\n",
   "        for key, value in six.iteritems(load_source(\"mod\", path)):\n",
   "            if key.startswith(\"__\"):\n",
   "            if isinstance(value, types.ModuleType):\n",
   "                err = \"'{}' is a module, which can't be used as a config value. (Are you perhaps giving a tasks file instead of a config file by mistake?)\"  # noqa\n",
   "                raise UnpicklableConfigMember(err.format(key))\n",
   "            data[key] = value\n",
   "        return data\n",
   "        desc += \" config file\"  # yup\n",
   "        found = getattr(self, \"_{}_found\".format(name))\n",
   "        path = getattr(self, \"_{}_path\".format(name))\n",
   "        data = getattr(self, \"_{}\".format(name))\n",
   "        if found is None:\n",
   "            debug(\"{} has not been loaded yet, skipping\".format(desc))\n",
   "        elif found:\n",
   "            debug(\"{} ({}): {!r}\".format(desc, path, data))\n",
   "            merge_dicts(self._config, data)\n",
   "            debug(\"{} not found, skipping\".format(desc))\n",
   "            err = \"'into' must be a subclass of {}!\"\n",
   "            raise TypeError(err.format(self.__class__.__name__))\n",
   "        klass = self.__class__ if into is None else into\n",
   "        new = klass(**self._clone_init_kwargs(into=into))\n",
   "        for name in \"\"\"\n",
   "            name = \"_{}\".format(name)\n",
   "            my_data = getattr(self, name)\n",
   "            if not isinstance(my_data, dict):\n",
   "                new._set(name, copy.copy(my_data))\n",
   "                merge_dicts(getattr(new, name), my_data)\n",
   "        new.load_base_conf_files()\n",
   "        new.merge()\n",
   "        return new\n",
   "        new_defaults = copy_dict(self._defaults)\n",
   "            merge_dicts(new_defaults, into.global_defaults())\n",
   "            defaults=new_defaults,\n",
   "        excise(self._deletions, keypath + (key,))\n",
   "        data = self._modifications\n",
   "        keypath = list(keypath)\n",
   "        while keypath:\n",
   "            subkey = keypath.pop(0)\n",
   "            if subkey not in data:\n",
   "                data[subkey] = {}\n",
   "            data = data[subkey]\n",
   "        data[key] = value\n",
   "        data = self._deletions\n",
   "        keypath = list(keypath)\n",
   "        while keypath:\n",
   "            subkey = keypath.pop(0)\n",
   "            if subkey in data:\n",
   "                data = data[subkey]\n",
   "                if data is None:\n",
   "                data[subkey] = {}\n",
   "                data = data[subkey]\n",
   "        data[key] = None\n",
   "def merge_dicts(base, updates):\n",
   "    for key, value in (updates or {}).items():\n",
   "        if key in base:\n",
   "            if isinstance(value, dict):\n",
   "                if isinstance(base[key], dict):\n",
   "                    merge_dicts(base[key], value)\n",
   "                    raise _merge_error(base[key], value)\n",
   "                if isinstance(base[key], dict):\n",
   "                    raise _merge_error(base[key], value)\n",
   "                elif hasattr(value, \"fileno\"):\n",
   "                    base[key] = value\n",
   "                    base[key] = copy.copy(value)\n",
   "            if isinstance(value, dict):\n",
   "                base[key] = copy_dict(value)\n",
   "            elif hasattr(value, \"fileno\"):\n",
   "                base[key] = value\n",
   "                base[key] = copy.copy(value)\n",
   "    return base\n",
   "    return \"{} ({!r})\".format(type(x), x)\n",
   "    return merge_dicts({}, source)\n",
   "    data = dict_\n",
   "    keypath = list(keypath)\n",
   "    leaf_key = keypath.pop()\n",
   "    while keypath:\n",
   "        key = keypath.pop(0)\n",
   "        if key not in data:\n",
   "        data = data[key]\n",
   "    if leaf_key in data:\n",
   "        del data[leaf_key]\n",
   "        if isinstance(value, dict):\n",
   "            obliterate(base[key], deletions[key])\n",
   "            del base[key]\n"
  ]
 },
 "22": {
  "name": "leading_indent_width",
  "type": "int",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/program.py",
  "lineno": "170",
  "column": "4",
  "context": "subclass might override sometime\n    # maybe?\n    leading_indent_width = 2\n    leading_indent = \" \" * leading_indent_width\n  ",
  "context_lines": "            ),\n        ]\n\n    # Other class-level global variables a subclass might override sometime\n    # maybe?\n    leading_indent_width = 2\n    leading_indent = \" \" * leading_indent_width\n    indent_width = 4\n    indent = \" \" * indent_width\n    col_padding = 3\n\n",
  "slicing": [
   "    leading_indent_width = 2\n",
   "    leading_indent = \" \" * leading_indent_width\n"
  ]
 },
 "23": {
  "name": "leading_indent",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/program.py",
  "lineno": "171",
  "column": "4",
  "context": "ime\n    # maybe?\n    leading_indent_width = 2\n    leading_indent = \" \" * leading_indent_width\n    indent_width = 4\n    indent = \" \" * indent_wid",
  "context_lines": "        ]\n\n    # Other class-level global variables a subclass might override sometime\n    # maybe?\n    leading_indent_width = 2\n    leading_indent = \" \" * leading_indent_width\n    indent_width = 4\n    indent = \" \" * indent_width\n    col_padding = 3\n\n    def __init__(\n",
  "slicing": [
   "    leading_indent_width = 2\n",
   "    leading_indent = \" \" * leading_indent_width\n"
  ]
 },
 "24": {
  "name": "indent_width",
  "type": "int",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/program.py",
  "lineno": "172",
  "column": "4",
  "context": "  leading_indent = \" \" * leading_indent_width\n    indent_width = 4\n    indent = \" \" * indent_width\n    col_padding = ",
  "context_lines": "    # Other class-level global variables a subclass might override sometime\n    # maybe?\n    leading_indent_width = 2\n    leading_indent = \" \" * leading_indent_width\n    indent_width = 4\n    indent = \" \" * indent_width\n    col_padding = 3\n\n    def __init__(\n        self,\n",
  "slicing": [
   "    leading_indent_width = 2\n",
   "    leading_indent = \" \" * leading_indent_width\n",
   "    indent_width = 4\n",
   "    indent = \" \" * indent_width\n",
   "        run = {}\n",
   "            run[\"warn\"] = True\n",
   "            run[\"pty\"] = True\n",
   "            run[\"hide\"] = self.args.hide.value\n",
   "            run[\"echo\"] = True\n",
   "            run[\"dry\"] = True\n",
   "        tasks = {}\n",
   "            tasks[\"dedupe\"] = False\n",
   "        timeouts = {}\n",
   "        command = self.args[\"command-timeout\"].value\n",
   "        if command:\n",
   "            timeouts[\"command\"] = command\n",
   "        sudo = {}\n",
   "            prompt = \"Desired 'sudo.password' config value: \"\n",
   "            sudo[\"password\"] = getpass.getpass(prompt)\n",
   "        overrides = dict(run=run, tasks=tasks, sudo=sudo, timeouts=timeouts)\n",
   "        self.config.load_overrides(overrides, merge=False)\n",
   "        runtime_path = self.args.config.value\n",
   "        if runtime_path is None:\n",
   "            runtime_path = os.environ.get(\"INVOKE_RUNTIME_CONFIG\", None)\n",
   "        self.config.set_runtime_path(runtime_path)\n",
   "                    code = e.result.exited\n",
   "                    code = e.code\n",
   "                    code = 1\n",
   "                sys.exit(code)\n",
   "        halp = self.args.help.value\n",
   "        if halp is True:\n",
   "        if halp:\n",
   "            if halp in self.parser.contexts:\n",
   "                msg = \"Saw --help <taskname>, printing per-task help & exiting\"\n",
   "                debug(msg)\n",
   "                self.print_task_help(halp)\n",
   "                raise ParseError(\"No idea what '{}' is!\".format(halp))\n",
   "        list_root = self.args.list.value  # will be True or string\n",
   "        if list_root:\n",
   "            if isinstance(list_root, six.string_types):\n",
   "                self.list_root = list_root\n",
   "                    sub = self.collection.subcollection_from_path(list_root)\n",
   "                    self.scoped_collection = sub\n",
   "                    msg = \"Sub-collection '{}' not found!\"\n",
   "                    raise Exit(msg.format(list_root))\n",
   "        klass = self.executor_class\n",
   "        config_path = self.config.tasks.executor_class\n",
   "        if config_path is not None:\n",
   "            module_path, _, class_name = config_path.rpartition(\".\")\n",
   "            module = import_module(module_path)\n",
   "            klass = getattr(module, class_name)\n",
   "        executor = klass(self.collection, self.config, self.core)\n",
   "        executor.execute(*self.tasks)\n",
   "            argv = sys.argv\n",
   "            debug(\"argv was None; using sys.argv: {!r}\".format(argv))\n",
   "        elif isinstance(argv, six.string_types):\n",
   "            argv = argv.split()\n",
   "            debug(\"argv was string-like; splitting: {!r}\".format(argv))\n",
   "        self.argv = argv\n",
   "        args = self.core_args()\n",
   "            args += self.task_args()\n",
   "        return ParserContext(args=args)\n",
   "        usage_suffix = \"task1 [--task1-opts] ... taskN [--taskN-opts]\"\n",
   "            usage_suffix = \"<subcommand> [--subcommand-opts] ...\"\n",
   "        print(\"Usage: {} [--core-opts] {}\".format(self.binary, usage_suffix))\n",
   "        parser = Parser(initial=self.initial_context, ignore_unknown=True)\n",
   "        self.core = parser.parse_argv(self.argv[1:])\n",
   "        msg = \"Core-args parse result: {!r} & unparsed: {!r}\"\n",
   "        debug(msg.format(self.core, self.core.unparsed))\n",
   "        start = self.args[\"search-root\"].value\n",
   "        loader = self.loader_class(config=self.config, start=start)\n",
   "        coll_name = self.args.collection.value\n",
   "            module, parent = loader.load(coll_name)\n",
   "            self.config.set_project_location(parent)\n",
   "                module,\n",
   "                loaded_from=parent,\n",
   "        for key, arg in new_args.items():\n",
   "            if arg.got_value:\n",
   "                context.args[key]._value = arg._value\n",
   "        result = self.parser.parse_argv(self.core.unparsed)\n",
   "        self.core_via_tasks = result.pop(0)\n",
   "        self.tasks = result\n",
   "        ctx = self.parser.contexts[name]\n",
   "        tuples = ctx.help_tuples()\n",
   "        docstring = inspect.getdoc(self.collection[name])\n",
   "        header = \"Usage: {} [--core-opts] {} {}[other tasks here ...]\"\n",
   "        opts = \"[--options] \" if tuples else \"\"\n",
   "        print(header.format(self.binary, name, opts))\n",
   "        if docstring:\n",
   "            for line in docstring.splitlines():\n",
   "                if line.strip():\n",
   "                    print(self.leading_indent + line)\n",
   "        if tuples:\n",
   "            self.print_columns(tuples)\n",
   "        focus = self.scoped_collection\n",
   "        if not focus:\n",
   "            msg = \"No tasks found in collection '{}'!\"\n",
   "            raise Exit(msg.format(focus.name))\n",
   "        pairs = self._make_pairs(self.scoped_collection)\n",
   "        self.display_with_columns(pairs=pairs)\n",
   "        pairs = self._make_pairs(self.scoped_collection)\n",
   "        extra = \"'*' denotes collection defaults\"\n",
   "        self.display_with_columns(pairs=pairs, extra=extra)\n",
   "            ancestors = []\n",
   "        pairs = []\n",
   "        indent = len(ancestors) * self.indent\n",
   "        ancestor_path = \".\".join(x for x in ancestors)\n",
   "        for name, task in sorted(six.iteritems(coll.tasks)):\n",
   "            is_default = name == coll.default\n",
   "            displayname = name\n",
   "            aliases = list(map(coll.transform, sorted(task.aliases)))\n",
   "            if ancestors or self.list_root:\n",
   "                displayname = \".{}\".format(displayname)\n",
   "                aliases = [\".{}\".format(x) for x in aliases]\n",
   "                prefix = indent\n",
   "                if is_default:\n",
   "                    displayname += \"*\"\n",
   "                prefix = ancestor_path\n",
   "                if prefix and self.list_root:\n",
   "                    prefix = \".\" + prefix\n",
   "                aliases = [prefix + alias for alias in aliases]\n",
   "                if is_default and ancestors:\n",
   "                    aliases.insert(0, prefix)\n",
   "            alias_str = \" ({})\".format(\", \".join(aliases)) if aliases else \"\"\n",
   "            full = prefix + displayname + alias_str\n",
   "            pairs.append((full, helpline(task)))\n",
   "        truncate = self.list_depth and (len(ancestors) + 1) >= self.list_depth\n",
   "        for name, subcoll in sorted(six.iteritems(coll.collections)):\n",
   "            displayname = name\n",
   "            if ancestors or self.list_root:\n",
   "                displayname = \".{}\".format(displayname)\n",
   "            if truncate:\n",
   "                tallies = [\n",
   "                    \"{} {}\".format(len(getattr(subcoll, attr)), attr)\n",
   "                    for attr in (\"tasks\", \"collections\")\n",
   "                    if getattr(subcoll, attr)\n",
   "                displayname += \" [{}]\".format(\", \".join(tallies))\n",
   "                pairs.append((indent + displayname, helpline(subcoll)))\n",
   "            elif self.list_format == \"flat\" and truncate:\n",
   "                pairs.append((ancestor_path + displayname, helpline(subcoll)))\n",
   "            if not truncate:\n",
   "                recursed_pairs = self._make_pairs(\n",
   "                    coll=subcoll, ancestors=ancestors + [name]\n",
   "                pairs.extend(recursed_pairs)\n",
   "        return pairs\n",
   "        coll = self.scoped_collection\n",
   "        data = coll.serialized()\n",
   "        print(json.dumps(data))\n",
   "        root = self.list_root\n",
   "        depth = self.list_depth\n",
   "        specifier = \" '{}'\".format(root) if root else \"\"\n",
   "        tail = \"\"\n",
   "        if depth or extra:\n",
   "            depthstr = \"depth={}\".format(depth) if depth else \"\"\n",
   "            joiner = \"; \" if (depth and extra) else \"\"\n",
   "            tail = \" ({}{}{})\".format(depthstr, joiner, extra)\n",
   "        text = \"Available{} tasks{}\".format(specifier, tail)\n",
   "            text = \"Subcommands\"\n",
   "        return text\n",
   "        root = self.list_root\n",
   "        print(\"{}:\\n\".format(self.task_list_opener(extra=extra)))\n",
   "        self.print_columns(pairs)\n",
   "        default = self.scoped_collection.default\n",
   "        if default:\n",
   "            specific = \"\"\n",
   "            if root:\n",
   "                specific = \" '{}'\".format(root)\n",
   "                default = \".{}\".format(default)\n",
   "            print(\"Default{} task: {}\\n\".format(specific, default))\n",
   "        name_width = max(len(x[0]) for x in tuples)\n",
   "        desc_width = (\n",
   "            - name_width\n",
   "        wrapper = textwrap.TextWrapper(width=desc_width)\n",
   "        for name, help_str in tuples:\n",
   "            if help_str is None:\n",
   "                help_str = \"\"\n",
   "            help_chunks = wrapper.wrap(help_str)\n",
   "            name_padding = name_width - len(name)\n",
   "                    name,\n",
   "                    name_padding * \" \",\n",
   "            if help_chunks:\n",
   "                print(spec + help_chunks[0])\n",
   "                for chunk in help_chunks[1:]:\n",
   "                    print((\" \" * len(spec)) + chunk)\n"
  ]
 },
 "25": {
  "name": "indent",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/program.py",
  "lineno": "173",
  "column": "4",
  "context": "\" * leading_indent_width\n    indent_width = 4\n    indent = \" \" * indent_width\n    col_padding = 3\n\n    def __init__(\n        sel",
  "context_lines": "    # maybe?\n    leading_indent_width = 2\n    leading_indent = \" \" * leading_indent_width\n    indent_width = 4\n    indent = \" \" * indent_width\n    col_padding = 3\n\n    def __init__(\n        self,\n        version=None,\n",
  "slicing": [
   "    leading_indent_width = 2\n",
   "    leading_indent = \" \" * leading_indent_width\n",
   "    indent_width = 4\n",
   "    indent = \" \" * indent_width\n",
   "        run = {}\n",
   "            run[\"warn\"] = True\n",
   "            run[\"pty\"] = True\n",
   "            run[\"hide\"] = self.args.hide.value\n",
   "            run[\"echo\"] = True\n",
   "            run[\"dry\"] = True\n",
   "        tasks = {}\n",
   "            tasks[\"dedupe\"] = False\n",
   "        timeouts = {}\n",
   "        command = self.args[\"command-timeout\"].value\n",
   "        if command:\n",
   "            timeouts[\"command\"] = command\n",
   "        sudo = {}\n",
   "            prompt = \"Desired 'sudo.password' config value: \"\n",
   "            sudo[\"password\"] = getpass.getpass(prompt)\n",
   "        overrides = dict(run=run, tasks=tasks, sudo=sudo, timeouts=timeouts)\n",
   "        self.config.load_overrides(overrides, merge=False)\n",
   "        runtime_path = self.args.config.value\n",
   "        if runtime_path is None:\n",
   "            runtime_path = os.environ.get(\"INVOKE_RUNTIME_CONFIG\", None)\n",
   "        self.config.set_runtime_path(runtime_path)\n",
   "                    code = e.result.exited\n",
   "                    code = e.code\n",
   "                    code = 1\n",
   "                sys.exit(code)\n",
   "        halp = self.args.help.value\n",
   "        if halp is True:\n",
   "        if halp:\n",
   "            if halp in self.parser.contexts:\n",
   "                msg = \"Saw --help <taskname>, printing per-task help & exiting\"\n",
   "                debug(msg)\n",
   "                self.print_task_help(halp)\n",
   "                raise ParseError(\"No idea what '{}' is!\".format(halp))\n",
   "        list_root = self.args.list.value  # will be True or string\n",
   "        if list_root:\n",
   "            if isinstance(list_root, six.string_types):\n",
   "                self.list_root = list_root\n",
   "                    sub = self.collection.subcollection_from_path(list_root)\n",
   "                    self.scoped_collection = sub\n",
   "                    msg = \"Sub-collection '{}' not found!\"\n",
   "                    raise Exit(msg.format(list_root))\n",
   "        klass = self.executor_class\n",
   "        config_path = self.config.tasks.executor_class\n",
   "        if config_path is not None:\n",
   "            module_path, _, class_name = config_path.rpartition(\".\")\n",
   "            module = import_module(module_path)\n",
   "            klass = getattr(module, class_name)\n",
   "        executor = klass(self.collection, self.config, self.core)\n",
   "        executor.execute(*self.tasks)\n",
   "            argv = sys.argv\n",
   "            debug(\"argv was None; using sys.argv: {!r}\".format(argv))\n",
   "        elif isinstance(argv, six.string_types):\n",
   "            argv = argv.split()\n",
   "            debug(\"argv was string-like; splitting: {!r}\".format(argv))\n",
   "        self.argv = argv\n",
   "        args = self.core_args()\n",
   "            args += self.task_args()\n",
   "        return ParserContext(args=args)\n",
   "        usage_suffix = \"task1 [--task1-opts] ... taskN [--taskN-opts]\"\n",
   "            usage_suffix = \"<subcommand> [--subcommand-opts] ...\"\n",
   "        print(\"Usage: {} [--core-opts] {}\".format(self.binary, usage_suffix))\n",
   "        parser = Parser(initial=self.initial_context, ignore_unknown=True)\n",
   "        self.core = parser.parse_argv(self.argv[1:])\n",
   "        msg = \"Core-args parse result: {!r} & unparsed: {!r}\"\n",
   "        debug(msg.format(self.core, self.core.unparsed))\n",
   "        start = self.args[\"search-root\"].value\n",
   "        loader = self.loader_class(config=self.config, start=start)\n",
   "        coll_name = self.args.collection.value\n",
   "            module, parent = loader.load(coll_name)\n",
   "            self.config.set_project_location(parent)\n",
   "                module,\n",
   "                loaded_from=parent,\n",
   "        for key, arg in new_args.items():\n",
   "            if arg.got_value:\n",
   "                context.args[key]._value = arg._value\n",
   "        result = self.parser.parse_argv(self.core.unparsed)\n",
   "        self.core_via_tasks = result.pop(0)\n",
   "        self.tasks = result\n",
   "        ctx = self.parser.contexts[name]\n",
   "        tuples = ctx.help_tuples()\n",
   "        docstring = inspect.getdoc(self.collection[name])\n",
   "        header = \"Usage: {} [--core-opts] {} {}[other tasks here ...]\"\n",
   "        opts = \"[--options] \" if tuples else \"\"\n",
   "        print(header.format(self.binary, name, opts))\n",
   "        if docstring:\n",
   "            for line in docstring.splitlines():\n",
   "                if line.strip():\n",
   "                    print(self.leading_indent + line)\n",
   "        if tuples:\n",
   "            self.print_columns(tuples)\n",
   "        focus = self.scoped_collection\n",
   "        if not focus:\n",
   "            msg = \"No tasks found in collection '{}'!\"\n",
   "            raise Exit(msg.format(focus.name))\n",
   "        pairs = self._make_pairs(self.scoped_collection)\n",
   "        self.display_with_columns(pairs=pairs)\n",
   "        pairs = self._make_pairs(self.scoped_collection)\n",
   "        extra = \"'*' denotes collection defaults\"\n",
   "        self.display_with_columns(pairs=pairs, extra=extra)\n",
   "            ancestors = []\n",
   "        pairs = []\n",
   "        indent = len(ancestors) * self.indent\n",
   "        ancestor_path = \".\".join(x for x in ancestors)\n",
   "        for name, task in sorted(six.iteritems(coll.tasks)):\n",
   "            is_default = name == coll.default\n",
   "            displayname = name\n",
   "            aliases = list(map(coll.transform, sorted(task.aliases)))\n",
   "            if ancestors or self.list_root:\n",
   "                displayname = \".{}\".format(displayname)\n",
   "                aliases = [\".{}\".format(x) for x in aliases]\n",
   "                prefix = indent\n",
   "                if is_default:\n",
   "                    displayname += \"*\"\n",
   "                prefix = ancestor_path\n",
   "                if prefix and self.list_root:\n",
   "                    prefix = \".\" + prefix\n",
   "                aliases = [prefix + alias for alias in aliases]\n",
   "                if is_default and ancestors:\n",
   "                    aliases.insert(0, prefix)\n",
   "            alias_str = \" ({})\".format(\", \".join(aliases)) if aliases else \"\"\n",
   "            full = prefix + displayname + alias_str\n",
   "            pairs.append((full, helpline(task)))\n",
   "        truncate = self.list_depth and (len(ancestors) + 1) >= self.list_depth\n",
   "        for name, subcoll in sorted(six.iteritems(coll.collections)):\n",
   "            displayname = name\n",
   "            if ancestors or self.list_root:\n",
   "                displayname = \".{}\".format(displayname)\n",
   "            if truncate:\n",
   "                tallies = [\n",
   "                    \"{} {}\".format(len(getattr(subcoll, attr)), attr)\n",
   "                    for attr in (\"tasks\", \"collections\")\n",
   "                    if getattr(subcoll, attr)\n",
   "                displayname += \" [{}]\".format(\", \".join(tallies))\n",
   "                pairs.append((indent + displayname, helpline(subcoll)))\n",
   "            elif self.list_format == \"flat\" and truncate:\n",
   "                pairs.append((ancestor_path + displayname, helpline(subcoll)))\n",
   "            if not truncate:\n",
   "                recursed_pairs = self._make_pairs(\n",
   "                    coll=subcoll, ancestors=ancestors + [name]\n",
   "                pairs.extend(recursed_pairs)\n",
   "        return pairs\n",
   "        coll = self.scoped_collection\n",
   "        data = coll.serialized()\n",
   "        print(json.dumps(data))\n",
   "        root = self.list_root\n",
   "        depth = self.list_depth\n",
   "        specifier = \" '{}'\".format(root) if root else \"\"\n",
   "        tail = \"\"\n",
   "        if depth or extra:\n",
   "            depthstr = \"depth={}\".format(depth) if depth else \"\"\n",
   "            joiner = \"; \" if (depth and extra) else \"\"\n",
   "            tail = \" ({}{}{})\".format(depthstr, joiner, extra)\n",
   "        text = \"Available{} tasks{}\".format(specifier, tail)\n",
   "            text = \"Subcommands\"\n",
   "        return text\n",
   "        root = self.list_root\n",
   "        print(\"{}:\\n\".format(self.task_list_opener(extra=extra)))\n",
   "        self.print_columns(pairs)\n",
   "        default = self.scoped_collection.default\n",
   "        if default:\n",
   "            specific = \"\"\n",
   "            if root:\n",
   "                specific = \" '{}'\".format(root)\n",
   "                default = \".{}\".format(default)\n",
   "            print(\"Default{} task: {}\\n\".format(specific, default))\n",
   "        name_width = max(len(x[0]) for x in tuples)\n",
   "        desc_width = (\n",
   "            - name_width\n",
   "        wrapper = textwrap.TextWrapper(width=desc_width)\n",
   "        for name, help_str in tuples:\n",
   "            if help_str is None:\n",
   "                help_str = \"\"\n",
   "            help_chunks = wrapper.wrap(help_str)\n",
   "            name_padding = name_width - len(name)\n",
   "                    name,\n",
   "                    name_padding * \" \",\n",
   "            if help_chunks:\n",
   "                print(spec + help_chunks[0])\n",
   "                for chunk in help_chunks[1:]:\n",
   "                    print((\" \" * len(spec)) + chunk)\n"
  ]
 },
 "26": {
  "name": "col_padding",
  "type": "int",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/program.py",
  "lineno": "174",
  "column": "4",
  "context": "ent_width = 4\n    indent = \" \" * indent_width\n    col_padding = 3\n\n    def __init__(\n        self,\n        version=N",
  "context_lines": "    leading_indent_width = 2\n    leading_indent = \" \" * leading_indent_width\n    indent_width = 4\n    indent = \" \" * indent_width\n    col_padding = 3\n\n    def __init__(\n        self,\n        version=None,\n",
  "slicing": "    col_padding = 3\n"
 },
 "27": {
  "name": "method",
  "type": "method",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/collection.py",
  "lineno": "117",
  "column": "12",
  "context": "e):\n        if isinstance(obj, Task):\n            method = self.add_task\n        elif isinstance(obj, (Collection, types.Mo",
  "context_lines": "        for name, obj in six.iteritems(kwargs):\n            self._add_object(obj, name)\n\n    def _add_object(self, obj, name=None):\n        if isinstance(obj, Task):\n            method = self.add_task\n        elif isinstance(obj, (Collection, types.ModuleType)):\n            method = self.add_collection\n        else:\n            raise TypeError(\"No idea how to insert {!r}!\".format(type(obj)))\n",
  "slicing": [
   "        args = list(args)\n",
   "        if args and isinstance(args[0], six.string_types):\n",
   "            self.name = self.transform(args.pop(0))\n",
   "        for arg in args:\n",
   "            self._add_object(arg)\n",
   "        for name, obj in six.iteritems(kwargs):\n",
   "            self._add_object(obj, name)\n",
   "        if isinstance(obj, Task):\n",
   "            method = self.add_task\n",
   "        elif isinstance(obj, (Collection, types.ModuleType)):\n",
   "            method = self.add_collection\n",
   "            raise TypeError(\"No idea how to insert {!r}!\".format(type(obj)))\n",
   "        return method(obj, name=name)\n",
   "        task_names = list(self.tasks.keys())\n",
   "        collections = [\"{}...\".format(x) for x in self.collections.keys()]\n",
   "            self.name, \", \".join(sorted(task_names) + sorted(collections))\n",
   "        module_name = module.__name__.split(\".\")[-1]\n",
   "            args = [name or obj_name or module_name]\n",
   "            kwargs = dict(\n",
   "            instance = cls(*args, **kwargs)\n",
   "            instance.__doc__ = module.__doc__\n",
   "            return instance\n",
   "        for candidate in (\"ns\", \"namespace\"):\n",
   "            obj = getattr(module, candidate, None)\n",
   "            if obj and isinstance(obj, Collection):\n",
   "                ret = instantiate(obj_name=obj.name)\n",
   "                ret.tasks = ret._transform_lexicon(obj.tasks)\n",
   "                ret.collections = ret._transform_lexicon(obj.collections)\n",
   "                ret.default = ret.transform(obj.default)\n",
   "                obj_config = copy_dict(obj._configuration)\n",
   "                    merge_dicts(obj_config, config)\n",
   "                ret._configuration = obj_config\n",
   "                return ret\n",
   "        tasks = filter(lambda x: isinstance(x, Task), vars(module).values())\n",
   "        collection = instantiate()\n",
   "        for task in tasks:\n",
   "            collection.add_task(task)\n",
   "            collection.configure(config)\n",
   "        return collection\n",
   "        if name is None:\n",
   "            if task.name:\n",
   "                name = task.name\n",
   "            elif hasattr(task.body, \"func_name\"):\n",
   "                name = task.body.func_name\n",
   "            elif hasattr(task.body, \"__name__\"):\n",
   "                name = task.__name__\n",
   "        name = self.transform(name)\n",
   "        if name in self.collections:\n",
   "            err = \"Name conflict: this collection has a sub-collection named {!r} already\"  # noqa\n",
   "            raise ValueError(err.format(name))\n",
   "        self.tasks[name] = task\n",
   "        for alias in list(task.aliases) + list(aliases or []):\n",
   "            self.tasks.alias(self.transform(alias), to=name)\n",
   "        if default is True or (default is None and task.is_default):\n",
   "                msg = \"'{}' cannot be the default because '{}' already is!\"\n",
   "                raise ValueError(msg.format(name, self.default))\n",
   "            self.default = name\n",
   "            coll = Collection.from_module(coll)\n",
   "        name = name or coll.name\n",
   "        if not name:\n",
   "        name = self.transform(name)\n",
   "        if name in self.tasks:\n",
   "            err = (\n",
   "            raise ValueError(err.format(name))\n",
   "        self.collections[name] = coll\n",
   "        parts = path.split(\".\")\n",
   "        coll = parts.pop(0)\n",
   "        rest = \".\".join(parts)\n",
   "        return coll, rest\n",
   "        parts = path.split(\".\")\n",
   "        collection = self\n",
   "        while parts:\n",
   "            collection = collection.collections[parts.pop(0)]\n",
   "        return collection\n",
   "        return self.task_with_config(name)[0]\n",
   "        task, config = self.collections[coll].task_with_config(rest)\n",
   "        return task, dict(config, **ours)\n",
   "        ours = self.configuration()\n",
   "        if not name:\n",
   "                return self[self.default], ours\n",
   "        name = self.transform(name)\n",
   "        if \".\" in name:\n",
   "            coll, rest = self._split_path(name)\n",
   "            return self._task_with_merged_config(coll, rest, ours)\n",
   "        if name in self.collections:\n",
   "            return self._task_with_merged_config(name, \"\", ours)\n",
   "        return self.tasks[name], ours\n",
   "            self[name]\n",
   "        result = []\n",
   "        for primary, aliases in six.iteritems(self.task_names):\n",
   "            task = self[primary]\n",
   "            result.append(\n",
   "                    name=primary, aliases=aliases, args=task.get_arguments()\n",
   "        return result\n",
   "        if not name:\n",
   "            return name\n",
   "        end = len(name) - 1\n",
   "        for i, char in enumerate(name):\n",
   "                i not in (0, end)\n",
   "                and char == from_\n",
   "                and name[i - 1] != \".\"\n",
   "                and name[i + 1] != \".\"\n",
   "            replaced.append(char)\n",
   "            ret[name] = list(map(self.transform, task.aliases))\n",
   "            for task_name, aliases in six.iteritems(coll.task_names):\n",
   "                    map(lambda x: self.subtask_name(coll_name, x), aliases)\n",
   "                if coll.default == task_name:\n",
   "                ret[self.subtask_name(coll_name, task_name)] = aliases\n",
   "        return ret\n",
   "                    \"name\": self.transform(x.name),\n",
   "                    \"help\": helpline(x),\n",
   "                    \"aliases\": [self.transform(y) for y in x.aliases],\n",
   "                for x in sorted(self.tasks.values(), key=lambda x: x.name)\n",
   "                x.serialized()\n",
   "                    self.collections.values(), key=lambda x: x.name or \"\"\n"
  ]
 },
 "28": {
  "name": "method",
  "type": "method",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/collection.py",
  "lineno": "119",
  "column": "12",
  "context": "obj, (Collection, types.ModuleType)):\n            method = self.add_collection\n        else:\n            raise TypeError(\"No idea",
  "context_lines": "    def _add_object(self, obj, name=None):\n        if isinstance(obj, Task):\n            method = self.add_task\n        elif isinstance(obj, (Collection, types.ModuleType)):\n            method = self.add_collection\n        else:\n            raise TypeError(\"No idea how to insert {!r}!\".format(type(obj)))\n        return method(obj, name=name)\n\n    def __repr__(self):\n",
  "slicing": [
   "        args = list(args)\n",
   "        if args and isinstance(args[0], six.string_types):\n",
   "            self.name = self.transform(args.pop(0))\n",
   "        for arg in args:\n",
   "            self._add_object(arg)\n",
   "        for name, obj in six.iteritems(kwargs):\n",
   "            self._add_object(obj, name)\n",
   "        if isinstance(obj, Task):\n",
   "            method = self.add_task\n",
   "        elif isinstance(obj, (Collection, types.ModuleType)):\n",
   "            method = self.add_collection\n",
   "            raise TypeError(\"No idea how to insert {!r}!\".format(type(obj)))\n",
   "        return method(obj, name=name)\n",
   "        task_names = list(self.tasks.keys())\n",
   "        collections = [\"{}...\".format(x) for x in self.collections.keys()]\n",
   "            self.name, \", \".join(sorted(task_names) + sorted(collections))\n",
   "        module_name = module.__name__.split(\".\")[-1]\n",
   "            args = [name or obj_name or module_name]\n",
   "            kwargs = dict(\n",
   "            instance = cls(*args, **kwargs)\n",
   "            instance.__doc__ = module.__doc__\n",
   "            return instance\n",
   "        for candidate in (\"ns\", \"namespace\"):\n",
   "            obj = getattr(module, candidate, None)\n",
   "            if obj and isinstance(obj, Collection):\n",
   "                ret = instantiate(obj_name=obj.name)\n",
   "                ret.tasks = ret._transform_lexicon(obj.tasks)\n",
   "                ret.collections = ret._transform_lexicon(obj.collections)\n",
   "                ret.default = ret.transform(obj.default)\n",
   "                obj_config = copy_dict(obj._configuration)\n",
   "                    merge_dicts(obj_config, config)\n",
   "                ret._configuration = obj_config\n",
   "                return ret\n",
   "        tasks = filter(lambda x: isinstance(x, Task), vars(module).values())\n",
   "        collection = instantiate()\n",
   "        for task in tasks:\n",
   "            collection.add_task(task)\n",
   "            collection.configure(config)\n",
   "        return collection\n",
   "        if name is None:\n",
   "            if task.name:\n",
   "                name = task.name\n",
   "            elif hasattr(task.body, \"func_name\"):\n",
   "                name = task.body.func_name\n",
   "            elif hasattr(task.body, \"__name__\"):\n",
   "                name = task.__name__\n",
   "        name = self.transform(name)\n",
   "        if name in self.collections:\n",
   "            err = \"Name conflict: this collection has a sub-collection named {!r} already\"  # noqa\n",
   "            raise ValueError(err.format(name))\n",
   "        self.tasks[name] = task\n",
   "        for alias in list(task.aliases) + list(aliases or []):\n",
   "            self.tasks.alias(self.transform(alias), to=name)\n",
   "        if default is True or (default is None and task.is_default):\n",
   "                msg = \"'{}' cannot be the default because '{}' already is!\"\n",
   "                raise ValueError(msg.format(name, self.default))\n",
   "            self.default = name\n",
   "            coll = Collection.from_module(coll)\n",
   "        name = name or coll.name\n",
   "        if not name:\n",
   "        name = self.transform(name)\n",
   "        if name in self.tasks:\n",
   "            err = (\n",
   "            raise ValueError(err.format(name))\n",
   "        self.collections[name] = coll\n",
   "        parts = path.split(\".\")\n",
   "        coll = parts.pop(0)\n",
   "        rest = \".\".join(parts)\n",
   "        return coll, rest\n",
   "        parts = path.split(\".\")\n",
   "        collection = self\n",
   "        while parts:\n",
   "            collection = collection.collections[parts.pop(0)]\n",
   "        return collection\n",
   "        return self.task_with_config(name)[0]\n",
   "        task, config = self.collections[coll].task_with_config(rest)\n",
   "        return task, dict(config, **ours)\n",
   "        ours = self.configuration()\n",
   "        if not name:\n",
   "                return self[self.default], ours\n",
   "        name = self.transform(name)\n",
   "        if \".\" in name:\n",
   "            coll, rest = self._split_path(name)\n",
   "            return self._task_with_merged_config(coll, rest, ours)\n",
   "        if name in self.collections:\n",
   "            return self._task_with_merged_config(name, \"\", ours)\n",
   "        return self.tasks[name], ours\n",
   "            self[name]\n",
   "        result = []\n",
   "        for primary, aliases in six.iteritems(self.task_names):\n",
   "            task = self[primary]\n",
   "            result.append(\n",
   "                    name=primary, aliases=aliases, args=task.get_arguments()\n",
   "        return result\n",
   "        if not name:\n",
   "            return name\n",
   "        end = len(name) - 1\n",
   "        for i, char in enumerate(name):\n",
   "                i not in (0, end)\n",
   "                and char == from_\n",
   "                and name[i - 1] != \".\"\n",
   "                and name[i + 1] != \".\"\n",
   "            replaced.append(char)\n",
   "            ret[name] = list(map(self.transform, task.aliases))\n",
   "            for task_name, aliases in six.iteritems(coll.task_names):\n",
   "                    map(lambda x: self.subtask_name(coll_name, x), aliases)\n",
   "                if coll.default == task_name:\n",
   "                ret[self.subtask_name(coll_name, task_name)] = aliases\n",
   "        return ret\n",
   "                    \"name\": self.transform(x.name),\n",
   "                    \"help\": helpline(x),\n",
   "                    \"aliases\": [self.transform(y) for y in x.aliases],\n",
   "                for x in sorted(self.tasks.values(), key=lambda x: x.name)\n",
   "                x.serialized()\n",
   "                    self.collections.values(), key=lambda x: x.name or \"\"\n"
  ]
 },
 "29": {
  "name": "instance",
  "type": "Collection",
  "class": "customized",
  "approach": "annotation",
  "file_path": "invoke/invoke/collection.py",
  "lineno": "208",
  "column": "12",
  "context": "h_names=auto_dash_names\n            )\n            instance = cls(*args, **kwargs)\n            instance.__doc__ = module.__doc__\n    ",
  "context_lines": "            args = [name or obj_name or module_name]\n            kwargs = dict(\n                loaded_from=loaded_from, auto_dash_names=auto_dash_names\n            )\n            instance = cls(*args, **kwargs)\n            instance.__doc__ = module.__doc__\n            return instance\n\n        # See if the module provides a default NS to use in lieu of creating\n        # our own collection.\n",
  "slicing": [
   "        args = list(args)\n",
   "        if args and isinstance(args[0], six.string_types):\n",
   "            self.name = self.transform(args.pop(0))\n",
   "        for arg in args:\n",
   "            self._add_object(arg)\n",
   "        for name, obj in six.iteritems(kwargs):\n",
   "            self._add_object(obj, name)\n",
   "        if isinstance(obj, Task):\n",
   "            method = self.add_task\n",
   "        elif isinstance(obj, (Collection, types.ModuleType)):\n",
   "            method = self.add_collection\n",
   "            raise TypeError(\"No idea how to insert {!r}!\".format(type(obj)))\n",
   "        return method(obj, name=name)\n",
   "        task_names = list(self.tasks.keys())\n",
   "        collections = [\"{}...\".format(x) for x in self.collections.keys()]\n",
   "            self.name, \", \".join(sorted(task_names) + sorted(collections))\n",
   "        module_name = module.__name__.split(\".\")[-1]\n",
   "            args = [name or obj_name or module_name]\n",
   "            kwargs = dict(\n",
   "            instance = cls(*args, **kwargs)\n",
   "            instance.__doc__ = module.__doc__\n",
   "            return instance\n",
   "        for candidate in (\"ns\", \"namespace\"):\n",
   "            obj = getattr(module, candidate, None)\n",
   "            if obj and isinstance(obj, Collection):\n",
   "                ret = instantiate(obj_name=obj.name)\n",
   "                ret.tasks = ret._transform_lexicon(obj.tasks)\n",
   "                ret.collections = ret._transform_lexicon(obj.collections)\n",
   "                ret.default = ret.transform(obj.default)\n",
   "                obj_config = copy_dict(obj._configuration)\n",
   "                    merge_dicts(obj_config, config)\n",
   "                ret._configuration = obj_config\n",
   "                return ret\n",
   "        tasks = filter(lambda x: isinstance(x, Task), vars(module).values())\n",
   "        collection = instantiate()\n",
   "        for task in tasks:\n",
   "            collection.add_task(task)\n",
   "            collection.configure(config)\n",
   "        return collection\n",
   "        if name is None:\n",
   "            if task.name:\n",
   "                name = task.name\n",
   "            elif hasattr(task.body, \"func_name\"):\n",
   "                name = task.body.func_name\n",
   "            elif hasattr(task.body, \"__name__\"):\n",
   "                name = task.__name__\n",
   "        name = self.transform(name)\n",
   "        if name in self.collections:\n",
   "            err = \"Name conflict: this collection has a sub-collection named {!r} already\"  # noqa\n",
   "            raise ValueError(err.format(name))\n",
   "        self.tasks[name] = task\n",
   "        for alias in list(task.aliases) + list(aliases or []):\n",
   "            self.tasks.alias(self.transform(alias), to=name)\n",
   "        if default is True or (default is None and task.is_default):\n",
   "                msg = \"'{}' cannot be the default because '{}' already is!\"\n",
   "                raise ValueError(msg.format(name, self.default))\n",
   "            self.default = name\n",
   "            coll = Collection.from_module(coll)\n",
   "        name = name or coll.name\n",
   "        if not name:\n",
   "        name = self.transform(name)\n",
   "        if name in self.tasks:\n",
   "            err = (\n",
   "            raise ValueError(err.format(name))\n",
   "        self.collections[name] = coll\n",
   "        parts = path.split(\".\")\n",
   "        coll = parts.pop(0)\n",
   "        rest = \".\".join(parts)\n",
   "        return coll, rest\n",
   "        parts = path.split(\".\")\n",
   "        collection = self\n",
   "        while parts:\n",
   "            collection = collection.collections[parts.pop(0)]\n",
   "        return collection\n",
   "        return self.task_with_config(name)[0]\n",
   "        task, config = self.collections[coll].task_with_config(rest)\n",
   "        return task, dict(config, **ours)\n",
   "        ours = self.configuration()\n",
   "        if not name:\n",
   "                return self[self.default], ours\n",
   "        name = self.transform(name)\n",
   "        if \".\" in name:\n",
   "            coll, rest = self._split_path(name)\n",
   "            return self._task_with_merged_config(coll, rest, ours)\n",
   "        if name in self.collections:\n",
   "            return self._task_with_merged_config(name, \"\", ours)\n",
   "        return self.tasks[name], ours\n",
   "            self[name]\n",
   "        result = []\n",
   "        for primary, aliases in six.iteritems(self.task_names):\n",
   "            task = self[primary]\n",
   "            result.append(\n",
   "                    name=primary, aliases=aliases, args=task.get_arguments()\n",
   "        return result\n",
   "        if not name:\n",
   "            return name\n",
   "        end = len(name) - 1\n",
   "        for i, char in enumerate(name):\n",
   "                i not in (0, end)\n",
   "                and char == from_\n",
   "                and name[i - 1] != \".\"\n",
   "                and name[i + 1] != \".\"\n",
   "            replaced.append(char)\n",
   "            ret[name] = list(map(self.transform, task.aliases))\n",
   "            for task_name, aliases in six.iteritems(coll.task_names):\n",
   "                    map(lambda x: self.subtask_name(coll_name, x), aliases)\n",
   "                if coll.default == task_name:\n",
   "                ret[self.subtask_name(coll_name, task_name)] = aliases\n",
   "        return ret\n",
   "                    \"name\": self.transform(x.name),\n",
   "                    \"help\": helpline(x),\n",
   "                    \"aliases\": [self.transform(y) for y in x.aliases],\n",
   "                for x in sorted(self.tasks.values(), key=lambda x: x.name)\n",
   "                x.serialized()\n",
   "                    self.collections.values(), key=lambda x: x.name or \"\"\n"
  ]
 },
 "30": {
  "name": "obj",
  "type": "NoneType",
  "class": "unknown",
  "approach": "annotation",
  "file_path": "invoke/invoke/collection.py",
  "lineno": "215",
  "column": "12",
  "context": "for candidate in (\"ns\", \"namespace\"):\n            obj = getattr(module, candidate, None)\n            if obj and isinstance(obj, Collection)",
  "context_lines": "            return instance\n\n        # See if the module provides a default NS to use in lieu of creating\n        # our own collection.\n        for candidate in (\"ns\", \"namespace\"):\n            obj = getattr(module, candidate, None)\n            if obj and isinstance(obj, Collection):\n                # TODO: make this into Collection.clone() or similar?\n                ret = instantiate(obj_name=obj.name)\n                ret.tasks = ret._transform_lexicon(obj.tasks)\n",
  "slicing": [
   "        args = list(args)\n",
   "        if args and isinstance(args[0], six.string_types):\n",
   "            self.name = self.transform(args.pop(0))\n",
   "        for arg in args:\n",
   "            self._add_object(arg)\n",
   "        for name, obj in six.iteritems(kwargs):\n",
   "            self._add_object(obj, name)\n",
   "        if isinstance(obj, Task):\n",
   "            method = self.add_task\n",
   "        elif isinstance(obj, (Collection, types.ModuleType)):\n",
   "            method = self.add_collection\n",
   "            raise TypeError(\"No idea how to insert {!r}!\".format(type(obj)))\n",
   "        return method(obj, name=name)\n",
   "        task_names = list(self.tasks.keys())\n",
   "        collections = [\"{}...\".format(x) for x in self.collections.keys()]\n",
   "            self.name, \", \".join(sorted(task_names) + sorted(collections))\n",
   "        module_name = module.__name__.split(\".\")[-1]\n",
   "            args = [name or obj_name or module_name]\n",
   "            kwargs = dict(\n",
   "            instance = cls(*args, **kwargs)\n",
   "            instance.__doc__ = module.__doc__\n",
   "            return instance\n",
   "        for candidate in (\"ns\", \"namespace\"):\n",
   "            obj = getattr(module, candidate, None)\n",
   "            if obj and isinstance(obj, Collection):\n",
   "                ret = instantiate(obj_name=obj.name)\n",
   "                ret.tasks = ret._transform_lexicon(obj.tasks)\n",
   "                ret.collections = ret._transform_lexicon(obj.collections)\n",
   "                ret.default = ret.transform(obj.default)\n",
   "                obj_config = copy_dict(obj._configuration)\n",
   "                    merge_dicts(obj_config, config)\n",
   "                ret._configuration = obj_config\n",
   "                return ret\n",
   "        tasks = filter(lambda x: isinstance(x, Task), vars(module).values())\n",
   "        collection = instantiate()\n",
   "        for task in tasks:\n",
   "            collection.add_task(task)\n",
   "            collection.configure(config)\n",
   "        return collection\n",
   "        if name is None:\n",
   "            if task.name:\n",
   "                name = task.name\n",
   "            elif hasattr(task.body, \"func_name\"):\n",
   "                name = task.body.func_name\n",
   "            elif hasattr(task.body, \"__name__\"):\n",
   "                name = task.__name__\n",
   "        name = self.transform(name)\n",
   "        if name in self.collections:\n",
   "            err = \"Name conflict: this collection has a sub-collection named {!r} already\"  # noqa\n",
   "            raise ValueError(err.format(name))\n",
   "        self.tasks[name] = task\n",
   "        for alias in list(task.aliases) + list(aliases or []):\n",
   "            self.tasks.alias(self.transform(alias), to=name)\n",
   "        if default is True or (default is None and task.is_default):\n",
   "                msg = \"'{}' cannot be the default because '{}' already is!\"\n",
   "                raise ValueError(msg.format(name, self.default))\n",
   "            self.default = name\n",
   "            coll = Collection.from_module(coll)\n",
   "        name = name or coll.name\n",
   "        if not name:\n",
   "        name = self.transform(name)\n",
   "        if name in self.tasks:\n",
   "            err = (\n",
   "            raise ValueError(err.format(name))\n",
   "        self.collections[name] = coll\n",
   "        parts = path.split(\".\")\n",
   "        coll = parts.pop(0)\n",
   "        rest = \".\".join(parts)\n",
   "        return coll, rest\n",
   "        parts = path.split(\".\")\n",
   "        collection = self\n",
   "        while parts:\n",
   "            collection = collection.collections[parts.pop(0)]\n",
   "        return collection\n",
   "        return self.task_with_config(name)[0]\n",
   "        task, config = self.collections[coll].task_with_config(rest)\n",
   "        return task, dict(config, **ours)\n",
   "        ours = self.configuration()\n",
   "        if not name:\n",
   "                return self[self.default], ours\n",
   "        name = self.transform(name)\n",
   "        if \".\" in name:\n",
   "            coll, rest = self._split_path(name)\n",
   "            return self._task_with_merged_config(coll, rest, ours)\n",
   "        if name in self.collections:\n",
   "            return self._task_with_merged_config(name, \"\", ours)\n",
   "        return self.tasks[name], ours\n",
   "            self[name]\n",
   "        result = []\n",
   "        for primary, aliases in six.iteritems(self.task_names):\n",
   "            task = self[primary]\n",
   "            result.append(\n",
   "                    name=primary, aliases=aliases, args=task.get_arguments()\n",
   "        return result\n",
   "        if not name:\n",
   "            return name\n",
   "        end = len(name) - 1\n",
   "        for i, char in enumerate(name):\n",
   "                i not in (0, end)\n",
   "                and char == from_\n",
   "                and name[i - 1] != \".\"\n",
   "                and name[i + 1] != \".\"\n",
   "            replaced.append(char)\n",
   "            ret[name] = list(map(self.transform, task.aliases))\n",
   "            for task_name, aliases in six.iteritems(coll.task_names):\n",
   "                    map(lambda x: self.subtask_name(coll_name, x), aliases)\n",
   "                if coll.default == task_name:\n",
   "                ret[self.subtask_name(coll_name, task_name)] = aliases\n",
   "        return ret\n",
   "                    \"name\": self.transform(x.name),\n",
   "                    \"help\": helpline(x),\n",
   "                    \"aliases\": [self.transform(y) for y in x.aliases],\n",
   "                for x in sorted(self.tasks.values(), key=lambda x: x.name)\n",
   "                x.serialized()\n",
   "                    self.collections.values(), key=lambda x: x.name or \"\"\n"
  ]
 },
 "31": {
  "name": "tasks",
  "type": "filter",
  "class": "unknown",
  "approach": "annotation",
  "file_path": "invoke/invoke/collection.py",
  "lineno": "229",
  "column": "8",
  "context": "r own collection from the module's tasks.\n        tasks = filter(lambda x: isinstance(x, Task), vars(module).values())\n        # Again, explicit name wins over implicit ",
  "context_lines": "                    merge_dicts(obj_config, config)\n                ret._configuration = obj_config\n                return ret\n        # Failing that, make our own collection from the module's tasks.\n        tasks = filter(lambda x: isinstance(x, Task), vars(module).values())\n        # Again, explicit name wins over implicit one from module path\n        collection = instantiate()\n        for task in tasks:\n            collection.add_task(task)\n",
  "slicing": [
   "        args = list(args)\n",
   "        if args and isinstance(args[0], six.string_types):\n",
   "            self.name = self.transform(args.pop(0))\n",
   "        for arg in args:\n",
   "            self._add_object(arg)\n",
   "        for name, obj in six.iteritems(kwargs):\n",
   "            self._add_object(obj, name)\n",
   "        if isinstance(obj, Task):\n",
   "            method = self.add_task\n",
   "        elif isinstance(obj, (Collection, types.ModuleType)):\n",
   "            method = self.add_collection\n",
   "            raise TypeError(\"No idea how to insert {!r}!\".format(type(obj)))\n",
   "        return method(obj, name=name)\n",
   "        task_names = list(self.tasks.keys())\n",
   "        collections = [\"{}...\".format(x) for x in self.collections.keys()]\n",
   "            self.name, \", \".join(sorted(task_names) + sorted(collections))\n",
   "        module_name = module.__name__.split(\".\")[-1]\n",
   "            args = [name or obj_name or module_name]\n",
   "            kwargs = dict(\n",
   "            instance = cls(*args, **kwargs)\n",
   "            instance.__doc__ = module.__doc__\n",
   "            return instance\n",
   "        for candidate in (\"ns\", \"namespace\"):\n",
   "            obj = getattr(module, candidate, None)\n",
   "            if obj and isinstance(obj, Collection):\n",
   "                ret = instantiate(obj_name=obj.name)\n",
   "                ret.tasks = ret._transform_lexicon(obj.tasks)\n",
   "                ret.collections = ret._transform_lexicon(obj.collections)\n",
   "                ret.default = ret.transform(obj.default)\n",
   "                obj_config = copy_dict(obj._configuration)\n",
   "                    merge_dicts(obj_config, config)\n",
   "                ret._configuration = obj_config\n",
   "                return ret\n",
   "        tasks = filter(lambda x: isinstance(x, Task), vars(module).values())\n",
   "        collection = instantiate()\n",
   "        for task in tasks:\n",
   "            collection.add_task(task)\n",
   "            collection.configure(config)\n",
   "        return collection\n",
   "        if name is None:\n",
   "            if task.name:\n",
   "                name = task.name\n",
   "            elif hasattr(task.body, \"func_name\"):\n",
   "                name = task.body.func_name\n",
   "            elif hasattr(task.body, \"__name__\"):\n",
   "                name = task.__name__\n",
   "        name = self.transform(name)\n",
   "        if name in self.collections:\n",
   "            err = \"Name conflict: this collection has a sub-collection named {!r} already\"  # noqa\n",
   "            raise ValueError(err.format(name))\n",
   "        self.tasks[name] = task\n",
   "        for alias in list(task.aliases) + list(aliases or []):\n",
   "            self.tasks.alias(self.transform(alias), to=name)\n",
   "        if default is True or (default is None and task.is_default):\n",
   "                msg = \"'{}' cannot be the default because '{}' already is!\"\n",
   "                raise ValueError(msg.format(name, self.default))\n",
   "            self.default = name\n",
   "            coll = Collection.from_module(coll)\n",
   "        name = name or coll.name\n",
   "        if not name:\n",
   "        name = self.transform(name)\n",
   "        if name in self.tasks:\n",
   "            err = (\n",
   "            raise ValueError(err.format(name))\n",
   "        self.collections[name] = coll\n",
   "        parts = path.split(\".\")\n",
   "        coll = parts.pop(0)\n",
   "        rest = \".\".join(parts)\n",
   "        return coll, rest\n",
   "        parts = path.split(\".\")\n",
   "        collection = self\n",
   "        while parts:\n",
   "            collection = collection.collections[parts.pop(0)]\n",
   "        return collection\n",
   "        return self.task_with_config(name)[0]\n",
   "        task, config = self.collections[coll].task_with_config(rest)\n",
   "        return task, dict(config, **ours)\n",
   "        ours = self.configuration()\n",
   "        if not name:\n",
   "                return self[self.default], ours\n",
   "        name = self.transform(name)\n",
   "        if \".\" in name:\n",
   "            coll, rest = self._split_path(name)\n",
   "            return self._task_with_merged_config(coll, rest, ours)\n",
   "        if name in self.collections:\n",
   "            return self._task_with_merged_config(name, \"\", ours)\n",
   "        return self.tasks[name], ours\n",
   "            self[name]\n",
   "        result = []\n",
   "        for primary, aliases in six.iteritems(self.task_names):\n",
   "            task = self[primary]\n",
   "            result.append(\n",
   "                    name=primary, aliases=aliases, args=task.get_arguments()\n",
   "        return result\n",
   "        if not name:\n",
   "            return name\n",
   "        end = len(name) - 1\n",
   "        for i, char in enumerate(name):\n",
   "                i not in (0, end)\n",
   "                and char == from_\n",
   "                and name[i - 1] != \".\"\n",
   "                and name[i + 1] != \".\"\n",
   "            replaced.append(char)\n",
   "            ret[name] = list(map(self.transform, task.aliases))\n",
   "            for task_name, aliases in six.iteritems(coll.task_names):\n",
   "                    map(lambda x: self.subtask_name(coll_name, x), aliases)\n",
   "                if coll.default == task_name:\n",
   "                ret[self.subtask_name(coll_name, task_name)] = aliases\n",
   "        return ret\n",
   "                    \"name\": self.transform(x.name),\n",
   "                    \"help\": helpline(x),\n",
   "                    \"aliases\": [self.transform(y) for y in x.aliases],\n",
   "                for x in sorted(self.tasks.values(), key=lambda x: x.name)\n",
   "                x.serialized()\n",
   "                    self.collections.values(), key=lambda x: x.name or \"\"\n"
  ]
 },
 "32": {
  "name": "collection",
  "type": "Collection",
  "class": "customized",
  "approach": "annotation",
  "file_path": "invoke/invoke/collection.py",
  "lineno": "231",
  "column": "8",
  "context": "e wins over implicit one from module path\n        collection = instantiate()\n        for task in tasks:\n            collection.",
  "context_lines": "                return ret\n        # Failing that, make our own collection from the module's tasks.\n        tasks = filter(lambda x: isinstance(x, Task), vars(module).values())\n        # Again, explicit name wins over implicit one from module path\n        collection = instantiate()\n        for task in tasks:\n            collection.add_task(task)\n        if config:\n            collection.configure(config)\n",
  "slicing": [
   "        args = list(args)\n",
   "        if args and isinstance(args[0], six.string_types):\n",
   "            self.name = self.transform(args.pop(0))\n",
   "        for arg in args:\n",
   "            self._add_object(arg)\n",
   "        for name, obj in six.iteritems(kwargs):\n",
   "            self._add_object(obj, name)\n",
   "        if isinstance(obj, Task):\n",
   "            method = self.add_task\n",
   "        elif isinstance(obj, (Collection, types.ModuleType)):\n",
   "            method = self.add_collection\n",
   "            raise TypeError(\"No idea how to insert {!r}!\".format(type(obj)))\n",
   "        return method(obj, name=name)\n",
   "        task_names = list(self.tasks.keys())\n",
   "        collections = [\"{}...\".format(x) for x in self.collections.keys()]\n",
   "            self.name, \", \".join(sorted(task_names) + sorted(collections))\n",
   "        module_name = module.__name__.split(\".\")[-1]\n",
   "            args = [name or obj_name or module_name]\n",
   "            kwargs = dict(\n",
   "            instance = cls(*args, **kwargs)\n",
   "            instance.__doc__ = module.__doc__\n",
   "            return instance\n",
   "        for candidate in (\"ns\", \"namespace\"):\n",
   "            obj = getattr(module, candidate, None)\n",
   "            if obj and isinstance(obj, Collection):\n",
   "                ret = instantiate(obj_name=obj.name)\n",
   "                ret.tasks = ret._transform_lexicon(obj.tasks)\n",
   "                ret.collections = ret._transform_lexicon(obj.collections)\n",
   "                ret.default = ret.transform(obj.default)\n",
   "                obj_config = copy_dict(obj._configuration)\n",
   "                    merge_dicts(obj_config, config)\n",
   "                ret._configuration = obj_config\n",
   "                return ret\n",
   "        tasks = filter(lambda x: isinstance(x, Task), vars(module).values())\n",
   "        collection = instantiate()\n",
   "        for task in tasks:\n",
   "            collection.add_task(task)\n",
   "            collection.configure(config)\n",
   "        return collection\n",
   "        if name is None:\n",
   "            if task.name:\n",
   "                name = task.name\n",
   "            elif hasattr(task.body, \"func_name\"):\n",
   "                name = task.body.func_name\n",
   "            elif hasattr(task.body, \"__name__\"):\n",
   "                name = task.__name__\n",
   "        name = self.transform(name)\n",
   "        if name in self.collections:\n",
   "            err = \"Name conflict: this collection has a sub-collection named {!r} already\"  # noqa\n",
   "            raise ValueError(err.format(name))\n",
   "        self.tasks[name] = task\n",
   "        for alias in list(task.aliases) + list(aliases or []):\n",
   "            self.tasks.alias(self.transform(alias), to=name)\n",
   "        if default is True or (default is None and task.is_default):\n",
   "                msg = \"'{}' cannot be the default because '{}' already is!\"\n",
   "                raise ValueError(msg.format(name, self.default))\n",
   "            self.default = name\n",
   "            coll = Collection.from_module(coll)\n",
   "        name = name or coll.name\n",
   "        if not name:\n",
   "        name = self.transform(name)\n",
   "        if name in self.tasks:\n",
   "            err = (\n",
   "            raise ValueError(err.format(name))\n",
   "        self.collections[name] = coll\n",
   "        parts = path.split(\".\")\n",
   "        coll = parts.pop(0)\n",
   "        rest = \".\".join(parts)\n",
   "        return coll, rest\n",
   "        parts = path.split(\".\")\n",
   "        collection = self\n",
   "        while parts:\n",
   "            collection = collection.collections[parts.pop(0)]\n",
   "        return collection\n",
   "        return self.task_with_config(name)[0]\n",
   "        task, config = self.collections[coll].task_with_config(rest)\n",
   "        return task, dict(config, **ours)\n",
   "        ours = self.configuration()\n",
   "        if not name:\n",
   "                return self[self.default], ours\n",
   "        name = self.transform(name)\n",
   "        if \".\" in name:\n",
   "            coll, rest = self._split_path(name)\n",
   "            return self._task_with_merged_config(coll, rest, ours)\n",
   "        if name in self.collections:\n",
   "            return self._task_with_merged_config(name, \"\", ours)\n",
   "        return self.tasks[name], ours\n",
   "            self[name]\n",
   "        result = []\n",
   "        for primary, aliases in six.iteritems(self.task_names):\n",
   "            task = self[primary]\n",
   "            result.append(\n",
   "                    name=primary, aliases=aliases, args=task.get_arguments()\n",
   "        return result\n",
   "        if not name:\n",
   "            return name\n",
   "        end = len(name) - 1\n",
   "        for i, char in enumerate(name):\n",
   "                i not in (0, end)\n",
   "                and char == from_\n",
   "                and name[i - 1] != \".\"\n",
   "                and name[i + 1] != \".\"\n",
   "            replaced.append(char)\n",
   "            ret[name] = list(map(self.transform, task.aliases))\n",
   "            for task_name, aliases in six.iteritems(coll.task_names):\n",
   "                    map(lambda x: self.subtask_name(coll_name, x), aliases)\n",
   "                if coll.default == task_name:\n",
   "                ret[self.subtask_name(coll_name, task_name)] = aliases\n",
   "        return ret\n",
   "                    \"name\": self.transform(x.name),\n",
   "                    \"help\": helpline(x),\n",
   "                    \"aliases\": [self.transform(y) for y in x.aliases],\n",
   "                for x in sorted(self.tasks.values(), key=lambda x: x.name)\n",
   "                x.serialized()\n",
   "                    self.collections.values(), key=lambda x: x.name or \"\"\n"
  ]
 },
 "33": {
  "name": "name",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/collection.py",
  "lineno": "260",
  "column": "16",
  "context": "s None:\n            if task.name:\n                name = task.name\n            elif hasattr(task.body, \"func_name\"):\n",
  "context_lines": "        .. versionadded:: 1.0\n        \"\"\"\n        if name is None:\n            if task.name:\n                name = task.name\n            elif hasattr(task.body, \"func_name\"):\n                name = task.body.func_name\n            elif hasattr(task.body, \"__name__\"):\n                name = task.__name__\n",
  "slicing": [
   "        args = list(args)\n",
   "        if args and isinstance(args[0], six.string_types):\n",
   "            self.name = self.transform(args.pop(0))\n",
   "        for arg in args:\n",
   "            self._add_object(arg)\n",
   "        for name, obj in six.iteritems(kwargs):\n",
   "            self._add_object(obj, name)\n",
   "        if isinstance(obj, Task):\n",
   "            method = self.add_task\n",
   "        elif isinstance(obj, (Collection, types.ModuleType)):\n",
   "            method = self.add_collection\n",
   "            raise TypeError(\"No idea how to insert {!r}!\".format(type(obj)))\n",
   "        return method(obj, name=name)\n",
   "        task_names = list(self.tasks.keys())\n",
   "        collections = [\"{}...\".format(x) for x in self.collections.keys()]\n",
   "            self.name, \", \".join(sorted(task_names) + sorted(collections))\n",
   "        module_name = module.__name__.split(\".\")[-1]\n",
   "            args = [name or obj_name or module_name]\n",
   "            kwargs = dict(\n",
   "            instance = cls(*args, **kwargs)\n",
   "            instance.__doc__ = module.__doc__\n",
   "            return instance\n",
   "        for candidate in (\"ns\", \"namespace\"):\n",
   "            obj = getattr(module, candidate, None)\n",
   "            if obj and isinstance(obj, Collection):\n",
   "                ret = instantiate(obj_name=obj.name)\n",
   "                ret.tasks = ret._transform_lexicon(obj.tasks)\n",
   "                ret.collections = ret._transform_lexicon(obj.collections)\n",
   "                ret.default = ret.transform(obj.default)\n",
   "                obj_config = copy_dict(obj._configuration)\n",
   "                    merge_dicts(obj_config, config)\n",
   "                ret._configuration = obj_config\n",
   "                return ret\n",
   "        tasks = filter(lambda x: isinstance(x, Task), vars(module).values())\n",
   "        collection = instantiate()\n",
   "        for task in tasks:\n",
   "            collection.add_task(task)\n",
   "            collection.configure(config)\n",
   "        return collection\n",
   "        if name is None:\n",
   "            if task.name:\n",
   "                name = task.name\n",
   "            elif hasattr(task.body, \"func_name\"):\n",
   "                name = task.body.func_name\n",
   "            elif hasattr(task.body, \"__name__\"):\n",
   "                name = task.__name__\n",
   "        name = self.transform(name)\n",
   "        if name in self.collections:\n",
   "            err = \"Name conflict: this collection has a sub-collection named {!r} already\"  # noqa\n",
   "            raise ValueError(err.format(name))\n",
   "        self.tasks[name] = task\n",
   "        for alias in list(task.aliases) + list(aliases or []):\n",
   "            self.tasks.alias(self.transform(alias), to=name)\n",
   "        if default is True or (default is None and task.is_default):\n",
   "                msg = \"'{}' cannot be the default because '{}' already is!\"\n",
   "                raise ValueError(msg.format(name, self.default))\n",
   "            self.default = name\n",
   "            coll = Collection.from_module(coll)\n",
   "        name = name or coll.name\n",
   "        if not name:\n",
   "        name = self.transform(name)\n",
   "        if name in self.tasks:\n",
   "            err = (\n",
   "            raise ValueError(err.format(name))\n",
   "        self.collections[name] = coll\n",
   "        parts = path.split(\".\")\n",
   "        coll = parts.pop(0)\n",
   "        rest = \".\".join(parts)\n",
   "        return coll, rest\n",
   "        parts = path.split(\".\")\n",
   "        collection = self\n",
   "        while parts:\n",
   "            collection = collection.collections[parts.pop(0)]\n",
   "        return collection\n",
   "        return self.task_with_config(name)[0]\n",
   "        task, config = self.collections[coll].task_with_config(rest)\n",
   "        return task, dict(config, **ours)\n",
   "        ours = self.configuration()\n",
   "        if not name:\n",
   "                return self[self.default], ours\n",
   "        name = self.transform(name)\n",
   "        if \".\" in name:\n",
   "            coll, rest = self._split_path(name)\n",
   "            return self._task_with_merged_config(coll, rest, ours)\n",
   "        if name in self.collections:\n",
   "            return self._task_with_merged_config(name, \"\", ours)\n",
   "        return self.tasks[name], ours\n",
   "            self[name]\n",
   "        result = []\n",
   "        for primary, aliases in six.iteritems(self.task_names):\n",
   "            task = self[primary]\n",
   "            result.append(\n",
   "                    name=primary, aliases=aliases, args=task.get_arguments()\n",
   "        return result\n",
   "        if not name:\n",
   "            return name\n",
   "        end = len(name) - 1\n",
   "        for i, char in enumerate(name):\n",
   "                i not in (0, end)\n",
   "                and char == from_\n",
   "                and name[i - 1] != \".\"\n",
   "                and name[i + 1] != \".\"\n",
   "            replaced.append(char)\n",
   "            ret[name] = list(map(self.transform, task.aliases))\n",
   "            for task_name, aliases in six.iteritems(coll.task_names):\n",
   "                    map(lambda x: self.subtask_name(coll_name, x), aliases)\n",
   "                if coll.default == task_name:\n",
   "                ret[self.subtask_name(coll_name, task_name)] = aliases\n",
   "        return ret\n",
   "                    \"name\": self.transform(x.name),\n",
   "                    \"help\": helpline(x),\n",
   "                    \"aliases\": [self.transform(y) for y in x.aliases],\n",
   "                for x in sorted(self.tasks.values(), key=lambda x: x.name)\n",
   "                x.serialized()\n",
   "                    self.collections.values(), key=lambda x: x.name or \"\"\n"
  ]
 },
 "34": {
  "name": "name",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/collection.py",
  "lineno": "267",
  "column": "8",
  "context": "\"Could not obtain a name for this task!\")\n        name = self.transform(name)\n        if name in self.collections:\n            e",
  "context_lines": "            elif hasattr(task.body, \"__name__\"):\n                name = task.__name__\n            else:\n                raise ValueError(\"Could not obtain a name for this task!\")\n        name = self.transform(name)\n        if name in self.collections:\n            err = \"Name conflict: this collection has a sub-collection named {!r} already\"  # noqa\n            raise ValueError(err.format(name))\n        self.tasks[name] = task\n",
  "slicing": [
   "        args = list(args)\n",
   "        if args and isinstance(args[0], six.string_types):\n",
   "            self.name = self.transform(args.pop(0))\n",
   "        for arg in args:\n",
   "            self._add_object(arg)\n",
   "        for name, obj in six.iteritems(kwargs):\n",
   "            self._add_object(obj, name)\n",
   "        if isinstance(obj, Task):\n",
   "            method = self.add_task\n",
   "        elif isinstance(obj, (Collection, types.ModuleType)):\n",
   "            method = self.add_collection\n",
   "            raise TypeError(\"No idea how to insert {!r}!\".format(type(obj)))\n",
   "        return method(obj, name=name)\n",
   "        task_names = list(self.tasks.keys())\n",
   "        collections = [\"{}...\".format(x) for x in self.collections.keys()]\n",
   "            self.name, \", \".join(sorted(task_names) + sorted(collections))\n",
   "        module_name = module.__name__.split(\".\")[-1]\n",
   "            args = [name or obj_name or module_name]\n",
   "            kwargs = dict(\n",
   "            instance = cls(*args, **kwargs)\n",
   "            instance.__doc__ = module.__doc__\n",
   "            return instance\n",
   "        for candidate in (\"ns\", \"namespace\"):\n",
   "            obj = getattr(module, candidate, None)\n",
   "            if obj and isinstance(obj, Collection):\n",
   "                ret = instantiate(obj_name=obj.name)\n",
   "                ret.tasks = ret._transform_lexicon(obj.tasks)\n",
   "                ret.collections = ret._transform_lexicon(obj.collections)\n",
   "                ret.default = ret.transform(obj.default)\n",
   "                obj_config = copy_dict(obj._configuration)\n",
   "                    merge_dicts(obj_config, config)\n",
   "                ret._configuration = obj_config\n",
   "                return ret\n",
   "        tasks = filter(lambda x: isinstance(x, Task), vars(module).values())\n",
   "        collection = instantiate()\n",
   "        for task in tasks:\n",
   "            collection.add_task(task)\n",
   "            collection.configure(config)\n",
   "        return collection\n",
   "        if name is None:\n",
   "            if task.name:\n",
   "                name = task.name\n",
   "            elif hasattr(task.body, \"func_name\"):\n",
   "                name = task.body.func_name\n",
   "            elif hasattr(task.body, \"__name__\"):\n",
   "                name = task.__name__\n",
   "        name = self.transform(name)\n",
   "        if name in self.collections:\n",
   "            err = \"Name conflict: this collection has a sub-collection named {!r} already\"  # noqa\n",
   "            raise ValueError(err.format(name))\n",
   "        self.tasks[name] = task\n",
   "        for alias in list(task.aliases) + list(aliases or []):\n",
   "            self.tasks.alias(self.transform(alias), to=name)\n",
   "        if default is True or (default is None and task.is_default):\n",
   "                msg = \"'{}' cannot be the default because '{}' already is!\"\n",
   "                raise ValueError(msg.format(name, self.default))\n",
   "            self.default = name\n",
   "            coll = Collection.from_module(coll)\n",
   "        name = name or coll.name\n",
   "        if not name:\n",
   "        name = self.transform(name)\n",
   "        if name in self.tasks:\n",
   "            err = (\n",
   "            raise ValueError(err.format(name))\n",
   "        self.collections[name] = coll\n",
   "        parts = path.split(\".\")\n",
   "        coll = parts.pop(0)\n",
   "        rest = \".\".join(parts)\n",
   "        return coll, rest\n",
   "        parts = path.split(\".\")\n",
   "        collection = self\n",
   "        while parts:\n",
   "            collection = collection.collections[parts.pop(0)]\n",
   "        return collection\n",
   "        return self.task_with_config(name)[0]\n",
   "        task, config = self.collections[coll].task_with_config(rest)\n",
   "        return task, dict(config, **ours)\n",
   "        ours = self.configuration()\n",
   "        if not name:\n",
   "                return self[self.default], ours\n",
   "        name = self.transform(name)\n",
   "        if \".\" in name:\n",
   "            coll, rest = self._split_path(name)\n",
   "            return self._task_with_merged_config(coll, rest, ours)\n",
   "        if name in self.collections:\n",
   "            return self._task_with_merged_config(name, \"\", ours)\n",
   "        return self.tasks[name], ours\n",
   "            self[name]\n",
   "        result = []\n",
   "        for primary, aliases in six.iteritems(self.task_names):\n",
   "            task = self[primary]\n",
   "            result.append(\n",
   "                    name=primary, aliases=aliases, args=task.get_arguments()\n",
   "        return result\n",
   "        if not name:\n",
   "            return name\n",
   "        end = len(name) - 1\n",
   "        for i, char in enumerate(name):\n",
   "                i not in (0, end)\n",
   "                and char == from_\n",
   "                and name[i - 1] != \".\"\n",
   "                and name[i + 1] != \".\"\n",
   "            replaced.append(char)\n",
   "            ret[name] = list(map(self.transform, task.aliases))\n",
   "            for task_name, aliases in six.iteritems(coll.task_names):\n",
   "                    map(lambda x: self.subtask_name(coll_name, x), aliases)\n",
   "                if coll.default == task_name:\n",
   "                ret[self.subtask_name(coll_name, task_name)] = aliases\n",
   "        return ret\n",
   "                    \"name\": self.transform(x.name),\n",
   "                    \"help\": helpline(x),\n",
   "                    \"aliases\": [self.transform(y) for y in x.aliases],\n",
   "                for x in sorted(self.tasks.values(), key=lambda x: x.name)\n",
   "                x.serialized()\n",
   "                    self.collections.values(), key=lambda x: x.name or \"\"\n"
  ]
 },
 "35": {
  "name": "name",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/collection.py",
  "lineno": "299",
  "column": "8",
  "context": "\"Non-root collections must have a name!\")\n        name = self.transform(name)\n        # Test for conflict\n        if name in sel",
  "context_lines": "        # Ensure we have a name, or die trying\n        name = name or coll.name\n        if not name:\n            raise ValueError(\"Non-root collections must have a name!\")\n        name = self.transform(name)\n        # Test for conflict\n        if name in self.tasks:\n            err = (\n                \"Name conflict: this collection has a task named {!r} already\"\n",
  "slicing": [
   "        args = list(args)\n",
   "        if args and isinstance(args[0], six.string_types):\n",
   "            self.name = self.transform(args.pop(0))\n",
   "        for arg in args:\n",
   "            self._add_object(arg)\n",
   "        for name, obj in six.iteritems(kwargs):\n",
   "            self._add_object(obj, name)\n",
   "        if isinstance(obj, Task):\n",
   "            method = self.add_task\n",
   "        elif isinstance(obj, (Collection, types.ModuleType)):\n",
   "            method = self.add_collection\n",
   "            raise TypeError(\"No idea how to insert {!r}!\".format(type(obj)))\n",
   "        return method(obj, name=name)\n",
   "        task_names = list(self.tasks.keys())\n",
   "        collections = [\"{}...\".format(x) for x in self.collections.keys()]\n",
   "            self.name, \", \".join(sorted(task_names) + sorted(collections))\n",
   "        module_name = module.__name__.split(\".\")[-1]\n",
   "            args = [name or obj_name or module_name]\n",
   "            kwargs = dict(\n",
   "            instance = cls(*args, **kwargs)\n",
   "            instance.__doc__ = module.__doc__\n",
   "            return instance\n",
   "        for candidate in (\"ns\", \"namespace\"):\n",
   "            obj = getattr(module, candidate, None)\n",
   "            if obj and isinstance(obj, Collection):\n",
   "                ret = instantiate(obj_name=obj.name)\n",
   "                ret.tasks = ret._transform_lexicon(obj.tasks)\n",
   "                ret.collections = ret._transform_lexicon(obj.collections)\n",
   "                ret.default = ret.transform(obj.default)\n",
   "                obj_config = copy_dict(obj._configuration)\n",
   "                    merge_dicts(obj_config, config)\n",
   "                ret._configuration = obj_config\n",
   "                return ret\n",
   "        tasks = filter(lambda x: isinstance(x, Task), vars(module).values())\n",
   "        collection = instantiate()\n",
   "        for task in tasks:\n",
   "            collection.add_task(task)\n",
   "            collection.configure(config)\n",
   "        return collection\n",
   "        if name is None:\n",
   "            if task.name:\n",
   "                name = task.name\n",
   "            elif hasattr(task.body, \"func_name\"):\n",
   "                name = task.body.func_name\n",
   "            elif hasattr(task.body, \"__name__\"):\n",
   "                name = task.__name__\n",
   "        name = self.transform(name)\n",
   "        if name in self.collections:\n",
   "            err = \"Name conflict: this collection has a sub-collection named {!r} already\"  # noqa\n",
   "            raise ValueError(err.format(name))\n",
   "        self.tasks[name] = task\n",
   "        for alias in list(task.aliases) + list(aliases or []):\n",
   "            self.tasks.alias(self.transform(alias), to=name)\n",
   "        if default is True or (default is None and task.is_default):\n",
   "                msg = \"'{}' cannot be the default because '{}' already is!\"\n",
   "                raise ValueError(msg.format(name, self.default))\n",
   "            self.default = name\n",
   "            coll = Collection.from_module(coll)\n",
   "        name = name or coll.name\n",
   "        if not name:\n",
   "        name = self.transform(name)\n",
   "        if name in self.tasks:\n",
   "            err = (\n",
   "            raise ValueError(err.format(name))\n",
   "        self.collections[name] = coll\n",
   "        parts = path.split(\".\")\n",
   "        coll = parts.pop(0)\n",
   "        rest = \".\".join(parts)\n",
   "        return coll, rest\n",
   "        parts = path.split(\".\")\n",
   "        collection = self\n",
   "        while parts:\n",
   "            collection = collection.collections[parts.pop(0)]\n",
   "        return collection\n",
   "        return self.task_with_config(name)[0]\n",
   "        task, config = self.collections[coll].task_with_config(rest)\n",
   "        return task, dict(config, **ours)\n",
   "        ours = self.configuration()\n",
   "        if not name:\n",
   "                return self[self.default], ours\n",
   "        name = self.transform(name)\n",
   "        if \".\" in name:\n",
   "            coll, rest = self._split_path(name)\n",
   "            return self._task_with_merged_config(coll, rest, ours)\n",
   "        if name in self.collections:\n",
   "            return self._task_with_merged_config(name, \"\", ours)\n",
   "        return self.tasks[name], ours\n",
   "            self[name]\n",
   "        result = []\n",
   "        for primary, aliases in six.iteritems(self.task_names):\n",
   "            task = self[primary]\n",
   "            result.append(\n",
   "                    name=primary, aliases=aliases, args=task.get_arguments()\n",
   "        return result\n",
   "        if not name:\n",
   "            return name\n",
   "        end = len(name) - 1\n",
   "        for i, char in enumerate(name):\n",
   "                i not in (0, end)\n",
   "                and char == from_\n",
   "                and name[i - 1] != \".\"\n",
   "                and name[i + 1] != \".\"\n",
   "            replaced.append(char)\n",
   "            ret[name] = list(map(self.transform, task.aliases))\n",
   "            for task_name, aliases in six.iteritems(coll.task_names):\n",
   "                    map(lambda x: self.subtask_name(coll_name, x), aliases)\n",
   "                if coll.default == task_name:\n",
   "                ret[self.subtask_name(coll_name, task_name)] = aliases\n",
   "        return ret\n",
   "                    \"name\": self.transform(x.name),\n",
   "                    \"help\": helpline(x),\n",
   "                    \"aliases\": [self.transform(y) for y in x.aliases],\n",
   "                for x in sorted(self.tasks.values(), key=lambda x: x.name)\n",
   "                x.serialized()\n",
   "                    self.collections.values(), key=lambda x: x.name or \"\"\n"
  ]
 },
 "36": {
  "name": "char",
  "type": "str",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "invoke/invoke/collection.py",
  "lineno": "454",
  "column": "16",
  "context": "name[i + 1] != \".\"\n            ):\n                char = to\n            replaced.append(char)\n        return \"",
  "context_lines": "                and char == from_\n                and name[i - 1] != \".\"\n                and name[i + 1] != \".\"\n            ):\n                char = to\n            replaced.append(char)\n        return \"\".join(replaced)\n\n    def _transform_lexicon(self, old):\n        \"\"\"\n",
  "slicing": [
   "        args = list(args)\n",
   "        if args and isinstance(args[0], six.string_types):\n",
   "            self.name = self.transform(args.pop(0))\n",
   "        for arg in args:\n",
   "            self._add_object(arg)\n",
   "        for name, obj in six.iteritems(kwargs):\n",
   "            self._add_object(obj, name)\n",
   "        if isinstance(obj, Task):\n",
   "            method = self.add_task\n",
   "        elif isinstance(obj, (Collection, types.ModuleType)):\n",
   "            method = self.add_collection\n",
   "            raise TypeError(\"No idea how to insert {!r}!\".format(type(obj)))\n",
   "        return method(obj, name=name)\n",
   "        task_names = list(self.tasks.keys())\n",
   "        collections = [\"{}...\".format(x) for x in self.collections.keys()]\n",
   "            self.name, \", \".join(sorted(task_names) + sorted(collections))\n",
   "        module_name = module.__name__.split(\".\")[-1]\n",
   "            args = [name or obj_name or module_name]\n",
   "            kwargs = dict(\n",
   "            instance = cls(*args, **kwargs)\n",
   "            instance.__doc__ = module.__doc__\n",
   "            return instance\n",
   "        for candidate in (\"ns\", \"namespace\"):\n",
   "            obj = getattr(module, candidate, None)\n",
   "            if obj and isinstance(obj, Collection):\n",
   "                ret = instantiate(obj_name=obj.name)\n",
   "                ret.tasks = ret._transform_lexicon(obj.tasks)\n",
   "                ret.collections = ret._transform_lexicon(obj.collections)\n",
   "                ret.default = ret.transform(obj.default)\n",
   "                obj_config = copy_dict(obj._configuration)\n",
   "                    merge_dicts(obj_config, config)\n",
   "                ret._configuration = obj_config\n",
   "                return ret\n",
   "        tasks = filter(lambda x: isinstance(x, Task), vars(module).values())\n",
   "        collection = instantiate()\n",
   "        for task in tasks:\n",
   "            collection.add_task(task)\n",
   "            collection.configure(config)\n",
   "        return collection\n",
   "        if name is None:\n",
   "            if task.name:\n",
   "                name = task.name\n",
   "            elif hasattr(task.body, \"func_name\"):\n",
   "                name = task.body.func_name\n",
   "            elif hasattr(task.body, \"__name__\"):\n",
   "                name = task.__name__\n",
   "        name = self.transform(name)\n",
   "        if name in self.collections:\n",
   "            err = \"Name conflict: this collection has a sub-collection named {!r} already\"  # noqa\n",
   "            raise ValueError(err.format(name))\n",
   "        self.tasks[name] = task\n",
   "        for alias in list(task.aliases) + list(aliases or []):\n",
   "            self.tasks.alias(self.transform(alias), to=name)\n",
   "        if default is True or (default is None and task.is_default):\n",
   "                msg = \"'{}' cannot be the default because '{}' already is!\"\n",
   "                raise ValueError(msg.format(name, self.default))\n",
   "            self.default = name\n",
   "            coll = Collection.from_module(coll)\n",
   "        name = name or coll.name\n",
   "        if not name:\n",
   "        name = self.transform(name)\n",
   "        if name in self.tasks:\n",
   "            err = (\n",
   "            raise ValueError(err.format(name))\n",
   "        self.collections[name] = coll\n",
   "        parts = path.split(\".\")\n",
   "        coll = parts.pop(0)\n",
   "        rest = \".\".join(parts)\n",
   "        return coll, rest\n",
   "        parts = path.split(\".\")\n",
   "        collection = self\n",
   "        while parts:\n",
   "            collection = collection.collections[parts.pop(0)]\n",
   "        return collection\n",
   "        return self.task_with_config(name)[0]\n",
   "        task, config = self.collections[coll].task_with_config(rest)\n",
   "        return task, dict(config, **ours)\n",
   "        ours = self.configuration()\n",
   "        if not name:\n",
   "                return self[self.default], ours\n",
   "        name = self.transform(name)\n",
   "        if \".\" in name:\n",
   "            coll, rest = self._split_path(name)\n",
   "            return self._task_with_merged_config(coll, rest, ours)\n",
   "        if name in self.collections:\n",
   "            return self._task_with_merged_config(name, \"\", ours)\n",
   "        return self.tasks[name], ours\n",
   "            self[name]\n",
   "        result = []\n",
   "        for primary, aliases in six.iteritems(self.task_names):\n",
   "            task = self[primary]\n",
   "            result.append(\n",
   "                    name=primary, aliases=aliases, args=task.get_arguments()\n",
   "        return result\n",
   "        if not name:\n",
   "            return name\n",
   "        from_, to = \"_\", \"-\"\n",
   "            from_, to = \"-\", \"_\"\n",
   "        end = len(name) - 1\n",
   "        for i, char in enumerate(name):\n",
   "                i not in (0, end)\n",
   "                and char == from_\n",
   "                and name[i - 1] != \".\"\n",
   "                and name[i + 1] != \".\"\n",
   "                char = to\n",
   "            replaced.append(char)\n",
   "            ret[name] = list(map(self.transform, task.aliases))\n",
   "            for task_name, aliases in six.iteritems(coll.task_names):\n",
   "                    map(lambda x: self.subtask_name(coll_name, x), aliases)\n",
   "                if coll.default == task_name:\n",
   "                ret[self.subtask_name(coll_name, task_name)] = aliases\n",
   "        return ret\n",
   "                    \"name\": self.transform(x.name),\n",
   "                    \"help\": helpline(x),\n",
   "                    \"aliases\": [self.transform(y) for y in x.aliases],\n",
   "                for x in sorted(self.tasks.values(), key=lambda x: x.name)\n",
   "                x.serialized()\n",
   "                    self.collections.values(), key=lambda x: x.name or \"\"\n"
  ]
 },
 "37": {
  "name": "read_chunk_size",
  "type": "int",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/runners.py",
  "lineno": "58",
  "column": "4",
  "context": "`.Local`.\n\n    .. versionadded:: 1.0\n    \"\"\"\n\n    read_chunk_size = 1000\n    input_sleep = 0.01\n\n    def __init__(self, con",
  "context_lines": "    number of methods such as `start`, `wait` and `returncode`. For a subclass\n    implementation example, see the source code for `.Local`.\n\n    .. versionadded:: 1.0\n    \"\"\"\n\n    read_chunk_size = 1000\n    input_sleep = 0.01\n\n    def __init__(self, context):\n        \"\"\"\n        Create a new runner with a handle on some `.Context`.\n\n",
  "slicing": "    read_chunk_size = 1000\n"
 },
 "38": {
  "name": "input_sleep",
  "type": "float",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/runners.py",
  "lineno": "59",
  "column": "4",
  "context": "ded:: 1.0\n    \"\"\"\n\n    read_chunk_size = 1000\n    input_sleep = 0.01\n\n    def __init__(self, context):\n        \"\"\"\n    ",
  "context_lines": "    implementation example, see the source code for `.Local`.\n\n    .. versionadded:: 1.0\n    \"\"\"\n\n    read_chunk_size = 1000\n    input_sleep = 0.01\n\n    def __init__(self, context):\n        \"\"\"\n        Create a new runner with a handle on some `.Context`.\n\n",
  "slicing": "    input_sleep = 0.01\n"
 },
 "39": {
  "name": "result",
  "type": "module|builtin_function_or_method",
  "class": "unknown",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/six.py",
  "lineno": "92",
  "column": "8",
  "context": "e = name\n\n    def __get__(self, obj, tp):\n        result = self._resolve()\n        setattr(obj, self.name, result)  # Invokes",
  "context_lines": "class _LazyDescr(object):\n\n    def __init__(self, name):\n        self.name = name\n\n    def __get__(self, obj, tp):\n        result = self._resolve()\n        setattr(obj, self.name, result)  # Invokes __set__.\n        try:\n            # This is a bit ugly, but it avoids running this again by\n            # removing this descriptor.\n",
  "slicing": [
   "PY3 = sys.version_info[0] == 3\n",
   "if PY3:\n",
   "        result = self._resolve()\n",
   "        setattr(obj, self.name, result)  # Invokes __set__.\n",
   "        return result\n",
   "        if PY3:\n",
   "        if PY3:\n",
   "if PY3:\n",
   "if PY3:\n",
   "if PY3:\n",
   "if PY3:\n",
   "if PY3:\n"
  ]
 },
 "40": {
  "name": "_module",
  "type": "package.module",
  "class": "imported",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/six.py",
  "lineno": "118",
  "column": "8",
  "context": "lf.mod)\n\n    def __getattr__(self, attr):\n        _module = self._resolve()\n        value = getattr(_module, attr)\n        set",
  "context_lines": "            self.mod = old\n\n    def _resolve(self):\n        return _import_module(self.mod)\n\n    def __getattr__(self, attr):\n        _module = self._resolve()\n        value = getattr(_module, attr)\n        setattr(self, attr, value)\n        return value\n\n\nclass _LazyModule(types.ModuleType):\n\n",
  "slicing": [
   "PY3 = sys.version_info[0] == 3\n",
   "if PY3:\n",
   "def _import_module(name):\n",
   "        result = self._resolve()\n",
   "        setattr(obj, self.name, result)  # Invokes __set__.\n",
   "        return result\n",
   "        if PY3:\n",
   "                new = name\n",
   "            self.mod = new\n",
   "        _module = self._resolve()\n",
   "        value = getattr(_module, attr)\n",
   "        setattr(self, attr, value)\n",
   "        return value\n",
   "        super(_LazyModule, self).__init__(name)\n",
   "        attrs = [\"__doc__\", \"__name__\"]\n",
   "        attrs += [attr.name for attr in self._moved_attributes]\n",
   "        return attrs\n",
   "        super(MovedAttribute, self).__init__(name)\n",
   "        if PY3:\n",
   "                new_mod = name\n",
   "            self.mod = new_mod\n",
   "                    new_attr = name\n",
   "                    new_attr = old_attr\n",
   "            self.attr = new_attr\n",
   "                old_attr = name\n",
   "            self.attr = old_attr\n",
   "    setattr(_MovedItems, attr.name, attr)\n",
   "    if isinstance(attr, MovedModule):\n",
   "        _importer._add_module(attr, \"moves.\" + attr.name)\n",
   "    setattr(Module_six_moves_urllib_parse, attr.name, attr)\n",
   "    setattr(Module_six_moves_urllib_error, attr.name, attr)\n",
   "    setattr(Module_six_moves_urllib_request, attr.name, attr)\n",
   "    setattr(Module_six_moves_urllib_response, attr.name, attr)\n",
   "    setattr(Module_six_moves_urllib_robotparser, attr.name, attr)\n",
   "        delattr(_MovedItems, name)\n",
   "            del moves.__dict__[name]\n",
   "            raise AttributeError(\"no such move, %r\" % (name,))\n",
   "if PY3:\n",
   "if PY3:\n",
   "if PY3:\n",
   "if PY3:\n",
   "if PY3:\n",
   "        if value is None:\n",
   "        if value.__traceback__ is not tb:\n",
   "            raise value.with_traceback(tb)\n",
   "        raise value\n",
   "        raise value\n",
   "            return meta(name, bases, d)\n"
  ]
 },
 "41": {
  "name": "new_attr",
  "type": "str",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "invoke/invoke/vendor/six.py",
  "lineno": "151",
  "column": "20",
  "context": " = name\n                else:\n                    new_attr = old_attr\n            self.attr = new_attr\n        else:\n   ",
  "context_lines": "            if new_attr is None:\n                if old_attr is None:\n                    new_attr = name\n                else:\n                    new_attr = old_attr\n            self.attr = new_attr\n        else:\n            self.mod = old_mod\n            if old_attr is None:\n",
  "slicing": [
   "PY3 = sys.version_info[0] == 3\n",
   "if PY3:\n",
   "def _import_module(name):\n",
   "        result = self._resolve()\n",
   "        setattr(obj, self.name, result)  # Invokes __set__.\n",
   "        return result\n",
   "        if PY3:\n",
   "                new = name\n",
   "            self.mod = new\n",
   "        _module = self._resolve()\n",
   "        value = getattr(_module, attr)\n",
   "        setattr(self, attr, value)\n",
   "        return value\n",
   "        super(_LazyModule, self).__init__(name)\n",
   "        attrs = [\"__doc__\", \"__name__\"]\n",
   "        attrs += [attr.name for attr in self._moved_attributes]\n",
   "        return attrs\n",
   "        super(MovedAttribute, self).__init__(name)\n",
   "        if PY3:\n",
   "                new_mod = name\n",
   "            self.mod = new_mod\n",
   "                    new_attr = name\n",
   "                    new_attr = old_attr\n",
   "            self.attr = new_attr\n",
   "                old_attr = name\n",
   "            self.attr = old_attr\n",
   "    setattr(_MovedItems, attr.name, attr)\n",
   "    if isinstance(attr, MovedModule):\n",
   "        _importer._add_module(attr, \"moves.\" + attr.name)\n",
   "    setattr(Module_six_moves_urllib_parse, attr.name, attr)\n",
   "    setattr(Module_six_moves_urllib_error, attr.name, attr)\n",
   "    setattr(Module_six_moves_urllib_request, attr.name, attr)\n",
   "    setattr(Module_six_moves_urllib_response, attr.name, attr)\n",
   "    setattr(Module_six_moves_urllib_robotparser, attr.name, attr)\n",
   "        delattr(_MovedItems, name)\n",
   "            del moves.__dict__[name]\n",
   "            raise AttributeError(\"no such move, %r\" % (name,))\n",
   "if PY3:\n",
   "if PY3:\n",
   "if PY3:\n",
   "if PY3:\n",
   "if PY3:\n",
   "        if value is None:\n",
   "        if value.__traceback__ is not tb:\n",
   "            raise value.with_traceback(tb)\n",
   "        raise value\n",
   "        raise value\n",
   "            return meta(name, bases, d)\n"
  ]
 },
 "42": {
  "name": "module",
  "type": "package.module",
  "class": "imported",
  "approach": "annotation",
  "file_path": "invoke/invoke/vendor/six.py",
  "lineno": "160",
  "column": "8",
  "context": ".attr = old_attr\n\n    def _resolve(self):\n        module = _import_module(self.mod)\n        return getattr(module, self.attr)\n\n\nclass ",
  "context_lines": "            if old_attr is None:\n                old_attr = name\n            self.attr = old_attr\n\n    def _resolve(self):\n        module = _import_module(self.mod)\n        return getattr(module, self.attr)\n\n\nclass _SixMetaPathImporter(object):\n\n    \"\"\"\n    A meta path importer to import six.moves and its submodules.\n\n",
  "slicing": [
   "PY3 = sys.version_info[0] == 3\n",
   "if PY3:\n",
   "def _import_module(name):\n",
   "        result = self._resolve()\n",
   "        setattr(obj, self.name, result)  # Invokes __set__.\n",
   "        return result\n",
   "        if PY3:\n",
   "                new = name\n",
   "            self.mod = new\n",
   "        _module = self._resolve()\n",
   "        value = getattr(_module, attr)\n",
   "        setattr(self, attr, value)\n",
   "        return value\n",
   "        super(_LazyModule, self).__init__(name)\n",
   "        attrs = [\"__doc__\", \"__name__\"]\n",
   "        attrs += [attr.name for attr in self._moved_attributes]\n",
   "        return attrs\n",
   "        super(MovedAttribute, self).__init__(name)\n",
   "        if PY3:\n",
   "                new_mod = name\n",
   "            self.mod = new_mod\n",
   "                    new_attr = name\n",
   "                    new_attr = old_attr\n",
   "            self.attr = new_attr\n",
   "                old_attr = name\n",
   "            self.attr = old_attr\n",
   "        module = _import_module(self.mod)\n",
   "        return getattr(module, self.attr)\n",
   "    setattr(_MovedItems, attr.name, attr)\n",
   "    if isinstance(attr, MovedModule):\n",
   "        _importer._add_module(attr, \"moves.\" + attr.name)\n",
   "    setattr(Module_six_moves_urllib_parse, attr.name, attr)\n",
   "    setattr(Module_six_moves_urllib_error, attr.name, attr)\n",
   "    setattr(Module_six_moves_urllib_request, attr.name, attr)\n",
   "    setattr(Module_six_moves_urllib_response, attr.name, attr)\n",
   "    setattr(Module_six_moves_urllib_robotparser, attr.name, attr)\n",
   "        delattr(_MovedItems, name)\n",
   "            del moves.__dict__[name]\n",
   "            raise AttributeError(\"no such move, %r\" % (name,))\n",
   "if PY3:\n",
   "if PY3:\n",
   "if PY3:\n",
   "if PY3:\n",
   "if PY3:\n",
   "        if value is None:\n",
   "        if value.__traceback__ is not tb:\n",
   "            raise value.with_traceback(tb)\n",
   "        raise value\n",
   "        raise value\n",
   "            return meta(name, bases, d)\n"
  ]
 },
 "43": {
  "name": "mod",
  "type": "_MovedItems",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/six.py",
  "lineno": "201",
  "column": "8",
  "context": "        except KeyError:\n            pass\n        mod = self.__get_module(fullname)\n        if isinstance(mod, MovedModule):\n         ",
  "context_lines": "            # in case of a reload\n            return sys.modules[fullname]\n        except KeyError:\n            pass\n        mod = self.__get_module(fullname)\n        if isinstance(mod, MovedModule):\n            mod = mod._resolve()\n        else:\n            mod.__loader__ = self\n",
  "slicing": [
   "PY3 = sys.version_info[0] == 3\n",
   "if PY3:\n",
   "def _import_module(name):\n",
   "        result = self._resolve()\n",
   "        setattr(obj, self.name, result)  # Invokes __set__.\n",
   "        return result\n",
   "        if PY3:\n",
   "                new = name\n",
   "            self.mod = new\n",
   "        _module = self._resolve()\n",
   "        value = getattr(_module, attr)\n",
   "        setattr(self, attr, value)\n",
   "        return value\n",
   "        super(_LazyModule, self).__init__(name)\n",
   "        attrs = [\"__doc__\", \"__name__\"]\n",
   "        attrs += [attr.name for attr in self._moved_attributes]\n",
   "        return attrs\n",
   "        super(MovedAttribute, self).__init__(name)\n",
   "        if PY3:\n",
   "                new_mod = name\n",
   "            self.mod = new_mod\n",
   "                    new_attr = name\n",
   "                    new_attr = old_attr\n",
   "            self.attr = new_attr\n",
   "                old_attr = name\n",
   "            self.attr = old_attr\n",
   "        module = _import_module(self.mod)\n",
   "        return getattr(module, self.attr)\n",
   "        for fullname in fullnames:\n",
   "            self.known_modules[self.name + \".\" + fullname] = mod\n",
   "        return self.known_modules[self.name + \".\" + fullname]\n",
   "        if fullname in self.known_modules:\n",
   "            return self.known_modules[fullname]\n",
   "            raise ImportError(\"This loader does not know module \" + fullname)\n",
   "            return sys.modules[fullname]\n",
   "        mod = self.__get_module(fullname)\n",
   "        if isinstance(mod, MovedModule):\n",
   "            mod = mod._resolve()\n",
   "            mod.__loader__ = self\n",
   "        sys.modules[fullname] = mod\n",
   "        return mod\n",
   "        return hasattr(self.__get_module(fullname), \"__path__\")\n",
   "        self.__get_module(fullname)  # eventually raises ImportError\n",
   "    setattr(_MovedItems, attr.name, attr)\n",
   "    if isinstance(attr, MovedModule):\n",
   "        _importer._add_module(attr, \"moves.\" + attr.name)\n",
   "    setattr(Module_six_moves_urllib_parse, attr.name, attr)\n",
   "    setattr(Module_six_moves_urllib_error, attr.name, attr)\n",
   "    setattr(Module_six_moves_urllib_request, attr.name, attr)\n",
   "    setattr(Module_six_moves_urllib_response, attr.name, attr)\n",
   "    setattr(Module_six_moves_urllib_robotparser, attr.name, attr)\n",
   "        delattr(_MovedItems, name)\n",
   "            del moves.__dict__[name]\n",
   "            raise AttributeError(\"no such move, %r\" % (name,))\n",
   "if PY3:\n",
   "if PY3:\n",
   "if PY3:\n",
   "if PY3:\n",
   "if PY3:\n",
   "        if value is None:\n",
   "        if value.__traceback__ is not tb:\n",
   "            raise value.with_traceback(tb)\n",
   "        raise value\n",
   "        raise value\n",
   "            return meta(name, bases, d)\n"
  ]
 },
 "44": {
  "name": "mod",
  "type": "package.module",
  "class": "imported",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/six.py",
  "lineno": "203",
  "column": "12",
  "context": "     if isinstance(mod, MovedModule):\n            mod = mod._resolve()\n        else:\n            mod.__loader__ = self\n  ",
  "context_lines": "        except KeyError:\n            pass\n        mod = self.__get_module(fullname)\n        if isinstance(mod, MovedModule):\n            mod = mod._resolve()\n        else:\n            mod.__loader__ = self\n        sys.modules[fullname] = mod\n        return mod\n\n",
  "slicing": [
   "PY3 = sys.version_info[0] == 3\n",
   "if PY3:\n",
   "def _import_module(name):\n",
   "        result = self._resolve()\n",
   "        setattr(obj, self.name, result)  # Invokes __set__.\n",
   "        return result\n",
   "        if PY3:\n",
   "                new = name\n",
   "            self.mod = new\n",
   "        _module = self._resolve()\n",
   "        value = getattr(_module, attr)\n",
   "        setattr(self, attr, value)\n",
   "        return value\n",
   "        super(_LazyModule, self).__init__(name)\n",
   "        attrs = [\"__doc__\", \"__name__\"]\n",
   "        attrs += [attr.name for attr in self._moved_attributes]\n",
   "        return attrs\n",
   "        super(MovedAttribute, self).__init__(name)\n",
   "        if PY3:\n",
   "                new_mod = name\n",
   "            self.mod = new_mod\n",
   "                    new_attr = name\n",
   "                    new_attr = old_attr\n",
   "            self.attr = new_attr\n",
   "                old_attr = name\n",
   "            self.attr = old_attr\n",
   "        module = _import_module(self.mod)\n",
   "        return getattr(module, self.attr)\n",
   "        for fullname in fullnames:\n",
   "            self.known_modules[self.name + \".\" + fullname] = mod\n",
   "        return self.known_modules[self.name + \".\" + fullname]\n",
   "        if fullname in self.known_modules:\n",
   "            return self.known_modules[fullname]\n",
   "            raise ImportError(\"This loader does not know module \" + fullname)\n",
   "            return sys.modules[fullname]\n",
   "        mod = self.__get_module(fullname)\n",
   "        if isinstance(mod, MovedModule):\n",
   "            mod = mod._resolve()\n",
   "            mod.__loader__ = self\n",
   "        sys.modules[fullname] = mod\n",
   "        return mod\n",
   "        return hasattr(self.__get_module(fullname), \"__path__\")\n",
   "        self.__get_module(fullname)  # eventually raises ImportError\n",
   "    setattr(_MovedItems, attr.name, attr)\n",
   "    if isinstance(attr, MovedModule):\n",
   "        _importer._add_module(attr, \"moves.\" + attr.name)\n",
   "    setattr(Module_six_moves_urllib_parse, attr.name, attr)\n",
   "    setattr(Module_six_moves_urllib_error, attr.name, attr)\n",
   "    setattr(Module_six_moves_urllib_request, attr.name, attr)\n",
   "    setattr(Module_six_moves_urllib_response, attr.name, attr)\n",
   "    setattr(Module_six_moves_urllib_robotparser, attr.name, attr)\n",
   "        delattr(_MovedItems, name)\n",
   "            del moves.__dict__[name]\n",
   "            raise AttributeError(\"no such move, %r\" % (name,))\n",
   "if PY3:\n",
   "if PY3:\n",
   "if PY3:\n",
   "if PY3:\n",
   "if PY3:\n",
   "        if value is None:\n",
   "        if value.__traceback__ is not tb:\n",
   "            raise value.with_traceback(tb)\n",
   "        raise value\n",
   "        raise value\n",
   "            return meta(name, bases, d)\n"
  ]
 },
 "45": {
  "name": "get_source",
  "type": "function",
  "class": "unknown",
  "approach": "annotation",
  "file_path": "invoke/invoke/vendor/six.py",
  "lineno": "224",
  "column": "4",
  "context": "tually raises ImportError\n        return None\n    get_source = get_code  # same as get_code\n\n_importer = _SixMetaPathImporter(__name__)\n\n\nclas",
  "context_lines": "        \"\"\"Return None\n\n        Required, if is_package is implemented\"\"\"\n        self.__get_module(fullname)  # eventually raises ImportError\n        return None\n    get_source = get_code  # same as get_code\n\n_importer = _SixMetaPathImporter(__name__)\n\n\nclass _MovedItems(_LazyModule):\n\n    \"\"\"Lazy loading of moved objects\"\"\"\n",
  "slicing": [
   "PY3 = sys.version_info[0] == 3\n",
   "if PY3:\n",
   "def _import_module(name):\n",
   "        result = self._resolve()\n",
   "        setattr(obj, self.name, result)  # Invokes __set__.\n",
   "        return result\n",
   "        if PY3:\n",
   "                new = name\n",
   "            self.mod = new\n",
   "        _module = self._resolve()\n",
   "        value = getattr(_module, attr)\n",
   "        setattr(self, attr, value)\n",
   "        return value\n",
   "        super(_LazyModule, self).__init__(name)\n",
   "        attrs = [\"__doc__\", \"__name__\"]\n",
   "        attrs += [attr.name for attr in self._moved_attributes]\n",
   "        return attrs\n",
   "        super(MovedAttribute, self).__init__(name)\n",
   "        if PY3:\n",
   "                new_mod = name\n",
   "            self.mod = new_mod\n",
   "                    new_attr = name\n",
   "                    new_attr = old_attr\n",
   "            self.attr = new_attr\n",
   "                old_attr = name\n",
   "            self.attr = old_attr\n",
   "        module = _import_module(self.mod)\n",
   "        return getattr(module, self.attr)\n",
   "        for fullname in fullnames:\n",
   "            self.known_modules[self.name + \".\" + fullname] = mod\n",
   "        return self.known_modules[self.name + \".\" + fullname]\n",
   "        if fullname in self.known_modules:\n",
   "            return self.known_modules[fullname]\n",
   "            raise ImportError(\"This loader does not know module \" + fullname)\n",
   "            return sys.modules[fullname]\n",
   "        mod = self.__get_module(fullname)\n",
   "        if isinstance(mod, MovedModule):\n",
   "            mod = mod._resolve()\n",
   "            mod.__loader__ = self\n",
   "        sys.modules[fullname] = mod\n",
   "        return mod\n",
   "        return hasattr(self.__get_module(fullname), \"__path__\")\n",
   "        self.__get_module(fullname)  # eventually raises ImportError\n",
   "    get_source = get_code  # same as get_code\n",
   "    setattr(_MovedItems, attr.name, attr)\n",
   "    if isinstance(attr, MovedModule):\n",
   "        _importer._add_module(attr, \"moves.\" + attr.name)\n",
   "    setattr(Module_six_moves_urllib_parse, attr.name, attr)\n",
   "    setattr(Module_six_moves_urllib_error, attr.name, attr)\n",
   "    setattr(Module_six_moves_urllib_request, attr.name, attr)\n",
   "    setattr(Module_six_moves_urllib_response, attr.name, attr)\n",
   "    setattr(Module_six_moves_urllib_robotparser, attr.name, attr)\n",
   "        delattr(_MovedItems, name)\n",
   "            del moves.__dict__[name]\n",
   "            raise AttributeError(\"no such move, %r\" % (name,))\n",
   "if PY3:\n",
   "if PY3:\n",
   "if PY3:\n",
   "if PY3:\n",
   "if PY3:\n",
   "        if value is None:\n",
   "        if value.__traceback__ is not tb:\n",
   "            raise value.with_traceback(tb)\n",
   "        raise value\n",
   "        raise value\n",
   "            return meta(name, bases, d)\n"
  ]
 },
 "46": {
  "name": "parse",
  "type": "Module_six_moves_urllib_parse",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/six.py",
  "lineno": "473",
  "column": "4",
  "context": "space\"\"\"\n    __path__ = []  # mark as package\n    parse = _importer._get_module(\"moves.urllib_parse\")\n    error = _importer._get_module(\"moves.urllib_er",
  "context_lines": "                      \"moves.urllib_robotparser\", \"moves.urllib.robotparser\")\n\n\nclass Module_six_moves_urllib(types.ModuleType):\n\n    \"\"\"Create a six.moves.urllib namespace that resembles the Python 3 namespace\"\"\"\n    __path__ = []  # mark as package\n    parse = _importer._get_module(\"moves.urllib_parse\")\n    error = _importer._get_module(\"moves.urllib_error\")\n    request = _importer._get_module(\"moves.urllib_request\")\n    response = _importer._get_module(\"moves.urllib_response\")\n    robotparser = _importer._get_module(\"moves.urllib_robotparser\")\n\n",
  "slicing": [
   "PY3 = sys.version_info[0] == 3\n",
   "PY34 = sys.version_info[0:2] >= (3, 4)\n",
   "if PY3:\n",
   "def _add_doc(func, doc):\n",
   "    func.__doc__ = doc\n",
   "def _import_module(name):\n",
   "        result = self._resolve()\n",
   "        setattr(obj, self.name, result)  # Invokes __set__.\n",
   "        return result\n",
   "        if PY3:\n",
   "                new = name\n",
   "            self.mod = new\n",
   "        _module = self._resolve()\n",
   "        value = getattr(_module, attr)\n",
   "        setattr(self, attr, value)\n",
   "        return value\n",
   "        super(_LazyModule, self).__init__(name)\n",
   "        attrs = [\"__doc__\", \"__name__\"]\n",
   "        attrs += [attr.name for attr in self._moved_attributes]\n",
   "        return attrs\n",
   "    _moved_attributes = []\n",
   "        super(MovedAttribute, self).__init__(name)\n",
   "        if PY3:\n",
   "                new_mod = name\n",
   "            self.mod = new_mod\n",
   "                    new_attr = name\n",
   "                    new_attr = old_attr\n",
   "            self.attr = new_attr\n",
   "                old_attr = name\n",
   "            self.attr = old_attr\n",
   "        module = _import_module(self.mod)\n",
   "        return getattr(module, self.attr)\n",
   "        for fullname in fullnames:\n",
   "            self.known_modules[self.name + \".\" + fullname] = mod\n",
   "        return self.known_modules[self.name + \".\" + fullname]\n",
   "        if fullname in self.known_modules:\n",
   "            return self.known_modules[fullname]\n",
   "            raise ImportError(\"This loader does not know module \" + fullname)\n",
   "            return sys.modules[fullname]\n",
   "        mod = self.__get_module(fullname)\n",
   "        if isinstance(mod, MovedModule):\n",
   "            mod = mod._resolve()\n",
   "            mod.__loader__ = self\n",
   "        sys.modules[fullname] = mod\n",
   "        return mod\n",
   "        return hasattr(self.__get_module(fullname), \"__path__\")\n",
   "        self.__get_module(fullname)  # eventually raises ImportError\n",
   "_importer = _SixMetaPathImporter(__name__)\n",
   "_moved_attributes = [\n",
   "    MovedAttribute(\"reload_module\", \"__builtin__\", \"importlib\" if PY34 else \"imp\", \"reload\"),\n",
   "    _moved_attributes += [\n",
   "for attr in _moved_attributes:\n",
   "    setattr(_MovedItems, attr.name, attr)\n",
   "    if isinstance(attr, MovedModule):\n",
   "        _importer._add_module(attr, \"moves.\" + attr.name)\n",
   "_MovedItems._moved_attributes = _moved_attributes\n",
   "moves = _MovedItems(__name__ + \".moves\")\n",
   "_importer._add_module(moves, \"moves\")\n",
   "_urllib_parse_moved_attributes = [\n",
   "for attr in _urllib_parse_moved_attributes:\n",
   "    setattr(Module_six_moves_urllib_parse, attr.name, attr)\n",
   "Module_six_moves_urllib_parse._moved_attributes = _urllib_parse_moved_attributes\n",
   "_importer._add_module(Module_six_moves_urllib_parse(__name__ + \".moves.urllib_parse\"),\n",
   "_urllib_error_moved_attributes = [\n",
   "for attr in _urllib_error_moved_attributes:\n",
   "    setattr(Module_six_moves_urllib_error, attr.name, attr)\n",
   "Module_six_moves_urllib_error._moved_attributes = _urllib_error_moved_attributes\n",
   "_importer._add_module(Module_six_moves_urllib_error(__name__ + \".moves.urllib.error\"),\n",
   "_urllib_request_moved_attributes = [\n",
   "for attr in _urllib_request_moved_attributes:\n",
   "    setattr(Module_six_moves_urllib_request, attr.name, attr)\n",
   "Module_six_moves_urllib_request._moved_attributes = _urllib_request_moved_attributes\n",
   "_importer._add_module(Module_six_moves_urllib_request(__name__ + \".moves.urllib.request\"),\n",
   "_urllib_response_moved_attributes = [\n",
   "for attr in _urllib_response_moved_attributes:\n",
   "    setattr(Module_six_moves_urllib_response, attr.name, attr)\n",
   "Module_six_moves_urllib_response._moved_attributes = _urllib_response_moved_attributes\n",
   "_importer._add_module(Module_six_moves_urllib_response(__name__ + \".moves.urllib.response\"),\n",
   "_urllib_robotparser_moved_attributes = [\n",
   "for attr in _urllib_robotparser_moved_attributes:\n",
   "    setattr(Module_six_moves_urllib_robotparser, attr.name, attr)\n",
   "Module_six_moves_urllib_robotparser._moved_attributes = _urllib_robotparser_moved_attributes\n",
   "_importer._add_module(Module_six_moves_urllib_robotparser(__name__ + \".moves.urllib.robotparser\"),\n",
   "    parse = _importer._get_module(\"moves.urllib_parse\")\n",
   "    error = _importer._get_module(\"moves.urllib_error\")\n",
   "    request = _importer._get_module(\"moves.urllib_request\")\n",
   "    response = _importer._get_module(\"moves.urllib_response\")\n",
   "    robotparser = _importer._get_module(\"moves.urllib_robotparser\")\n",
   "_importer._add_module(Module_six_moves_urllib(__name__ + \".moves.urllib\"),\n",
   "        delattr(_MovedItems, name)\n",
   "            del moves.__dict__[name]\n",
   "            raise AttributeError(\"no such move, %r\" % (name,))\n",
   "if PY3:\n",
   "    _meth_func = \"__func__\"\n",
   "    _meth_self = \"__self__\"\n",
   "    _func_closure = \"__closure__\"\n",
   "    _func_code = \"__code__\"\n",
   "    _func_defaults = \"__defaults__\"\n",
   "    _func_globals = \"__globals__\"\n",
   "    _meth_func = \"im_func\"\n",
   "    _meth_self = \"im_self\"\n",
   "    _func_closure = \"func_closure\"\n",
   "    _func_code = \"func_code\"\n",
   "    _func_defaults = \"func_defaults\"\n",
   "    _func_globals = \"func_globals\"\n",
   "    advance_iterator = next\n",
   "next = advance_iterator\n",
   "    callable = callable\n",
   "        return any(\"__call__\" in klass.__dict__ for klass in type(obj).__mro__)\n",
   "if PY3:\n",
   "        return types.MethodType(func, None, cls)\n",
   "    callable = callable\n",
   "_add_doc(get_unbound_function,\n",
   "get_method_function = operator.attrgetter(_meth_func)\n",
   "get_method_self = operator.attrgetter(_meth_self)\n",
   "get_function_closure = operator.attrgetter(_func_closure)\n",
   "get_function_code = operator.attrgetter(_func_code)\n",
   "get_function_defaults = operator.attrgetter(_func_defaults)\n",
   "get_function_globals = operator.attrgetter(_func_globals)\n",
   "if PY3:\n",
   "_add_doc(iterkeys, \"Return an iterator over the keys of a dictionary.\")\n",
   "_add_doc(itervalues, \"Return an iterator over the values of a dictionary.\")\n",
   "_add_doc(iteritems,\n",
   "_add_doc(iterlists,\n",
   "if PY3:\n",
   "    unichr = chr\n",
   "    StringIO = io.StringIO\n",
   "    _assertCountEqual = \"assertCountEqual\"\n",
   "        _assertRaisesRegex = \"assertRaisesRegexp\"\n",
   "        _assertRegex = \"assertRegexpMatches\"\n",
   "        _assertRaisesRegex = \"assertRaisesRegex\"\n",
   "        _assertRegex = \"assertRegex\"\n",
   "    unichr = unichr\n",
   "    StringIO = BytesIO = StringIO.StringIO\n",
   "    _assertCountEqual = \"assertItemsEqual\"\n",
   "    _assertRaisesRegex = \"assertRaisesRegexp\"\n",
   "    _assertRegex = \"assertRegexpMatches\"\n",
   "_add_doc(b, \"\"\"Byte literal\"\"\")\n",
   "_add_doc(u, \"\"\"Text literal\"\"\")\n",
   "    return getattr(self, _assertCountEqual)(*args, **kwargs)\n",
   "    return getattr(self, _assertRaisesRegex)(*args, **kwargs)\n",
   "    return getattr(self, _assertRegex)(*args, **kwargs)\n",
   "if PY3:\n",
   "    exec_ = getattr(moves.builtins, \"exec\")\n",
   "        if value is None:\n",
   "            value = tp()\n",
   "        if value.__traceback__ is not tb:\n",
   "            raise value.with_traceback(tb)\n",
   "        raise value\n",
   "            frame = sys._getframe(1)\n",
   "            _globs_ = frame.f_globals\n",
   "                _locs_ = frame.f_locals\n",
   "        elif _locs_ is None:\n",
   "            _locs_ = _globs_\n",
   "    exec_(\"\"\"def reraise(tp, value, tb=None):\n",
   "    exec_(\"\"\"def raise_from(value, from_value):\n",
   "    exec_(\"\"\"def raise_from(value, from_value):\n",
   "        raise value\n",
   "print_ = getattr(moves.builtins, \"print\", None)\n",
   "if print_ is None:\n",
   "        fp = kwargs.pop(\"file\", sys.stdout)\n",
   "        if fp is None:\n",
   "        def write(data):\n",
   "                data = str(data)\n",
   "            if (isinstance(fp, file) and\n",
   "                    isinstance(data, unicode) and\n",
   "                    fp.encoding is not None):\n",
   "                errors = getattr(fp, \"errors\", None)\n",
   "                if errors is None:\n",
   "                    errors = \"strict\"\n",
   "                data = data.encode(fp.encoding, errors)\n",
   "            fp.write(data)\n",
   "        want_unicode = False\n",
   "        sep = kwargs.pop(\"sep\", None)\n",
   "        if sep is not None:\n",
   "            if isinstance(sep, unicode):\n",
   "                want_unicode = True\n",
   "            elif not isinstance(sep, str):\n",
   "        end = kwargs.pop(\"end\", None)\n",
   "        if end is not None:\n",
   "            if isinstance(end, unicode):\n",
   "                want_unicode = True\n",
   "            elif not isinstance(end, str):\n",
   "        if not want_unicode:\n",
   "            for arg in args:\n",
   "                if isinstance(arg, unicode):\n",
   "                    want_unicode = True\n",
   "        if want_unicode:\n",
   "            newline = unicode(\"\\n\")\n",
   "            space = unicode(\" \")\n",
   "            newline = \"\\n\"\n",
   "            space = \" \"\n",
   "        if sep is None:\n",
   "            sep = space\n",
   "        if end is None:\n",
   "            end = newline\n",
   "        for i, arg in enumerate(args):\n",
   "            if i:\n",
   "                write(sep)\n",
   "            write(arg)\n",
   "        write(end)\n",
   "    _print = print_\n",
   "        _print(*args, **kwargs)\n",
   "        if flush and fp is not None:\n",
   "            fp.flush()\n",
   "_add_doc(reraise, \"\"\"Reraise an exception.\"\"\")\n",
   "            return meta(name, bases, d)\n",
   "        if '__str__' not in klass.__dict__:\n",
   "                             klass.__name__)\n",
   "        klass.__unicode__ = klass.__str__\n",
   "        klass.__str__ = lambda self: self.__unicode__().encode('utf-8')\n",
   "    return klass\n",
   "            del sys.meta_path[i]\n",
   "sys.meta_path.append(_importer)\n"
  ]
 },
 "47": {
  "name": "error",
  "type": "Module_six_moves_urllib_error",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/six.py",
  "lineno": "474",
  "column": "4",
  "context": "= _importer._get_module(\"moves.urllib_parse\")\n    error = _importer._get_module(\"moves.urllib_error\")\n    request = _importer._get_module(\"moves.urllib_",
  "context_lines": "class Module_six_moves_urllib(types.ModuleType):\n\n    \"\"\"Create a six.moves.urllib namespace that resembles the Python 3 namespace\"\"\"\n    __path__ = []  # mark as package\n    parse = _importer._get_module(\"moves.urllib_parse\")\n    error = _importer._get_module(\"moves.urllib_error\")\n    request = _importer._get_module(\"moves.urllib_request\")\n    response = _importer._get_module(\"moves.urllib_response\")\n    robotparser = _importer._get_module(\"moves.urllib_robotparser\")\n\n    def __dir__(self):\n",
  "slicing": [
   "PY3 = sys.version_info[0] == 3\n",
   "PY34 = sys.version_info[0:2] >= (3, 4)\n",
   "if PY3:\n",
   "def _add_doc(func, doc):\n",
   "    func.__doc__ = doc\n",
   "def _import_module(name):\n",
   "        result = self._resolve()\n",
   "        setattr(obj, self.name, result)  # Invokes __set__.\n",
   "        return result\n",
   "        if PY3:\n",
   "                new = name\n",
   "            self.mod = new\n",
   "        _module = self._resolve()\n",
   "        value = getattr(_module, attr)\n",
   "        setattr(self, attr, value)\n",
   "        return value\n",
   "        super(_LazyModule, self).__init__(name)\n",
   "        attrs = [\"__doc__\", \"__name__\"]\n",
   "        attrs += [attr.name for attr in self._moved_attributes]\n",
   "        return attrs\n",
   "    _moved_attributes = []\n",
   "        super(MovedAttribute, self).__init__(name)\n",
   "        if PY3:\n",
   "                new_mod = name\n",
   "            self.mod = new_mod\n",
   "                    new_attr = name\n",
   "                    new_attr = old_attr\n",
   "            self.attr = new_attr\n",
   "                old_attr = name\n",
   "            self.attr = old_attr\n",
   "        module = _import_module(self.mod)\n",
   "        return getattr(module, self.attr)\n",
   "        for fullname in fullnames:\n",
   "            self.known_modules[self.name + \".\" + fullname] = mod\n",
   "        return self.known_modules[self.name + \".\" + fullname]\n",
   "        if fullname in self.known_modules:\n",
   "            return self.known_modules[fullname]\n",
   "            raise ImportError(\"This loader does not know module \" + fullname)\n",
   "            return sys.modules[fullname]\n",
   "        mod = self.__get_module(fullname)\n",
   "        if isinstance(mod, MovedModule):\n",
   "            mod = mod._resolve()\n",
   "            mod.__loader__ = self\n",
   "        sys.modules[fullname] = mod\n",
   "        return mod\n",
   "        return hasattr(self.__get_module(fullname), \"__path__\")\n",
   "        self.__get_module(fullname)  # eventually raises ImportError\n",
   "_importer = _SixMetaPathImporter(__name__)\n",
   "_moved_attributes = [\n",
   "    MovedAttribute(\"reload_module\", \"__builtin__\", \"importlib\" if PY34 else \"imp\", \"reload\"),\n",
   "    _moved_attributes += [\n",
   "for attr in _moved_attributes:\n",
   "    setattr(_MovedItems, attr.name, attr)\n",
   "    if isinstance(attr, MovedModule):\n",
   "        _importer._add_module(attr, \"moves.\" + attr.name)\n",
   "_MovedItems._moved_attributes = _moved_attributes\n",
   "moves = _MovedItems(__name__ + \".moves\")\n",
   "_importer._add_module(moves, \"moves\")\n",
   "_urllib_parse_moved_attributes = [\n",
   "for attr in _urllib_parse_moved_attributes:\n",
   "    setattr(Module_six_moves_urllib_parse, attr.name, attr)\n",
   "Module_six_moves_urllib_parse._moved_attributes = _urllib_parse_moved_attributes\n",
   "_importer._add_module(Module_six_moves_urllib_parse(__name__ + \".moves.urllib_parse\"),\n",
   "_urllib_error_moved_attributes = [\n",
   "for attr in _urllib_error_moved_attributes:\n",
   "    setattr(Module_six_moves_urllib_error, attr.name, attr)\n",
   "Module_six_moves_urllib_error._moved_attributes = _urllib_error_moved_attributes\n",
   "_importer._add_module(Module_six_moves_urllib_error(__name__ + \".moves.urllib.error\"),\n",
   "_urllib_request_moved_attributes = [\n",
   "for attr in _urllib_request_moved_attributes:\n",
   "    setattr(Module_six_moves_urllib_request, attr.name, attr)\n",
   "Module_six_moves_urllib_request._moved_attributes = _urllib_request_moved_attributes\n",
   "_importer._add_module(Module_six_moves_urllib_request(__name__ + \".moves.urllib.request\"),\n",
   "_urllib_response_moved_attributes = [\n",
   "for attr in _urllib_response_moved_attributes:\n",
   "    setattr(Module_six_moves_urllib_response, attr.name, attr)\n",
   "Module_six_moves_urllib_response._moved_attributes = _urllib_response_moved_attributes\n",
   "_importer._add_module(Module_six_moves_urllib_response(__name__ + \".moves.urllib.response\"),\n",
   "_urllib_robotparser_moved_attributes = [\n",
   "for attr in _urllib_robotparser_moved_attributes:\n",
   "    setattr(Module_six_moves_urllib_robotparser, attr.name, attr)\n",
   "Module_six_moves_urllib_robotparser._moved_attributes = _urllib_robotparser_moved_attributes\n",
   "_importer._add_module(Module_six_moves_urllib_robotparser(__name__ + \".moves.urllib.robotparser\"),\n",
   "    parse = _importer._get_module(\"moves.urllib_parse\")\n",
   "    error = _importer._get_module(\"moves.urllib_error\")\n",
   "    request = _importer._get_module(\"moves.urllib_request\")\n",
   "    response = _importer._get_module(\"moves.urllib_response\")\n",
   "    robotparser = _importer._get_module(\"moves.urllib_robotparser\")\n",
   "_importer._add_module(Module_six_moves_urllib(__name__ + \".moves.urllib\"),\n",
   "        delattr(_MovedItems, name)\n",
   "            del moves.__dict__[name]\n",
   "            raise AttributeError(\"no such move, %r\" % (name,))\n",
   "if PY3:\n",
   "    _meth_func = \"__func__\"\n",
   "    _meth_self = \"__self__\"\n",
   "    _func_closure = \"__closure__\"\n",
   "    _func_code = \"__code__\"\n",
   "    _func_defaults = \"__defaults__\"\n",
   "    _func_globals = \"__globals__\"\n",
   "    _meth_func = \"im_func\"\n",
   "    _meth_self = \"im_self\"\n",
   "    _func_closure = \"func_closure\"\n",
   "    _func_code = \"func_code\"\n",
   "    _func_defaults = \"func_defaults\"\n",
   "    _func_globals = \"func_globals\"\n",
   "    advance_iterator = next\n",
   "next = advance_iterator\n",
   "    callable = callable\n",
   "        return any(\"__call__\" in klass.__dict__ for klass in type(obj).__mro__)\n",
   "if PY3:\n",
   "        return types.MethodType(func, None, cls)\n",
   "    callable = callable\n",
   "_add_doc(get_unbound_function,\n",
   "get_method_function = operator.attrgetter(_meth_func)\n",
   "get_method_self = operator.attrgetter(_meth_self)\n",
   "get_function_closure = operator.attrgetter(_func_closure)\n",
   "get_function_code = operator.attrgetter(_func_code)\n",
   "get_function_defaults = operator.attrgetter(_func_defaults)\n",
   "get_function_globals = operator.attrgetter(_func_globals)\n",
   "if PY3:\n",
   "_add_doc(iterkeys, \"Return an iterator over the keys of a dictionary.\")\n",
   "_add_doc(itervalues, \"Return an iterator over the values of a dictionary.\")\n",
   "_add_doc(iteritems,\n",
   "_add_doc(iterlists,\n",
   "if PY3:\n",
   "    unichr = chr\n",
   "    StringIO = io.StringIO\n",
   "    _assertCountEqual = \"assertCountEqual\"\n",
   "        _assertRaisesRegex = \"assertRaisesRegexp\"\n",
   "        _assertRegex = \"assertRegexpMatches\"\n",
   "        _assertRaisesRegex = \"assertRaisesRegex\"\n",
   "        _assertRegex = \"assertRegex\"\n",
   "    unichr = unichr\n",
   "    StringIO = BytesIO = StringIO.StringIO\n",
   "    _assertCountEqual = \"assertItemsEqual\"\n",
   "    _assertRaisesRegex = \"assertRaisesRegexp\"\n",
   "    _assertRegex = \"assertRegexpMatches\"\n",
   "_add_doc(b, \"\"\"Byte literal\"\"\")\n",
   "_add_doc(u, \"\"\"Text literal\"\"\")\n",
   "    return getattr(self, _assertCountEqual)(*args, **kwargs)\n",
   "    return getattr(self, _assertRaisesRegex)(*args, **kwargs)\n",
   "    return getattr(self, _assertRegex)(*args, **kwargs)\n",
   "if PY3:\n",
   "    exec_ = getattr(moves.builtins, \"exec\")\n",
   "        if value is None:\n",
   "            value = tp()\n",
   "        if value.__traceback__ is not tb:\n",
   "            raise value.with_traceback(tb)\n",
   "        raise value\n",
   "            frame = sys._getframe(1)\n",
   "            _globs_ = frame.f_globals\n",
   "                _locs_ = frame.f_locals\n",
   "        elif _locs_ is None:\n",
   "            _locs_ = _globs_\n",
   "    exec_(\"\"\"def reraise(tp, value, tb=None):\n",
   "    exec_(\"\"\"def raise_from(value, from_value):\n",
   "    exec_(\"\"\"def raise_from(value, from_value):\n",
   "        raise value\n",
   "print_ = getattr(moves.builtins, \"print\", None)\n",
   "if print_ is None:\n",
   "        fp = kwargs.pop(\"file\", sys.stdout)\n",
   "        if fp is None:\n",
   "        def write(data):\n",
   "                data = str(data)\n",
   "            if (isinstance(fp, file) and\n",
   "                    isinstance(data, unicode) and\n",
   "                    fp.encoding is not None):\n",
   "                errors = getattr(fp, \"errors\", None)\n",
   "                if errors is None:\n",
   "                    errors = \"strict\"\n",
   "                data = data.encode(fp.encoding, errors)\n",
   "            fp.write(data)\n",
   "        want_unicode = False\n",
   "        sep = kwargs.pop(\"sep\", None)\n",
   "        if sep is not None:\n",
   "            if isinstance(sep, unicode):\n",
   "                want_unicode = True\n",
   "            elif not isinstance(sep, str):\n",
   "        end = kwargs.pop(\"end\", None)\n",
   "        if end is not None:\n",
   "            if isinstance(end, unicode):\n",
   "                want_unicode = True\n",
   "            elif not isinstance(end, str):\n",
   "        if not want_unicode:\n",
   "            for arg in args:\n",
   "                if isinstance(arg, unicode):\n",
   "                    want_unicode = True\n",
   "        if want_unicode:\n",
   "            newline = unicode(\"\\n\")\n",
   "            space = unicode(\" \")\n",
   "            newline = \"\\n\"\n",
   "            space = \" \"\n",
   "        if sep is None:\n",
   "            sep = space\n",
   "        if end is None:\n",
   "            end = newline\n",
   "        for i, arg in enumerate(args):\n",
   "            if i:\n",
   "                write(sep)\n",
   "            write(arg)\n",
   "        write(end)\n",
   "    _print = print_\n",
   "        _print(*args, **kwargs)\n",
   "        if flush and fp is not None:\n",
   "            fp.flush()\n",
   "_add_doc(reraise, \"\"\"Reraise an exception.\"\"\")\n",
   "            return meta(name, bases, d)\n",
   "        if '__str__' not in klass.__dict__:\n",
   "                             klass.__name__)\n",
   "        klass.__unicode__ = klass.__str__\n",
   "        klass.__str__ = lambda self: self.__unicode__().encode('utf-8')\n",
   "    return klass\n",
   "            del sys.meta_path[i]\n",
   "sys.meta_path.append(_importer)\n"
  ]
 },
 "48": {
  "name": "request",
  "type": "Module_six_moves_urllib_request",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/six.py",
  "lineno": "475",
  "column": "4",
  "context": "= _importer._get_module(\"moves.urllib_error\")\n    request = _importer._get_module(\"moves.urllib_request\")\n    response = _importer._get_module(\"moves.urllib",
  "context_lines": "    \"\"\"Create a six.moves.urllib namespace that resembles the Python 3 namespace\"\"\"\n    __path__ = []  # mark as package\n    parse = _importer._get_module(\"moves.urllib_parse\")\n    error = _importer._get_module(\"moves.urllib_error\")\n    request = _importer._get_module(\"moves.urllib_request\")\n    response = _importer._get_module(\"moves.urllib_response\")\n    robotparser = _importer._get_module(\"moves.urllib_robotparser\")\n\n    def __dir__(self):\n        return ['parse', 'error', 'request', 'response', 'robotparser']\n\n",
  "slicing": [
   "PY3 = sys.version_info[0] == 3\n",
   "PY34 = sys.version_info[0:2] >= (3, 4)\n",
   "if PY3:\n",
   "def _add_doc(func, doc):\n",
   "    func.__doc__ = doc\n",
   "def _import_module(name):\n",
   "        result = self._resolve()\n",
   "        setattr(obj, self.name, result)  # Invokes __set__.\n",
   "        return result\n",
   "        if PY3:\n",
   "                new = name\n",
   "            self.mod = new\n",
   "        _module = self._resolve()\n",
   "        value = getattr(_module, attr)\n",
   "        setattr(self, attr, value)\n",
   "        return value\n",
   "        super(_LazyModule, self).__init__(name)\n",
   "        attrs = [\"__doc__\", \"__name__\"]\n",
   "        attrs += [attr.name for attr in self._moved_attributes]\n",
   "        return attrs\n",
   "    _moved_attributes = []\n",
   "        super(MovedAttribute, self).__init__(name)\n",
   "        if PY3:\n",
   "                new_mod = name\n",
   "            self.mod = new_mod\n",
   "                    new_attr = name\n",
   "                    new_attr = old_attr\n",
   "            self.attr = new_attr\n",
   "                old_attr = name\n",
   "            self.attr = old_attr\n",
   "        module = _import_module(self.mod)\n",
   "        return getattr(module, self.attr)\n",
   "        for fullname in fullnames:\n",
   "            self.known_modules[self.name + \".\" + fullname] = mod\n",
   "        return self.known_modules[self.name + \".\" + fullname]\n",
   "        if fullname in self.known_modules:\n",
   "            return self.known_modules[fullname]\n",
   "            raise ImportError(\"This loader does not know module \" + fullname)\n",
   "            return sys.modules[fullname]\n",
   "        mod = self.__get_module(fullname)\n",
   "        if isinstance(mod, MovedModule):\n",
   "            mod = mod._resolve()\n",
   "            mod.__loader__ = self\n",
   "        sys.modules[fullname] = mod\n",
   "        return mod\n",
   "        return hasattr(self.__get_module(fullname), \"__path__\")\n",
   "        self.__get_module(fullname)  # eventually raises ImportError\n",
   "_importer = _SixMetaPathImporter(__name__)\n",
   "_moved_attributes = [\n",
   "    MovedAttribute(\"reload_module\", \"__builtin__\", \"importlib\" if PY34 else \"imp\", \"reload\"),\n",
   "    _moved_attributes += [\n",
   "for attr in _moved_attributes:\n",
   "    setattr(_MovedItems, attr.name, attr)\n",
   "    if isinstance(attr, MovedModule):\n",
   "        _importer._add_module(attr, \"moves.\" + attr.name)\n",
   "_MovedItems._moved_attributes = _moved_attributes\n",
   "moves = _MovedItems(__name__ + \".moves\")\n",
   "_importer._add_module(moves, \"moves\")\n",
   "_urllib_parse_moved_attributes = [\n",
   "for attr in _urllib_parse_moved_attributes:\n",
   "    setattr(Module_six_moves_urllib_parse, attr.name, attr)\n",
   "Module_six_moves_urllib_parse._moved_attributes = _urllib_parse_moved_attributes\n",
   "_importer._add_module(Module_six_moves_urllib_parse(__name__ + \".moves.urllib_parse\"),\n",
   "_urllib_error_moved_attributes = [\n",
   "for attr in _urllib_error_moved_attributes:\n",
   "    setattr(Module_six_moves_urllib_error, attr.name, attr)\n",
   "Module_six_moves_urllib_error._moved_attributes = _urllib_error_moved_attributes\n",
   "_importer._add_module(Module_six_moves_urllib_error(__name__ + \".moves.urllib.error\"),\n",
   "_urllib_request_moved_attributes = [\n",
   "for attr in _urllib_request_moved_attributes:\n",
   "    setattr(Module_six_moves_urllib_request, attr.name, attr)\n",
   "Module_six_moves_urllib_request._moved_attributes = _urllib_request_moved_attributes\n",
   "_importer._add_module(Module_six_moves_urllib_request(__name__ + \".moves.urllib.request\"),\n",
   "_urllib_response_moved_attributes = [\n",
   "for attr in _urllib_response_moved_attributes:\n",
   "    setattr(Module_six_moves_urllib_response, attr.name, attr)\n",
   "Module_six_moves_urllib_response._moved_attributes = _urllib_response_moved_attributes\n",
   "_importer._add_module(Module_six_moves_urllib_response(__name__ + \".moves.urllib.response\"),\n",
   "_urllib_robotparser_moved_attributes = [\n",
   "for attr in _urllib_robotparser_moved_attributes:\n",
   "    setattr(Module_six_moves_urllib_robotparser, attr.name, attr)\n",
   "Module_six_moves_urllib_robotparser._moved_attributes = _urllib_robotparser_moved_attributes\n",
   "_importer._add_module(Module_six_moves_urllib_robotparser(__name__ + \".moves.urllib.robotparser\"),\n",
   "    parse = _importer._get_module(\"moves.urllib_parse\")\n",
   "    error = _importer._get_module(\"moves.urllib_error\")\n",
   "    request = _importer._get_module(\"moves.urllib_request\")\n",
   "    response = _importer._get_module(\"moves.urllib_response\")\n",
   "    robotparser = _importer._get_module(\"moves.urllib_robotparser\")\n",
   "_importer._add_module(Module_six_moves_urllib(__name__ + \".moves.urllib\"),\n",
   "        delattr(_MovedItems, name)\n",
   "            del moves.__dict__[name]\n",
   "            raise AttributeError(\"no such move, %r\" % (name,))\n",
   "if PY3:\n",
   "    _meth_func = \"__func__\"\n",
   "    _meth_self = \"__self__\"\n",
   "    _func_closure = \"__closure__\"\n",
   "    _func_code = \"__code__\"\n",
   "    _func_defaults = \"__defaults__\"\n",
   "    _func_globals = \"__globals__\"\n",
   "    _meth_func = \"im_func\"\n",
   "    _meth_self = \"im_self\"\n",
   "    _func_closure = \"func_closure\"\n",
   "    _func_code = \"func_code\"\n",
   "    _func_defaults = \"func_defaults\"\n",
   "    _func_globals = \"func_globals\"\n",
   "    advance_iterator = next\n",
   "next = advance_iterator\n",
   "    callable = callable\n",
   "        return any(\"__call__\" in klass.__dict__ for klass in type(obj).__mro__)\n",
   "if PY3:\n",
   "        return types.MethodType(func, None, cls)\n",
   "    callable = callable\n",
   "_add_doc(get_unbound_function,\n",
   "get_method_function = operator.attrgetter(_meth_func)\n",
   "get_method_self = operator.attrgetter(_meth_self)\n",
   "get_function_closure = operator.attrgetter(_func_closure)\n",
   "get_function_code = operator.attrgetter(_func_code)\n",
   "get_function_defaults = operator.attrgetter(_func_defaults)\n",
   "get_function_globals = operator.attrgetter(_func_globals)\n",
   "if PY3:\n",
   "_add_doc(iterkeys, \"Return an iterator over the keys of a dictionary.\")\n",
   "_add_doc(itervalues, \"Return an iterator over the values of a dictionary.\")\n",
   "_add_doc(iteritems,\n",
   "_add_doc(iterlists,\n",
   "if PY3:\n",
   "    unichr = chr\n",
   "    StringIO = io.StringIO\n",
   "    _assertCountEqual = \"assertCountEqual\"\n",
   "        _assertRaisesRegex = \"assertRaisesRegexp\"\n",
   "        _assertRegex = \"assertRegexpMatches\"\n",
   "        _assertRaisesRegex = \"assertRaisesRegex\"\n",
   "        _assertRegex = \"assertRegex\"\n",
   "    unichr = unichr\n",
   "    StringIO = BytesIO = StringIO.StringIO\n",
   "    _assertCountEqual = \"assertItemsEqual\"\n",
   "    _assertRaisesRegex = \"assertRaisesRegexp\"\n",
   "    _assertRegex = \"assertRegexpMatches\"\n",
   "_add_doc(b, \"\"\"Byte literal\"\"\")\n",
   "_add_doc(u, \"\"\"Text literal\"\"\")\n",
   "    return getattr(self, _assertCountEqual)(*args, **kwargs)\n",
   "    return getattr(self, _assertRaisesRegex)(*args, **kwargs)\n",
   "    return getattr(self, _assertRegex)(*args, **kwargs)\n",
   "if PY3:\n",
   "    exec_ = getattr(moves.builtins, \"exec\")\n",
   "        if value is None:\n",
   "            value = tp()\n",
   "        if value.__traceback__ is not tb:\n",
   "            raise value.with_traceback(tb)\n",
   "        raise value\n",
   "            frame = sys._getframe(1)\n",
   "            _globs_ = frame.f_globals\n",
   "                _locs_ = frame.f_locals\n",
   "        elif _locs_ is None:\n",
   "            _locs_ = _globs_\n",
   "    exec_(\"\"\"def reraise(tp, value, tb=None):\n",
   "    exec_(\"\"\"def raise_from(value, from_value):\n",
   "    exec_(\"\"\"def raise_from(value, from_value):\n",
   "        raise value\n",
   "print_ = getattr(moves.builtins, \"print\", None)\n",
   "if print_ is None:\n",
   "        fp = kwargs.pop(\"file\", sys.stdout)\n",
   "        if fp is None:\n",
   "        def write(data):\n",
   "                data = str(data)\n",
   "            if (isinstance(fp, file) and\n",
   "                    isinstance(data, unicode) and\n",
   "                    fp.encoding is not None):\n",
   "                errors = getattr(fp, \"errors\", None)\n",
   "                if errors is None:\n",
   "                    errors = \"strict\"\n",
   "                data = data.encode(fp.encoding, errors)\n",
   "            fp.write(data)\n",
   "        want_unicode = False\n",
   "        sep = kwargs.pop(\"sep\", None)\n",
   "        if sep is not None:\n",
   "            if isinstance(sep, unicode):\n",
   "                want_unicode = True\n",
   "            elif not isinstance(sep, str):\n",
   "        end = kwargs.pop(\"end\", None)\n",
   "        if end is not None:\n",
   "            if isinstance(end, unicode):\n",
   "                want_unicode = True\n",
   "            elif not isinstance(end, str):\n",
   "        if not want_unicode:\n",
   "            for arg in args:\n",
   "                if isinstance(arg, unicode):\n",
   "                    want_unicode = True\n",
   "        if want_unicode:\n",
   "            newline = unicode(\"\\n\")\n",
   "            space = unicode(\" \")\n",
   "            newline = \"\\n\"\n",
   "            space = \" \"\n",
   "        if sep is None:\n",
   "            sep = space\n",
   "        if end is None:\n",
   "            end = newline\n",
   "        for i, arg in enumerate(args):\n",
   "            if i:\n",
   "                write(sep)\n",
   "            write(arg)\n",
   "        write(end)\n",
   "    _print = print_\n",
   "        _print(*args, **kwargs)\n",
   "        if flush and fp is not None:\n",
   "            fp.flush()\n",
   "_add_doc(reraise, \"\"\"Reraise an exception.\"\"\")\n",
   "            return meta(name, bases, d)\n",
   "        if '__str__' not in klass.__dict__:\n",
   "                             klass.__name__)\n",
   "        klass.__unicode__ = klass.__str__\n",
   "        klass.__str__ = lambda self: self.__unicode__().encode('utf-8')\n",
   "    return klass\n",
   "            del sys.meta_path[i]\n",
   "sys.meta_path.append(_importer)\n"
  ]
 },
 "49": {
  "name": "response",
  "type": "Module_six_moves_urllib_response",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/six.py",
  "lineno": "476",
  "column": "4",
  "context": "_importer._get_module(\"moves.urllib_request\")\n    response = _importer._get_module(\"moves.urllib_response\")\n    robotparser = _importer._get_module(\"moves.url",
  "context_lines": "    __path__ = []  # mark as package\n    parse = _importer._get_module(\"moves.urllib_parse\")\n    error = _importer._get_module(\"moves.urllib_error\")\n    request = _importer._get_module(\"moves.urllib_request\")\n    response = _importer._get_module(\"moves.urllib_response\")\n    robotparser = _importer._get_module(\"moves.urllib_robotparser\")\n\n    def __dir__(self):\n        return ['parse', 'error', 'request', 'response', 'robotparser']\n\n_importer._add_module(Module_six_moves_urllib(__name__ + \".moves.urllib\"),\n",
  "slicing": [
   "PY3 = sys.version_info[0] == 3\n",
   "PY34 = sys.version_info[0:2] >= (3, 4)\n",
   "if PY3:\n",
   "def _add_doc(func, doc):\n",
   "    func.__doc__ = doc\n",
   "def _import_module(name):\n",
   "        result = self._resolve()\n",
   "        setattr(obj, self.name, result)  # Invokes __set__.\n",
   "        return result\n",
   "        if PY3:\n",
   "                new = name\n",
   "            self.mod = new\n",
   "        _module = self._resolve()\n",
   "        value = getattr(_module, attr)\n",
   "        setattr(self, attr, value)\n",
   "        return value\n",
   "        super(_LazyModule, self).__init__(name)\n",
   "        attrs = [\"__doc__\", \"__name__\"]\n",
   "        attrs += [attr.name for attr in self._moved_attributes]\n",
   "        return attrs\n",
   "    _moved_attributes = []\n",
   "        super(MovedAttribute, self).__init__(name)\n",
   "        if PY3:\n",
   "                new_mod = name\n",
   "            self.mod = new_mod\n",
   "                    new_attr = name\n",
   "                    new_attr = old_attr\n",
   "            self.attr = new_attr\n",
   "                old_attr = name\n",
   "            self.attr = old_attr\n",
   "        module = _import_module(self.mod)\n",
   "        return getattr(module, self.attr)\n",
   "        for fullname in fullnames:\n",
   "            self.known_modules[self.name + \".\" + fullname] = mod\n",
   "        return self.known_modules[self.name + \".\" + fullname]\n",
   "        if fullname in self.known_modules:\n",
   "            return self.known_modules[fullname]\n",
   "            raise ImportError(\"This loader does not know module \" + fullname)\n",
   "            return sys.modules[fullname]\n",
   "        mod = self.__get_module(fullname)\n",
   "        if isinstance(mod, MovedModule):\n",
   "            mod = mod._resolve()\n",
   "            mod.__loader__ = self\n",
   "        sys.modules[fullname] = mod\n",
   "        return mod\n",
   "        return hasattr(self.__get_module(fullname), \"__path__\")\n",
   "        self.__get_module(fullname)  # eventually raises ImportError\n",
   "_importer = _SixMetaPathImporter(__name__)\n",
   "_moved_attributes = [\n",
   "    MovedAttribute(\"reload_module\", \"__builtin__\", \"importlib\" if PY34 else \"imp\", \"reload\"),\n",
   "    _moved_attributes += [\n",
   "for attr in _moved_attributes:\n",
   "    setattr(_MovedItems, attr.name, attr)\n",
   "    if isinstance(attr, MovedModule):\n",
   "        _importer._add_module(attr, \"moves.\" + attr.name)\n",
   "_MovedItems._moved_attributes = _moved_attributes\n",
   "moves = _MovedItems(__name__ + \".moves\")\n",
   "_importer._add_module(moves, \"moves\")\n",
   "_urllib_parse_moved_attributes = [\n",
   "for attr in _urllib_parse_moved_attributes:\n",
   "    setattr(Module_six_moves_urllib_parse, attr.name, attr)\n",
   "Module_six_moves_urllib_parse._moved_attributes = _urllib_parse_moved_attributes\n",
   "_importer._add_module(Module_six_moves_urllib_parse(__name__ + \".moves.urllib_parse\"),\n",
   "_urllib_error_moved_attributes = [\n",
   "for attr in _urllib_error_moved_attributes:\n",
   "    setattr(Module_six_moves_urllib_error, attr.name, attr)\n",
   "Module_six_moves_urllib_error._moved_attributes = _urllib_error_moved_attributes\n",
   "_importer._add_module(Module_six_moves_urllib_error(__name__ + \".moves.urllib.error\"),\n",
   "_urllib_request_moved_attributes = [\n",
   "for attr in _urllib_request_moved_attributes:\n",
   "    setattr(Module_six_moves_urllib_request, attr.name, attr)\n",
   "Module_six_moves_urllib_request._moved_attributes = _urllib_request_moved_attributes\n",
   "_importer._add_module(Module_six_moves_urllib_request(__name__ + \".moves.urllib.request\"),\n",
   "_urllib_response_moved_attributes = [\n",
   "for attr in _urllib_response_moved_attributes:\n",
   "    setattr(Module_six_moves_urllib_response, attr.name, attr)\n",
   "Module_six_moves_urllib_response._moved_attributes = _urllib_response_moved_attributes\n",
   "_importer._add_module(Module_six_moves_urllib_response(__name__ + \".moves.urllib.response\"),\n",
   "_urllib_robotparser_moved_attributes = [\n",
   "for attr in _urllib_robotparser_moved_attributes:\n",
   "    setattr(Module_six_moves_urllib_robotparser, attr.name, attr)\n",
   "Module_six_moves_urllib_robotparser._moved_attributes = _urllib_robotparser_moved_attributes\n",
   "_importer._add_module(Module_six_moves_urllib_robotparser(__name__ + \".moves.urllib.robotparser\"),\n",
   "    parse = _importer._get_module(\"moves.urllib_parse\")\n",
   "    error = _importer._get_module(\"moves.urllib_error\")\n",
   "    request = _importer._get_module(\"moves.urllib_request\")\n",
   "    response = _importer._get_module(\"moves.urllib_response\")\n",
   "    robotparser = _importer._get_module(\"moves.urllib_robotparser\")\n",
   "_importer._add_module(Module_six_moves_urllib(__name__ + \".moves.urllib\"),\n",
   "        delattr(_MovedItems, name)\n",
   "            del moves.__dict__[name]\n",
   "            raise AttributeError(\"no such move, %r\" % (name,))\n",
   "if PY3:\n",
   "    _meth_func = \"__func__\"\n",
   "    _meth_self = \"__self__\"\n",
   "    _func_closure = \"__closure__\"\n",
   "    _func_code = \"__code__\"\n",
   "    _func_defaults = \"__defaults__\"\n",
   "    _func_globals = \"__globals__\"\n",
   "    _meth_func = \"im_func\"\n",
   "    _meth_self = \"im_self\"\n",
   "    _func_closure = \"func_closure\"\n",
   "    _func_code = \"func_code\"\n",
   "    _func_defaults = \"func_defaults\"\n",
   "    _func_globals = \"func_globals\"\n",
   "    advance_iterator = next\n",
   "next = advance_iterator\n",
   "    callable = callable\n",
   "        return any(\"__call__\" in klass.__dict__ for klass in type(obj).__mro__)\n",
   "if PY3:\n",
   "        return types.MethodType(func, None, cls)\n",
   "    callable = callable\n",
   "_add_doc(get_unbound_function,\n",
   "get_method_function = operator.attrgetter(_meth_func)\n",
   "get_method_self = operator.attrgetter(_meth_self)\n",
   "get_function_closure = operator.attrgetter(_func_closure)\n",
   "get_function_code = operator.attrgetter(_func_code)\n",
   "get_function_defaults = operator.attrgetter(_func_defaults)\n",
   "get_function_globals = operator.attrgetter(_func_globals)\n",
   "if PY3:\n",
   "_add_doc(iterkeys, \"Return an iterator over the keys of a dictionary.\")\n",
   "_add_doc(itervalues, \"Return an iterator over the values of a dictionary.\")\n",
   "_add_doc(iteritems,\n",
   "_add_doc(iterlists,\n",
   "if PY3:\n",
   "    unichr = chr\n",
   "    StringIO = io.StringIO\n",
   "    _assertCountEqual = \"assertCountEqual\"\n",
   "        _assertRaisesRegex = \"assertRaisesRegexp\"\n",
   "        _assertRegex = \"assertRegexpMatches\"\n",
   "        _assertRaisesRegex = \"assertRaisesRegex\"\n",
   "        _assertRegex = \"assertRegex\"\n",
   "    unichr = unichr\n",
   "    StringIO = BytesIO = StringIO.StringIO\n",
   "    _assertCountEqual = \"assertItemsEqual\"\n",
   "    _assertRaisesRegex = \"assertRaisesRegexp\"\n",
   "    _assertRegex = \"assertRegexpMatches\"\n",
   "_add_doc(b, \"\"\"Byte literal\"\"\")\n",
   "_add_doc(u, \"\"\"Text literal\"\"\")\n",
   "    return getattr(self, _assertCountEqual)(*args, **kwargs)\n",
   "    return getattr(self, _assertRaisesRegex)(*args, **kwargs)\n",
   "    return getattr(self, _assertRegex)(*args, **kwargs)\n",
   "if PY3:\n",
   "    exec_ = getattr(moves.builtins, \"exec\")\n",
   "        if value is None:\n",
   "            value = tp()\n",
   "        if value.__traceback__ is not tb:\n",
   "            raise value.with_traceback(tb)\n",
   "        raise value\n",
   "            frame = sys._getframe(1)\n",
   "            _globs_ = frame.f_globals\n",
   "                _locs_ = frame.f_locals\n",
   "        elif _locs_ is None:\n",
   "            _locs_ = _globs_\n",
   "    exec_(\"\"\"def reraise(tp, value, tb=None):\n",
   "    exec_(\"\"\"def raise_from(value, from_value):\n",
   "    exec_(\"\"\"def raise_from(value, from_value):\n",
   "        raise value\n",
   "print_ = getattr(moves.builtins, \"print\", None)\n",
   "if print_ is None:\n",
   "        fp = kwargs.pop(\"file\", sys.stdout)\n",
   "        if fp is None:\n",
   "        def write(data):\n",
   "                data = str(data)\n",
   "            if (isinstance(fp, file) and\n",
   "                    isinstance(data, unicode) and\n",
   "                    fp.encoding is not None):\n",
   "                errors = getattr(fp, \"errors\", None)\n",
   "                if errors is None:\n",
   "                    errors = \"strict\"\n",
   "                data = data.encode(fp.encoding, errors)\n",
   "            fp.write(data)\n",
   "        want_unicode = False\n",
   "        sep = kwargs.pop(\"sep\", None)\n",
   "        if sep is not None:\n",
   "            if isinstance(sep, unicode):\n",
   "                want_unicode = True\n",
   "            elif not isinstance(sep, str):\n",
   "        end = kwargs.pop(\"end\", None)\n",
   "        if end is not None:\n",
   "            if isinstance(end, unicode):\n",
   "                want_unicode = True\n",
   "            elif not isinstance(end, str):\n",
   "        if not want_unicode:\n",
   "            for arg in args:\n",
   "                if isinstance(arg, unicode):\n",
   "                    want_unicode = True\n",
   "        if want_unicode:\n",
   "            newline = unicode(\"\\n\")\n",
   "            space = unicode(\" \")\n",
   "            newline = \"\\n\"\n",
   "            space = \" \"\n",
   "        if sep is None:\n",
   "            sep = space\n",
   "        if end is None:\n",
   "            end = newline\n",
   "        for i, arg in enumerate(args):\n",
   "            if i:\n",
   "                write(sep)\n",
   "            write(arg)\n",
   "        write(end)\n",
   "    _print = print_\n",
   "        _print(*args, **kwargs)\n",
   "        if flush and fp is not None:\n",
   "            fp.flush()\n",
   "_add_doc(reraise, \"\"\"Reraise an exception.\"\"\")\n",
   "            return meta(name, bases, d)\n",
   "        if '__str__' not in klass.__dict__:\n",
   "                             klass.__name__)\n",
   "        klass.__unicode__ = klass.__str__\n",
   "        klass.__str__ = lambda self: self.__unicode__().encode('utf-8')\n",
   "    return klass\n",
   "            del sys.meta_path[i]\n",
   "sys.meta_path.append(_importer)\n"
  ]
 },
 "50": {
  "name": "robotparser",
  "type": "Module_six_moves_urllib_robotparser",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/six.py",
  "lineno": "477",
  "column": "4",
  "context": "importer._get_module(\"moves.urllib_response\")\n    robotparser = _importer._get_module(\"moves.urllib_robotparser\")\n\n    def __dir__(self):\n        return ['parse', '",
  "context_lines": "    parse = _importer._get_module(\"moves.urllib_parse\")\n    error = _importer._get_module(\"moves.urllib_error\")\n    request = _importer._get_module(\"moves.urllib_request\")\n    response = _importer._get_module(\"moves.urllib_response\")\n    robotparser = _importer._get_module(\"moves.urllib_robotparser\")\n\n    def __dir__(self):\n        return ['parse', 'error', 'request', 'response', 'robotparser']\n\n_importer._add_module(Module_six_moves_urllib(__name__ + \".moves.urllib\"),\n",
  "slicing": [
   "PY3 = sys.version_info[0] == 3\n",
   "PY34 = sys.version_info[0:2] >= (3, 4)\n",
   "if PY3:\n",
   "def _add_doc(func, doc):\n",
   "    func.__doc__ = doc\n",
   "def _import_module(name):\n",
   "        result = self._resolve()\n",
   "        setattr(obj, self.name, result)  # Invokes __set__.\n",
   "        return result\n",
   "        if PY3:\n",
   "                new = name\n",
   "            self.mod = new\n",
   "        _module = self._resolve()\n",
   "        value = getattr(_module, attr)\n",
   "        setattr(self, attr, value)\n",
   "        return value\n",
   "        super(_LazyModule, self).__init__(name)\n",
   "        attrs = [\"__doc__\", \"__name__\"]\n",
   "        attrs += [attr.name for attr in self._moved_attributes]\n",
   "        return attrs\n",
   "    _moved_attributes = []\n",
   "        super(MovedAttribute, self).__init__(name)\n",
   "        if PY3:\n",
   "                new_mod = name\n",
   "            self.mod = new_mod\n",
   "                    new_attr = name\n",
   "                    new_attr = old_attr\n",
   "            self.attr = new_attr\n",
   "                old_attr = name\n",
   "            self.attr = old_attr\n",
   "        module = _import_module(self.mod)\n",
   "        return getattr(module, self.attr)\n",
   "        for fullname in fullnames:\n",
   "            self.known_modules[self.name + \".\" + fullname] = mod\n",
   "        return self.known_modules[self.name + \".\" + fullname]\n",
   "        if fullname in self.known_modules:\n",
   "            return self.known_modules[fullname]\n",
   "            raise ImportError(\"This loader does not know module \" + fullname)\n",
   "            return sys.modules[fullname]\n",
   "        mod = self.__get_module(fullname)\n",
   "        if isinstance(mod, MovedModule):\n",
   "            mod = mod._resolve()\n",
   "            mod.__loader__ = self\n",
   "        sys.modules[fullname] = mod\n",
   "        return mod\n",
   "        return hasattr(self.__get_module(fullname), \"__path__\")\n",
   "        self.__get_module(fullname)  # eventually raises ImportError\n",
   "_importer = _SixMetaPathImporter(__name__)\n",
   "_moved_attributes = [\n",
   "    MovedAttribute(\"reload_module\", \"__builtin__\", \"importlib\" if PY34 else \"imp\", \"reload\"),\n",
   "    _moved_attributes += [\n",
   "for attr in _moved_attributes:\n",
   "    setattr(_MovedItems, attr.name, attr)\n",
   "    if isinstance(attr, MovedModule):\n",
   "        _importer._add_module(attr, \"moves.\" + attr.name)\n",
   "_MovedItems._moved_attributes = _moved_attributes\n",
   "moves = _MovedItems(__name__ + \".moves\")\n",
   "_importer._add_module(moves, \"moves\")\n",
   "_urllib_parse_moved_attributes = [\n",
   "for attr in _urllib_parse_moved_attributes:\n",
   "    setattr(Module_six_moves_urllib_parse, attr.name, attr)\n",
   "Module_six_moves_urllib_parse._moved_attributes = _urllib_parse_moved_attributes\n",
   "_importer._add_module(Module_six_moves_urllib_parse(__name__ + \".moves.urllib_parse\"),\n",
   "_urllib_error_moved_attributes = [\n",
   "for attr in _urllib_error_moved_attributes:\n",
   "    setattr(Module_six_moves_urllib_error, attr.name, attr)\n",
   "Module_six_moves_urllib_error._moved_attributes = _urllib_error_moved_attributes\n",
   "_importer._add_module(Module_six_moves_urllib_error(__name__ + \".moves.urllib.error\"),\n",
   "_urllib_request_moved_attributes = [\n",
   "for attr in _urllib_request_moved_attributes:\n",
   "    setattr(Module_six_moves_urllib_request, attr.name, attr)\n",
   "Module_six_moves_urllib_request._moved_attributes = _urllib_request_moved_attributes\n",
   "_importer._add_module(Module_six_moves_urllib_request(__name__ + \".moves.urllib.request\"),\n",
   "_urllib_response_moved_attributes = [\n",
   "for attr in _urllib_response_moved_attributes:\n",
   "    setattr(Module_six_moves_urllib_response, attr.name, attr)\n",
   "Module_six_moves_urllib_response._moved_attributes = _urllib_response_moved_attributes\n",
   "_importer._add_module(Module_six_moves_urllib_response(__name__ + \".moves.urllib.response\"),\n",
   "_urllib_robotparser_moved_attributes = [\n",
   "for attr in _urllib_robotparser_moved_attributes:\n",
   "    setattr(Module_six_moves_urllib_robotparser, attr.name, attr)\n",
   "Module_six_moves_urllib_robotparser._moved_attributes = _urllib_robotparser_moved_attributes\n",
   "_importer._add_module(Module_six_moves_urllib_robotparser(__name__ + \".moves.urllib.robotparser\"),\n",
   "    parse = _importer._get_module(\"moves.urllib_parse\")\n",
   "    error = _importer._get_module(\"moves.urllib_error\")\n",
   "    request = _importer._get_module(\"moves.urllib_request\")\n",
   "    response = _importer._get_module(\"moves.urllib_response\")\n",
   "    robotparser = _importer._get_module(\"moves.urllib_robotparser\")\n",
   "_importer._add_module(Module_six_moves_urllib(__name__ + \".moves.urllib\"),\n",
   "        delattr(_MovedItems, name)\n",
   "            del moves.__dict__[name]\n",
   "            raise AttributeError(\"no such move, %r\" % (name,))\n",
   "if PY3:\n",
   "    _meth_func = \"__func__\"\n",
   "    _meth_self = \"__self__\"\n",
   "    _func_closure = \"__closure__\"\n",
   "    _func_code = \"__code__\"\n",
   "    _func_defaults = \"__defaults__\"\n",
   "    _func_globals = \"__globals__\"\n",
   "    _meth_func = \"im_func\"\n",
   "    _meth_self = \"im_self\"\n",
   "    _func_closure = \"func_closure\"\n",
   "    _func_code = \"func_code\"\n",
   "    _func_defaults = \"func_defaults\"\n",
   "    _func_globals = \"func_globals\"\n",
   "    advance_iterator = next\n",
   "next = advance_iterator\n",
   "    callable = callable\n",
   "        return any(\"__call__\" in klass.__dict__ for klass in type(obj).__mro__)\n",
   "if PY3:\n",
   "        return types.MethodType(func, None, cls)\n",
   "    callable = callable\n",
   "_add_doc(get_unbound_function,\n",
   "get_method_function = operator.attrgetter(_meth_func)\n",
   "get_method_self = operator.attrgetter(_meth_self)\n",
   "get_function_closure = operator.attrgetter(_func_closure)\n",
   "get_function_code = operator.attrgetter(_func_code)\n",
   "get_function_defaults = operator.attrgetter(_func_defaults)\n",
   "get_function_globals = operator.attrgetter(_func_globals)\n",
   "if PY3:\n",
   "_add_doc(iterkeys, \"Return an iterator over the keys of a dictionary.\")\n",
   "_add_doc(itervalues, \"Return an iterator over the values of a dictionary.\")\n",
   "_add_doc(iteritems,\n",
   "_add_doc(iterlists,\n",
   "if PY3:\n",
   "    unichr = chr\n",
   "    StringIO = io.StringIO\n",
   "    _assertCountEqual = \"assertCountEqual\"\n",
   "        _assertRaisesRegex = \"assertRaisesRegexp\"\n",
   "        _assertRegex = \"assertRegexpMatches\"\n",
   "        _assertRaisesRegex = \"assertRaisesRegex\"\n",
   "        _assertRegex = \"assertRegex\"\n",
   "    unichr = unichr\n",
   "    StringIO = BytesIO = StringIO.StringIO\n",
   "    _assertCountEqual = \"assertItemsEqual\"\n",
   "    _assertRaisesRegex = \"assertRaisesRegexp\"\n",
   "    _assertRegex = \"assertRegexpMatches\"\n",
   "_add_doc(b, \"\"\"Byte literal\"\"\")\n",
   "_add_doc(u, \"\"\"Text literal\"\"\")\n",
   "    return getattr(self, _assertCountEqual)(*args, **kwargs)\n",
   "    return getattr(self, _assertRaisesRegex)(*args, **kwargs)\n",
   "    return getattr(self, _assertRegex)(*args, **kwargs)\n",
   "if PY3:\n",
   "    exec_ = getattr(moves.builtins, \"exec\")\n",
   "        if value is None:\n",
   "            value = tp()\n",
   "        if value.__traceback__ is not tb:\n",
   "            raise value.with_traceback(tb)\n",
   "        raise value\n",
   "            frame = sys._getframe(1)\n",
   "            _globs_ = frame.f_globals\n",
   "                _locs_ = frame.f_locals\n",
   "        elif _locs_ is None:\n",
   "            _locs_ = _globs_\n",
   "    exec_(\"\"\"def reraise(tp, value, tb=None):\n",
   "    exec_(\"\"\"def raise_from(value, from_value):\n",
   "    exec_(\"\"\"def raise_from(value, from_value):\n",
   "        raise value\n",
   "print_ = getattr(moves.builtins, \"print\", None)\n",
   "if print_ is None:\n",
   "        fp = kwargs.pop(\"file\", sys.stdout)\n",
   "        if fp is None:\n",
   "        def write(data):\n",
   "                data = str(data)\n",
   "            if (isinstance(fp, file) and\n",
   "                    isinstance(data, unicode) and\n",
   "                    fp.encoding is not None):\n",
   "                errors = getattr(fp, \"errors\", None)\n",
   "                if errors is None:\n",
   "                    errors = \"strict\"\n",
   "                data = data.encode(fp.encoding, errors)\n",
   "            fp.write(data)\n",
   "        want_unicode = False\n",
   "        sep = kwargs.pop(\"sep\", None)\n",
   "        if sep is not None:\n",
   "            if isinstance(sep, unicode):\n",
   "                want_unicode = True\n",
   "            elif not isinstance(sep, str):\n",
   "        end = kwargs.pop(\"end\", None)\n",
   "        if end is not None:\n",
   "            if isinstance(end, unicode):\n",
   "                want_unicode = True\n",
   "            elif not isinstance(end, str):\n",
   "        if not want_unicode:\n",
   "            for arg in args:\n",
   "                if isinstance(arg, unicode):\n",
   "                    want_unicode = True\n",
   "        if want_unicode:\n",
   "            newline = unicode(\"\\n\")\n",
   "            space = unicode(\" \")\n",
   "            newline = \"\\n\"\n",
   "            space = \" \"\n",
   "        if sep is None:\n",
   "            sep = space\n",
   "        if end is None:\n",
   "            end = newline\n",
   "        for i, arg in enumerate(args):\n",
   "            if i:\n",
   "                write(sep)\n",
   "            write(arg)\n",
   "        write(end)\n",
   "    _print = print_\n",
   "        _print(*args, **kwargs)\n",
   "        if flush and fp is not None:\n",
   "            fp.flush()\n",
   "_add_doc(reraise, \"\"\"Reraise an exception.\"\"\")\n",
   "            return meta(name, bases, d)\n",
   "        if '__str__' not in klass.__dict__:\n",
   "                             klass.__name__)\n",
   "        klass.__unicode__ = klass.__str__\n",
   "        klass.__str__ = lambda self: self.__unicode__().encode('utf-8')\n",
   "    return klass\n",
   "            del sys.meta_path[i]\n",
   "sys.meta_path.append(_importer)\n"
  ]
 },
 "51": {
  "name": "Machine",
  "type": "MetaStateMachine",
  "class": "customized",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/fluidity/machine.py",
  "lineno": "22",
  "column": "8",
  "context": "bal _transition_gatherer, _state_gatherer\n        Machine = super(MetaStateMachine, cls).__new__(cls, name, bases, dictionary)\n        Machine._class_transitions = []\n        Ma",
  "context_lines": "    _state_gatherer.append([name, enter, exit])\n\n\nclass MetaStateMachine(type):\n\n    def __new__(cls, name, bases, dictionary):\n        global _transition_gatherer, _state_gatherer\n        Machine = super(MetaStateMachine, cls).__new__(cls, name, bases, dictionary)\n        Machine._class_transitions = []\n        Machine._class_states = {}\n        for s in _state_gatherer:\n            Machine._add_class_state(*s)\n",
  "slicing": [
   "_transition_gatherer = []\n",
   "    _transition_gatherer.append([event, from_, to, action, guard])\n",
   "_state_gatherer = []\n",
   "    _state_gatherer.append([name, enter, exit])\n",
   "        Machine = super(MetaStateMachine, cls).__new__(cls, name, bases, dictionary)\n",
   "        Machine._class_transitions = []\n",
   "        Machine._class_states = {}\n",
   "        for s in _state_gatherer:\n",
   "            Machine._add_class_state(*s)\n",
   "        for i in _transition_gatherer:\n",
   "            Machine._add_class_transition(*i)\n",
   "        _transition_gatherer = []\n",
   "        _state_gatherer = []\n",
   "        return Machine\n",
   "StateMachineBase = MetaStateMachine('StateMachineBase', (object, ), {})\n",
   "class StateMachine(StateMachineBase):\n",
   "        obj = super(StateMachine, cls).__new__(cls)\n",
   "        obj._states = {}\n",
   "        obj._transitions = []\n",
   "        return obj\n",
   "        for collection in [self._states.values(), self._transitions]:\n",
   "            for component in collection:\n",
   "                component.machine = self\n",
   "        state = _State(name, enter, exit)\n",
   "        setattr(self, state.getter_name(), state.getter_method().__get__(self, self.__class__))\n",
   "        self._states[name] = state\n",
   "        self.changing_state(self._current_state_object.name, state.name)\n",
   "        self._current_state_object = state\n",
   "        return [s.name for s in self._state_objects()]\n",
   "        transition = _Transition(event, [cls._class_states[s] for s in _listize(from_)],\n",
   "        cls._class_transitions.append(transition)\n",
   "        setattr(cls, event, transition.event_method())\n",
   "        transition = _Transition(event, [self._state_by_name(s) for s in _listize(from_)],\n",
   "        self._transitions.append(transition)\n",
   "        setattr(self, event, transition.event_method().__get__(self, self.__class__))\n",
   "            setattr(self, state.getter_name(), state.getter_method().__get__(self, self.__class__))\n",
   "            if state.name == name:\n",
   "                return state\n",
   "        return list(filter(lambda transition: transition.event == name, self._transitions))\n",
   "          lambda transition: transition.is_valid_from(self._current_state_object),\n",
   "            if transition.check_guard(self):\n",
   "                allowed_transitions.append(transition)\n"
  ]
 },
 "52": {
  "name": "current_state",
  "type": "property",
  "class": "unknown",
  "approach": "annotation",
  "file_path": "invoke/invoke/vendor/fluidity/machine.py",
  "lineno": "82",
  "column": "4",
  "context": "      return self._current_state_object.name\n\n    current_state = property(_current_state_name)\n\n    def changing_state(self, from_, to):\n        ",
  "context_lines": "        setattr(self, state.getter_name(), state.getter_method().__get__(self, self.__class__))\n        self._states[name] = state\n\n    def _current_state_name(self):\n        return self._current_state_object.name\n\n    current_state = property(_current_state_name)\n\n    def changing_state(self, from_, to):\n        \"\"\"\n        This method is called whenever a state change is executed\n",
  "slicing": [
   "_transition_gatherer = []\n",
   "    _transition_gatherer.append([event, from_, to, action, guard])\n",
   "_state_gatherer = []\n",
   "    _state_gatherer.append([name, enter, exit])\n",
   "        Machine = super(MetaStateMachine, cls).__new__(cls, name, bases, dictionary)\n",
   "        Machine._class_transitions = []\n",
   "        Machine._class_states = {}\n",
   "        for s in _state_gatherer:\n",
   "            Machine._add_class_state(*s)\n",
   "        for i in _transition_gatherer:\n",
   "            Machine._add_class_transition(*i)\n",
   "        _transition_gatherer = []\n",
   "        _state_gatherer = []\n",
   "        return Machine\n",
   "StateMachineBase = MetaStateMachine('StateMachineBase', (object, ), {})\n",
   "class StateMachine(StateMachineBase):\n",
   "        obj = super(StateMachine, cls).__new__(cls)\n",
   "        obj._states = {}\n",
   "        obj._transitions = []\n",
   "        return obj\n",
   "        for collection in [self._states.values(), self._transitions]:\n",
   "            for component in collection:\n",
   "                component.machine = self\n",
   "        state = _State(name, enter, exit)\n",
   "        setattr(self, state.getter_name(), state.getter_method().__get__(self, self.__class__))\n",
   "        self._states[name] = state\n",
   "    current_state = property(_current_state_name)\n",
   "        self.changing_state(self._current_state_object.name, state.name)\n",
   "        self._current_state_object = state\n",
   "        return [s.name for s in self._state_objects()]\n",
   "        transition = _Transition(event, [cls._class_states[s] for s in _listize(from_)],\n",
   "        cls._class_transitions.append(transition)\n",
   "        setattr(cls, event, transition.event_method())\n",
   "        transition = _Transition(event, [self._state_by_name(s) for s in _listize(from_)],\n",
   "        self._transitions.append(transition)\n",
   "        setattr(self, event, transition.event_method().__get__(self, self.__class__))\n",
   "            setattr(self, state.getter_name(), state.getter_method().__get__(self, self.__class__))\n",
   "            if state.name == name:\n",
   "                return state\n",
   "        return list(filter(lambda transition: transition.event == name, self._transitions))\n",
   "          lambda transition: transition.is_valid_from(self._current_state_object),\n",
   "            if transition.check_guard(self):\n",
   "                allowed_transitions.append(transition)\n"
  ]
 },
 "53": {
  "name": "ANCHOR_TEMPLATE",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/yaml3/serializer.py",
  "lineno": "13",
  "column": "4",
  "context": "rror(YAMLError):\n    pass\n\nclass Serializer:\n\n    ANCHOR_TEMPLATE = 'id%03d'\n\n    def __init__(self, encoding=None,\n           ",
  "context_lines": "from .nodes import *\n\nclass SerializerError(YAMLError):\n    pass\n\nclass Serializer:\n\n    ANCHOR_TEMPLATE = 'id%03d'\n\n    def __init__(self, encoding=None,\n            explicit_start=None, explicit_end=None, version=None, tags=None):\n        self.use_encoding = encoding\n",
  "slicing": "    ANCHOR_TEMPLATE = 'id%03d'\n"
 },
 "54": {
  "name": "inf_value",
  "type": "float",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/yaml3/representer.py",
  "lineno": "163",
  "column": "4",
  "context": "t_scalar('tag:yaml.org,2002:int', str(data))\n\n    inf_value = 1e300\n    while repr(inf_value) != repr(inf_value*inf_va",
  "context_lines": "            value = 'false'\n        return self.represent_scalar('tag:yaml.org,2002:bool', value)\n\n    def represent_int(self, data):\n        return self.represent_scalar('tag:yaml.org,2002:int', str(data))\n\n    inf_value = 1e300\n    while repr(inf_value) != repr(inf_value*inf_value):\n        inf_value *= inf_value\n\n    def represent_float(self, data):\n        if data != data or (data == 0.0 and data == 1.0):\n",
  "slicing": [
   "    inf_value = 1e300\n",
   "    while repr(inf_value) != repr(inf_value*inf_value):\n",
   "        inf_value *= inf_value\n"
  ]
 },
 "55": {
  "name": "inf_value",
  "type": "float",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "invoke/invoke/vendor/yaml3/representer.py",
  "lineno": "165",
  "column": "8",
  "context": "(inf_value) != repr(inf_value*inf_value):\n        inf_value *= inf_value\n\n    def represent_float(self, data):\n        if d",
  "context_lines": "    def represent_int(self, data):\n        return self.represent_scalar('tag:yaml.org,2002:int', str(data))\n\n    inf_value = 1e300\n    while repr(inf_value) != repr(inf_value*inf_value):\n        inf_value *= inf_value\n\n    def represent_float(self, data):\n        if data != data or (data == 0.0 and data == 1.0):\n            value = '.nan'\n",
  "slicing": [
   "        inf_value *= inf_value\n"
  ]
 },
 "56": {
  "name": "DEFAULT_SCALAR_TAG",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/yaml3/resolver.py",
  "lineno": "14",
  "column": "4",
  "context": "or(YAMLError):\n    pass\n\nclass BaseResolver:\n\n    DEFAULT_SCALAR_TAG = 'tag:yaml.org,2002:str'\n    DEFAULT_SEQUENCE_TAG = 'tag:yaml.org,2002:seq'",
  "context_lines": "import re\n\nclass ResolverError(YAMLError):\n    pass\n\nclass BaseResolver:\n\n    DEFAULT_SCALAR_TAG = 'tag:yaml.org,2002:str'\n    DEFAULT_SEQUENCE_TAG = 'tag:yaml.org,2002:seq'\n    DEFAULT_MAPPING_TAG = 'tag:yaml.org,2002:map'\n\n    yaml_implicit_resolvers = {}\n    yaml_path_resolvers = {}\n\n",
  "slicing": "    DEFAULT_SCALAR_TAG = 'tag:yaml.org,2002:str'\n"
 },
 "57": {
  "name": "DEFAULT_SEQUENCE_TAG",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/yaml3/resolver.py",
  "lineno": "15",
  "column": "4",
  "context": " DEFAULT_SCALAR_TAG = 'tag:yaml.org,2002:str'\n    DEFAULT_SEQUENCE_TAG = 'tag:yaml.org,2002:seq'\n    DEFAULT_MAPPING_TAG = 'tag:yaml.org,2002:map'\n",
  "context_lines": "class ResolverError(YAMLError):\n    pass\n\nclass BaseResolver:\n\n    DEFAULT_SCALAR_TAG = 'tag:yaml.org,2002:str'\n    DEFAULT_SEQUENCE_TAG = 'tag:yaml.org,2002:seq'\n    DEFAULT_MAPPING_TAG = 'tag:yaml.org,2002:map'\n\n    yaml_implicit_resolvers = {}\n    yaml_path_resolvers = {}\n\n    def __init__(self):\n",
  "slicing": "    DEFAULT_SEQUENCE_TAG = 'tag:yaml.org,2002:seq'\n"
 },
 "58": {
  "name": "DEFAULT_MAPPING_TAG",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/yaml3/resolver.py",
  "lineno": "16",
  "column": "4",
  "context": "EFAULT_SEQUENCE_TAG = 'tag:yaml.org,2002:seq'\n    DEFAULT_MAPPING_TAG = 'tag:yaml.org,2002:map'\n\n    yaml_implicit_resolvers = {}\n    yaml_path_re",
  "context_lines": "    pass\n\nclass BaseResolver:\n\n    DEFAULT_SCALAR_TAG = 'tag:yaml.org,2002:str'\n    DEFAULT_SEQUENCE_TAG = 'tag:yaml.org,2002:seq'\n    DEFAULT_MAPPING_TAG = 'tag:yaml.org,2002:map'\n\n    yaml_implicit_resolvers = {}\n    yaml_path_resolvers = {}\n\n    def __init__(self):\n",
  "slicing": "    DEFAULT_MAPPING_TAG = 'tag:yaml.org,2002:map'\n"
 },
 "59": {
  "name": "yaml_tag",
  "type": "NoneType",
  "class": "unknown",
  "approach": "annotation",
  "file_path": "invoke/invoke/vendor/yaml3/__init__.py",
  "lineno": "295",
  "column": "4",
  "context": "aml_loader = Loader\n    yaml_dumper = Dumper\n\n    yaml_tag = None\n    yaml_flow_style = None\n\n    @classmethod\n    d",
  "context_lines": "    \"\"\"\n\n    __slots__ = ()  # no direct instantiation, so allow immutable subclasses\n\n    yaml_loader = Loader\n    yaml_dumper = Dumper\n\n    yaml_tag = None\n    yaml_flow_style = None\n\n    @classmethod\n    def from_yaml(cls, loader, node):\n        \"\"\"\n",
  "slicing": "    yaml_tag = None\n"
 },
 "60": {
  "name": "yaml_flow_style",
  "type": "NoneType",
  "class": "unknown",
  "approach": "annotation",
  "file_path": "invoke/invoke/vendor/yaml3/__init__.py",
  "lineno": "296",
  "column": "4",
  "context": "    yaml_dumper = Dumper\n\n    yaml_tag = None\n    yaml_flow_style = None\n\n    @classmethod\n    def from_yaml(cls, loader, n",
  "context_lines": "    __slots__ = ()  # no direct instantiation, so allow immutable subclasses\n\n    yaml_loader = Loader\n    yaml_dumper = Dumper\n\n    yaml_tag = None\n    yaml_flow_style = None\n\n    @classmethod\n    def from_yaml(cls, loader, node):\n        \"\"\"\n",
  "slicing": "    yaml_flow_style = None\n"
 },
 "61": {
  "name": "id",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/yaml3/nodes.py",
  "lineno": "26",
  "column": "4",
  "context": "__, self.tag, value)\n\nclass ScalarNode(Node):\n    id = 'scalar'\n    def __init__(self, tag, value,\n            sta",
  "context_lines": "        #        value = repr(value)\n        value = repr(value)\n        return '%s(tag=%r, value=%s)' % (self.__class__.__name__, self.tag, value)\n\nclass ScalarNode(Node):\n    id = 'scalar'\n    def __init__(self, tag, value,\n            start_mark=None, end_mark=None, style=None):\n        self.tag = tag\n        self.value = value\n",
  "slicing": "    id = 'scalar'\n"
 },
 "62": {
  "name": "id",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/yaml3/nodes.py",
  "lineno": "45",
  "column": "4",
  "context": "ow_style\n\nclass SequenceNode(CollectionNode):\n    id = 'sequence'\n\nclass MappingNode(CollectionNode):\n    id = 'mapp",
  "context_lines": "        self.start_mark = start_mark\n        self.end_mark = end_mark\n        self.flow_style = flow_style\n\nclass SequenceNode(CollectionNode):\n    id = 'sequence'\n\nclass MappingNode(CollectionNode):\n    id = 'mapping'\n",
  "slicing": "    id = 'sequence'\n"
 },
 "63": {
  "name": "id",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/yaml3/nodes.py",
  "lineno": "48",
  "column": "4",
  "context": "sequence'\n\nclass MappingNode(CollectionNode):\n    id = 'mapping'\n\n",
  "context_lines": "        self.flow_style = flow_style\n\nclass SequenceNode(CollectionNode):\n    id = 'sequence'\n\nclass MappingNode(CollectionNode):\n    id = 'mapping'\n",
  "slicing": "    id = 'mapping'\n"
 },
 "64": {
  "name": "id",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/yaml3/tokens.py",
  "lineno": "18",
  "column": "4",
  "context": "te order mark>'\n\nclass DirectiveToken(Token):\n    id = '<directive>'\n    def __init__(self, name, value, start_mark, en",
  "context_lines": "        return '%s(%s)' % (self.__class__.__name__, arguments)\n\n#class BOMToken(Token):\n#    id = '<byte order mark>'\n\nclass DirectiveToken(Token):\n    id = '<directive>'\n    def __init__(self, name, value, start_mark, end_mark):\n        self.name = name\n        self.value = value\n        self.start_mark = start_mark\n",
  "slicing": "    id = '<directive>'\n"
 },
 "65": {
  "name": "id",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/yaml3/tokens.py",
  "lineno": "26",
  "column": "4",
  "context": " = end_mark\n\nclass DocumentStartToken(Token):\n    id = '<document start>'\n\nclass DocumentEndToken(Token):\n    id = '<documen",
  "context_lines": "        self.value = value\n        self.start_mark = start_mark\n        self.end_mark = end_mark\n\nclass DocumentStartToken(Token):\n    id = '<document start>'\n\nclass DocumentEndToken(Token):\n    id = '<document end>'\n\nclass StreamStartToken(Token):\n",
  "slicing": "    id = '<document start>'\n"
 },
 "66": {
  "name": "id",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/yaml3/tokens.py",
  "lineno": "29",
  "column": "4",
  "context": "ument start>'\n\nclass DocumentEndToken(Token):\n    id = '<document end>'\n\nclass StreamStartToken(Token):\n    id = '<stream ",
  "context_lines": "        self.end_mark = end_mark\n\nclass DocumentStartToken(Token):\n    id = '<document start>'\n\nclass DocumentEndToken(Token):\n    id = '<document end>'\n\nclass StreamStartToken(Token):\n    id = '<stream start>'\n    def __init__(self, start_mark=None, end_mark=None,\n",
  "slicing": "    id = '<document end>'\n"
 },
 "67": {
  "name": "id",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/yaml3/tokens.py",
  "lineno": "32",
  "column": "4",
  "context": "ocument end>'\n\nclass StreamStartToken(Token):\n    id = '<stream start>'\n    def __init__(self, start_mark=None, end_mark=N",
  "context_lines": "    id = '<document start>'\n\nclass DocumentEndToken(Token):\n    id = '<document end>'\n\nclass StreamStartToken(Token):\n    id = '<stream start>'\n    def __init__(self, start_mark=None, end_mark=None,\n            encoding=None):\n        self.start_mark = start_mark\n        self.end_mark = end_mark\n",
  "slicing": "    id = '<stream start>'\n"
 },
 "68": {
  "name": "id",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/yaml3/tokens.py",
  "lineno": "40",
  "column": "4",
  "context": "ding = encoding\n\nclass StreamEndToken(Token):\n    id = '<stream end>'\n\nclass BlockSequenceStartToken(Token):\n    id = '<",
  "context_lines": "        self.start_mark = start_mark\n        self.end_mark = end_mark\n        self.encoding = encoding\n\nclass StreamEndToken(Token):\n    id = '<stream end>'\n\nclass BlockSequenceStartToken(Token):\n    id = '<block sequence start>'\n\nclass BlockMappingStartToken(Token):\n",
  "slicing": "    id = '<stream end>'\n"
 },
 "69": {
  "name": "id",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/yaml3/tokens.py",
  "lineno": "43",
  "column": "4",
  "context": " end>'\n\nclass BlockSequenceStartToken(Token):\n    id = '<block sequence start>'\n\nclass BlockMappingStartToken(Token):\n    id = '<b",
  "context_lines": "        self.encoding = encoding\n\nclass StreamEndToken(Token):\n    id = '<stream end>'\n\nclass BlockSequenceStartToken(Token):\n    id = '<block sequence start>'\n\nclass BlockMappingStartToken(Token):\n    id = '<block mapping start>'\n\nclass BlockEndToken(Token):\n",
  "slicing": "    id = '<block sequence start>'\n"
 },
 "70": {
  "name": "id",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/yaml3/tokens.py",
  "lineno": "46",
  "column": "4",
  "context": "start>'\n\nclass BlockMappingStartToken(Token):\n    id = '<block mapping start>'\n\nclass BlockEndToken(Token):\n    id = '<block end>",
  "context_lines": "    id = '<stream end>'\n\nclass BlockSequenceStartToken(Token):\n    id = '<block sequence start>'\n\nclass BlockMappingStartToken(Token):\n    id = '<block mapping start>'\n\nclass BlockEndToken(Token):\n    id = '<block end>'\n\nclass FlowSequenceStartToken(Token):\n",
  "slicing": "    id = '<block mapping start>'\n"
 },
 "71": {
  "name": "id",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/yaml3/tokens.py",
  "lineno": "49",
  "column": "4",
  "context": " mapping start>'\n\nclass BlockEndToken(Token):\n    id = '<block end>'\n\nclass FlowSequenceStartToken(Token):\n    id = '['",
  "context_lines": "    id = '<block sequence start>'\n\nclass BlockMappingStartToken(Token):\n    id = '<block mapping start>'\n\nclass BlockEndToken(Token):\n    id = '<block end>'\n\nclass FlowSequenceStartToken(Token):\n    id = '['\n\nclass FlowMappingStartToken(Token):\n",
  "slicing": "    id = '<block end>'\n"
 },
 "72": {
  "name": "id",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/yaml3/tokens.py",
  "lineno": "52",
  "column": "4",
  "context": "k end>'\n\nclass FlowSequenceStartToken(Token):\n    id = '['\n\nclass FlowMappingStartToken(Token):\n    id = '{'\n",
  "context_lines": "    id = '<block mapping start>'\n\nclass BlockEndToken(Token):\n    id = '<block end>'\n\nclass FlowSequenceStartToken(Token):\n    id = '['\n\nclass FlowMappingStartToken(Token):\n    id = '{'\n\nclass FlowSequenceEndToken(Token):\n",
  "slicing": "    id = '['\n"
 },
 "73": {
  "name": "id",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/yaml3/tokens.py",
  "lineno": "55",
  "column": "4",
  "context": "id = '['\n\nclass FlowMappingStartToken(Token):\n    id = '{'\n\nclass FlowSequenceEndToken(Token):\n    id = ']'\n\n",
  "context_lines": "    id = '<block end>'\n\nclass FlowSequenceStartToken(Token):\n    id = '['\n\nclass FlowMappingStartToken(Token):\n    id = '{'\n\nclass FlowSequenceEndToken(Token):\n    id = ']'\n\nclass FlowMappingEndToken(Token):\n",
  "slicing": "    id = '{'\n"
 },
 "74": {
  "name": "id",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/yaml3/tokens.py",
  "lineno": "58",
  "column": "4",
  "context": " id = '{'\n\nclass FlowSequenceEndToken(Token):\n    id = ']'\n\nclass FlowMappingEndToken(Token):\n    id = '}'\n\nc",
  "context_lines": "    id = '['\n\nclass FlowMappingStartToken(Token):\n    id = '{'\n\nclass FlowSequenceEndToken(Token):\n    id = ']'\n\nclass FlowMappingEndToken(Token):\n    id = '}'\n\nclass KeyToken(Token):\n",
  "slicing": "    id = ']'\n"
 },
 "75": {
  "name": "id",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/yaml3/tokens.py",
  "lineno": "61",
  "column": "4",
  "context": "  id = ']'\n\nclass FlowMappingEndToken(Token):\n    id = '}'\n\nclass KeyToken(Token):\n    id = '?'\n\nclass ValueT",
  "context_lines": "    id = '{'\n\nclass FlowSequenceEndToken(Token):\n    id = ']'\n\nclass FlowMappingEndToken(Token):\n    id = '}'\n\nclass KeyToken(Token):\n    id = '?'\n\nclass ValueToken(Token):\n",
  "slicing": "    id = '}'\n"
 },
 "76": {
  "name": "id",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/yaml3/tokens.py",
  "lineno": "64",
  "column": "4",
  "context": "(Token):\n    id = '}'\n\nclass KeyToken(Token):\n    id = '?'\n\nclass ValueToken(Token):\n    id = ':'\n\nclass Bloc",
  "context_lines": "    id = ']'\n\nclass FlowMappingEndToken(Token):\n    id = '}'\n\nclass KeyToken(Token):\n    id = '?'\n\nclass ValueToken(Token):\n    id = ':'\n\nclass BlockEntryToken(Token):\n",
  "slicing": "    id = '?'\n"
 },
 "77": {
  "name": "id",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/yaml3/tokens.py",
  "lineno": "67",
  "column": "4",
  "context": "oken):\n    id = '?'\n\nclass ValueToken(Token):\n    id = ':'\n\nclass BlockEntryToken(Token):\n    id = '-'\n\nclass",
  "context_lines": "    id = '}'\n\nclass KeyToken(Token):\n    id = '?'\n\nclass ValueToken(Token):\n    id = ':'\n\nclass BlockEntryToken(Token):\n    id = '-'\n\nclass FlowEntryToken(Token):\n",
  "slicing": "    id = ':'\n"
 },
 "78": {
  "name": "id",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/yaml3/tokens.py",
  "lineno": "70",
  "column": "4",
  "context": ":\n    id = ':'\n\nclass BlockEntryToken(Token):\n    id = '-'\n\nclass FlowEntryToken(Token):\n    id = ','\n\nclass ",
  "context_lines": "    id = '?'\n\nclass ValueToken(Token):\n    id = ':'\n\nclass BlockEntryToken(Token):\n    id = '-'\n\nclass FlowEntryToken(Token):\n    id = ','\n\nclass AliasToken(Token):\n",
  "slicing": "    id = '-'\n"
 },
 "79": {
  "name": "id",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/yaml3/tokens.py",
  "lineno": "73",
  "column": "4",
  "context": "):\n    id = '-'\n\nclass FlowEntryToken(Token):\n    id = ','\n\nclass AliasToken(Token):\n    id = '<alias>'\n    d",
  "context_lines": "    id = ':'\n\nclass BlockEntryToken(Token):\n    id = '-'\n\nclass FlowEntryToken(Token):\n    id = ','\n\nclass AliasToken(Token):\n    id = '<alias>'\n    def __init__(self, value, start_mark, end_mark):\n",
  "slicing": "    id = ','\n"
 },
 "80": {
  "name": "id",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/yaml3/tokens.py",
  "lineno": "76",
  "column": "4",
  "context": "oken):\n    id = ','\n\nclass AliasToken(Token):\n    id = '<alias>'\n    def __init__(self, value, start_mark, end_mark",
  "context_lines": "    id = '-'\n\nclass FlowEntryToken(Token):\n    id = ','\n\nclass AliasToken(Token):\n    id = '<alias>'\n    def __init__(self, value, start_mark, end_mark):\n        self.value = value\n        self.start_mark = start_mark\n        self.end_mark = end_mark\n\n",
  "slicing": "    id = '<alias>'\n"
 },
 "81": {
  "name": "id",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/yaml3/tokens.py",
  "lineno": "83",
  "column": "4",
  "context": "nd_mark = end_mark\n\nclass AnchorToken(Token):\n    id = '<anchor>'\n    def __init__(self, value, start_mark, end_mark",
  "context_lines": "        self.value = value\n        self.start_mark = start_mark\n        self.end_mark = end_mark\n\nclass AnchorToken(Token):\n    id = '<anchor>'\n    def __init__(self, value, start_mark, end_mark):\n        self.value = value\n        self.start_mark = start_mark\n        self.end_mark = end_mark\n\n",
  "slicing": "    id = '<anchor>'\n"
 },
 "82": {
  "name": "id",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/yaml3/tokens.py",
  "lineno": "90",
  "column": "4",
  "context": "f.end_mark = end_mark\n\nclass TagToken(Token):\n    id = '<tag>'\n    def __init__(self, value, start_mark, end_mark",
  "context_lines": "        self.value = value\n        self.start_mark = start_mark\n        self.end_mark = end_mark\n\nclass TagToken(Token):\n    id = '<tag>'\n    def __init__(self, value, start_mark, end_mark):\n        self.value = value\n        self.start_mark = start_mark\n        self.end_mark = end_mark\n\n",
  "slicing": "    id = '<tag>'\n"
 },
 "83": {
  "name": "id",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/yaml3/tokens.py",
  "lineno": "97",
  "column": "4",
  "context": "nd_mark = end_mark\n\nclass ScalarToken(Token):\n    id = '<scalar>'\n    def __init__(self, value, plain, start_mark, e",
  "context_lines": "        self.value = value\n        self.start_mark = start_mark\n        self.end_mark = end_mark\n\nclass ScalarToken(Token):\n    id = '<scalar>'\n    def __init__(self, value, plain, start_mark, end_mark, style=None):\n        self.value = value\n        self.plain = plain\n        self.start_mark = start_mark\n",
  "slicing": "    id = '<scalar>'\n"
 },
 "84": {
  "name": "NON_PRINTABLE",
  "type": "re",
  "class": "imported",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/yaml3/reader.py",
  "lineno": "137",
  "column": "4",
  "context": "lf.encoding = 'utf-8'\n        self.update(1)\n\n    NON_PRINTABLE = re.compile('[^\\x09\\x0A\\x0D\\x20-\\x7E\\x85\\xA0-\\uD7FF\\uE000-\\uFFFD]')\n    def check_printable(self, data):\n        match",
  "context_lines": "            else:\n                self.raw_decode = codecs.utf_8_decode\n                self.encoding = 'utf-8'\n        self.update(1)\n\n    NON_PRINTABLE = re.compile('[^\\x09\\x0A\\x0D\\x20-\\x7E\\x85\\xA0-\\uD7FF\\uE000-\\uFFFD]')\n    def check_printable(self, data):\n        match = self.NON_PRINTABLE.search(data)\n        if match:\n            character = match.group()\n",
  "slicing": [
   "            ch = self.buffer[self.pointer]\n",
   "            if ch in '\\n\\x85\\u2028\\u2029'  \\\n",
   "                    or (ch == '\\r' and self.buffer[self.pointer] != '\\n'):\n",
   "            elif ch != '\\uFEFF':\n",
   "            length -= 1\n",
   "    NON_PRINTABLE = re.compile('[^\\x09\\x0A\\x0D\\x20-\\x7E\\x85\\xA0-\\uD7FF\\uE000-\\uFFFD]')\n",
   "        while len(self.buffer) < length:\n"
  ]
 },
 "85": {
  "name": "inf_value",
  "type": "float",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/yaml3/constructor.py",
  "lineno": "251",
  "column": "4",
  "context": "    else:\n            return sign*int(value)\n\n    inf_value = 1e300\n    while inf_value != inf_value*inf_value:\n      ",
  "context_lines": "                base *= 60\n            return sign*value\n        else:\n            return sign*int(value)\n\n    inf_value = 1e300\n    while inf_value != inf_value*inf_value:\n        inf_value *= inf_value\n    nan_value = -inf_value/inf_value   # Trying to make a quiet NaN (like C99).\n\n    def construct_yaml_float(self, node):\n",
  "slicing": [
   "        node = self.get_single_node()\n",
   "        if node is not None:\n",
   "            return self.construct_document(node)\n",
   "        data = self.construct_object(node)\n",
   "            state_generators = self.state_generators\n",
   "            for generator in state_generators:\n",
   "                for dummy in generator:\n",
   "        return data\n",
   "        if node in self.constructed_objects:\n",
   "            return self.constructed_objects[node]\n",
   "            old_deep = self.deep_construct\n",
   "        if node in self.recursive_objects:\n",
   "                    \"found unconstructable recursive node\", node.start_mark)\n",
   "        self.recursive_objects[node] = None\n",
   "        constructor = None\n",
   "        tag_suffix = None\n",
   "        if node.tag in self.yaml_constructors:\n",
   "            constructor = self.yaml_constructors[node.tag]\n",
   "            for tag_prefix in self.yaml_multi_constructors:\n",
   "                if node.tag.startswith(tag_prefix):\n",
   "                    tag_suffix = node.tag[len(tag_prefix):]\n",
   "                    constructor = self.yaml_multi_constructors[tag_prefix]\n",
   "                    tag_suffix = node.tag\n",
   "                    constructor = self.yaml_multi_constructors[None]\n",
   "                    constructor = self.yaml_constructors[None]\n",
   "                elif isinstance(node, ScalarNode):\n",
   "                    constructor = self.__class__.construct_scalar\n",
   "                elif isinstance(node, SequenceNode):\n",
   "                    constructor = self.__class__.construct_sequence\n",
   "                elif isinstance(node, MappingNode):\n",
   "                    constructor = self.__class__.construct_mapping\n",
   "        if tag_suffix is None:\n",
   "            data = constructor(self, node)\n",
   "            data = constructor(self, tag_suffix, node)\n",
   "        if isinstance(data, types.GeneratorType):\n",
   "            generator = data\n",
   "            data = next(generator)\n",
   "                for dummy in generator:\n",
   "                self.state_generators.append(generator)\n",
   "        self.constructed_objects[node] = data\n",
   "        del self.recursive_objects[node]\n",
   "            self.deep_construct = old_deep\n",
   "        return data\n",
   "        if not isinstance(node, ScalarNode):\n",
   "                    \"expected a scalar node, but found %s\" % node.id,\n",
   "                    node.start_mark)\n",
   "        return node.value\n",
   "        if not isinstance(node, SequenceNode):\n",
   "                    \"expected a sequence node, but found %s\" % node.id,\n",
   "                    node.start_mark)\n",
   "                for child in node.value]\n",
   "        if not isinstance(node, MappingNode):\n",
   "                    \"expected a mapping node, but found %s\" % node.id,\n",
   "                    node.start_mark)\n",
   "        mapping = {}\n",
   "        for key_node, value_node in node.value:\n",
   "            key = self.construct_object(key_node, deep=deep)\n",
   "            if not isinstance(key, collections.Hashable):\n",
   "                raise ConstructorError(\"while constructing a mapping\", node.start_mark,\n",
   "                        \"found unhashable key\", key_node.start_mark)\n",
   "            value = self.construct_object(value_node, deep=deep)\n",
   "            mapping[key] = value\n",
   "        return mapping\n",
   "        if not isinstance(node, MappingNode):\n",
   "                    \"expected a mapping node, but found %s\" % node.id,\n",
   "                    node.start_mark)\n",
   "        pairs = []\n",
   "        for key_node, value_node in node.value:\n",
   "            key = self.construct_object(key_node, deep=deep)\n",
   "            value = self.construct_object(value_node, deep=deep)\n",
   "            pairs.append((key, value))\n",
   "        return pairs\n",
   "        cls.yaml_constructors[tag] = constructor\n",
   "        cls.yaml_multi_constructors[tag_prefix] = multi_constructor\n",
   "        if isinstance(node, MappingNode):\n",
   "            for key_node, value_node in node.value:\n",
   "                if key_node.tag == 'tag:yaml.org,2002:value':\n",
   "                    return self.construct_scalar(value_node)\n",
   "        return super().construct_scalar(node)\n",
   "        merge = []\n",
   "        index = 0\n",
   "        while index < len(node.value):\n",
   "            key_node, value_node = node.value[index]\n",
   "            if key_node.tag == 'tag:yaml.org,2002:merge':\n",
   "                del node.value[index]\n",
   "                if isinstance(value_node, MappingNode):\n",
   "                    self.flatten_mapping(value_node)\n",
   "                    merge.extend(value_node.value)\n",
   "                elif isinstance(value_node, SequenceNode):\n",
   "                    submerge = []\n",
   "                    for subnode in value_node.value:\n",
   "                        if not isinstance(subnode, MappingNode):\n",
   "                                    node.start_mark,\n",
   "                                    % subnode.id, subnode.start_mark)\n",
   "                        self.flatten_mapping(subnode)\n",
   "                        submerge.append(subnode.value)\n",
   "                    submerge.reverse()\n",
   "                    for value in submerge:\n",
   "                        merge.extend(value)\n",
   "                    raise ConstructorError(\"while constructing a mapping\", node.start_mark,\n",
   "                            % value_node.id, value_node.start_mark)\n",
   "            elif key_node.tag == 'tag:yaml.org,2002:value':\n",
   "                key_node.tag = 'tag:yaml.org,2002:str'\n",
   "                index += 1\n",
   "                index += 1\n",
   "        if merge:\n",
   "            node.value = merge + node.value\n",
   "        if isinstance(node, MappingNode):\n",
   "            self.flatten_mapping(node)\n",
   "        return super().construct_mapping(node, deep=deep)\n",
   "        self.construct_scalar(node)\n",
   "        value = self.construct_scalar(node)\n",
   "        return self.bool_values[value.lower()]\n",
   "        value = self.construct_scalar(node)\n",
   "        value = value.replace('_', '')\n",
   "        sign = +1\n",
   "        if value[0] == '-':\n",
   "            sign = -1\n",
   "        if value[0] in '+-':\n",
   "            value = value[1:]\n",
   "        if value == '0':\n",
   "        elif value.startswith('0b'):\n",
   "            return sign*int(value[2:], 2)\n",
   "        elif value.startswith('0x'):\n",
   "            return sign*int(value[2:], 16)\n",
   "        elif value[0] == '0':\n",
   "            return sign*int(value, 8)\n",
   "        elif ':' in value:\n",
   "            digits = [int(part) for part in value.split(':')]\n",
   "            digits.reverse()\n",
   "            base = 1\n",
   "            value = 0\n",
   "            for digit in digits:\n",
   "                value += digit*base\n",
   "                base *= 60\n",
   "            return sign*value\n",
   "            return sign*int(value)\n",
   "    inf_value = 1e300\n",
   "    while inf_value != inf_value*inf_value:\n",
   "        inf_value *= inf_value\n",
   "    nan_value = -inf_value/inf_value   # Trying to make a quiet NaN (like C99).\n",
   "        value = self.construct_scalar(node)\n",
   "        value = value.replace('_', '').lower()\n",
   "        sign = +1\n",
   "        if value[0] == '-':\n",
   "            sign = -1\n",
   "        if value[0] in '+-':\n",
   "            value = value[1:]\n",
   "        if value == '.inf':\n",
   "            return sign*self.inf_value\n",
   "        elif value == '.nan':\n",
   "        elif ':' in value:\n",
   "            digits = [float(part) for part in value.split(':')]\n",
   "            digits.reverse()\n",
   "            base = 1\n",
   "            value = 0.0\n",
   "            for digit in digits:\n",
   "                value += digit*base\n",
   "                base *= 60\n",
   "            return sign*value\n",
   "            return sign*float(value)\n",
   "            value = self.construct_scalar(node).encode('ascii')\n",
   "                    node.start_mark)\n",
   "                return base64.decodebytes(value)\n",
   "                return base64.decodestring(value)\n",
   "                    \"failed to decode base64 data: %s\" % exc, node.start_mark)\n",
   "        value = self.construct_scalar(node)\n",
   "        match = self.timestamp_regexp.match(node.value)\n",
   "        values = match.groupdict()\n",
   "        year = int(values['year'])\n",
   "        month = int(values['month'])\n",
   "        day = int(values['day'])\n",
   "        if not values['hour']:\n",
   "            return datetime.date(year, month, day)\n",
   "        hour = int(values['hour'])\n",
   "        minute = int(values['minute'])\n",
   "        second = int(values['second'])\n",
   "        fraction = 0\n",
   "        if values['fraction']:\n",
   "            fraction = values['fraction'][:6]\n",
   "            while len(fraction) < 6:\n",
   "                fraction += '0'\n",
   "            fraction = int(fraction)\n",
   "        delta = None\n",
   "        if values['tz_sign']:\n",
   "            tz_hour = int(values['tz_hour'])\n",
   "            tz_minute = int(values['tz_minute'] or 0)\n",
   "            delta = datetime.timedelta(hours=tz_hour, minutes=tz_minute)\n",
   "            if values['tz_sign'] == '-':\n",
   "                delta = -delta\n",
   "        data = datetime.datetime(year, month, day, hour, minute, second, fraction)\n",
   "        if delta:\n",
   "            data -= delta\n",
   "        return data\n",
   "        omap = []\n",
   "        yield omap\n",
   "        if not isinstance(node, SequenceNode):\n",
   "            raise ConstructorError(\"while constructing an ordered map\", node.start_mark,\n",
   "                    \"expected a sequence, but found %s\" % node.id, node.start_mark)\n",
   "        for subnode in node.value:\n",
   "            if not isinstance(subnode, MappingNode):\n",
   "                raise ConstructorError(\"while constructing an ordered map\", node.start_mark,\n",
   "                        \"expected a mapping of length 1, but found %s\" % subnode.id,\n",
   "                        subnode.start_mark)\n",
   "            if len(subnode.value) != 1:\n",
   "                raise ConstructorError(\"while constructing an ordered map\", node.start_mark,\n",
   "                        \"expected a single mapping item, but found %d items\" % len(subnode.value),\n",
   "                        subnode.start_mark)\n",
   "            key_node, value_node = subnode.value[0]\n",
   "            key = self.construct_object(key_node)\n",
   "            value = self.construct_object(value_node)\n",
   "            omap.append((key, value))\n",
   "        pairs = []\n",
   "        yield pairs\n",
   "        if not isinstance(node, SequenceNode):\n",
   "            raise ConstructorError(\"while constructing pairs\", node.start_mark,\n",
   "                    \"expected a sequence, but found %s\" % node.id, node.start_mark)\n",
   "        for subnode in node.value:\n",
   "            if not isinstance(subnode, MappingNode):\n",
   "                raise ConstructorError(\"while constructing pairs\", node.start_mark,\n",
   "                        \"expected a mapping of length 1, but found %s\" % subnode.id,\n",
   "                        subnode.start_mark)\n",
   "            if len(subnode.value) != 1:\n",
   "                raise ConstructorError(\"while constructing pairs\", node.start_mark,\n",
   "                        \"expected a single mapping item, but found %d items\" % len(subnode.value),\n",
   "                        subnode.start_mark)\n",
   "            key_node, value_node = subnode.value[0]\n",
   "            key = self.construct_object(key_node)\n",
   "            value = self.construct_object(value_node)\n",
   "            pairs.append((key, value))\n",
   "        data = set()\n",
   "        yield data\n",
   "        value = self.construct_mapping(node)\n",
   "        data.update(value)\n",
   "        return self.construct_scalar(node)\n",
   "        data = []\n",
   "        yield data\n",
   "        data.extend(self.construct_sequence(node))\n",
   "        data = {}\n",
   "        yield data\n",
   "        value = self.construct_mapping(node)\n",
   "        data.update(value)\n",
   "        data = cls.__new__(cls)\n",
   "        yield data\n",
   "        if hasattr(data, '__setstate__'):\n",
   "            state = self.construct_mapping(node, deep=True)\n",
   "            data.__setstate__(state)\n",
   "            state = self.construct_mapping(node)\n",
   "            data.__dict__.update(state)\n",
   "                \"could not determine a constructor for the tag %r\" % node.tag,\n",
   "                node.start_mark)\n",
   "        return self.construct_scalar(node)\n",
   "        return self.construct_scalar(node)\n",
   "            value = self.construct_scalar(node).encode('ascii')\n",
   "                    node.start_mark)\n",
   "                return base64.decodebytes(value)\n",
   "                return base64.decodestring(value)\n",
   "                    \"failed to decode base64 data: %s\" % exc, node.start_mark)\n",
   "        return self.construct_yaml_int(node)\n",
   "       return complex(self.construct_scalar(node))\n",
   "        return tuple(self.construct_sequence(node))\n",
   "            module_name, object_name = name.rsplit('.', 1)\n",
   "            module_name = 'builtins'\n",
   "            object_name = name\n",
   "            __import__(module_name)\n",
   "                    \"cannot find module %r (%s)\" % (module_name, exc), mark)\n",
   "        module = sys.modules[module_name]\n",
   "        if not hasattr(module, object_name):\n",
   "                    % (object_name, module.__name__), mark)\n",
   "        return getattr(module, object_name)\n",
   "        value = self.construct_scalar(node)\n",
   "        if value:\n",
   "            raise ConstructorError(\"while constructing a Python name\", node.start_mark,\n",
   "                    \"expected the empty value, but found %r\" % value, node.start_mark)\n",
   "        return self.find_python_name(suffix, node.start_mark)\n",
   "        value = self.construct_scalar(node)\n",
   "        if value:\n",
   "            raise ConstructorError(\"while constructing a Python module\", node.start_mark,\n",
   "                    \"expected the empty value, but found %r\" % value, node.start_mark)\n",
   "        return self.find_python_module(suffix, node.start_mark)\n",
   "            args = []\n",
   "            kwds = {}\n",
   "        cls = self.find_python_name(suffix, node.start_mark)\n",
   "        if newobj and isinstance(cls, type):\n",
   "            return cls.__new__(cls, *args, **kwds)\n",
   "            return cls(*args, **kwds)\n",
   "            instance.__setstate__(state)\n",
   "            slotstate = {}\n",
   "            if isinstance(state, tuple) and len(state) == 2:\n",
   "                state, slotstate = state\n",
   "                instance.__dict__.update(state)\n",
   "            elif state:\n",
   "                slotstate.update(state)\n",
   "            for key, value in slotstate.items():\n",
   "                setattr(object, key, value)\n",
   "        instance = self.make_python_instance(suffix, node, newobj=True)\n",
   "        yield instance\n",
   "        deep = hasattr(instance, '__setstate__')\n",
   "        state = self.construct_mapping(node, deep=deep)\n",
   "        self.set_python_instance_state(instance, state)\n",
   "        if isinstance(node, SequenceNode):\n",
   "            args = self.construct_sequence(node, deep=True)\n",
   "            kwds = {}\n",
   "            state = {}\n",
   "            value = self.construct_mapping(node, deep=True)\n",
   "            args = value.get('args', [])\n",
   "            kwds = value.get('kwds', {})\n",
   "            state = value.get('state', {})\n",
   "            listitems = value.get('listitems', [])\n",
   "            dictitems = value.get('dictitems', {})\n",
   "        instance = self.make_python_instance(suffix, node, args, kwds, newobj)\n",
   "        if state:\n",
   "            self.set_python_instance_state(instance, state)\n",
   "        if listitems:\n",
   "            instance.extend(listitems)\n",
   "        if dictitems:\n",
   "            for key in dictitems:\n",
   "                instance[key] = dictitems[key]\n",
   "        return instance\n",
   "        return self.construct_python_object_apply(suffix, node, newobj=True)\n"
  ]
 },
 "86": {
  "name": "inf_value",
  "type": "float",
  "class": "build-in",
  "approach": "annotation",
  "file_path": "invoke/invoke/vendor/yaml3/constructor.py",
  "lineno": "253",
  "column": "8",
  "context": "  while inf_value != inf_value*inf_value:\n        inf_value *= inf_value\n    nan_value = -inf_value/inf_value   # Trying to",
  "context_lines": "        else:\n            return sign*int(value)\n\n    inf_value = 1e300\n    while inf_value != inf_value*inf_value:\n        inf_value *= inf_value\n    nan_value = -inf_value/inf_value   # Trying to make a quiet NaN (like C99).\n\n    def construct_yaml_float(self, node):\n        value = self.construct_scalar(node)\n        value = value.replace('_', '').lower()\n",
  "slicing": [
   "        node = self.get_single_node()\n",
   "        if node is not None:\n",
   "            return self.construct_document(node)\n",
   "        data = self.construct_object(node)\n",
   "            state_generators = self.state_generators\n",
   "            for generator in state_generators:\n",
   "                for dummy in generator:\n",
   "        return data\n",
   "        if node in self.constructed_objects:\n",
   "            return self.constructed_objects[node]\n",
   "            old_deep = self.deep_construct\n",
   "        if node in self.recursive_objects:\n",
   "                    \"found unconstructable recursive node\", node.start_mark)\n",
   "        self.recursive_objects[node] = None\n",
   "        constructor = None\n",
   "        tag_suffix = None\n",
   "        if node.tag in self.yaml_constructors:\n",
   "            constructor = self.yaml_constructors[node.tag]\n",
   "            for tag_prefix in self.yaml_multi_constructors:\n",
   "                if node.tag.startswith(tag_prefix):\n",
   "                    tag_suffix = node.tag[len(tag_prefix):]\n",
   "                    constructor = self.yaml_multi_constructors[tag_prefix]\n",
   "                    tag_suffix = node.tag\n",
   "                    constructor = self.yaml_multi_constructors[None]\n",
   "                    constructor = self.yaml_constructors[None]\n",
   "                elif isinstance(node, ScalarNode):\n",
   "                    constructor = self.__class__.construct_scalar\n",
   "                elif isinstance(node, SequenceNode):\n",
   "                    constructor = self.__class__.construct_sequence\n",
   "                elif isinstance(node, MappingNode):\n",
   "                    constructor = self.__class__.construct_mapping\n",
   "        if tag_suffix is None:\n",
   "            data = constructor(self, node)\n",
   "            data = constructor(self, tag_suffix, node)\n",
   "        if isinstance(data, types.GeneratorType):\n",
   "            generator = data\n",
   "            data = next(generator)\n",
   "                for dummy in generator:\n",
   "                self.state_generators.append(generator)\n",
   "        self.constructed_objects[node] = data\n",
   "        del self.recursive_objects[node]\n",
   "            self.deep_construct = old_deep\n",
   "        return data\n",
   "        if not isinstance(node, ScalarNode):\n",
   "                    \"expected a scalar node, but found %s\" % node.id,\n",
   "                    node.start_mark)\n",
   "        return node.value\n",
   "        if not isinstance(node, SequenceNode):\n",
   "                    \"expected a sequence node, but found %s\" % node.id,\n",
   "                    node.start_mark)\n",
   "                for child in node.value]\n",
   "        if not isinstance(node, MappingNode):\n",
   "                    \"expected a mapping node, but found %s\" % node.id,\n",
   "                    node.start_mark)\n",
   "        mapping = {}\n",
   "        for key_node, value_node in node.value:\n",
   "            key = self.construct_object(key_node, deep=deep)\n",
   "            if not isinstance(key, collections.Hashable):\n",
   "                raise ConstructorError(\"while constructing a mapping\", node.start_mark,\n",
   "                        \"found unhashable key\", key_node.start_mark)\n",
   "            value = self.construct_object(value_node, deep=deep)\n",
   "            mapping[key] = value\n",
   "        return mapping\n",
   "        if not isinstance(node, MappingNode):\n",
   "                    \"expected a mapping node, but found %s\" % node.id,\n",
   "                    node.start_mark)\n",
   "        pairs = []\n",
   "        for key_node, value_node in node.value:\n",
   "            key = self.construct_object(key_node, deep=deep)\n",
   "            value = self.construct_object(value_node, deep=deep)\n",
   "            pairs.append((key, value))\n",
   "        return pairs\n",
   "        cls.yaml_constructors[tag] = constructor\n",
   "        cls.yaml_multi_constructors[tag_prefix] = multi_constructor\n",
   "        if isinstance(node, MappingNode):\n",
   "            for key_node, value_node in node.value:\n",
   "                if key_node.tag == 'tag:yaml.org,2002:value':\n",
   "                    return self.construct_scalar(value_node)\n",
   "        return super().construct_scalar(node)\n",
   "        merge = []\n",
   "        index = 0\n",
   "        while index < len(node.value):\n",
   "            key_node, value_node = node.value[index]\n",
   "            if key_node.tag == 'tag:yaml.org,2002:merge':\n",
   "                del node.value[index]\n",
   "                if isinstance(value_node, MappingNode):\n",
   "                    self.flatten_mapping(value_node)\n",
   "                    merge.extend(value_node.value)\n",
   "                elif isinstance(value_node, SequenceNode):\n",
   "                    submerge = []\n",
   "                    for subnode in value_node.value:\n",
   "                        if not isinstance(subnode, MappingNode):\n",
   "                                    node.start_mark,\n",
   "                                    % subnode.id, subnode.start_mark)\n",
   "                        self.flatten_mapping(subnode)\n",
   "                        submerge.append(subnode.value)\n",
   "                    submerge.reverse()\n",
   "                    for value in submerge:\n",
   "                        merge.extend(value)\n",
   "                    raise ConstructorError(\"while constructing a mapping\", node.start_mark,\n",
   "                            % value_node.id, value_node.start_mark)\n",
   "            elif key_node.tag == 'tag:yaml.org,2002:value':\n",
   "                key_node.tag = 'tag:yaml.org,2002:str'\n",
   "                index += 1\n",
   "                index += 1\n",
   "        if merge:\n",
   "            node.value = merge + node.value\n",
   "        if isinstance(node, MappingNode):\n",
   "            self.flatten_mapping(node)\n",
   "        return super().construct_mapping(node, deep=deep)\n",
   "        self.construct_scalar(node)\n",
   "        value = self.construct_scalar(node)\n",
   "        return self.bool_values[value.lower()]\n",
   "        value = self.construct_scalar(node)\n",
   "        value = value.replace('_', '')\n",
   "        sign = +1\n",
   "        if value[0] == '-':\n",
   "            sign = -1\n",
   "        if value[0] in '+-':\n",
   "            value = value[1:]\n",
   "        if value == '0':\n",
   "        elif value.startswith('0b'):\n",
   "            return sign*int(value[2:], 2)\n",
   "        elif value.startswith('0x'):\n",
   "            return sign*int(value[2:], 16)\n",
   "        elif value[0] == '0':\n",
   "            return sign*int(value, 8)\n",
   "        elif ':' in value:\n",
   "            digits = [int(part) for part in value.split(':')]\n",
   "            digits.reverse()\n",
   "            base = 1\n",
   "            value = 0\n",
   "            for digit in digits:\n",
   "                value += digit*base\n",
   "                base *= 60\n",
   "            return sign*value\n",
   "            return sign*int(value)\n",
   "    inf_value = 1e300\n",
   "    while inf_value != inf_value*inf_value:\n",
   "        inf_value *= inf_value\n",
   "    nan_value = -inf_value/inf_value   # Trying to make a quiet NaN (like C99).\n",
   "        value = self.construct_scalar(node)\n",
   "        value = value.replace('_', '').lower()\n",
   "        sign = +1\n",
   "        if value[0] == '-':\n",
   "            sign = -1\n",
   "        if value[0] in '+-':\n",
   "            value = value[1:]\n",
   "        if value == '.inf':\n",
   "            return sign*self.inf_value\n",
   "        elif value == '.nan':\n",
   "        elif ':' in value:\n",
   "            digits = [float(part) for part in value.split(':')]\n",
   "            digits.reverse()\n",
   "            base = 1\n",
   "            value = 0.0\n",
   "            for digit in digits:\n",
   "                value += digit*base\n",
   "                base *= 60\n",
   "            return sign*value\n",
   "            return sign*float(value)\n",
   "            value = self.construct_scalar(node).encode('ascii')\n",
   "                    node.start_mark)\n",
   "                return base64.decodebytes(value)\n",
   "                return base64.decodestring(value)\n",
   "                    \"failed to decode base64 data: %s\" % exc, node.start_mark)\n",
   "        value = self.construct_scalar(node)\n",
   "        match = self.timestamp_regexp.match(node.value)\n",
   "        values = match.groupdict()\n",
   "        year = int(values['year'])\n",
   "        month = int(values['month'])\n",
   "        day = int(values['day'])\n",
   "        if not values['hour']:\n",
   "            return datetime.date(year, month, day)\n",
   "        hour = int(values['hour'])\n",
   "        minute = int(values['minute'])\n",
   "        second = int(values['second'])\n",
   "        fraction = 0\n",
   "        if values['fraction']:\n",
   "            fraction = values['fraction'][:6]\n",
   "            while len(fraction) < 6:\n",
   "                fraction += '0'\n",
   "            fraction = int(fraction)\n",
   "        delta = None\n",
   "        if values['tz_sign']:\n",
   "            tz_hour = int(values['tz_hour'])\n",
   "            tz_minute = int(values['tz_minute'] or 0)\n",
   "            delta = datetime.timedelta(hours=tz_hour, minutes=tz_minute)\n",
   "            if values['tz_sign'] == '-':\n",
   "                delta = -delta\n",
   "        data = datetime.datetime(year, month, day, hour, minute, second, fraction)\n",
   "        if delta:\n",
   "            data -= delta\n",
   "        return data\n",
   "        omap = []\n",
   "        yield omap\n",
   "        if not isinstance(node, SequenceNode):\n",
   "            raise ConstructorError(\"while constructing an ordered map\", node.start_mark,\n",
   "                    \"expected a sequence, but found %s\" % node.id, node.start_mark)\n",
   "        for subnode in node.value:\n",
   "            if not isinstance(subnode, MappingNode):\n",
   "                raise ConstructorError(\"while constructing an ordered map\", node.start_mark,\n",
   "                        \"expected a mapping of length 1, but found %s\" % subnode.id,\n",
   "                        subnode.start_mark)\n",
   "            if len(subnode.value) != 1:\n",
   "                raise ConstructorError(\"while constructing an ordered map\", node.start_mark,\n",
   "                        \"expected a single mapping item, but found %d items\" % len(subnode.value),\n",
   "                        subnode.start_mark)\n",
   "            key_node, value_node = subnode.value[0]\n",
   "            key = self.construct_object(key_node)\n",
   "            value = self.construct_object(value_node)\n",
   "            omap.append((key, value))\n",
   "        pairs = []\n",
   "        yield pairs\n",
   "        if not isinstance(node, SequenceNode):\n",
   "            raise ConstructorError(\"while constructing pairs\", node.start_mark,\n",
   "                    \"expected a sequence, but found %s\" % node.id, node.start_mark)\n",
   "        for subnode in node.value:\n",
   "            if not isinstance(subnode, MappingNode):\n",
   "                raise ConstructorError(\"while constructing pairs\", node.start_mark,\n",
   "                        \"expected a mapping of length 1, but found %s\" % subnode.id,\n",
   "                        subnode.start_mark)\n",
   "            if len(subnode.value) != 1:\n",
   "                raise ConstructorError(\"while constructing pairs\", node.start_mark,\n",
   "                        \"expected a single mapping item, but found %d items\" % len(subnode.value),\n",
   "                        subnode.start_mark)\n",
   "            key_node, value_node = subnode.value[0]\n",
   "            key = self.construct_object(key_node)\n",
   "            value = self.construct_object(value_node)\n",
   "            pairs.append((key, value))\n",
   "        data = set()\n",
   "        yield data\n",
   "        value = self.construct_mapping(node)\n",
   "        data.update(value)\n",
   "        return self.construct_scalar(node)\n",
   "        data = []\n",
   "        yield data\n",
   "        data.extend(self.construct_sequence(node))\n",
   "        data = {}\n",
   "        yield data\n",
   "        value = self.construct_mapping(node)\n",
   "        data.update(value)\n",
   "        data = cls.__new__(cls)\n",
   "        yield data\n",
   "        if hasattr(data, '__setstate__'):\n",
   "            state = self.construct_mapping(node, deep=True)\n",
   "            data.__setstate__(state)\n",
   "            state = self.construct_mapping(node)\n",
   "            data.__dict__.update(state)\n",
   "                \"could not determine a constructor for the tag %r\" % node.tag,\n",
   "                node.start_mark)\n",
   "        return self.construct_scalar(node)\n",
   "        return self.construct_scalar(node)\n",
   "            value = self.construct_scalar(node).encode('ascii')\n",
   "                    node.start_mark)\n",
   "                return base64.decodebytes(value)\n",
   "                return base64.decodestring(value)\n",
   "                    \"failed to decode base64 data: %s\" % exc, node.start_mark)\n",
   "        return self.construct_yaml_int(node)\n",
   "       return complex(self.construct_scalar(node))\n",
   "        return tuple(self.construct_sequence(node))\n",
   "            module_name, object_name = name.rsplit('.', 1)\n",
   "            module_name = 'builtins'\n",
   "            object_name = name\n",
   "            __import__(module_name)\n",
   "                    \"cannot find module %r (%s)\" % (module_name, exc), mark)\n",
   "        module = sys.modules[module_name]\n",
   "        if not hasattr(module, object_name):\n",
   "                    % (object_name, module.__name__), mark)\n",
   "        return getattr(module, object_name)\n",
   "        value = self.construct_scalar(node)\n",
   "        if value:\n",
   "            raise ConstructorError(\"while constructing a Python name\", node.start_mark,\n",
   "                    \"expected the empty value, but found %r\" % value, node.start_mark)\n",
   "        return self.find_python_name(suffix, node.start_mark)\n",
   "        value = self.construct_scalar(node)\n",
   "        if value:\n",
   "            raise ConstructorError(\"while constructing a Python module\", node.start_mark,\n",
   "                    \"expected the empty value, but found %r\" % value, node.start_mark)\n",
   "        return self.find_python_module(suffix, node.start_mark)\n",
   "            args = []\n",
   "            kwds = {}\n",
   "        cls = self.find_python_name(suffix, node.start_mark)\n",
   "        if newobj and isinstance(cls, type):\n",
   "            return cls.__new__(cls, *args, **kwds)\n",
   "            return cls(*args, **kwds)\n",
   "            instance.__setstate__(state)\n",
   "            slotstate = {}\n",
   "            if isinstance(state, tuple) and len(state) == 2:\n",
   "                state, slotstate = state\n",
   "                instance.__dict__.update(state)\n",
   "            elif state:\n",
   "                slotstate.update(state)\n",
   "            for key, value in slotstate.items():\n",
   "                setattr(object, key, value)\n",
   "        instance = self.make_python_instance(suffix, node, newobj=True)\n",
   "        yield instance\n",
   "        deep = hasattr(instance, '__setstate__')\n",
   "        state = self.construct_mapping(node, deep=deep)\n",
   "        self.set_python_instance_state(instance, state)\n",
   "        if isinstance(node, SequenceNode):\n",
   "            args = self.construct_sequence(node, deep=True)\n",
   "            kwds = {}\n",
   "            state = {}\n",
   "            value = self.construct_mapping(node, deep=True)\n",
   "            args = value.get('args', [])\n",
   "            kwds = value.get('kwds', {})\n",
   "            state = value.get('state', {})\n",
   "            listitems = value.get('listitems', [])\n",
   "            dictitems = value.get('dictitems', {})\n",
   "        instance = self.make_python_instance(suffix, node, args, kwds, newobj)\n",
   "        if state:\n",
   "            self.set_python_instance_state(instance, state)\n",
   "        if listitems:\n",
   "            instance.extend(listitems)\n",
   "        if dictitems:\n",
   "            for key in dictitems:\n",
   "                instance[key] = dictitems[key]\n",
   "        return instance\n",
   "        return self.construct_python_object_apply(suffix, node, newobj=True)\n"
  ]
 },
 "87": {
  "name": "nan_value",
  "type": "float",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/yaml3/constructor.py",
  "lineno": "254",
  "column": "4",
  "context": "lue*inf_value:\n        inf_value *= inf_value\n    nan_value = -inf_value/inf_value   # Trying to make a quiet NaN (like C99).\n\n    def construct_yaml_float(self, node):\n       ",
  "context_lines": "            return sign*int(value)\n\n    inf_value = 1e300\n    while inf_value != inf_value*inf_value:\n        inf_value *= inf_value\n    nan_value = -inf_value/inf_value   # Trying to make a quiet NaN (like C99).\n\n    def construct_yaml_float(self, node):\n        value = self.construct_scalar(node)\n        value = value.replace('_', '').lower()\n",
  "slicing": [
   "        node = self.get_single_node()\n",
   "        if node is not None:\n",
   "            return self.construct_document(node)\n",
   "        data = self.construct_object(node)\n",
   "            state_generators = self.state_generators\n",
   "            for generator in state_generators:\n",
   "                for dummy in generator:\n",
   "        return data\n",
   "        if node in self.constructed_objects:\n",
   "            return self.constructed_objects[node]\n",
   "            old_deep = self.deep_construct\n",
   "        if node in self.recursive_objects:\n",
   "                    \"found unconstructable recursive node\", node.start_mark)\n",
   "        self.recursive_objects[node] = None\n",
   "        constructor = None\n",
   "        tag_suffix = None\n",
   "        if node.tag in self.yaml_constructors:\n",
   "            constructor = self.yaml_constructors[node.tag]\n",
   "            for tag_prefix in self.yaml_multi_constructors:\n",
   "                if node.tag.startswith(tag_prefix):\n",
   "                    tag_suffix = node.tag[len(tag_prefix):]\n",
   "                    constructor = self.yaml_multi_constructors[tag_prefix]\n",
   "                    tag_suffix = node.tag\n",
   "                    constructor = self.yaml_multi_constructors[None]\n",
   "                    constructor = self.yaml_constructors[None]\n",
   "                elif isinstance(node, ScalarNode):\n",
   "                    constructor = self.__class__.construct_scalar\n",
   "                elif isinstance(node, SequenceNode):\n",
   "                    constructor = self.__class__.construct_sequence\n",
   "                elif isinstance(node, MappingNode):\n",
   "                    constructor = self.__class__.construct_mapping\n",
   "        if tag_suffix is None:\n",
   "            data = constructor(self, node)\n",
   "            data = constructor(self, tag_suffix, node)\n",
   "        if isinstance(data, types.GeneratorType):\n",
   "            generator = data\n",
   "            data = next(generator)\n",
   "                for dummy in generator:\n",
   "                self.state_generators.append(generator)\n",
   "        self.constructed_objects[node] = data\n",
   "        del self.recursive_objects[node]\n",
   "            self.deep_construct = old_deep\n",
   "        return data\n",
   "        if not isinstance(node, ScalarNode):\n",
   "                    \"expected a scalar node, but found %s\" % node.id,\n",
   "                    node.start_mark)\n",
   "        return node.value\n",
   "        if not isinstance(node, SequenceNode):\n",
   "                    \"expected a sequence node, but found %s\" % node.id,\n",
   "                    node.start_mark)\n",
   "                for child in node.value]\n",
   "        if not isinstance(node, MappingNode):\n",
   "                    \"expected a mapping node, but found %s\" % node.id,\n",
   "                    node.start_mark)\n",
   "        mapping = {}\n",
   "        for key_node, value_node in node.value:\n",
   "            key = self.construct_object(key_node, deep=deep)\n",
   "            if not isinstance(key, collections.Hashable):\n",
   "                raise ConstructorError(\"while constructing a mapping\", node.start_mark,\n",
   "                        \"found unhashable key\", key_node.start_mark)\n",
   "            value = self.construct_object(value_node, deep=deep)\n",
   "            mapping[key] = value\n",
   "        return mapping\n",
   "        if not isinstance(node, MappingNode):\n",
   "                    \"expected a mapping node, but found %s\" % node.id,\n",
   "                    node.start_mark)\n",
   "        pairs = []\n",
   "        for key_node, value_node in node.value:\n",
   "            key = self.construct_object(key_node, deep=deep)\n",
   "            value = self.construct_object(value_node, deep=deep)\n",
   "            pairs.append((key, value))\n",
   "        return pairs\n",
   "        cls.yaml_constructors[tag] = constructor\n",
   "        cls.yaml_multi_constructors[tag_prefix] = multi_constructor\n",
   "        if isinstance(node, MappingNode):\n",
   "            for key_node, value_node in node.value:\n",
   "                if key_node.tag == 'tag:yaml.org,2002:value':\n",
   "                    return self.construct_scalar(value_node)\n",
   "        return super().construct_scalar(node)\n",
   "        merge = []\n",
   "        index = 0\n",
   "        while index < len(node.value):\n",
   "            key_node, value_node = node.value[index]\n",
   "            if key_node.tag == 'tag:yaml.org,2002:merge':\n",
   "                del node.value[index]\n",
   "                if isinstance(value_node, MappingNode):\n",
   "                    self.flatten_mapping(value_node)\n",
   "                    merge.extend(value_node.value)\n",
   "                elif isinstance(value_node, SequenceNode):\n",
   "                    submerge = []\n",
   "                    for subnode in value_node.value:\n",
   "                        if not isinstance(subnode, MappingNode):\n",
   "                                    node.start_mark,\n",
   "                                    % subnode.id, subnode.start_mark)\n",
   "                        self.flatten_mapping(subnode)\n",
   "                        submerge.append(subnode.value)\n",
   "                    submerge.reverse()\n",
   "                    for value in submerge:\n",
   "                        merge.extend(value)\n",
   "                    raise ConstructorError(\"while constructing a mapping\", node.start_mark,\n",
   "                            % value_node.id, value_node.start_mark)\n",
   "            elif key_node.tag == 'tag:yaml.org,2002:value':\n",
   "                key_node.tag = 'tag:yaml.org,2002:str'\n",
   "                index += 1\n",
   "                index += 1\n",
   "        if merge:\n",
   "            node.value = merge + node.value\n",
   "        if isinstance(node, MappingNode):\n",
   "            self.flatten_mapping(node)\n",
   "        return super().construct_mapping(node, deep=deep)\n",
   "        self.construct_scalar(node)\n",
   "        value = self.construct_scalar(node)\n",
   "        return self.bool_values[value.lower()]\n",
   "        value = self.construct_scalar(node)\n",
   "        value = value.replace('_', '')\n",
   "        sign = +1\n",
   "        if value[0] == '-':\n",
   "            sign = -1\n",
   "        if value[0] in '+-':\n",
   "            value = value[1:]\n",
   "        if value == '0':\n",
   "        elif value.startswith('0b'):\n",
   "            return sign*int(value[2:], 2)\n",
   "        elif value.startswith('0x'):\n",
   "            return sign*int(value[2:], 16)\n",
   "        elif value[0] == '0':\n",
   "            return sign*int(value, 8)\n",
   "        elif ':' in value:\n",
   "            digits = [int(part) for part in value.split(':')]\n",
   "            digits.reverse()\n",
   "            base = 1\n",
   "            value = 0\n",
   "            for digit in digits:\n",
   "                value += digit*base\n",
   "                base *= 60\n",
   "            return sign*value\n",
   "            return sign*int(value)\n",
   "    inf_value = 1e300\n",
   "    while inf_value != inf_value*inf_value:\n",
   "        inf_value *= inf_value\n",
   "    nan_value = -inf_value/inf_value   # Trying to make a quiet NaN (like C99).\n",
   "        value = self.construct_scalar(node)\n",
   "        value = value.replace('_', '').lower()\n",
   "        sign = +1\n",
   "        if value[0] == '-':\n",
   "            sign = -1\n",
   "        if value[0] in '+-':\n",
   "            value = value[1:]\n",
   "        if value == '.inf':\n",
   "            return sign*self.inf_value\n",
   "        elif value == '.nan':\n",
   "        elif ':' in value:\n",
   "            digits = [float(part) for part in value.split(':')]\n",
   "            digits.reverse()\n",
   "            base = 1\n",
   "            value = 0.0\n",
   "            for digit in digits:\n",
   "                value += digit*base\n",
   "                base *= 60\n",
   "            return sign*value\n",
   "            return sign*float(value)\n",
   "            value = self.construct_scalar(node).encode('ascii')\n",
   "                    node.start_mark)\n",
   "                return base64.decodebytes(value)\n",
   "                return base64.decodestring(value)\n",
   "                    \"failed to decode base64 data: %s\" % exc, node.start_mark)\n",
   "        value = self.construct_scalar(node)\n",
   "        match = self.timestamp_regexp.match(node.value)\n",
   "        values = match.groupdict()\n",
   "        year = int(values['year'])\n",
   "        month = int(values['month'])\n",
   "        day = int(values['day'])\n",
   "        if not values['hour']:\n",
   "            return datetime.date(year, month, day)\n",
   "        hour = int(values['hour'])\n",
   "        minute = int(values['minute'])\n",
   "        second = int(values['second'])\n",
   "        fraction = 0\n",
   "        if values['fraction']:\n",
   "            fraction = values['fraction'][:6]\n",
   "            while len(fraction) < 6:\n",
   "                fraction += '0'\n",
   "            fraction = int(fraction)\n",
   "        delta = None\n",
   "        if values['tz_sign']:\n",
   "            tz_hour = int(values['tz_hour'])\n",
   "            tz_minute = int(values['tz_minute'] or 0)\n",
   "            delta = datetime.timedelta(hours=tz_hour, minutes=tz_minute)\n",
   "            if values['tz_sign'] == '-':\n",
   "                delta = -delta\n",
   "        data = datetime.datetime(year, month, day, hour, minute, second, fraction)\n",
   "        if delta:\n",
   "            data -= delta\n",
   "        return data\n",
   "        omap = []\n",
   "        yield omap\n",
   "        if not isinstance(node, SequenceNode):\n",
   "            raise ConstructorError(\"while constructing an ordered map\", node.start_mark,\n",
   "                    \"expected a sequence, but found %s\" % node.id, node.start_mark)\n",
   "        for subnode in node.value:\n",
   "            if not isinstance(subnode, MappingNode):\n",
   "                raise ConstructorError(\"while constructing an ordered map\", node.start_mark,\n",
   "                        \"expected a mapping of length 1, but found %s\" % subnode.id,\n",
   "                        subnode.start_mark)\n",
   "            if len(subnode.value) != 1:\n",
   "                raise ConstructorError(\"while constructing an ordered map\", node.start_mark,\n",
   "                        \"expected a single mapping item, but found %d items\" % len(subnode.value),\n",
   "                        subnode.start_mark)\n",
   "            key_node, value_node = subnode.value[0]\n",
   "            key = self.construct_object(key_node)\n",
   "            value = self.construct_object(value_node)\n",
   "            omap.append((key, value))\n",
   "        pairs = []\n",
   "        yield pairs\n",
   "        if not isinstance(node, SequenceNode):\n",
   "            raise ConstructorError(\"while constructing pairs\", node.start_mark,\n",
   "                    \"expected a sequence, but found %s\" % node.id, node.start_mark)\n",
   "        for subnode in node.value:\n",
   "            if not isinstance(subnode, MappingNode):\n",
   "                raise ConstructorError(\"while constructing pairs\", node.start_mark,\n",
   "                        \"expected a mapping of length 1, but found %s\" % subnode.id,\n",
   "                        subnode.start_mark)\n",
   "            if len(subnode.value) != 1:\n",
   "                raise ConstructorError(\"while constructing pairs\", node.start_mark,\n",
   "                        \"expected a single mapping item, but found %d items\" % len(subnode.value),\n",
   "                        subnode.start_mark)\n",
   "            key_node, value_node = subnode.value[0]\n",
   "            key = self.construct_object(key_node)\n",
   "            value = self.construct_object(value_node)\n",
   "            pairs.append((key, value))\n",
   "        data = set()\n",
   "        yield data\n",
   "        value = self.construct_mapping(node)\n",
   "        data.update(value)\n",
   "        return self.construct_scalar(node)\n",
   "        data = []\n",
   "        yield data\n",
   "        data.extend(self.construct_sequence(node))\n",
   "        data = {}\n",
   "        yield data\n",
   "        value = self.construct_mapping(node)\n",
   "        data.update(value)\n",
   "        data = cls.__new__(cls)\n",
   "        yield data\n",
   "        if hasattr(data, '__setstate__'):\n",
   "            state = self.construct_mapping(node, deep=True)\n",
   "            data.__setstate__(state)\n",
   "            state = self.construct_mapping(node)\n",
   "            data.__dict__.update(state)\n",
   "                \"could not determine a constructor for the tag %r\" % node.tag,\n",
   "                node.start_mark)\n",
   "        return self.construct_scalar(node)\n",
   "        return self.construct_scalar(node)\n",
   "            value = self.construct_scalar(node).encode('ascii')\n",
   "                    node.start_mark)\n",
   "                return base64.decodebytes(value)\n",
   "                return base64.decodestring(value)\n",
   "                    \"failed to decode base64 data: %s\" % exc, node.start_mark)\n",
   "        return self.construct_yaml_int(node)\n",
   "       return complex(self.construct_scalar(node))\n",
   "        return tuple(self.construct_sequence(node))\n",
   "            module_name, object_name = name.rsplit('.', 1)\n",
   "            module_name = 'builtins'\n",
   "            object_name = name\n",
   "            __import__(module_name)\n",
   "                    \"cannot find module %r (%s)\" % (module_name, exc), mark)\n",
   "        module = sys.modules[module_name]\n",
   "        if not hasattr(module, object_name):\n",
   "                    % (object_name, module.__name__), mark)\n",
   "        return getattr(module, object_name)\n",
   "        value = self.construct_scalar(node)\n",
   "        if value:\n",
   "            raise ConstructorError(\"while constructing a Python name\", node.start_mark,\n",
   "                    \"expected the empty value, but found %r\" % value, node.start_mark)\n",
   "        return self.find_python_name(suffix, node.start_mark)\n",
   "        value = self.construct_scalar(node)\n",
   "        if value:\n",
   "            raise ConstructorError(\"while constructing a Python module\", node.start_mark,\n",
   "                    \"expected the empty value, but found %r\" % value, node.start_mark)\n",
   "        return self.find_python_module(suffix, node.start_mark)\n",
   "            args = []\n",
   "            kwds = {}\n",
   "        cls = self.find_python_name(suffix, node.start_mark)\n",
   "        if newobj and isinstance(cls, type):\n",
   "            return cls.__new__(cls, *args, **kwds)\n",
   "            return cls(*args, **kwds)\n",
   "            instance.__setstate__(state)\n",
   "            slotstate = {}\n",
   "            if isinstance(state, tuple) and len(state) == 2:\n",
   "                state, slotstate = state\n",
   "                instance.__dict__.update(state)\n",
   "            elif state:\n",
   "                slotstate.update(state)\n",
   "            for key, value in slotstate.items():\n",
   "                setattr(object, key, value)\n",
   "        instance = self.make_python_instance(suffix, node, newobj=True)\n",
   "        yield instance\n",
   "        deep = hasattr(instance, '__setstate__')\n",
   "        state = self.construct_mapping(node, deep=deep)\n",
   "        self.set_python_instance_state(instance, state)\n",
   "        if isinstance(node, SequenceNode):\n",
   "            args = self.construct_sequence(node, deep=True)\n",
   "            kwds = {}\n",
   "            state = {}\n",
   "            value = self.construct_mapping(node, deep=True)\n",
   "            args = value.get('args', [])\n",
   "            kwds = value.get('kwds', {})\n",
   "            state = value.get('state', {})\n",
   "            listitems = value.get('listitems', [])\n",
   "            dictitems = value.get('dictitems', {})\n",
   "        instance = self.make_python_instance(suffix, node, args, kwds, newobj)\n",
   "        if state:\n",
   "            self.set_python_instance_state(instance, state)\n",
   "        if listitems:\n",
   "            instance.extend(listitems)\n",
   "        if dictitems:\n",
   "            for key in dictitems:\n",
   "                instance[key] = dictitems[key]\n",
   "        return instance\n",
   "        return self.construct_python_object_apply(suffix, node, newobj=True)\n"
  ]
 },
 "88": {
  "name": "timestamp_regexp",
  "type": "re",
  "class": "imported",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/vendor/yaml3/constructor.py",
  "lineno": "296",
  "column": "4",
  "context": "ode base64 data: %s\" % exc, node.start_mark)\n\n    timestamp_regexp = re.compile(\n            r'''^(?P<year>[0-9][0-9][0-9][0-9])\n  ",
  "context_lines": "                return base64.decodestring(value)\n        except binascii.Error as exc:\n            raise ConstructorError(None, None,\n                    \"failed to decode base64 data: %s\" % exc, node.start_mark)\n\n    timestamp_regexp = re.compile(\n            r'''^(?P<year>[0-9][0-9][0-9][0-9])\n                -(?P<month>[0-9][0-9]?)\n                -(?P<day>[0-9][0-9]?)\n                (?:(?:[Tt]|[ \\t]+)\n",
  "slicing": [
   "        node = self.get_single_node()\n",
   "        if node is not None:\n",
   "            return self.construct_document(node)\n",
   "        data = self.construct_object(node)\n",
   "            state_generators = self.state_generators\n",
   "            for generator in state_generators:\n",
   "                for dummy in generator:\n",
   "        return data\n",
   "        if node in self.constructed_objects:\n",
   "            return self.constructed_objects[node]\n",
   "            old_deep = self.deep_construct\n",
   "        if node in self.recursive_objects:\n",
   "                    \"found unconstructable recursive node\", node.start_mark)\n",
   "        self.recursive_objects[node] = None\n",
   "        constructor = None\n",
   "        tag_suffix = None\n",
   "        if node.tag in self.yaml_constructors:\n",
   "            constructor = self.yaml_constructors[node.tag]\n",
   "            for tag_prefix in self.yaml_multi_constructors:\n",
   "                if node.tag.startswith(tag_prefix):\n",
   "                    tag_suffix = node.tag[len(tag_prefix):]\n",
   "                    constructor = self.yaml_multi_constructors[tag_prefix]\n",
   "                    tag_suffix = node.tag\n",
   "                    constructor = self.yaml_multi_constructors[None]\n",
   "                    constructor = self.yaml_constructors[None]\n",
   "                elif isinstance(node, ScalarNode):\n",
   "                    constructor = self.__class__.construct_scalar\n",
   "                elif isinstance(node, SequenceNode):\n",
   "                    constructor = self.__class__.construct_sequence\n",
   "                elif isinstance(node, MappingNode):\n",
   "                    constructor = self.__class__.construct_mapping\n",
   "        if tag_suffix is None:\n",
   "            data = constructor(self, node)\n",
   "            data = constructor(self, tag_suffix, node)\n",
   "        if isinstance(data, types.GeneratorType):\n",
   "            generator = data\n",
   "            data = next(generator)\n",
   "                for dummy in generator:\n",
   "                self.state_generators.append(generator)\n",
   "        self.constructed_objects[node] = data\n",
   "        del self.recursive_objects[node]\n",
   "            self.deep_construct = old_deep\n",
   "        return data\n",
   "        if not isinstance(node, ScalarNode):\n",
   "                    \"expected a scalar node, but found %s\" % node.id,\n",
   "                    node.start_mark)\n",
   "        return node.value\n",
   "        if not isinstance(node, SequenceNode):\n",
   "                    \"expected a sequence node, but found %s\" % node.id,\n",
   "                    node.start_mark)\n",
   "                for child in node.value]\n",
   "        if not isinstance(node, MappingNode):\n",
   "                    \"expected a mapping node, but found %s\" % node.id,\n",
   "                    node.start_mark)\n",
   "        mapping = {}\n",
   "        for key_node, value_node in node.value:\n",
   "            key = self.construct_object(key_node, deep=deep)\n",
   "            if not isinstance(key, collections.Hashable):\n",
   "                raise ConstructorError(\"while constructing a mapping\", node.start_mark,\n",
   "                        \"found unhashable key\", key_node.start_mark)\n",
   "            value = self.construct_object(value_node, deep=deep)\n",
   "            mapping[key] = value\n",
   "        return mapping\n",
   "        if not isinstance(node, MappingNode):\n",
   "                    \"expected a mapping node, but found %s\" % node.id,\n",
   "                    node.start_mark)\n",
   "        pairs = []\n",
   "        for key_node, value_node in node.value:\n",
   "            key = self.construct_object(key_node, deep=deep)\n",
   "            value = self.construct_object(value_node, deep=deep)\n",
   "            pairs.append((key, value))\n",
   "        return pairs\n",
   "        cls.yaml_constructors[tag] = constructor\n",
   "        cls.yaml_multi_constructors[tag_prefix] = multi_constructor\n",
   "        if isinstance(node, MappingNode):\n",
   "            for key_node, value_node in node.value:\n",
   "                if key_node.tag == 'tag:yaml.org,2002:value':\n",
   "                    return self.construct_scalar(value_node)\n",
   "        return super().construct_scalar(node)\n",
   "        merge = []\n",
   "        index = 0\n",
   "        while index < len(node.value):\n",
   "            key_node, value_node = node.value[index]\n",
   "            if key_node.tag == 'tag:yaml.org,2002:merge':\n",
   "                del node.value[index]\n",
   "                if isinstance(value_node, MappingNode):\n",
   "                    self.flatten_mapping(value_node)\n",
   "                    merge.extend(value_node.value)\n",
   "                elif isinstance(value_node, SequenceNode):\n",
   "                    submerge = []\n",
   "                    for subnode in value_node.value:\n",
   "                        if not isinstance(subnode, MappingNode):\n",
   "                                    node.start_mark,\n",
   "                                    % subnode.id, subnode.start_mark)\n",
   "                        self.flatten_mapping(subnode)\n",
   "                        submerge.append(subnode.value)\n",
   "                    submerge.reverse()\n",
   "                    for value in submerge:\n",
   "                        merge.extend(value)\n",
   "                    raise ConstructorError(\"while constructing a mapping\", node.start_mark,\n",
   "                            % value_node.id, value_node.start_mark)\n",
   "            elif key_node.tag == 'tag:yaml.org,2002:value':\n",
   "                key_node.tag = 'tag:yaml.org,2002:str'\n",
   "                index += 1\n",
   "                index += 1\n",
   "        if merge:\n",
   "            node.value = merge + node.value\n",
   "        if isinstance(node, MappingNode):\n",
   "            self.flatten_mapping(node)\n",
   "        return super().construct_mapping(node, deep=deep)\n",
   "        self.construct_scalar(node)\n",
   "        value = self.construct_scalar(node)\n",
   "        return self.bool_values[value.lower()]\n",
   "        value = self.construct_scalar(node)\n",
   "        value = value.replace('_', '')\n",
   "        sign = +1\n",
   "        if value[0] == '-':\n",
   "            sign = -1\n",
   "        if value[0] in '+-':\n",
   "            value = value[1:]\n",
   "        if value == '0':\n",
   "        elif value.startswith('0b'):\n",
   "            return sign*int(value[2:], 2)\n",
   "        elif value.startswith('0x'):\n",
   "            return sign*int(value[2:], 16)\n",
   "        elif value[0] == '0':\n",
   "            return sign*int(value, 8)\n",
   "        elif ':' in value:\n",
   "            digits = [int(part) for part in value.split(':')]\n",
   "            digits.reverse()\n",
   "            base = 1\n",
   "            value = 0\n",
   "            for digit in digits:\n",
   "                value += digit*base\n",
   "                base *= 60\n",
   "            return sign*value\n",
   "            return sign*int(value)\n",
   "    inf_value = 1e300\n",
   "    while inf_value != inf_value*inf_value:\n",
   "        inf_value *= inf_value\n",
   "    nan_value = -inf_value/inf_value   # Trying to make a quiet NaN (like C99).\n",
   "        value = self.construct_scalar(node)\n",
   "        value = value.replace('_', '').lower()\n",
   "        sign = +1\n",
   "        if value[0] == '-':\n",
   "            sign = -1\n",
   "        if value[0] in '+-':\n",
   "            value = value[1:]\n",
   "        if value == '.inf':\n",
   "            return sign*self.inf_value\n",
   "        elif value == '.nan':\n",
   "        elif ':' in value:\n",
   "            digits = [float(part) for part in value.split(':')]\n",
   "            digits.reverse()\n",
   "            base = 1\n",
   "            value = 0.0\n",
   "            for digit in digits:\n",
   "                value += digit*base\n",
   "                base *= 60\n",
   "            return sign*value\n",
   "            return sign*float(value)\n",
   "            value = self.construct_scalar(node).encode('ascii')\n",
   "                    node.start_mark)\n",
   "                return base64.decodebytes(value)\n",
   "                return base64.decodestring(value)\n",
   "                    \"failed to decode base64 data: %s\" % exc, node.start_mark)\n",
   "    timestamp_regexp = re.compile(\n",
   "        value = self.construct_scalar(node)\n",
   "        match = self.timestamp_regexp.match(node.value)\n",
   "        values = match.groupdict()\n",
   "        year = int(values['year'])\n",
   "        month = int(values['month'])\n",
   "        day = int(values['day'])\n",
   "        if not values['hour']:\n",
   "            return datetime.date(year, month, day)\n",
   "        hour = int(values['hour'])\n",
   "        minute = int(values['minute'])\n",
   "        second = int(values['second'])\n",
   "        fraction = 0\n",
   "        if values['fraction']:\n",
   "            fraction = values['fraction'][:6]\n",
   "            while len(fraction) < 6:\n",
   "                fraction += '0'\n",
   "            fraction = int(fraction)\n",
   "        delta = None\n",
   "        if values['tz_sign']:\n",
   "            tz_hour = int(values['tz_hour'])\n",
   "            tz_minute = int(values['tz_minute'] or 0)\n",
   "            delta = datetime.timedelta(hours=tz_hour, minutes=tz_minute)\n",
   "            if values['tz_sign'] == '-':\n",
   "                delta = -delta\n",
   "        data = datetime.datetime(year, month, day, hour, minute, second, fraction)\n",
   "        if delta:\n",
   "            data -= delta\n",
   "        return data\n",
   "        omap = []\n",
   "        yield omap\n",
   "        if not isinstance(node, SequenceNode):\n",
   "            raise ConstructorError(\"while constructing an ordered map\", node.start_mark,\n",
   "                    \"expected a sequence, but found %s\" % node.id, node.start_mark)\n",
   "        for subnode in node.value:\n",
   "            if not isinstance(subnode, MappingNode):\n",
   "                raise ConstructorError(\"while constructing an ordered map\", node.start_mark,\n",
   "                        \"expected a mapping of length 1, but found %s\" % subnode.id,\n",
   "                        subnode.start_mark)\n",
   "            if len(subnode.value) != 1:\n",
   "                raise ConstructorError(\"while constructing an ordered map\", node.start_mark,\n",
   "                        \"expected a single mapping item, but found %d items\" % len(subnode.value),\n",
   "                        subnode.start_mark)\n",
   "            key_node, value_node = subnode.value[0]\n",
   "            key = self.construct_object(key_node)\n",
   "            value = self.construct_object(value_node)\n",
   "            omap.append((key, value))\n",
   "        pairs = []\n",
   "        yield pairs\n",
   "        if not isinstance(node, SequenceNode):\n",
   "            raise ConstructorError(\"while constructing pairs\", node.start_mark,\n",
   "                    \"expected a sequence, but found %s\" % node.id, node.start_mark)\n",
   "        for subnode in node.value:\n",
   "            if not isinstance(subnode, MappingNode):\n",
   "                raise ConstructorError(\"while constructing pairs\", node.start_mark,\n",
   "                        \"expected a mapping of length 1, but found %s\" % subnode.id,\n",
   "                        subnode.start_mark)\n",
   "            if len(subnode.value) != 1:\n",
   "                raise ConstructorError(\"while constructing pairs\", node.start_mark,\n",
   "                        \"expected a single mapping item, but found %d items\" % len(subnode.value),\n",
   "                        subnode.start_mark)\n",
   "            key_node, value_node = subnode.value[0]\n",
   "            key = self.construct_object(key_node)\n",
   "            value = self.construct_object(value_node)\n",
   "            pairs.append((key, value))\n",
   "        data = set()\n",
   "        yield data\n",
   "        value = self.construct_mapping(node)\n",
   "        data.update(value)\n",
   "        return self.construct_scalar(node)\n",
   "        data = []\n",
   "        yield data\n",
   "        data.extend(self.construct_sequence(node))\n",
   "        data = {}\n",
   "        yield data\n",
   "        value = self.construct_mapping(node)\n",
   "        data.update(value)\n",
   "        data = cls.__new__(cls)\n",
   "        yield data\n",
   "        if hasattr(data, '__setstate__'):\n",
   "            state = self.construct_mapping(node, deep=True)\n",
   "            data.__setstate__(state)\n",
   "            state = self.construct_mapping(node)\n",
   "            data.__dict__.update(state)\n",
   "                \"could not determine a constructor for the tag %r\" % node.tag,\n",
   "                node.start_mark)\n",
   "        return self.construct_scalar(node)\n",
   "        return self.construct_scalar(node)\n",
   "            value = self.construct_scalar(node).encode('ascii')\n",
   "                    node.start_mark)\n",
   "                return base64.decodebytes(value)\n",
   "                return base64.decodestring(value)\n",
   "                    \"failed to decode base64 data: %s\" % exc, node.start_mark)\n",
   "        return self.construct_yaml_int(node)\n",
   "       return complex(self.construct_scalar(node))\n",
   "        return tuple(self.construct_sequence(node))\n",
   "            module_name, object_name = name.rsplit('.', 1)\n",
   "            module_name = 'builtins'\n",
   "            object_name = name\n",
   "            __import__(module_name)\n",
   "                    \"cannot find module %r (%s)\" % (module_name, exc), mark)\n",
   "        module = sys.modules[module_name]\n",
   "        if not hasattr(module, object_name):\n",
   "                    % (object_name, module.__name__), mark)\n",
   "        return getattr(module, object_name)\n",
   "        value = self.construct_scalar(node)\n",
   "        if value:\n",
   "            raise ConstructorError(\"while constructing a Python name\", node.start_mark,\n",
   "                    \"expected the empty value, but found %r\" % value, node.start_mark)\n",
   "        return self.find_python_name(suffix, node.start_mark)\n",
   "        value = self.construct_scalar(node)\n",
   "        if value:\n",
   "            raise ConstructorError(\"while constructing a Python module\", node.start_mark,\n",
   "                    \"expected the empty value, but found %r\" % value, node.start_mark)\n",
   "        return self.find_python_module(suffix, node.start_mark)\n",
   "            args = []\n",
   "            kwds = {}\n",
   "        cls = self.find_python_name(suffix, node.start_mark)\n",
   "        if newobj and isinstance(cls, type):\n",
   "            return cls.__new__(cls, *args, **kwds)\n",
   "            return cls(*args, **kwds)\n",
   "            instance.__setstate__(state)\n",
   "            slotstate = {}\n",
   "            if isinstance(state, tuple) and len(state) == 2:\n",
   "                state, slotstate = state\n",
   "                instance.__dict__.update(state)\n",
   "            elif state:\n",
   "                slotstate.update(state)\n",
   "            for key, value in slotstate.items():\n",
   "                setattr(object, key, value)\n",
   "        instance = self.make_python_instance(suffix, node, newobj=True)\n",
   "        yield instance\n",
   "        deep = hasattr(instance, '__setstate__')\n",
   "        state = self.construct_mapping(node, deep=deep)\n",
   "        self.set_python_instance_state(instance, state)\n",
   "        if isinstance(node, SequenceNode):\n",
   "            args = self.construct_sequence(node, deep=True)\n",
   "            kwds = {}\n",
   "            state = {}\n",
   "            value = self.construct_mapping(node, deep=True)\n",
   "            args = value.get('args', [])\n",
   "            kwds = value.get('kwds', {})\n",
   "            state = value.get('state', {})\n",
   "            listitems = value.get('listitems', [])\n",
   "            dictitems = value.get('dictitems', {})\n",
   "        instance = self.make_python_instance(suffix, node, args, kwds, newobj)\n",
   "        if state:\n",
   "            self.set_python_instance_state(instance, state)\n",
   "        if listitems:\n",
   "            instance.extend(listitems)\n",
   "        if dictitems:\n",
   "            for key in dictitems:\n",
   "                instance[key] = dictitems[key]\n",
   "        return instance\n",
   "        return self.construct_python_object_apply(suffix, node, newobj=True)\n"
  ]
 },
 "89": {
  "name": "initial_state",
  "type": "str",
  "class": "build-in",
  "approach": "Pysonar2",
  "file_path": "invoke/invoke/parser/parser.py",
  "lineno": "177",
  "column": "4",
  "context": "rn result\n\n\nclass ParseMachine(StateMachine):\n    initial_state = \"context\"\n\n    state(\"context\", enter=[\"complete_flag\", \"com",
  "context_lines": "        result = machine.result\n        result.remainder = \" \".join(remainder)\n        return result\n\n\nclass ParseMachine(StateMachine):\n    initial_state = \"context\"\n\n    state(\"context\", enter=[\"complete_flag\", \"complete_context\"])\n    state(\"unknown\", enter=[\"complete_flag\", \"complete_context\"])\n    state(\"end\", enter=[\"complete_flag\", \"complete_context\"])\n\n",
  "slicing": "    initial_state = \"context\"\n"
 }
}